[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.10.28
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-25**|**Evaluation of strategies for efficient rate-distortion NeRF streaming**|神经辐射场（NeRF）通过从稀疏的图像集实现高度逼真和详细的场景重建，彻底改变了3D视觉表示领域。NeRF使用体积函数表示法，将3D点映射到其相应的颜色和不透明度，从而允许从任意视点进行逼真的视图合成。尽管取得了进步，但由于涉及大量数据，NeRF内容的高效流式传输仍然是一个重大挑战。本文研究了两种NeRF流媒体策略的率失真性能：基于像素的流媒体和基于神经网络（NN）参数的流媒体。在前者中，图像被编码并随后在整个网络中传输，而在后者中，相应的NeRF模型参数被编码并传输。这项工作还强调了复杂性和性能之间的权衡，表明基于NN参数的策略通常具有更高的效率，使其适用于一对多的流媒体场景。 et.al.|[2410.19459](http://arxiv.org/abs/2410.19459)|null|
|**2024-10-24**|**Where Am I and What Will I See: An Auto-Regressive Model for Spatial Localization and View Prediction**|空间智能是机器在空间和时间的三维空间中感知、推理和行动的能力。大规模自回归模型的最新进展在各种推理任务中表现出了显著的能力。然而，这些模型经常在空间推理的基本方面遇到困难，特别是在回答“我在哪里？”和“我会看到什么？”等问题时。虽然已经进行了一些尝试，但现有的方法通常将它们视为单独的任务，未能捕捉到它们相互关联的性质。在本文中，我们提出了生成空间变换器（GST），这是一种新型的自回归框架，可以同时解决空间定位和视图预测问题。我们的模型同时从单个图像中估计相机姿态，并从新的相机姿态预测视图，有效地弥合了空间感知和视觉预测之间的差距。所提出的创新相机标记化方法使模型能够以自回归的方式学习2D投影的联合分布及其相应的空间视角。这种统一的训练范式表明，姿态估计和新颖视图合成的联合优化首次提高了这两项任务的性能，突出了空间感知和视觉预测之间的内在关系。 et.al.|[2410.18962](http://arxiv.org/abs/2410.18962)|null|
|**2024-10-24**|**Binocular-Guided 3D Gaussian Splatting with View Consistency for Sparse View Synthesis**|稀疏输入的新颖视图合成是3D计算机视觉中一项至关重要但具有挑战性的任务。之前的方法探索了使用神经先验（如深度先验）作为额外监督的3D高斯散斑，与基于NeRF的方法相比，显示出有前景的质量和效率。然而，来自2D预训练模型的神经先验通常是嘈杂和模糊的，这很难精确地指导辐射场的学习。在本文中，我们提出了一种新的方法，通过高斯散斑从稀疏视图合成新视图，该方法不需要外部先验作为监督。我们的关键思想在于探索通过视差引导图像扭曲构建的每对双目图像之间的双目立体一致性所固有的自我监督。为此，我们还引入了高斯不透明度约束，该约束使高斯位置正则化，避免了高斯冗余，以提高从稀疏视图推断3D高斯的鲁棒性和效率。在LLFF、DTU和Blender数据集上进行的广泛实验表明，我们的方法明显优于最先进的方法。 et.al.|[2410.18822](http://arxiv.org/abs/2410.18822)|null|
|**2024-10-23**|**FreeVS: Generative View Synthesis on Free Driving Trajectory**|现有的基于重建的新型驾驶场景视图合成方法侧重于沿自我车辆记录的轨迹合成相机视图。当视点偏离记录的轨迹，相机光线未经训练时，它们的图像渲染性能将严重下降。我们提出了FreeVS，这是一种新颖的完全生成方法，可以在真实驾驶场景中合成自由新轨迹上的相机视图。为了控制生成结果与真实场景的3D一致性和视点姿态的准确性，我们提出了视图先验的伪图像表示来控制生成过程。视点变换模拟应用于伪图像，以模拟相机在每个方向上的运动。一旦经过训练，FreeVS可以应用于任何验证序列，而无需对新轨迹进行重建过程和合成视图。此外，我们提出了两个针对驾驶场景量身定制的具有挑战性的新基准，即新颖的相机合成和新颖的轨迹合成，强调视点的自由度。鉴于新轨迹上没有地面真实图像，我们还建议用3D感知模型评估新轨迹上合成的图像的一致性。在Waymo开放数据集上的实验表明，FreeVS在记录的轨迹和新的轨迹上都具有很强的图像合成性能。项目页面：https://freevs24.github.io/ et.al.|[2410.18079](http://arxiv.org/abs/2410.18079)|null|
|**2024-10-23**|**VR-Splatting: Foveated Radiance Field Rendering via 3D Gaussian Splatting and Neural Points**|新视图合成（NVS）的最新进展，特别是神经辐射场（NeRF）和高斯溅射（3DGS），在真实感场景渲染方面取得了令人印象深刻的结果。这些技术在虚拟旅游和隐形传态中具有巨大的应用潜力，其中沉浸式真实感至关重要。然而，由于延迟和计算限制，虚拟现实（VR）系统的高性能需求给直接利用如此快速的渲染3DGS等场景表示带来了挑战。在本文中，我们提出了中心凹渲染作为解决这些障碍的有前景的解决方案。我们分析了最先进的NVS方法的渲染性能和与人类视觉系统的兼容性。我们的方法为虚拟现实引入了一种新的中心凹渲染方法，该方法利用了中心凹区域神经点渲染的清晰、详细的输出，并与周边视觉的3DGS平滑渲染相融合。我们的评估证实，与标准的VR就绪3DGS配置相比，我们的方法提高了感知的清晰度和细节丰富性。我们的系统满足了实时VR交互的必要性能要求，最终增强了用户的沉浸式体验。项目页面：https://lfranke.github.io/vr_splatting et.al.|[2410.17932](http://arxiv.org/abs/2410.17932)|null|
|**2024-10-23**|**Few-shot NeRF by Adaptive Rendering Loss Regularization**|稀疏输入的新型视图合成对神经辐射场（NeRF）提出了巨大挑战。最近的工作表明，位置编码（PE）的频率正则化可以在少镜头NeRF中取得有前景的结果。在这项工作中，我们发现PE的频率正则化和渲染损失之间存在不一致。这使得很少拍摄的NeRF无法合成更高质量的新颖视图。为了减轻这种不一致性，我们提出了针对少镜头NeRF的自适应渲染损失正则化，称为AR NeRF。具体来说，我们提出了一种两阶段渲染监督和一种自适应渲染损失权重学习策略，以对齐PE和2D像素监督之间的频率关系。通过这种方式，AR NeRF可以在早期训练阶段更好地学习全局结构，并在整个训练过程中自适应地学习局部细节。广泛的实验表明，我们的AR NeRF在不同的数据集上实现了最先进的性能，包括对象级和复杂场景。 et.al.|[2410.17839](http://arxiv.org/abs/2410.17839)|null|
|**2024-10-22**|**SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes**|我们提出了SpectroMotion，这是一种将3D高斯散斑（3DGS）与基于物理的渲染（PBR）和变形场相结合的新方法，用于重建动态镜面场景。以前将3DGS扩展到动态场景建模的方法很难准确地表示镜面反射表面。我们的方法通过引入残差校正技术来解决这一局限性，该技术用于在变形过程中进行精确的表面法线计算，并辅以适应时变照明条件的可变形环境贴图。我们实施了一种从粗到细的训练策略，显著增强了场景几何和镜面颜色预测。我们证明，我们的模型在包含动态镜面对象的场景的视图合成方面优于现有的方法，并且它是唯一能够合成逼真的真实世界动态镜面场景的3DGS方法，在渲染复杂、动态和镜面场景方面优于最先进的方法。 et.al.|[2410.17249](http://arxiv.org/abs/2410.17249)|null|
|**2024-10-22**|**LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias**|我们提出了大视图合成模型（LVSM），这是一种基于变换器的新方法，用于从稀疏视图输入中进行可扩展和可推广的新视图合成。我们介绍了两种架构：（1）编码器-解码器LVSM，它将输入图像令牌编码为固定数量的1D潜在令牌，作为完全学习的场景表示，并从中解码出新的视图图像；以及（2）仅解码器LVSM，它直接将输入图像映射到新的视图输出，完全消除了中间场景表示。这两种模型都绕过了以前方法中使用的3D感应偏差——从3D表示（如NeRF、3DGS）到网络设计（如极线投影、平面扫描）——用完全数据驱动的方法解决了新颖的视图合成问题。虽然编码器-解码器模型由于其独立的潜在表示而提供了更快的推断，但仅解码器的LVSM实现了卓越的质量、可扩展性和零样本泛化，比以前最先进的方法高1.5至3.5 dB PSNR。对多个数据集的综合评估表明，这两种LVSM变体都达到了最先进的新颖视图合成质量。值得注意的是，即使计算资源减少（1-2个GPU），我们的模型也超越了所有以前的方法。请访问我们的网站了解更多详情：https://haian-jin.github.io/projects/LVSM/ . et.al.|[2410.17242](http://arxiv.org/abs/2410.17242)|null|
|**2024-10-22**|**VistaDream: Sampling multiview consistent images for single-view scene reconstruction**|本文中，我们提出了一种新的框架VistaDream，用于从单视图图像重建3D场景。最近的扩散模型能够从单个视图输入图像生成高质量的新颖视图图像。大多数现有的方法只专注于建立输入图像和生成图像之间的一致性，而失去了生成图像间的一致性。VistaDream通过两阶段管道解决了这个问题。在第一阶段，VistaDream从构建一个全局粗略的3D脚手架开始，通过缩小一小步来修复边界和估计深度图。然后，在这个全局支架上，我们使用基于迭代扩散的RGB-D修复来生成新的视图图像，以修复支架的孔。在第二阶段，我们通过一种新的无训练多视图一致性采样（MCS）进一步增强了生成的新视图图像之间的一致性，该MCS在扩散模型的反向采样过程中引入了多视图一致度约束。实验结果表明，在不训练或微调现有扩散模型的情况下，VistaDream仅使用单视图图像即可实现一致和高质量的新视图合成，并且远远优于基线方法。代码、视频和交互式演示可在以下网址获得https://vistadream-project-page.github.io/. et.al.|[2410.16892](http://arxiv.org/abs/2410.16892)|null|
|**2024-10-21**|**FrugalNeRF: Fast Convergence for Few-shot Novel View Synthesis without Learned Priors**|神经辐射场（NeRF）在少数拍摄场景中面临着重大挑战，主要是由于高保真渲染的过拟合和长训练时间。现有的方法，如FreeNeRF和SparseNeRF，使用频率正则化或预训练先验，但难以应对复杂的调度和偏差。我们介绍了FrugalNeRF，这是一种新颖的少镜头NeRF框架，它利用跨多个尺度的权重共享体素来有效地表示场景细节。我们的主要贡献是一种跨尺度几何自适应方案，该方案基于跨尺度的重投影误差来选择伪地面真值深度。这可以指导培训，而不依赖于外部学习的先验知识，从而充分利用培训数据。它还可以整合预先训练的先验，在不减缓收敛的情况下提高质量。在LLFF、DTU和RealEstate-10K上的实验表明，FrugalNeRF优于其他少镜头NeRF方法，同时显著减少了训练时间，使其成为高效准确的3D场景重建的实用解决方案。 et.al.|[2410.16271](http://arxiv.org/abs/2410.16271)|null|

<p align=right>(<a href=#updated-on-20241028>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-24**|**Large Spatial Model: End-to-end Unposed Images to Semantic 3D**|从有限数量的图像重建和理解3D结构是计算机视觉中一个公认的问题。传统方法通常将此任务分解为多个子任务，每个子任务都需要在不同数据表示之间进行复杂的转换。例如，通过运动结构（SfM）进行密集重建涉及将图像转换为关键点、优化相机参数和估计结构。之后，需要精确的稀疏重建来进行进一步的密集建模，随后将其输入到特定任务的神经网络中。这种多步骤的过程导致了相当长的处理时间和工程复杂性的增加。在这项工作中，我们提出了大空间模型（LSM），它将未经处理的RGB图像直接处理成语义辐射场。LSM在单个前馈操作中同时估计几何、外观和语义，并且可以通过在新的视点与语言交互来生成通用的标签图。LSM利用基于Transformer的架构，通过像素对齐的点图集成全局几何。为了增强空间属性回归，我们将局部上下文聚合与多尺度融合相结合，提高了精细局部细节的准确性。为了解决标记的3D语义数据的稀缺性并实现自然语言驱动的场景操纵，我们将一个预先训练的基于2D语言的分割模型整合到一个3D一致的语义特征字段中。然后，一个高效的解码器将一组语义各向异性高斯分布参数化，从而促进有监督的端到端学习。在各种任务中的广泛实验表明，LSM直接从无基图像中统一了多个3D视觉任务，首次实现了实时语义3D重建。 et.al.|[2410.18956](http://arxiv.org/abs/2410.18956)|null|
|**2024-10-24**|**A Cranial-Feature-Based Registration Scheme for Robotic Micromanipulation Using a Microscopic Stereo Camera System**|生物标本在大小和形状上表现出显著的变化，对自主机器人操作提出了挑战。我们专注于鼠标头骨窗口创建任务来说明这些挑战。该研究引入了一种由深度感知线性模型增强的微观立体相机系统（MSCS）。除此之外，还为部分暴露的小鼠颅骨表面开发了一种精确的配准方案，采用基于CNN的约束和彩色配准策略。这些方法与MSCS集成，用于机器人微操作任务。MSCS在台阶高度实验中测得的精度高达0.10 mm，在3D重建中的实时性能为30 FPS。该配准方案证明了其精度，在105个连续帧上以1.60 FPS的平均速度测试了1.13 mm的平移误差和3.38 mm的旋转误差。本研究介绍了MSCS和一种新的配准方案在提高科学和手术环境中机器人微操作的精度和准确性方面的应用。这里提出的创新提供了处理显微操作挑战的自动化方法，为显微手术和科学研究各个领域更准确、更高效、侵入性更小的手术铺平了道路。 et.al.|[2410.18630](http://arxiv.org/abs/2410.18630)|null|
|**2024-10-22**|**SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes**|我们提出了SpectroMotion，这是一种将3D高斯散斑（3DGS）与基于物理的渲染（PBR）和变形场相结合的新方法，用于重建动态镜面场景。以前将3DGS扩展到动态场景建模的方法很难准确地表示镜面反射表面。我们的方法通过引入残差校正技术来解决这一局限性，该技术用于在变形过程中进行精确的表面法线计算，并辅以适应时变照明条件的可变形环境贴图。我们实施了一种从粗到细的训练策略，显著增强了场景几何和镜面颜色预测。我们证明，我们的模型在包含动态镜面对象的场景的视图合成方面优于现有的方法，并且它是唯一能够合成逼真的真实世界动态镜面场景的3DGS方法，在渲染复杂、动态和镜面场景方面优于最先进的方法。 et.al.|[2410.17249](http://arxiv.org/abs/2410.17249)|null|
|**2024-10-22**|**E-3DGS: Gaussian Splatting with Exposure and Motion Events**|从最佳条件下捕获的图像中估计神经辐射场（NeRF）在视觉界得到了广泛的探索。然而，机器人应用经常面临运动模糊、照明不足和计算开销高等挑战，这些挑战对导航、检查和场景可视化等下游任务产生了不利影响。为了应对这些挑战，我们提出了E-3DGS，这是一种基于事件的新方法，将事件划分为运动（来自相机或物体运动）和曝光（来自相机曝光），使用前者来处理快速运动的场景，使用后者来重建灰度图像，以进行基于事件的3D高斯散斑（3DGS）的高质量训练和优化。我们介绍了一种将3DGS与曝光事件相结合的新方法，用于高质量重建显式场景表示。我们的多功能框架可以单独操作运动事件进行3D重建，使用曝光事件提高质量，或者采用混合模式，通过优化初始曝光事件和高速运动事件来平衡质量和有效性。我们还介绍了EME-3D，这是一个真实世界的3D数据集，包含曝光事件、运动事件、相机校准参数和稀疏点云。我们的方法比基于事件的NeRF更快，重建质量更好，同时比使用单个事件传感器组合事件和RGB数据的NeRF方法更具成本效益。通过结合运动和曝光事件，E-3DGS为基于事件的3D重建设定了新的基准，在具有挑战性的条件下和较低的硬件需求下具有强大的性能。源代码和数据集将在https://github.com/MasterHow/E-3DGS. et.al.|[2410.16995](http://arxiv.org/abs/2410.16995)|**[link](https://github.com/masterhow/e-3dgs)**|
|**2024-10-21**|**MvDrag3D: Drag-based Creative 3D Editing via Multi-view Generation-Reconstruction Priors**|在图像生成模型的推动下，基于拖动的编辑在2D内容创建中变得流行起来。然而，将这项技术扩展到3D仍然是一个挑战。现有的基于3D拖动的编辑方法，无论是采用显式空间变换还是依赖于有限容量3D生成模型中的隐式潜在优化，在处理重大拓扑变化或跨不同对象类别生成新纹理方面都存在不足。为了克服这些局限性，我们引入了MVDrag3D，这是一种利用多视图生成和重建先验进行更灵活、更有创意的基于拖动的3D编辑的新框架。我们方法的核心是使用多视图扩散模型作为强生成模型，然后在多个渲染视图上执行一致的拖动编辑，接着是重建模型，重建编辑对象的3D高斯分布。虽然初始的3D高斯分布可能会在不同视图之间出现错位，但我们通过视图特定的变形网络来解决这个问题，该网络可以调整高斯分布的位置以使其很好地对齐。此外，我们提出了一种多视图评分函数，从多个视图中提取生成先验，以进一步提高视图的一致性和视觉质量。大量实验表明，MVDrag3D为基于3D拖动的编辑提供了一种精确、生成和灵活的解决方案，支持各种对象类别和3D表示的更通用的编辑效果。 et.al.|[2410.16272](http://arxiv.org/abs/2410.16272)|null|
|**2024-10-22**|**LucidFusion: Generating 3D Gaussians with Arbitrary Unposed Images**|最近的大型重建模型在从单个图像生成高质量3D对象方面取得了显著进展。然而，这些方法往往难以控制，因为它们缺乏来自多个视图的信息，导致不完整或不一致的3D重建。为了解决这一局限性，我们引入了LucidFusion，这是一种灵活的端到端前馈框架，利用了相对坐标图（RCM）。与传统的通过姿势将图像与3D世界联系起来的方法不同，LucidFusion利用RCM在不同的视图中连贯地对齐几何特征，使其高度适用于从任意、未经处理的图像生成3D。此外，LucidFusion与原始的单图像到3D流水线无缝集成，以512美元乘以512美元的分辨率生成详细的3D高斯分布，使其非常适合广泛的应用。 et.al.|[2410.15636](http://arxiv.org/abs/2410.15636)|null|
|**2024-10-19**|**EndoMetric: Near-light metric scale monocular SLAM**|近年来，内窥镜图像的几何重建和SLAM取得了重大进展。在大多数医学专业中，使用的内窥镜是单眼的，所应用的算法通常是为外部环境设计的算法的扩展，从而产生高达未知比例因子的3D重建。在这篇论文中，我们利用了这样一个事实，即标准内窥镜配备了近光源，这些近光源位于距离相机较小但非零的基线处。通过利用光衰减的平方反比定律，我们首次实现了具有精确度量尺度的单眼重建。这为将任何内窥镜转换为公制设备铺平了道路，这对于测量息肉、狭窄或受疾病影响的组织范围等实际应用至关重要。 et.al.|[2410.15065](http://arxiv.org/abs/2410.15065)|null|
|**2024-10-17**|**Object Pose Estimation Using Implicit Representation For Transparent Objects**|物体姿态估计是计算机视觉中的一项重要任务。物体姿态给出了物体在现实世界空间中的方向和平移，这允许各种应用，如操纵、增强现实等。各种物体对光表现出不同的特性，如反射、吸收等。这使得在RGB和深度通道中理解对象的结构变得具有挑战性。最近的研究一直在向基于学习的方法发展，这些方法利用深度学习为对象姿态估计提供了一种更灵活、更通用的方法。一种这样的方法是渲染和比较方法，该方法从多个视图渲染对象并将其与给定的2D图像进行比较，这通常需要CAD模型形式的对象表示。我们认为CAD模型的合成纹理可能不适合渲染和比较操作。我们发现，如果对象以神经辐射场（NeRF）的形式表示为隐式（神经）表示，它会对实际场景进行更逼真的渲染，并保留关键的空间特征，这使得比较更加通用。我们在透明数据集上评估了渲染和比较方法的NeRF实现，发现它超过了当前最先进的结果。 et.al.|[2410.13465](http://arxiv.org/abs/2410.13465)|null|
|**2024-10-18**|**Context-Enhanced Multi-View Trajectory Representation Learning: Bridging the Gap through Self-Supervised Models**|使用通用密集表示对轨迹数据进行建模已成为各种下游应用的流行范式，如轨迹分类、行程时间估计和相似性计算。然而，现有的方法通常依赖于单一空间视图的轨迹，限制了它们捕获丰富上下文信息的能力，而丰富上下文信息对于深入了解不同地理空间背景下的运动模式至关重要。为此，我们提出了MVTraj，这是一种用于轨迹表示学习的新型多视图建模方法。MVTraj整合了从GPS到道路网络和兴趣点的各种背景知识，以更全面地了解轨迹数据。为了在多个视图之间对齐学习过程，我们利用GPS轨迹作为桥梁，并采用自我监督的借口任务来捕捉和区分不同空间视图之间的运动模式。在此之后，我们将来自不同视角的轨迹视为不同的模态，并应用分层跨模态交互模块来融合表示，从而丰富了从多个来源获得的知识。对真实世界数据集的广泛实验表明，MVTraj在与各种空间视图相关的任务中明显优于现有基线，验证了其在时空建模中的有效性和实用性。 et.al.|[2410.13196](http://arxiv.org/abs/2410.13196)|null|
|**2024-10-18**|**UniG: Modelling Unitary 3D Gaussians for View-consistent 3D Reconstruction**|在这项工作中，我们提出了UniG，这是一种视图一致的3D重建和新颖的视图合成模型，可以从稀疏图像中生成3D高斯的高保真表示。现有的基于3D高斯的方法通常对每个视图的每个像素进行高斯回归，分别为每个视图创建3D高斯，并通过点连接将其合并。这种与视图无关的重建方法通常会导致视图不一致问题，其中来自不同视图的同一3D点的预测位置可能存在差异。为了解决这个问题，我们开发了一个类似DETR（DEtect TRansformer）的框架，该框架将3D高斯视为解码器查询，并通过在多个输入图像上执行多视图交叉注意（MVDFA）来逐层更新其参数。通过这种方式，多个视图自然有助于对3D高斯的统一表示进行建模，从而使3D重建更加视图一致。此外，由于用作解码器查询的3D高斯数与输入视图的数量无关，因此允许任意数量的输入图像，而不会导致内存爆炸。大量的实验验证了我们的方法的优势，在定量和定性上展示了优于现有方法的性能（在Objaverse上训练并在GSO基准上测试时，PSNR提高了4.2 dB）。该代码将于https://github.com/jwubz123/UNIG. et.al.|[2410.13195](http://arxiv.org/abs/2410.13195)|**[link](https://github.com/jwubz123/UNIG)**|

<p align=right>(<a href=#updated-on-20241028>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-25**|**Adversarial Environment Design via Regret-Guided Diffusion Models**|训练对环境变化具有鲁棒性的代理仍然是深度强化学习（RL）中的一个重大挑战。最近出现了无监督环境设计（UED），通过生成一组针对代理能力量身定制的训练环境来解决这个问题。虽然先前的工作表明UED具有学习稳健策略的潜力，但它们的性能受到环境生成能力的限制。为此，我们提出了一种新的UED算法，即通过后悔引导扩散模型（ADD）进行对抗环境设计。所提出的方法引导基于扩散的环境生成器在代理感到遗憾的情况下生成代理认为具有挑战性但有利于进一步改进的环境。通过利用扩散模型的表示能力，ADD可以直接生成对抗环境，同时保持训练环境的多样性，使代理能够有效地学习稳健的策略。我们的实验结果表明，所提出的方法成功地生成了具有指导意义的环境课程，在新的分布外环境中，在零样本泛化中优于UED基线。项目页面：https://github.com/rllab-snu.github.io/projects/ADD et.al.|[2410.19715](http://arxiv.org/abs/2410.19715)|null|
|**2024-10-25**|**Sylvester-Preconditioned Adaptive-Rank Implicit Time Integrators for Advection-Diffusion Equations with Inhomogeneous Coefficients**|我们考虑了具有空间变系数的一般时变平流扩散偏微分方程（PDE）的自适应秩积分。我们采用标准有限差分法进行空间离散化，并结合对角隐式龙格-库塔方案进行时间离散化。完全离散化方案可以写成广义Sylvester方程，我们使用围绕三个关键策略构建的自适应秩算法求解：（i）基于扩展的Krylov策略构建维度子空间，（ii）开发一个有效的平均系数Sylvester（ACS）预处理器，以有效地反转系数矩阵的缩减系统，以及（iii）在不显式恢复到全秩形式的情况下有效地计算方程的残差。所提出的方法的计算复杂度为O（Nr2+r3），其中r表示Krylov迭代过程中的秩，N是一维的分辨率，与常系数情况相称[El Kahza等人，J.Comput.Phys。，518（2024）]。我们给出了数值例子，说明了我们算法的计算效率和复杂性。 et.al.|[2410.19662](http://arxiv.org/abs/2410.19662)|null|
|**2024-10-25**|**DiffGS: Functional Gaussian Splatting Diffusion**|3D高斯散点（3DGS）在渲染速度和保真度方面表现出了令人信服的性能，但由于其离散性和非结构化特性，高斯散点的生成仍然是一个挑战。在这项工作中，我们提出了DiffGS，一种基于潜在扩散模型的通用高斯生成器。DiffGS是一种强大而高效的3D生成模型，能够生成任意数量的高斯基元，用于光栅化的高保真渲染。关键的见解是通过三个新颖的函数来模拟高斯概率、颜色和变换，以一种解纠缠的方式表示高斯散斑。通过3DGS的新颖解纠缠，我们用连续高斯散布函数表示离散和非结构化的3DGS，然后我们训练一个潜在的扩散模型，目标是无条件和有条件地生成这些高斯散布函数。同时，我们引入了一种离散化算法，通过八叉树引导采样和优化从生成的函数中提取任意数量的高斯分布。我们探索了DiffGS的各种任务，包括无条件生成、从文本、图像和部分3DGS的条件生成，以及点到高斯的生成。我们认为，DiffGS为灵活建模和生成高斯散斑提供了新的方向。 et.al.|[2410.19657](http://arxiv.org/abs/2410.19657)|null|
|**2024-10-25**|**Planning-Aware Diffusion Networks for Enhanced Motion Forecasting in Autonomous Driving**|自动驾驶技术已经取得了重大进展，但现有的模型往往无法完全捕捉到多智能体环境的复杂性，在这种环境中，动态智能体之间的交互至关重要。为了解决这个问题，我们提出了规划综合预测模型（PIFM），这是一个受大脑中控制决策和多智能体协调的神经机制启发的新框架。PIFM利用丰富的上下文信息，整合道路结构、交通规则和周围车辆的行为，以提高预测的准确性和可解释性。通过采用基于扩散的架构，类似于预测和规划中涉及的神经扩散过程，PIFM能够预测场景中所有智能体的未来轨迹。这种架构提高了模型的透明度，因为它与大脑根据外部刺激和其他智能体的行为动态调整预测的方法相似。广泛的实验验证了PIFM能够以极低的参数数量为更安全、更高效的自动驾驶系统提供可解释的、神经科学驱动的解决方案。 et.al.|[2410.19639](http://arxiv.org/abs/2410.19639)|null|
|**2024-10-25**|**Improved performance of polycrystalline antiferromagnet/ferromagnet stack by nitrogen assisted deposition**|在磁控溅射Co $_{70}$Fe$_{30}$层的过程中，通过在氩等离子体中引入氮添加剂，对反铁磁体/铁磁体（AF/FM）型IrMn$_3$/Co$_{70}$Fe$_{30}$双层的沉积过程进行了改进。对于IrMn层厚度在20{\AA}至50{\AA]范围内的情况，这种轻微的修改显著提高了AF/FM双层的交换偏置能量，并降低了FM层的矫顽力。计算表明，交换偏置能量的提高和矫顽力的降低可归因于反铁磁体各向异性能量的增加，从而导致反铁磁晶粒对铁磁体的更有效钉扎。各向异性的增加是由氮从FM扩散到AF层引起的，如X射线衍射、中子反射计和X射线磁圆二色性所确定的。我们的研究允许通过对溅射工艺进行微小修改来改善交换耦合FM/AF结构的磁特性，和/或通过减小AF层的厚度来节省高达20%的昂贵IrMn$_3$ 靶材。 et.al.|[2410.19620](http://arxiv.org/abs/2410.19620)|null|
|**2024-10-25**|**Diffusion models for lattice gauge field simulations**|我们开发了基于随机量子化概念的晶格规范理论的扩散模型。该框架应用于 $1+1$维度的$U（1）$ 规范理论。我们证明，在一个小的逆耦合下训练的模型可以有效地转移到更大的逆耦合，而不会遇到与拓扑冻结相关的问题，即该模型可以通过引入玻尔兹曼因子作为物理条件来生成与不同耦合相对应的配置，同时保持正确的物理分布，而无需任何额外的训练。这证明了物理条件扩散模型在高效和灵活的晶格规范理论模拟中的潜力。 et.al.|[2410.19602](http://arxiv.org/abs/2410.19602)|null|
|**2024-10-25**|**Utilizing Image Transforms and Diffusion Models for Generative Modeling of Short and Long Time Series**|最近，人们对时间序列数据的生成建模兴趣激增。大多数现有的方法都是为了处理短序列或处理长序列而设计的。这种二分法可归因于循环网络的梯度问题、与变压器相关的计算成本以及状态空间模型的有限表达能力。针对变长时间序列的统一生成模型，我们在这项工作中提出将序列转换为图像。通过采用延迟嵌入和短时傅里叶变换等可逆变换，我们解锁了三个主要优点：i）我们可以利用先进的扩散视觉模型；ii）我们可以在同一框架内显著处理短期和长期输入；以及iii）我们可以利用时间序列中提出的最新和已建立的工具来形象化文献。我们通过跨多个任务的综合评估来验证我们方法的有效性，包括无条件生成、插值和外推。我们证明，我们的方法在强有力的基线下取得了始终如一的最新成果。在无条件生成任务中，我们在短判别得分上比之前的扩散模型显著提高了58.17%，在（超）长分类得分上平均提高了132.61%。代码位于https://github.com/azencot-group/ImagenTime. et.al.|[2410.19538](http://arxiv.org/abs/2410.19538)|null|
|**2024-10-25**|**Ensemble Data Assimilation for Particle-based Methods**|本研究提出了一种使用集成卡尔曼滤波器将数据同化技术应用于基于粒子的模拟的新方法。虽然数据同化方法已被有效地应用于欧拉模拟，但它们在拉格朗日解离散化中的应用尚未得到适当的探索。我们介绍了两种具体的方法来解决这一差距。第一种方法采用中间欧拉变换，将投影与重网格过程相结合。第二种是纯拉格朗日方案，专为不适合重新网格划分的情况而设计。第二种是纯拉格朗日方案，适用于不进行网格重划分的情况。这些方法使用具有周期性边界的一维平流扩散模型进行评估。一维场景的性能基准是针对基于网格的同化滤波器进行的。随后，同化方案被应用于非线性二维不可压缩流问题，通过涡胞法求解。结果表明，在更复杂的场景中应用这些方法是可行的，突出了它们在一维和二维环境中的有效性。 et.al.|[2410.19525](http://arxiv.org/abs/2410.19525)|null|
|**2024-10-25**|**Nutation-orbit resonances: The origin of the chaotic rotation of Hyperion and the barrel instability**|虽然许多行星和小行星卫星显示出非平凡旋转状态的证据，但没有一个像Hyperion那样具有象征意义，Hyperion长期以来一直被认为是太阳系中混沌自旋轨道演化的最引人注目的例子。然而，尚未开发出一种可分析的Hyperion全三维自旋轨道动力学理论。我们推导了行星引力势中旋转轴对称卫星的哈密顿量，而不需要假设平面或主轴旋转，也不需要在自旋周期内进行平均。使用这个模型，我们证明了章动频率和轨道频率之间共振的出现，这些共振是自旋动力学的主要驱动因素。这一分析表明，与长期以来的信念相反，海伯利安号并没有混乱地翻滚。相反，它位于偏心率为一阶的章动轨道共振附近或其中，使其能够准规则地旋转。最可靠的观测结果与非混沌运动或比最初声称的小几个数量级的混沌一致。一个单独的现象，即所谓的桶不稳定性，被证明与一组不同的章动轨道共振有关，这些共振推广了平面自旋轨道共振。最后，我们表明，通过考虑准守恒量的混沌扩散，可以最好地理解自旋态在长时间尺度上的变化。 et.al.|[2410.19518](http://arxiv.org/abs/2410.19518)|null|
|**2024-10-25**|**Physics-based inverse modeling of battery degradation with Bayesian methods**|为了进一步改进锂离子电池（LiBs），深入了解复杂的电池工艺至关重要。物理模型提供了理解，但很难验证和参数化。因此，自动化机器学习方法（ML）对于用实验数据评估模型是必要的。贝叶斯方法，例如用于无似然推理的贝叶斯优化（EP-BOLFI），在捕获模型和数据中的不确定性的同时，也提供了有意义的参数化，因此脱颖而出。一个重要的话题是延长电池寿命，这受到退化的限制，如固体电解质界面（SEI）的生长。作为一个案例研究，我们应用EP-BOLFI来用合成和真实的降解数据对SEI生长模型进行参数化。EP-BOLFI允许以适当的特征选择的形式结合人类专业知识，从而改善参数化。我们证明，即使在受阻条件下，我们也能通过合理的不确定性量化实现正确的参数化，比标准的马尔可夫链蒙特卡洛方法需要更少的计算量。此外，物理上可靠的汇总统计数据显示了参数是否具有很强的相关性，并且无法明确识别。此外，我们研究了计算模型概率的贝叶斯交替子采样求积法（BASQ），以确认电子扩散是描述电池存储过程中SEI增长的最佳理论模型。 et.al.|[2410.19478](http://arxiv.org/abs/2410.19478)|null|

<p align=right>(<a href=#updated-on-20241028>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-24**|**3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation**|多视图图像扩散模型显著推进了开放域3D对象生成。然而，大多数现有模型依赖于缺乏固有3D偏差的2D网络架构，导致几何一致性受损。为了应对这一挑战，我们引入了3D Adapter，这是一个插件模块，旨在将3D几何感知注入预训练的图像扩散模型中。我们方法的核心是3D反馈增强的思想：对于采样循环中的每个去噪步骤，3D Adapter将中间的多视图特征解码为连贯的3D表示，然后对渲染的RGBD视图进行重新编码，通过特征添加来增强预训练的基础模型。我们研究了3D Adapter的两种变体：一种是基于高斯飞溅的快速前馈版本，另一种是利用神经场和网格的通用无训练版本。我们广泛的实验表明，3D Adapter不仅大大提高了文本到多视图模型（如Instant3D和Zero123++）的几何质量，而且还使用纯文本到图像的稳定扩散实现了高质量的3D生成。此外，我们通过在文本到3D、图像到3D、文本到纹理和文本到化身任务中呈现高质量的结果，展示了3D适配器的广泛应用潜力。 et.al.|[2410.18974](http://arxiv.org/abs/2410.18974)|**[link](https://github.com/Lakonik/MVEdit)**|
|**2024-10-22**|**Cortical Dynamics of Neural-Connectivity Fields**|皮质组织的宏观研究揭示了振荡活动的普遍性，这反映了神经相互作用的微调。本研究通过将广义振荡动力学纳入先前关于保守或半保守神经场动力学的工作中，扩展了神经场理论。先前的研究在很大程度上假设了神经单元之间的各向同性连接；然而，这项研究表明，广泛的各向异性和波动连接仍然可以维持振荡。使用拉格朗日场方法，我们研究了不同类型的连接、它们的动力学以及与神经场的潜在相互作用。基于这一理论基础，我们推导出了一个框架，该框架通过连接场的概念将Hebbian和非Hebbian学习（即可塑性）纳入神经场的研究中。 et.al.|[2410.16852](http://arxiv.org/abs/2410.16852)|null|
|**2024-10-15**|**Deep vectorised operators for pulsatile hemodynamics estimation in coronary arteries from a steady-state prior**|心血管血流动力学场为冠状动脉疾病提供了有价值的医学决策标志。计算流体动力学（CFD）是体内准确、无创评估这些量的金标准。在这项工作中，我们提出了一种基于机器学习的时间高效替代模型，用于基于稳态先验估计脉动血流动力学。我们引入了深度矢量化算子，这是一种用于在无限维函数空间上进行离散化独立学习的建模框架。基础神经结构是一个以血流动力学边界条件为条件的神经场。重要的是，我们展示了如何将逐点动作的要求放宽到置换等变，从而产生一系列可以通过消息传递和自我关注层进行参数化的模型。我们在从冠状动脉计算机断层扫描血管造影（CCTA）中提取的74条狭窄冠状动脉的数据集上评估了我们的方法，并将患者特异性脉动CFD模拟作为基本事实。我们证明，我们的模型能够准确估计脉动速度和压力，同时不受源域重新采样的影响（离散化独立性）。这表明，深度矢量化算子是冠状动脉及其他动脉心血管血流动力学估计的强大建模工具。 et.al.|[2410.11920](http://arxiv.org/abs/2410.11920)|null|
|**2024-10-07**|**Fast Training of Sinusoidal Neural Fields via Scaling Initialization**|神经场是一种新兴的范式，它将数据表示为由神经网络参数化的连续函数。尽管有许多优点，但神经场通常具有较高的训练成本，这阻碍了更广泛的采用。在本文中，我们关注一个流行的神经场家族，称为正弦神经场（SNF），并研究如何初始化它以最大限度地提高训练速度。我们发现，基于信号传播原理设计的SNF标准初始化方案是次优的。特别是，我们证明，通过简单地将每个权重（最后一层除外）乘以一个常数，我们可以将SNF训练加速10 $\times$。这种方法被称为$\textit{weight scaling}$ ，在各种数据域上持续提供显著的加速，使SNF的训练速度比最近提出的架构更快。为了理解为什么权重缩放效果良好，我们进行了广泛的理论和实证分析，结果表明，权重缩放不仅有效地解决了频谱偏差，而且具有良好的优化轨迹。 et.al.|[2410.04779](http://arxiv.org/abs/2410.04779)|null|
|**2024-10-04**|**End-to-End Reaction Field Energy Modeling via Deep Learning based Voxel-to-voxel Transform**|在计算生物化学和生物物理学中，理解静电相互作用的作用对于阐明生物分子的结构、动力学和功能至关重要。泊松-玻尔兹曼（PB）方程是通过描述带电分子内部和周围的静电势来模拟这些相互作用的基础工具。然而，由于生物分子表面的复杂性和需要考虑可移动离子，求解PB方程带来了重大的计算挑战。虽然求解PB方程的传统数值方法是准确的，但它们的计算成本很高，并且随着系统规模的增加而扩展性较差。为了应对这些挑战，我们引入了PBNeF，这是一种新的机器学习方法，灵感来自基于神经网络的偏微分方程求解器的最新进展。我们的方法将PB方程的输入和边界静电条件转化为可学习的体素表示，使神经场变换器能够预测PB解，进而预测反应场势能。大量实验表明，与传统的PB求解器相比，PBNeF的速度提高了100倍以上，同时保持了与广义玻恩（GB）模型相当的精度。 et.al.|[2410.03927](http://arxiv.org/abs/2410.03927)|null|
|**2024-10-08**|**DressRecon: Freeform 4D Human Reconstruction from Monocular Video**|我们提出了一种从单目视频中重建时间一致的人体模型的方法，重点是极其宽松的衣服或手持物体的交互。之前在人体重建方面的工作要么局限于没有物体交互的紧身衣服，要么需要校准的多视图捕捉或个性化的模板扫描，而大规模收集这些数据成本很高。我们对高质量但灵活的重建的关键见解是，将关于关节体形状的通用人类先验（从大规模训练数据中学习）与视频特定的关节“骨骼袋”变形（通过测试时间优化适合单个视频）仔细结合。我们通过学习一个神经隐式模型来实现这一点，该模型将身体和衣服的变形作为单独的运动模型层来解开。为了捕捉服装的微妙几何形状，我们在优化过程中利用了基于图像的先验，如人体姿势、表面法线和光流。由此产生的神经场可以提取到时间一致的网格中，或进一步优化为显式3D高斯分布，以实现高保真交互式渲染。在具有高度挑战性的服装变形和物体交互的数据集上，DressReston可以产生比现有技术更高保真的3D重建。项目页面：https://jefftan969.github.io/dressrecon/ et.al.|[2409.20563](http://arxiv.org/abs/2409.20563)|null|
|**2024-09-25**|**TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans**|我们介绍了一种新的框架，该框架从单眼视频中学习全身说话的人的动态神经辐射场（NeRF）。之前的工作只代表身体姿势或面部。然而，人类通过全身进行交流，结合身体姿势、手势和面部表情。在这项工作中，我们提出了TalkinNeRF，这是一个基于NeRF的统一网络，代表了整体4D人体运动。给定一个受试者的单眼视频，我们学习身体、面部和手的相应模块，这些模块结合在一起生成最终结果。为了捕捉复杂的手指关节，我们学习了手的额外变形场。我们的多身份表示能够同时训练多个科目，以及在完全看不见的姿势下进行强大的动画。只要输入一段短视频，它也可以推广到新的身份。我们展示了最先进的性能，用于为全身说话的人类制作动画，具有精细的手部发音和面部表情。 et.al.|[2409.16666](http://arxiv.org/abs/2409.16666)|null|
|**2024-09-24**|**Generative 3D Cardiac Shape Modelling for In-Silico Trials**|我们提出了一种深度学习方法，基于将形状表示为神经有符号距离场的零级集，对合成主动脉形状进行建模和生成，该方法受一系列可训练的嵌入向量的约束，并对每个形状的几何特征进行编码。通过使神经场在采样表面点上消失并强制其空间梯度具有单位范数，在从CT图像重建的主动脉根部网格数据集上训练网络。实证结果表明，我们的模型可以高保真地表示主动脉形状。此外，通过从学习到的嵌入向量中采样，我们可以生成类似于真实患者解剖结构的新形状，可用于计算机模拟试验。 et.al.|[2409.16058](http://arxiv.org/abs/2409.16058)|null|
|**2024-09-21**|**MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors**|由于缺乏几何指导和不完美的视图相关2D先验，从单眼图像中精确重建密集和语义注释的3D网格仍然是一项具有挑战性的任务。尽管我们已经见证了隐式神经场景表示的最新进展，能够简单地从多视图图像中进行精确的2D渲染，但很少有研究仅使用单眼先验来解决3D场景理解问题。在本文中，我们提出了MOSE，这是一种神经场语义重建方法，可以将推断的图像级噪声先验提升到3D，在3D和2D空间中产生精确的语义和几何。我们方法的关键动机是利用通用类不可知的分段掩码作为指导，在训练过程中促进渲染语义的局部一致性。在语义的帮助下，我们进一步将平滑正则化应用于无纹理区域，以获得更好的几何质量，从而实现几何和语义的互惠互利。在ScanNet数据集上的实验表明，我们的MOSE在3D语义分割、2D语义分割和3D表面重建任务的所有指标上都优于相关基线。 et.al.|[2409.14019](http://arxiv.org/abs/2409.14019)|null|
|**2024-09-17**|**SplatFields: Neural Gaussian Splats for Sparse 3D and 4D Reconstruction**|从多视图图像中数字化3D静态场景和4D动态事件长期以来一直是计算机视觉和图形学领域的一个挑战。最近，3D高斯散斑（3DGS）已经成为一种实用且可扩展的重建方法，由于其令人印象深刻的重建质量、实时渲染能力以及与广泛使用的可视化工具的兼容性而越来越受欢迎。然而，该方法需要大量的输入视图来实现高质量的场景重建，这引入了一个重大的实际瓶颈。在捕捉动态场景时，这一挑战尤为严峻，因为部署广泛的相机阵列的成本可能高得令人望而却步。在这项工作中，我们发现斑点特征缺乏空间自相关性是导致3DGS技术在稀疏重建环境中性能不佳的因素之一。为了解决这个问题，我们提出了一种优化策略，通过将splat特征建模为相应隐式神经场的输出，有效地正则化splat特征。这导致在各种场景中重建质量的一致提高。我们的方法有效地处理了静态和动态情况，这在不同设置和场景复杂性的广泛测试中得到了证明。 et.al.|[2409.11211](http://arxiv.org/abs/2409.11211)|null|

<p align=right>(<a href=#updated-on-20241028>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

