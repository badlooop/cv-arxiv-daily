[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.05.30
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|从预先捕获的单目胃镜图像中合成患者胃内任意新颖的视点图像是胃诊断中一个很有前途的课题。实现这一目标的典型方法集成了传统的三维重建技术，包括运动结构（SfM）和泊松曲面重建。这些方法产生显式的3D表示，例如点云和网格，从而能够从新的视点渲染图像。然而，胃内低纹理和非朗伯区域的存在往往会导致点云和网格重建的噪声和不完整，阻碍了高质量图像渲染的实现。本文将新兴的神经辐射场（NeRF）技术应用于单目胃镜数据，以合成新视点的照片逼真图像。为了解决单眼胃镜检查局部区域中由于视图稀疏而导致的性能下降问题，我们将来自预重建点云的几何先验纳入NeRF的训练中，这为预捕获的观察到的视图和生成的未观察到的图像引入了一种新的基于几何的损失。与最近的其他NeRF方法相比，我们的方法在定性和定量上都展示了从胃内新视角进行的高保真图像渲染。 et.al.|[2405.18863](http://arxiv.org/abs/2405.18863)|null|
|**2024-05-29**|**LP-3DGS: Learning to Prune 3D Gaussian Splatting**|近年来，三维高斯散射（3DGS）以其高质量和快速的渲染速度成为新视图合成（NVS）的主流方法之一。然而，作为一种基于点的场景表示，3DGS可能会生成大量高斯来适应场景，从而导致高内存使用率。已经提出的改进需要经验和预设的修剪比率或重要性得分阈值来修剪点云。这样的超参数需要多轮训练来优化和实现最大修剪率，同时保持每个场景的渲染质量。在这项工作中，我们提出了学习修剪3DGS（LP-3DGS），其中将可训练的二进制掩码应用于重要性得分，可以自动找到最佳修剪率。我们没有使用传统的直通估计器（STE）方法来近似二进制掩模梯度，而是重新设计了掩模函数，以利用Gumbel-Sigmoid方法，使其可微并与现有的3DGS训练过程兼容。大量实验表明，LP-3DGS始终能产生高效且高质量的良好平衡。 et.al.|[2405.18784](http://arxiv.org/abs/2405.18784)|null|
|**2024-05-29**|**Zero-to-Hero: Enhancing Zero-Shot Novel View Synthesis via Attention Map Filtering**|基于单一源图像从任意视图生成逼真图像仍然是计算机视觉中的一个重大挑战，其应用范围从电子商务到沉浸式虚拟体验。扩散模型的最新进展，特别是Zero-1-to-3模型，已被广泛用于生成看似合理的视图、视频和3D模型。然而，这些模型在新视图生成中仍然存在不一致和不可信的问题，尤其是在具有挑战性的观点变化中。在这项工作中，我们提出了Zero-to-Hero，这是一种新的测试时间方法，通过在Zero-1-3的去噪过程中操纵注意力图来增强视图合成。通过将去噪过程与随机梯度下降（SGD）进行类比，我们实现了一种聚合注意力图的过滤机制，增强了生成的可靠性和真实性。这个过程提高了几何一致性，而不需要重新训练或大量的计算资源。此外，我们修改了自注意机制，以整合来自源代码的信息，减少形状失真。这些过程得到了专门的采样计划的进一步支持。实验结果表明，在一组不同的分布对象上验证了保真度和一致性的显著提高。 et.al.|[2405.18677](http://arxiv.org/abs/2405.18677)|null|
|**2024-05-28**|**NeRAF: 3D Scene Infused Neural Radiance and Acoustic Fields**|声音在人类感知中起着重要作用，它与视觉一起提供了重要的场景信息，以了解我们的环境。尽管在神经隐式表示方面取得了进展，但学习与视觉场景相匹配的声学仍然具有挑战性。我们提出了NeRAF，这是一种联合学习声场和辐射场的方法。NeRAF被设计为Nerfstudio模块，可方便地访问逼真的视听生成。它在新的位置合成新的视图和空间化的音频，利用辐射场能力用3D场景信息调节声场。在推理时，每个模态都可以独立地呈现在空间分离的位置，从而提供更大的通用性。我们在SoundSpaces数据集上展示了我们的方法的优势。NeRAF在提高数据效率的同时，比以前的作品实现了显著的性能改进。此外，NeRAF通过跨模态学习增强了用稀疏数据训练的复杂场景的新颖视图合成。 et.al.|[2405.18213](http://arxiv.org/abs/2405.18213)|null|
|**2024-05-28**|**RT-GS2: Real-Time Generalizable Semantic Segmentation for 3D Gaussian Representations of Radiance Fields**|高斯飞溅通过实现高实时渲染性能，彻底改变了新颖视图合成的世界。最近，研究的重点是用下游任务的语义信息丰富这些3D表示。在本文中，我们介绍了RT-GS2，这是第一种使用高斯Splatting的可推广语义分割方法。虽然现有的基于高斯飞溅的方法依赖于特定场景的训练，但RT-GS2展示了推广到看不见的场景的能力。我们的方法采用了一种新的方法，首先以自监督的方式提取与视图无关的3D高斯特征，然后进行新的与视图相关/与视图无关（VDVI）的特征融合，以增强不同视图的语义一致性。在三个不同的数据集上进行的广泛实验表明，RT-GS2在语义分割质量方面优于最先进的方法，例如Replica数据集的mIoU增加了8.01%。此外，我们的方法实现了27.03 FPS的实时性能，与现有方法相比，速度提高了901倍。据我们所知，这项工作通过引入第一种用于辐射场的3D高斯表示的实时可推广语义分割方法，代表了该领域的重大进展。 et.al.|[2405.18033](http://arxiv.org/abs/2405.18033)|null|
|**2024-05-28**|**FreeSplat: Generalizable 3D Gaussian Splatting Towards Free-View Synthesis of Indoor Scenes**|赋予3D高斯飞溅以泛化能力是很有吸引力的。然而，现有的可推广的3D高斯散点方法由于其主干较重，在很大程度上局限于立体图像之间的窄范围插值，因此缺乏准确定位3D高斯并支持宽视野范围内的自由视野合成的能力。在本文中，我们提出了一种新的框架FreeSplat，它能够从长序列输入到自由视图合成重建几何一致的3D场景。具体而言，我们首先介绍了低成本跨视图聚合，该聚合通过在附近视图之间构建自适应成本体积并使用多尺度结构聚合特征来实现。随后，我们提出了逐像素三元组融合，以消除重叠视图区域中3D高斯的冗余，并聚合在多个视图中观察到的特征。此外，我们提出了一种简单但有效的自由视图训练策略，无论视图的数量如何，都能确保在更广泛的视图范围内进行稳健的视图合成。我们的经验结果表明，在不同数量的输入视图中，新视图渲染的颜色图质量和深度图精度都具有最先进的新视图合成性能。我们还表明，FreeSplat可以更有效地执行推理，并可以有效地减少冗余高斯，为无深度先验的前馈大场景重建提供了可能性。 et.al.|[2405.17958](http://arxiv.org/abs/2405.17958)|**[link](https://github.com/wangys16/freesplat)**|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|近年来，神经辐射场（NeRF）以其隐式表示方式彻底改变了三维重建。基于NeRF，3D高斯飞溅（3D-GS）已经脱离了神经网络的隐式表示，而是直接将场景表示为具有高斯形状分布的点云。虽然这种转变显著提高了辐射场的渲染质量和速度，但不可避免地导致了内存使用量的显著增加。此外，在3D-GS中有效地渲染动态场景已经成为一个紧迫的挑战。为了解决这些问题，本文提出了一种用于高质量动态场景重建的精细3D高斯表示。首先，我们使用可变形多层感知器（MLP）网络来捕捉高斯点的动态偏移，并通过哈希编码和微小的MLP来表达点的颜色特征，以减少存储需求。随后，我们引入了一种可学习的去噪掩模，结合去噪损失来消除场景中的噪声点，从而进一步压缩3D高斯模型。最后，通过静态约束和运动一致性约束来减轻点的运动噪声。实验结果表明，我们的方法在渲染质量和速度方面优于现有方法，同时显著减少了与3D-GS相关的内存使用，使其非常适合于各种任务，如新颖的视图合成和动态映射。 et.al.|[2405.17891](http://arxiv.org/abs/2405.17891)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|神经3D表示，如神经辐射场（NeRF），擅长产生逼真的渲染结果，但缺乏对内容创建至关重要的操作和编辑灵活性。先前的工作试图通过在规范空间中变形NeRF或基于显式网格操纵辐射场来解决这个问题。然而，操纵NeRF不是高度可控的，并且需要长的训练和推理时间。随着3D高斯散射（3DGS）的出现，使用基于显式点的3D表示可以以更快的训练和渲染速度实现极高保真度的新视图合成。然而，仍然缺乏在保持渲染质量的同时自由操作3DGS的有效手段。在这项工作中，我们的目标是解决实现可操作的照片真实感渲染的挑战。我们建议利用三角形网格直接自适应地操作3DGS。这种方法减少了为不同类型的高斯操作设计各种算法的需要。利用三角形状感知的高斯绑定和自适应方法，可以实现3DGS操作，并在操作后保持高保真度渲染。我们的方法能够处理大变形、局部操作和柔体模拟，同时保持高质量的渲染。此外，我们还证明了我们的方法在处理从3DGS中提取的不准确网格时也是有效的。进行的实验证明了我们的方法的有效性及其优于基线方法的优势。 et.al.|[2405.17811](http://arxiv.org/abs/2405.17811)|null|
|**2024-05-28**|**SafeguardGS: 3D Gaussian Primitive Pruning While Avoiding Catastrophic Scene Destruction**|三维高斯散射（3DGS）在新视图合成方面迈出了重要的一步，在实现实时渲染速度的同时，展现了一流的渲染质量。然而，3DGS的次优致密化过程导致了过多的高斯基元，这带来了一个重大挑战，降低了每秒帧数（FPS），并要求相当大的内存成本，这对低端设备不利。为了解决这个问题，许多后续研究提出了各种修剪技术，通常与不同的分数函数相结合，以优化渲染性能。尽管如此，关于其有效性和对所有技术的影响的全面讨论仍然缺失。在本文中，我们首先将3DGS修剪技术分为两种类型：跨视图修剪和逐像素修剪，这两种技术在对基元进行排序的方法上有所不同。我们随后的实验表明，虽然在极端高斯基元抽取下，交叉视图修剪会导致灾难性的质量下降，但逐像素修剪技术不仅在性能下降很小的情况下保持了相对较高的渲染质量，而且还为修剪提供了合理的最小边界。基于这一观察，我们进一步提出了分数函数的多种变体，并根据经验发现，颜色加权分数函数在区分用于渲染的不重要基元方面优于其他函数。我们相信，我们的研究为优化未来作品的3DGS修剪策略提供了有价值的见解。 et.al.|[2405.17793](http://arxiv.org/abs/2405.17793)|null|
|**2024-05-29**|**DC-Gaussian: Improving 3D Gaussian Splatting for Reflective Dash Cam Videos**|我们提出了DC高斯，一种从车载行车记录仪视频中生成新视图的新方法。虽然神经渲染技术在驾驶场景中取得了重大进展，但现有的方法主要是为自动驾驶汽车收集的视频设计的。然而，与行车记录仪视频相比，这些视频在数量和多样性方面都有限，行车记录仪视频更广泛地用于各种类型的车辆，并捕捉更广泛的场景。行车记录仪视频经常会遇到严重的障碍，如挡风玻璃上的反射和遮挡，这严重阻碍了神经渲染技术的应用。为了应对这一挑战，我们在最近的实时神经渲染技术3D高斯飞溅（3DGS）的基础上开发了DC高斯。我们的方法包括一个自适应图像分解模块，以统一的方式对反射和遮挡进行建模。此外，我们引入了照明感知障碍建模，以管理不同照明条件下的反射和遮挡。最后，我们采用几何引导的高斯增强策略，通过引入额外的几何先验来改善渲染细节。在自拍和公共行车记录仪视频上的实验表明，我们的方法不仅在新颖的视图合成方面取得了最先进的性能，而且可以准确地重建拍摄的场景，消除障碍。 et.al.|[2405.17705](http://arxiv.org/abs/2405.17705)|null|

<p align=right>(<a href=#updated-on-20240530>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-05-29**|**Learning Mixture-of-Experts for General-Purpose Black-Box Discrete Optimization**|实际应用涉及各种离散优化问题。为这些问题中的每一个设计专门的优化器都是具有挑战性的，通常需要大量的领域知识和人力。因此，开发通用优化器作为解决一系列问题的现成工具一直是一个长期的研究目标。本文介绍了MEGO，这是一种通过完全数据驱动的学习优化（L2O）方法训练的新型通用神经优化器。MEGO由根据解决训练问题的经验训练的专家组成，可以被视为具有二元决策变量的优化问题的基础模型。当遇到需要解决的问题时，MEGO会主动选择相关的专家模型来生成高质量的解决方案。MEGO可以用作独立的高效样本优化器，也可以与现有的搜索方法一起用作初始解决方案生成器。在六个问题类中验证了MEGO的通用性，包括三个经典问题类和三个由编译器、网络分析和三维重建中的真实应用程序产生的问题类。仅在经典问题类上进行过培训，MEGO在所有六个问题类上都表现出色，在解决方案质量和效率方面显著超过了广泛使用的通用优化器。在某些情况下，MEGO甚至超越了最先进的专业优化器。此外，MEGO提供了问题之间的相似性度量，为问题分类提供了一个新的视角。在通过L2O追求通用优化器的过程中，MEGO代表了向前迈出的第一步，但意义重大。 et.al.|[2405.18884](http://arxiv.org/abs/2405.18884)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|从预先捕获的单目胃镜图像中合成患者胃内任意新颖的视点图像是胃诊断中一个很有前途的课题。实现这一目标的典型方法集成了传统的三维重建技术，包括运动结构（SfM）和泊松曲面重建。这些方法产生显式的3D表示，例如点云和网格，从而能够从新的视点渲染图像。然而，胃内低纹理和非朗伯区域的存在往往会导致点云和网格重建的噪声和不完整，阻碍了高质量图像渲染的实现。本文将新兴的神经辐射场（NeRF）技术应用于单目胃镜数据，以合成新视点的照片逼真图像。为了解决单眼胃镜检查局部区域中由于视图稀疏而导致的性能下降问题，我们将来自预重建点云的几何先验纳入NeRF的训练中，这为预捕获的观察到的视图和生成的未观察到的图像引入了一种新的基于几何的损失。与最近的其他NeRF方法相比，我们的方法在定性和定量上都展示了从胃内新视角进行的高保真图像渲染。 et.al.|[2405.18863](http://arxiv.org/abs/2405.18863)|null|
|**2024-05-28**|**FreeSplat: Generalizable 3D Gaussian Splatting Towards Free-View Synthesis of Indoor Scenes**|赋予3D高斯飞溅以泛化能力是很有吸引力的。然而，现有的可推广的3D高斯散点方法由于其主干较重，在很大程度上局限于立体图像之间的窄范围插值，因此缺乏准确定位3D高斯并支持宽视野范围内的自由视野合成的能力。在本文中，我们提出了一种新的框架FreeSplat，它能够从长序列输入到自由视图合成重建几何一致的3D场景。具体而言，我们首先介绍了低成本跨视图聚合，该聚合通过在附近视图之间构建自适应成本体积并使用多尺度结构聚合特征来实现。随后，我们提出了逐像素三元组融合，以消除重叠视图区域中3D高斯的冗余，并聚合在多个视图中观察到的特征。此外，我们提出了一种简单但有效的自由视图训练策略，无论视图的数量如何，都能确保在更广泛的视图范围内进行稳健的视图合成。我们的经验结果表明，在不同数量的输入视图中，新视图渲染的颜色图质量和深度图精度都具有最先进的新视图合成性能。我们还表明，FreeSplat可以更有效地执行推理，并可以有效地减少冗余高斯，为无深度先验的前馈大场景重建提供了可能性。 et.al.|[2405.17958](http://arxiv.org/abs/2405.17958)|**[link](https://github.com/wangys16/freesplat)**|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|近年来，神经辐射场（NeRF）以其隐式表示方式彻底改变了三维重建。基于NeRF，3D高斯飞溅（3D-GS）已经脱离了神经网络的隐式表示，而是直接将场景表示为具有高斯形状分布的点云。虽然这种转变显著提高了辐射场的渲染质量和速度，但不可避免地导致了内存使用量的显著增加。此外，在3D-GS中有效地渲染动态场景已经成为一个紧迫的挑战。为了解决这些问题，本文提出了一种用于高质量动态场景重建的精细3D高斯表示。首先，我们使用可变形多层感知器（MLP）网络来捕捉高斯点的动态偏移，并通过哈希编码和微小的MLP来表达点的颜色特征，以减少存储需求。随后，我们引入了一种可学习的去噪掩模，结合去噪损失来消除场景中的噪声点，从而进一步压缩3D高斯模型。最后，通过静态约束和运动一致性约束来减轻点的运动噪声。实验结果表明，我们的方法在渲染质量和速度方面优于现有方法，同时显著减少了与3D-GS相关的内存使用，使其非常适合于各种任务，如新颖的视图合成和动态映射。 et.al.|[2405.17891](http://arxiv.org/abs/2405.17891)|null|
|**2024-05-27**|**Memorize What Matters: Emergent Scene Decomposition from Multitraverse**|人类自然会保留对永恒元素的记忆，而短暂的时刻往往会从记忆的缝隙中溜走。这种选择性保留对于机器人感知、定位和绘图至关重要。为了赋予机器人这种能力，我们引入了3D高斯映射（3DGM），这是一种基于3D高斯飞溅的自监督、仅限相机的离线映射框架。3DGM将来自同一区域的多遍历RGB视频转换为基于高斯的环境图，同时执行2D短暂对象分割。我们的主要观察结果是，环境在遍历中保持一致，而对象经常发生变化。这使我们能够利用重复遍历的自我监督来实现环境对象分解。更具体地说，3DGM将多遍历环境映射公式化为一个鲁棒的可微渲染问题，将环境和对象的像素分别视为内值和外值。3DGM使用稳健特征提取、特征残差挖掘和稳健优化，在没有人工干预的情况下联合执行3D映射和2D分割。我们建立了Mapverse基准，来源于伊萨卡365和nuPlan数据集，以评估我们在无监督二维分割、三维重建和神经渲染中的方法。大量结果验证了我们的方法在自动驾驶和机器人方面的有效性和潜力。 et.al.|[2405.17187](http://arxiv.org/abs/2405.17187)|null|
|**2024-05-27**|**SDL-MVS: View Space and Depth Deformable Learning Paradigm for Multi-View Stereo Reconstruction in Remote Sensing**|基于遥感图像的多视角立体研究促进了大规模城市三维重建的发展。然而，遥感多视点图像数据在获取过程中存在遮挡和视点之间亮度不均匀的问题，这导致了深度估计中细节模糊的问题。为了解决上述问题，我们重新审视了多视图立体任务中的可变形学习方法，并提出了一种基于视图空间和深度可变形学习（SDL-MVS）的新范式，旨在学习不同视图空间中特征的可变形交互，并对深度范围和区间进行可变形建模，以实现高精度的深度估计。具体来说，为了解决遮挡和亮度不均匀导致的视图噪声问题，我们提出了一种渐进空间可变形采样（PSS）机制，该机制以渐进的方式对3D截头体空间和2D图像空间中的采样点进行可变形学习，以自适应地将源特征嵌入到参考特征中。为了进一步优化深度，我们引入了深度假设可变形离散化（DHD），它通过自适应调整深度范围假设和对深度区间假设进行可变形离散来实现深度先验的精确定位。最后，我们的SDL-MVS通过视图空间和深度的可变形学习范式，实现了多视图立体中遮挡和亮度不均的显式建模，实现了精确的多视图深度估计。在珞珈MVS和WHU数据集上进行的大量实验表明，我们的SDL-MVS达到了最先进的性能。值得注意的是，在三个视图作为输入的前提下，我们的SDL-MVS在珞珈MVS数据集上实现了0.086的MAE误差，<0.6米的准确率为98.9%，<3区间的准确度为98.9%。 et.al.|[2405.17140](http://arxiv.org/abs/2405.17140)|null|
|**2024-05-27**|**DINO-SD: Champion Solution for ICRA 2024 RoboDepth Challenge**|环绕视图深度估计是一项关键任务，旨在获取周围视图的深度图。它在自动驾驶、AR/VR和3D重建等现实场景中有许多应用。然而，鉴于自动驾驶数据集中的大部分数据都是在白天场景中收集的，这导致深度模型在面对分布外（OoD）数据时性能较差。虽然一些工作试图提高OoD数据下深度模型的稳健性，但这些方法要么需要额外的训练数据，要么需要湖的可推广性。在本报告中，我们介绍了DINO-SD，一种新的环绕视图深度估计模型。我们的DINO-SD不需要额外的数据，并且具有很强的稳健性。我们的DINO-SD在ICRA 2024机器人深度挑战赛的赛道4中获得最佳表现。 et.al.|[2405.17102](http://arxiv.org/abs/2405.17102)|null|
|**2024-05-27**|**Part123: Part-aware 3D Reconstruction from a Single-view Image**|最近，扩散模型的出现为单视图重建开辟了新的机会。然而，所有现有的方法都将目标对象表示为没有任何结构信息的闭合网格，从而忽略了重建形状的基于零件的结构，这对许多下游应用至关重要。此外，生成的网格通常会遇到大噪声、表面不光滑和纹理模糊的问题，这使得使用3D分割技术获得令人满意的零件分割具有挑战性。在本文中，我们提出了Part123，这是一种从单视图图像进行零件感知三维重建的新框架。我们首先使用扩散模型从给定的图像中生成多视角一致的图像，然后利用对任意对象表现出强大泛化能力的分段任意模型（SAM）来生成多视角分割掩模。为了有效地将基于2D零件的信息纳入3D重建并处理不一致性，我们将对比学习引入神经渲染框架，以学习基于多视图分割掩模的零件感知特征空间。还开发了一种基于聚类的算法，以从重建的模型中自动导出3D零件分割结果。实验表明，我们的方法可以在各种物体上生成具有高质量分割部分的三维模型。与现有的非结构化重建方法相比，该方法中的零件感知三维模型有利于一些重要的应用，包括特征保持重建、基元拟合和三维形状编辑。 et.al.|[2405.16888](http://arxiv.org/abs/2405.16888)|null|
|**2024-05-29**|**3D Reconstruction with Fast Dipole Sums**|我们介绍了一种从多视图图像重建高保真表面的技术。我们的技术使用了一种新的基于点的表示，即偶极和，它推广了绕组数，以允许在具有噪声或异常点的点云中对任意每点属性进行插值。使用偶极和，我们可以根据点云的点属性来表示隐含的几何和辐射场，我们可以直接从运动的结构中初始化点云。我们还推导了用于加速正向和反向模式偶极和查询的Barnes-Hut快速求和方案。这些查询有助于使用光线跟踪，以使用基于点的表示高效且可微分地渲染图像，从而更新其点属性以优化场景几何体和外观。我们根据最先进的替代方案，基于神经表示的光线跟踪或基于高斯点的表示的光栅化，来评估这种反向渲染框架。我们的技术在同等运行时间显著提高了重建质量，同时还支持更通用的渲染技术，如用于直接照明的阴影光线。在补充中，我们提供了结果的交互式可视化。 et.al.|[2405.16788](http://arxiv.org/abs/2405.16788)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|3D Gaussian Splatting已成为仅RGB密集同时定位和映射（SLAM）的几何和外观的强大表示，因为它提供了紧凑的密集地图表示，同时实现了高效和高质量的地图渲染。然而，现有方法显示出比使用其他3D表示（如神经点云）的竞争方法差得多的重建质量，因为它们要么不采用全局地图和姿态优化，要么利用单目深度。作为回应，我们提出了第一个具有密集3D高斯图表示的仅RGB SLAM系统，该系统通过主动变形3D高斯图来动态适应关键帧姿态和深度更新，从而利用全局优化跟踪的所有好处。此外，我们发现，用单目深度估计器细化不准确区域的深度更新进一步提高了3D重建的准确性。我们在Replica、TUM-RGBD和ScanNet数据集上的实验表明了全局优化的3D高斯的有效性，因为该方法在跟踪、映射和渲染精度方面与现有的仅RGB的SLAM方法实现了卓越或不相上下的性能，同时产生了小的地图大小和快速的运行时间。源代码位于https://github.com/eriksandstroem/Splat-SLAM. et.al.|[2405.16544](http://arxiv.org/abs/2405.16544)|null|

<p align=right>(<a href=#updated-on-20240530>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-05-29**|**X-VILA: Cross-Modality Alignment for Large Language Model**|我们介绍了X-VILA，这是一种全模态模型，旨在通过结合图像、视频和音频模态来扩展大型语言模型（LLM）的功能。通过将特定于模态的编码器与LLM输入对齐，将扩散解码器与LLM输出对齐，X-VILA实现了跨模态的理解、推理和生成。为了促进这种跨模态对齐，我们策划了一个有效的交错任意到任意模态指令的数据集。此外，我们发现了当前跨模态对齐方法的一个重大问题，该问题导致视觉信息丢失。为了解决这个问题，我们提出了一种具有视觉嵌入高速公路模块的视觉对齐机制。然后，我们介绍了一种用于训练X-VILA的资源高效配方，该配方在任何形式的对话中都表现出熟练程度，大大超过了以前的方法。X-VILA还展示了跨模态的涌现特性，即使在没有类似训练数据的情况下也是如此。该项目将开源。 et.al.|[2405.19335](http://arxiv.org/abs/2405.19335)|null|
|**2024-05-29**|**Hilbert Space Diffusion in Systems with Approximate Symmetries**|随机矩阵理论（RMT）的普遍性是量子力学混沌系统的定义性质，可以通过谱形状因子（SFF）等可观察性来探索。在本文中，我们描述了具有近似对称性的系统在中间时间尺度上与RMT行为的系统偏差。在早期，对称性允许我们将希尔伯特空间组织成近似解耦的扇区，每个扇区独立地对SFF做出贡献。在后期，SFF转变为完全混合的混沌哈密顿量的最后斜坡。对于近似连续对称性，过渡行为由我们称之为希尔伯特空间扩散的普遍过程控制。该过程对应的扩散常数与相关的近似守恒电荷的弛豫率有关。通过实现希尔伯特空间扩散的混沌西格玛模型，我们建立了该过程的解析理论，该理论与我们对不同例子的数值结果在数量上一致。 et.al.|[2405.19260](http://arxiv.org/abs/2405.19260)|null|
|**2024-05-29**|**Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation**|Ito扩散过程的采样不变分布在随机模拟中提出了重大挑战。随机微分方程的传统数值求解器需要精细的步长和漫长的模拟周期，从而产生有偏差和相关的样本。目前基于深度学习的方法以深度神经网络的形式求解平稳的福克-普朗克方程来确定不变概率密度函数，但它们通常不会直接解决从计算的密度函数中采样的问题。在这项工作中，我们介绍了一个框架，该框架使用弱生成采样器（WGS）直接生成由平稳福克-普朗克方程导出的变换图诱导的独立同分布（iid）样本。我们提出的损失函数基于福克-普朗克方程的弱形式，对归一化流进行积分以表征不变分布，并促进从基本分布生成样本。我们的随机测试函数避开了传统弱公式中最小-最大优化的需要。与传统的生成模型不同，我们的方法既不需要计算密集型的雅可比行列式计算，也不需要变换映射的可逆性。我们框架的一个关键组成部分是自适应选择的高斯核函数形式的测试函数族，其中心从生成的数据样本中选择。在几个基准例子上的实验结果证明了我们的方法的有效性，它提供了低计算成本和探索多个亚稳态的优异能力。 et.al.|[2405.19256](http://arxiv.org/abs/2405.19256)|null|
|**2024-05-29**|**ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning**|虽然大规模的文本到图像扩散模型已经证明了令人印象深刻的图像生成能力，但人们非常担心它们可能被滥用来生成不安全的内容、侵犯版权和延续社会偏见。最近，文本到图像生成社区已经开始通过编辑或忘记预训练模型中不需要的概念来解决这些问题。然而，这些方法往往涉及数据密集型和低效的微调或利用各种形式的令牌重映射，使其容易受到对抗性越狱的影响。在本文中，我们提出了一种简单有效的无训练方法ConceptPrune，其中我们首先在预先训练的模型中识别负责生成不期望的概念的关键区域，从而通过权重修剪促进直接的概念遗忘。对包括艺术风格、裸体、对象擦除和性别去偏在内的一系列概念进行的实验表明，通过修剪一小部分（约占总权重的0.12%），可以有效地擦除目标概念，从而实现多概念擦除和对各种白盒和黑盒对抗性攻击的鲁棒性。 et.al.|[2405.19237](http://arxiv.org/abs/2405.19237)|null|
|**2024-05-29**|**Pseudo-Gevrey Smoothing for the Passive Scalar Equations near Couette**|在这篇文章中，我们研究了两个在流体动力学中很重要的线性方程的正则性理论：在 $\mathbb T\times[-1,1]$中靠近Couette的（时变）剪切流的被动标量方程，其扩散系数为$\nu\to0$，以及在类似于这种被动标量的函数空间中表现为右手边的泊松方程。这项工作的主要动机是开发我们在配套工作中处理（非线性）2D Navier-Stokes方程所需的一些主要技术工具。这两个方程都是在齐次狄利克雷条件（类似于Navier滑移型边界条件）下研究的，初始条件被认为是远离墙壁的紧密支撑。我们开发了具有以下三个特征的平滑估计：[1]-$\nu$正则性中的一致性是关于$\partial_x$和时间相关的自适应向量场$\Gamma$的，该向量场近似地与被动标量方程（与“平坦”导数相反）和标度梯度$\sqrt｛\nu｝\nabla$进行交换；[2] $（\partial_x，\Gamma）$-正则性估计是在Gevrey空间中执行的，其正则性取决于空间坐标$y$ （我们称之为“伪Gevrey”）；[3] 这些伪Gevrey空间的正则性在通道中心附近退化为有限正则性，因此标准Gevrey乘积规则和其他可服从的性质不成立。在这样一个微妙的函数环境中的非线性分析是我们的配套论文的关键组成部分之一，该论文证明了具有滑移边界条件的Couette流的完全非线性渐近稳定性。本文介绍了这些退化伪Gevrey空间中相关线性问题的新估计，这具有独立的意义。 et.al.|[2405.19233](http://arxiv.org/abs/2405.19233)|null|
|**2024-05-29**|**DiPPeST: Diffusion-based Path Planner for Synthesizing Trajectories Applied on Quadruped Robots**|我们提出了DiPPeST，这是一种用于四足机器人路径规划的基于图像和目标条件扩散的新型轨迹生成器。DiPPeST是对我们之前引入的基于扩散的2D全局轨迹生成器（DiPPeR）的零样本改编。所引入的系统结合了一种新的局部实时路径细化策略，该策略对相机输入做出反应，不需要任何进一步的训练、图像处理或环境解释技术。DiPPeST在标称环境中的避障成功率为92%，在像素变化比DiPPeR复杂3.5倍的环境中进行测试时，平均成功率为88%。开发了一种视觉伺服框架，允许在现实世界中执行，并在四足机器人上进行了测试，在不同的环境中实现了80%的成功率，并在狭窄的环境中展示了比复杂的最先进的本地规划者更好的行为。 et.al.|[2405.19232](http://arxiv.org/abs/2405.19232)|null|
|**2024-05-29**|**Contrastive-Adversarial and Diffusion: Exploring pre-training and fine-tuning strategies for sulcal identification**|在过去的十年里，计算机视觉见证了各种培训和学习方法的建立。对抗性学习、对比学习、扩散去噪学习和普通重建学习等技术已成为标准，代表了广泛用于在各种视觉任务中全面训练或预训练网络的最先进方法。对微调方法的探索已成为当前的焦点，解决了在提高整体性能的同时减少GPU内存使用和时间成本的高效模型调整的需求，如低秩自适应（LoRA）等方法。关键问题出现了：哪种预训练技术能产生最佳结果——对抗性、对比性、重建或扩散去噪？这些方法的性能如何随着微调复杂性的调整而变化？本研究旨在阐明预训练技术和微调策略的优势，以增强独立同分布（IID）队列中神经网络的学习过程。我们通过检查各种情况来强调微调的重要性，包括全调谐、解码器调谐、顶级调谐和使用LoRA的线性参数微调。利用准确性、时间成本和内存效率等指标，对模型性能和效率进行了系统总结。为了实证证明我们的发现，我们通过使用包括596名受试者的TOP-OSLO队列，使用不同的3D卷积神经网络（CNN）架构，重点关注涉及扣带旁沟（PCS）的多任务分割分类挑战。 et.al.|[2405.19204](http://arxiv.org/abs/2405.19204)|null|
|**2024-05-29**|**$E^{3}$Gen: Efficient, Expressive and Editable Avatars Generation**|本文旨在介绍3D高斯用于高效、表达和可编辑的数字化身生成。这项任务面临两大挑战：（1）三维高斯的非结构化性质使其与当前一代管道不兼容；（2） 3D高斯在涉及多个受试者训练的生成环境中的表达动画仍未被探索。在本文中，我们提出了一种新的化身生成方法$E^3$ Gen，以有效地解决这些挑战。首先，我们提出了一种新的生成UV特征平面表示，该表示将非结构化的3D高斯编码到由SMPL-X参数模型定义的结构化2D UV空间上。这种新颖的表示不仅保留了原始3D高斯的表示能力，而且在受试者之间引入了共享结构，以实现扩散模型的生成学习。为了应对第二个挑战，我们提出了一个部分感知变形模块，以实现稳健和准确的全身表情姿态控制。大量实验表明，我们的方法在化身生成方面取得了卓越的性能，并能够进行富有表现力的全身姿势控制和编辑。 et.al.|[2405.19203](http://arxiv.org/abs/2405.19203)|null|
|**2024-05-29**|**Going beyond compositional generalization, DDPMs can produce zero-shot interpolation**|去噪扩散概率模型（DDPM）在图像生成方面表现出显著的能力，研究表明，它们可以通过组合从训练数据中学习的潜在因素来进行推广。在这项工作中，我们进一步研究了在潜在因素支持下，在数据分布的严格分离子集上训练的DDPM，这些子集之间存在很大差距。我们证明，这样的模型可以有效地在分布的未探索的中间区域生成图像。例如，当在明显微笑和不微笑的脸上训练时，我们演示了一种采样程序，该程序可以在没有参考图像的情况下生成轻微微笑的脸（零样本插值）。我们将这些发现复制到其他属性以及其他数据集 $\href{https://github.com/jdeschena/ddpm-zero-shot-interpolation}｛\text｛我们的代码可在GitHub上获得。｝｝$ et.al.|[2405.19201](http://arxiv.org/abs/2405.19201)|null|
|**2024-05-29**|**Diffusion-based Dynamics Models for Long-Horizon Rollout in Offline Reinforcement Learning**|随着扩散模型在生成逼真的合成视觉数据方面的巨大成功，许多研究人员已经研究了其在决策和控制方面的潜力。这些工作中的大多数都利用DM直接从轨迹空间进行采样，其中DM可以被视为动力学模型和策略的组合。在这项工作中，我们探索了如何在完全离线的环境中解耦DM作为动力学模型的能力，允许学习策略推出轨迹。当DM从数据集中学习数据分布时，其内在策略实际上是从数据集中诱导的行为策略，这导致了行为策略和学习策略之间的不匹配。我们提出了动态扩散，简称DyDiff，它可以迭代地将学习策略中的信息注入DM。DyDiff确保了长期推出的准确性，同时保持了策略的一致性，并且可以轻松地部署在无模型算法上。我们提供了理论分析，以显示DM在长期推广方面相对于模型的优势，并证明DyDiff在离线强化学习的背景下的有效性，其中提供了推广数据集，但没有用于交互的在线环境。我们的代码位于https://github.com/FineArtz/DyDiff. et.al.|[2405.19189](http://arxiv.org/abs/2405.19189)|null|

<p align=right>(<a href=#updated-on-20240530>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-05-27**|**Extreme Compression of Adaptive Neural Images**|隐式神经表示（INRs）和神经场是一种新的信号表示范式，从图像和音频到3D场景和视频。其基本思想是将信号表示为连续且可微分的神经网络。这一思想提供了前所未有的优势，如连续分辨率和存储效率，从而实现了新的压缩技术。然而，将数据表示为神经网络带来了新的挑战。例如，给定一个2D图像作为神经网络，我们如何进一步压缩这样的神经图像？。在这项工作中，我们提出了一种新的压缩神经场的分析，重点是图像。我们还介绍了自适应神经图像（ANI），这是一种有效的神经表示，能够适应不同的推理或传输要求。我们提出的方法可以将神经图像的每像素比特数（bpp）减少4倍，而不会丢失敏感细节或损害保真度。我们之所以能做到这一点，是因为我们成功地实现了4位神经表示。我们的工作为开发压缩神经场提供了一个新的框架。 et.al.|[2405.16807](http://arxiv.org/abs/2405.16807)|null|
|**2024-05-24**|**Blaze3DM: Marry Triplane Representation with Diffusion for 3D Medical Inverse Problem Solving**|解决图像恢复和重建等三维医学逆问题在现代医学领域至关重要。然而，3D医疗数据中的维度诅咒导致主流的体积方法遭受高资源消耗，并挑战模型成功捕捉自然分布，导致不可避免的体积不一致和伪影。最近的一些工作试图简化潜在空间中的生成，但缺乏对复杂图像细节进行有效建模的能力。为了解决这些局限性，我们提出了Blaze3DM，这是一种新的方法，通过集成紧凑的三平面神经场和强大的扩散模型，实现了快速高保真的生成。在技术上，Blaze3DM首先同时优化数据相关的三平面嵌入和共享解码器，将每个三平面重建回相应的3D体积。为了进一步增强3D一致性，我们引入了一个轻量级的3D感知模块来对三个垂直平面的相关性进行建模。然后，在潜在的三平面嵌入上训练扩散模型，并实现无条件和有条件的三平面生成，最终解码为任意大小的体积。对零样本三维医学逆问题求解的大量实验，包括稀疏视图CT、有限角度CT、压缩传感MRI和MRI各向同性超分辨率，表明Blaze3DM不仅实现了最先进的性能，而且显著提高了现有方法的计算效率（比以前的工作快22~40倍）。 et.al.|[2405.15241](http://arxiv.org/abs/2405.15241)|null|
|**2024-05-17**|**SNF-ROM: Projection-based nonlinear reduced order modeling with smooth neural fields**|降阶建模通过从数据中学习低阶空间表示并使用控制方程的流形投影动态演化这些表示，降低了求解偏微分方程的计算成本。虽然通常使用线性子空间降阶模型（ROM），但对于Kolmogorov $n$ -宽度缓慢衰减的问题，例如高雷诺数下以平流为主的流体流动，通常是次优的。人们对非线性ROM越来越感兴趣，它使用最先进的表示学习技术以较少的自由度准确地捕捉这种现象。我们提出了光滑神经场ROM（SNF-ROM），这是一种将无网格简化表示与Galerkin投影相结合的非线性简化建模框架。SNF-ROM体系结构将学习到的ROM轨迹约束为平滑变化的路径，这在根据支配PDE遍历简化流形时的动力学评估中是有益的。此外，我们设计了鲁棒正则化方案，以确保学习的神经场是光滑和可微的。这使我们能够使用自动微分来非侵入地计算简化系统的基于物理的动力学，并使用经典时间积分器来演化简化系统。SNF-ROM可以实现快速的离线训练，并提高在线动力学评估的准确性和稳定性。我们证明了SNF-ROM在一系列平流主导的线性和非线性PDE问题上的有效性，在这些问题上，我们始终优于最先进的ROM。 et.al.|[2405.14890](http://arxiv.org/abs/2405.14890)|null|
|**2024-05-23**|**NeuroGauss4D-PCI: 4D Neural Fields and Gaussian Deformation Fields for Point Cloud Interpolation**|点云插值面临着点稀疏性、复杂的时空动力学以及从稀疏的时间信息中导出完整的三维点云的困难等挑战。本文介绍了NeuroGauss4D PCI，它擅长在各种动态场景中建模复杂的非刚性变形。该方法从迭代高斯云软聚类模块开始，提供结构化的时间点云表示。所提出的时间径向基函数高斯残差利用高斯参数随时间插值，实现平滑的参数转换并捕获高斯分布的时间残差。此外，4D高斯变形场跟踪这些参数的演变，创建连续的时空变形场。4D神经场将低维时空坐标（ $x，y，z，t$ ）转换为高维潜在空间。最后，我们自适应有效地融合了来自神经场的潜在特征和来自高斯变形场的几何特征。NeuroGauss4D PCI在点云帧插值方面优于现有方法，在对象级（DHB）和大规模自动驾驶数据集（NL Drive）上都提供了领先的性能，并可扩展到自动标记和点云加密任务。源代码发布于https://github.com/jiangchaokang/NeuroGauss4D-PCI. et.al.|[2405.14241](http://arxiv.org/abs/2405.14241)|null|
|**2024-05-23**|**Multi-view Remote Sensing Image Segmentation With SAM priors**|遥感中的多视图分割（RS）寻求从场景内的不同视角对图像进行分割。最近的方法利用了从隐式神经场（INF）中提取的3D信息，增强了多个视图的结果一致性，同时使用有限的标签（甚至在3-5个标签内）来简化劳动力。尽管如此，由于不充分的全场景监督和INF中不充分的语义特征，在有限视图标签的约束下实现卓越性能仍然具有挑战性。我们建议将视觉基础模型Segment Anything（SAM）的先验注入INF，以在有限的训练数据下获得更好的结果。具体而言，我们对比测试视图和训练视图之间的SAM特征，以导出每个测试视图的伪标签，增强场景范围的标签信息。随后，我们通过转换器将SAM特征引入场景的INF中，补充语义信息。实验结果表明，我们的方法优于主流方法，证实了SAM作为INF的补充对该任务的有效性。 et.al.|[2405.14171](http://arxiv.org/abs/2405.14171)|null|
|**2024-05-22**|**Bridging Operator Learning and Conditioned Neural Fields: A Unifying Perspective**|算子学习是机器学习的一个新兴领域，旨在学习无穷维函数空间之间的映射。在这里，我们从计算机视觉中揭示了算子学习架构和条件神经场之间的联系，为研究流行的算子学习模型之间的差异提供了一个统一的视角。我们发现，许多常用的算子学习模型可以被视为神经场，其条件机制仅限于点和/或全局信息。受此启发，我们提出了连续视觉转换器（CViT），这是一种新的神经算子架构，它使用视觉转换器编码器，并使用交叉注意力来调制由可训练的基于网格的查询坐标位置编码构建的基场。尽管它很简单，但CViT在气候建模和流体动力学的挑战性基准中取得了最先进的结果。我们的贡献可以被视为在物理科学中适应先进的计算机视觉架构以构建更灵活、更准确的机器学习模型的第一步。 et.al.|[2405.13998](http://arxiv.org/abs/2405.13998)|**[link](https://github.com/predictiveintelligencelab/cvit)**|
|**2024-05-21**|**Unsupervised Searches for Cosmological Parity Violation: Improving Detection Power with the Neural Field Scattering Transform**|最近使用四点相关性的研究表明，星系分布中存在宇称破坏，尽管这些探测的重要性对用于模拟星系分布噪声特性的模拟的选择很敏感。在最近的一篇论文中，我们介绍了一种无监督学习方法，该方法提供了一种替代方法，通过直接从观测数据中学习奇偶性违反，避免了对模拟目录的依赖。然而，我们以前的无监督方法所使用的卷积神经网络（CNN）模型很难扩展到数据有限的更现实的场景。我们提出了一种新的方法，即神经场散射变换（NFST），它通过添加可训练滤波器来增强小波散射变换（WST）技术，该滤波器被参数化为神经场。我们首先调整NFST模型，以在简化的数据集中检测奇偶校验违规，然后在不同的训练集大小下，将其性能与WST和CNN基准进行比较。我们发现，NFST可以检测奇偶校验违规，数据比CNN少4倍，比WST少32倍。此外，在数据有限的情况下，NFST可以检测到高达 $6\sigma$ 置信度的奇偶校验违规，其中WST和CNN无法进行任何检测。我们发现，与基准模型相比，NFST增加的灵活性，特别是学习不对称滤波器的能力，以及NFST架构中内置的特定对称性，有助于提高其性能。我们进一步证明了NFST是易于解释的，这对于物理应用（如奇偶校验违反的检测）是有价值的。 et.al.|[2405.13083](http://arxiv.org/abs/2405.13083)|null|
|**2024-05-21**|**Implicit-ARAP: Efficient Handle-Guided Deformation of High-Resolution Meshes and Neural Fields via Local Patch Meshing**|在这项工作中，我们提出了神经符号距离场的局部补丁网格表示。该技术允许通过仅使用SDF信息及其梯度将平面面片网格投影和变形到标高集曲面上来离散输入SDF的标高集的局部区域。我们的分析表明，这种方法比标准的行进立方体算法更准确地逼近隐式曲面。然后，我们将这种表示应用于手柄引导变形的设置：我们引入了两个不同的管道，它们利用3D神经场来计算在给定约束集下高分辨率网格和神经场的“尽可能刚性”变形。我们对我们的方法和神经场和网格变形的各种基线进行了全面评估，结果表明，这两条管道在结果质量和稳健性方面都取得了令人印象深刻的效率和显著的改进。通过我们的新型流水线，我们引入了一种可扩展的方法来解决高分辨率网格上公认的几何处理问题，并为通过局部面片网格将其他几何任务扩展到隐式曲面领域铺平了道路。 et.al.|[2405.12895](http://arxiv.org/abs/2405.12895)|null|
|**2024-05-16**|**Single-shot volumetric fluorescence imaging with neural fields**|与需要在多个轴向平面上扫描的传统成像方法相比，单次体积荧光（SVF）成像提供了显著的优势，因为它可以在大视场上以高时间分辨率捕获生物过程。现有的SVF成像方法通常需要大的、复杂的点扩展函数（PSF）来满足压缩传感的多路复用要求，这限制了信噪比、分辨率和/或视场。在本文中，我们介绍了QuadraPol-PSF与神经场相结合，这是一种新的SVF成像方法。该方法在后焦平面利用成本效益高的定制偏振器和偏振相机来检测荧光，在紧凑的PSF内有效地编码3D场景，而没有深度模糊。此外，我们提出了一种基于神经场技术的重建算法，该算法解决了用于校正成像系统像差的相位检索方法的不精确性。该算法将实验PSF的准确性与计算生成的检索PSF的长景深相结合。QuadraPol PSF与神经场相结合，可将传统荧光显微镜的采集时间显著缩短约20倍，并可一次性捕获100 mm $^3$ 立方体积。我们通过对沙子表面细菌菌落的全聚焦成像和植物根系形态的可视化，验证了我们的硬件和算法的有效性。我们的方法为推进生物学研究和生态学研究提供了强有力的工具。 et.al.|[2405.10463](http://arxiv.org/abs/2405.10463)|null|
|**2024-05-08**|**${M^2D}$NeRF: Multi-Modal Decomposition NeRF with 3D Feature Fields**|神经场（NeRF）已经成为表示连续3D场景的一种很有前途的方法。然而，NeRF中缺乏语义编码对场景分解提出了重大挑战。为了应对这一挑战，我们提出了一个单一的模型，即多模式分解NeRF（${M^2D}$ NeRF），它能够进行基于文本和基于视觉补丁的编辑。具体来说，我们使用多模态特征提取将来自预训练的视觉和语言模型的教师特征集成到3D语义特征体积中，从而促进一致的3D编辑。为了增强三维特征体积中视觉特征和语言特征之间的一致性，我们引入了多模态相似性约束。我们还引入了一种基于补丁的联合对比损失，这有助于鼓励对象区域在3D特征空间中合并，从而产生更精确的边界。与先前的基于NeRF的方法相比，在各种真实世界场景上的实验显示出在3D场景分解任务中的优越性能。 et.al.|[2405.05010](http://arxiv.org/abs/2405.05010)|null|

<p align=right>(<a href=#updated-on-20240530>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

