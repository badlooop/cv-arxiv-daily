[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.05.15
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#video-diffusion>Video Diffusion</a></li>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## Video Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-05-14**|**Generating time-consistent dynamics with discriminator-guided image diffusion models**|真实的时间动态对于许多视频生成、处理和建模应用至关重要，例如在计算流体动力学、天气预报或长期气候模拟中。视频扩散模型（VDM）是目前最先进的生成高度逼真动态的方法。然而，从头开始训练VDM可能具有挑战性，需要大量的计算资源，限制了它们的广泛应用。在这里，我们提出了一种时间一致性鉴别器，使预训练的图像扩散模型能够生成逼真的时空动态。鉴别器指导采样推理过程，不需要扩展或微调图像扩散模型。我们将我们的方法与在理想湍流模拟和现实世界全球降水数据集上从头开始训练的VDM进行了比较。我们的方法在时间一致性方面表现同样出色，与VDM相比，显示出改进的不确定性校准和更低的偏差，并在每日时间步长实现了稳定的百年尺度气候模拟。 et.al.|[2505.09089](http://arxiv.org/abs/2505.09089)|null|
|**2025-05-13**|**Generative AI for Autonomous Driving: Frontiers and Opportunities**|生成型人工智能（GenAI）构成了一股变革性的技术浪潮，通过其无与伦比的内容创建、推理、规划和多模式理解能力重新配置行业。这股革命性的力量为解决工程领域最大的挑战之一提供了迄今为止最有前景的道路：实现可靠的全自动驾驶，特别是追求5级自动驾驶。这项调查对GenAI在自动驾驶堆栈中的新兴作用进行了全面而关键的综合。我们首先提炼了现代生成建模的原则和权衡，包括VAE、GAN、扩散模型和大型语言模型（LLM）。然后，我们绘制了它们在图像、激光雷达、轨迹、占用、视频生成以及LLM引导推理和决策中的前沿应用。我们对实际应用进行分类，如合成数据工作流程、端到端驱动策略、高保真数字孪生系统、智能交通网络和跨域传输到嵌入式人工智能。我们确定了关键障碍和可能性，如罕见情况下的全面概化、评估和安全检查、预算有限的实施、监管合规性、伦理问题和环境影响，同时提出了跨理论保证、信任指标、交通整合和社会技术影响的研究计划。通过统一这些线索，该调查为研究人员、工程师和政策制定者提供了一个前瞻性的参考，以引导生成人工智能和高级自主移动的融合。一个积极维护的引用作品库可在https://github.com/taco-group/GenAI4AD. et.al.|[2505.08854](http://arxiv.org/abs/2505.08854)|**[link](https://github.com/taco-group/genai4ad)**|
|**2025-05-13**|**Symbolically-Guided Visual Plan Inference from Uncurated Video Data**|视觉规划通过为目标条件的低级策略提供一系列中间视觉子目标，在长期操纵任务上取得了良好的性能。为了获得子目标，现有的方法通常求助于视频生成模型，但存在模型幻觉和计算成本的问题。我们提出了Vis2Plan，这是一个高效、可解释和白盒的视觉规划框架，由符号指导提供支持。从原始的、未标记的游戏数据中，Vis2Plan利用视觉基础模型自动提取一组紧凑的任务符号，这允许为多目标、多阶段规划构建高级符号转换图。在测试时，给定一个期望的任务目标，我们的规划者在符号层面进行规划，并根据底层符号表示组装一系列物理上一致的中间子目标图像。我们的Vis2Plan在真实机器人环境中的总成功率提高了53%，同时生成视觉计划的速度提高了35倍，优于基于强扩散视频生成的视觉计划。结果表明，Vis2Plan能够生成物理上一致的图像目标，同时提供完全可检查的推理步骤。 et.al.|[2505.08444](http://arxiv.org/abs/2505.08444)|null|
|**2025-05-13**|**ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image**|我们将自适应视图规划引入多视图合成，旨在提高单视图3D重建的遮挡显示和3D一致性。我们不是独立或同时生成一组无序的视图，而是生成一系列视图，利用时间一致性来增强3D一致性。最重要的是，我们的视图序列不是由预先确定的相机设置决定的。相反，我们计算自适应相机轨迹（ACT），具体来说，是相机视图的轨迹，它最大限度地提高了要重建的3D对象的遮挡区域的可见性。一旦找到最佳轨道，我们将其馈送到视频扩散模型，以生成轨道周围的新视图，然后将其传递到多视图3D重建模型以获得最终重建。我们的多视图合成管道非常高效，因为它不涉及运行时训练/优化，只涉及通过应用预训练的模型进行遮挡分析和多视图合成的前向推理。我们的方法预测了相机轨迹，有效地揭示了遮挡并产生了一致的新视图，在看不见的GSO数据集上显著改善了SOTA的3D重建，无论是定量还是定性。 et.al.|[2505.08239](http://arxiv.org/abs/2505.08239)|null|
|**2025-05-12**|**DanceGRPO: Unleashing GRPO on Visual Generation**|生成模型的最新突破，特别是扩散模型和校正流，彻底改变了视觉内容的创作，但将模型输出与人类偏好相匹配仍然是一个关键挑战。现有的基于强化学习（RL）的视觉生成方法面临着关键的局限性：与现代基于常微分方程（ODE）的采样范式不兼容，大规模训练中的不稳定性，以及缺乏对视频生成的验证。本文介绍了DanceGRPO，这是第一个将组相对策略优化（GRPO）应用于视觉生成范式的统一框架，它在两个生成范式（扩散模型和校正流）、三个任务（文本到图像、文本到视频、图像到视频）、四个基础模型（稳定扩散、浑源视频、FLUX、SkyReel-I2V）和五个奖励模型（图像/视频美学、文本图像对齐、视频运动质量和二进制奖励）中释放了一个统一的RL算法。据我们所知，DanceGRPO是第一个基于强化学习的统一框架，能够无缝适应不同的生成范式、任务、基础模型和奖励模型。DanceGRPO表现出持续和实质性的改进，在HPS-v2.1、CLIP Score、VideoAlign和GenEval等基准上比基线高出181%。值得注意的是，DanceGRPO不仅可以稳定复杂视频生成的策略优化，还可以使生成策略更好地捕获Best-of-N推理缩放的去噪轨迹，并从稀疏二进制反馈中学习。我们的研究结果表明，DanceGRPO是一种强大而通用的解决方案，用于在视觉生成中扩展基于人类反馈的强化学习（RLHF）任务，为协调强化学习和视觉合成提供了新的见解。代码将被发布。 et.al.|[2505.07818](http://arxiv.org/abs/2505.07818)|null|
|**2025-05-12**|**ShotAdapter: Text-to-Multi-Shot Video Generation with Diffusion Models**|目前基于扩散的文本到视频方法仅限于制作单镜头的短视频片段，并且缺乏生成具有离散过渡的多镜头视频的能力，在这些过渡中，同一角色在相同或不同的背景下执行不同的活动。为了解决这一局限性，我们提出了一个框架，其中包括数据集收集管道和视频扩散模型的架构扩展，以实现文本到多镜头视频的生成。我们的方法能够将多镜头视频生成为单个视频，在所有镜头的所有帧上都能全神贯注，确保角色和背景的一致性，并允许用户通过镜头特定的调节来控制镜头的数量、持续时间和内容。这是通过将转换标记合并到文本到视频模型中来实现的，以控制新镜头开始的帧，以及控制转换标记效果并允许镜头特定提示的局部注意力掩蔽策略。为了获得训练数据，我们提出了一种新的数据收集管道，从现有的单镜头视频数据集中构建多镜头视频数据集。大量实验表明，对预训练的文本到视频模型进行数千次迭代的微调就足以使该模型随后能够生成具有镜头特定控制的多镜头视频，优于基线。您可以在中找到更多详细信息https://shotadapter.github.io/ et.al.|[2505.07652](http://arxiv.org/abs/2505.07652)|null|
|**2025-05-13**|**Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model**|在眼科手术中，开发一个能够解释手术视频并预测后续手术的人工智能系统需要大量具有高质量注释的眼科手术视频，由于隐私问题和劳动力消耗，这些视频很难收集。文本引导视频生成（T2V）是一种有前景的解决方案，通过基于外科医生的指令生成眼科手术视频来克服这一问题。在这篇论文中，我们介绍了Ophora，这是一种可以按照自然语言指令生成眼科手术视频的开创性模型。为了构建Ophora，我们首先提出了一个综合数据治疗管道，将叙述性眼科手术视频转换为大规模、高质量的数据集，其中包括160K多个视频指令对Ophora-160K。然后，我们提出了一种渐进式视频指令调整方案，从在自然视频文本数据集上预训练的T2V模型中转移丰富的时空知识，用于基于Ophora-160K的隐私保护眼科手术视频生成。通过定量分析和眼科医生反馈进行视频质量评估的实验表明，Ophora可以根据外科医生的指示生成逼真可靠的眼科手术视频。我们还验证了Ophora在理解眼科手术工作流程的下游任务方面的能力。代码可在以下网址获得https://github.com/mar-cry/Ophora. et.al.|[2505.07449](http://arxiv.org/abs/2505.07449)|**[link](https://github.com/mar-cry/ophora)**|
|**2025-05-12**|**Generative Pre-trained Autoregressive Diffusion Transformer**|在这项工作中，我们提出了GPDiT，这是一种生成式预训练自回归扩散变换器，它在连续的潜在空间内统一了扩散和自回归建模的优点，用于长距离视频合成。GPDiT不是预测离散令牌，而是使用扩散损失自回归预测未来的潜在帧，从而能够对帧之间的运动动力学和语义一致性进行自然建模。这种连续自回归框架不仅提高了发电质量，还赋予了模型表示能力。此外，我们引入了一种轻量级的因果注意变体和一种基于无参数旋转的时间调节机制，提高了训练和推理效率。大量实验表明，GPDiT在视频生成质量、视频表示能力和少量镜头学习任务方面表现出色，突显了其作为连续空间视频建模有效框架的潜力。 et.al.|[2505.07344](http://arxiv.org/abs/2505.07344)|null|
|**2025-05-11**|**DAPE: Dual-Stage Parameter-Efficient Fine-Tuning for Consistent Video Editing with Diffusion Models**|基于扩散模型的视频生成是一项具有挑战性的多模式任务，视频编辑成为该领域的一个关键方向。最近的视频编辑方法主要分为两类：需要培训和不需要培训的方法。虽然基于训练的方法会产生很高的计算成本，但无训练的替代方案往往会产生次优性能。为了解决这些局限性，我们提出了DAPE，这是一种用于视频编辑的高质量但经济高效的两阶段参数高效微调（PEFT）框架。在第一阶段，我们设计了一种有效的范数调整方法来增强生成视频的时间一致性。第二阶段引入视觉友好型适配器以提高视觉质量。此外，我们还发现了现有基准测试中的关键缺陷，包括类别多样性有限、对象分布不平衡和帧数不一致。为了缓解这些问题，我们策划了一个大型数据集基准测试，包括232个具有丰富注释和6个编辑提示的视频，可以对高级方法进行客观和全面的评估。对现有数据集（BalanceCC、LOVEU-TGVE、RAVE）和我们提出的基准进行的广泛实验表明，DAPE显著提高了时间连贯性和文本视频对齐，同时优于以前最先进的方法。 et.al.|[2505.07057](http://arxiv.org/abs/2505.07057)|null|
|**2025-05-11**|**BridgeIV: Bridging Customized Image and Video Generation through Test-Time Autoregressive Identity Propagation**|零样本和基于调整的定制文本到图像（CT2I）生成在讲故事内容创作方面都取得了重大进展。相比之下，对定制文本到视频（CT2V）生成的研究仍然相对有限。现有的零样本CT2V方法具有较差的泛化能力，而另一种直接将基于调谐的T2I模型与时间运动模块相结合的工作通常会导致结构和纹理信息的丢失。为了弥合这一差距，我们提出了一种自回归结构和纹理传播模块（STPM），该模块从参考对象中提取关键的结构和纹理特征，并将其自回归地注入到每个视频帧中，以提高一致性。此外，我们引入了一种测试时间奖励优化（TTRO）方法，以进一步细化细粒度细节。定量和定性实验验证了STPM和TTRO的有效性，表明CLIP-I和DINO一致性指标分别比基线提高了7.8和13.1。 et.al.|[2505.06985](http://arxiv.org/abs/2505.06985)|null|

<p align=right>(<a href=#updated-on-20250515>back to top</a>)</p>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-05-13**|**FOCI: Trajectory Optimization on Gaussian Splats**|3D高斯散斑（3DGS）最近作为3D重建和视图合成方法中神经辐射场（NeRF）的更快替代方案而受到欢迎。利用3DGS中编码的空间信息，这项工作提出了FOCI（场重叠碰撞积分），这是一种能够直接在高斯本身上优化轨迹的算法。FOCI利用高斯重叠积分的概念，为3DGS利用了一种新颖且可解释的碰撞公式。与其他方法相反，这些方法用保守的边界框表示机器人，低估了环境的可穿越性，我们建议将环境和机器人表示为高斯散点。这不仅具有理想的计算特性，而且允许进行方向感知规划，使机器人能够穿过非常狭窄的空间。我们在合成和真实高斯Splats中广泛测试了我们的算法，展示了ANYmal腿式机器人的无碰撞轨迹，即使有数十万高斯人组成环境，也可以在几秒钟内计算出来。项目页面和代码可在https://rffr.leggedrobotics.com/works/foci/ et.al.|[2505.08510](http://arxiv.org/abs/2505.08510)|null|
|**2025-05-13**|**ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image**|我们将自适应视图规划引入多视图合成，旨在提高单视图3D重建的遮挡显示和3D一致性。我们不是独立或同时生成一组无序的视图，而是生成一系列视图，利用时间一致性来增强3D一致性。最重要的是，我们的视图序列不是由预先确定的相机设置决定的。相反，我们计算自适应相机轨迹（ACT），具体来说，是相机视图的轨迹，它最大限度地提高了要重建的3D对象的遮挡区域的可见性。一旦找到最佳轨道，我们将其馈送到视频扩散模型，以生成轨道周围的新视图，然后将其传递到多视图3D重建模型以获得最终重建。我们的多视图合成管道非常高效，因为它不涉及运行时训练/优化，只涉及通过应用预训练的模型进行遮挡分析和多视图合成的前向推理。我们的方法预测了相机轨迹，有效地揭示了遮挡并产生了一致的新视图，在看不见的GSO数据集上显著改善了SOTA的3D重建，无论是定量还是定性。 et.al.|[2505.08239](http://arxiv.org/abs/2505.08239)|null|
|**2025-05-13**|**TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin Benchmark Dataset**|城市数字双胞胎（UDTs）已成为管理城市和整合来自不同来源的复杂异构数据的关键。创建UDT涉及多个过程阶段的挑战，包括获取准确的3D源数据、重建高保真3D模型、维护模型的更新，以及确保与下游任务的无缝互操作性。当前的数据集通常仅限于处理链的一部分，阻碍了全面的UDT验证。为了应对这些挑战，我们推出了第一个全面的多模式城市数字孪生基准数据集：TUM2TWIN。该数据集包括地理参考、语义对齐的3D模型和网络，以及各种地面、移动、空中和卫星观测，拥有32个数据子集，数据量约为100000美元，目前为767 GB。通过确保地理参考的室内外采集、高精度和多模态数据集成，该基准支持传感器的稳健分析和先进重建方法的开发。此外，我们还探索了展示TUM2TWIN潜力的下游任务，包括NeRF和高斯散斑的新颖视图合成、太阳势分析、点云语义分割和LoD3建筑重建。我们相信，这一贡献为克服UDT创建中的当前局限性奠定了基础，为更智能、数据驱动的城市环境培养了新的研究方向和实用的解决方案。该项目可在以下网址获得：https://tum2t.win et.al.|[2505.07396](http://arxiv.org/abs/2505.07396)|null|
|**2025-05-12**|**Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild**|使用体绘制技术的神经隐式表面重建最近在从多个2D图像创建高保真表面方面取得了重大进展。然而，目前的方法主要针对具有一致照明的场景，并且难以在具有瞬态遮挡或不同外观的不受控制的环境中准确重建3D几何体。虽然一些基于神经辐射场（NeRF）的变体可以更好地管理复杂场景中的光度变化和瞬态对象，但由于有限的表面约束，它们被设计用于新颖的视图合成，而不是精确的表面重建。为了克服这一局限性，我们引入了一种新方法，该方法将多个几何约束应用于隐式曲面优化过程，从而能够从无约束图像集合中进行更精确的重建。首先，我们利用运动结构中的稀疏3D点（SfM）来细化重建表面的带符号距离函数估计，并通过位移补偿来适应稀疏点中的噪声。此外，我们采用从法线预测器导出的鲁棒法线先验，并通过边缘先验滤波和多视图一致性约束进行增强，以改善与实际表面几何形状的对齐。对Heritage Recon基准和其他数据集的广泛测试表明，所提出的方法可以从野外图像中准确重建表面，与现有技术相比，可以产生具有更高精度和粒度的几何形状。我们的方法能够对各种地标进行高质量的3D重建，使其适用于各种场景，如文化遗产的数字保护。 et.al.|[2505.07373](http://arxiv.org/abs/2505.07373)|null|
|**2025-05-11**|**NeuGen: Amplifying the 'Neural' in Neural Radiance Fields for Domain Generalization**|神经辐射场（NeRF）显著推进了新视图合成领域，但它们在不同场景和条件下的泛化仍然具有挑战性。为了解决这个问题，我们建议将一种新的大脑启发的归一化技术神经泛化（NeuGen）集成到领先的NeRF架构中，包括MVSNeRF和GeoNeRF。NeuGen提取域不变特征，从而增强模型的泛化能力。它可以无缝集成到NeRF架构中，并培养出一套全面的功能集，显著提高了图像渲染的准确性和鲁棒性。通过这种集成，NeuGen在最先进的NeRF架构的不同数据集上的基准测试中表现出了更高的性能，使其能够在不同的场景中更好地推广。我们的定量和定性综合评估证实，我们的方法不仅在泛化能力上超越了现有模型，而且显著提高了渲染质量。我们的工作展示了将神经科学原理与深度学习框架相结合的潜力，为提高新视图合成的泛化能力和效率树立了新的先例。我们的研究演示可在https://neugennerf.github.io. et.al.|[2505.06894](http://arxiv.org/abs/2505.06894)|null|
|**2025-05-10**|**Gaussian Wave Splatting for Computer-Generated Holography**|最先进的神经渲染方法从几张照片中优化高斯场景表示，以实现新颖的视图合成。基于这些表示，我们开发了一种高效的算法，称为高斯波散布，将这些高斯波转化为全息图。与现有的计算机生成全息术（CGH）算法不同，高斯波散布通过利用神经渲染的最新进展，为照片级真实感场景支持精确的遮挡和视图相关效果。具体来说，我们为支持遮挡和阿尔法混合的2D高斯到全息图变换推导了一个封闭形式的解决方案。受经典计算机图形学技术的启发，我们还推导出了傅里叶域中上述过程的有效近似值，该近似值易于并行化，并使用自定义CUDA内核实现。通过将新兴的神经渲染管道与全息显示技术相结合，我们基于高斯的CGH框架为下一代全息显示器铺平了道路。 et.al.|[2505.06582](http://arxiv.org/abs/2505.06582)|null|
|**2025-05-09**|**RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects**|现代3D重建和新颖的视图合成方法在具有不透明朗伯对象的场景中表现出了很强的性能。然而，大多数假设光路是直的，因此无法正确处理折射和反射材料。此外，专门针对这些效应的数据集有限，阻碍了评估性能和开发合适技术的努力。在这项工作中，我们引入了一个合成的RefRef数据集和基准，用于从姿态图像中重建具有折射和反射物体的场景。我们的数据集有50个不同复杂度的对象，从单材质凸形到多材质非凸形，每个对象都放置在三种不同的背景类型中，从而产生150个场景。我们还提出了一种预言方法，在给定物体几何形状和折射率的情况下，计算神经渲染的精确光路，并在此基础上提出了一个避免这些假设的方法。我们将这些方法与几种最先进的方法进行了比较，并表明所有方法都明显落后于oracle，突显了任务和数据集的挑战。 et.al.|[2505.05848](http://arxiv.org/abs/2505.05848)|null|
|**2025-05-08**|**UltraGauss: Ultrafast Gaussian Reconstruction of 3D Ultrasound Volumes**|超声成像因其安全性、可负担性和实时性而被广泛使用，但其二维解释高度依赖于操作员，导致可变性和认知需求增加。2D到3D重建通过提供标准化的体积视图来缓解这些挑战，但现有的方法通常计算成本高、内存密集或与超声物理不兼容。我们介绍了UltraGauss：第一个超声专用高斯散斑框架，将视图合成技术扩展到超声波传播。与传统的基于透视的溅射不同，UltraGauss在3D中模拟探头平面交点，与声像形成对齐。我们推导了一种用于GPU并行化的高效光栅化边界公式，并引入了数值稳定的协方差参数化，提高了计算效率和重建精度。在真实的临床超声数据上，UltraGauss在5分钟内实现了最先进的重建，并在单个GPU上在20分钟内达到0.99 SSIM。一项对专家临床医生的调查证实，UltraGauss的重建是竞争方法中最现实的。我们的CUDA实施将在发布后发布。 et.al.|[2505.05643](http://arxiv.org/abs/2505.05643)|null|
|**2025-05-08**|**Steepest Descent Density Control for Compact 3D Gaussian Splatting**|3D高斯散斑（3DGS）已成为实时、高分辨率新颖视图合成的强大技术。通过将场景表示为高斯基元的混合，3DGS利用GPU光栅化管道进行高效的渲染和重建。为了优化场景覆盖并捕捉精细细节，3DGS采用致密化算法来生成额外的点。然而，这一过程通常会导致冗余的点云，从而导致内存使用过度、性能下降和大量存储需求，给资源受限的设备上的部署带来了重大挑战。为了解决这一局限性，我们提出了一个理论框架，该框架揭开了3DGS中密度控制的神秘面纱并加以改进。我们的分析表明，分裂对于逃离鞍点至关重要。通过优化理论方法，我们建立了致密化的必要条件，确定了子高斯数的最小值，确定了最佳参数更新方向，并为归一化弹簧不透明度提供了解析解。基于这些见解，我们引入了SteepGS，它结合了最陡密度控制，这是一种原则性的策略，可以在保持紧凑点云的同时最大限度地减少损失。SteepGS在不影响渲染质量的情况下实现了高斯点减少约50%，显著提高了效率和可扩展性。 et.al.|[2505.05587](http://arxiv.org/abs/2505.05587)|null|
|**2025-05-07**|**SGCR: Spherical Gaussians for Efficient 3D Curve Reconstruction**|神经渲染技术在生成逼真的3D场景方面取得了重大进展。最新的3D高斯散点技术实现了高质量的新颖视图合成以及快速的渲染速度。然而，尽管3D高斯算子具有明确的原始表示，但它们在定义精确的3D几何结构方面缺乏熟练程度。这是因为高斯的属性主要是通过其各向异性来定制和微调的，以渲染各种2D图像。为了为高效的3D重建铺平道路，我们提出了球面高斯，这是一种简单有效的3D几何边界表示方法，我们可以从一组校准的多视图图像中直接重建3D特征曲线。球面高斯从网格初始化开始进行优化，具有基于视图的渲染损失，其中在特定视图处渲染2D边缘图，然后将其与从相应图像中提取的地面真实边缘图进行比较，而不需要任何3D指导或监督。考虑到球面高斯作为鲁棒边缘表示的媒介，我们进一步引入了一种新的基于优化的算法SGCR，可以直接从对齐的球面高斯中提取精确的参数曲线。我们证明，SGCR在3D边缘重建方面优于现有的最先进方法，同时具有很高的效率。 et.al.|[2505.04668](http://arxiv.org/abs/2505.04668)|**[link](https://github.com/martinyxr/sgcr)**|

<p align=right>(<a href=#updated-on-20250515>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-05-13**|**Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions**|高质量的肺节段三维重建在肺癌节段切除术和手术治疗计划中起着至关重要的作用。由于目标重建的分辨率要求，传统的基于深度学习的方法经常受到计算资源约束或粒度有限的影响。相反，隐式建模因其计算效率和在任何分辨率下的连续表示而受到青睐。我们提出了一种基于神经隐式函数的方法来学习3D表面，以实现解剖感知的精确肺段重建，通过变形可学习的模板将其表示为形状。此外，我们引入了两个临床相关的评估指标来全面评估重建。此外，由于缺乏公开可用的形状数据集来对重建算法进行基准测试，我们开发了一个名为Lung3D的形状数据集中，包括800个标记的肺段和相应的气道、动脉、静脉和段间静脉的3D模型。我们证明，所提出的方法优于现有的方法，为肺段重建提供了新的视角。代码和数据将在https://github.com/M3DV/ImPulSe. et.al.|[2505.08919](http://arxiv.org/abs/2505.08919)|**[link](https://github.com/m3dv/impulse)**|
|**2025-05-13**|**FOCI: Trajectory Optimization on Gaussian Splats**|3D高斯散斑（3DGS）最近作为3D重建和视图合成方法中神经辐射场（NeRF）的更快替代方案而受到欢迎。利用3DGS中编码的空间信息，这项工作提出了FOCI（场重叠碰撞积分），这是一种能够直接在高斯本身上优化轨迹的算法。FOCI利用高斯重叠积分的概念，为3DGS利用了一种新颖且可解释的碰撞公式。与其他方法相反，这些方法用保守的边界框表示机器人，低估了环境的可穿越性，我们建议将环境和机器人表示为高斯散点。这不仅具有理想的计算特性，而且允许进行方向感知规划，使机器人能够穿过非常狭窄的空间。我们在合成和真实高斯Splats中广泛测试了我们的算法，展示了ANYmal腿式机器人的无碰撞轨迹，即使有数十万高斯人组成环境，也可以在几秒钟内计算出来。项目页面和代码可在https://rffr.leggedrobotics.com/works/foci/ et.al.|[2505.08510](http://arxiv.org/abs/2505.08510)|null|
|**2025-05-13**|**A Survey of 3D Reconstruction with Event Cameras: From Event-based Geometry to Neural 3D Rendering**|事件相机已成为3D重建的有前景的传感器，因为它们能够异步捕获每像素的亮度变化。与传统的基于帧的相机不同，它们产生稀疏且时间丰富的数据流，这使得能够进行更精确的3D重建，并为在高速运动、低光照或高动态范围场景等极端环境中进行重建开辟了可能性。在这项调查中，我们提供了第一个专门针对使用事件相机进行3D重建的全面综述。该调查根据输入模态将现有作品分为三大类——立体、单眼和多模态系统，并通过重建方法进一步对其进行分类，包括基于几何、基于深度学习和最近的神经渲染技术，如神经辐射场和3D高斯散斑。具有相似研究重点的方法按时间顺序分为最细分的组。我们还总结了与基于事件的3D重建相关的公共数据集。最后，我们强调了当前在数据可用性、评估、表示和动态场景处理方面的研究局限性，并概述了未来有前景的研究方向。这项调查旨在为事件驱动的3D重建的未来发展提供全面的参考和路线图。 et.al.|[2505.08438](http://arxiv.org/abs/2505.08438)|null|
|**2025-05-13**|**ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image**|我们将自适应视图规划引入多视图合成，旨在提高单视图3D重建的遮挡显示和3D一致性。我们不是独立或同时生成一组无序的视图，而是生成一系列视图，利用时间一致性来增强3D一致性。最重要的是，我们的视图序列不是由预先确定的相机设置决定的。相反，我们计算自适应相机轨迹（ACT），具体来说，是相机视图的轨迹，它最大限度地提高了要重建的3D对象的遮挡区域的可见性。一旦找到最佳轨道，我们将其馈送到视频扩散模型，以生成轨道周围的新视图，然后将其传递到多视图3D重建模型以获得最终重建。我们的多视图合成管道非常高效，因为它不涉及运行时训练/优化，只涉及通过应用预训练的模型进行遮挡分析和多视图合成的前向推理。我们的方法预测了相机轨迹，有效地揭示了遮挡并产生了一致的新视图，在看不见的GSO数据集上显著改善了SOTA的3D重建，无论是定量还是定性。 et.al.|[2505.08239](http://arxiv.org/abs/2505.08239)|null|
|**2025-05-12**|**RDD: Robust Feature Detector and Descriptor using Deformable Transformer**|作为从运动和SLAM构建结构的核心步骤，尽管存在普遍性，但在诸如显著视点变化等具有挑战性的场景下，鲁棒的特征检测和描述仍未得到解决。虽然最近的工作已经确定了局部特征在建模几何变换中的重要性，但这些方法未能学习到长距离关系中存在的视觉线索。我们提出了鲁棒可变形检测器（RDD），这是一种利用可变形变换器的新型鲁棒关键点检测器/描述符，它通过可变形的自关注机制捕获全局上下文和几何不变性。具体来说，我们观察到可变形注意力集中在关键位置，有效地降低了搜索空间的复杂性，并对几何不变性进行了建模。此外，除了标准的MegaDepth数据集外，我们还收集了一个空对地数据集进行训练。我们提出的方法在稀疏匹配任务中优于所有最先进的关键点检测/描述方法，并且还能够进行半密集匹配。为了确保全面评估，我们引入了两个具有挑战性的基准：一个强调大视角和尺度变化，另一个是空对地基准——这是一种最近在不同高度的3D重建中越来越受欢迎的评估设置。 et.al.|[2505.08013](http://arxiv.org/abs/2505.08013)|null|
|**2025-05-12**|**Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild**|使用体绘制技术的神经隐式表面重建最近在从多个2D图像创建高保真表面方面取得了重大进展。然而，目前的方法主要针对具有一致照明的场景，并且难以在具有瞬态遮挡或不同外观的不受控制的环境中准确重建3D几何体。虽然一些基于神经辐射场（NeRF）的变体可以更好地管理复杂场景中的光度变化和瞬态对象，但由于有限的表面约束，它们被设计用于新颖的视图合成，而不是精确的表面重建。为了克服这一局限性，我们引入了一种新方法，该方法将多个几何约束应用于隐式曲面优化过程，从而能够从无约束图像集合中进行更精确的重建。首先，我们利用运动结构中的稀疏3D点（SfM）来细化重建表面的带符号距离函数估计，并通过位移补偿来适应稀疏点中的噪声。此外，我们采用从法线预测器导出的鲁棒法线先验，并通过边缘先验滤波和多视图一致性约束进行增强，以改善与实际表面几何形状的对齐。对Heritage Recon基准和其他数据集的广泛测试表明，所提出的方法可以从野外图像中准确重建表面，与现有技术相比，可以产生具有更高精度和粒度的几何形状。我们的方法能够对各种地标进行高质量的3D重建，使其适用于各种场景，如文化遗产的数字保护。 et.al.|[2505.07373](http://arxiv.org/abs/2505.07373)|null|
|**2025-05-10**|**3D Characterization of Smoke Plume Dispersion Using Multi-View Drone Swarm**|本研究提出了一种先进的多视图无人机群成像系统，用于烟羽扩散动力学的三维表征。该系统由一架经理无人机和四架工人无人机组成，每架无人机都配备了高分辨率摄像头和精确的GPS模块。管理者无人机使用图像反馈自主检测并定位自己在羽流上方，然后命令工作人员无人机以同步的圆形飞行模式绕该区域飞行，捕获多角度图像。首先估计这些图像的相机姿态，然后将图像分批分组，并使用神经辐射场（NeRF）进行处理，以生成随时间变化的羽流动力学的高分辨率3D重建。现场测试证明，该系统能够以约1秒的时间分辨率捕获关键的羽流特征，包括体积动力学、风驱动的方向变化和放样行为。该系统生成的3D重建为增强烟流扩散和火灾蔓延的预测模型提供了独特的现场数据。从广义上讲，无人机群系统为野火、火山爆发、规定烧伤和工业过程中污染物排放和运输的高分辨率测量提供了一个多功能平台，最终支持更有效的消防决策并降低野火风险。 et.al.|[2505.06638](http://arxiv.org/abs/2505.06638)|null|
|**2025-05-09**|**VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction**|Next Best View（NBV）算法旨在使用最少的资源、时间或捕获次数来获取一组最佳图像，以实现场景的高效3D重建。现有的方法通常依赖于先前的场景知识或额外的图像捕获，并经常制定最大化覆盖范围的策略。然而，对于许多具有复杂几何形状和自遮挡的真实场景，覆盖最大化并不能直接带来更好的重建质量。本文提出了视图自检网络（VIN）和VIN-NBV策略，该网络经过训练可以直接预测视图的重建质量改进。一种基于贪婪顺序采样的策略，在每个采集步骤，我们对多个查询视图进行采样，并选择VIN预测改进得分最高的视图。我们设计VIN来执行基于先前采集的重建的3D感知特征化，并为每个查询视图创建一个可以解码为改进分数的特征。然后，我们使用模仿学习来训练VIN，以预测重建改进分数。我们发现，在采集次数或运动时间受到限制的情况下，VIN-NBV在覆盖最大化基线上将重建质量提高了约30%。 et.al.|[2505.06219](http://arxiv.org/abs/2505.06219)|null|
|**2025-05-09**|**RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects**|现代3D重建和新颖的视图合成方法在具有不透明朗伯对象的场景中表现出了很强的性能。然而，大多数假设光路是直的，因此无法正确处理折射和反射材料。此外，专门针对这些效应的数据集有限，阻碍了评估性能和开发合适技术的努力。在这项工作中，我们引入了一个合成的RefRef数据集和基准，用于从姿态图像中重建具有折射和反射物体的场景。我们的数据集有50个不同复杂度的对象，从单材质凸形到多材质非凸形，每个对象都放置在三种不同的背景类型中，从而产生150个场景。我们还提出了一种预言方法，在给定物体几何形状和折射率的情况下，计算神经渲染的精确光路，并在此基础上提出了一个避免这些假设的方法。我们将这些方法与几种最先进的方法进行了比较，并表明所有方法都明显落后于oracle，突显了任务和数据集的挑战。 et.al.|[2505.05848](http://arxiv.org/abs/2505.05848)|null|
|**2025-05-08**|**The Moon's Many Faces: A Single Unified Transformer for Multimodal Lunar Reconstruction**|多模态学习是跨多个学科的新兴研究课题，但很少应用于行星科学。在这篇文章中，我们发现反射率参数估计和基于图像的月球图像3D重建可以被表述为一个多模态学习问题。我们提出了一种单一的、统一的变换器架构，该架构经过训练，可以学习多个源之间的共享表示，如灰度图像、数字高程模型、表面法线和反照率图。该架构支持从任何输入模态到任何目标模态的灵活转换。从灰度图像预测DEM和反照率图同时解决了行星表面的3D重建任务，并解开了光度参数和高度信息。我们的结果表明，我们的基础模型在这四种模式中学习了物理上合理的关系。未来添加更多的输入模式将实现光度归一化和共配准等任务。 et.al.|[2505.05644](http://arxiv.org/abs/2505.05644)|null|

<p align=right>(<a href=#updated-on-20250515>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-05-14**|**Robust Representation and Estimation of Barycenters and Modes of Probability Measures on Metric Spaces**|本文研究黎曼流形和更一般的度量空间上分布的统计定义和估计问题。挑战部分来自这样一个事实，即均值和众数等统计数据可能不稳定：例如，分布的一个小扰动可能会导致像圆这样简单的空间上的Fr’echet均值发生很大变化。我们通过引入一种新的重心合并树表示来解决这个问题，称为重心合并树（BMT），它采用测量度量图的形式，并以多尺度的方式总结分布的特征。通过扩散距离将模态视为重心的特例。与经典均值和模的性质相反，我们证明了BMT是稳定的——这被量化为涉及最优传输度量的Lipschitz估计。这种稳定性使我们能够从经验测量中得出近似BMT的一致性结果，具有明确的收敛速度。我们还给出了一种可证明精确的离散近似BMT构造的方法，并利用该方法为球体和形状空间上的分布提供了数值例子。 et.al.|[2505.09609](http://arxiv.org/abs/2505.09609)|null|
|**2025-05-14**|**LightLab: Controlling Light Sources in Images with Diffusion Models**|我们提出了一种简单而有效的基于扩散的方法，用于对图像中的光源进行细粒度的参数控制。现有的重新照明方法要么依赖于多个输入视图在推理时执行逆渲染，要么无法对灯光变化提供明确的控制。我们的方法在一小部分真实的原始照片对上微调扩散模型，辅以按比例合成渲染的图像，以得出其用于重新照明的真实感先验。我们利用光的线性来合成图像对，描绘目标光源或环境照明的受控光变化。使用这些数据和适当的微调方案，我们训练了一个模型，用于精确控制光强度和颜色的照明变化。最后，我们展示了我们的方法如何实现引人注目的灯光编辑结果，并优于基于用户偏好的现有方法。 et.al.|[2505.09608](http://arxiv.org/abs/2505.09608)|null|
|**2025-05-14**|**The Niche Connectivity Paradox: Multichrome Contagions Overcome Vaccine Hesitancy more effectively than Monochromacy**|疫苗犹豫的加剧导致麻疹和百日咳等可预防疫苗的疾病死灰复燃，同时人们普遍怀疑和拒绝接种新冠肺炎疫苗。虽然将个人分为支持或反对疫苗提供了一种方便的疫苗态度二分法，但疫苗犹豫要复杂得多，而且是动态的。它涉及态度波动的摇摆不定的人——那些可能一次表现出支持疫苗的态度，另一次又表现出反对疫苗态度的人。在这里，我们通过利用已知的抗vax和抗vax推特用户数据集（n=1.35亿美元）和大型新冠肺炎推特数据集（n=3.5亿美元；包括对1563472美元独特个体的密切分析），将多色传染病确定和分析为潜在的干预目标。我们使用顶级共同传播问题重建了一个不断发展的多元情绪格局，根据它们与疫苗接种的概念重叠，将它们描述为单色和多色传染。我们展示了转换者是深思熟虑的：他们更温和，参与更广泛的主题，并在他们的网络中占据更中心的位置。对他们的信息消费的进一步研究表明，他们的话语经常涉及气候变化等进步问题，这可以作为多色传染干预的途径，以促进支持疫苗的态度。使用数据驱动的干预模拟，我们展示了生态位连接的悖论，其中具有碎片化、非重叠社区的多色传染病产生了支持疫苗态度的最高传播水平。我们的工作为利用多色传染的协同搭便车效应来推动基于网络的干预措施中所需的态度和行为变化提供了见解，特别是为了克服疫苗犹豫。 et.al.|[2505.09605](http://arxiv.org/abs/2505.09605)|null|
|**2025-05-14**|**VTLA: Vision-Tactile-Language-Action Model with Preference Learning for Insertion Manipulation**|虽然视觉语言模型已经取得了显著进步，但它们在语言条件机器人操纵中的应用仍有待探索，特别是对于超出视觉主导的拾取和放置场景的接触丰富的任务。为了弥合这一差距，我们引入了视觉触觉语言行动模型，这是一种新的框架，通过跨模态语言基础有效地整合视觉和触觉输入，在接触密集型场景中实现了稳健的政策生成。在模拟环境中构建了一个低成本、多模式的数据集，其中包含专门为指尖插入任务设计的视觉-触觉-动作指令对。此外，我们引入了直接偏好优化（DPO），为VTLA模型提供类似回归的监督，有效地弥合了基于分类的下一个令牌预测丢失和连续机器人任务之间的差距。实验结果表明，VTLA模型优于传统的模仿学习方法（如扩散策略）和现有的多模态基线（TLA/VLA），在看不见的栓钉形状上实现了90%以上的成功率。最后，我们进行了真实世界的钻孔实验，以证明所提出的VTLA模型的出色Sim2Real性能。有关补充视频和结果，请访问我们的项目网站：https://sites.google.com/view/vtla et.al.|[2505.09577](http://arxiv.org/abs/2505.09577)|null|
|**2025-05-14**|**Don't Forget your Inverse DDIM for Image Editing**|随着扩散模型的引入，文本到图像生成领域取得了重大进展。然而，编辑真实图像的挑战仍然存在，因为大多数方法要么计算密集，要么重建效果不佳。本文介绍了SAGE（图像编辑的自我注意力引导），这是一种利用预训练扩散模型进行图像编辑的新技术。SAGE建立在DDIM算法的基础上，并采用了一种利用扩散U-Net的自关注层的新型制导机制。该机制基于逆DDIM过程中生成的注意力图计算重建目标，从而能够有效地重建未经编辑的区域，而不需要精确重建整个输入图像。因此，SAGE直接解决了图像编辑中的关键挑战。SAGE相对于其他方法的优越性通过定量和定性评估得到了证明，并通过一项经过统计验证的综合用户研究得到了证实，在该研究中，所有47名受访用户都更喜欢SAGE而不是竞争方法。此外，SAGE在10项定量分析中有7项排名第一，在其余3项中排名第二和第三。 et.al.|[2505.09571](http://arxiv.org/abs/2505.09571)|null|
|**2025-05-14**|**BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset**|在最近的多模态模型研究中，统一图像理解和生成越来越受到关注。尽管图像理解的设计选择已经得到了广泛的研究，但用于图像生成的统一框架的最佳模型架构和训练配方仍然没有得到充分的探索。受自回归和扩散模型在高质量生成和可扩展性方面的巨大潜力的启发，我们对它们在统一多模态设置中的使用进行了全面研究，重点是图像表示、建模目标和训练策略。基于这些研究，我们引入了一种新方法，与传统的基于VAE的表示相比，该方法采用扩散变换器来生成语义丰富的CLIP图像特征。这种设计既提高了训练效率，又提高了生成质量。此外，我们证明，统一模型的顺序预训练策略——首先训练图像理解，然后训练图像生成——通过在保持图像理解能力的同时发展强大的图像生成能力，提供了实际优势。最后，我们精心策划了一个高质量的指令调整数据集BLIP3o-60k，用于图像生成，通过用一组涵盖各种场景、对象、人类手势等的不同标题提示GPT-4o。基于我们创新的模型设计、训练配方和数据集，我们开发了BLIP3-o，这是一套最先进的统一多模态模型。BLIP3-o在大多数流行的基准测试中都实现了卓越的性能，涵盖了图像理解和生成任务。为了促进未来的研究，我们完全开源了我们的模型，包括代码、模型权重、训练脚本以及预训练和指令调优数据集。 et.al.|[2505.09568](http://arxiv.org/abs/2505.09568)|**[link](https://github.com/jiuhaichen/blip3o)**|
|**2025-05-14**|**Learning Long-Context Diffusion Policies via Past-Token Prediction**|对长序列的观察和动作进行推理对于许多机器人任务至关重要。然而，从示威活动中学习有效的长期政策仍然具有挑战性。随着上下文长度的增加，由于内存需求的增加，训练变得越来越昂贵，并且由于虚假相关性，策略性能往往会下降。最近的方法通常通过截断上下文长度来回避这些问题，丢弃可能对后续决策至关重要的历史信息。在本文中，我们提出了一种明确规范过去信息保留的替代方法。我们首先重新审视了模仿学习中的模仿问题，并在最近的扩散政策中发现了一个相反的挑战：它们往往无法捕捉到过去和未来行动之间的基本依赖关系，而不是过度依赖先前的行动。为了解决这个问题，我们引入了过去令牌预测（PTP），这是一个辅助任务，其中策略学习预测过去的动作令牌和未来的动作令牌。这种正则化显著改善了策略头中的时间建模，对视觉表示的依赖最小。基于这一观察，我们进一步引入了一种多阶段训练策略：用短上下文预训练视觉编码器，并使用缓存的长上下文嵌入微调策略头。该策略保留了PTP的优点，同时大大减少了内存和计算开销。最后，我们将PTP扩展为测试时的自我验证机制，使该策略能够在推理过程中对与过去行为一致的候选者进行评分和选择。在四个真实世界和六个模拟任务中的实验表明，我们提出的方法将长上下文扩散策略的性能提高了3倍，并将策略训练速度提高了10倍以上。 et.al.|[2505.09561](http://arxiv.org/abs/2505.09561)|null|
|**2025-05-14**|**Nonmonotonic diffusion in sheared active suspensions of squirmers**|我们研究了剪切力如何影响稀到浓悬浮液中活性颗粒的动力学。具体来说，我们关注的是蠕动器的非极性主动悬浮液，它们单独不动，但显示出活动诱导的流体动力学扩散。在剪切作用下，瞬时颗粒速度波动更快，类似于被动悬浮；然而，令人惊讶的是，长时间的扩散动力学可以减缓并表现出对剪切速率的非单调依赖性。我们表明，这种行为是由活动诱导的持续运动和剪切诱导的负速度自相关之间的相互作用引起的，这两者在较低的体积分数下都更为明显。具有可调持久性的自推进粒子的模拟支持了这一解释，并进一步提供了一种简单的机制来理解观察到的耦合。我们的研究结果揭示了剪切对活性悬浮液中扩散的普遍影响，阐明了内外力如何相互作用，并为调节活性流体中的传输提供了新的可能性。 et.al.|[2505.09457](http://arxiv.org/abs/2505.09457)|null|
|**2025-05-14**|**Variational formulations of transport on combinatorial meshes**|我们开发了描述拓扑空间标量物理性质传输的守恒定律的原始和混合变分公式的类似物，称为细胞复合体。这种发展仅限于具有简单多面体连接的细胞复合物。这些空间是由不同表观拓扑维度的元素组成的物理系统的合适表示，其中所有元素都可能具有单独的属性，给定维度的元素可能通过较低维度的公共元素相互作用。这个建模基础可以被认为是基于粒子的建模基础（离散拓扑）和连续体建模基础（平滑拓扑）之间的中间环节。新的基础为分析具有复杂内部结构的物理系统的行为提供了优势。该发展基于组合微分形式的微积分，它是微分形式光滑外微积分的离散模拟。我们称由此产生的微积分为组合网格微积分（CMC），因为它基于组合网格，因此忘记了嵌入，在计算中只使用了单元之间的连接性和单元的度量。我们讨论了所获得的公式如何专门用于几个不同的问题，包括质量扩散、热传导、多孔介质中的流体流动和电荷扩散，并提供了这些输运情况下初始边值问题公式的详细信息。给出了所选边值问题的示例和结果，以证明CMC公式的能力。 et.al.|[2505.09443](http://arxiv.org/abs/2505.09443)|null|
|**2025-05-14**|**Train a Multi-Task Diffusion Policy on RLBench-18 in One Day with One GPU**|我们提出了一种训练多任务视觉语言机器人扩散策略的方法，该方法将训练时间和内存使用量减少了一个数量级。这种改进源于之前对动作扩散和启发它的图像扩散技术之间未充分探索的区别：图像生成目标是高维的，而机器人动作位于低维空间中。同时，动作生成的视觉语言条件仍然是高维的。我们的方法Mini Diffuser通过引入二级微批处理来利用这种不对称性，该方法将多个有噪声的动作样本与每种视觉语言条件配对，而不是传统的一对一采样策略。为了支持这种批处理方案，我们对扩散变换器进行了架构调整，以防止样本之间的信息泄漏，同时保持完全的调节访问。在RLBench模拟中，迷你扩散器实现了最先进的多任务扩散策略性能的95%，而只使用了5%的训练时间和7%的内存。真实世界的实验进一步证实，迷你扩散器保留了基于扩散的策略的关键优势，包括对多模态动作分布进行建模的能力，以及产生基于不同感知输入的行为的能力。代码可以在github上找到。 et.al.|[2505.09430](http://arxiv.org/abs/2505.09430)|**[link](https://github.com/utomm/mini-diffuse-actor)**|

<p align=right>(<a href=#updated-on-20250515>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-04-30**|**Neural Co-Optimization of Structural Topology, Manufacturable Layers, and Path Orientations for Fiber-Reinforced Composites**|我们提出了一种基于神经网络的计算框架，用于同时优化结构拓扑、弯曲层和路径方向，以在确保可制造性的同时实现纤维增强热塑性复合材料的强各向异性强度。我们的框架采用三个隐式神经场来表示几何形状、层序列和纤维取向。这使得设计和可制造性目标（如各向异性强度、结构体积、机器运动控制、层曲率和层厚度）能够直接公式化为一个集成和可微分的优化过程。通过将这些目标作为损失函数，该框架确保了所得复合材料具有优化的机械强度，同时保持了其在不同硬件平台上基于长丝的多轴3D打印的可制造性。物理实验表明，与具有顺序优化结构和制造顺序的复合材料相比，我们的协同优化方法产生的复合材料的破坏载荷可以提高33.1%。 et.al.|[2505.03779](http://arxiv.org/abs/2505.03779)|null|
|**2025-05-05**|**A New Perspective To Understanding Multi-resolution Hash Encoding For Neural Fields**|Instant NGP是近年来最先进的神经场架构。其令人难以置信的信号拟合能力通常归因于其多分辨率哈希网格结构，并在许多后续工作中得到了使用和改进。然而，目前尚不清楚这种哈希网格结构如何以及为什么能够如此大幅度地提高神经网络的能力。对哈希网格缺乏原则性的理解也意味着，伴随Instant NGP的大量超参数只能通过经验进行调整，而没有太多的启发式方法。为了直观地解释哈希网格的工作原理，我们提出了一种新的视角，即域操作。这一视角提供了一种全新的解释，即特征网格如何学习目标信号，并通过人工创建多个预先存在的线性段来提高神经场的表现力。我们对精心构建的一维信号进行了大量实验，以实证支持我们的主张，并辅助我们的说明。虽然我们的分析主要集中在一维信号上，但我们表明这个想法可以推广到更高的维度。 et.al.|[2505.03042](http://arxiv.org/abs/2505.03042)|**[link](https://github.com/stevolopolis/cp)**|
|**2025-04-27**|**HumMorph: Generalized Dynamic Human Neural Fields from Few Views**|我们介绍了HumMorph，这是一种新的广义方法，用于在显式姿态控制下对动态人体进行自由视点渲染。HumMorph以任意姿势渲染给定几个观察到的视图（从一个开始）的任何指定姿势的人类演员。我们的方法能够实现快速推理，因为它只依赖于通过模型的前馈传递。我们首先在规范T姿势中构建演员的粗略表示，该表示结合了来自个体部分观察的视觉特征，并使用学习到的先验知识填充缺失的信息。粗表示由直接从观察到的视图中提取的细粒度像素对齐特征补充，这些特征提供了高分辨率的外观信息。我们证明，当只有一个输入视图可用时，HumMorph与最先进的技术具有竞争力，但是，在仅进行2次单目观察的情况下，我们可以获得明显更好的视觉质量。此外，之前的广义方法假设可以使用同步的多相机设置获得精确的身体形状和姿势参数。相比之下，我们考虑了一种更实际的场景，其中这些身体参数直接从观察到的视图中进行噪声估计。我们的实验结果表明，我们的架构对噪声参数中的误差更具鲁棒性，在这种情况下明显优于最新技术。 et.al.|[2504.19390](http://arxiv.org/abs/2504.19390)|null|
|**2025-04-24**|**Geometry aware inference of steady state PDEs using Equivariant Neural Fields representations**|神经场的最新进展使学习神经算子的强大离散不变方法成为可能，这些算子在一般几何上近似偏微分方程（PDE）的解。基于这些发展，我们引入了enf2enf，这是一种基于最近提出的等变神经场架构的编码器-解码器方法，用于预测具有非参数化几何变异性的稳态偏微分方程。在enf2enf中，输入几何被编码为潜在的点云嵌入，这些嵌入固有地保留了几何基础并捕获了局部现象。然后将得到的表示与全局参数相结合，并直接解码为连续的输出场，从而有效地对几何和物理之间的耦合进行建模。通过利用局部性和平移不变性的归纳偏差，我们的方法能够捕捉精细尺度的物理特征以及复杂的形状变化，从而增强泛化能力和物理顺应性。对高保真空气动力学数据集、超弹性材料基准和多元素翼型几何形状的广泛实验表明，与最先进的基于图、操作员学习和神经场的方法相比，所提出的模型具有更优越或更具竞争力的性能。值得注意的是，我们的方法支持实时推理和零样本超分辨率，能够在低分辨率网格上进行高效训练，同时保持全尺寸离散化的高精度。 et.al.|[2504.18591](http://arxiv.org/abs/2504.18591)|null|
|**2025-04-28**|**Physics-Driven Neural Compensation For Electrical Impedance Tomography**|电阻抗断层成像（EIT）提供了一种非侵入性的便携式成像方式，在医疗和工业应用中具有巨大的潜力。尽管EIT具有优势，但它遇到了两个主要挑战：其逆问题的不适定性质和空间可变、位置相关的灵敏度分布。传统的基于模型的方法通过正则化来减轻病态性，但忽略了灵敏度的可变性，而监督深度学习方法需要大量的训练数据，缺乏泛化能力。神经领域的最新发展引入了用于图像重建的隐式正则化技术，但这些方法通常忽略了EIT背后的物理原理，从而限制了它们的有效性。在这项研究中，我们提出了PhyNC（物理驱动神经补偿），这是一个无监督的深度学习框架，结合了EIT的物理原理。PhyNC通过动态地将神经表征能力分配给灵敏度较低的区域，确保准确和平衡的电导率重建，解决了不适定逆问题和灵敏度分布问题。对模拟和实验数据的广泛评估表明，PhyNC在细节保存和抗伪影方面优于现有方法，特别是在低灵敏度区域。我们的方法增强了EIT重建的鲁棒性，并提供了一个灵活的框架，可以适应具有类似挑战的其他成像方式。 et.al.|[2504.18067](http://arxiv.org/abs/2504.18067)|null|
|**2025-04-23**|**Spot solutions to a neural field equation on oblate spheroids**|理解神经场中激发模式的动力学是神经科学的一个重要课题。神经场方程是描述相互作用神经元的激发动力学以进行理论分析的数学模型。尽管许多神经场方程的分析都集中在神经元相互作用对平面的影响上，但在对大脑等器官进行建模时，动力学的几何约束也是一个有吸引力的话题。本文报道了在球体作为模型曲面上定义的神经场方程中的模式动力学。我们将点解视为局部模式，并讨论曲面的几何特性如何改变它们的特性。为了分析具有小展平的球体上的斑点模式，我们首先在球面上构造精确的静止斑点解，并揭示它们的稳定性。然后，我们扩展了分析，以证明球状情况下驻点解的存在性和稳定性。我们的一个理论结果是推导了扁球体极点处定域的驻点解的稳定性判据。该标准决定了点解是保持在极点还是移动。最后，我们进行了数值模拟，根据我们的理论预测讨论了点解的动力学。我们的结果表明，点解的动力学取决于曲面和神经相互作用的协调。 et.al.|[2504.16342](http://arxiv.org/abs/2504.16342)|null|
|**2025-04-22**|**Low-Rank Adaptation of Neural Fields**|处理视觉数据通常涉及微小的调整或变化序列，例如图像滤波、表面平滑和视频存储。虽然现有的图形技术，如法线映射和视频压缩，利用冗余来有效地对这种小变化进行编码，但对神经场（NF）的小变化（视觉或物理功能的神经网络参数化）进行编码的问题却很少受到关注。我们提出了一种使用低秩自适应（LoRA）更新神经场的参数高效策略。LoRA是一种来自参数高效微调LLM社区的方法，它以最小的计算开销对预训练模型进行小更新编码。我们使LoRA适应特定于实例的神经场，避免了对大型预训练模型的需求，从而产生了适用于低计算硬件的流水线。我们通过图像滤波、视频压缩和几何编辑的实验验证了我们的方法，证明了它在表示神经场更新方面的有效性和通用性。 et.al.|[2504.15933](http://arxiv.org/abs/2504.15933)|null|
|**2025-04-21**|**Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields**|弱引力透镜是星系形状的轻微扭曲，主要是由宇宙中暗物质的引力效应引起的。在我们的工作中，我们试图从2D望远镜图像中反转弱透镜信号，以重建宇宙暗物质场的3D图。虽然反演通常会产生暗物质场的二维投影，但暗物质分布的精确三维图对于定位感兴趣的结构和测试我们宇宙的理论至关重要。然而，3D反演带来了重大挑战。首先，与依赖于多个视点的标准3D重建不同，在这种情况下，图像仅从单个视点观察。通过观察整个体积中的星系发射器是如何被透镜化的，可以部分解决这一挑战。然而，这导致了第二个挑战：无透镜星系的形状和确切位置是未知的，只能在非常大的不确定性下进行估计。这引入了大量的噪声，几乎完全淹没了透镜信号。以前的方法通过对卷中的结构施加强有力的假设来解决这个问题。相反，我们提出了一种使用引力约束神经场来灵活模拟连续物质分布的方法。我们采用综合分析方法，通过完全可微的物理正向模型优化神经网络的权重，以再现图像测量中存在的透镜信号。我们展示了我们的模拟方法，包括模拟即将到来的望远镜调查数据的暗物质分布的真实模拟测量。我们的结果表明，我们的方法不仅可以超越以前的方法，而且重要的是还能够恢复潜在的令人惊讶的暗物质结构。 et.al.|[2504.15262](http://arxiv.org/abs/2504.15262)|null|
|**2025-04-20**|**Efficient Implicit Neural Compression of Point Clouds via Learnable Activation in Latent Space**|隐式神经表示（INR），也称为神经场，已成为深度学习中的一种强大范式，使用基于坐标的神经网络对连续空间场进行参数化。在本文中，我们提出了\textbf{PICO}，这是一个基于INR的静态点云压缩框架。与主流的编码器-解码器范式不同，我们将点云压缩任务分解为两个单独的阶段：几何压缩和属性压缩，每个阶段都有不同的INR优化目标。受Kolmogorov-Arnold网络（KANs）的启发，我们引入了一种新的网络架构\textbf{LeAFNet}，它利用潜在空间中的可学习激活函数来更好地近似目标信号的隐函数。通过将点云压缩重新表述为神经参数压缩，我们通过量化和熵编码进一步提高了压缩效率。实验结果表明，\textbf{LeAFNet}在基于INR的点云压缩中优于传统的MLP。此外，与当前的MPEG点云压缩标准相比，\textbf{PICO}实现了卓越的几何压缩性能，D1 PSNR平均提高了4.92 $dB。在联合几何和属性压缩方面，我们的方法表现出了极具竞争力的结果，平均PCQM增益为2.7美元乘以10^{-3}$ 。 et.al.|[2504.14471](http://arxiv.org/abs/2504.14471)|null|
|**2025-04-17**|**Radial Basis Function Techniques for Neural Field Models on Surfaces**|我们提出了一种使用径向基函数（RBF）插值和求积求解曲面上神经场方程的数值框架。神经场模型描述了宏观大脑活动的演变，但建模研究往往忽视了弯曲皮质区域的复杂几何形状。传统的数值方法，如有限元或谱方法，在计算上可能很昂贵，并且在不规则域上实现具有挑战性。相比之下，基于RBF的方法提供了一种灵活的替代方案，通过提供插值和正交方案，以高阶精度有效地处理任意几何形状。我们首先为一般曲面上的神经场模型开发了一个基于RBF的插值投影框架。详细推导了平面和曲面域的求积法，确保了高阶精度和稳定性，因为它们取决于RBF超参数（基函数、增广多项式和模板大小）。通过数值实验，我们证明了我们的方法的收敛性，突出了它在灵活性和准确性方面优于传统方法。最后，我们阐述了复杂表面上时空活动的数值模拟，说明了该方法捕捉复杂波传播模式的能力。 et.al.|[2504.13379](http://arxiv.org/abs/2504.13379)|null|

<p align=right>(<a href=#updated-on-20250515>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

