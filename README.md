[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.10.07
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-03**|**Flash-Splat: 3D Reflection Removal with Flash Cues and Gaussian Splats**|我们介绍了一种简单而有效的分离透射光和反射光的方法。我们的关键见解是，现代逆渲染方法（例如，~3D高斯散点）提供的强大的新颖视图合成功能允许人们使用不成对的测量值进行闪光/无闪光反射分离——这种松弛大大简化了传统成对闪光/无闪光反射分离方法的图像采集。通过广泛的现实世界实验，我们展示了我们的方法Flash Splat，可以准确地重建3D中的透射和反射场景。我们的方法在很大程度上优于不利用照明控制的现有3D反射分离方法。我们的项目网页位于https://flash-splat.github.io/. et.al.|[2410.02764](http://arxiv.org/abs/2410.02764)|null|
|**2024-10-03**|**GI-GS: Global Illumination Decomposition on Gaussian Splatting for Inverse Rendering**|我们提出了GI-GS，这是一种新颖的逆渲染框架，它利用3D高斯散斑（3DGS）和延迟着色来实现照片级逼真的新颖视图合成和重新照明。在逆渲染中，精确建模对象的着色过程对于实现高保真结果至关重要。因此，至关重要的是结合全局照明来考虑在场景中多次反弹后到达对象的间接照明。以前基于3DGS的方法试图通过将间接照明表征为可学习的照明体积或每个高斯的附加属性来模拟间接照明，同时使用烘焙遮挡来表示阴影效果。然而，这些方法无法准确模拟光和物体之间复杂的物理相互作用，使得在重新照明过程中无法构建逼真的间接照明。为了解决这一局限性，我们建议使用具有延迟着色的有效路径跟踪来计算间接照明。在我们的框架中，我们首先渲染一个G缓冲区，以捕获场景的详细几何体和材质属性。然后，我们仅对直接照明执行基于物理的渲染（PBR）。使用G缓冲区和之前的渲染结果，可以通过轻量级路径跟踪计算间接照明。我们的方法有效地模拟了任何给定照明条件下的间接照明，从而实现了更好的新颖视图合成和重新照明。定量和定性结果表明，我们的GI-GS在渲染质量和效率方面都优于现有的基线。 et.al.|[2410.02619](http://arxiv.org/abs/2410.02619)|null|
|**2024-10-03**|**SuperGS: Super-Resolution 3D Gaussian Splatting via Latent Feature Field and Gradient-guided Splitting**|最近，3D高斯散斑（3DGS）以其实时渲染能力和卓越的质量在新颖的视图合成中脱颖而出。然而，由于从低分辨率输入视图导出的基元的粗糙性质，它面临着高分辨率新视图合成（HRNVS）的挑战。为了解决这个问题，我们提出了超分辨率3DGS（SuperGS），它是3DGS的扩展，采用两阶段粗到细的训练框架设计，利用预训练的低分辨率场景表示作为超分辨率优化的初始化。此外，我们引入了多分辨率特征高斯散斑（MFGS），以结合潜在特征场进行灵活的特征采样，并引入梯度引导的选择性分裂（GSS）进行有效的高斯上采样。通过将这些策略整合到从粗到细的框架中，可以确保高保真度和内存效率。大量实验表明，SuperGS在仅使用低分辨率输入挑战现实世界数据集方面超越了最先进的HRNVS方法。 et.al.|[2410.02571](http://arxiv.org/abs/2410.02571)|null|
|**2024-10-02**|**MVGS: Multi-view-regulated Gaussian Splatting for Novel View Synthesis**|最近在体绘制方面的工作，例如NeRF和3D高斯散点（3DGS），在学习到的隐式神经辐射场或3D高斯分布的帮助下，显著提高了渲染质量和效率。在显式表示的基础上进行渲染，vanilla 3DGS及其变体通过在训练过程中每次迭代都进行单视图监督来优化参数模型，从而提供实时效率。因此，某些视图被过度拟合，导致新颖的视图合成和不精确的3D几何中的外观不令人满意。为了解决上述问题，我们提出了一种新的3DGS优化方法，该方法体现了四个关键的新贡献：1）我们将传统的单视图训练范式转变为多视图训练策略。通过我们提出的多视图调节，3D高斯属性得到了进一步优化，而不会过拟合某些训练视图。作为通用解决方案，我们提高了各种场景和不同高斯变体的整体精度。2） 受其他观点带来的好处的启发，我们进一步提出了一种跨内在指导方案，从而针对不同分辨率进行了从粗到细的训练过程。3） 基于我们的多视图调节训练，我们进一步提出了一种交叉射线致密化策略，从一系列视图中在射线交叉区域致密化更多的高斯核。4） 通过进一步研究致密化策略，我们发现当某些观点明显不同时，致密化的效果应该得到增强。作为一种解决方案，我们提出了一种新的多视图增强致密化策略，其中鼓励3D高斯模型相应地被致密化到足够的数量，从而提高了重建精度。 et.al.|[2410.02103](http://arxiv.org/abs/2410.02103)|null|
|**2024-10-03**|**EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis**|我们提出了精确体积椭球体渲染（EVER），这是一种用于实时可微发射的纯体积渲染的方法。与最近3D高斯散斑（3DGS）的基于光栅化的方法不同，我们的基于基元的表示允许精确的体积渲染，而不是阿尔法合成3D高斯广告牌。因此，与3DGS不同，我们的公式不会受到爆裂伪影和视图依赖密度的影响，但仍然实现了$\sim\！在NVIDIA RTX4090上，720p分辨率下的帧率为30美元。由于我们的方法是建立在光线追踪的基础上的，因此它能够实现散焦模糊和相机失真（例如鱼眼相机）等效果，而这些效果很难通过光栅化来实现。我们证明，我们的方法比3DGS更准确，混合问题更少，并且在视图一致性渲染方面进行了后续工作，特别是在Zip-NeRF数据集中具有挑战性的大规模场景上，它在实时技术中取得了最清晰的结果。 et.al.|[2410.01804](http://arxiv.org/abs/2410.01804)|null|
|**2024-10-02**|**3DGS-DET: Empower 3D Gaussian Splatting with Boundary Guidance and Box-Focused Sampling for 3D Object Detection**|神经辐射场（NeRF）被广泛用于新颖的视图合成，并已被应用于3D对象检测（3DOD），通过视图合成表示为3DOD提供了一种有前景的方法。然而，NeRF面临着固有的局限性：（i）由于其隐式特性，3DOD的表示能力有限，以及（ii）渲染速度较慢。最近，3D高斯散斑（3DGS）已经成为解决这些局限性的显式3D表示。受这些优点的启发，本文首次将3DGS引入3DOD，确定了两个主要挑战：（i）高斯斑点的模糊空间分布：3DGS主要依赖于2D像素级监督，导致高斯斑点的3D空间分布不清楚，对象和背景之间的区分差，阻碍了3DOD；（ii）背景斑点过多：2D图像通常包含大量背景像素，导致重建的3DGS密度很高，其中许多噪声高斯斑点代表背景，对检测产生负面影响。为了应对挑战（i），我们利用3DGS重建来自2D图像的事实，并通过结合2D边界引导来显著增强高斯斑点的空间分布，从而更清晰地区分物体及其背景，提出了一种优雅高效的解决方案。为了应对挑战（ii），我们提出了一种使用2D框在3D空间中生成对象概率分布的框聚焦采样策略，允许在3D中进行有效的概率采样，以保留更多的对象斑点并减少噪声背景斑点。得益于我们的设计，我们的3DGS-DET明显优于基于SOTA NeRF的方法NeRF-DET，在mAP@0.25+8.1开始mAP@0.5ScanNet数据集，令人印象深刻的+31.5mAP@0.25ARKITCenes数据集。 et.al.|[2410.01647](http://arxiv.org/abs/2410.01647)|**[link](https://github.com/yangcaoai/3dgs-det)**|
|**2024-10-02**|**Gaussian Splatting in Mirrors: Reflection-Aware Rendering via Virtual Camera Optimization**|3D高斯散斑（3D-GS）的最新进展彻底改变了新的视图合成，促进了实时、高质量的图像渲染。然而，在涉及反射表面（特别是镜子）的场景中，3D-GS经常将反射误解为虚拟空间，导致镜子内的多视图渲染模糊和不一致。我们提出了一种新方法，旨在通过将反射建模为基于物理的虚拟相机来获得高质量的多视图一致反射渲染。我们使用3D-GS的深度和法线估计来估计镜面，并定义围绕镜面对称放置的虚拟相机。然后，这些虚拟相机用于解释场景中的镜面反射。为了解决镜面估计中的缺陷，我们提出了一种简单而有效的虚拟相机优化方法来提高反射质量。我们收集了一个新的镜像数据集，其中包括三个真实世界的场景，以进行更多样化的评估。Mirror-Nerf和我们的真实世界数据集上的实验验证证明了我们方法的有效性。与之前的最先进技术相比，我们在显著减少训练时间的同时，取得了相当或更优的结果。 et.al.|[2410.01614](http://arxiv.org/abs/2410.01614)|null|
|**2024-10-02**|**EVA-Gaussian: 3D Gaussian-based Real-time Human Novel View Synthesis under Diverse Camera Settings**|基于前馈的3D高斯散点方法在实时人类新颖视图合成方面表现出了卓越的能力。然而，现有的方法仅限于密集的视点设置，这限制了它们在各种相机视角差异的自由视点渲染中的灵活性。为了解决这一局限性，我们提出了一种名为EVA-Gassian的实时流水线，用于跨不同相机设置的3D人体新颖视图合成。具体来说，我们首先引入了一个高效的交叉视图注意力（EVA）模块，以准确估计源图像中每个3D高斯的位置。然后，我们将源图像与估计的高斯位置图进行整合，以预测3D高斯图像的属性和特征嵌入。此外，我们采用循环特征细化器来校正位置估计中由几何误差引起的伪影，并提高视觉保真度。为了进一步提高合成质量，我们为3D高斯属性和人脸地标引入了强大的锚丢失函数。THuman2.0和THumansit数据集的实验结果展示了我们的EVA高斯方法在不同相机设置下的渲染质量方面的优越性。项目页面：https://zhenliuzju.github.io/huyingdong/EVA-Gaussian. et.al.|[2410.01425](http://arxiv.org/abs/2410.01425)|null|
|**2024-10-02**|**AniSDF: Fused-Granularity Neural Surfaces with Anisotropic Encoding for High-Fidelity 3D Reconstruction**|神经辐射场最近彻底改变了新颖的视图合成，并实现了高保真渲染。然而，这些方法为了渲染质量而牺牲了几何体，限制了它们的进一步应用，包括重新照明和变形。如何在重建精确几何的同时合成照片级真实感渲染仍然是一个未解决的问题。在这项工作中，我们提出了AniSDF，这是一种新的方法，通过基于物理的编码来学习融合粒度的神经表面，以实现高保真度的3D重建。与之前的神经曲面不同，我们的融合粒度几何结构平衡了整体结构和精细的几何细节，产生了精确的几何重建。为了将几何体与反射外观区分开来，我们引入了混合辐射场，按照各向异性球面高斯编码（一种基于物理的渲染管道）对漫反射和镜面反射进行建模。通过这些设计，AniSDF可以重建具有复杂结构的对象，并生成高质量的渲染图。此外，我们的方法是一个统一的模型，不需要对特定对象进行复杂的超参数调整。大量实验表明，我们的方法在几何重建和新颖的视图合成方面都大大提高了基于SDF的方法的质量。 et.al.|[2410.01202](http://arxiv.org/abs/2410.01202)|null|
|**2024-10-01**|**GMT: Enhancing Generalizable Neural Rendering via Geometry-Driven Multi-Reference Texture Transfer**|新视图合成（NVS）旨在使用多视图图像在任意视点生成图像，神经辐射场（NeRF）的最新见解为显著改进做出了贡献。最近，对可推广NeRF（G-NeRF）的研究解决了NeRF中每场景优化的挑战。G-NeRF中动态构建辐射场简化了NVS过程，使其非常适合实际应用。同时，由于缺乏每个场景的优化，即使使用纹理丰富的多视图源输入，G-NeRF仍然难以表示特定场景的精细细节。作为补救措施，我们提出了一种几何驱动的多参考纹理传输网络（GMT），作为专为G-NeRF设计的即插即用模块。具体来说，我们提出了光线施加的可变形卷积（RayDCN），它对齐反映场景几何的输入和参考特征。此外，所提出的纹理保持变换器（TP Former）在保留纹理信息的同时聚合了多视图源特征。因此，我们的模块能够在图像增强过程中实现相邻像素之间的直接交互，这在每个像素具有独立渲染过程的G-NeRF模型中是不足的。这解决了阻碍捕获高频细节的限制。实验表明，我们的即插即用模块在各种基准数据集上持续改进了G-NeRF模型。 et.al.|[2410.00672](http://arxiv.org/abs/2410.00672)|**[link](https://github.com/yh-yoon/gmt)**|

<p align=right>(<a href=#updated-on-20241007>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-04**|**Img2CAD: Conditioned 3D CAD Model Generation from Single Image with Structured Visual Geometry**|在本文中，我们提出了Img2CAD，这是我们所知的第一种方法，它使用2D图像输入来生成具有可编辑参数的CAD模型。与现有的使用文本或图像输入生成3D模型的AI方法不同，Img2CAD通常依赖于基于网格的表示，这与CAD工具不兼容，缺乏可编辑性和精细控制性，Img2AD实现了基于AI的3D重建和CAD软件之间的无缝集成。我们已经确定了一种名为结构化视觉几何（SVG）的创新中间表示，其特征是从对象中提取的矢量化线框。这种表示法显著提高了生成条件CAD模型的性能。此外，我们引入了两个新的数据集来进一步支持这一领域的研究：ABC mono，这是已知最大的数据集，包含超过200000个带有渲染图像的3D CAD模型，以及KOCAD，这是第一个包含真实世界捕获对象及其地面真实CAD模型的数据集。 et.al.|[2410.03417](http://arxiv.org/abs/2410.03417)|null|
|**2024-10-04**|**3D Segmentation of Neuronal Nuclei and Cell-Type Identification using Multi-channel Information**|背景使用自动方法分析图像以准确估计大脑中不同细胞类型的数量是神经科学的主要目标。神经元的自动和选择性检测和分割将是神经解剖学研究的重要一步。新方法我们提出了一种改进神经元核3D重建的方法，该方法允许对神经元核进行分割，不包括非神经元细胞类型的核。结果我们在一个复杂的场景中（大量图像、不均匀染色和三个不同的通道来可视化不同的细胞标记），在大鼠新皮层的图像堆栈上测试了该算法。它能够提供良好的神经元核识别率和3D分割。与现有方法的比较：事实上，目前有许多自动工具可用，但由于标记和成像技术以及用于检测细胞的算法的差异，即使在相同的大脑区域，不同的方法也会产生不同的细胞计数估计。此外，一些可用的自动化软件方法提供了细胞数量的估计，据报道，在神经解剖学家评估后，这些估计是不准确或不一致的。结论：拥有一个能够区分神经元、神经胶质细胞和血管周围细胞的自动分割工具至关重要。这将大大加快目前手动执行的任务，并使细胞计数系统化，避免人为偏见。此外，不同细胞类型的3D重建结果可用于生成细胞空间分布的模型。 et.al.|[2410.03248](http://arxiv.org/abs/2410.03248)|null|
|**2024-10-02**|**Learning from the Giants: A Practical Approach to Underwater Depth and Surface Normals Estimation**|单目深度和表面法线估计（MDSNE）对于3D重建、自主导航和水下勘探等任务至关重要。当前的方法要么依赖于与透明或反射表面斗争的判别模型，要么依赖于生成模型，尽管生成模型准确，但计算成本很高。本文提出了一种新的MDSNE深度学习模型，该模型专门针对水下环境量身定制，使用了一种混合架构，将卷积神经网络（CNN）与Transformers集成在一起，利用了这两种方法的优势。训练有效的MDSNE模型往往受到现实世界数据集噪声和合成数据集泛化能力有限的阻碍。为了解决这个问题，我们使用多个预训练的MDSNE模型生成伪标记的真实数据。为了确保这些数据的质量，我们提出了深度法线评估和选择算法（DNESA），该算法使用领域特定的度量来评估和选择最可靠的伪标记样本。然后，在这个精心策划的数据集上训练一个轻量级的学生模型。我们的模型将参数减少了90%，训练成本减少了80%，允许在资源受限的设备上进行实时3D感知。主要贡献包括：一种新颖高效的MDSNE模型、DNESA算法、特定领域的数据管道，以及对实时性能和可扩展性的关注。我们的模型专为现实世界的水下应用而设计，便于在水下机器人和自动驾驶车辆中进行低成本部署，弥合了研究与实际实施之间的差距。 et.al.|[2410.02072](http://arxiv.org/abs/2410.02072)|null|
|**2024-10-02**|**Enhancing Screen Time Identification in Children with a Multi-View Vision Language Model and Screen Time Tracker**|能够准确监测幼儿的屏幕暴露对于研究与屏幕使用相关的现象（如儿童肥胖、体育活动和社会互动）非常重要。大多数现有的研究都依赖于笨重的可穿戴传感器的自我报告或手动测量，因此在捕获定量屏幕曝光数据方面缺乏效率和准确性。在这项工作中，我们开发了一种新的传感器信息学框架，该框架利用了来自可穿戴传感器（称为屏幕时间跟踪器（STT））的以自我为中心的图像和视觉语言模型（VLM）。特别是，我们设计了一种多视图VLM，它从以自我为中心的图像序列中获取多个视图，并动态解释屏幕曝光。我们通过使用儿童自由生活活动的数据集验证了我们的方法，证明了其在普通视觉语言模型和对象检测模型方面比现有方法的显著改进。结果支持了这种监测方法的前景，它可以优化儿童自然环境中屏幕暴露的行为研究。 et.al.|[2410.01966](http://arxiv.org/abs/2410.01966)|null|
|**2024-10-02**|**GaussianBlock: Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians**|近年来，随着神经辐射场和高斯散斑技术的发展，三维重建技术已经达到了非常高的保真度。然而，通过这些方法学习的潜在表征是高度纠缠的，缺乏可解释性。在这篇论文中，我们提出了一种新的部分感知组合重建方法，称为GaussianBlock，它能够实现语义连贯和解纠缠的表示，允许类似于构建块的精确和物理编辑，同时保持高保真度。我们的GaussianBlock引入了一种混合表示法，该表示法利用了以灵活的可操作性和可编辑性而闻名的基元和在重建质量方面表现出色的3D Gaussian的优点。具体来说，我们通过一种新的注意力引导的中心丢失来实现语义连贯的原语，该丢失来自2D语义先验，并辅以动态分割和融合策略。此外，我们利用与基元杂交的3D高斯分布来细化结构细节并提高保真度。此外，采用绑定继承策略来加强和维护两者之间的连接。事实证明，我们重建的场景在不同的基准测试中表现出了解纠缠、构图和紧凑的特点，实现了无缝、直接和精确的编辑，同时保持了高质量。 et.al.|[2410.01535](http://arxiv.org/abs/2410.01535)|null|
|**2024-10-03**|**SurgPointTransformer: Vertebrae Shape Completion with RGB-D Data**|最先进的计算机和机器人辅助手术系统在很大程度上依赖于CT和荧光透视等术中成像技术来生成患者解剖结构的详细3D可视化。虽然成像技术非常准确，但它们基于电离辐射，使患者和临床医生暴露在外。本研究介绍了一种使用RGB-D数据重建3D脊柱解剖结构的无辐射替代方法。从外科医生在手术过程中形成的3D“心理图”中汲取灵感，我们介绍了SurgPointTransformer，这是一种用于手术应用的形状完成方法，可以从暴露表面的稀疏观察中准确重建未暴露的脊柱区域。我们的方法包括两个主要步骤：分割和形状完成。分割步骤包括脊柱定位和分割，然后是脊椎分割。然后，对分割的脊椎点云进行SurgPointTransformer处理，该处理利用注意力机制来学习可见表面特征和底层解剖结构之间的模式。为了进行评估，我们使用了九个样本的离体数据集。他们的CT数据用于建立地面实况数据，这些数据用于与我们的方法的输出进行比较。我们的方法明显优于最先进的基线，平均倒角距离为5.39，F分数为0.85，地球移动器距离为0.011，信噪比为22.90 dB。这项研究展示了我们的重建方法在3D椎体形状完成方面的潜力。它能够在没有电离辐射或侵入性成像的情况下对整个腰椎进行3D重建和手术指导。我们的工作有助于计算机辅助和机器人辅助手术，提高这些系统的感知和智能。 et.al.|[2410.01443](http://arxiv.org/abs/2410.01443)|null|
|**2024-10-02**|**AniSDF: Fused-Granularity Neural Surfaces with Anisotropic Encoding for High-Fidelity 3D Reconstruction**|神经辐射场最近彻底改变了新颖的视图合成，并实现了高保真渲染。然而，这些方法为了渲染质量而牺牲了几何体，限制了它们的进一步应用，包括重新照明和变形。如何在重建精确几何的同时合成照片级真实感渲染仍然是一个未解决的问题。在这项工作中，我们提出了AniSDF，这是一种新的方法，通过基于物理的编码来学习融合粒度的神经表面，以实现高保真度的3D重建。与之前的神经曲面不同，我们的融合粒度几何结构平衡了整体结构和精细的几何细节，产生了精确的几何重建。为了将几何体与反射外观区分开来，我们引入了混合辐射场，按照各向异性球面高斯编码（一种基于物理的渲染管道）对漫反射和镜面反射进行建模。通过这些设计，AniSDF可以重建具有复杂结构的对象，并生成高质量的渲染图。此外，我们的方法是一个统一的模型，不需要对特定对象进行复杂的超参数调整。大量实验表明，我们的方法在几何重建和新颖的视图合成方面都大大提高了基于SDF的方法的质量。 et.al.|[2410.01202](http://arxiv.org/abs/2410.01202)|null|
|**2024-10-02**|**Flex3D: Feed-Forward 3D Generation With Flexible Reconstruction Model And Input View Curation**|从文本、单幅图像或稀疏视图图像生成高质量的3D内容仍然是一项具有广泛应用的具有挑战性的任务。现有的方法通常采用多视图扩散模型来合成多视图图像，然后进行前馈过程进行3D重建。然而，这些方法往往受到少量固定数量的输入视图的限制，限制了它们捕获不同观点的能力，更糟糕的是，如果合成视图的质量较差，则会导致次优的生成结果。为了解决这些局限性，我们提出了Flex3D，这是一种新颖的两阶段框架，能够利用任意数量的高质量输入视图。第一阶段包括候选视图生成和管理管道。我们采用微调的多视图图像扩散模型和视频扩散模型来生成候选视图池，从而能够丰富地表示目标3D对象。随后，视图选择管道根据质量和一致性过滤这些视图，确保只有高质量和可靠的视图用于重建。在第二阶段，将策划的视图输入到灵活重建模型（FlexRM）中，该模型基于可以有效处理任意数量输入的变压器架构。FlemRM利用三平面表示直接输出3D高斯点，实现高效和详细的3D生成。通过对设计和培训策略的广泛探索，我们优化了FlexRM，以在重建和生成任务中实现卓越的性能。我们的结果表明，Flex3D实现了最先进的性能，与几种最新的前馈3D生成模型相比，在3D生成任务中的用户研究获胜率超过92%。 et.al.|[2410.00890](http://arxiv.org/abs/2410.00890)|null|
|**2024-10-01**|**A Low-Cost, High-Speed, and Robust Bin Picking System for Factory Automation Enabled by a Non-Stop, Multi-View, and Active Vision Scheme**|工厂自动化中的拣选系统通常面临由金属物体的稀疏和嘈杂的3D数据引起的鲁棒性问题。利用多个视图，特别是使用单次3D传感器和“手头传感器”配置，由于其有效性、灵活性和低成本而越来越受欢迎。在移动3D传感器以获取多个视图进行3D融合、关节优化或主动视觉时，会遇到低速问题。这是因为传感被视为一个与运动任务解耦的模块，而不是专门为垃圾箱拣选系统设计的。为了解决这些问题，我们设计了一个垃圾箱拣选系统，该系统将多视图、主动视觉方案与“手头传感器”配置中的运动任务紧密结合。它不仅通过将高速传感方案与机器人的位置动作并行化来加速系统，而且还决定了下一个传感路径，以保持整个拾取过程的连续性。与其他只关注传感评估的人不同，我们还通过在5种不同类型的物体上进行实验来评估我们的设计，而不需要人为干预。我们的实验表明，整个传感方案在CPU上可以在1.682秒内（最大）完成，平均拾取完成率超过97.75%。由于与机器人运动的并行化，传感方案的平均节拍时间仅为0.635秒。 et.al.|[2410.00706](http://arxiv.org/abs/2410.00706)|null|
|**2024-10-01**|**An Illumination-Robust Feature Extractor Augmented by Relightable 3D Reconstruction**|视觉特征的描述通常依赖于局部强度和梯度方向，近年来在机器人导航和定位中得到了广泛的应用。然而，视觉特征的提取通常会受到光照条件变化的干扰，这使得它在现实世界的应用中具有挑战性。以前的工作已经通过建立具有光照条件变化的数据集来解决这个问题，但可能成本高昂且耗时。本文提出了一种光照鲁棒特征提取器的设计过程，其中采用了最近开发的可重新照亮的3D重建技术，在不同的光照条件下快速直接地生成数据。提出了一种自监督框架，用于提取特征，该框架在关键点的可重复性和描述符在良好和不良光照条件下的相似性方面具有优势。实验证明了所提出的鲁棒特征提取方法的有效性。消融研究也表明了自我监督框架设计的有效性。 et.al.|[2410.00629](http://arxiv.org/abs/2410.00629)|null|

<p align=right>(<a href=#updated-on-20241007>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-04**|**Estimating Body and Hand Motion in an Ego-sensed World**|我们介绍了EgoAlo，这是一个从头戴式设备进行人体运动估计的系统。EgoAlo仅使用以自我为中心的SLAM姿势和图像，引导从条件扩散模型中采样，以估计3D身体姿势、高度和手部参数，这些参数在场景的非中心坐标系中捕捉佩戴者的动作。为了实现这一点，我们的关键见解在于表示：我们提出了提高模型性能的空间和时间不变性标准，从中我们推导出了一个头部运动调节参数化，将估计提高了18%。我们还展示了我们的系统估计的物体如何改善手部：与有噪声的单目估计相比，由此产生的运动学和时间约束使手部估计误差降低了40%以上。项目页面：https://egoallo.github.io/ et.al.|[2410.03665](http://arxiv.org/abs/2410.03665)|null|
|**2024-10-04**|**Connecting Lyman- $α$ and ionizing photon escape in the Sunburst Arc**|我们研究了日爆弧的Lyman-$\alpha$（Ly$\alpha$）和Lyman连续体（LyC）特性，日爆弧是一个z=2.37$的引力透镜星系，具有多重成像、紧凑区域泄漏的LyC和三峰Ly$\alpha$$轮廓，表明Ly$\阿尔法$直接逃逸。非LyC泄漏区域显示红移Ly$\alpha$峰值、红移和中心Ly$\alpha$峰值或三峰Ly$\阿尔法$曲线。我们使用$R\sim5000$Magellan/MagE光谱测量了星系不同区域的Ly$\alpha$轮廓的特性。我们将Ly$\alpha$光谱特性与LyC和哈勃太空望远镜（HST）成像的窄带Ly$\alpha$图进行了比较，以探索亚星系Ly$\阿尔法-$LyC连接。我们发现LyC逃逸分数（$f_{\rm esc}^{\rm LyC}$）和Ly$\alpha$之间存在很强的相关性（Pearson相关系数$r>0.6$）：（1）峰间距$v_{\rm{sep}}$，（2）红移和蓝移Ly$\alpha$峰之间的最小通量密度与连续通量密度$f_{rm{min}/f_{rm{cont}$的比值，以及（3）等效宽度。我们倾向于使用复杂的{H}{1}几何来解释非LyC泄漏区域的Ly$\alpha$轮廓，并提出了两种{H}{1}几何，它们可以将Ly$\alpha$峰值从LyC泄漏区扩散和/或重新散射到我们的视线中，跨越数百秒差距的横向距离。我们的结果强调了Ly$α$辐射传输的复杂性及其对亚星系尺度上离子{H}{1}气体各向异性的敏感性。我们观察到空间可变直接逃逸Ly$\alpha$、蓝移Ly$\alpha$和日爆弧中逃逸LyC光子的物理尺度存在很大差异，这突显了解决控制Ly$\阿尔法$ 和LyC逃逸的物理尺度的重要性。 et.al.|[2410.03660](http://arxiv.org/abs/2410.03660)|null|
|**2024-10-04**|**Geometric Representation Condition Improves Equivariant Molecule Generation**|分子生成模型的最新进展在加速科学发现方面显示出巨大的潜力，特别是在药物设计方面。然而，这些模型在生成高质量分子方面经常面临挑战，特别是在必须满足特定分子特性的条件下。在这项工作中，我们介绍了GeoRCG，这是一个通过整合几何表示条件来提高分子生成模型性能的通用框架。我们将分子生成过程分解为两个阶段：第一，生成信息丰富的几何表示；第二，生成以该表示为条件的分子。与直接生成分子相比，第一阶段相对容易生成的表示引导第二阶段生成以更面向目标和更快的方式达到高质量的分子。利用EDM作为基础生成器，我们观察到在广泛使用的QM9和GEOM-DRUG数据集上无条件分子生成的质量有了显著提高。更值得注意的是，在具有挑战性的条件分子生成任务中，我们的框架比最先进的方法平均提高了31%的性能，突显了对语义丰富的几何表示进行条件化的优越性，而不是像以前的方法那样对单个属性值进行条件化。此外，我们表明，通过这种表示指导，扩散步骤的数量可以减少到100个，同时保持比1000个步骤更高的生成质量，从而显著加速生成过程。 et.al.|[2410.03655](http://arxiv.org/abs/2410.03655)|null|
|**2024-10-04**|**Real-World Benchmarks Make Membership Inference Attacks Fail on Diffusion Models**|对扩散模型的成员推断攻击（MIA）已成为训练预训练扩散模型时未经授权使用数据的潜在证据。这些攻击旨在检测扩散模型训练数据集中特定图像的存在。我们的研究深入研究了扩散模型上最先进的MIA的评估，揭示了现有MIA评估中的关键缺陷和过于乐观的性能估计。我们介绍CopyMark，这是一个更现实的MIA基准，通过支持预训练的扩散模型、无偏数据集和公平的评估管道而脱颖而出。通过广泛的实验，我们证明，在这些更实际的条件下，当前MIA方法的有效性会显著降低。根据我们的研究结果，我们警告说，在目前的状态下，MIA不是识别预训练扩散模型中未经授权数据使用的可靠方法。据我们所知，我们是第一个发现扩散模型上MIA性能高估的人，并为更现实的评估提供了一个统一的基准。我们的代码可以在GitHub上找到：\url{https://github.com/caradryanl/CopyMark}. et.al.|[2410.03640](http://arxiv.org/abs/2410.03640)|**[link](https://github.com/caradryanl/copymark)**|
|**2024-10-04**|**Stabilizing the Consistent Quasidiffusion Method with Linear Prolongation**|准扩散（QD）方法，在天体物理学界也称为可变爱丁顿因子（VEF）方法，是一种已建立的迭代方法，用于加速SN计算中的源迭代。QD方法的一大优点是，加速SN源迭代的扩散方程可以在任何有效的离散化中离散化，而不必考虑与输运离散化的一致性。量子点与扩散合成加速（DSA）具有相当的有效性，但扩散方程的收敛标量通量将因空间截断误差而与输运解不同。Larsen等人介绍了一种新的一致QD方法（CQD），该方法包括一个与众所周知的粗网格有限差分（CMFD）和扩散合成加速（DSA）方法密切相关的直接定义的输运一致性因子。CQD方法保留了SN方程的离散标量通量解，对于光学薄空间单元的问题是稳定的，但就像非线性扩散加速（NDA）一样，当空间单元变得大于约一个平均自由程厚度时，它的性能会下降并最终变得不稳定。本文对CQD方法进行了形式化傅里叶分析，表明其理论光谱半径与NDA方法基本相同。为了提高CQD的稳定性，我们引入了lpCQD方法，该方法采用了线性延拓CMFD（lpCMFD）方法的思想。 et.al.|[2410.03605](http://arxiv.org/abs/2410.03605)|null|
|**2024-10-04**|**How Discrete and Continuous Diffusion Meet: Comprehensive Analysis of Discrete Diffusion Models via a Stochastic Integral Framework**|离散扩散模型因其能够通过易于处理的采样和推理对复杂分布进行建模而受到越来越多的关注。然而，离散扩散模型的误差分析仍然不太清楚。在这项工作中，我们提出了一个基于L’evy型随机积分的离散扩散模型误差分析的综合框架。通过将泊松随机测度推广为具有时间无关和状态相关强度的随机测度，我们严格建立了离散扩散模型的随机积分公式，并提供了相应的测度变化定理，这些定理与Ito积分和Girsanov定理的连续对应物有着有趣的相似性。我们的框架统一并加强了离散扩散模型的当前理论结果，并获得了KL散度中 $\tau$ 跳跃方案的第一个误差界。随着误差源的明确识别，我们的分析为离散扩散模型的数学性质提供了新的见解，并为现实世界离散扩散模型应用的高效准确算法的设计提供了指导。 et.al.|[2410.03601](http://arxiv.org/abs/2410.03601)|null|
|**2024-10-04**|**Free boundary problem governed by a non-linear diffusion-convection equation with Neumann condition**|我们考虑了一个由非线性扩散-对流方程控制的一维自由边界问题，该方程在固定面 $x=0$ 处具有Neumann条件，该条件在时间上是可变的，并且在自由边界上具有类似Stefan的对流条件。通过连续变换，得到了一个包含耦合非线性积分方程组的问题的积分表示。利用不动点定理，得到了解的存在性。 et.al.|[2410.03564](http://arxiv.org/abs/2410.03564)|null|
|**2024-10-04**|**Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features**|扩散模型最初是为图像生成而设计的。最近的研究表明，它们主干内的内部信号，即激活，也可以作为各种区分任务的密集特征，如语义分割。考虑到大量的激活，选择一个小而有效的子集是一个基本问题。为此，该领域的早期研究对激活的判别能力进行了大规模的定量比较。然而，我们发现许多潜在的激活尚未得到评估，例如用于计算注意力得分的查询和按键。此外，扩散架构的最新进展带来了许多新的激活，例如嵌入式ViT模块中的激活。两者结合，激活选择仍未解决，但被忽视了。为了解决这个问题，本文进一步评估了更广泛的激活范围。考虑到激活的显著增加，全面的定量比较已不再适用。相反，我们试图了解这些激活的性质，以便通过简单的定性评估提前过滤掉明显较差的激活。经过仔细分析，我们发现了扩散模型中普遍存在的三个性质，使本研究能够超越特定模型。除此之外，我们还为几种流行的扩散模型提供了有效的特征选择解决方案。最后，在多个判别任务上的实验验证了我们的方法优于SOTA竞争对手。我们的代码可在https://github.com/Darkbblue/generic-diffusion-feature. et.al.|[2410.03558](http://arxiv.org/abs/2410.03558)|**[link](https://github.com/darkbblue/generic-diffusion-feature)**|
|**2024-10-04**|**Seizure freedom after surgical resection of diffusion-weighted MRI abnormalities**|重要性：许多耐药性癫痫患者在切除手术后继续癫痫发作。准确识别局灶性脑异常对于成功的神经外科干预至关重要。目前用于识别癫痫手术靶向结构异常的临床方法不使用弥散加权MRI（dMRI），尽管有证据表明dMRI异常存在于癫痫中，可能与致痫区有关。目的：探讨手术切除弥散异常是否与术后癫痫发作自由度有关。设计：这项回顾性病例对照研究是在2009年至2022年间进行的。数据是在英国国家神经和神经外科医院获得的。研究参与者包括200名接受切除手术的耐药性局灶性癫痫患者和97名健康对照者，作为标准基线。主要结果：扩散异常簇和手术切除面罩之间的空间重叠，以及与术后结果的关系。结果：与最大异常簇重叠的手术切除与12个月（83%对55%；p<0.0001）和5年以上（p<0.00001）的持续癫痫发作自由度显著相关。值得注意的是，与未切除该簇的病例相比，仅切除最大簇的一小部分与更好的癫痫发作结果相关（p=0.008）。此外，与没有重叠相比，保留最大的簇但切除其他大簇仍然可以提高癫痫发作的自由率（p=0.03）。结论：我们的结果表明，使用dMRI识别的异常簇是致痫网络的组成部分，即使部分去除这种异常簇也足以实现癫痫发作自由。该研究强调了将dMRI纳入术前计划以改善局灶性癫痫预后的潜力。 et.al.|[2410.03548](http://arxiv.org/abs/2410.03548)|null|
|**2024-10-04**|**Generative Artificial Intelligence for Navigating Synthesizable Chemical Space**|我们介绍了SynFormer，这是一个生成建模框架，旨在有效地探索和导航可合成的化学空间。与传统的分子生成方法不同，我们为分子生成合成途径，以确保设计在合成上易于处理。通过整合可扩展的变压器架构和用于构建块选择的扩散模块，SynFormer在可合成分子设计方面超越了现有模型。我们证明了SynFormer在两个关键应用中的有效性：（1）局部化学空间探索，其中该模型生成参考分子的可合成类似物，以及（2）全球化学空间探索。此外，我们通过随着更多计算资源的可用而提高性能，展示了我们方法的可扩展性。随着我们的代码和训练模型的公开，我们希望SynFormer能够在药物发现和材料科学的应用中得到应用。 et.al.|[2410.03494](http://arxiv.org/abs/2410.03494)|**[link](https://github.com/wenhao-gao/synformer)**|

<p align=right>(<a href=#updated-on-20241007>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-09-30**|**DressRecon: Freeform 4D Human Reconstruction from Monocular Video**|我们提出了一种从单目视频中重建时间一致的人体模型的方法，重点是极其宽松的衣服或手持物体的交互。之前在人体重建方面的工作要么局限于没有物体交互的紧身衣服，要么需要校准的多视图捕捉或个性化的模板扫描，而大规模收集这些数据成本很高。我们对高质量但灵活的重建的关键见解是，将关于关节体形状的通用人类先验（从大规模训练数据中学习）与视频特定的关节“骨骼袋”变形（通过测试时间优化适合单个视频）仔细结合。我们通过学习一个神经隐式模型来实现这一点，该模型将身体和衣服的变形作为单独的运动模型层来解开。为了捕捉服装的微妙几何形状，我们在优化过程中利用了基于图像的先验，如人体姿势、表面法线和光流。由此产生的神经场可以提取到时间一致的网格中，或进一步优化为显式3D高斯分布，以实现高保真交互式渲染。在具有高度挑战性的服装变形和物体交互的数据集上，DressReston可以产生比现有技术更高保真的3D重建。项目页面：https://jefftan969.github.io/dressrecon/ et.al.|[2409.20563](http://arxiv.org/abs/2409.20563)|null|
|**2024-09-25**|**TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans**|我们介绍了一种新的框架，该框架从单眼视频中学习全身说话的人的动态神经辐射场（NeRF）。之前的工作只代表身体姿势或面部。然而，人类通过全身进行交流，结合身体姿势、手势和面部表情。在这项工作中，我们提出了TalkinNeRF，这是一个基于NeRF的统一网络，代表了整体4D人体运动。给定一个受试者的单眼视频，我们学习身体、面部和手的相应模块，这些模块结合在一起生成最终结果。为了捕捉复杂的手指关节，我们学习了手的额外变形场。我们的多身份表示能够同时训练多个科目，以及在完全看不见的姿势下进行强大的动画。只要输入一段短视频，它也可以推广到新的身份。我们展示了最先进的性能，用于为全身说话的人类制作动画，具有精细的手部发音和面部表情。 et.al.|[2409.16666](http://arxiv.org/abs/2409.16666)|null|
|**2024-09-24**|**Generative 3D Cardiac Shape Modelling for In-Silico Trials**|我们提出了一种深度学习方法，基于将形状表示为神经有符号距离场的零级集，对合成主动脉形状进行建模和生成，该方法受一系列可训练的嵌入向量的约束，并对每个形状的几何特征进行编码。通过使神经场在采样表面点上消失并强制其空间梯度具有单位范数，在从CT图像重建的主动脉根部网格数据集上训练网络。实证结果表明，我们的模型可以高保真地表示主动脉形状。此外，通过从学习到的嵌入向量中采样，我们可以生成类似于真实患者解剖结构的新形状，可用于计算机模拟试验。 et.al.|[2409.16058](http://arxiv.org/abs/2409.16058)|null|
|**2024-09-21**|**MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors**|由于缺乏几何指导和不完美的视图相关2D先验，从单眼图像中精确重建密集和语义注释的3D网格仍然是一项具有挑战性的任务。尽管我们已经见证了隐式神经场景表示的最新进展，能够简单地从多视图图像中进行精确的2D渲染，但很少有研究仅使用单眼先验来解决3D场景理解问题。在本文中，我们提出了MOSE，这是一种神经场语义重建方法，可以将推断的图像级噪声先验提升到3D，在3D和2D空间中产生精确的语义和几何。我们方法的关键动机是利用通用类不可知的分段掩码作为指导，在训练过程中促进渲染语义的局部一致性。在语义的帮助下，我们进一步将平滑正则化应用于无纹理区域，以获得更好的几何质量，从而实现几何和语义的互惠互利。在ScanNet数据集上的实验表明，我们的MOSE在3D语义分割、2D语义分割和3D表面重建任务的所有指标上都优于相关基线。 et.al.|[2409.14019](http://arxiv.org/abs/2409.14019)|null|
|**2024-09-17**|**SplatFields: Neural Gaussian Splats for Sparse 3D and 4D Reconstruction**|从多视图图像中数字化3D静态场景和4D动态事件长期以来一直是计算机视觉和图形学领域的一个挑战。最近，3D高斯散斑（3DGS）已经成为一种实用且可扩展的重建方法，由于其令人印象深刻的重建质量、实时渲染能力以及与广泛使用的可视化工具的兼容性而越来越受欢迎。然而，该方法需要大量的输入视图来实现高质量的场景重建，这引入了一个重大的实际瓶颈。在捕捉动态场景时，这一挑战尤为严峻，因为部署广泛的相机阵列的成本可能高得令人望而却步。在这项工作中，我们发现斑点特征缺乏空间自相关性是导致3DGS技术在稀疏重建环境中性能不佳的因素之一。为了解决这个问题，我们提出了一种优化策略，通过将splat特征建模为相应隐式神经场的输出，有效地正则化splat特征。这导致在各种场景中重建质量的一致提高。我们的方法有效地处理了静态和动态情况，这在不同设置和场景复杂性的广泛测试中得到了证明。 et.al.|[2409.11211](http://arxiv.org/abs/2409.11211)|null|
|**2024-10-02**|**Neural Fields for Adaptive Photoacoustic Computed Tomography**|光声计算机断层扫描（PACT）是一种具有广泛医学应用的非侵入性成像技术。传统的PACT图像重建算法受到组织中声速不均匀（SOS）引起的波前失真的影响，导致图像质量下降。考虑到这些影响可以提高图像质量，但测量SOS分布的实验成本很高。另一种方法是仅使用PA信号对初始压力图像和SOS进行联合重建。现有的关节重建方法存在局限性：计算成本高，无法直接恢复SOS，以及依赖于不准确的简化假设。隐式神经表示或神经场是计算机视觉中的一种新兴技术，用于通过基于坐标的神经网络学习物理场的有效和连续表示。在这项工作中，我们介绍了NF-APACT，这是一种高效的自监督框架，利用神经场来估计SOS，以实现准确和鲁棒的多通道解卷积。我们的方法比现有方法更快、更准确地消除了SOS像差。我们在一个新的数值体模以及实验收集的体模和体内数据上证明了我们的方法的成功。我们的代码和数字幻影可在https://github.com/Lukeli0425/NF-APACT. et.al.|[2409.10876](http://arxiv.org/abs/2409.10876)|null|
|**2024-09-09**|**Lagrangian Hashing for Compressed Neural Field Representations**|我们提出了拉格朗日散列，这是一种神经场的表示，结合了依赖于欧拉网格（即~InstantNGP）的快速训练NeRF方法的特征，以及使用配备有特征的点作为表示信息的方法（例如3D高斯散点或PointNeRF）。我们通过将基于点的表示合并到InstantNGP表示的分层哈希表的高分辨率层中来实现这一点。由于我们的点具有影响域，因此我们的表示可以被解释为哈希表中存储的高斯混合。我们提出的损失鼓励我们的高斯人向需要更多代表预算才能充分代表的地区移动。我们的主要发现是，我们的表示允许使用更紧凑的表示来重建信号，而不会影响质量。 et.al.|[2409.05334](http://arxiv.org/abs/2409.05334)|null|
|**2024-09-08**|**Exploring spectropolarimetric inversions using neural fields. Solar chromospheric magnetic field under the weak-field approximation**|全斯托克斯偏振数据集来源于狭缝光谱仪或窄带滤光片图，如今已被常规采集。随着二维光谱偏振仪和允许长时间高质量观测序列的观测技术的出现，数据速率正在增加。在光谱偏振反演中，显然需要通过利用推断物理量的时空相干性来超越传统的逐像素策略。我们探索了神经网络作为时间和空间（也称为神经场）上物理量的连续表示的潜力，用于光谱极化反演。我们已经实现并测试了一个神经场，以在弱场近似（WFA）下执行磁场矢量的推理（也称为物理知情神经网络的方法）。通过使用神经场来描述磁场矢量，我们可以通过假设物理量是坐标的连续函数来在空间和时间域中正则化解。我们研究了Ca II 8542 A谱线的合成和真实观测结果。我们还探讨了其他显式正则化的影响，例如使用外推磁场的信息或色球原纤维的取向。与传统的逐像素反演相比，神经场方法提高了磁场矢量重建的保真度，特别是横向分量。这种隐式正则化是一种提高观测值有效信噪比的方法。虽然它比逐像素WFA估计慢，但这种方法通过减少自由参数的数量并在解决方案中引入时空约束，显示出深度分层反演的巨大潜力。 et.al.|[2409.05156](http://arxiv.org/abs/2409.05156)|**[link](https://github.com/cdiazbas/neural_wfa)**|
|**2024-09-04**|**MDNF: Multi-Diffusion-Nets for Neural Fields on Meshes**|我们提出了一种在三角形网格上表示神经场的新框架，该框架在空间和频率域上都是多分辨率的。受神经傅里叶滤波器组（NFFB）的启发，我们的架构通过将更精细的空间分辨率级别与更高的频带相关联来分解空间和频率域，而将更粗糙的分辨率映射到较低的频率。为了实现几何感知的空间分解，我们利用了多个扩散网络组件，每个组件都与不同的空间分辨率级别相关联。随后，我们应用傅里叶特征映射来鼓励更精细的分辨率水平与更高的频率相关联。最终信号是使用正弦激活的MLP以小波激励的方式组成的，将高频信号聚集在低频信号之上。我们的架构在学习复杂神经场方面具有很高的精度，并且对目标场的不连续性、指数尺度变化和网格修改具有鲁棒性。我们通过将我们的方法应用于不同的神经领域，如合成RGB函数、UV纹理坐标和顶点法线，展示了其有效性，并说明了不同的挑战。为了验证我们的方法，我们将其性能与两种替代方案进行了比较，展示了我们的多分辨率架构的优势。 et.al.|[2409.03034](http://arxiv.org/abs/2409.03034)|null|
|**2024-09-03**|**GraspSplats: Efficient Manipulation with 3D Feature Splatting**|机器人对物体部件进行高效和零样本抓取的能力对于实际应用至关重要，并且随着视觉语言模型（VLM）的最新进展而变得普遍。为了弥合二维到三维表示的差距以支持这种能力，现有的方法依赖于神经场（NeRF），通过可微渲染或基于点的投影方法。然而，我们证明了NeRF由于其隐含性而不适合场景变化，并且基于点的方法对于没有基于渲染的优化的零件定位是不准确的。为了修正这些问题，我们提出了“把握辉煌”。使用深度监督和一种新的参考特征计算方法，GraspSplats在60秒内生成高质量的场景表示。我们进一步验证了基于高斯表示法的优势，表明GraspSplats中的显式和优化几何足以原生支持（1）实时抓取采样和（2）使用点跟踪器进行动态和铰接对象操作。通过在Franka机器人上进行的广泛实验，我们证明了在不同的任务设置下，GraspSplats的表现明显优于现有的方法。特别是，GraspSplats的性能优于基于NeRF的方法，如F3RM和LERF-TOGO，以及2D检测方法。 et.al.|[2409.02084](http://arxiv.org/abs/2409.02084)|null|

<p align=right>(<a href=#updated-on-20241007>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

