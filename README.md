[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.10.21
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-17**|**DepthSplat: Connecting Gaussian Splatting and Depth**|高斯散射和单/多视图深度估计通常是单独研究的。本文中，我们提出了DepthSplat来连接高斯溅射和深度估计，并研究了它们之间的相互作用。更具体地说，我们首先通过利用预先训练的单眼深度特征来贡献一个稳健的多视图深度模型，从而得到高质量的前馈3D高斯飞溅重建。我们还表明，高斯飞溅可以作为一种无监督的预训练目标，用于从大规模未标记的数据集中学习强大的深度模型。我们通过广泛的消融和跨任务转移实验验证了高斯溅射和深度估计之间的协同作用。我们的DepthSplat在ScanNet、RealEstate10K和DL3DV数据集上实现了深度估计和新颖视图合成方面的最先进性能，展示了连接这两个任务的互惠互利。我们的代码、模型和视频结果可在https://haofeixu.github.io/depthsplat/. et.al.|[2410.13862](http://arxiv.org/abs/2410.13862)|**[link](https://github.com/cvg/depthsplat)**|
|**2024-10-17**|**Hybrid bundle-adjusting 3D Gaussians for view consistent rendering with pose optimization**|新型视图合成在3D计算机视觉领域取得了重大进展。然而，从不完美的相机姿态渲染视图一致的新颖视图仍然具有挑战性。本文介绍了一种混合束调整3D高斯模型，该模型能够实现具有姿态优化的视图一致性渲染。该模型联合提取基于图像和神经的3D表示，以在面向前方的场景中同时生成视图一致的图像和相机姿态。我们的模型的有效性通过在真实和合成数据集上进行的广泛实验得到了证明。这些实验清楚地表明，我们的模型可以有效地优化神经场景表示，同时解决明显的相机姿态失准问题。源代码可在https://github.com/Bistu3DV/hybridBA. et.al.|[2410.13280](http://arxiv.org/abs/2410.13280)|**[link](https://github.com/bistu3dv/hybridba)**|
|**2024-10-18**|**UniG: Modelling Unitary 3D Gaussians for View-consistent 3D Reconstruction**|在这项工作中，我们提出了UniG，这是一种视图一致的3D重建和新颖的视图合成模型，可以从稀疏图像中生成3D高斯的高保真表示。现有的基于3D高斯的方法通常对每个视图的每个像素进行高斯回归，分别为每个视图创建3D高斯，并通过点连接将其合并。这种与视图无关的重建方法通常会导致视图不一致问题，其中来自不同视图的同一3D点的预测位置可能存在差异。为了解决这个问题，我们开发了一个类似DETR（DEtect TRansformer）的框架，该框架将3D高斯视为解码器查询，并通过在多个输入图像上执行多视图交叉注意（MVDFA）来逐层更新其参数。通过这种方式，多个视图自然有助于对3D高斯的统一表示进行建模，从而使3D重建更加视图一致。此外，由于用作解码器查询的3D高斯数与输入视图的数量无关，因此允许任意数量的输入图像，而不会导致内存爆炸。大量的实验验证了我们的方法的优势，在定量和定性上展示了优于现有方法的性能（在Objaverse上训练并在GSO基准上测试时，PSNR提高了4.2 dB）。该代码将于https://github.com/jwubz123/UNIG. et.al.|[2410.13195](http://arxiv.org/abs/2410.13195)|**[link](https://github.com/jwubz123/UNIG)**|
|**2024-10-16**|**Triplet: Triangle Patchlet for Mesh-Based Inverse Rendering and Scene Parameters Approximation**|辐射场的最新进展显著改善了新颖的视图合成。然而，在许多现实世界的应用中，更高级的挑战在于逆渲染，它试图推导场景的物理属性，包括光、几何、纹理和材质。然而，网格作为许多模拟管道采用的传统表示方法，在逆渲染的辐射场中仍然显示出有限的影响。本文介绍了一种名为三角形补丁（缩写为Triplet）的新框架，这是一种基于网格的表示方法，可以全面近似这些场景参数。我们首先用随机生成的点或从相机校准中获得的稀疏点组装三元组，其中所有人脸都被视为一个独立的元素。接下来，我们模拟光的物理交互，并使用光栅化和光线跟踪等传统图形渲染技术优化场景参数，同时进行密度控制和传播。还提出了一种迭代网格提取过程，在该过程中，我们继续通过基于图的操作对几何形状和材料进行优化。我们还引入了几个监管术语，以便更好地概括材料性能。我们的框架可以在没有统一框架中的光、材料和几何先验的情况下，通过网格精确估计光、材料及几何。实验表明，我们的方法可以在重建高质量几何和精确材料属性的同时实现最先进的视觉质量。 et.al.|[2410.12414](http://arxiv.org/abs/2410.12414)|**[link](https://github.com/rando11199/triplet)**|
|**2024-10-16**|**GAN Based Top-Down View Synthesis in Reinforcement Learning Environments**|人类的行为是基于对环境的心理感知。即使环境的所有方面都不可见，人类也有一个内部心理模型，可以将部分可见的场景概括为完全构建和连接的视图。这种内部心理模型使用过去遇到的环境的空间和时间方面的学习抽象表示。强化学习环境中的人工智能也受益于从经验中学习环境的表示。它为代理提供了不直接可见的观点，帮助其做出更好的策略决策。它还可以用于预测环境的未来状态。该项目探索了基于人工智能的第一人称视图观察，使用生成对抗网络（GAN）学习强化学习环境的自上而下视图。自顶向下视图很有用，因为它通过构建整个环境的地图来提供环境的完整概述。它提供有关对象的尺寸和形状以及它们彼此之间的相对位置的信息。最初，当代理只能看到环境的部分观察时，只会生成部分自上而下的视图。当代理通过一组操作探索环境时，生成的自上而下的视图就完成了。这种生成的自上而下的视图可以帮助代理推断出更好的策略决策。该项目的重点是学习强化学习环境的自上而下的视图。它不处理任何强化学习任务。 et.al.|[2410.12372](http://arxiv.org/abs/2410.12372)|null|
|**2024-10-16**|**EG-HumanNeRF: Efficient Generalizable Human NeRF Utilizing Human Prior for Sparse View**|可泛化神经辐射场（NeRF）实现了基于神经的数字人体渲染，而无需对每个场景进行再训练。当与人类先验知识相结合时，即使输入视图稀疏，也可以实现高质量的人类渲染。然而，这些方法的推理仍然很慢，因为需要对每条射线进行大量的神经网络查询来确保渲染质量。此外，遮挡区域通常会出现伪影，尤其是在输入视图稀疏的情况下。为了解决这些问题，我们提出了一种通用的人类NeRF框架，通过广泛利用人类先验知识，实现了稀疏输入视图的高质量和实时渲染。我们采用两阶段采样缩减策略加速渲染：首先在人体几何体周围构建边界网格，以减少采样引导回归的光线样本数量，然后使用较少的引导样本进行体绘制。为了提高渲染质量，特别是在遮挡区域，我们提出了一种遮挡感知注意力机制，从人类先验中提取遮挡信息，然后使用图像空间细化网络来提高渲染质量。此外，对于体绘制，我们采用了符号射线距离函数（SRDF）公式，这使我们能够在每个采样位置提出SRDF损失，以进一步提高渲染质量。我们的实验表明，我们的方法在渲染质量方面优于最先进的方法，并且与速度优先的新型视图合成方法相比，具有竞争力的渲染速度。 et.al.|[2410.12242](http://arxiv.org/abs/2410.12242)|null|
|**2024-10-15**|**SplatPose+: Real-time Image-Based Pose-Agnostic 3D Anomaly Detection**|基于图像的姿态不可知三维异常检测是工业质量控制中出现的一项重要任务。该任务旨在在给定一组无异常对象的参考图像的情况下，从测试对象的查询图像中查找异常。挑战在于查询视图（也称为姿势）是未知的，可能与参考视图不同。目前，已经出现了OmniposeAD和SplatPose等新方法，通过在查询视图中合成伪参考图像进行像素间比较来弥合这一差距。然而，这些方法都不能实时推断，这在大规模生产的工业质量控制中至关重要。因此，我们提出了SplatPose+，它采用了一种混合表示，由用于定位的运动结构（SfM）模型和用于新视图合成的3D高斯散点（3DGS）模型组成。尽管我们提出的管道需要计算额外的SfM模型，但与SplatPose相比，它提供了实时推理速度和更快的训练。在质量方面，我们利用多姿态异常检测（MAD-SIM）数据集在姿态无关异常检测基准上实现了新的SOTA。 et.al.|[2410.12080](http://arxiv.org/abs/2410.12080)|null|
|**2024-10-15**|**LoGS: Visual Localization via Gaussian Splatting with Fewer Training Images**|视觉定位涉及估计查询图像的6-DoF（自由度）相机姿态，这是各种计算机视觉和机器人任务中的基本组成部分。本文介绍了LoGS，这是一种基于视觉的定位流水线，利用3D高斯散点（GS）技术作为场景表示。这种新颖的表示允许高质量的新颖视图合成。在映射阶段，首先应用运动结构（SfM），然后生成GS图。在定位过程中，通过图像检索、局部特征匹配和PnP求解器获得初始位置，然后在GS地图上通过综合分析的方式实现高精度姿态。在四个大规模数据集上的实验结果证明了所提出的方法在估计相机姿态方面的SoTA准确性和在具有挑战性的少镜头条件下的鲁棒性。 et.al.|[2410.11505](http://arxiv.org/abs/2410.11505)|null|
|**2024-10-15**|**GS^3: Efficient Relighting with Triple Gaussian Splatting**|我们提出了一种基于空间和角度高斯的表示和三重叠加过程，用于从多视点照明输入图像中实时、高质量地进行新颖的照明和视图合成。为了描述复杂的外观，我们采用朗伯加角高斯混合作为每个空间高斯的有效反射函数。为了生成自阴影，我们将所有空间高斯分布向光源投射以获得阴影值，这些值由一个小型多层感知器进一步细化。为了补偿全局照明等其他影响，训练另一个网络来计算并添加每个空间的高斯RGB元组。我们的表示方法的有效性在30个几何形状（从实心到蓬松）和外观（从半透明到各向异性）变化很大的样本上得到了证明，并使用了不同形式的输入数据，包括合成/重建物体的渲染图像、用手持相机和闪光灯拍摄的照片，或来自专业光台的照片。我们在单个商品GPU上实现了40-70分钟的训练时间和90 fps的渲染速度。我们的结果在质量/性能方面与最先进的技术相比毫不逊色。我们的代码和数据可在以下网址公开获取https://GSrelight.github.io/. et.al.|[2410.11419](http://arxiv.org/abs/2410.11419)|**[link](https://github.com/gsrelight/gs-relight)**|
|**2024-10-15**|**MCGS: Multiview Consistency Enhancement for Sparse-View 3D Gaussian Radiance Fields**|由3D高斯表示的辐射场擅长合成新颖的视图，提供了高训练效率和快速渲染。然而，在稀疏输入视图的情况下，缺乏多视图一致性约束会导致点云初始化不佳，优化和致密化的启发式方法不可靠，从而导致性能不佳。现有的方法通常包含来自密集估计网络的深度先验，但忽略了输入图像中固有的多视图一致性。此外，它们依赖于基于多视图立体（MVS）的初始化，这限制了场景表示的效率。为了克服这些挑战，我们提出了一种基于3D高斯散斑的视图合成框架，称为MCGS，能够从稀疏输入视图中重建出逼真的场景。MCGS在增强多视图一致性方面的关键创新如下：i）我们引入了一种初始化方法，该方法利用稀疏匹配器结合随机填充策略，产生了一组紧凑但足够的初始点。这种方法增强了初始几何先验，促进了高效的场景表示。ii）我们开发了一种多视图一致性引导的渐进修剪策略，通过增强一致性和消除低贡献高斯分布来细化高斯场。这些模块化的即插即用策略增强了对稀疏输入视图的鲁棒性，加速了渲染，减少了内存消耗，使MCGS成为3D高斯散斑的实用高效框架。 et.al.|[2410.11394](http://arxiv.org/abs/2410.11394)|null|

<p align=right>(<a href=#updated-on-20241021>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-17**|**Object Pose Estimation Using Implicit Representation For Transparent Objects**|物体姿态估计是计算机视觉中的一项重要任务。物体姿态给出了物体在现实世界空间中的方向和平移，这允许各种应用，如操纵、增强现实等。各种物体对光表现出不同的特性，如反射、吸收等。这使得理解物体在RGB和深度通道中的结构具有挑战性。最近的研究一直在向基于学习的方法发展，这些方法利用深度学习为对象姿态估计提供了一种更灵活、更通用的方法。一种这样的方法是渲染和比较方法，该方法从多个视图渲染对象并将其与给定的2D图像进行比较，这通常需要CAD模型形式的对象表示。我们认为CAD模型的合成纹理可能不适合渲染和比较操作。我们发现，如果对象以神经辐射场（NeRF）的形式表示为隐式（神经）表示，它会对实际场景进行更逼真的渲染，并保留关键的空间特征，这使得比较更加通用。我们在透明数据集上评估了渲染和比较方法的NeRF实现，发现它超过了当前最先进的结果。 et.al.|[2410.13465](http://arxiv.org/abs/2410.13465)|null|
|**2024-10-18**|**Context-Enhanced Multi-View Trajectory Representation Learning: Bridging the Gap through Self-Supervised Models**|使用通用密集表示对轨迹数据进行建模已成为各种下游应用的流行范式，如轨迹分类、行程时间估计和相似性计算。然而，现有的方法通常依赖于单一空间视图的轨迹，限制了它们捕获丰富上下文信息的能力，而丰富上下文信息对于深入了解不同地理空间背景下的运动模式至关重要。为此，我们提出了MVTraj，这是一种用于轨迹表示学习的新型多视图建模方法。MVTraj整合了从GPS到道路网络和兴趣点的各种背景知识，以更全面地了解轨迹数据。为了在多个视图之间对齐学习过程，我们利用GPS轨迹作为桥梁，并采用自我监督的借口任务来捕捉和区分不同空间视图之间的运动模式。在此之后，我们将来自不同视角的轨迹视为不同的模态，并应用分层跨模态交互模块来融合表示，从而丰富了从多个来源获得的知识。对真实世界数据集的广泛实验表明，MVTraj在与各种空间视图相关的任务中明显优于现有基线，验证了其在时空建模中的有效性和实用性。 et.al.|[2410.13196](http://arxiv.org/abs/2410.13196)|null|
|**2024-10-18**|**UniG: Modelling Unitary 3D Gaussians for View-consistent 3D Reconstruction**|在这项工作中，我们提出了UniG，这是一种视图一致的3D重建和新颖的视图合成模型，可以从稀疏图像中生成3D高斯的高保真表示。现有的基于3D高斯的方法通常对每个视图的每个像素进行高斯回归，分别为每个视图创建3D高斯，并通过点连接将其合并。这种与视图无关的重建方法通常会导致视图不一致问题，其中来自不同视图的同一3D点的预测位置可能存在差异。为了解决这个问题，我们开发了一个类似DETR（DEtect TRansformer）的框架，该框架将3D高斯视为解码器查询，并通过在多个输入图像上执行多视图交叉注意（MVDFA）来逐层更新其参数。通过这种方式，多个视图自然有助于对3D高斯的统一表示进行建模，从而使3D重建更加视图一致。此外，由于用作解码器查询的3D高斯数与输入视图的数量无关，因此允许任意数量的输入图像，而不会导致内存爆炸。大量的实验验证了我们的方法的优势，在定量和定性上展示了优于现有方法的性能（在Objaverse上训练并在GSO基准上测试时，PSNR提高了4.2 dB）。该代码将于https://github.com/jwubz123/UNIG. et.al.|[2410.13195](http://arxiv.org/abs/2410.13195)|**[link](https://github.com/jwubz123/UNIG)**|
|**2024-10-16**|**Configurable Embodied Data Generation for Class-Agnostic RGB-D Video Segmentation**|本文提出了一种生成大规模数据集的方法，以改善不同形状因子的机器人之间的类无关视频分割。具体来说，我们考虑的问题是，如果在数据生成过程中考虑了机器人的实施方式，那么在通用分割数据上训练的视频分割模型是否对特定的机器人平台更有效。为了回答这个问题，制定了一个管道，用于使用3D重建（例如来自HM3DSem）生成分段视频，这些视频可以根据机器人的实施例（例如传感器类型、传感器放置和照明源）进行配置。由此产生的大量RGB-D视频全景分割数据集（MVPd）被引入，用于与基础和视频分割模型进行广泛的基准测试，并支持视频分割中以实施例为重点的研究。我们的实验结果表明，在将基础模型转移到某些机器人实施例（如特定的相机放置）时，使用MVPd进行微调可以提高性能。这些实验还表明，使用3D模态（深度图像和相机姿态）可以提高视频分割的准确性和一致性。项目网页可在https://topipari.com/projects/MVPd et.al.|[2410.12995](http://arxiv.org/abs/2410.12995)|null|
|**2024-10-16**|**Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans**|骨关节炎是一种影响骨骼和软骨的退行性疾病，通常导致骨赘形成、骨密度降低和关节间隙狭窄。恢复正常关节功能的治疗方案因病情的严重程度而异。这项工作引入了一种处理肩部CT扫描的创新深度学习框架。它具有肱骨近端和肩胛骨的语义分割、骨表面的3D重建、肩关节（GH）关节区域的识别以及三种常见骨关节炎相关病理的分期：骨赘形成（OS）、GH间隙缩小（JS）和肱骨肩胛骨对齐（HSA）。该流水线包括两个级联的CNN架构：用于分割的3D CEL-UNet和用于三重分类的3D Arthro-Net。使用571次CT扫描的回顾性数据集，对患有不同程度GH骨关节炎相关疾病的患者进行训练、验证和测试。肱骨三维重建的均方根误差和豪斯多夫距离中值分别为0.22mm和1.48mm，肩胛骨为0.24mm和1.48mm。其性能优于最先进的架构，可能适用于基于PSI的肩关节置换术前计划。OS、JS和HSA在所有三个类别中的分类准确率始终达到90%左右。推理管道的计算时间不到15秒，展示了该框架的效率和与骨科放射学实践的兼容性。这些结果代表了人工智能工具在医学翻译方面的一个有前景的进步。这一进展旨在简化术前计划流程，提供高质量的骨表面，并支持外科医生根据独特的患者关节状况选择最合适的手术方法。 et.al.|[2410.12641](http://arxiv.org/abs/2410.12641)|null|
|**2024-10-15**|**Stochastic 3D reconstruction of cracked polycrystalline NMC particles using 2D SEM data**|锂离子电池的性能受到其阴极性能的强烈影响，因此也受到阴极所含颗粒的3D微观结构的影响。在压延和循环过程中，阴极颗粒内会产生裂纹，这可能会以多种方式影响性能。一方面，裂纹降低了内部连接性，从而阻碍了阴极粒子内的电子传输。另一方面，颗粒内裂纹可以增加阴极反应表面。由于这些相互矛盾的影响，有必要定量研究电池循环如何影响开裂，以及开裂又如何影响电池性能。因此，有必要用结构描述符表征3D颗粒形态，并将其与有效电池性能定量关联。通常，使用图像数据进行3D结构表征。然而，信息丰富的3D成像技术耗时、昂贵且很少可用，因此分析通常必须依赖于2D图像数据。本文提出了一种新的体视学方法，用于生成虚拟3D阴极粒子，这些粒子表现出与实验测量粒子的2D截面中观察到的裂纹网络在统计上等效的裂纹网络。因此，更容易获得的2D图像数据足以得出破裂阴极颗粒的完整3D特征。在未来的研究中，虚拟生成的3D粒子将被用作空间分辨电化学机械模拟的几何输入，以加深我们对锂离子电池阴极结构-性能关系的理解。 et.al.|[2410.12020](http://arxiv.org/abs/2410.12020)|null|
|**2024-10-15**|**Robotic Arm Platform for Multi-View Image Acquisition and 3D Reconstruction in Minimally Invasive Surgery**|微创手术（MIS）具有显著的优势，如缩短恢复时间和最大限度地减少患者创伤，但在可见性和可及性方面存在挑战，使精确的3D重建成为手术规划和导航的重要工具。这项工作介绍了一种机器人手臂平台，用于在MIS环境中进行高效的多视图图像采集和精确的3D重建。我们将腹腔镜改装成机器人手臂，并在不同的照明条件（手术室和腹腔镜）和轨迹（球形和腹腔镜）下捕获了几个绵羊器官的离体图像。我们采用了最近发布的基于学习的特征匹配器与COLMAP相结合来生成我们的重建。通过高精度激光扫描对重建进行定量评估。我们的结果表明，虽然重建在真实的MIS照明和轨迹下遭受的损失最大，但我们的管道的许多版本都达到了接近亚毫米的精度，平均均方根误差为1.05毫米，倒角距离为0.82毫米。我们最好的重建结果发生在手术室照明和球形轨迹上。我们的机器人平台为MIS环境中的3D生成提供了一种受控、可重复的多视图数据采集工具，我们希望这能为训练基于学习的模型带来新的数据集。 et.al.|[2410.11703](http://arxiv.org/abs/2410.11703)|null|
|**2024-10-15**|**Simultaneous Diffusion Sampling for Conditional LiDAR Generation**|通过捕获反映周围环境几何形状的3D点云，LiDAR已成为自主系统的主要传感器。如果激光雷达扫描太稀疏、被障碍物遮挡或范围太小，在尊重场景几何形状的同时增强点云扫描对下游任务很有用。在视觉生成方法兴趣爆炸式增长的推动下，条件激光雷达生成开始兴起。本文提出了一种新的同时扩散采样方法，用于生成基于多视角场景三维结构的点云。关键思想是对生成过程施加多视图几何约束，利用互信息来增强结果。我们的方法首先将输入扫描重新转换为扫描周围的多个新视点，从而创建多个合成激光雷达扫描。然后，根据我们的方法，合成和输入的激光雷达扫描同时进行条件生成。结果表明，我们的方法可以对点云扫描产生准确和几何一致的增强，使其在各种基准测试中大大优于现有方法。 et.al.|[2410.11628](http://arxiv.org/abs/2410.11628)|null|
|**2024-10-16**|**Depth Estimation From Monocular Images With Enhanced Encoder-Decoder Architecture**|由于需要通常提供深度信息的立体或多视图数据，因此从单个2D图像估计深度是一项具有挑战性的任务。本文通过引入一种使用编码器-解码器架构的基于深度学习的新方法来应对这一挑战，其中Inception-ResNet-v2模型被用作编码器。根据现有文献，这是首次使用Inception-ResNet-v2作为单目深度估计的编码器，表明其性能优于之前的模型。Inception-ResNet-v2的使用使我们的模型能够有效地捕获通常难以预测的复杂对象和细粒度细节。此外，我们的模型结合了多尺度特征提取，以提高不同类型对象大小和距离的深度预测精度。我们提出了一种由深度损失、梯度边缘损失和SSIM损失组成的复合损失函数，其中对权重进行微调以优化加权和，确保深度估计不同方面的更好平衡。纽约大学深度V2数据集的实验结果表明，我们的模型达到了最先进的性能，ARE为0.064，RMSE为0.228，准确率（ $\delta$<1.25$ ）为89.3%。这些指标表明，即使在具有挑战性的情况下，我们的模型也能有效地预测深度，为机器人、3D重建和增强现实等现实世界的应用提供可扩展的解决方案。 et.al.|[2410.11610](http://arxiv.org/abs/2410.11610)|null|
|**2024-10-15**|**Multiview Scene Graph**|适当的场景表示是追求空间智能的核心，智能体可以稳健地重建并有效地理解3D场景。场景表示可以是度量，如3D重建中的地标图、对象检测中的3D边界框或占用预测中的体素网格，也可以是拓扑，如SLAM中具有循环闭包的姿态图或SfM中的可见性图。在这项工作中，我们建议从未涂胶的图像构建多视图场景图（MSG），用互连的位置和对象节点在拓扑上表示场景。构建MSG的任务对现有的表示学习方法来说是具有挑战性的，因为它需要联合解决视觉位置识别、对象检测和来自视野有限和潜在大视点变化的图像的对象关联问题。为了评估任何解决这一任务的方法，我们开发了一个基于公共3D数据集的MSG数据集和注释。我们还提出了一种基于MSG边联合得分交集的评估度量。此外，我们开发了一种基于主流预训练视觉模型的新基线方法，将视觉位置识别和对象关联结合到一个Transformer解码器架构中。实验证明，与现有的相关基线相比，我们的方法具有更优的性能。 et.al.|[2410.11187](http://arxiv.org/abs/2410.11187)|null|

<p align=right>(<a href=#updated-on-20241021>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-17**|**Diffusing States and Matching Scores: A New Framework for Imitation Learning**|对抗性模仿学习传统上被定义为学习者和对抗性选择的成本函数之间的两人零和博弈，因此可以被认为是生成性对抗网络（GAN）的顺序泛化。这一框架的一个突出例子是生成对抗模仿学习（GAIL）。然而，近年来，扩散模型已经成为GAN的一种非对抗性替代方案，GAN只需要通过回归训练分数函数，但可以产生更高质量的几代。作为回应，我们研究了如何将洞察力从扩散建模提升到顺序设置。我们提出了扩散状态，并沿着扩散状态进行分数匹配，以衡量专家和学习者状态之间的差异。因此，我们的方法只需要训练分数函数来通过标准回归预测噪声，这使得训练比对抗方法更容易、更稳定。从理论上讲，我们在时域内用线性缩放证明了一阶和二阶实例相关的界限，证明了我们的方法避免了阻碍离线模仿学习方法的复合误差。根据经验，我们表明我们的方法在各种连续控制问题上优于GAN风格的模仿学习基线，包括控制类人机器人行走、坐下和爬行等复杂任务。 et.al.|[2410.13855](http://arxiv.org/abs/2410.13855)|**[link](https://github.com/ziqian2000/smiling)**|
|**2024-10-17**|**Influence Functions for Scalable Data Attribution in Diffusion Models**|扩散模型在生成建模方面取得了重大进展。然而，它们的广泛采用给数据归因和可解释性带来了挑战。在本文中，我们的目标是通过开发一个\textit{影响函数}框架来帮助解决扩散模型中的这些挑战。基于影响函数的数据归因方法近似了如果删除一些训练数据，模型的输出将如何变化。在监督学习中，这通常用于预测特定示例的损失将如何变化。对于扩散模型，我们专注于通过几个代理测量来预测生成特定示例的概率的变化。我们展示了如何为这些量制定影响函数，以及如何将之前提出的方法解释为我们框架中的特定设计选择。为了确保影响函数中Hessian计算的可扩展性，我们系统地开发了基于专门针对扩散模型的广义高斯-牛顿矩阵的K-FAC近似。我们将之前提出的方法重新定义为我们框架中的具体设计选择，并表明我们推荐的方法在常见评估上优于之前的数据归因方法，例如线性数据建模得分（LDS）或无顶部影响的再训练，而不需要特定于方法的超参数调整。 et.al.|[2410.13850](http://arxiv.org/abs/2410.13850)|null|
|**2024-10-17**|**DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise Motion Control**|定制视频生成的最新进展使用户能够创建针对特定主题和运动轨迹量身定制的视频。然而，现有的方法通常需要复杂的测试时间微调，并且难以平衡学科学习和运动控制，这限制了它们在现实世界中的应用。在本文中，我们提出了DreamVideo-2，这是一种零样本视频定制框架，能够生成具有特定主题和运动轨迹的视频，分别由单个图像和边界框序列引导，而无需测试时间微调。具体来说，我们引入了参考注意力，它利用了模型固有的受试者学习能力，并设计了一个掩模引导的运动模块，通过充分利用从边界框中导出的框掩模的鲁棒运动信号来实现精确的运动控制。虽然这两个组件实现了预期的功能，但我们实证观察到，运动控制往往主导着学科学习。为了解决这个问题，我们提出了两个关键设计：1）掩蔽参考注意力，它将混合潜在掩模建模方案集成到参考注意力中，以增强所需位置的主体表示，2）重新加权扩散损失，它区分边界框内外区域的贡献，以确保主体和运动控制之间的平衡。在新策划的数据集上进行的广泛实验结果表明，DreamVideo-2在主题定制和运动控制方面都优于最先进的方法。数据集、代码和模型将公开。 et.al.|[2410.13830](http://arxiv.org/abs/2410.13830)|null|
|**2024-10-17**|**Deep Generative Models Unveil Patterns in Medical Images Through Vision-Language Conditioning**|深度生成模型通过提高数据集的大小和质量，显著推进了医学影像分析。除了单纯的数据增强，我们在本文中的研究还强调了深度生成模型的另一个重要能力：它们揭示和展示医学图像模式的能力。我们采用具有混合条件的生成结构，结合临床数据和分割掩模来指导图像合成过程。此外，我们创新性地将表格形式的临床数据转化为文本描述。这种方法简化了对缺失值的处理，也使我们能够利用大型预训练的视觉语言模型来研究独立临床条目之间的关系，并理解性别和吸烟状况等一般术语。由于我们的临床信息与图像的视觉相关性较低，我们的方法不同于传统的医学报告指导合成，并且比传统的医疗报告指导合成更具挑战性。为了克服这一点，我们引入了一种文本视觉嵌入机制，该机制加强了条件，确保网络有效利用所提供的信息。我们的管道可推广到基于GAN和扩散模型。胸部CT实验，特别是关注吸烟状况的实验，表明肺部的强度变化是一致的，这与临床观察结果一致，表明我们的方法在捕捉和可视化特定属性对医学图像模式的影响方面是有效的。我们的方法为利用深度生成模型早期检测和精确可视化复杂的临床状况提供了一条新途径。所有代码都是https://github.com/junzhin/DGM-VLC. et.al.|[2410.13823](http://arxiv.org/abs/2410.13823)|**[link](https://github.com/junzhin/dgm-vlc)**|
|**2024-10-17**|**Enhancing universal machine learning potentials with polarizable long-range interactions**|长程相互作用在决定化学系统在各种环境中的行为方面至关重要。在原子水平上对物理和化学现象的准确预测取决于对这些相互作用的准确建模。在这里，我们提出了一个框架，通过将显式极化长程相互作用与等变图神经网络短程势相结合，大大提高了机器学习原子间势的预测能力。预训练的通用模型适用于整个元素周期表，可以达到第一性原理的精度。这种多功能模型已被进一步应用于不同的研究领域，包括机械性能、固态电解质中的离子扩散率、铁电性和界面反应的研究，证明了其广泛的适用性和鲁棒性。 et.al.|[2410.13820](http://arxiv.org/abs/2410.13820)|null|
|**2024-10-17**|**ConsisSR: Delving Deep into Consistency in Diffusion-based Image Super-Resolution**|真实世界图像超分辨率（Real ISR）旨在从被未知和复杂退化损坏的低质量（LQ）输入中恢复高质量（HQ）图像。特别是，预训练的文本到图像（T2I）扩散模型提供了强大的生成先验来重建可信和复杂的细节。然而，T2I生成侧重于语义一致性，而Real ISR强调像素级重建，这阻碍了现有方法充分利用扩散先验。为了应对这一挑战，我们引入了ConsisSR来处理语义和像素级的一致性。具体来说，与粗粒度文本提示相比，我们利用了更强大的CLIP图像嵌入，并通过我们的混合提示适配器（HPA）有效地利用这两种模式进行语义指导。其次，我们引入了时间感知延迟增强（TALA）来缓解T2I生成和真实ISR一致性要求之间的固有差距。通过随机混合LQ和HQ潜在输入，我们的模型不仅可以处理时间步长特定的扩散噪声，还可以细化累积的潜在表示。最后，我们的GAN嵌入策略采用预训练的Real ESRGAN模型来细化扩散起点。这将推理过程加速到10个步骤，同时以无训练的方式保持采样质量。我们的方法在全尺寸和加速模型中都表现出了最先进的性能。该代码将公开发布。 et.al.|[2410.13807](http://arxiv.org/abs/2410.13807)|null|
|**2024-10-17**|**Arbitrarily-Conditioned Multi-Functional Diffusion for Multi-Physics Emulation**|现代物理模拟通常涉及多个感兴趣的函数，已知传统的数值方法复杂且计算成本高。虽然基于机器学习的代理模型可以显著降低成本，但大多数模型都专注于单一任务，如前向预测，并且通常缺乏不确定性量化——这是许多应用中的重要组成部分。为了克服这些局限性，我们提出了任意条件多函数扩散（ACMFD），这是一种用于多物理场仿真的通用概率替代模型。ACMFD可以在一个框架内执行广泛的任务，包括前向预测、各种逆问题，以及模拟整个系统或基于其他条件的量子集的数据。具体来说，我们通过将噪声建模为高斯过程（GP），扩展了用于多功能生成的标准去噪扩散概率模型（DDPM）。然后，我们引入了一种创新的去噪损失。训练包括随机采样条件部分并将相应的预测噪声拟合为零，使ACMFD能够灵活地生成基于任何其他函数或量的函数值。为了实现高效的训练和采样，并灵活处理不规则采样的数据，我们使用GP将函数样本插值到网格上，从而引入Kronecker乘积结构以实现高效计算。我们展示了ACMFD在几个基本多物理系统中的优势。 et.al.|[2410.13794](http://arxiv.org/abs/2410.13794)|null|
|**2024-10-17**|**DPLM-2: A Multimodal Diffusion Protein Language Model**|蛋白质是由其氨基酸序列定义的重要大分子，决定了它们的三维结构，从而决定了它们在所有生物体中的功能。因此，生成性蛋白质建模需要一种多模式方法来同时建模、理解和生成序列和结构。然而，现有的方法通常对每种模态使用单独的模型，限制了它们捕捉序列和结构之间复杂关系的能力。这导致在需要联合理解和生成两种模式的任务中表现不佳。本文介绍了DPLM-2，这是一种多模式蛋白质基础模型，它扩展了离散扩散蛋白质语言模型（DPLM），以适应序列和结构。为了使用语言模型进行结构学习，使用基于无查找量化的标记器将3D坐标转换为离散标记。通过实验和高质量合成结构的训练，DPLM-2学习序列和结构的联合分布，以及它们的边缘和条件句。我们还实施了一种有效的预热策略，以利用大规模进化数据与预训练的基于序列的蛋白质语言模型的结构归纳偏差之间的联系。经验评估表明，DPLM-2可以同时生成高度兼容的氨基酸序列及其相应的3D结构，从而消除了两阶段生成方法的需要。此外，DPLM-2在各种条件生成任务中表现出了有竞争力的性能，包括折叠、反向折叠和具有多模态基序输入的支架，以及为预测任务提供结构感知表示。 et.al.|[2410.13782](http://arxiv.org/abs/2410.13782)|null|
|**2024-10-17**|**Conductance in graphene through double laser barriers and magnetic field**|研究了通过由磁场辅助的区域分隔的双势垒激光结构的光子辅助电荷输运。利用Floquet理论和矩阵形式，计算了中心带和边带的传输概率。由于能谱的简并性，激光场的时间周期性产生了无限数量的传输模式。数值解决所有模式的挑战需要限制与能量 $\varepsilon\pm\varpi$ 对应的第一边带。发现两个激光场之间的临界相位差抵消了由于量子干涉引起的通过边带的传输。改变施加磁场的区域的宽度可以抑制横向传输并控制传输模式。激光场的强度还允许抑制克莱因隧穿和阻断零光子交换的传输过程，以及激活光子交换的透射过程。电导也受到系统参数变化的影响。由于激光场对费米子的限制，增加激光场的强度会降低电导。此外，增加施加磁场的区域的大小会降低电导，因为增加的距离给费米子提供了更大的扩散机会，并增加了它们与磁场的相互作用。 et.al.|[2410.13771](http://arxiv.org/abs/2410.13771)|null|
|**2024-10-17**|**Probing the Latent Hierarchical Structure of Data via Diffusion Models**|高维数据必须高度结构化才能学习。尽管人们经常提出数据的组成和层次性来解释可学习性，但建立这些属性的定量测量却很少。同样，访问这种数据结构背后的潜在变量仍然是一个挑战。在这项工作中，我们表明，在基于扩散的模型中进行前后向实验，对数据进行噪声处理，然后进行去噪以生成新的样本，是探索数据潜在结构的有前景的工具。我们在简单的层次模型中预测，在这个过程中，数据的变化是由相关块发生的，其长度尺度在已知发生相变的噪声水平下发散。值得注意的是，我们使用最先进的扩散模型在文本和图像数据集中证实了这一预测。我们的结果显示了潜在变量变化如何在数据中表现出来，并建立了如何使用扩散模型在真实数据中衡量这些影响。 et.al.|[2410.13770](http://arxiv.org/abs/2410.13770)|null|

<p align=right>(<a href=#updated-on-20241021>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-15**|**Deep vectorised operators for pulsatile hemodynamics estimation in coronary arteries from a steady-state prior**|心血管血流动力学场为冠状动脉疾病提供了有价值的医学决策标志。计算流体动力学（CFD）是体内准确、无创评估这些量的金标准。在这项工作中，我们提出了一种基于机器学习的时间高效替代模型，用于基于稳态先验估计脉动血流动力学。我们引入了深度矢量化算子，这是一种用于在无限维函数空间上进行离散化独立学习的建模框架。基础神经结构是一个以血流动力学边界条件为条件的神经场。重要的是，我们展示了如何将逐点动作的要求放宽到置换等变，从而产生一系列可以通过消息传递和自我关注层进行参数化的模型。我们在从冠状动脉计算机断层扫描血管造影（CCTA）中提取的74条狭窄冠状动脉的数据集上评估了我们的方法，并将患者特异性脉动CFD模拟作为基本事实。我们证明，我们的模型能够准确估计脉动速度和压力，同时不受源域重新采样的影响（离散化独立性）。这表明，深度矢量化算子是冠状动脉及其他动脉心血管血流动力学估计的强大建模工具。 et.al.|[2410.11920](http://arxiv.org/abs/2410.11920)|null|
|**2024-10-07**|**Fast Training of Sinusoidal Neural Fields via Scaling Initialization**|神经场是一种新兴的范式，它将数据表示为由神经网络参数化的连续函数。尽管有许多优点，但神经场通常具有较高的训练成本，这阻碍了更广泛的采用。在本文中，我们关注一个流行的神经场家族，称为正弦神经场（SNF），并研究如何初始化它以最大限度地提高训练速度。我们发现，基于信号传播原理设计的SNF标准初始化方案是次优的。特别是，我们证明，通过简单地将每个权重（最后一层除外）乘以一个常数，我们可以将SNF训练加速10 $\times$。这种方法被称为$\textit{weight scaling}$ ，在各种数据域上持续提供显著的加速，使SNF的训练速度比最近提出的架构更快。为了理解为什么权重缩放效果良好，我们进行了广泛的理论和实证分析，结果表明，权重缩放不仅有效地解决了频谱偏差，而且具有良好的优化轨迹。 et.al.|[2410.04779](http://arxiv.org/abs/2410.04779)|null|
|**2024-10-04**|**End-to-End Reaction Field Energy Modeling via Deep Learning based Voxel-to-voxel Transform**|在计算生物化学和生物物理学中，理解静电相互作用的作用对于阐明生物分子的结构、动力学和功能至关重要。泊松-玻尔兹曼（PB）方程是通过描述带电分子内部和周围的静电势来模拟这些相互作用的基础工具。然而，由于生物分子表面的复杂性和需要考虑可移动离子，求解PB方程带来了重大的计算挑战。虽然求解PB方程的传统数值方法是准确的，但它们的计算成本很高，并且随着系统规模的增加而扩展性较差。为了应对这些挑战，我们引入了PBNeF，这是一种新的机器学习方法，灵感来自基于神经网络的偏微分方程求解器的最新进展。我们的方法将PB方程的输入和边界静电条件转化为可学习的体素表示，使神经场变换器能够预测PB解，进而预测反应场势能。大量实验表明，与传统的PB求解器相比，PBNeF的速度提高了100倍以上，同时保持了与广义玻恩（GB）模型相当的精度。 et.al.|[2410.03927](http://arxiv.org/abs/2410.03927)|null|
|**2024-10-08**|**DressRecon: Freeform 4D Human Reconstruction from Monocular Video**|我们提出了一种从单目视频中重建时间一致的人体模型的方法，重点是极其宽松的衣服或手持物体的交互。之前在人体重建方面的工作要么局限于没有物体交互的紧身衣服，要么需要校准的多视图捕捉或个性化的模板扫描，而大规模收集这些数据成本很高。我们对高质量但灵活的重建的关键见解是，将关于关节体形状的通用人类先验（从大规模训练数据中学习）与视频特定的关节“骨骼袋”变形（通过测试时间优化适合单个视频）仔细结合。我们通过学习一个神经隐式模型来实现这一点，该模型将身体和衣服的变形作为单独的运动模型层来解开。为了捕捉服装的微妙几何形状，我们在优化过程中利用了基于图像的先验，如人体姿势、表面法线和光流。由此产生的神经场可以提取到时间一致的网格中，或进一步优化为显式3D高斯分布，以实现高保真交互式渲染。在具有高度挑战性的服装变形和物体交互的数据集上，DressReston可以产生比现有技术更高保真的3D重建。项目页面：https://jefftan969.github.io/dressrecon/ et.al.|[2409.20563](http://arxiv.org/abs/2409.20563)|null|
|**2024-09-25**|**TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans**|我们介绍了一种新的框架，该框架从单眼视频中学习全身说话的人的动态神经辐射场（NeRF）。之前的工作只代表身体姿势或面部。然而，人类通过全身进行交流，结合身体姿势、手势和面部表情。在这项工作中，我们提出了TalkinNeRF，这是一个基于NeRF的统一网络，代表了整体4D人体运动。给定一个受试者的单眼视频，我们学习身体、面部和手的相应模块，这些模块结合在一起生成最终结果。为了捕捉复杂的手指关节，我们学习了手的额外变形场。我们的多身份表示能够同时训练多个科目，以及在完全看不见的姿势下进行强大的动画。只要输入一段短视频，它也可以推广到新的身份。我们展示了最先进的性能，用于为全身说话的人类制作动画，具有精细的手部发音和面部表情。 et.al.|[2409.16666](http://arxiv.org/abs/2409.16666)|null|
|**2024-09-24**|**Generative 3D Cardiac Shape Modelling for In-Silico Trials**|我们提出了一种深度学习方法，基于将形状表示为神经有符号距离场的零级集，对合成主动脉形状进行建模和生成，该方法受一系列可训练的嵌入向量的约束，并对每个形状的几何特征进行编码。通过使神经场在采样表面点上消失并强制其空间梯度具有单位范数，在从CT图像重建的主动脉根部网格数据集上训练网络。实证结果表明，我们的模型可以高保真地表示主动脉形状。此外，通过从学习到的嵌入向量中采样，我们可以生成类似于真实患者解剖结构的新形状，可用于计算机模拟试验。 et.al.|[2409.16058](http://arxiv.org/abs/2409.16058)|null|
|**2024-09-21**|**MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors**|由于缺乏几何指导和不完美的视图相关2D先验，从单眼图像中精确重建密集和语义注释的3D网格仍然是一项具有挑战性的任务。尽管我们已经见证了隐式神经场景表示的最新进展，能够简单地从多视图图像中进行精确的2D渲染，但很少有研究仅使用单眼先验来解决3D场景理解问题。在本文中，我们提出了MOSE，这是一种神经场语义重建方法，可以将推断的图像级噪声先验提升到3D，在3D和2D空间中产生精确的语义和几何。我们方法的关键动机是利用通用类不可知的分段掩码作为指导，在训练过程中促进渲染语义的局部一致性。在语义的帮助下，我们进一步将平滑正则化应用于无纹理区域，以获得更好的几何质量，从而实现几何和语义的互惠互利。在ScanNet数据集上的实验表明，我们的MOSE在3D语义分割、2D语义分割和3D表面重建任务的所有指标上都优于相关基线。 et.al.|[2409.14019](http://arxiv.org/abs/2409.14019)|null|
|**2024-09-17**|**SplatFields: Neural Gaussian Splats for Sparse 3D and 4D Reconstruction**|从多视图图像中数字化3D静态场景和4D动态事件长期以来一直是计算机视觉和图形学领域的一个挑战。最近，3D高斯散斑（3DGS）已经成为一种实用且可扩展的重建方法，由于其令人印象深刻的重建质量、实时渲染能力以及与广泛使用的可视化工具的兼容性而越来越受欢迎。然而，该方法需要大量的输入视图来实现高质量的场景重建，这引入了一个重大的实际瓶颈。在捕捉动态场景时，这一挑战尤为严峻，因为部署广泛的相机阵列的成本可能高得令人望而却步。在这项工作中，我们发现斑点特征缺乏空间自相关性是导致3DGS技术在稀疏重建环境中性能不佳的因素之一。为了解决这个问题，我们提出了一种优化策略，通过将splat特征建模为相应隐式神经场的输出，有效地正则化splat特征。这导致在各种场景中重建质量的一致提高。我们的方法有效地处理了静态和动态情况，这在不同设置和场景复杂性的广泛测试中得到了证明。 et.al.|[2409.11211](http://arxiv.org/abs/2409.11211)|null|
|**2024-10-02**|**Neural Fields for Adaptive Photoacoustic Computed Tomography**|光声计算机断层扫描（PACT）是一种具有广泛医学应用的非侵入性成像技术。传统的PACT图像重建算法受到组织中声速不均匀（SOS）引起的波前失真的影响，导致图像质量下降。考虑到这些影响可以提高图像质量，但测量SOS分布的实验成本很高。另一种方法是仅使用PA信号对初始压力图像和SOS进行联合重建。现有的关节重建方法存在局限性：计算成本高，无法直接恢复SOS，以及依赖于不准确的简化假设。隐式神经表示或神经场是计算机视觉中的一种新兴技术，用于通过基于坐标的神经网络学习物理场的有效和连续表示。在这项工作中，我们介绍了NF-APACT，这是一种高效的自监督框架，利用神经场来估计SOS，以实现准确和鲁棒的多通道解卷积。我们的方法比现有方法更快、更准确地消除了SOS像差。我们在一个新的数值体模以及实验收集的体模和体内数据上证明了我们的方法的成功。我们的代码和数字幻影可在https://github.com/Lukeli0425/NF-APACT. et.al.|[2409.10876](http://arxiv.org/abs/2409.10876)|null|
|**2024-09-09**|**Lagrangian Hashing for Compressed Neural Field Representations**|我们提出了拉格朗日散列，这是一种神经场的表示，结合了依赖于欧拉网格（即~InstantNGP）的快速训练NeRF方法的特征，以及使用配备有特征的点作为表示信息的方法（例如3D高斯散点或PointNeRF）。我们通过将基于点的表示合并到InstantNGP表示的分层哈希表的高分辨率层中来实现这一点。由于我们的点具有影响域，我们的表示可以被解释为哈希表中存储的高斯混合。我们提出的损失鼓励我们的高斯人向需要更多代表预算才能充分代表的地区移动。我们的主要发现是，我们的表示允许使用更紧凑的表示来重建信号，而不会影响质量。 et.al.|[2409.05334](http://arxiv.org/abs/2409.05334)|null|

<p align=right>(<a href=#updated-on-20241021>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

