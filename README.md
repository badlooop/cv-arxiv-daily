[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.12.27
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-26**|**fMPI: Fast Novel View Synthesis in the Wild with Layered Scene Representations**|在这项研究中，我们为基于分层场景表示的新视图合成（NVS）方法提出了两种新的输入处理范式，这两种方法在不影响质量的情况下显著提高了它们的运行时间。我们的方法识别并减轻了传统管道最耗时的两个方面：构建和处理所谓的平面扫描体积（PSV），这是输入相机视图的平面重新投影的高维张量。特别是，我们建议在并行组中处理该张量，以提高计算效率，并对相邻输入平面进行超采样，从而生成更密集、更准确的场景表示。所提出的增强提供了显著的灵活性，允许在性能和速度之间取得平衡，从而朝着实时应用迈出了实质性的步伐。此外，它们非常通用，因为任何基于PSV的方法都可以使用它们，包括使用多平面图像、多球体图像和分层深度图像的方法。在一组全面的实验中，我们证明了我们提出的范式能够设计出一种NVS方法，该方法在公共基准上达到最先进的水平，同时比现有的最先进的方法快50倍。它在速度方面也比目前的前辈高出3倍多，同时实现了明显更好的渲染质量。 et.al.|[2312.16109](http://arxiv.org/abs/2312.16109)|null|
|**2023-12-25**|**Sparse-view CT Reconstruction with 3D Gaussian Volumetric Representation**|稀疏视图CT是减少传统CT扫描辐射剂量的一种很有前途的策略，但从不完整和有噪声的数据中重建高质量图像是一项挑战。最近，3D高斯已被应用于复杂自然场景的建模，与隐式神经表示（INRs）相比，它表现出快速收敛和更好的新颖视图渲染。我们从3D高斯在自然场景建模和新视图合成中的成功应用中获得灵感，研究了它们在稀疏视图CT重建中的潜力。我们利用来自滤波后的反投影重建图像的先验信息来初始化高斯；并且通过比较投影空间中的差异来更新它们的参数。自适应密度控制进一步提高了性能。与INRs相比，3D高斯从先验信息中受益更多，可以明确绕过空白空间中的学习，并有效地分配容量，加速收敛。3D高斯还可以有效地学习高频细节。3D高斯以自我监督的方式进行训练，避免了对大规模配对数据的需要。我们在AAPM-Mayo数据集上的实验表明，与基于INR的方法相比，3D高斯可以提供优越的性能。这项工作正在进行中，代码将公开。 et.al.|[2312.15676](http://arxiv.org/abs/2312.15676)|null|
|**2023-12-22**|**Deformable 3D Gaussian Splatting for Animatable Human Avatars**|神经辐射场的最新进展使得能够在动态设置中对照片真实感图像进行新颖的视图合成，这可以应用于具有人类动画的场景。然而，通常使用的隐式主干来建立准确的模型，需要许多输入视图和额外的注释，如人体遮罩、UV贴图和深度贴图。在这项工作中，我们提出了ParDy Human（参数化动态人类化身），这是一种完全明确的方法，可以从一个单一的单目序列中构建数字化身。ParDy Human在3D高斯飞溅中引入了参数驱动的动力学，其中通过人体姿势模型使3D高斯变形以使化身动画化。我们的方法由两个部分组成：第一个模块根据SMPL顶点使标准3D高斯变形，第二个模块进一步采用其设计的联合编码并预测每高斯变形，以处理SMPL顶点变形之外的动力学。然后通过光栅化器合成图像。ParDy Human构成了逼真动态人类化身的显式模型，其需要显著更少的训练视图和图像。我们的化身学习不需要额外的注释，如掩码，并且可以在可变背景下进行训练，同时即使在消费硬件上也能高效地推断出全分辨率图像。我们提供的实验证据表明，在ZJU MoCap和THUman4.0数据集上，ParDy-Human在数量和视觉上都优于最先进的方法。 et.al.|[2312.15059](http://arxiv.org/abs/2312.15059)|null|
|**2023-12-21**|**PlatoNeRF: 3D Reconstruction in Plato's Cave via Single-View Two-Bounce Lidar**|由于单目线索的模糊性和缺乏关于遮挡区域的信息，从单个视图进行3D重建是具有挑战性的。神经辐射场（NeRF）虽然在视图合成和3D重建中很受欢迎，但通常依赖于多视图图像。现有的使用NeRF进行单视图3D重建的方法要么依赖于数据先验来幻觉被遮挡区域的视图，这在物理上可能不准确，要么依赖于RGB相机观察到的阴影，这在环境光和低反照率背景中很难检测到。我们建议使用单光子雪崩二极管捕获的飞行时间数据来克服这些限制。我们的方法使用NeRF对两个反弹光路进行建模，使用激光雷达瞬态数据进行监督。通过利用激光雷达测量的NeRF和双反射光的优势，我们证明了我们可以在没有数据先验或依赖受控环境照明或场景反照率的情况下重建可见和遮挡的几何结构。此外，我们还展示了在传感器空间和时间分辨率的实际约束下改进的泛化能力。我们相信，随着单光子激光雷达在手机、平板电脑和耳机等消费设备上无处不在，我们的方法是一个很有前途的方向。 et.al.|[2312.14239](http://arxiv.org/abs/2312.14239)|null|
|**2023-12-21**|**SyncDreamer for 3D Reconstruction of Endangered Animal Species with NeRF and NeuS**|本研究的主要目的是演示如何使用创新的视图合成和3D重建技术，使用单目RGB图像创建濒危物种的模型。为了实现这一点，我们使用SyncDreamer来产生独特的视角，并使用NeuS和NeRF来重建3D表示。我们选择了四种不同的动物，包括东方鹳、青蛙、蜻蜓和老虎，作为我们的研究对象。我们的研究结果表明，SyncDreamer、NeRF和NeuS技术的结合可以成功创建濒危动物的3D模型。然而，我们也观察到NeuS产生了模糊的图像，而NeRF产生了更清晰但更嘈杂的图像。这项研究突出了模拟濒危动物的潜力，并为该领域的未来研究提供了新的方向。通过展示这些先进技术的有效性，我们希望鼓励进一步探索和发展保护和研究濒危物种的技术。 et.al.|[2312.13832](http://arxiv.org/abs/2312.13832)|null|
|**2023-12-21**|**DyBluRF: Dynamic Deblurring Neural Radiance Fields for Blurry Monocular Video**|视频视图合成允许从任意视点和时间创建具有视觉吸引力的帧，提供身临其境的观看体验。神经辐射场，特别是最初为静态场景开发的NeRF，刺激了视频视图合成的各种方法的产生。然而，视频视图合成的挑战来自运动模糊，这是物体或相机在曝光过程中移动的结果，阻碍了清晰的时空视图的精确合成。作为回应，我们提出了一种用于模糊单目视频的新的动态去模糊NeRF框架，称为DyBluRF，由Interleave Ray Refinement（IRR）阶段和基于运动分解的去模糊（MDD）阶段组成。我们的DyBluRF是第一个解决和处理模糊单目视频的新型视图合成的公司。IRR阶段联合重建动态3D场景，并细化不准确的相机姿态信息，以对抗从给定模糊帧中提取的不准确姿态信息。MDD阶段是一种新的增量潜在锐射线预测（ILSP）方法，用于模糊单目视频帧，将潜在锐射线分解为全局相机运动和局部对象运动分量。大量的实验结果表明，我们的DyBluRF在质量和数量上都优于最新的最先进的方法。我们的项目页面包括源代码和预训练模型，可在https://kaist-viclab.github.io/dyblurf-site/. et.al.|[2312.13528](http://arxiv.org/abs/2312.13528)|null|
|**2023-12-20**|**NeRF-VO: Real-Time Sparse Visual Odometry with Neural Radiance Fields**|我们介绍了一种新的单目视觉里程计（VO）系统NeRF VO，该系统集成了用于低延迟相机跟踪的基于学习的稀疏视觉里程计和用于复杂密集重建和新颖视图合成的神经辐射场景表示。我们的系统使用稀疏视觉里程计初始化相机姿态，并从单目深度预测网络中获得与视图相关的密集几何先验。我们协调姿势的尺度和密集的几何体，将它们视为训练神经隐式场景表示的监督线索。NeRF VO通过联合优化关键帧姿势的滑动窗口和底层密集几何体，在场景表示的光度和几何保真度方面表现出非凡的性能，这是通过使用体渲染训练辐射场来实现的。我们在各种合成和真实世界数据集的姿态估计精度、新颖的视图合成保真度和密集的重建质量方面超过了最先进的方法，同时实现了更高的相机跟踪频率和更少的GPU内存消耗。 et.al.|[2312.13471](http://arxiv.org/abs/2312.13471)|null|
|**2023-12-20**|**SWAGS: Sampling Windows Adaptively for Dynamic 3D Gaussian Splatting**|最近，新的视图合成显示出快速的进展，其方法能够产生越来越逼真的结果。3D高斯飞溅已成为一种特别有前途的方法，可以产生高质量的静态场景渲染，并实现实时帧率的交互式观看。然而，它目前仅限于静态场景。在这项工作中，我们扩展了三维高斯飞溅来重建动态场景。我们使用可调MLP对场景的动力学进行建模，该MLP学习从规范空间到每帧一组3D高斯的变形场。为了理清场景的静态和动态部分，我们为每个高斯学习一个可调谐的参数，该参数对各自的MLP参数进行加权，以将注意力集中在动态部分上。这提高了模型在静态区域与动态区域不平衡的场景中捕捉动态的能力。为了处理任意长度的场景，同时保持高渲染质量，我们引入了一种自适应窗口采样策略，根据序列中的移动量将序列划分为多个窗口。我们为每个窗口训练一个单独的动态高斯飞溅模型，允许规范表示发生变化，从而能够重建具有显著几何或拓扑变化的场景。在随机采样的新视图上，使用具有自监督一致性损失的微调步骤来增强时间一致性。因此，我们的方法可以生成具有竞争性定量性能的一般动态场景的高质量渲染图，可以使用我们的动态交互式查看器实时查看。 et.al.|[2312.13308](http://arxiv.org/abs/2312.13308)|null|
|**2023-12-22**|**DiffPortrait3D: Controllable Diffusion for Zero-Shot Portrait View Synthesis**|我们提出了DiffPortrait3D，这是一种条件扩散模型，能够从野生肖像中的一张照片中合成3D一致的照片逼真的新颖视图。具体来说，在给定单个RGB输入的情况下，我们的目标是合成从新颖的相机视图中呈现的看似合理但一致的面部细节，同时保留身份和面部表情。除了耗时的优化和微调外，我们的零样本方法很好地推广到任意面部肖像，具有无污染的相机视图、极端的面部表情和多样化的艺术描绘。其核心是，我们利用在大规模图像数据集上预先训练的2D扩散模型的生成先验作为我们的渲染骨干，而去噪是通过对外观和相机姿态的细致控制来指导的。为了实现这一点，我们首先将参考图像的外观上下文注入冻结的UNets的自关注层。然后利用新颖的条件控制模块来操纵渲染视图，该条件控制模块通过从同一视图观看交叉对象的条件图像来解释相机姿态。此外，我们插入了一个可训练的跨视图注意力模块来增强视图一致性，在推理过程中，通过一个新颖的3D感知噪声生成过程进一步增强了视图一致性。我们在野外和多视图基准测试中展示了最先进的定性和定量结果。 et.al.|[2312.13016](http://arxiv.org/abs/2312.13016)|**[link](https://github.com/FreedomGu/DiffPortrait3D)**|
|**2023-12-20**|**Radar Fields: An Extension of Radiance Fields to SAR**|辐射场是多视图图像采集中复杂场景的反向渲染、新颖视图合成和3D建模领域的一个重大突破。自从它们被引入以来，已经表明它们可以扩展到其他模式，如激光雷达、射频、X射线或超声波。在本文中，我们表明，尽管光学和合成孔径雷达（SAR）图像形成模型之间存在重要差异，但有可能将辐射场扩展到雷达图像，从而呈现第一个“雷达场”。这使我们能够仅使用雷达图像的集合来学习表面模型，类似于规则辐射场的学习方式，并且平均具有相同的计算复杂度。由于这两个领域的定义方式相似，这项工作也显示了将光学图像和SAR图像相结合的混合方法的潜力。 et.al.|[2312.12961](http://arxiv.org/abs/2312.12961)|null|

<p align=right>(<a href=#updated-on-20231227>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-24**|**A theory of volumetric representations for opaque solids**|我们开发了一种将不透明固体表示为体积模型的理论。从不透明固体作为随机指示函数的随机表示开始，我们证明了可以使用指数体积输运对这种固体进行建模的条件。我们还导出了体积衰减系数的表达式，作为基本指标函数的概率分布的函数。我们将我们的理论推广到考虑固体不同部分的各向同性和各向异性散射，以及将不透明固体表示为隐式表面。我们从第一性原理推导出体积表示，这确保了它满足物理约束，如互易性和可逆性。我们使用我们的理论来解释、比较和纠正以前的体积表示，并提出有意义的扩展，从而提高3D重建任务的性能。 et.al.|[2312.15406](http://arxiv.org/abs/2312.15406)|null|
|**2023-12-23**|**WildScenes: A Benchmark for 2D and 3D Semantic Segmentation in Large-scale Natural Environments**|语义场景理解的最新进展主要得益于城市环境中语义注释的双模（相机和激光雷达）数据集的可用性。然而，自然、非结构化环境也需要这样的注释数据集，以实现应用程序的语义感知，包括保护、搜救、环境监测和农业自动化。因此，我们介绍了WildScenes，这是一个双模态基准数据集，由自然环境中的多个大规模遍历组成，包括高分辨率2D图像和密集3D激光雷达点云中的语义注释，以及精确的6-DoF姿态信息。数据（1）以轨迹为中心，具有精确的定位和全局对齐的点云，（2）校准和同步以支持双模态推理，以及（3）在6个月内包含不同的自然环境，以支持领域适应研究。我们的3D语义标签是通过一个高效的自动化过程获得的，该过程将人工注释的2D标签从多个视图转移到3D点云中，从而避免了在3D中进行昂贵且耗时的人工注释的需要。我们介绍了2D和3D语义分割的基准，并评估了最近的各种深度学习技术，以展示自然环境中语义分割的挑战。我们建议为标准基准和领域自适应基准训练val测试分割，并利用自动分割生成技术来确保类标签分布的平衡。数据、评估脚本和预训练模型将在https://csiro-robotics.github.io/WildScenes. et.al.|[2312.15364](http://arxiv.org/abs/2312.15364)|null|
|**2023-12-22**|**Enhanced Latent Multi-view Subspace Clustering**|潜在多视图子空间聚类已被证明具有理想的聚类性能。然而，原始的潜在表示方法沿着维度方向将来自多个视图的数据矩阵垂直连接到单个矩阵中，以恢复潜在表示矩阵，这可能导致不完整的信息恢复。为了完全恢复潜在空间表示，我们在本文中提出了一种增强的潜在多视图子空间聚类（ELMSC）方法。ELMSC方法包括构建增强数据矩阵，该矩阵增强多视图数据的表示。具体来说，我们将来自不同视图的数据矩阵堆叠到增广矩阵的块对角位置，以利用互补信息。同时，基于不同视图之间的相似性来组合非块对角条目，以获取一致的信息。此外，我们对增广自表示矩阵的非对角块强制执行稀疏正则化，以避免一致性信息的冗余计算。最后，基于交替方向乘法器（ADMM）的框架，提出了一种新的迭代算法来解决ELMSC的优化问题。在真实世界数据集上的大量实验表明，我们提出的ELMSC能够实现比一些现有技术的多视图聚类方法更高的聚类性能。 et.al.|[2312.14763](http://arxiv.org/abs/2312.14763)|**[link](https://github.com/caolei2000/elmsc-code)**|
|**2023-12-22**|**BonnBeetClouds3D: A Dataset Towards Point Cloud-based Organ-level Phenotyping of Sugar Beet Plants under Field Conditions**|未来几十年，农业生产面临着气候变化和可持续性需求带来的严峻挑战，从而减少其对环境的影响。通过机器人的非化学除草，结合自动无人机对作物的监测，以及培育新的、更具弹性的作物品种，在田间管理方面取得了进展，这有助于应对这些挑战。植物性状的分析，即表型分析，是植物育种中的一项重要活动，但它需要大量的体力劳动。通过这篇论文，我们解决了精确表型所需的自动细粒度器官级几何分析的问题。由于该领域的真实世界数据相对较少，我们提出了一个新的数据集，该数据集是使用无人机获取的，该无人机捕捉了包含48个植物品种的真实育种试验的高分辨率图像，因此涵盖了巨大的形态和外观多样性。这使得自主表型的方法能够很好地推广到不同的品种。基于多个视角的重叠高分辨率图像，我们计算了摄影测量密集点云，并为植物、叶子和作为尖端和底部的突出点提供了详细准确的逐点标签。此外，我们还包括德国联邦植物品种办公室的专家对真实植物进行的表型性状测量，从而不仅可以评估分割和关键点检测方面的新方法，还可以直接评估下游任务。所提供的标记点云能够进行细粒度的植物分析，并支持自动表型方法开发的进一步进展，但也能够在表面重建、点云完成和点云的语义解释方面进行进一步研究。 et.al.|[2312.14706](http://arxiv.org/abs/2312.14706)|null|
|**2023-12-22**|**Pola4All: survey of polarimetric applications and an open-source toolkit to analyze polarization**|光的偏振信息可以为计算机视觉和场景理解任务提供丰富的线索，例如物体的材料类型、姿势和形状。随着新的廉价偏振传感器的出现，这种成像方式越来越容易被更广泛的公众所使用，以解决诸如姿态估计、3D重建、水下导航和深度估计等问题。然而，我们观察到这种感觉模态的使用存在一些局限性，并且缺乏分析偏振图像的标准和公开可用的工具。此外，尽管偏振相机制造商通常提供采集工具来与他们的相机接口，但他们很少包括利用偏振信息的处理算法。在这篇论文中，我们回顾了偏振成像应用的最新进展，包括对视觉和机器人感知任务的偏振最新进展的全面调查。我们还介绍了一个完整的软件工具包，该工具包提供了与市场上大多数现有微栅格偏振相机通信和处理信息的通用标准。该工具包还为这种模式实现了几种图像处理算法，并在GitHub上公开提供：https://github.com/vibot-lab/Pola4all_JEI_2023. et.al.|[2312.14697](http://arxiv.org/abs/2312.14697)|null|
|**2023-12-22**|**Scalable 3D Reconstruction From Single Particle X-Ray Diffraction Images Based on Online Machine Learning**|X射线自由电子激光器（XFEL）为测量生物分子的结构和动力学提供了独特的能力，帮助我们理解生命的基本组成部分。值得注意的是，高重复率XFEL实现了单粒子成像（X射线SPI），其中单个弱散射生物分子在接近生理条件下成像，有机会进入在低温或结晶条件下无法捕获的短暂状态。现有的X射线SPI重建算法估计每个捕获图像中粒子的未知方向及其共享的3D结构，不足以处理这些新兴XFEL生成的海量数据集。在这里，我们介绍了X-RAI，这是一种在线重建框架，可以从大型X射线SPI数据集中估计3D大分子的结构。X-RAI由卷积编码器和基于物理的解码器组成，卷积编码器在大型数据集上分摊姿态估计，解码器采用隐式神经表示，以端到端、自监督的方式实现高质量的3D重建。我们证明了X-RAI在模拟和具有挑战性的实验环境中为小规模数据集实现了最先进的性能，并证明了其以在线方式处理包含数百万衍射图像的大型数据集的前所未有的能力。这些能力意味着X射线SPI向实时捕获和重建的范式转变。 et.al.|[2312.14432](http://arxiv.org/abs/2312.14432)|null|
|**2023-12-22**|**Towards an Exploratory Visual Analytics System for Griefer Identification in MOBA Games**|多人在线战斗竞技场（MOBA）在全球范围内获得了大量玩家，年游戏收入超过20亿美元。然而，故意激怒和骚扰游戏中其他玩家的骗子的存在可能会对玩家的体验产生不利影响，损害游戏的公平性，并可能导致灰色产业的出现。不幸的是，由于缺乏标准化的标准，以及缺乏高质量的标记和注释数据，检测灰蝶的存在具有挑战性。考虑到MOBA游戏的多变量时空数据的复杂性，游戏开发者在很大程度上依赖于对整个游戏视频记录的手动审查来标记和注释griefers，这是一个耗时的过程。为了缓解这个问题，我们与游戏专家团队合作开发了一个名为GrieferLens的交互式视觉分析界面。它概述了球员的行为分析，并综合了他们的关键比赛事件。通过呈现多个信息视图，GrieferLens可以帮助游戏设计团队有效识别和标记MOBA游戏中的Griefer，并为创造更愉快、更公平的游戏环境奠定基础。 et.al.|[2312.14401](http://arxiv.org/abs/2312.14401)|null|
|**2023-12-21**|**PlatoNeRF: 3D Reconstruction in Plato's Cave via Single-View Two-Bounce Lidar**|由于单目线索的模糊性和缺乏关于遮挡区域的信息，从单个视图进行3D重建是具有挑战性的。神经辐射场（NeRF）虽然在视图合成和3D重建中很受欢迎，但通常依赖于多视图图像。现有的使用NeRF进行单视图3D重建的方法要么依赖于数据先验来幻觉被遮挡区域的视图，这在物理上可能不准确，要么依赖于RGB相机观察到的阴影，这在环境光和低反照率背景中很难检测到。我们建议使用单光子雪崩二极管捕获的飞行时间数据来克服这些限制。我们的方法使用NeRF对两个反弹光路进行建模，使用激光雷达瞬态数据进行监督。通过利用激光雷达测量的NeRF和双反射光的优势，我们证明了我们可以在没有数据先验或依赖受控环境照明或场景反照率的情况下重建可见和遮挡的几何结构。此外，我们还展示了在传感器空间和时间分辨率的实际约束下改进的泛化能力。我们相信，随着单光子激光雷达在手机、平板电脑和耳机等消费设备上无处不在，我们的方法是一个很有前途的方向。 et.al.|[2312.14239](http://arxiv.org/abs/2312.14239)|null|
|**2023-12-21**|**3D Pose Estimation of Two Interacting Hands from a Monocular Event Camera**|由于手的相互作用、遮挡、左右手模糊和快速运动，单目视频中的3D手跟踪是一个非常具有挑战性的问题。大多数现有的方法都依赖于RGB输入，而RGB输入在弱光条件下具有严重的局限性，并且存在运动模糊。相比之下，事件相机捕捉局部亮度变化而不是完整的图像帧，并且不会受到所描述的效果的影响。不幸的是，由于数据模态的显著差异，现有的基于图像的技术不能直接应用于事件。为了应对这些挑战，本文介绍了第一个从单目事件相机对两个快速移动和相互作用的手进行3D跟踪的框架。我们的方法使用一种新颖的半监督特征式注意力机制来解决左右手模糊问题，并集成交叉点损失来修复手碰撞。为了促进这一研究领域的进展，我们发布了一个由两只相互作用的手组成的新的合成大规模数据集Ev2Hands-S，以及一个具有真实事件流和地面实况3D注释的新的真实基准Ev2Hands-R。在3D重建精度方面，我们的方法优于现有方法，并在恶劣的光照条件下推广到真实数据。 et.al.|[2312.14157](http://arxiv.org/abs/2312.14157)|null|
|**2023-12-21**|**DUSt3R: Geometric 3D Vision Made Easy**|野外的多视角立体重建（MVS）需要首先估计相机参数，例如内在和外在参数。这些通常是乏味和繁琐的，但它们必须在3D空间中对相应的像素进行三角测量，这是所有性能最好的MVS算法的核心。在这项工作中，我们采取了相反的立场，并引入了DUSt3R，这是一种对任意图像集合进行密集和无约束立体3D重建的全新范式，即在没有关于相机校准或视点姿态的先验信息的情况下操作。我们将成对重建问题视为点图的回归，放松了通常投影相机模型的硬约束。我们证明了这个公式平滑地统一了单目和双目重建的情况。在提供两个以上图像的情况下，我们进一步提出了一种简单而有效的全局对齐策略，该策略在公共参考系中表达所有成对的点图。我们的网络架构基于标准的Transformer编码器和解码器，使我们能够利用强大的预训练模型。我们的公式直接提供了场景的3D模型以及深度信息，但有趣的是，我们可以从中无缝恢复，像素匹配，相对和绝对相机。对所有这些任务的详尽实验表明，所提出的DUSt3R可以统一各种3D视觉任务，并在单目/多视角深度估计和相对姿态估计上设置新的SoTA。总之，DUSt3R使许多几何三维视觉任务变得容易。 et.al.|[2312.14132](http://arxiv.org/abs/2312.14132)|null|

<p align=right>(<a href=#updated-on-20231227>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-26**|**One-dimensional Adapter to Rule Them All: Concepts, Diffusion Models and Erasing Applications**|用于文本到图像生成的商业和开源扩散模型（DM）的普遍使用促使风险缓解以防止不期望的行为。学术界现有的概念擦除方法都是基于全参数或基于规范的微调，从中我们观察到以下问题：1）向侵蚀的生成交替：目标消除过程中的参数漂移导致所有生成的交替和潜在变形，甚至不同程度地侵蚀其他概念，这一点在多概念消除后更为明显；2） 转移能力和部署效率低下：以前的特定于模型的擦除阻碍了概念的灵活组合和向其他模型的无训练转移，导致随着部署场景的增加，成本线性增长。为了实现非侵入性、精确、可定制和可转移的消除，我们将擦除框架建立在一维适配器上，以便在多功能擦除应用程序中同时从大多数DM中擦除多个概念。将概念半渗透结构作为膜（SPM）注入到任何DM中，以学习有针对性的擦除，同时通过一种新的潜在锚定微调策略有效地缓解了变化和侵蚀现象。一旦获得，SPM可以灵活组合，并为其他DM即插即用，而无需特定的重新调整，从而能够及时有效地适应不同的场景。在生成过程中，我们的促进传输机制动态调节每个SPM的渗透率，以响应不同的输入提示，进一步将对其他概念的影响降至最低。40个概念、7个DM和4个擦除应用程序的定量和定性结果证明了SPM的卓越擦除。我们的代码和预调SPM将在项目页面上提供https://lyumengyao.github.io/projects/spm. et.al.|[2312.16145](http://arxiv.org/abs/2312.16145)|null|
|**2023-12-26**|**Morse index of steady-states to the SKT model with Dirichlet boundary conditions**|本文讨论了在Dirichlet边界条件下受SKT模型全交叉扩散极限扰动的稳态的稳定性分析。我们先前的结果表明，正稳态由从平凡解分叉的小共存型分支和从小共存型分枝上的点分叉的分离型分支组成。本文给出了分支上稳态的Morse指数，并围绕每个稳态构造了维数等于Morse指数的局部不稳定流形。 et.al.|[2312.16107](http://arxiv.org/abs/2312.16107)|null|
|**2023-12-26**|**Mathematical analysis and multiscale derivation of a nonlinear predator-prey cross-diffusion--fluid system with two chemicals**|本文提出了一个具有化学项的非线性交叉扩散流体系统来描述牛顿流体中捕食者-猎物的动力学。基于Schauder不动点理论、先验估计和紧性论证，证明了所提出的宏观系统弱解的存在性。所提出的系统是通过多尺度方法从动力学流体理论模型提供的基本描述中导出的。最后，我们讨论了所提出的宏观尺度系统在二维空间中的计算结果。 et.al.|[2312.16092](http://arxiv.org/abs/2312.16092)|null|
|**2023-12-26**|**Stronger resilience to disorder in 2D quantum walks than in 1D**|我们研究了二维离散时间量子行走的传播行为对跳跃长度中玻璃态无序的响应。我们考虑不同的离散概率分布来模拟无序，并考虑三种类型的硬币算子，即Grover、傅立叶和Hadamard，来分析无序平均扩展的尺度指数。我们发现，在无序的情况下，干净步行的弹道传播受到抑制，并且步行变为亚弹道，但仍具有超扩散性。与一维相同相比，对于所有考虑的硬币操作，二维行走对无序诱导的抑制的弹性更强。因此，量子行走的量子优势在二维比在一维更安全。 et.al.|[2312.16076](http://arxiv.org/abs/2312.16076)|null|
|**2023-12-26**|**Compositional Search of Stable Crystalline Structures in Multi-Component Alloys Using Generative Diffusion Models**|由于涉及耗时的程序，探索多组分合金的广阔组成空间对从头算（第一性原理）和实验方法来说都是一项具有挑战性的任务。这最终阻碍了可能表现出特殊性能的新型稳定材料的发现。这里，晶体扩散变分自动编码器（CDVAE）模型适用于表征经过充分研究的多组分合金NiFeCr的稳定成分，该合金具有两个不同的晶相，已知在其组成空间内是稳定的。为此，提出了对CDVAE的新扩展，将模型从测试集中的潜在空间重构配置的能力提高了约30%。这一事实增加了模型在处理各种晶体结构时发现新材料的概率。然后，将新模型应用于材料生成，与第一性原理数据相比，在识别三元相空间内的稳定构型方面表现出了极好的一致性。最后，提出了一种计算高效的逆向设计框架，采用分子动力学（MD）模拟具有可靠原子间势的多组分合金，从而能够优化整个相空间的材料性能。 et.al.|[2312.16073](http://arxiv.org/abs/2312.16073)|null|
|**2023-12-26**|**HarmonyView: Harmonizing Consistency and Diversity in One-Image-to-3D**|单图像3D生成的最新进展突出了多视图一致性的重要性，利用了在互联网规模的图像上预训练的大规模扩散模型的3D先验。然而，由于在将2D图像转换为3D内容时存在歧义，可能会出现许多潜在的形状，因此在研究领域中，新颖视角多样性的方面仍然没有得到充分的探索。在这里，我们的目标是通过同时解决一致性和多样性来解决这一研究差距。然而，在这两个方面之间取得平衡是一个相当大的挑战，因为它们之间存在固有的权衡。这项工作介绍了HarmonyView，这是一种简单而有效的扩散采样技术，擅长分解单图像3D生成中的两个复杂方面：一致性和多样性。这种方法为更细致地探索采样过程中的两个关键维度铺平了道路。此外，我们提出了一种基于CLIP图像和文本编码器的新评估指标，以全面评估生成视图的多样性，这与人类评估者的判断密切一致。在实验中，HarmonyView实现了和谐的平衡，展示了一致性和多样性的双赢场景。 et.al.|[2312.15980](http://arxiv.org/abs/2312.15980)|null|
|**2023-12-26**|**Filtered data based estimators for stochastic processes driven by colored noise**|在给定连续时间观测的情况下，我们考虑了有色噪声驱动的随机微分方程中未知参数的估计问题。有色噪声被建模为具有指数自相关函数的均值为零的高斯平稳过程序列，具有递减的相关时间。我们的目标是在给定有色噪声动力学观测值的情况下，推断由白噪声驱动的极限方程中的参数。与多尺度扩散的参数估计的情况一样，观测值仅与白噪声极限中的数据兼容，并且经典估计量变得有偏差，这意味着需要对数据进行预处理。我们考虑了连续时间估计量中的最大似然和随机梯度下降，并提出了这些方法的修改版本，其中使用指数滤波器对观测值进行滤波。同时考虑了具有加性噪声和乘性噪声的随机微分方程。我们对我们的新估计量在无限数据极限和白噪声极限下的收敛性进行了分析，证明了估计量是渐近无偏的。我们详细考虑了乘性有色噪声的情况，特别是当L’evy区域校正漂移出现在极限白噪声方程中时。一系列数值实验证实了我们的理论结果。 et.al.|[2312.15975](http://arxiv.org/abs/2312.15975)|null|
|**2023-12-26**|**Semantic Guidance Tuning for Text-To-Image Diffusion Models**|文本到图像（T2I）扩散模型的最新进展表明，在生成具有零样本泛化能力的高质量图像方面取得了令人印象深刻的成功。然而，当前的模型很难严格遵守提示语义，经常歪曲或忽略特定的属性。为了解决这一问题，我们提出了一种简单的、无需训练的方法，该方法在推理过程中调节扩散模型的引导方向。我们首先将提示语义分解为一组概念，并监控与每个概念相关的引导轨迹。我们的关键观察结果是，模型对提示语义的遵守程度的偏差与这些概念中的一个或多个概念的指导意见的偏差高度相关。基于这一观察结果，我们设计了一种技术，将引导方向引向模型偏离的任何概念。大量实验验证了我们的方法改进了扩散模型响应提示生成的图像的语义对齐。项目页面位于：https://korguy.github.io/ et.al.|[2312.15964](http://arxiv.org/abs/2312.15964)|null|
|**2023-12-26**|**Implied volatility (also) is path-dependent**|我们提出了一个新的模型，用于对隐含波动率表面和基础资产回报进行一致预测。Guyon和Lekeufack（2023）对波动率指数（如波动率指数）对相关股票指数（如标准普尔500指数）路径的依赖性感兴趣，本着他们的精神，我们首先研究了如何使用基础资产价格的过去轨迹来预测隐含波动率。我们的实证研究表明，两年到期的货币远期隐含波动率的大部分变动可以用过去的收益率及其平方来解释。此外，我们还表明，应该使用基础价格过去四年的演变来进行预测，并且当成熟度增加时，这种反馈效应会减弱。在这个新的程式化事实的基础上，我们将仅依赖于四个参数的隐含波动率表面的SSVI参数化（Gatheral和Jacquir，2014）的简约版本拟合到历史数据中，并表明作为到期日函数的货币远期隐含波动率的两个参数相对于基础资产价格表现出路径依赖行为。最后，我们提出了一个隐含波动率表面和基础资产价格的联合动力学模型。后者是使用Guyon和Lekeufack的路径相关波动率模型的变体进行建模的，前者是通过将基础资产价格的反馈效应添加到简约SSVI参数化中支配货币远期隐含波动率的两个参数上，并通过为这两个参数的残差指定隐藏的半马尔可夫扩散模型来获得的以及另外两个参数。由于这个模型，我们能够模拟无套利的隐含波动率表面的高度现实的路径。 et.al.|[2312.15950](http://arxiv.org/abs/2312.15950)|null|
|**2023-12-26**|**EnchantDance: Unveiling the Potential of Music-Driven Dance Movement**|音乐驱动的舞蹈生成任务包括创建与给定音乐相对应的连贯舞蹈动作。虽然现有的方法可以产生物理上看似合理的舞蹈，但它们往往难以推广到集合外的数据。挑战来自三个方面：1）舞蹈动作的高度多样性和音乐形式分布的显著差异，这使得很难产生与音乐一致的舞蹈动作。2） 缺乏大规模的音乐舞蹈数据集，阻碍了从音乐中生成广义舞蹈动作。3） 舞蹈动作的持久性对保持一致的舞蹈风格提出了挑战。在这项工作中，我们介绍了EnchantDance框架，这是一种最先进的舞蹈生成方法。由于原始舞蹈序列沿时间轴的冗余性，EnchantDance首先构建了一个强大的舞蹈潜在空间，然后在舞蹈潜在空间上训练舞蹈扩散模型。为了解决数据缺口，我们构建了一个大型音乐舞蹈数据集ChoreoSpectrum3D数据集，该数据集包括四种舞蹈流派，总时长为70.32小时，是迄今为止报道的最大的音乐舞蹈数据集中。为了增强音乐流派和舞蹈风格之间的一致性，我们使用迁移学习预训练音乐流派预测网络，并在舞蹈扩散模型的训练中加入音乐流派作为额外的条件信息。大量实验表明，我们提出的框架在舞蹈质量、多样性和一致性方面达到了最先进的性能。 et.al.|[2312.15946](http://arxiv.org/abs/2312.15946)|null|

<p align=right>(<a href=#updated-on-20231227>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-22**|**Fluid Simulation on Neural Flow Maps**|我们介绍了神经流图，这是一种新的模拟方法，将新兴的隐式神经表示范式与基于流图理论的流体模拟相结合，以实现最先进的无粘流体现象模拟。我们设计了一种新的混合神经场表示，空间稀疏神经场（SSNF），它将小型神经网络与重叠、多分辨率和空间稀疏网格的金字塔相融合，以高精度紧凑地表示长期时空速度场。有了这个神经速度缓冲器，我们以机械对称的方式计算长期双向流图及其雅可比矩阵，以促进对现有解决方案的大幅精度提高。这些长程双向流图实现了低耗散的高平流精度，进而促进了高保真度的不可压缩流模拟，显示了复杂的旋涡结构。我们展示了我们的神经流体模拟在各种具有挑战性的模拟场景中的有效性，包括跳跃涡流、碰撞涡流、涡流重新连接，以及移动障碍物和密度差异产生的涡流。我们的例子表明，在能量守恒、视觉复杂性、对实验观测的遵守以及详细旋涡结构的保存方面，与现有方法相比，性能有所提高。 et.al.|[2312.14635](http://arxiv.org/abs/2312.14635)|null|
|**2023-12-21**|**Geometric Awareness in Neural Fields for 3D Human Registration**|将模板与三维人体点云对齐是一个长期存在的问题，对于动画、重建和启用监督学习管道等任务至关重要。最近的数据驱动方法利用了预测的表面对应关系；然而，它们对不同的姿态或分布并不鲁棒。相比之下，工业解决方案往往依赖于昂贵的手动注释或多视图捕获系统。最近，神经场已经显示出有希望的结果，但它们纯粹的数据驱动性质缺乏几何意识，通常导致模板配准的微小错位。在这项工作中，我们提出了两种解决方案：LoVD，一种新的神经场模型，它预测朝向目标表面上的局部SMPL顶点的方向；和INT，这是第一个专门用于神经领域的自监督任务，在测试时，它利用目标几何结构来细化主干。我们将它们组合到INLoVD中，这是一个在大型MoCap数据集上训练的强大的3D人体注册管道。INLoVD是高效的（不到一分钟），在公共基准上稳定地达到了最先进的水平，并对分布外的数据提供了前所未有的概括。我们将在\url｛url｝中发布代码和检查点。 et.al.|[2312.14024](http://arxiv.org/abs/2312.14024)|null|
|**2023-12-20**|**Neural feels with neural fields: Visuo-tactile perception for in-hand manipulation**|为了实现人类水平的灵活性，机器人必须从多模式感知推断空间意识，以推理接触互动。在新物体的手操作过程中，这种空间意识包括估计物体的姿势和形状。手内感知的现状主要采用视觉，并局限于跟踪先验已知对象。此外，在操作过程中，手上物体的视觉遮挡迫在眉睫，这阻止了当前系统在没有遮挡的情况下超越任务。我们将多指手的视觉和触摸传感相结合，在手内操作过程中估计物体的姿势和形状。我们的方法NeuralFeels通过在线学习神经场来编码对象几何，并通过优化姿态图问题来联合跟踪它。我们研究了模拟和现实世界中的多模式手部感知，通过本体感觉驱动的策略与不同的物体进行交互。我们的实验显示，使用已知的CAD模型，最终重建F分数为 $81$%，平均姿势漂移为$4.7\，\text｛mm｝$，进一步降低到$2.3\，\text{mm｝$。此外，我们观察到，与仅使用视觉的方法相比，在严重的视觉遮挡下，我们可以实现高达94$ %的跟踪改进。我们的研究结果表明，在手部操作过程中，触摸至少可以改善视觉估计，并在最好的情况下消除视觉估计的歧义。我们发布了70个实验的评估数据集FeelSight，作为在该领域进行基准测试的一步。我们由多模态感知驱动的神经表示可以作为提高机器人灵活性的感知支柱。视频可以在我们的项目网站上找到https://suddhu.github.io/neural-feels/ et.al.|[2312.13469](http://arxiv.org/abs/2312.13469)|null|
|**2023-12-20**|**Deep Learning on 3D Neural Fields**|近年来，神经场（NFs）已成为编码各种连续信号（如图像、视频、音频和3D形状）的有效工具。当应用于3D数据时，NFs提供了一种解决方案来解决与流行的离散表示相关的碎片化和局限性。然而，鉴于神经网络本质上是神经网络，目前尚不清楚它们是否以及如何无缝集成到深度学习管道中，以解决下游任务。本文解决了这一研究问题，并介绍了nf2vec，这是一个能够在单个推理过程中为输入NF生成紧凑的潜在表示的框架，同时专门处理NFs。我们在几个用于表示3D曲面的NFs上测试了这个框架，例如无符号/有符号距离和占用字段。此外，我们用更复杂的NFs证明了我们的方法的有效性，这些NFs包括3D对象的几何形状和外观，如神经辐射场。 et.al.|[2312.13277](http://arxiv.org/abs/2312.13277)|null|
|**2023-12-16**|**How to Train Neural Field Representations: A Comprehensive Study and Benchmark**|神经场（NeFs）最近已成为一种用于对各种模态（包括图像、形状和场景）的信号进行建模的通用方法。随后，许多工作探索了使用NeF作为下游任务的表示，例如，根据适合的NeF的参数对图像进行分类。然而，NeF超参数对其作为下游表示的质量的影响很少被理解，而且在很大程度上仍未被探索。这在一定程度上是由于拟合神经场数据集所需的大量时间造成的。在这项工作中，我们提出了 $\verb|fit-a-nef|$ ，这是一个基于JAX的库，它利用并行化来实现大规模nef数据集的快速优化，从而显著加快速度。有了这个库，我们进行了一项全面的研究，研究了不同超参数——包括初始化、网络架构和优化策略——对下游任务的NeF拟合的影响。我们的研究为如何训练NeF提供了宝贵的见解，并为优化其在下游应用中的有效性提供了指导。最后，基于所提出的库和我们的分析，我们提出了Neural Field Arena，这是一个由流行视觉数据集的神经场变体组成的基准，包括MNIST、CIFAR、ImageNet和ShapeNetv2的变体。我们的图书馆和神经领域竞技场将是开源的，以引入标准化的基准测试，并促进对神经领域的进一步研究。 et.al.|[2312.10531](http://arxiv.org/abs/2312.10531)|**[link](https://github.com/samuelepapa/fit-a-nef)**|
|**2023-12-18**|**LatentEditor: Text Driven Local Editing of 3D Scenes**|虽然神经领域在视图合成和场景重建方面取得了重大进展，但由于其对来自多视图输入的几何和纹理信息的隐式编码，编辑它们带来了巨大的挑战。在本文中，我们介绍了\textsc｛LatentEditor｝，这是一个创新的框架，旨在让用户能够使用文本提示对神经字段进行精确和本地控制的编辑。利用去噪扩散模型，我们成功地将真实世界的场景嵌入到潜在空间中，与传统方法相比，产生了更快、更具适应性的NeRF主干进行编辑。为了提高编辑精度，我们引入了一个delta分数来计算潜在空间中的2D掩模，该分数可以作为局部修改的指南，同时保留不相关的区域。我们新颖的像素级评分方法利用InstructPix2Pix（IP2P）的能力来辨别潜在空间中IP2P条件和无条件噪声预测之间的差异。然后在训练集中迭代地更新以2D掩码为条件的编辑的潜伏时间，以实现3D局部编辑。与现有的3D编辑模型相比，我们的方法实现了更快的编辑速度和卓越的输出质量，弥合了文本指令和潜在空间中高质量3D场景编辑之间的差距。我们在LLFF、IN2N、NeRFStudio和NeRFArt四个基准3D数据集上展示了我们的方法的优势。 et.al.|[2312.09313](http://arxiv.org/abs/2312.09313)|**[link](https://github.com/umarkhalidAI/LatentEditor)**|
|**2023-12-14**|**ZeroRF: Fast Sparse View 360° Reconstruction with Zero Pretraining**|我们提出了ZeroRF，这是一种新的每场景优化方法，解决了神经场表示中稀疏视图360重建的挑战。目前的突破，如神经辐射场（NeRF）已经证明了高保真度的图像合成，但难以处理稀疏的输入视图。现有的方法，如可泛化的NeRF和每场景优化方法，在数据依赖性、计算成本和跨不同场景的泛化方面面临限制。为了克服这些挑战，我们提出了ZeroRF，其关键思想是将定制的深度图像先验集成到因子分解的NeRF表示中。与传统方法不同，ZeroRF使用神经网络生成器对特征网格进行参数化，从而实现高效的稀疏视图360重建，而无需任何预训练或额外的正则化。大量实验展示了ZeroRF在质量和速度方面的多功能性和优势，在基准数据集上取得了最先进的结果。ZeroRF的意义延伸到3D内容生成和编辑的应用。项目页面：https://sarahweiii.github.io/zerorf/ et.al.|[2312.09249](http://arxiv.org/abs/2312.09249)|null|
|**2023-12-12**|**SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration**|最近的实时视图合成技术在保真度和速度上迅速进步，现代方法能够以交互式帧速率渲染接近照片级真实感的场景。与此同时，在易于光栅化的显式场景表示和基于射线行进的神经场之间出现了紧张关系，后者的最先进实例在质量上超过了前者，同时对于实时应用来说成本高得令人望而却步。在这项工作中，我们介绍了SMERF，这是一种视图合成方法，在占地面积高达3亿 $^2$、体积分辨率为3.5毫米$^3$ 的大型场景中，它实现了实时方法中最先进的精度。我们的方法建立在两个主要贡献之上：一个是分层模型划分方案，它在限制计算和内存消耗的同时增加了模型容量，另一个是蒸馏训练策略，它同时产生高保真度和内部一致性。我们的方法能够在网络浏览器中实现全六自由度（6DOF）导航，并在商品智能手机和笔记本电脑上实时渲染。大量实验表明，我们的方法在实时新视图合成方面，在标准基准上超过了当前最先进的0.78 dB，在大型场景上超过了1.78 dB，渲染帧的速度比最先进的辐射场模型快三个数量级，并在包括智能手机在内的各种商品设备上实现了实时性能。我们鼓励读者在我们的项目网站上亲自探索这些模型：https://smerf-3d.github.io. et.al.|[2312.07541](http://arxiv.org/abs/2312.07541)|null|
|**2023-12-11**|**Representing stimulus motion with waves in adaptive neural fields**|神经活动的行波在皮层网络中自发出现，并对刺激做出反应。波的时空结构可以指示它们编码的信息以及维持它们的生理过程。在这里，我们研究了作为视觉运动处理模型的自适应神经场中出现的行波的刺激响应关系。神经场方程将皮层组织的活动建模为连续的可兴奋介质，自适应过程提供负反馈，产生局部活动模式。在我们的模型中，突触连接由一个积分核来描述，该积分核由于依赖于活动的突触抑制而动态减弱，导致边缘稳定的行进前沿（具有衰减的后部）或固定速度的脉冲。我们的分析量化了弱刺激如何随着时间的推移改变这些波的相对位置，其特征是我们扰动地获得的波响应函数。持续和连续可见的刺激模拟移动的视觉对象。在视觉空间中跳跃的间歇性闪光可以产生流畅的视觉运动体验。我们的理论和数值模拟很好地描述了波对两种运动刺激的夹带，提供了视觉运动感知的机制描述。 et.al.|[2312.06100](http://arxiv.org/abs/2312.06100)|null|
|**2023-12-11**|**Nuvo: Neural UV Mapping for Unruly 3D Representations**|现有的UV映射算法被设计为在性能良好的网格上操作，而不是由最先进的3D重建和生成技术产生的几何表示。因此，将这些方法应用于由神经辐射场和相关技术（或从这些场三角化的网格）恢复的体积密度会导致纹理图谱过于分散，无法用于视图合成或外观编辑等任务。我们提出了一种UV映射方法，旨在对通过3D重建和生成技术产生的几何体进行操作。我们的方法Nuvo不是计算在网格顶点上定义的映射，而是使用神经场来表示连续的UV映射，并将其优化为仅针对一组可见点（即仅影响场景外观的点）的有效且性能良好的映射。我们展示了我们的模型对不良几何体带来的挑战是稳健的，并且它生成了可以表示详细外观的可编辑UV映射。 et.al.|[2312.05283](http://arxiv.org/abs/2312.05283)|null|

<p align=right>(<a href=#updated-on-20231227>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

