[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.10.04
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-10-03**|**MIMO-NeRF: Fast Neural Rendering with Multi-input Multi-output Neural Radiance Fields**|神经辐射场（NeRF）在新的视图合成中显示出令人印象深刻的结果。然而，它们依赖于重复使用单输入单输出多层感知器（SISO MLP），该感知器以逐样本的方式将3D坐标和视图方向映射到颜色和体积密度，这会减慢渲染速度。我们提出了一种多输入多输出NeRF（MIMO NeRF），通过用MIMO MLP替换SISO MLP并以分组方式进行映射来减少运行的MLP的数量。这种方法的一个显著挑战是，根据组中输入坐标的选择，每个点的颜色和体积密度可能不同，这可能导致一些显著的模糊性。我们还提出了一种自监督学习方法，该方法使用多个快速重新表述的MLP来正则化MIMO MLP，以在不使用预训练模型的情况下缓解这种模糊性。包括比较和消融研究在内的综合实验评估结果表明，在合理的训练时间内，MIMO NeRF在速度和质量之间取得了良好的平衡。然后，我们通过将MIMO NeRF应用于两个具有代表性的快速NeRF，即具有样本减少的NeRF（DONeRF）和具有替代表示的NeRF，来证明MIMO NeRF与NeRF的先前进步兼容并互补。 et.al.|[2310.01821](http://arxiv.org/abs/2310.01821)|null|
|**2023-10-02**|**LEAP: Liberate Sparse-view 3D Modeling from Camera Poses**|多视图三维建模是否需要相机姿势？现有的方法主要假设能够获得准确的相机姿势。虽然这一假设可能适用于密集视图，但准确估计稀疏视图的相机姿态往往是难以捉摸的。我们的分析表明，噪声估计的姿态会导致现有稀疏视图三维建模方法的性能下降。为了解决这个问题，我们提出了LEAP，这是一种新颖的无姿势方法，因此挑战了相机姿势不可或缺的普遍观念。LEAP放弃基于姿态的操作，并从数据中学习几何知识。LEAP配备了一个神经体积，该体积在场景中共享，并被参数化以编码几何和纹理先验。对于每个进入的场景，我们通过以特征相似性驱动的方式聚集2D图像特征来更新神经体积。更新后的神经体积被解码到辐射场中，从而能够从任何视点进行新颖的视图合成。在以对象为中心和场景级别的数据集上，我们表明，当LEAP使用最先进的姿态估计器的预测姿态时，它们显著优于先前的方法。值得注意的是，LEAP的表现与之前使用真实姿势的方法不相上下，同时比PixelNeRF快400美元\倍。我们展示了LEAP可以推广到新的对象类别和场景，并学习与极线几何非常相似的知识。项目页面：https://hwjiang1510.github.io/LEAP/ et.al.|[2310.01410](http://arxiv.org/abs/2310.01410)|null|
|**2023-09-30**|**MMPI: a Flexible Radiance Field Representation by Multiple Multi-plane Images Blending**|本文提出了一种基于多平面图像（MPI）的神经辐射场的灵活表示方法，用于复杂场景的高质量视图合成。带归一化设备坐标（NDC）参数化的MPI因其定义简单、计算简单以及表示无界场景的强大能力而在NeRF学习中广泛使用。然而，现有的采用MPI表示进行新颖视图合成的NeRF作品只能处理简单的前向无界场景，其中输入相机都以较小的相对平移在相似的方向上进行观察。因此，将这些基于MPI的方法扩展到更复杂的场景，如大范围甚至360度场景，是非常具有挑战性的。在本文中，我们探索了MPI的潜力，并表明MPI可以合成具有不同相机分布和视角方向的复杂场景的高质量新颖视图，而不仅仅局限于简单的前向场景。我们的关键思想是用面向不同方向的多个MPI对神经辐射场进行编码，并通过自适应混合操作将其混合。对于场景的每个区域，混合操作为那些具有较强局部表示能力的有利MPIs提供较大的混合权重，而为那些具有较弱表示能力的MPIs提供较低的权重。这种混合操作自动地调制多个MPI以适当地表示不同的局部密度和颜色信息。在KITTI数据集和ScanNet数据集上的实验表明，我们提出的MMPI从不同的相机姿态分布中合成高质量的图像，并且训练速度快，优于以前用于新视图合成的快速训练NeRF方法。此外，我们还表明MMPI可以对超长轨迹进行编码，并生成新颖的视图渲染，展示了其在自动驾驶等应用中的潜力。 et.al.|[2310.00249](http://arxiv.org/abs/2310.00249)|null|
|**2023-09-29**|**Multi-task View Synthesis with Neural Radiance Fields**|多任务视觉学习是计算机视觉的一个重要方面。然而，目前的研究主要集中在多任务密集预测环境上，它忽略了内在的3D世界及其多视图一致的结构，缺乏丰富想象力的能力。为了应对这些限制，我们提出了一种新的问题设置——多任务视图合成（MTVS），它将多任务预测重新解释为一组针对多个场景属性（包括RGB）的新视图合成任务。为了解决MTVS问题，我们提出了MuvieNeRF，这是一个结合了多任务和跨视图知识的框架，可以同时合成多个场景属性。MuvieNeRF集成了两个关键模块，即跨任务注意力（CTA）和跨视图注意力（CVA）模块，实现了跨多个视图和任务的信息高效使用。对合成和逼真基准的广泛评估表明，MuvieNeRF能够同时合成具有良好视觉质量的不同场景属性，甚至在各种设置下都优于传统的判别模型。值得注意的是，我们发现MuvieNeRF在一系列NeRF主干上表现出普遍的适用性。我们的代码可在https://github.com/zsh2000/MuvieNeRF. et.al.|[2309.17450](http://arxiv.org/abs/2309.17450)|**[link](https://github.com/zsh2000/muvienerf)**|
|**2023-09-29**|**Forward Flow for Novel View Synthesis of Dynamic Scenes**|本文提出了一种利用前向翘曲进行动态场景新视图合成的神经辐射场（NeRF）方法。现有的方法通常采用静态NeRF来表示规范空间，并通过将采样的3D点映射回具有所学习的反向流场的规范空间来在其他时间步长渲染动态图像。然而，这种反向流场是非光滑和不连续的，很难用常用的光滑运动模型来拟合。为了解决这个问题，我们建议估计正向流场，并将正则辐射场直接扭曲到其他时间步长。这种正向流场在物体区域内是平滑和连续的，这有利于运动模型的学习。为了实现这一目标，我们用体素网格表示规范辐射场，以实现有效的前向翘曲，并提出了一种可微分的翘曲过程，包括平均飞溅操作和修复网络，以解决多对一和一对多映射问题。深入的实验表明，我们的方法在新视图渲染和运动建模方面都优于现有方法，证明了我们的正向流运动建模的有效性。项目页面：https://npucvr.github.io/ForwardFlowDNeRF et.al.|[2309.17390](http://arxiv.org/abs/2309.17390)|null|
|**2023-09-29**|**PARF: Primitive-Aware Radiance Fusion for Indoor Scene Novel View Synthesis**|本文提出了一种快速场景辐射场重建方法，该方法具有较强的新颖视图合成性能和方便的场景编辑功能。其关键思想是充分利用语义解析和基元提取来约束和加速辐射场重建过程。为了实现这一目标，提出了一种基元感知混合渲染策略，以实现体积渲染和基元渲染的最佳效果。我们进一步贡献了一个重建管道，它对每个输入帧迭代地进行基元解析和辐射场学习，成功地将语义、基元和辐射信息融合到一个框架中。广泛的评估证明了我们方法的快速重建能力、高渲染质量和方便的编辑功能。 et.al.|[2309.17190](http://arxiv.org/abs/2309.17190)|null|
|**2023-09-27**|**P2I-NET: Mapping Camera Pose to Image via Adversarial Learning for New View Synthesis in Real Indoor Environments**|给定室内环境中一个新的 $6DoF$ 相机姿势，我们研究了基于一组参考RGBD视图从该姿势预测视图的挑战性问题。现有的显式或隐式3D几何构造方法在计算上是昂贵的，而那些基于学习的方法主要关注具有规则几何结构的对象类别的孤立视图。与传统的\textit{rend-inpaint}方法不同，我们提出了一种条件生成对抗性神经网络（P2I-NET）来直接从给定的姿态预测新视图。P2I-NET学习环境图像的条件分布，以建立相机姿势与其环境视图之间的对应关系，并通过其架构中的许多创新设计和训练丢失的功能来实现这一点。引入了两个辅助鉴别器约束，用于在潜在特征空间和真实世界姿势空间中增强生成图像的姿势与对应真实世界图像的姿势之间的一致性。此外，引入了深度卷积神经网络（CNN）来进一步增强像素空间中的这种一致性。我们在真实的室内数据集上进行了大量的新视图合成实验。结果表明，与许多基于NeRF的强基线模型相比，P2I-NET具有优越的性能。特别是，我们发现P2I-NET在合成类似质量的图像时比这些竞争对手的技术快40到100倍。此外，我们贡献了一个新的公开可用的室内环境数据集，其中包含22个高分辨率RGBD视频，其中每一帧也有准确的相机姿态参数。 et.al.|[2309.15526](http://arxiv.org/abs/2309.15526)|null|
|**2023-09-29**|**3D Reconstruction with Generalizable Neural Fields using Scene Priors**|由于神经领域的最新进展，高保真3D场景重建得到了实质性的推进。然而，大多数现有的方法为每个单独的场景从头开始训练单独的网络。这是不可扩展的，效率低下，并且在视图有限的情况下无法产生良好的结果。虽然基于学习的多视图立体方法在一定程度上缓解了这一问题，但它们的多视图设置使其扩展和广泛应用的灵活性降低。相反，我们引入了结合场景先验（NFP）的训练可推广神经场。NFP网络将任何单视图RGB-D图像映射为带符号的距离和辐射值。在没有融合模块的情况下，可以通过合并体积空间中的各个帧来重建完整的场景，这提供了更好的灵活性。场景先验可以在大规模数据集上进行训练，从而能够快速适应具有较少视图的新场景的重建。NFP不仅展示了SOTA场景重建的性能和效率，而且还支持单图像新视图合成，这在神经领域还没有得到充分的探索。更多定性结果可在以下网站获得：https://oasisyang.github.io/neural-prior et.al.|[2309.15164](http://arxiv.org/abs/2309.15164)|null|
|**2023-09-25**|**NAS-NeRF: Generative Neural Architecture Search for Neural Radiance Fields**|神经辐射场（NeRF）能够实现高质量的新视图合成，但其高得令人望而却步的计算复杂性限制了可部署性，尤其是在资源受限的平台上。为了实现NeRF的实际使用，质量调整对于降低计算复杂性至关重要，类似于视频游戏中的可调整图形设置。然而，尽管现有的解决方案努力提高效率，但无论场景复杂程度如何，它们都使用一刀切的架构，尽管相同的架构对于简单场景可能不必要地大，但对于复杂场景则不够。因此，随着NeRF越来越广泛地用于3D可视化，需要动态优化NeRF的神经网络组件，以实现计算复杂性和合成质量特定目标之间的平衡。为了解决这一差距，我们引入了NAS NeRF：一种生成神经架构搜索策略，通过优化复杂性和性能之间的权衡，同时遵守计算预算和最低合成质量的限制，专门针对每个场景生成NeRF架构。我们在Blender合成数据集上的实验表明，与基线NeRF相比，所提出的NAS NeRF在GPU上生成的架构可以小5.74 $\times$，FLOP少4.19$\times$，速度快1.93$\times]，而SSIM不会下降。此外，我们还表明，NAS NeRF还可以实现比基线NeRF小23$\times$、FLOP少22$\times$和快4.7$ \times\的架构，平均SSIM下降5.3\%。我们工作的源代码也可在https://saeejithnair.github.io/NAS-NeRF. et.al.|[2309.14293](http://arxiv.org/abs/2309.14293)|null|
|**2023-09-22**|**NeRRF: 3D Reconstruction and View Synthesis for Transparent and Specular Objects with Neural Refractive-Reflective Fields**|神经辐射场（NeRF）已经彻底改变了基于图像的视图合成领域。然而，NeRF使用直线光线，无法处理由折射和反射引起的复杂光路变化。这阻碍了NeRF成功合成透明或镜面物体，而这些物体在现实世界的机器人和A/VR应用中无处不在。本文介绍了折射反射场。以物体轮廓为输入，我们首先利用渐进编码的行进四面体来重建非朗伯物体的几何结构，然后使用菲涅耳项在统一的框架中对物体的折射和反射效应进行建模。同时，为了实现高效、有效的抗混叠，我们提出了一种虚拟锥超采样技术。我们在真实世界和合成数据集的不同形状、背景和菲涅耳项上对我们的方法进行了基准测试。我们还对各种编辑应用程序的渲染结果进行了定性和定量的基准测试，包括材质编辑、对象替换/插入和环境照明估计。代码和数据可在https://github.com/dawning77/NeRRF. et.al.|[2309.13039](http://arxiv.org/abs/2309.13039)|**[link](https://github.com/dawning77/nerrf)**|

<p align=right>(<a href=#updated-on-20231004>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-10-02**|**PC-NeRF: Parent-Child Neural Radiance Fields under Partial Sensor Data Loss in Autonomous Driving Environments**|重建大规模3D场景对自动驾驶汽车至关重要，尤其是在部分传感器数据丢失的情况下。尽管最近开发的神经辐射场（NeRF）在隐式表示中显示出了令人信服的结果，但使用部分丢失的激光雷达点云数据进行大规模3D场景重建仍需探索。为了弥补这一差距，我们提出了一种新的3D场景重建框架，称为父子神经辐射场（PC NeRF）。该框架包括两个模块，父NeRF和子NeRF，以同时优化场景级、分段级和点级场景表示。通过利用子NeRF的分段级表示能力，可以更有效地利用传感器数据，并且即使在有限的观测下也可以快速获得场景的近似体积表示。经过大量的实验，我们提出的PC NeRF被证明可以在大规模场景中实现高精度的3D重建。此外，PC NeRF可以有效地处理部分传感器数据丢失的情况，并且在有限的训练时间内具有较高的部署效率。我们的方法实施和预先培训的模型将在https://github.com/biter0088/pc-nerf. et.al.|[2310.00874](http://arxiv.org/abs/2310.00874)|**[link](https://github.com/biter0088/pc-nerf)**|
|**2023-10-01**|**Enabling Neural Radiance Fields (NeRF) for Large-scale Aerial Images -- A Multi-tiling Approaching and the Geometry Assessment of NeRF**|神经辐射场（NeRF）提供了有益于3D重建任务的潜力，包括航空摄影测量。然而，对于大规模航空资产，推断几何结构的可扩展性和准确性并没有得到很好的证明，因为这样的数据集通常会导致非常高的内存消耗和缓慢的收敛。。在本文中，我们的目标是在大型scael航空数据集上缩放NeRF，并对NeRF进行全面的几何评估。具体而言，我们介绍了一种特定于位置的采样技术以及多摄像头拼接（MCT）策略，以减少RAM图像加载期间的内存消耗、GPU内存的表示训练，并提高拼接内的收敛率。MCT将大帧图像分解为具有不同相机模型的多个拼接图像，允许这些小帧图像根据特定位置的需要被输入到训练过程中，而不会损失准确性。我们在一种具有代表性的方法Mip-NeRF上实现了我们的方法，并在两个典型的航空数据集上与激光雷达参考数据比较了其几何性能与三光图MVS管道。定性和定量结果都表明，与传统方法相比，所提出的NeRF方法产生了更好的完整性和对象细节，尽管到目前为止，它在准确性方面仍然不足。 et.al.|[2310.00530](http://arxiv.org/abs/2310.00530)|null|
|**2023-09-29**|**3D Reconstruction in Noisy Agricultural Environments: A Bayesian Optimization Perspective for View Planning**|三维重建是机器人技术中的一项基本任务，由于其在农业、水下和城市环境等各种实际环境中的重大影响而受到关注。这项任务的一个重要方法，即视图规划，是明智地将多个相机放置在最大限度地提高视觉信息的位置，从而改进最终的3D重建。为了避免对大量任意图像的需求，可以应用几何标准来选择更少但信息更丰富的图像，以显著提高3D重建性能。尽管如此，将存在于各种真实世界场景中的环境噪声纳入这些标准可能是具有挑战性的，特别是当没有提供关于噪声的先验信息时。为此，这项工作提倡一种新的几何函数，它可以解释现有的噪声，只依赖于相对少量的噪声实现，而不需要其闭合形式的表达式。在没有几何函数的解析表达式的情况下，本文提出了一种在噪声存在的情况下进行精确三维重建的贝叶斯优化算法。在嘈杂的农业环境中进行的数值测试表明，即使使用少量可用的摄像机，所提出的3D重建方法也具有令人印象深刻的优点。 et.al.|[2310.00145](http://arxiv.org/abs/2310.00145)|null|
|**2023-09-29**|**Multi-task View Synthesis with Neural Radiance Fields**|多任务视觉学习是计算机视觉的一个重要方面。然而，目前的研究主要集中在多任务密集预测环境上，它忽略了内在的3D世界及其多视图一致的结构，缺乏丰富想象力的能力。为了应对这些限制，我们提出了一种新的问题设置——多任务视图合成（MTVS），它将多任务预测重新解释为一组针对多个场景属性（包括RGB）的新视图合成任务。为了解决MTVS问题，我们提出了MuvieNeRF，这是一个结合了多任务和跨视图知识的框架，可以同时合成多个场景属性。MuvieNeRF集成了两个关键模块，即跨任务注意力（CTA）和跨视图注意力（CVA）模块，实现了跨多个视图和任务的信息高效使用。对合成和逼真基准的广泛评估表明，MuvieNeRF能够同时合成具有良好视觉质量的不同场景属性，甚至在各种设置下都优于传统的判别模型。值得注意的是，我们发现MuvieNeRF在一系列NeRF主干上表现出普遍的适用性。我们的代码可在https://github.com/zsh2000/MuvieNeRF. et.al.|[2309.17450](http://arxiv.org/abs/2309.17450)|**[link](https://github.com/zsh2000/muvienerf)**|
|**2023-09-29**|**Effect of structure-based training on 3D localization precision and quality**|本研究介绍了一种基于结构的训练方法，用于单分子定位显微镜（SMLM）和三维物体重建中基于CNN的算法。我们将这种方法与传统的基于随机的训练方法进行了比较，利用LUENN包作为我们的AI管道。定量评估表明，使用基于结构的训练方法，特别是在不同信噪比（SNR）的情况下，检测率和定位精度显著提高。此外，该方法有效地去除了棋盘伪影，确保了更准确的三维重建。我们的发现突出了基于结构的训练方法在推进超分辨率显微镜和加深我们对纳米级复杂生物系统的理解方面的潜力。 et.al.|[2309.17265](http://arxiv.org/abs/2309.17265)|null|
|**2023-09-28**|**Sketch2CADScript: 3D Scene Reconstruction from 2D Sketch using Visual Transformer and Rhino Grasshopper**|现有的3D模型重建方法通常以体素、点云或网格的形式产生输出。然而，这些方法中的每一种都有其局限性，可能不适合每种情况。例如，生成的模型可能会呈现粗糙的表面和扭曲的结构，这使得手动编辑和后处理对人类来说具有挑战性。在本文中，我们介绍了一种新的三维重建方法，旨在解决这些问题。我们训练了一个视觉转换器来从单线帧图像中预测“场景描述符”。该描述符包含关键信息，包括对象类型和参数，如位置、旋转和大小。有了预测的参数，可以使用Blender或Rhino Grasshopper等3D建模软件重建3D场景，该软件提供了可编程的界面，从而生成精细且易于编辑的3D模型。为了评估所提出的模型，我们创建了两个数据集：一个以简单场景为特征，另一个以复杂场景为特征。测试结果证明了该模型准确重建简单场景的能力，但也揭示了其在更复杂场景中的挑战。 et.al.|[2309.16850](http://arxiv.org/abs/2309.16850)|null|
|**2023-09-28**|**HyperLISTA-ABT: An Ultra-light Unfolded Network for Accurate Multi-component Differential Tomographic SAR Inversion**|基于展开迭代算法的深度神经网络在稀疏重建应用中取得了显著成功，如合成孔径雷达（SAR）断层反演（TomoSAR）。然而，目前可用的基于深度学习的TomoSAR算法仅限于三维（3D）重建。基于深度学习的算法扩展到四维（4D）成像，即差分TomoSAR（D-TomoSAR）应用，主要由于为D-TomoSAR反演设计的网络所需的高维权重矩阵而受到阻碍，该矩阵通常包含数百万个可自由训练的参数。学习如此大量的权重需要大量的训练样本，导致大量的记忆负担和过度的时间消耗。为了解决这个问题，我们提出了一种高效准确的算法HyperLISTA-ABT。HyperLISTA ABT中的权重是根据最小相干标准以分析的方式确定的，将模型裁剪为只有三个超参数的超轻模型。此外，HyperLISTA ABT通过利用自适应分块阈值化方案改进了全局阈值化，该方案应用块坐标技术并在局部块中进行阈值化，从而可以在收缩步骤中逐层保留弱表达式和局部特征。进行了仿真，并证明了我们方法的有效性，表明与最先进的方法相比，HyperLISTA ABT实现了卓越的计算效率，并且没有显著的性能下降。实际数据实验表明，所提出的HyperLISTA ABT可以用负担得起的计算资源在短时间内在大面积上重建高质量的4D点云。 et.al.|[2309.16468](http://arxiv.org/abs/2309.16468)|null|
|**2023-09-29**|**3D Reconstruction with Generalizable Neural Fields using Scene Priors**|由于神经领域的最新进展，高保真3D场景重建得到了实质性的推进。然而，大多数现有的方法为每个单独的场景从头开始训练单独的网络。这是不可扩展的，效率低下，并且在视图有限的情况下无法产生良好的结果。虽然基于学习的多视图立体方法在一定程度上缓解了这一问题，但它们的多视图设置使其扩展和广泛应用的灵活性降低。相反，我们引入了结合场景先验（NFP）的训练可推广神经场。NFP网络将任何单视图RGB-D图像映射为带符号的距离和辐射值。在没有融合模块的情况下，可以通过合并体积空间中的各个帧来重建完整的场景，这提供了更好的灵活性。场景先验可以在大规模数据集上进行训练，从而能够快速适应具有较少视图的新场景的重建。NFP不仅展示了SOTA场景重建的性能和效率，而且还支持单图像新视图合成，这在神经领域还没有得到充分的探索。更多定性结果可在以下网站获得：https://oasisyang.github.io/neural-prior et.al.|[2309.15164](http://arxiv.org/abs/2309.15164)|null|
|**2023-09-26**|**PHRIT: Parametric Hand Representation with Implicit Template**|我们提出了PHRIT，这是一种使用隐式模板进行参数化手网格建模的新方法，它结合了参数化网格和隐式表示的优点。我们的方法使用带符号距离场（SDF）和基于零件的形状先验来表示可变形的手部形状，利用变形场来执行变形。该模型通过以无限分辨率变形规范模板来提供高效的高保真手部重建。此外，它是完全可微的，并且可以很容易地用于手建模，因为它可以由骨架和形状潜在代码驱动。我们在多个下游任务上对PHRIT进行了评估，包括骨骼驱动的手部重建、点云形状和单视图3D重建，证明了我们的方法以最先进的性能实现了逼真和身临其境的手部建模。 et.al.|[2309.14916](http://arxiv.org/abs/2309.14916)|null|
|**2023-09-26**|**Unsupervised Reconstruction of 3D Human Pose Interactions From 2D Poses Alone**|由于单目图像中的视角模糊性，当前的无监督2D-3D人体姿态估计（HPE）方法在多人场景中不起作用。因此，我们提出了第一项研究，仅从2D姿势研究无监督多人2D-3D HPE的可行性，重点是重建人类互动。为了解决视角模糊的问题，我们通过预测摄像机相对于受试者骨盆的仰角来扩展先前的工作。这使我们能够将预测的姿势旋转到与地平面齐平的位置，同时获得个体之间3D垂直偏移的估计值。我们的方法包括独立地将每个受试者的2D姿势提升到3D，然后将它们组合到共享的3D坐标系中。然后，在缩放之前，将姿势旋转并偏移预测的仰角。这本身就使我们能够检索到他们姿势的精确3D重建。我们在CHI3D数据集上展示了我们的结果，介绍了它在无监督2D-3D姿态估计中的应用，以及三种新的定量指标，并为未来的研究建立了基准。 et.al.|[2309.14865](http://arxiv.org/abs/2309.14865)|null|

<p align=right>(<a href=#updated-on-20231004>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-10-03**|**Hierarchical Generation of Human-Object Interactions with Diffusion Probabilistic Models**|本文提出了一种生成人类与目标物体交互的三维运动的新方法，重点解决了合成长距离和多样化运动的挑战，而现有的自回归模型或基于路径规划的方法无法实现这一挑战。我们提出了一个层次生成框架来解决这一挑战。具体来说，我们的框架首先生成一组里程碑，然后合成沿着它们的运动。因此，长距离运动生成可以简化为合成由里程碑引导的几个短运动序列。在NSM、COUCH和SAMP数据集上的实验表明，我们的方法在质量和多样性方面都大大优于以前的方法。源代码可在我们的项目页面上获得https://zju3dv.github.io/hghoi. et.al.|[2310.02242](http://arxiv.org/abs/2310.02242)|null|
|**2023-10-03**|**Generalized Schrödinger Bridge Matching**|用于训练扩散或流动模型的现代分布匹配算法直接规定了两个边界分布之间的边缘分布的时间演化。在这项工作中，我们考虑了一种广义分布匹配设置，其中这些边际仅被隐式描述为某些特定任务目标函数的解。被称为广义薛定谔桥（GSB）的问题设置在机器学习内外的许多科学领域都很普遍。我们提出了广义薛定谔桥匹配（GSBM），这是一种受最新进展启发的新匹配算法，将其推广到动能最小化之外，并考虑到特定任务的状态成本。我们证明了这种推广可以被视为求解条件随机最优控制，可以使用有效的变分近似，并借助路径积分理论进一步去偏。与解决GSB问题的现有方法相比，我们的GSBM算法在整个训练过程中始终保持边界分布之间的可行传输图，从而实现稳定的收敛和显著提高的可扩展性。我们在一系列实验装置上实证验证了我们的主张，包括人群导航、意见去极化、激光雷达流形和图像域转移。我们的工作为训练扩散模型带来了新的算法机会，该模型通过特定任务的最优性结构得到了增强。 et.al.|[2310.02233](http://arxiv.org/abs/2310.02233)|null|
|**2023-10-03**|**Leveraging Diffusion Disentangled Representations to Mitigate Shortcuts in Underspecified Visual Tasks**|数据中的虚假相关性，即多个线索可以预测目标标签，通常会导致捷径学习现象，即模型可能依赖错误的、易于学习的线索，而忽略可靠的线索。在这项工作中，我们提出了一个集合多样化框架，利用扩散概率模型（DPM）生成合成反事实。我们发现，DPM具有独立表示多个视觉线索的固有能力，即使它们在训练数据中有很大的相关性。我们利用这一特征来鼓励模型的多样性，并从经验上展示了该方法在几个多元化目标方面的有效性。我们表明，扩散引导的多样化可以使模型避免对捷径线索的关注，实现与以前需要额外数据收集的方法相当的集成多样性性能。 et.al.|[2310.02230](http://arxiv.org/abs/2310.02230)|null|
|**2023-10-03**|**Competition of many searchers**|首次通过时间（FPT）通常用于研究物理、化学和生物过程中的时间尺度。FPT通常描述随机“搜索者”找到“目标”所需的时间。在许多系统中，重要的时间尺度不是单个搜索者找到目标所需的速度，而是许多搜索者中最快的搜索者找到一个目标所用的时间。这种最快的FPT或极端的FPT是由许多搜索者竞争寻找目标而产生的，并且与单个搜索者的FPT明显不同。在本章中，我们回顾了最快FPT的最新结果。我们展示了最快的FPT如何取决于随机搜索模式（包括扩散搜索、次扩散搜索、超扩散搜索和离散跳跃搜索）、初始搜索器分布和空间域的性质。 et.al.|[2310.02157](http://arxiv.org/abs/2310.02157)|null|
|**2023-10-03**|**Global solution for superlinear stochastic heat equation on $\mathbb{R}^d$ under Osgood-type conditions**|我们研究了$\R^d$ 上的随机热方程（SHE），该方程受时间为白色、空间为彩色的中心高斯噪声的影响。假设漂移项满足Osgood型条件，并且扩散系数可能具有一定的相关增长。我们证明了存在在有限时间内不爆炸的随机场解。这是对最近关于随机偏微分方程解爆破的结果的补充和改进。 et.al.|[2310.02153](http://arxiv.org/abs/2310.02153)|null|
|**2023-10-03**|**A Variable Eddington Factor Model for Thermal Radiative Transfer with Closure based on Data-Driven Shape Function**|针对热辐射传输的非线性问题，提出了一种新的可变Eddington因子（VEF）模型。VEF模型是一个数据驱动的模型，它作用于TRT问题中材料温度的已知（先验）辐射扩散解。为辐射传输方程（RTE）构造了一个线性辅助问题，该问题具有在已知材料温度下评估的不透明性和发射源。该RTE的解近似于问题在所有相空间和时间中的特定强度分布。它被用作形状函数来定义所提出的VEF模型的Eddington张量。通过辅助RTE问题计算的形状函数将捕捉TRT问题中的某种程度的传输效应。因此，用这种近似爱丁顿张量闭合的VEF矩方程将携带这些捕获的输运效应。在本研究中，温度数据来自多组 $P_1$、$P_{1/3}$ 和通量限制扩散辐射传输（RT）模型。所提出的VEF模型可以解释为输运校正的扩散降阶模型。给出了Fleck-Cummings试验问题的数值结果，该问题模拟了辐射的超音速波前。与所考虑的TRT问题的辐射扩散模型解决方案相比，所提出的VEF模型可靠地将精度提高了1-2个数量级。 et.al.|[2310.02072](http://arxiv.org/abs/2310.02072)|null|
|**2023-10-03**|**Global Attractor for a Reaction-Diffusion Model Arising in Biological Dynamic in 3D Soil Structure**|偏微分方程（PDE）作为建模和理解复杂自然过程的工具发挥着至关重要的作用，尤其是在生物学领域。这项研究探索了三维土壤结构复杂矩阵中微生物活动的领域，为了解解的存在性和唯一性以及相应PDE模型的渐近行为提供了有价值的理解。我们的研究结果发现了一个全局吸引子，这是一个对长期系统行为具有重要意义的基本特征。为了提高我们发现的清晰度，我们采用了数值模拟来直观地说明这个全局吸引子的属性。 et.al.|[2310.02060](http://arxiv.org/abs/2310.02060)|null|
|**2023-10-03**|**AlignDiff: Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model**|由于人类偏好固有的抽象性和可变性，将主体行为与不同的人类偏好相协调仍然是强化学习中一个具有挑战性的问题。为了解决这些问题，我们提出了AlignDiff，这是一个新颖的框架，利用来自人类反馈（RLHF）的RL来量化人类偏好，涵盖抽象性，并利用它们来指导零样本行为定制的扩散规划，涵盖可变性。AlignDiff可以准确匹配用户自定义的行为，并有效地从一种行为切换到另一种行为。为了构建该框架，我们首先建立了多视角的人类反馈数据集，其中包含不同行为属性的比较，然后训练属性强度模型来预测量化的相对强度。在重新标记具有相对强度的行为数据集后，我们继续训练一个属性条件扩散模型，该模型作为规划者，属性强度模型作为推理阶段偏好对齐的指导者。我们在各种移动任务上评估了AlignDiff，并证明了与其他基线相比，它在偏好匹配、切换和覆盖方面的卓越性能。它在人类指令下完成看不见的下游任务的能力也展示了人类人工智能协作的潜力。更多可视化视频发布于https://aligndiff.github.io/. et.al.|[2310.02054](http://arxiv.org/abs/2310.02054)|null|
|**2023-10-03**|**Spectral operator learning for parametric PDEs without data reliance**|在本文中，我们介绍了通过算子网络的谱系数学习（SCLON），这是一种新的基于算子学习的方法，用于求解参数偏微分方程（PDE），而不需要数据处理。我们方法的基石是谱方法，该方法使用正交函数（如傅立叶级数和勒让德多项式）进行展开，从而实现具有较少网格点的精确PDE解决方案。通过将谱方法的优点（包括高精度、高效、泛化和精确满足边界条件）与深度神经网络的能力相结合，SCLON提供了一种变革策略。我们的方法不仅消除了对成对输入输出训练数据的需求，这通常需要大量的数值计算，而且还有效地学习和预测了复杂参数偏微分方程的解，从奇摄动对流扩散方程到Navier-Stokes方程。与现有的科学机器学习技术相比，所提出的框架表现出了优越的性能，在不利用数据的情况下为参数偏微分方程的多个实例提供了解决方案。该数学框架稳健可靠，具有从弱公式推导出的完善的损失函数，确保了解的精确逼近，同时完全满足边界条件。该方法的有效性通过其准确预测复杂自然行为（如Kolmogorov流和边界层）的能力得到了进一步的证明。本质上，我们的工作为参数PDE解决方案开辟了一条引人注目的途径，成为科学计算领域传统数值方法和尖端机器学习技术之间的桥梁。 et.al.|[2310.02013](http://arxiv.org/abs/2310.02013)|null|
|**2023-10-03**|**Optimizing microlens arrays for incoherent HiLo microscopy**|HiLo显微镜是一种功能强大、低成本且易于配置的技术，用于获取高对比度的光学切片图像。然而，传统的HiLo显微镜是基于具有漫射玻璃板的相干光源或具有数字镜器件（DMD）和空间光调制器（SLM）的非相干光源，这更昂贵。在这里，我们提出了一种新的低成本HiLo显微镜技术，使用MLA和非相干LED光源。我们模拟了基于菲涅耳衍射和非相干成像的结构照明（SI）模式和HiLo图像生成。为了观察MLA如何影响HiLo图像，我们使用了三种具有特定微透镜间距和数值孔径（NA）的常见MLA来生成周期性照明图案。根据我们的模拟，与传统的宽场荧光显微镜相比，使用MLA和非相干光源可以增强图像对比度。我们发现MLA NA不会显著影响HiLo图像。较大的透镜间距可以带来更高的图像对比度。然而，有一个优化的镜头间距。如果透镜间距过高，则在HiLo图像中会观察到伪影。据我们所知，这是第一次对基于MLA的HiLo显微镜进行数值研究。这项研究可以使使用MLA和非相干光源配置低成本HiLo显微镜的研究人员受益。 et.al.|[2310.01939](http://arxiv.org/abs/2310.01939)|null|

<p align=right>(<a href=#updated-on-20231004>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-10-02**|**Neural Processing of Tri-Plane Hybrid Neural Fields**|在用于存储和通信3D数据的神经场的吸引人的特性的驱动下，直接处理它们以解决分类和零件分割等任务的问题已经出现，并在最近的工作中进行了研究。早期的方法使用由在整个数据集上训练的共享网络参数化的神经场，实现了良好的任务性能，但牺牲了重建质量。为了改进后者，后来的方法侧重于参数化为大型多层感知器（MLP）的单个神经场，然而，由于权重空间的高维性、固有的权重空间对称性和对随机初始化的敏感性，这些神经元场的处理具有挑战性。因此，结果明显不如通过处理显式表示（例如点云或网格）所获得的结果。与此同时，混合表示，特别是基于三平面的混合表示，已经成为实现神经场的一种更有效的替代方案，但其直接处理尚未得到研究。在本文中，我们证明了三平面离散数据结构编码了丰富的信息，标准的深度学习机器可以有效地处理这些信息。我们定义了一个广泛的基准，涵盖了一组不同的字段，如占用率、有符号/无符号距离，以及首次定义的辐射字段。在处理具有相同重建质量的字段时，我们实现的任务性能远远优于处理大型MLP的框架，并且首次几乎与处理显式表示的架构不相上下。 et.al.|[2310.01140](http://arxiv.org/abs/2310.01140)|null|
|**2023-09-27**|**Neural Acoustic Context Field: Rendering Realistic Room Impulse Response With Neural Fields**|房间脉冲响应（RIR）测量声音在环境中的传播，对于合成给定环境下的高保真音频至关重要。一些先前的工作已经提出将RIR表示为声音发射器和接收器位置的神经场函数。然而，这些方法没有充分考虑音频场景的声学特性，导致性能不令人满意。这封信提出了一种新的神经声学上下文场方法，称为NACF，通过利用多个声学上下文（如几何结构、材料特性和空间信息）来参数化音频场景。在RIR的独特性质，即时间不光滑性和单调能量衰减的驱动下，我们设计了一个时间相关模块和多尺度能量衰减准则。实验结果表明，NACF的性能显著优于现有的基于字段的方法。请访问我们的项目页面了解更多定性结果。 et.al.|[2309.15977](http://arxiv.org/abs/2309.15977)|null|
|**2023-09-27**|**SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations**|隐式神经表示（INR）或神经场已成为编码多媒体信号（如图像和辐射场）同时保持高质量的流行框架。最近，Instant NGP提出的可学习特征网格通过用特征向量的多分辨率查找表和更小的神经网络取代大型神经网络，在训练和INR采样方面实现了显著的加速。然而，这些功能网格是以大量内存消耗为代价的，这可能是存储和流应用程序的瓶颈。在这项工作中，我们提出了SHACIRA，这是一个简单而有效的任务无关框架，用于压缩这种特征网格，而不需要额外的事后修剪/量化阶段。我们用量化的潜在权重对特征网格进行重新参数化，并在潜在空间中应用熵正则化，以在各个领域实现高水平的压缩。在由图像、视频和辐射场组成的不同数据集上的定量和定性结果表明，我们的方法优于现有的INR方法，而不需要任何大型数据集或特定领域的启发式方法。我们的项目页面可在http://shacira.github.io。 et.al.|[2309.15848](http://arxiv.org/abs/2309.15848)|null|
|**2023-09-27**|**NeuRBF: A Neural Fields Representation with Adaptive Radial Basis Functions**|我们提出了一种新型的神经场，它使用一般的径向基来表示信号。现有技术的神经领域通常依赖于用于存储局部神经特征的基于网格的表示和用于在连续查询点处插值特征的N维线性核。它们的神经特征的空间位置固定在网格节点上，不能很好地适应目标信号。相反，我们的方法建立在具有灵活内核位置和形状的通用径向基上，这些径向基具有更高的空间自适应性，可以更紧密地拟合目标信号。为了进一步提高径向基函数的信道容量，我们建议将它们与多频率正弦函数组合。该技术将径向基扩展到不同频带的多个傅立叶径向基，而不需要额外的参数，便于细节的表示。此外，通过将自适应径向基与基于网格的径向基相结合，我们的混合组合继承了自适应性和插值平滑性。我们精心设计了加权方案，使径向基有效地适应不同类型的信号。我们在2D图像和3D符号距离场表示上的实验证明了我们的方法比现有技术更高的精度和紧凑性。当应用于神经辐射场重建时，我们的方法实现了最先进的渲染质量，模型大小小，训练速度相当。 et.al.|[2309.15426](http://arxiv.org/abs/2309.15426)|**[link](https://github.com/oppo-us-research/NeuRBF)**|
|**2023-09-29**|**3D Reconstruction with Generalizable Neural Fields using Scene Priors**|由于神经领域的最新进展，高保真3D场景重建得到了实质性的推进。然而，大多数现有的方法为每个单独的场景从头开始训练单独的网络。这是不可扩展的，效率低下，并且在视图有限的情况下无法产生良好的结果。虽然基于学习的多视图立体方法在一定程度上缓解了这一问题，但它们的多视图设置使其扩展和广泛应用的灵活性降低。相反，我们引入了结合场景先验（NFP）的训练可推广神经场。NFP网络将任何单视图RGB-D图像映射为带符号的距离和辐射值。在没有融合模块的情况下，可以通过合并体积空间中的各个帧来重建完整的场景，这提供了更好的灵活性。场景先验可以在大规模数据集上进行训练，从而能够快速适应具有较少视图的新场景的重建。NFP不仅展示了SOTA场景重建的性能和效率，而且还支持单图像新视图合成，这在神经领域还没有得到充分的探索。更多定性结果可在以下网站获得：https://oasisyang.github.io/neural-prior et.al.|[2309.15164](http://arxiv.org/abs/2309.15164)|null|
|**2023-09-22**|**NOC: High-Quality Neural Object Cloning with 3D Lifting of Segment Anything**|随着神经领域的发展，从多视图输入重建目标物体的3D模型最近越来越受到社会的关注。现有的方法通常学习整个场景的神经场，而如何在飞行中重建用户指示的特定对象仍在探索之中。考虑到分段任意模型（SAM）在分割任何2D图像方面都显示出了有效性，本文提出了一种新的高质量3D对象重建方法——神经对象克隆（NOC），它从两个方面利用了神经场和SAM的优点。首先，为了将目标对象从场景中分离出来，我们提出了一种新的策略，将SAM的多视图2D分割掩模提升到一个统一的3D变化场中。然后，3D变化场被投影到2D空间中，并生成SAM的新提示。这个过程是迭代的，直到收敛，以将目标对象从场景中分离出来。然后，除了2D掩模之外，我们进一步将SAM编码器的2D特征提升到3D SAM场中，以提高目标对象的重建质量。NOC将SAM的2D掩模和特征提升到3D神经场中，用于高质量的目标对象重建。我们在几个基准数据集上进行了详细的实验，以证明我们的方法的优势。代码将被发布。 et.al.|[2309.12790](http://arxiv.org/abs/2309.12790)|null|
|**2023-09-15**|**Breathing New Life into 3D Assets with Generative Repainting**|基于扩散的文本到图像模型引发了视觉社区、艺术家和内容创作者的巨大关注。这些模型的广泛采用是由于世代质量的显著提高以及对各种模式的有效调节，而不仅仅是文本。然而，将这些2D模型的丰富生成先验提升到3D中是具有挑战性的。最近的工作提出了由扩散模型和神经场的纠缠提供动力的各种管道。我们探索了预训练的2D扩散模型和标准3D神经辐射场作为独立工具的威力，并展示了它们以非学习方式协同工作的能力。这种模块化具有易于部分升级的内在优势，这在这样一个快节奏的领域中成为了一个重要的特性。我们的管道接受任何遗留的可渲染几何体，如纹理或无纹理网格，协调2D生成细化和3D一致性强制工具之间的交互，并以多种格式输出绘制的输入几何体。我们对ShapeNetSem数据集中的广泛对象和类别进行了大规模研究，并从定性和定量两个方面展示了我们方法的优势。项目页面：https://www.obukhov.ai/repainting_3d_assets et.al.|[2309.08523](http://arxiv.org/abs/2309.08523)|**[link](https://github.com/kongdai123/repainting_3d_assets)**|
|**2023-09-14**|**Neural Field Representations of Articulated Objects for Robotic Manipulation Planning**|传统的操作规划方法依赖于环境的显式几何模型来将给定任务公式化为优化问题。然而，从原始传感器输入推断准确的模型本身就是一个难题，尤其是对于铰接物体（例如壁橱、抽屉）。在本文中，我们提出了一种关节对象的神经场表示（NFR），可以直接从图像中进行操作规划。具体来说，在拍摄了一个新的关节物体的几张照片后，我们可以向前模拟它可能的运动，因此，可以直接使用该神经模型进行轨迹优化规划。此外，这种表示可以用于形状重建、语义分割和图像渲染，这在训练和泛化过程中提供了强大的监督信号。我们表明，我们的模型仅在合成图像上训练，能够在模拟和真实图像中为同类看不见的物体提取有意义的表示。此外，我们证明了该表示能够直接从图像中对现实世界中的关节物体进行机器人操作。 et.al.|[2309.07620](http://arxiv.org/abs/2309.07620)|null|
|**2023-09-13**|**Generalizable Neural Fields as Partially Observed Neural Processes**|神经场将信号表示为由神经网络参数化的函数，是传统离散矢量或基于网格的表示的一种很有前途的替代方案。与离散表示相比，神经表示既能很好地扩展分辨率，又是连续的，并且可以是多次可微的。然而，给定我们想要表示的信号数据集，必须为每个信号优化单独的神经场是低效的，并且不能利用信号之间的共享信息或结构。现有的泛化方法将其视为元学习问题，并采用基于梯度的元学习来学习初始化，然后通过测试时间优化对初始化进行微调，或者学习超网络来产生神经场的权重。相反，我们提出了一种新的范式，将神经表征的大规模训练视为部分观察到的神经过程框架的一部分，并利用神经过程算法来解决这一任务。我们证明，这种方法优于最先进的基于梯度的元学习方法和超网络方法。 et.al.|[2309.06660](http://arxiv.org/abs/2309.06660)|null|
|**2023-09-08**|**Single View Refractive Index Tomography with Neural Fields**|折射率层析成像是一个反问题，我们试图从2D投影图像测量中重建场景的3D折射场。折射场本身是不可见的，而是影响光线在空间中传播时路径的连续弯曲。折射场出现在各种各样的科学应用中，从显微镜中的半透明细胞样本到弯曲来自遥远星系的光的暗物质场。这个问题带来了一个独特的挑战，因为折射场直接影响光的路径，使其恢复成为一个非线性问题。此外，与传统的层析成像相比，我们试图通过利用散射在整个介质中的光源的知识，仅从单个视点使用投影图像来恢复折射场。在这项工作中，我们介绍了一种使用基于坐标的神经网络对场景中潜在的连续折射场进行建模的方法。然后，我们使用射线三维空间曲率的显式建模来优化该网络的参数，通过综合分析方法重建折射场。通过在模拟中恢复折射场，并分析光源分布对恢复的影响，证明了我们方法的有效性。然后，我们在模拟暗物质映射问题上测试了我们的方法，在该问题中，我们恢复了真实模拟暗物质分布下的折射场。 et.al.|[2309.04437](http://arxiv.org/abs/2309.04437)|null|

<p align=right>(<a href=#updated-on-20231004>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

