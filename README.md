[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.09.24
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#video-diffusion>Video Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## Video Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-09-23**|**Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation**|生成虚拟环境的能力对于从游戏到物理AI领域（例如机器人技术，自动驾驶和工业AI）等应用至关重要。当前基于学习的3D重建方法取决于捕获的现实世界多视图数据的可用性，这并不总是很容易获得。视频扩散模型的最新进展显示出了显着的想象力，但是它们的2D性质将应用程序限制为模拟机器人需要导航和与环境交互的模拟。在本文中，我们提出了一个自distillation框架，旨在将视频扩散模型中的隐式3D知识提炼成明显的3D高斯分裂（3DGS）表示，从而消除了对多视图训练数据的需求。具体来说，我们使用3DGS解码器增强了典型的RGB解码器，该解码器由RGB解码器的输出进行监督。在这种方法中，3DGS解码器可以通过视频扩散模型生成的合成数据纯粹训练。在推理时，我们的模型可以从文本提示或单个图像中合成3D场景以进行实时渲染。我们的框架进一步扩展到单眼输入视频的动态3D场景生成。实验结果表明，我们的框架在静态和动态的3D场景生成中实现了最先进的性能。|[2509.19296](http://arxiv.org/abs/2509.19296)|null|
|**2025-09-23**|**Flow marching for a generative PDE foundation model**|在大规模的PDE州时空轨迹上进行了预处理，最近显示出有望构建动态系统的可通用模型。然而，大多数现有的PDE基础模型都依赖于确定性的变压器体系结构，这些结构缺乏许多科学和工程应用程序的生成灵活性。我们提出了流程，这是一种算法，该算法将神经操作员学习与流动匹配，该流程匹配是通过分析物理动力学系统中错误积累的分析，并且我们在其上构建了生成的PDE基础模型。通过共同采样噪声水平和相邻状态之间的物理时间步长，该模型学习了一个统一的速度场，该速度场将嘈杂的当前状态传输到其干净的后继者，从而减少了长期的推出漂移，同时使不确定性吸引了一代。除了该核心算法外，我们还引入了物理学预言的变异自动编码器（P2VAE），将物理状态嵌入到一个紧凑的潜在空间中，并有效的流动变压器（FMT）结合了扩散式方案，该方案将扩散型方案与潜在的较大的较大的范围延伸到更大的范围，从而达到更大的计算范围，从而达到15x的良好范围，以达到15x的范围，以达到15x的范围，以达到15倍的范围。大大降低了成本。我们在12个不同的PDE家族中策划了约250万个轨迹的语料库，并在多个尺度上策划了P2VAES和FMT的套件。在下游评估中，我们基于看不见的kolmogorov湍流，几乎没有射击适应，证明了对确定性对应物的长期推出稳定性，并提出了不确定性分层的集合结果，强调了生成PDE基础模型对现实世界应用的重要性。|[2509.18611](http://arxiv.org/abs/2509.18611)|null|
|**2025-09-22**|**VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models**|在本文中，我们提出了Videofrom3D，这是一个新颖的框架，用于合成粗糙几何，摄像机轨迹和参考图像的高质量3D场景视频。我们的方法简化了3D图形设计工作流程，从而可以灵活设计探索并快速生产可交付成果。从粗几何形状中综合视频的直接方法可能会使视频扩散模型在几何结构上。但是，由于难以联合建模视觉质量，运动和时间一致性，因此现有的视频扩散模型难以为复杂场景产生高保真结果。为了解决这个问题，我们提出了一个生成框架，以利用图像和视频扩散模型的互补优势。具体而言，我们的框架由稀疏的锚定生成（SAG）和几何引导的生成式Inbetinging（GGI）模块组成。 SAG模块使用图像扩散模型生成高质量的，跨视图一致的锚点视图，并通过稀疏的外观引导采样的帮助。 GGI模块以这些锚点的视图为基础，使用视频扩散模型忠实地插入了中间帧，并通过基于流动的摄像机控制和结构指导增强了中间框架。值得注意的是，两个模块都没有任何配对的3D场景模型和自然图像的数据集，这非常困难。综合实验表明，我们的方法在多样化和挑战性的场景下产生高质量的风格场景视频，表现优于简单和扩展的基线。|[2509.17985](http://arxiv.org/abs/2509.17985)|null|
|**2025-09-22**|**I2VWM: Robust Watermarking for Image to Video Generation**|图像引导的视频生成（I2V）的快速进步引起了人们对其在错误信息和欺诈方面的潜在滥用的担忧，强调了迫切需要有效的数字水印。尽管现有的水印方法证明了单个模态内的鲁棒性，但它们无法在I2V设置中追踪源图像。为了解决这一差距，我们介绍了稳健的扩散距离的概念，该距离衡量了生成的视频中水印信号的时间持久性。在此基础上，我们提出了I2VWM，这是一种跨模式水印框架，旨在增强随时间的水印稳健性。 I2VWM在训练过程中利用视频模拟噪声层，并在推理过程中采用基于光学的对准模块。开源和商业I2V模型的实验表明，I2VWM在保持不可识别的同时显着提高了鲁棒性，在生成视频时代建立了新的跨模式水印范式。 \ href {https://github.com/mrcrims/i2vwm-robust-watermarking-for-image-to-video-generation} {代码发布。}|[2509.17773](http://arxiv.org/abs/2509.17773)|null|
|**2025-09-21**|**Echo-Path: Pathology-Conditioned Echo Video Generation**|心血管疾病（CVD）仍然是全球死亡率的主要原因，超声心动图对于诊断常见和先天性心脏状况至关重要。但是，某些病理的超声心动图数据稀缺，阻碍了强大的自动诊断模型的发展。在这项工作中，我们提出了Echo-Path，这是一种新型的生成框架，以生成以特定心脏病理为条件的超声心动图视频。 Echo-Path可以合成具有靶向异常的现实超声视频序列，重点是心房间隔缺陷（ASD）和肺动脉高压（PAH）。我们的方法将病理条件的机制引入了最新的回声视频发生器，从而使模型可以在心脏中学习和控制特定于疾病的结构和运动模式。定量评估表明，合成视频达到了低分布距离，表明视觉效果很高。在临床上，产生的回声表现出合理的病理标记。此外，经过培训的合成数据的分类器可以很好地推广到真实数据，并且在用于增强实际训练集的情况下，它将ASD和PAH的下游诊断分别提高了7 \％和8 \％。代码，权重和数据集可在此处提供https://github.com/marshall-mk/echopathv1|[2509.17190](http://arxiv.org/abs/2509.17190)|null|
|**2025-09-21**|**VidCLearn: A Continual Learning Approach for Text-to-Video Generation**|文本到视频生成是生成AI的新兴领域，从而从文本提示中创建了现实的，语义上准确的视频。尽管当前模型具有令人印象深刻的视觉质量和与输入文本的对齐，但它们通常依赖于静态知识，因此很难在不从头开始重新培训的新数据。为了解决这一限制，我们提出了Vidclearn，这是一个基于扩散的文本到视频生成的持续学习框架。 Vidclearn具有学生教师的体系结构，其中学生模型通过新的文本视频对进行了逐步更新，而教师模型可以通过生成重播来维护以前学习的知识。此外，我们引入了一种新型的时间一致性损失，以增强运动平滑度和视频检索模块，以提供推理结构指导。我们的体系结构还旨在在保持令人满意的生成性能的同时，比现有模型更有效地计算效率。实验结果表明，在视觉质量，语义比对和时间连贯性方面，Vidclearn优于基线方法。|[2509.16956](http://arxiv.org/abs/2509.16956)|null|
|**2025-09-21**|**$\mathtt{M^3VIR}$: A Large-Scale Multi-Modality Multi-View Synthesized Benchmark Dataset for Image Restoration and Content Creation**|游戏和娱乐业正在迅速发展，这是由沉浸式体验和生成AI（GAI）技术的整合驱动的。有效地培训此类模型需要大规模数据集来捕获游戏环境的多样性和背景。但是，现有数据集通常仅限于特定域或依赖人工降解，而人工降解并不能准确捕获游戏内容的独特特征。此外，仍缺乏可控视频的基准。   为了解决这些限制，我们介绍了$ \ mathtt {m^3vir} $，这是一种大规模的多模式，多视图数据集，专门设计用于克服当前资源的缺点。与现有数据集不同，$ \ mathtt {m^3vir} $提供了多样的，高保真的游戏内容，并用虚幻引擎5呈现，在8个类别的80个场景中提供了真实的地面LR-HR配对和多视图框架。它包括$ \ Mathtt {M^3vir \ _mr} $用于超分辨率（SR），新颖的视图合成（NVS）和组合的NVS+SR任务，以及$ \ Mathtt {M^3vir \ _ {MS}} $，首次进行多型式的“启用”启用，以下设置了启动的研究。此外，我们基于建立性能基准的几种最先进的SR和NVS方法。尽管没有现有的方法直接处理受控视频生成，但$ \ mathtt {m^3vir}$ 为推进此区域提供了基准。通过释放数据集，我们旨在促进下一代云游戏和娱乐的AI驱动恢复，压缩和可控内容的研究。|[2509.16873](http://arxiv.org/abs/2509.16873)|null|
|**2025-09-20**|**FG-Attn: Leveraging Fine-Grained Sparsity In Diffusion Transformers**|用扩散变压器生成逼真的视频需要大量的计算，而注意力层则是中央瓶颈。即使产生一个短剪辑也需要在很长的嵌入序列上运行变压器，例如5秒视频的嵌入超过30k的嵌入，从而产生了显着的延迟。先前的工作旨在通过利用注意层中的稀疏性来减少计算来减轻这种瓶颈。但是，这些作品通常依赖于块 - 帕克斯的注意，只有当注意力分数中的所有条目（对应于M Queries和M键，通常为M = 64）时，它才会跳过计算计算。这种对注意力评分的粗粒度跳过并不能完全利用注意图中的稀疏性，并为改进留出了空间。在这项工作中，我们提出了FG-ATTN，这是一种稀疏的关注机制，用于长期延伸变压器，以颗粒状的粒度利用稀疏性。与块状块的注意不同，它跳过了整个MXM块，我们的方法跳过了注意力图的MX1切片的粒度计算。每个切片都是通过查询向量和一个键之间的查询点点产生的。为了实施我们提出的稀疏注意机制，我们开发了一种新的有效的大量负载操作，称为异步聚会负载。此加载操作从内存中收集了一组稀疏的相关键值向量，并将它们安排到GPU共享内存中的包装瓷砖中。在计算查询块的关注时，仅将与这些查询相关的一组稀疏键将其加载到共享内存中，这与将键令的完整块中的整个块中的块加载到块中的注意力中。我们的细粒度稀疏注意力应用于视频扩散模型，平均达到1.55倍（高达1.65倍）的速度，持续5秒，480p视频和平均1.41倍（高达1.49倍），持续5秒，720p视频，在单个H100 GPU上。|[2509.16518](http://arxiv.org/abs/2509.16518)|null|
|**2025-09-20**|**RLGF: Reinforcement Learning with Geometric Feedback for Autonomous Driving Video Generation**|合成数据对于推进自动驾驶（AD）系统至关重要，但是当前最新的视频生成模型尽管具有视觉现实主义，但仍遭受了微妙的几何扭曲，这些扭曲限制了其对下游感知任务的效用。我们识别并量化了这个关键问题，在使用合成数据与实际数据时，证明了3D对象检测的显着性能差距。为了解决这个问题，我们通过几何反馈（RLGF）介绍了增强学习，RLGF通过纳入专门的潜在空间广告感知模型的奖励来独特地完善视频扩散模型。它的核心组件包括在扩散过程中针对目标反馈的有效的潜在空间窗口优化技术，以及一个分层的几何奖励（HGR）系统，为点线平面比对提供多级奖励以及场景占用连贯性。为了量化这些扭曲，我们提出了地质。 RLGF应用于潜水的模型，将几何误差（例如，VP误差降低21 \％，深度误差，57 \％）将3D对象检测图提高到12.7 \％，从而将差距缩小到实时数据范围。 RLGF提供了一种插件解决方案，用于生成几何声音和可靠的合成视频，以进行广告开发。|[2509.16500](http://arxiv.org/abs/2509.16500)|null|
|**2025-09-19**|**Lynx: Towards High-Fidelity Personalized Video Generation**|我们提出了Lynx，这是一种来自单个输入图像的个性化视频合成的高保真模型。 Lynx建立在开源扩散变压器（DIT）基础模型的基础上，引入了两个轻巧的适配器，以确保身份保真度。 ID-ADAPTER采用感知器的重新采样器将斜面衍生的面部嵌入转换为紧凑的身份代币进行调节，而Ref-Adapter则通过交叉注意从冻结的参考途径中整合了冷冻参考途径的密集VAE特征，从而在所有变压器层中注入细粒度的细节。这些模块共同实现了稳健的身份，同时保持时间连贯性和视觉现实主义。通过对40名受试者和20个无偏的提示的精心策划的基准进行评估，产生了800个测试用例，Lynx表现出了出色的面部相似之处，竞争性的提示和强大的视频质量，从而提高了个性化视频生成的状态。|[2509.15496](http://arxiv.org/abs/2509.15496)|null|

<p align=right>(<a href=#updated-on-20250924>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-09-22**|**Learning Neural Antiderivatives**|神经领域提供的连续，可学习的表示形式超出了视觉计算中传统的离散格式。我们研究了直接从功能中学习反复抗激素的神经表示的问题，该功能是汇总表的连续类似物。尽管在离散域中广泛使用，但此类累积方案依赖于网格，从而阻止了它们在连续的神经环境中的适用性。我们介绍和分析一系列重复整合的神经方法，包括先前工作和新颖设计的改编。我们的评估涵盖了多个输入维度和集成订单，评估了诸如过滤和渲染等下游任务中的重建质量和性能。这些结果使将古典累积操作员整合到现代神经系统中，并为学习涉及差异和积分操作员的学习任务提供见解。|[2509.17755](http://arxiv.org/abs/2509.17755)|null|
|**2025-09-23**|**HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis**|最近，3D高斯脱落（3DG）已成为基于NERF的方法的有力替代品，可以通过明确的，可优化的3D高斯人实现实时，高质量的小说合成。但是，3DG由于依赖于高斯参数而遭受了重要的内存开销，因为它依赖于视图依赖性效应和各向异性形状。尽管最近的作品提出了具有神经场的压缩3DG，但这些方法努力捕获高斯性质的高频空间变化，从而导致细节的重新降低。我们提出了混合辐射场（HYRF），这是一种新颖的场景表示，结合了显式高斯和神经领域的优势。 HYRF将场景分解为（1）仅存储关键高频参数的紧凑型高斯和（2）基于网格的神经场，以预测其余特性。为了增强表示能力，我们引入了一个脱钩的神经场体系结构，分别建模几何形状（比例，不透明度，旋转）和视图依赖性颜色。此外，我们提出了一种混合渲染方案，该方案与神经场所预测的背景合成高斯裂片，以解决遥远场景表示中的局限性。实验表明，与3DG相比，HYRF达到了最新的渲染质量，同时将模型尺寸降低了20倍以上并保持实时性能。我们的项目页面可在https://wzpscott.github.io/hyrf/上找到。|[2509.17083](http://arxiv.org/abs/2509.17083)|null|
|**2025-09-02**|**INF-3DP: Implicit Neural Fields for Collision-Free Multi-Axis 3D Printing**|我们基于隐式神经场（INF）介绍了多轴3D打印的通用，可扩展的计算框架，该框架统一了工具路径生成和全球无冲动运动计划的所有阶段。在我们的管道中，输入模型表示为签名的距离字段，其制造目标（例如无支撑打印，表面饰面质量和挤出控制）直接在优化隐式指导字段的优化中进行编码。这种统一的方法可以在表面和内部域进行刀具路径优化，从而可以通过隐式场插值生成壳和填充路径。然后，在连续的季节场上共同优化了打印序列和多轴运动。我们的连续配方将不断发展的印刷对象构建为随时间变化的SDF，从而支持整个基于INF的运动计划中的可区分全球碰撞处理。与基于明确代表的方法相比，INF-3DP最多达到了两个数量级的速度，并显着降低了路点到地面误差。我们使用机器人辅助的多轴系统来验证各种复杂模型的框架，并通过物理制造实验来证明其效率。|[2509.05345](http://arxiv.org/abs/2509.05345)|null|
|**2025-09-03**|**Revealing Fine Structure in Protoplanetary Disks with Physics Constrained Neural Fields**|原月球磁盘是行星的出生地，解决其三维结构是理解磁盘进化的关键。阿尔玛（Alma）的前所未有的分辨率需要建模方法，以捕获超出传统方法触及的特征。我们介绍了一个计算框架，该计算框架将物理受限的神经场与可区分的渲染和Radjax集成在一起，Radjax是GPU加速的，完全可区分的线辐射传输求解器，可在常规射线示踪剂上实现高达10,000倍的加速，从而实现先前可靠的高维神经造型。该框架应用于HD 163296的ALMA CO观测值，恢复了富含共同层的垂直形态，揭示了超过400 AU的发射表面的明显变窄和变平 - 现有方法错过的特征。我们的工作建立了一个新的范式，用于提取复杂的磁盘结构并促进我们对原球门进化的理解。|[2509.03623](http://arxiv.org/abs/2509.03623)|null|
|**2025-08-27**|**Neural Field Turing Machine: A Differentiable Spatial Computer**|我们介绍了神经场图灵机（NFTM），这是一种在连续空间场内统一符号计算，物理模拟和感知推断的可区分体系结构。 NFTM结合了一个神经控制器，连续的内存字段和可移动的读/写头，以执行本地更新。在每个时间步中，控制器读取本地补丁，通过学习的规则计算更新，并在更新头部位置时写回。该设计实现了线性O（n）通过固定拉迪乌斯社区的扩展，同时在有限的误差下保持图丁完整性。我们演示了NFTM的三个示例实例：细胞自动机仿真（规则110），物理知识的PDE求解器（2D热方程）和迭代图像细化（CIFAR-10 Inpainting）。这些实例化学习了构成全球动态的本地更新规则，展示了稳定的长匹马推出并概括了训练范围的范围。 NFTM在单个可区分的框架内提供了统一的计算基板桥接离散算法和连续的场动力学。|[2509.03370](http://arxiv.org/abs/2509.03370)|null|
|**2025-09-03**|**PatchNet: A hierarchical approach for neural field-level inference from Quijote Simulations**|\ textIt {暗物质的立方gigaparsec的宇宙学信息内容是什么？ }从非线性物质分布中提取宇宙学信息具有很高的潜力，可以在下一代调查（例如Euclid，desi和Vera Rubin天文台）的时代加强参数约束。传统的方法依赖于诸如功率谱和双光谱之类的摘要统计数据，尽管可以在分析上进行处理，但未能捕获密度场的完整非高斯和非线性结构。基于仿真的推理（SBI）通过直接从前向模拟中学习提供了强大的替代方法。在这项工作中，我们将SBI应用于\ textIt {quijote}暗物质模拟，并引入了一种层次方法，该方法将来自字段子弹或\ textit {patches}的小规模信息与大规模统计数据（例如功率光谱和Biseptrum）相结合。这种混合策略在计算和所需培训数据的量上都是有效的。它克服了与全场培训相关的内存限制。我们表明，我们的方法增强了有关分析摘要的Fisher信息，并与非常不同的方法（基于小波的统计数据）相匹配，这提供了证据，证明我们正在估计 $\ sim 7.8〜 \ mathrm {mpc}/h$ 的分辨率下的暗物质密度字段的完整信息内容。|[2509.03165](http://arxiv.org/abs/2509.03165)|null|
|**2025-08-20**|**Gaussian Process Regression of Steering Vectors With Physics-Aware Deep Composite Kernels for Augmented Listening**|本文研究了麦克风的频率和位置的转向向量的连续表示，并通过对用户感知的声场进行精确控制，以增强听力的频率和源源（例如，空间滤波和双耳渲染）。转向向量通常用于表示声场的空间特性作为听力位置的函数。假设理想化环境的转向向量的基本代数表示无法处理声场的散射效果。因此，可以收集一组离散的真实转向向量，这些转向向量在专用的设施和超级溶解（即，取样）中测量。最近，物理学意识到的深度学习方法已被有效地用于此目的。然而，这种确定性的超分辨率由于在测量空间上的不确定性不确定而遭受了过度拟合的问题。为了解决这个问题，我们将基于神经场（NF）的表达式表示为基于高斯过程（GP）的原则性概率框架。具体而言，我们提出了一个物理感知的复合核，该内核对定向传入波和随后的散射效果进行了建模。我们的全面比较实验显示了在数据不足条件下提出的方法的有效性。在使用Spear Challenge的模拟数据（例如语音增强和双耳渲染）之类的下游任务中，甲骨文表演的测量值少于十倍。|[2509.02571](http://arxiv.org/abs/2509.02571)|null|
|**2025-08-27**|**DATR: Diffusion-based 3D Apple Tree Reconstruction Framework with Sparse-View**|数字双胞胎应用程序通过通过准确的物理资产的虚拟复制品实现实时监控和机器人模拟来提供变革潜力。这些系统的关键是具有高几何富达的3D重建。但是，现有的方法在现场条件下苦苦挣扎，尤其是稀疏和遮挡的观点。这项研究开发了一个两阶段的框架（DATR），用于从稀疏视图中重建苹果树。第一阶段利用板载传感器和基础模型，可以从复杂的字段图像中生成树罩。树蒙版用于在第二阶段的单形图表到3D重建中滤除多模式数据中的背景信息。此阶段由一个扩散模型和一个大型重建模型组成，用于各自的多视图和隐式神经场产生。扩散模型和LRM的训练是通过使用由Real2SIM数据生成器产生的逼真的合成苹果树实现的。该框架在字段和合成数据集上进行了评估。现场数据集包括六棵具有现场测量地面真相的苹果树，而合成数据集则具有结构上多样的树。评估结果表明，我们的DATR框架的表现优于两个数据集的现有3D重建方法，并实现了与工业级固定固定激光扫描仪相当的域特征估计，同时将吞吐量提高了 $\ sim$ 360倍，证明了可扩展的农业数字孪生双胞胎系统的强大潜力。|[2508.19508](http://arxiv.org/abs/2508.19508)|null|
|**2025-08-26**|**Graph Neural Network-Based Topology Optimization for Self-Supporting Structures in Additive Manufacturing**|本文介绍了一个基于机器学习的框架，用于拓扑优化自支撑结构，专门针对添加剂制造（AM）量身定制。通过采用图形神经网络（GNN），该神经网络在有限元网格上充当神经场，框架有效地学习并预测了连续的材料分布。集成的AM滤波器通过消除无支撑的悬垂性来确保可打印性，而优化过程可最大程度地减少体积和应力限制下的结构合规性。使用von Mises应力的可区分P-Norm聚集来实施应力限制，从而促进了优化设计中的机械可靠性。该方法的关键优势在于其完全可区分的体系结构，该体系结构在整个优化循环中利用自动差异化 - 取消对滤波器和应力约束的显式灵敏度派生的需求。数值实验证明了该框架在各种载荷和边界条件下生成应力受限的可制造拓扑的能力，从而提供了实用的途径，可以通过减少后处理要求进行AM-Ready高性能设计。|[2508.19169](http://arxiv.org/abs/2508.19169)|null|
|**2025-08-26**|**A Bag of Tricks for Efficient Implicit Neural Point Clouds**|隐式神经点云（INPC）是一种最近的混合表示，将神经场的表现力与基于点渲染的效率相结合，在新型视图合成中实现了最新的图像质量。但是，与其他在渲染过程中查询神经网络的其他高质量方法一样，INPC的实际可用性受到相对较慢的渲染限制。在这项工作中，我们提供了一系列优化，这些优化可以显着改善INPC的训练和推理性能，而不会牺牲视觉保真度。最重要的修改是改进的栅格实现，更有效的采样技术以及用于用于孔洞填充的卷积神经网络的预训练。此外，我们证明可以在推断过程中将点建模为小型高斯人，以进一步提高推断的质量，例如场景的特写视图。我们设计实施方法是在INPC之外广泛适用，并在一系列实验中系统地评估每个修改。我们优化的INPC管道可实现高达25％的训练，更快的渲染速度和20％的VRAM使用量与略有图像质量改进相结合。|[2508.19140](http://arxiv.org/abs/2508.19140)|null|

<p align=right>(<a href=#updated-on-20250924>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

