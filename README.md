[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2026.02.26
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#video-diffusion>Video Diffusion</a></li>
    <li><a href=#3d>3D</a></li>
    <li><a href=#具生智能&自动驾驶>具生智能&自动驾驶</a></li>
  </ol>
</details>

## Video Diffusion

- **2026-02-25** **Solaris: Building a Multiplayer Video World Model in Minecraft** [2602.22208](http://arxiv.org/abs/2602.22208)
  > 现有的动作条件视频生成模型（视频世界模型）仅限于单智能体视角，无法捕捉现实世界环境的多智能体交互。我们介绍 Solaris，这是一种模拟一致的多视图观察的多人视频世界模型。为了实现这一目标，我们开发了一个多人数据系统，专为《我的世界》等视频游戏的稳健、连续和自动化数据收集而设计。与之前为单人游戏设置构建的平台不同，我们的系统支持协调的多代理交互和同步视频+动作捕捉。使用该系统，我们收集了 1264 万个多人游戏帧，并提出了多人运动、记忆、接地、构建和视图一致性的评估框架。我们使用分阶段的管道来训练 Solaris，该管道逐渐从单人模式过渡到多人模式，结合了双向、因果和自我强迫训练。在最后阶段，我们引入了检查点自我强迫，这是一种内存高效的自我强迫变体，可以实现更长视野的教师。结果显示我们的架构和培训设计优于现有基线。通过开源我们的系统和模型，我们希望为新一代多智能体世界模型奠定基础。

- **2026-02-25** **Geometry-as-context: Modulating Explicit 3D in Scene-consistent Video Generation to Geometry Context** [2602.21929](http://arxiv.org/abs/2602.21929)
  > 场景一致的视频生成旨在创建基于摄像机轨迹探索 3D 场景的视频。以前的方法依赖具有外部存储器的视频生成模型来实现一致性，或者迭代 3D 重建和修复，这会在推理过程中由于不正确的中间输出、不可微分的过程和单独的模型而累积错误。为了克服这些限制，我们引入了“几何即上下文”。它使用自回归相机控制的视频生成模型迭代地完成以下步骤：（1）估计 3D 重建所需的当前视图的几何形状，以及（2）模拟和恢复 3D 场景渲染的新视图图像。在这个多任务框架下，我们开发了相机门控注意力模块，以增强模型有效利用相机姿势的能力。在训练阶段，利用文本上下文为了确定应该生成几何图像还是 RGB 图像，为了确保模型在推理过程中可以生成仅 RGB 的输出，从交错的文本-图像-几何训练序列中随机删除该方法，并在单向和前后轨迹的场景视频生成上进行了测试，结果表明其在保持场景一致性和摄像机控制方面优于以前的方法。

- **2026-02-25** **UniVBench: Towards Unified Evaluation for Video Foundation Models** [2602.21835](http://arxiv.org/abs/2602.21835)
  > 视频基础模型旨在将视频理解、生成、编辑和指令跟踪集成在一个框架内，使其成为下一代多模态系统的中心方向。然而，现有的评估基准仍然分散且范围有限，因为它们每个都针对单个任务，依赖于特定于任务的指标，并且通常使用短或简单的视频剪辑。因此，它们无法捕获这些模型旨在提供的统一功能。为了解决这一差距，我们引入了 UniVBench，这是一个专门为评估视频基础模型的四个核心能力而构建的基准：视频理解、视频生成、视频编辑，以及新提出的任务视频重建，该任务评估模型如何忠实地再现其遇到的视频内容。我们的基准测试通过纳入 200 个高质量、多样化的多镜头视频，每个视频都配有详细的标题、多格式编辑说明和参考图像，极大地扩展了评估的复杂性。所有视频均由人工创作并经过仔细验证，提供比之前的基准更丰富的电影信息。此外，我们开发了一个统一的代理评估系统（UniV-Eval），该系统标准化了所有任务的提示、指令解析和评分，从而实现了统一视频模型的公平、可扩展和可重复的比较。通过在基于指令的多镜头视频任务中进行基础评估，UniVBench 提供了第一个用于测量视频基础模型旨在实现的集成功能的框架。广泛的人工注释确保我们的评估与人类判断一致，从而实现严格的评估并加速实现强大的视频智能。

- **2026-02-25** **SkyReels-V4: Multi-modal Video-Audio Generation, Inpainting and Editing model** [2602.21818](http://arxiv.org/abs/2602.21818)
  > SkyReels V4 是一个统一的多模态视频基础模型，用于联合视频音频生成、修复和编辑。该模型采用双流多模态扩散变压器（MMDiT）架构，其中一个分支合成视频，另一个分支生成时间对齐的音频，同时共享基于多模态大语言模型（MMLM）的强大文本编码器。 SkyReels V4 接受丰富的多模式指令，包括文本、图像、视频剪辑、蒙版和音频参考。通过将 MMLM 多模态指令跟随功能与视频分支 MMDiT 中的上下文学习相结合，该模型可以在复杂条件下注入细粒度的视觉指导，而音频分支 MMDiT 同时利用音频参考来指导声音生成。在视频方面，我们采用通道串联公式，将图像到视频、视频扩展和视频编辑等多种修复风格任务统一在一个界面下，并通过多模式提示自然扩展到视觉参考修复和编辑。 SkyReels V4 支持高达 1080p 的分辨率、32 FPS 和 15 秒的持续时间，可生成具有同步音频的高保真、多镜头、影院级视频。为了使这种高分辨率、长时间的生成在计算上可行，我们引入了一种效率策略：联合生成低分辨率全序列和高分辨率关键帧，然后是专用的超分辨率和帧插值模型。据我们所知，SkyReels V4是第一个同时支持多模态输入、联合视频音频生成以及生成、修复和编辑统一处理的视频基础模型，同时在电影分辨率和时长上保持强大的效率和质量。

- **2026-02-25** **MultiAnimate: Pose-Guided Image Animation Made Extensible** [2602.21581](http://arxiv.org/abs/2602.21581)
  > 姿势引导的人体图像动画旨在合成由一系列姿势驱动的参考角色的逼真视频。虽然基于扩散的方法取得了显着的成功，但大多数现有方法仅限于单角色动画。我们观察到，天真地将这些方法扩展到多角色场景通常会导致角色之间的身份混乱和令人难以置信的遮挡。为了解决这些挑战，在本文中，我们提出了一种基于现代扩散变压器（DiT）的可扩展多字符图像动画框架，用于视频生成。我们的框架的核心引入了两个新颖的组件——标识符分配器和标识符适配器——它们协作捕获每个人的位置线索和人与人之间的空间关系。这种掩码驱动的方案以及可扩展的训练策略不仅增强了灵活性，而且还能够泛化到比训练期间看到的字符更多的场景。值得注意的是，我们的模型仅在两个字符数据集上进行训练，可推广到多字符动画，同时保持与单字符情况的兼容性。大量的实验表明，我们的方法在多字符图像动画中实现了最先进的性能，超越了现有的基于扩散的基线。

- **2026-02-24** **Towards Controllable Video Synthesis of Routine and Rare OR Events** [2602.21365](http://arxiv.org/abs/2602.21365)
  > 目的：整理包含罕见、安全关键或非典型事件的手术室 (OR) 工作流程的大规模数据集，在操作和道德上仍然具有挑战性。这一数据瓶颈使得用于检测、理解和缓解手术室中罕见或安全关键事件的环境智能的开发变得复杂。   方法：这项工作提出了一个 OR 视频扩散框架，可以控制罕见和安全关键事件的合成。该框架集成了几何抽象模块、调节模块和微调扩散模型，首先将 OR 场景转换为抽象几何表示，然后调节合成过程，最后生成逼真的 OR 事件视频。使用这个框架，我们还整理了一个合成数据集来训练和验证人工智能模型，以检测无菌区违规事件的险情。   结果：在合成常规 OR 事件时，我们的方法优于现成的视频扩散基线，在域内和域外数据集中实现了较低的 FVD/LPIPS 和较高的 SSIM/PSNR。通过定性结果，我们说明了其对反事实事件进行受控视频合成的能力。根据生成的合成数据进行训练和验证的 AI 模型在检测临近安全关键事件时实现了 70.13% 的召回率。最后，我们进行了一项消融研究，以量化关键设计选择带来的性能增益。   结论：我们的解决方案能够从抽象几何表示中控制合成常规和罕见的 OR 事件。除了展示其生成罕见和安全关键场景的能力之外，我们还展示了其支持环境智能模型开发的潜力。

- **2026-02-24** **HorizonForge: Driving Scene Editing with Any Trajectories and Any Vehicles** [2602.21333](http://arxiv.org/abs/2602.21333)
  > 可控驾驶场景生成对于真实且可扩展的自动驾驶模拟至关重要，但现有方法很难同时实现照片真实感和精确控制。我们推出了 Horizo​​nForge，这是一个统一的框架，可将场景重建为可编辑的高斯图和网格，从而实现细粒度的 3D 操作和语言驱动的车辆插入。编辑是通过噪声感知视频扩散过程进行渲染的，该过程强制执行空间和时间一致性，在单个前馈通道中产生不同的场景变化，而无需每个轨迹优化。为了标准化评估，我们进一步提出了 Horizo​​nSuite，这是一个涵盖自我和代理级别编辑任务（例如轨迹修改和对象操作）的综合基准。大量实验表明，高斯网格表示比其他 3D 表示具有更高的保真度，并且视频扩散的时间先验对于相干合成至关重要。结合这些发现，Horizo​​nForge 建立了一个简单而强大的范例，用于逼真、可控的驾驶模拟，与第二最佳的最先进方法相比，实现了 83.4% 的用户偏好增益和 25.19% 的 FID 改进。项目页面：https://horizo​​nforge.github.io/。

- **2026-02-24** **Human Video Generation from a Single Image with 3D Pose and View Control** [2602.21188](http://arxiv.org/abs/2602.21188)
  > 最近的扩散方法由于其强大的视觉生成能力，在从单个图像生成视频方面取得了重大进展。然而，图像到视频的合成仍然存在挑战，特别是在人类视频生成方面，从单个图像推断视图一致、运动相关的衣服皱纹仍然是一个艰巨的问题。在本文中，我们提出了 4D 人类视频生成 (HVG)，这是一种潜在视频扩散模型，能够从具有 3D 姿势和视图控制的单个图像生成高质量、多视图、时空连贯的人类视频。 HVG 通过三个关键设计实现了这一目标：(i) 关节姿势调制，通过新颖的二维骨图捕获 3D 关节的解剖关系，并通过引入 3D 信息解决跨视图的自遮挡问题； (ii) 视图和时间对齐，确保参考图像和姿势序列之间的多视图一致性和对齐，以实现帧到帧的稳定性； (iii) 渐进式时空采样与时间对齐，以保持长多视图动画中的平滑过渡。对图像到视频任务的大量实验表明，HVG 在从不同的人类图像和姿势输入生成高质量 4D 人类视频方面优于现有方法。

- **2026-02-24** **VII: Visual Instruction Injection for Jailbreaking Image-to-Video Generation Models** [2602.20999](http://arxiv.org/abs/2602.20999)
  > 图像到视频 (I2V) 生成模型在参考图像上调节视频生成，已显示出新兴的视觉指令跟踪功能，允许参考图像中的某些视觉提示充当视频生成的隐式控制信号。然而，这种功能也带来了一个以前被忽视的风险：对手可能会利用视觉指令通过图像模态注入恶意意图。在这项工作中，我们通过提出视觉指令注入（VII）来揭示这一风险，这是一种免训练且可转移的越狱框架，有意将不安全文本提示的恶意意图伪装成安全参考图像中的良性视觉指令。具体来说，VII 协调恶意意图重新编程模块，从不安全文本提示中提取恶意意图，同时最大限度地减少其静态危害性，并协调视觉指令接地模块，通过渲染与原始不安全文本提示保持语义一致性的视觉指令，将提取的意图接地到安全输入图像上，从而在 I2V 生成过程中引入有害内容。根据经验，我们对四种最先进的商业 I2V 模型（Kling-v2.5-turbo、Gemini Veo-3.1、Seedance-1.5-pro 和 PixVerse-V5）进行的广泛实验表明，VII 的攻击成功率高达 83.5%，同时将拒绝率降低到接近零，显着优于现有基线。

- **2026-02-25** **RAYNOVA: Scale-Temporal Autoregressive World Modeling in Ray Space** [2602.20685](http://arxiv.org/abs/2602.20685)
  > 世界基础模型旨在通过物理上合理的行为来模拟现实世界的演化。与之前分别处理空间和时间相关性的方法不同，我们提出了 RAYNOVA，这是一种采用双因果自回归框架的驾驶场景的几何对抗多视图世界模型。它在自回归过程中遵循尺度和时间拓扑顺序，并利用全局注意力进行统一的 4D 时空推理。与强加强 3D 几何先验的现有作品不同，RAYNOVA 基于相对 Plücker 射线位置编码构建了跨视图、帧和尺度的各向同性时空表示，从而能够对不同的相机设置和自我运动进行稳健的泛化。我们进一步引入了一种循环训练范例，以减轻长视野视频生成中的分布漂移。 RAYNOVA 在 nuScenes 上实现了最先进的多视图视频生成结果，同时在不同的输入条件下提供更高的吞吐量和强大的可控性，推广到新颖的视图和相机配置，而无需明确的 3D 场景表示。我们的代码将在 https://raynova-ai.github.io/ 发布。

- **2026-02-24** **GA-Drive: Geometry-Appearance Decoupled Modeling for Free-viewpoint Driving Scene Generatio** [2602.20673](http://arxiv.org/abs/2602.20673)
  > 自由视角、可编辑且高保真的驾驶模拟器对于训练和评估端到端自动驾驶系统至关重要。在本文中，我们提出了 GA-Drive，这是一种新颖的模拟框架，能够通过几何外观解耦和基于扩散的生成沿着用户指定的新颖轨迹生成相机视图。给定沿着记录轨迹捕获的一组图像和相应的场景几何形状，GA-Drive 使用几何信息合成新颖的伪视图。然后使用经过训练的视频扩散模型将这些伪视图转换为逼真的视图。通过这种方式，我们将场景的几何形状和外观解耦。这种解耦的优点是它支持通过最先进的视频到视频编辑技术进行外观编辑，同时保留底层几何形状，从而能够在原始和新颖的轨迹上进行一致的编辑。大量实验表明，GA-Drive 在 NTA-IoU、NTL-IoU 和 FID 分数方面明显优于现有方法。

- **2026-02-24** **PropFly: Learning to Propagate via On-the-Fly Supervision from Pre-trained Video Diffusion Models** [2602.20583](http://arxiv.org/abs/2602.20583)
  > 基于传播的视频编辑通过将单个编辑帧传播到后续帧中来实现精确的用户控制，同时保持原始上下文（例如运动和结构）。然而，训练此类模型需要大规模、配对（源和编辑）视频数据集，获取这些数据集成本高昂且复杂。因此，我们提出了 PropFly，一种基于传播的视频编辑的训练管道，依赖于预先训练的视频扩散模型 (VDM) 的即时监督，而不需要现成的或预先计算的配对视频编辑数据集。具体来说，我们的 PropFly 利用具有不同无分类器指导 (CFG) 尺度的中间噪声潜伏的一步干净潜伏估计来动态合成不同的“源”（低 CFG）和“编辑”（高 CFG）潜伏对。源潜在变量充当视频的结构信息，而编辑后的潜在变量提供学习传播的目标转换。我们的管道支持附加到预先训练的 VDM 的附加适配器，以学习通过引导调制流匹配 (GMFM) 损失来传播编辑，从而引导模型复制目标转换。我们的动态监督确保模型能够学习时间一致的动态转换。大量实验表明，我们的 PropFly 在各种视频编辑任务上显着优于最先进的方法，产生高质量的编辑结果。

- **2026-02-24** **LESA: Learnable Stage-Aware Predictors for Diffusion Model Acceleration** [2602.20497](http://arxiv.org/abs/2602.20497)
  > 扩散模型在图像和视频生成任务中取得了显着的成功。然而，扩散变压器（DiT）的高计算要求对其实际部署提出了重大挑战。虽然特征缓存是一种很有前途的加速策略，但基于简单重用或免训练预测的现有方法很难适应扩散过程的复杂、阶段相关的动态，通常会导致质量下降，并且无法保持与标准去噪过程的一致性。为了解决这个问题，我们提出了一个基于两阶段训练的 LEarnable Stage-Aware (LESA) 预测器框架。我们的方法利用柯尔莫哥洛夫-阿诺德网络（KAN）来准确地从数据中学习时间特征映射。我们进一步引入了多阶段、多专家架构，将专门的预测器分配给不同的噪声级别阶段，从而实现更精确和稳健的特征预测。大量的实验表明，我们的方法在保持高保真生成的同时实现了显着的加速。实验表明，FLUX.1-dev 上的加速为 5.00 倍，质量下降最小（下降 1.0%）；Qwen-Image 上的加速为 6.25 倍，与之前的 SOTA（TaylorSeer）相比，质量提高了 20.2%；HunyuanVideo 上的加速为 5.00 倍，PSNR 比 TaylorSeer 提高了 24.7%。文本到图像和文本到视频合成的最先进性能验证了我们基于训练的框架在不同模型上的有效性和泛化能力。我们的代码包含在补充材料中，并将在 GitHub 上发布。

- **2026-02-23** **3DSPA: A 3D Semantic Point Autoencoder for Evaluating Video Realism** [2602.20354](http://arxiv.org/abs/2602.20354)
  > 人工智能视频生成正在迅速发展。为了使视频生成器能够用于从机器人到电影制作等各种应用，它们必须始终如一地生成逼真的视频。然而，评估生成视频的真实感仍然是一个很大程度上手动的过程——需要人工注释或范围有限的定制评估数据集。在这里，我们开发了一个视频真实感自动评估框架，它可以捕获语义和连贯的 3D 结构，并且不需要访问参考视频。我们的方法 3DSPA 是一种 3D 时空点自动编码器，它将 3D 点轨迹、深度线索和 DINO 语义特征集成到视频评估的统一表示中。 3DSPA 对物体如何移动以及场景中发生的情况进行建模，从而能够对真实性、时间一致性和物理合理性进行可靠的评估。实验表明，3DSPA 能够可靠地识别违反物理定律的视频，对运动伪影更敏感，并且更符合人类对多个数据集的视频质量和真实感的判断。我们的结果表明，利用 3D 语义丰富基于轨迹的表示为基准生成视频模型提供了更坚实的基础，并隐式捕获物理规则违规行为。代码和预训练模型权重将在 https://github.com/TheProParadox/3dspa_code 上提供。

- **2026-02-23** **NovaPlan: Zero-Shot Long-Horizon Manipulation via Closed-Loop Video Language Planning** [2602.20119](http://arxiv.org/abs/2602.20119)
  > 解决长期任务需要机器人将高级语义推理与低级物理交互相结合。虽然视觉语言模型 (VLM) 和视频生成模型可以分解任务并想象结果，但它们通常缺乏现实世界执行所需的物理基础。我们引入了 NovaPlan，这是一个分层框架，它将闭环 VLM 和视频规划与几何接地机器人执行相结合，以实现零样本长视野操作。在高层，VLM 规划器将任务分解为子目标，并在闭环中监控机器人的执行情况，使系统能够通过自主重新规划从单步故障中恢复。为了计算低级机器人动作，我们从生成的视频中提取并利用与任务相关的对象关键点和人手姿势作为运动学先验，并采用切换机制来选择更好的动作作为机器人动作的参考，即使在严重遮挡或深度不准确的情况下也能保持稳定的执行。我们展示了 NovaPlan 在三项长期任务和功能操作基准（FMB）上的有效性。我们的结果表明，NovaPlan 可以执行复杂的组装任务并表现出灵巧的错误恢复行为，而无需任何事先演示或培训。项目页面：https://nova-plan.github.io/

- **2026-02-23** **PedaCo-Gen: Scaffolding Pedagogical Agency in Human-AI Collaborative Video Authoring** [2602.19623](http://arxiv.org/abs/2602.19623)
  > 虽然文本到视频 (T2V) 生成式人工智能的进步为内容创作民主化提供了一条充满希望的道路，但当前的模型通常针对视觉保真度而不是教学效果进行优化。本研究介绍了 PedaCo-Gen，这是一种基于教学的人类与人工智能协作视频生成系统，用于根据 Mayer 的多媒体学习认知理论 (CTML) 创作教学视频。 PedaCo-Gen 摆脱了传统的“一次性”生成，引入了中间表示 (IR) 阶段，使教育工作者能够与人工智能审阅者交互地审阅和完善视频蓝图（包括脚本和视觉描述）。我们与 23 名教育专家进行的研究表明，与基线相比，PedaCo-Gen 显着提高了各种主题和 CTML 原则的视频质量。参与者认为人工智能驱动的指导不仅是一组指令，而且是一个元认知支架，可以增强他们的教学设计专业知识，报告高生产效率（M = 4.26）和指南有效性（M = 4.04）。这些发现强调了通过有原则的共同创造来恢复教学机构的重要性，为未来将生成能力与人类专业知识相协调的人工智能创作工具奠定了基础。

- **2026-02-22** **UniE2F: A Unified Diffusion Framework for Event-to-Frame Reconstruction with Video Foundation Models** [2602.19202](http://arxiv.org/abs/2602.19202)
  > 事件摄像机擅长高速、低功耗和高动态范围场景感知。然而，由于它们从根本上只记录相对强度变化而不是绝对强度，因此生成的数据流会遭受空间信息和静态纹理细节的显着损失。在本文中，我们通过利用预训练视频扩散模型的生成先验从稀疏事件数据重建高保真视频帧来解决这一限制。具体来说，我们首先通过直接应用事件数据作为合成视频的条件来建立基线模型。然后，基于事件流和视频帧之间的物理相关性，我们进一步引入基于事件的帧间残差引导，以提高视频帧重建的准确性。此外，我们通过调制反向扩散采样过程，以零镜头方式将我们的方法扩展到视频帧插值和预测，从而创建统一的事件到帧重建框架。现实世界和合成数据集的实验结果表明，我们的方法在数量和质量上都显着优于以前的方法。我们还向审稿人推荐视频结果补充材料中包含的视频演示。该代码将在 https://github.com/CS-GangXu/UniE2F 上公开提供。

- **2026-02-22** **JavisDiT++: Unified Modeling and Optimization for Joint Audio-Video Generation** [2602.19163](http://arxiv.org/abs/2602.19163)
  > AIGC 已从文本到图像的生成迅速扩展到跨视频和音频的高质量多模态合成。在此背景下，联合音视频生成（JAVG）已成为一项基本任务，它可以根据文本描述生成同步且语义一致的声音和视觉。然而，与 Veo3 等先进商业模型相比，现有的开源方法在生成质量、时间同步性以及与人类偏好的一致性等方面仍然存在局限性。为了弥补这一差距，本文提出了 JavisDiT++，这是一个简洁而强大的框架，用于 JAVG 的统一建模和优化。首先，我们引入了一种特定模态的专家混合（MS-MoE）设计，该设计可以实现跨模态交互功效，同时提高单模态生成质量。然后，我们提出了一种时间对齐 RoPE (TA-RoPE) 策略来实现音频和视频令牌之间的显式帧级同步。此外，我们开发了一种音视频直接偏好优化（AV-DPO）方法，使模型输出在质量、一致性和同步维度上与人类偏好保持一致。我们的模型基于 Wan2.1-1.3B-T2V 构建，仅通过大约 100 万个公共训练条目就实现了最先进的性能，在定性和定量评估方面都显着优于先前的方法。已经进行了全面的消融研究来验证我们提出的模块的有效性。所有代码、模型和数据集均在 https://JavisVerse.github.io/JavisDiT2-page 发布。

- **2026-02-22** **Flash-VAED: Plug-and-Play VAE Decoders for Efficient Video Generation** [2602.19161](http://arxiv.org/abs/2602.19161)
  > 潜在扩散模型已经实现了高质量的视频合成，但其推理仍然成本高昂且耗时。随着扩散变压器变得越来越高效，延迟瓶颈不可避免地转移到 VAE 解码器。为了在保持质量的同时减少延迟，我们提出了一种适用于 VAE 解码器的通用加速框架，该框架保持与原始潜在分布的完全对齐。具体来说，我们提出（1）一种独立感知的通道修剪方法，以有效减轻严重的通道冗余，以及（2）一种分阶段的主导算子优化策略，以解决 VAE 解码器中广泛使用的因果 3D 卷积的高推理成本问题。基于这些创新，我们构建了 Flash-VAED 系列。此外，我们设计了一个三相动态蒸馏框架，可以有效地将原始 VAE 解码器的功能转移到 Flash-VAED。在 Wan 和 LTX-Video VAE 解码器上进行的大量实验表明，我们的方法在质量和速度方面都优于基线，实现了大约 6 倍的加速，同时保持了高达 96.9% 的重建性能。值得注意的是，Flash-VAED 将端到端生成流程加速高达 36%，而 VBench-2.0 上的质量下降可以忽略不计。

- **2026-02-22** **Ani3DHuman: Photorealistic 3D Human Animation with Self-guided Stochastic Sampling** [2602.19089](http://arxiv.org/abs/2602.19089)
  > 当前的 3D 人体动画方法很难实现照片级真实感：基于运动学的方法缺乏非刚性动力学（例如服装动力学），而利用视频扩散先验的方法可以合成非刚性运动，但会遭受质量伪影和身份损失。为了克服这些限制，我们提出了 Ani3DHuman，一个将基于运动学的动画与视频扩散先验相结合的框架。我们首先引入分层运动表示，将刚性运动与残余非刚性运动分开。刚性运动是通过运动学方法生成的，然后产生粗略渲染以指导视频扩散模型生成恢复残余非刚性运动的视频序列。然而，这种基于扩散采样的恢复任务非常具有挑战性，因为初始渲染不符合分布，导致标准确定性 ODE 采样器失败。因此，我们提出了一种新颖的自引导随机采样方法，该方法通过将随机采样（用于真实感质量）与自引导（用于身份保真度）相结合，有效地解决了分布外问题。这些恢复的视频提供高质量的监督，从而能够优化残余非刚性运动场。大量实验表明 \MethodName 可以生成逼真的 3D 人体动画，性能优于现有方法。代码可在 https://github.com/qiisun/ani3d human 中找到。

- **2026-02-21** **RoboCurate: Harnessing Diversity with Action-Verified Neural Trajectory for Robot Learning** [2602.18742](http://arxiv.org/abs/2602.18742)
  > 视频生成模型生成的合成数据已显示出机器人学习作为可扩展管道的前景，但由于生成的视频不完美，它经常会出现动作质量不一致的问题。最近，视觉语言模型（VLM）已被用来验证视频质量，但它们在区分物理准确的视频方面存在局限性，即使如此，也无法直接评估生成的动作本身。为了解决这个问题，我们引入了 RoboCurate，这是一种新颖的合成机器人数据生成框架，它通过将注释动作与模拟回放进行比较来评估和过滤注释动作的质量。具体来说，RoboCurate 在模拟器中重播预测的动作，并通过测量模拟器推出和生成的视频之间的运动一致性来评估动作质量。此外，我们通过图像到图像编辑解锁可用数据集之外的观察多样性，并应用保留动作的视频到视频传输来进一步增强外观。我们观察到，与仅使用真实数据相比，RoboCurate 生成的数据在成功率方面取得了显着的相对提高，在 GR-1 Tabletop（300 个演示）上实现了 +70.1%，在预训练设置中在 DexMimicGen 上实现了 +16.1%，在具有挑战性的现实世界 ALLEX 人形灵巧操作设置中实现了 +179.9%。

- **2026-02-20** **Narrating For You: Prompt-guided Audio-visual Narrating Face Generation Employing Multi-entangled Latent Space** [2602.18618](http://arxiv.org/abs/2602.18618)
  > 我们提出了一种新颖的方法，通过从静态图像、语音配置文件和目标文本合成人的声音和面部动作来生成逼真的说话和说话的面孔。该模型对提示/驾驶文本、驾驶图像和个人语音档案进行编码，然后将它们组合起来，将它们传递到多重纠缠潜在空间，以促进音频和视频模态生成管道的键值对和查询。多重纠缠的潜在空间负责建立模态之间的时空个人特定特征。此外，纠缠特征被传递到每种模态的相应解码器以生成输出音频和视频。

- **2026-02-20** **Generated Reality: Human-centric World Simulation using Interactive Video Generation with Hand and Camera Control** [2602.18422](http://arxiv.org/abs/2602.18422)
  > 扩展现实（XR）需要生成模型来响应用户跟踪的现实世界运动，但当前的视频世界模型仅接受粗略的控制信号，例如文本或键盘输入，限制了它们在实体交互中的实用性。我们引入了一种以人为中心的视频世界模型，该模型以跟踪的头部姿势和关节级手部姿势为条件。为此，我们评估了现有的扩散变压器调节策略，并提出了一种有效的 3D 头部和手部控制机制，实现灵巧的手-物体交互。我们使用这种策略训练双向视频传播模型教师，并将其提炼成一个因果交互系统，生成以自我为中心的虚拟环境。我们用人类受试者评估了这个生成的现实系统，并证明了与相关基线相比，任务绩效得到了改善，并且对所执行的操作的感知控制程度显着提高。

- **2026-02-20** **Predict to Skip: Linear Multistep Feature Forecasting for Efficient Diffusion Transformers** [2602.18093](http://arxiv.org/abs/2602.18093)
  > 扩散变压器（DiT）已成为广泛采用的高保真图像和视频生成的骨干，但其迭代去噪过程会产生高昂的计算成本。现有的免训练加速方法依赖于时间稳定性假设下的特征缓存和重用。然而，在多个步骤中重用特征可能会导致潜在漂移和视觉退化。我们观察到模型输出沿着大部分扩散轨迹平稳演变，从而实现有原则的预测而不是幼稚的重用。基于这一见解，我们提出了 \textbf{PrediT}，这是一种免训练加速框架，它将特征预测表述为线性多步问题。我们采用经典的线性多步方法根据历史信息预测未来的模型输出，并结合在高动态区域激活的校正器以防止误差累积。动态步进调制机制通过监控特征变化率来自适应调整预测范围。这些组件共同实现了大幅加速，同时保持了生成保真度。大量实验验证，我们的方法在各种基于 DiT 的图像和视频生成模型中实现了高达 5.54 美元×$ 的延迟减少，同时引起的质量下降可以忽略不计。

- **2026-02-20** **A Single Image and Multimodality Is All You Need for Novel View Synthesis** [2602.17909](http://arxiv.org/abs/2602.17909)
  > 基于扩散的方法最近通过调节从单目深度估计推断出的几何形状的生成模型，证明了单图像新颖视图合成的强大性能。然而，在实践中，合成视图的质量和一致性从根本上受到底层深度估计可靠性的限制，在低纹理、恶劣天气和遮挡严重的现实世界条件下，这些估计通常很脆弱。在这项工作中，我们表明，结合稀疏多模态范围测量提供了一种简单而有效的方法来克服这些限制。我们引入了一种多模态深度重建框架，该框架利用极其稀疏的距离感测数据（例如汽车雷达或激光雷达）来生成密集的深度图，作为基于扩散的新颖视图合成的稳健几何条件。我们的方法使用局部高斯过程公式对角域中的深度进行建模，从而实现计算高效的推理，同时明确量化观测有限的区域中的不确定性。重建的深度和不确定性被用作现有基于扩散的渲染管道中单目深度估计器的直接替代品，而无需修改生成模型本身。对现实世界多模态驾驶场景的实验表明，用基于稀疏范围的重建替换仅视觉深度可以显着提高单图像新颖视图视频生成中的几何一致性和视觉质量。这些结果强调了可靠的几何先验对于基于扩散的视图合成的重要性，并证明了即使在极端稀疏的情况下多模态传感的实际好处。


<p align=right>(<a href=#updated-on-20260226>back to top</a>)</p>

## 3D

- **2026-02-25** **Electrical coupling of a horizontal dipole antenna to a dielectric half-space: applications to radio astronomy from the lunar surface** [2602.22194](http://arxiv.org/abs/2602.22194)
  > 月球的背面不受地面无线电频率干扰，也不受地球电离层的影响，应该为射电天文学和宇宙学实验提供独特的安静环境。 30 MHz 以下的射电天空很大程度上尚未被探索，并且被认为包含早期高红移宇宙中新物理的光谱特征。要在此频段实现精确测量，需要准确了解天线性能和系统学。对于即将到来的月球表面射电天文学任务，这种建模将具有挑战性，因为天线将部署在距离月球风化层上方波长一小部分的高度，天线和表面之间的强耦合会显着改变阻抗、辐射模式和效率。风化层的层状介电结构和介电常数随深度增加的趋势使这一挑战变得更加复杂，这两者都很难在数值模拟中忠实地表示。   在这项工作中，我们回顾了对介电半空间上方的简单水平偶极子（代表月球风化层）行为的理论预测，并将其与使用 Ansys HFSS 积分方程求解器获得的仿真结果进行比较。我们量化了代表性月球表面射电天文学实验的天线阻抗和波束方向图如何与天空耦合。结果表明，即使风化层上方的天线高度适度增加，表面感应效应也会迅速减弱。相反，放置在月球表面或非常靠近月球表面的偶极天线将表现出复杂的光谱响应，如果没有风化层特性的详细信息，系统控制将变得非常困难。

- **2026-02-25** **Budgeted Active Experimentation for Treatment Effect Estimation from Observational and Randomized Data** [2602.22021](http://arxiv.org/abs/2602.22021)
  > 估计异质治疗效果是数据驱动决策的核心，但工业应用常常面临有限的随机对照试验 (RCT) 预算与根据历史目标政策收集的丰富但有偏见的观察数据之间的根本紧张关系。尽管观测日志具有规模优势，但它们本质上受到政策引起的严重不平衡和重叠违规的影响，导致独立估计不可靠。我们提出了一个预算主动实验框架，该框架通过主动采样迭代增强因果效应估计的模型训练。通过利用观察先验，我们开发了一个针对提升估计不确定性、重叠赤字和域差异的采集函数，以选择信息最丰富的单元进行随机实验。我们建立有限样本偏差界限、通过鞅中心极限定理 (CLT) 的渐近正态性和极小极大下界来证明信息论最优性。对工业数据集的大量实验表明，我们的方法在成本受限的环境中显着优于标准随机基线。

- **2026-02-25** **Geometry-as-context: Modulating Explicit 3D in Scene-consistent Video Generation to Geometry Context** [2602.21929](http://arxiv.org/abs/2602.21929)
  > 场景一致的视频生成旨在创建基于摄像机轨迹探索 3D 场景的视频。以前的方法依赖具有外部存储器的视频生成模型来实现一致性，或者迭代 3D 重建和修复，这会在推理过程中由于不正确的中间输出、不可微分的过程和单独的模型而累积错误。为了克服这些限制，我们引入了“几何即上下文”。它使用自回归相机控制的视频生成模型迭代地完成以下步骤：（1）估计 3D 重建所需的当前视图的几何形状，以及（2）模拟和恢复 3D 场景渲染的新视图图像。在这个多任务框架下，我们开发了相机门控注意力模块，以增强模型有效利用相机姿势的能力。在训练阶段，利用文本上下文为了确定应该生成几何图像还是 RGB 图像，为了确保模型在推理过程中可以生成仅 RGB 的输出，从交错的文本-图像-几何训练序列中随机删除该方法，并在单向和前后轨迹的场景视频生成上进行了测试，结果表明其在保持场景一致性和摄像机控制方面优于以前的方法。

- **2026-02-25** **The Silent Spill: Measuring Sensitive Data Leaks Across Public URL Repositories** [2602.21826](http://arxiv.org/abs/2602.21826)
  > 各种平台公开了大量 URL，用于安全分析、存档和粘贴共享，例如 VirusTotal、URLScan.io、Hybrid Analysis、Wayback Machine 和 RedHunt。正如一些新闻文章和博客文章中所报道的那样，这些服务可能会无意中暴露包含敏感信息的链接。然而，还没有大规模的测量来量化此类暴露的程度。我们提出了一个自动化系统，可以检测和分析通过可公开访问的 URL 泄露的潜在敏感信息。该系统结合了词汇 URL 过滤、动态渲染、基于 OCR 的提取和内容分类来识别潜在的泄漏。我们将其应用于从公共扫描平台、粘贴网站和网络档案收集的 6,094,475 个 URL，识别出身份验证、财务、个人和文档相关领域的 12,331 个潜在风险。这些发现表明敏感信息仍然暴露，强调了自动检测以识别意外泄漏的重要性。

- **2026-02-25** **Joint Shadow Generation and Relighting via Light-Geometry Interaction Maps** [2602.21820](http://arxiv.org/abs/2602.21820)
  > 我们提出了光几何交互（LGI）图，这是一种从单眼深度编码光感知遮挡的新颖表示。与需要完整 3D 重建的光线追踪不同，LGI 能够可靠、准确地捕获基本的光影交互，并根据现成的 2.5D 深度图预测进行计算。 LGI 明确地将照明方向与几何形状联系起来，提供了一个受物理启发的先验来约束生成模型。如果没有这样的先验，这些模型通常会产生浮动阴影、不一致的照明和不可信的阴影几何形状。在此表示的基础上，我们提出了一个用于联合阴影生成和重新照明的统一管道（与将它们视为不相交任务的先前方法不同），捕获对于建模间接效果至关重要的照明和阴影的内在耦合。通过将 LGI 嵌入到桥匹配生成主干中，我们减少了歧义并强制执行物理上一致的光影推理。为了实现有效的训练，我们策划了第一个用于联合阴影和重新照明的大型基准数据集，涵盖反射、透明度和复杂的相互反射。实验表明，合成图像和真实图像的真实性和一致性有了显着提高。因此，LGI 将几何启发的渲染与生成建模联系起来，实现高效、物理一致的阴影生成和重新照明。

- **2026-02-25** **SemVideo: Reconstructs What You Watch from Brain Activity via Hierarchical Semantic Guidance** [2602.21819](http://arxiv.org/abs/2602.21819)
  > 从大脑活动重建动态视觉体验为探索人类视觉感知的神经机制提供了一条引人注目的途径。虽然基于功能磁共振成像的图像重建最近取得了显着的进展，但将这一成功扩展到视频重建仍然是一个重大挑战。当前的功能磁共振成像到视频重建方法始终遇到两个主要缺点：（i）跨帧的显着对象的视觉表示不一致，导致外观不匹配； (ii) 时间相干性差，导致运动错位或突然的帧过渡。为了解决这些限制，我们引入了 SemVideo，一种由分层语义信息引导的新型 fMRI 到视频重建框架。 SemVideo 的核心是 SemMiner，这是一个分层指导模块，它根据原始视频刺激构建三个级别的语义线索：静态锚点描述、面向运动的叙述和整体摘要。利用这种语义指导，SemVideo 包含三个关键组件：语义对齐解码器，将 fMRI 信号与源自 SemMiner 的 CLIP 式嵌入对齐；运动适应解码器，使用新颖的三方注意力融合架构重建动态运动模式；以及条件视频渲染，利用分层语义指导进行视频重建。在 CC2017 和 HCP 数据集上进行的实验表明，SemVideo 在语义对齐和时间一致性方面均实现了卓越的性能，在 fMRI 到视频重建方面树立了新的最先进水平。

- **2026-02-25** **From Statics to Dynamics: Physics-Aware Image Editing with Latent Transition Priors** [2602.21778](http://arxiv.org/abs/2602.21778)
  > 基于指令的图像编辑在语义对齐方面取得了显着的成功，但当编辑涉及复杂的因果动态（例如折射或材料变形）时，最先进的模型经常无法呈现物理上合理的结果。我们将此限制归因于主流范式，该范式将编辑视为图像对之间的离散映射，它仅提供边界条件并且未指定过渡动态。为了解决这个问题，我们将物理感知编辑重新表述为预测物理状态转换，并引入了 PhysicTran38K，这是一个基于视频的大型数据集，包含跨五个物理域的 38K 转换轨迹，通过两级过滤和约束感知注释管道构建。在此监督的基础上，我们提出了PhysicEdit，一个配备文本-视觉双重思维机制的端到端框架。它将用于物理基础推理的冻结 Qwen2.5-VL 与可学习的转换查询相结合，为扩散主干提供时间步自适应视觉指导。实验表明，PhysicEdit 在物理真实感方面比 Qwen-Image-Edit 提高了 5.9%，在基于知识的编辑方面提高了 10.1%，为开源方法树立了新的最先进水平，同时保持与领先的专有模型的竞争力。

- **2026-02-25** **Adaptive isogeometric analysis of high-order phase-field fracture based on THB-splines** [2602.21685](http://arxiv.org/abs/2602.21685)
  > 近几十年来，固体中断裂扩展的研究越来越依赖于相场模型。最近的一些贡献强调了这种方法在静态和动态框架中的潜力。然而，一个主要限制仍然是高计算成本。已经确定了两种主要策略来缓解这个问题：使用局部细化网格和采用高阶模型。在这项工作中，我们利用截断分层 B 样条（THB 样条）引入了高阶相场公式（AT1 和 AT2）的自适应模拟，主要关注二维断裂问题。

- **2026-02-25** **Space-Time Forecasting of Dynamic Scenes with Motion-aware Gaussian Grouping** [2602.21668](http://arxiv.org/abs/2602.21668)
  > 预测动态场景仍然是计算机视觉中的一个基本挑战，因为有限的观测使得捕捉连贯的物体级运动和长期时间演化变得困难。我们提出了运动组感知高斯预测 (MoGaF)，这是一个基于 4D 高斯泼溅表示的长期场景外推框架。 MoGaF 引入了运动感知高斯分组和分组优化，以在刚性和非刚性区域上强制执行物理一致的运动，从而产生空间相干的动态表示。利用这种结构化的时空表示，轻量级预测模块可以预测未来的运动，从而实现现实且时间稳定的场景演化。对合成数据集和真实数据集的实验表明，MoGaF 在渲染质量、运动合理性和长期预测稳定性方面始终优于现有基线。我们的项目页面位于 https://slime0519.github.io/mogaf

- **2026-02-25** **Pure-amplitude holograms for high-efficiency generation of phase radial grating based radial carpet beams: Theory and experiments under plane-wave and Gaussian illumination** [2602.21656](http://arxiv.org/abs/2602.21656)
  > 本研究介绍了一种用于生成径向地毯光束 (RCB) 的纯振幅全息图 (PAH)，传统上使用纯相位径向光栅 (PRG) 生成径向地毯光束 (RCB)。全息图是通过将二元 PRG 的传输函数嵌入到幅度线性光栅的余弦项的相位参数中来设计的。当用平面波照射时，该全息图会生成非零衍射级的 RCB，而当用高斯光束照射时，它会在特定的传播距离处生成类似 RCB 的图案。这种方法完全消除了对复杂且昂贵的空间光调制器（SLM）的需求。该研究提出了来自此类全息图的平面光束和高斯光束的衍射理论，包括来自 PRG 的高斯光束衍射的具体理论处理。通过理论分析和实验，我们证明了当照明光束是平面波时，由于衍射级数乘以嵌入式基础PRG的相位幅度所产生的相位幅度增强，如何在不同的衍射级产生不同的RCB。对于高斯光束情况，我们展示了如何出于相同的原因在不同的衍射级生成不同的类似 RCB 的图案，尽管仅在特定的传播距离处。实验和数值结果表明，该技术产生的 RCB 和类似 RCB 的图案的有用功率约为 SLM 生成的同类图案的五倍，显示出显着更高的功率效率。这一优点使得所提出的方法非常适合多重光捕获和自由空间光通信等应用。

- **2026-02-24** **Region of Interest Segmentation and Morphological Analysis for Membranes in Cryo-Electron Tomography** [2602.21195](http://arxiv.org/abs/2602.21195)
  > 冷冻电子断层扫描 (cryo-ET) 能够对生物结构（包括膜和膜蛋白）进行高分辨率、三维重建。感兴趣区域 (ROI) 的识别是科学成像的核心，因为它可以对复杂数据集中的特定结构特征进行隔离和定量分析。然而，在实践中，投资回报率通常是通过完整的结构分割和事后分析间接得出的。对于连续且几何复杂的结构（例如被分割为单个实体的膜），这种限制尤其明显。在这里，我们开发了 TomoROIS-SurfORA，这是一个两步框架，用于直接、形状无关的 ROI 分割和形态表面分析。 TomoROIS 执行基于深度学习的 ROI 分割，并且可以使用小型注释数据集从头开始训练，从而实现跨不同成像数据的实际应用。 SurfORA 将分段结构处理为点云和表面网格，以提取定量形态特征，包括膜间距离、曲率和表面粗糙度。它支持封闭和开放表面，并特别考虑开放表面，由于缺少楔形效应，开放表面在冷冻电子断层扫描中很常见。我们展示了两种工具，使用含有复杂几何形状的可变形囊泡的体外重构膜系统，能够自动定量分析膜接触位点和内陷等重塑事件。虽然此处在冷冻 ET 膜数据上进行了演示，但组合方法适用于更广泛的科学成像环境中的 ROI 检测和表面分析。

- **2026-02-24** **Circumventing the CAP Theorem with Open Atomic Ethernet** [2602.21182](http://arxiv.org/abs/2602.21182)
  > CAP 定理通常被视为系统法则：在网络分区下，复制服务必须牺牲一致性或可用性。该定理在其标准异步网络模型中是正确的，但操作实践取决于在哪里可以观察到类似分区的现象，以及较低层如何丢弃或保留有关消息命运的语义信息。本文认为，开放原子以太网 (OAE) 改变了工程机制，使 CAP 权衡变得对应用程序可见，方法是：(i) 用端点状态的有限时间双边协调（我们称之为双同步的属性）取代即发即忘链路语义，以及 (ii) 通过八价网格避免 Clos 漏斗点，其中每个节点都可以充当本地修复的生成树的根。其结果不是消除硬图切割，而是通过在数百纳秒内检测和修复主要结构缺陷，大幅减少应用程序可见的“软分区”的频率和持续时间。我们将此观点与 Brewer 的原始 CAP 框架、Gilbert 和 Lynch 的形式化、Lee 等人的 CAL 定理（用表观延迟的定量度量取代二进制分区容差）以及 Abadi 的 PACELC 扩展联系起来。

- **2026-02-24** **Seeing Through Words: Controlling Visual Retrieval Quality with Language Models** [2602.21175](http://arxiv.org/abs/2602.21175)
  > 文本到图像检索是视觉语言学习中的一项基本任务，但在现实场景中，它经常受到简短且不明确的用户查询的挑战。此类查询通常只有一两个单词长，导致语义模糊，容易在不同的视觉解释之间发生冲突，并且缺乏对检索图像质量的明确控制。为了解决这些问题，我们提出了一种新的质量可控检索范例，它用上下文细节丰富了简短的查询，同时结合了图像质量的明确概念。我们的关键思想是利用生成语言模型作为查询完成功能，将未指定的查询扩展到描述性形式，以捕获细粒度的视觉属性，例如姿势、场景和美学。我们引入了一个通用框架，该框架在离散质量级别上条件查询完成，该质量级别源自相关性和美学评分模型，因此查询丰富不仅在语义上有意义，而且具有质量意识。由此产生的系统具有三个关键优势：1）灵活性，无需修改即可与任何预训练的视觉语言模型（VLM）兼容； 2) 透明、丰富的查询可由用户明确解释； 3）可控性，使检索结果能够转向用户偏好的质量水平。大量实验表明，我们提出的方法显着改善了检索结果并提供了有效的质量控制，弥补了现代 VLM 的表达能力与短用户查询的未指定性质之间的差距。我们的代码可在 https://github.com/Jianglin954/QCQC 获取。

- **2026-02-24** **Revisiting CPL with sign-switching density: to cross or not to cross the NECB** [2602.21169](http://arxiv.org/abs/2602.21169)
  > 最近的 DESI DR2 BAO 测量结果与 CMB 和 SNeIa 数据相结合，显示出对 CPL 参数化状态方程描述的动态暗能量 (DE) 的 $3.2σ$-$3.4σ$ 偏好。这些重建的一个特别显着的特征是从早期的幻影般的政权到晚期的精髓般的行为的明显转变。对于正定 DE 密度，这种转变通常被表述为在 $w(a)=-1$ 处穿过虚拟分界线 (PDL)。然而，允许 DE 密度变为负值，会使 PDL（在 $w(a)=-1$ 的意义上）作为全局分隔符变得非诊断性：物理上有意义的标准是零能量条件边界 (NECB)，$ρ_{\rm DE}+p_{\rm DE}=0$。因此，我们测试一旦承认幻象行为的替代实现，特别是通过符号切换 DE 密度，CPL 重建中对 NECB 交叉的数据驱动偏好是否持续存在。为此，我们引入并约束了 CPL 框架的两个受控现象学扩展，其特征是过去具有负 DE 阶段。在 CPL$\to-Λ$ 模型中，切换历元与 CPL 推断的 NECB 交叉比例因子相关，产生早期负宇宙常数相位，而切换后的演化遵循 CPL 分支。在sCPL模型中，CPL状态方程始终保持不变，而能量密度的符号切换发生在独立的跃迁红移处。我们发现后期 BAO 和 SNeIa 数据驱动负密度相位超出其有效红移覆盖范围，并且这一要求是推断参数行为的主要驱动因素。虽然相对于基线 CPL，这两种模型在统计上都不受欢迎，但承认负 DE 相位通常会降低与宇宙学常数的偏差的显着性。

- **2026-02-24** **A Light Fixture Color Temperature and Color Rendering Index Measuring Device** [2602.21163](http://arxiv.org/abs/2602.21163)
  > 人造光源的相关色温 (CCT) 和显色指数 (CRI) 非常重要，因为它们对人类生物学和专业应用具有影响。尽管商用灯通常可以获得 CCT 信息，但通常不会报告 CRI。此外，测量这些参数的设备很难获得，因为它们需要分光光度计，而分光光度计通常是昂贵的设备。在此背景下，本工作详细设计和构建了一个仪表，从设备的结构部分、与传感器的接口、计算到补偿算法的实现，旨在构建分光光度计的专用功能，其设计不使用光学镜头。除了简化设备之外，这种方法还可以使测量不受光学镜头典型色差引起的色散的影响。所获得的原型被证明是有效的，它捕获了各种光源的光谱功率分布并计算它们的 CCT 和 CRI。

- **2026-02-24** **SPRITETOMESH: Automatic Mesh Generation for 2D Skeletal Animation Using Learned Segmentation and Contour-Aware Vertex Placement** [2602.21153](http://arxiv.org/abs/2602.21153)
  > 我们推出了 SPRITETOMESH，这是一个全自动管道，用于将 2D 游戏精灵图像转换为与 Spine2D 等骨骼动画框架兼容的三角形网格。创建动画就绪网格传统上是一个繁琐的手动过程，需要艺术家沿着视觉边界仔细放置顶点，这项任务通常每个精灵需要 15-60 分钟。我们的方法通过混合学习算法方法解决了这个问题。分割网络（带有 U-Net 解码器的 EfficientNet-B0 编码器）在来自 172 个游戏的超过 100,000 个精灵掩码对上进行训练，实现了 0.87 的 IoU，从任意输入图像中提供准确的二进制掩码。从这些掩模中，我们使用 Douglas-Peucker 简化和自适应弧细分提取外部轮廓顶点，并通过双边滤波多通道 Canny 边缘检测和轮廓跟踪放置沿视觉边界检测内部顶点。具有基于掩模的质心过滤的 Delaunay 三角测量产生最终的网格。通过受控实验，我们证明通过神经网络热图回归进行直接顶点位置预测对于此任务来说根本上是不可行的：热图解码器始终无法收敛（损失稳定在 0.061），而分割解码器在相同条件下正常训练。我们将此归因于顶点放置的固有艺术本质 - 相同的精灵可以通过多种不同的方式进行有效的网格划分。这个负面结果验证了我们的混合设计：在地面事实明确的情况下进行学习分割，在领域启发法适用的情况下进行算法放置。完整的管道在 3 秒内处理一个精灵，比手动创建速度提高了 300 倍至 1200 倍。我们向游戏开发社区发布经过训练的模型。

- **2026-02-24** **RAMSES-MCR: A consistent multi-group treatment of cosmic rays physics in momentum-space with the RAMSES code** [2602.21147](http://arxiv.org/abs/2602.21147)
  > 众所周知，宇宙射线（CR）在许多天体物理环境中发挥着关键作用：它们可以改变冲击动力学，影响星际介质的热化学和电离，通过驱动银河风来调节星系质量含量，并由活跃星系核的喷流释放。它们还通过γ射线发射、射电同步加速器和二次粒子产生作为重要的观测示踪剂。由于 CR 粒子在跨越数十年能量的动量空间中遵循幂律分布，并且由于扩散和辐射损失进一步塑造了这些光谱，因此在数值模拟中对光谱解析 CR 进行建模并评估该建模对气体动力学和观测特征的影响至关重要。我们在自适应网格细化代码 RAMSES 中提出了一种在动量空间中用于 CR 质子的一致多组谱方法，称为 RAMSES-MCR，该方法基于两矩形式主义，该形式主义在动量空间中演化 CR 能量和数密度及其相关通量。模拟的 CR 过程包括平流、各向异性/各向同性扩散、流动不稳定性、库仑和强子损失、绝热变化以及气体反馈。我们还表明，该方法可以自然地扩展到 CR 电子（例如包括同步加速器损耗）并推广到多种 CR 物种。该实施已根据一套标准多维测试进行了验证。最后，我们将 RAMSES-MCR 应用于超新星遗迹的三维膨胀，包括具有各向异性扩散和能量损失的 CR，并演示 CR 能量如何以动量相关的方式重新分布，并在扫雪阶段改变气体动量。

- **2026-02-24** **BrepGaussian: CAD reconstruction from Multi-View Images with Gaussian Splatting** [2602.21105](http://arxiv.org/abs/2602.21105)
  > 边界表示 (B-rep) 将 3D 实体建模为其显式边界：修剪的角、边和面。从非结构化数据中恢复 B-rep 表示是计算机视觉和图形领域一项具有挑战性且有价值的任务。深度学习的最新进展极大地改善了 3D 形状几何的恢复，但仍然依赖于密集和干净的点云，并且很难推广到新的形状。我们提出了 B-rep Gaussian Splatting (BrepGaussian)，这是一种从 2D 图像学习 3D 参数表示的新颖框架。我们采用具有可学习特征的高斯泼溅渲染器，然后采用特定的拟合策略。为了解开几何重建和特征学习，我们引入了一个两阶段学习框架，首先捕获几何和边缘，然后细化补丁特征以实现干净的几何和连贯的实例表示。大量的实验证明了我们的方法具有最先进的方法的卓越性能。我们将在接受后发布我们的代码和数据集。

- **2026-02-24** **Prompt-Level Distillation: A Non-Parametric Alternative to Model Fine-Tuning for Efficient Reasoning** [2602.21103](http://arxiv.org/abs/2602.21103)
  > 高级推理通常需要思想链提示，这是准确的，但会产生令人望而却步的延迟和大量的测试时间推理成本。标准的替代方案是对较小的模型进行微调，通常会牺牲可解释性，同时引入大量的资源和运营开销。为了解决这些限制，我们引入了即时级蒸馏 (PLD)。我们从教师模型中提取明确的推理模式，并将它们组织成学生模型系统提示的表达指令的结构化列表。使用 Gemma-3 4B 对 StereoSet 和 Contract-NLI 数据集进行评估，PLD 将 Macro F1 分数分别从 57% 提高到 90.0% 和 67% 提高到 83%，使这个紧凑的模型能够以可忽略的延迟开销匹配前沿性能。这些富有表现力的指令使决策过程变得透明，允许对逻辑进行全面的人工验证，使这种方法成为法律、金融和内容审核等受监管行业以及大容量用例和边缘设备的理想选择。

- **2026-02-24** **Skullptor: High Fidelity 3D Head Reconstruction in Seconds with Multi-View Normal Prediction** [2602.21100](http://arxiv.org/abs/2602.21100)
  > 从图像重建高保真 3D 头部几何形状对于广泛的应用至关重要，但现有方法面临根本性的限制。传统摄影测量可实现出色的细节，但需要大量相机阵列（25-200+ 视图）、大量计算以及在面部毛发等具有挑战性的区域进行手动清理。最近的替代方案提出了一个基本的权衡：基础模型可以实现高效的单图像重建，但缺乏精细的几何细节，而基于优化的方法可以实现更高的保真度，但需要密集的视图和昂贵的计算。我们通过结合两种范式优势的混合方法来弥补这一差距。我们的方法引入了多视图表面​​法线预测模型，该模型通过交叉视图注意力扩展单眼基础模型，以在前馈传递中产生几何一致的法线。然后，我们在逆向渲染优化框架中利用这些预测作为强大的几何先验来恢复高频表面细节。我们的方法优于最先进的单图像和多视图方法，实现了与密集视图摄影测量相当的高保真度重建，同时降低了相机要求和计算成本。代码和模型将被发布。

- **2026-02-23** **tttLRM: Test-Time Training for Long Context and Autoregressive 3D Reconstruction** [2602.20160](http://arxiv.org/abs/2602.20160)
  > 我们提出了 tttLRM，这是一种新颖的大型 3D 重建模型，它利用测试时训练 (TTT) 层来实现具有线性计算复杂性的长上下文、自回归 3D 重建，从而进一步扩展模型的能力。我们的框架有效地将多个图像观测结果压缩为 TTT 层的快速权重，在潜在空间中形成隐式 3D 表示，该表示可以解码为各种显式格式，例如用于下游应用的高斯 Splats (GS)。我们模型的在线学习变体支持通过流观察进行渐进式 3D 重建和细化。我们证明，新视图合成任务的预训练可以有效地转移到显式 3D 建模，从而提高重建质量和更快的收敛速度。大量实验表明，与物体和场景上最先进的方法相比，我们的方法在前馈 3D 高斯重建方面实现了卓越的性能。

- **2026-02-23** **Transcending the Annotation Bottleneck: AI-Powered Discovery in Biology and Medicine** [2602.20100](http://arxiv.org/abs/2602.20100)
  > 对专家注释的依赖长期以来一直是人工智能应用于生物医学的主要限制步骤。虽然监督学习推动了临床算法的最初浪潮，但向无监督和自监督学习 (SSL) 的范式转变目前正在释放生物样本库规模数据集的潜在潜力。通过直接学习数据的内在结构——无论是磁共振图像（MRI）中的像素、体积扫描中的体素还是基因组序列中的标记——这些方法有助于发现新的表型、形态学与遗传学的联系以及在没有人为偏见的情况下检测异常。本文综合了“无标签学习”方面的开创性和最新进展，强调了无监督框架如何导出可遗传的心脏特征，预测组织学中的空间基因表达，并以与监督框架相媲美或超过监督框架的性能检测病理。

- **2026-02-23** **SemanticNVS: Improving Semantic Scene Understanding in Generative Novel View Synthesis** [2602.20079](http://arxiv.org/abs/2602.20079)
  > 我们提出了 SemanticNVS，一种用于新颖视图合成（NVS）的相机条件多视图扩散模型，它通过集成预先训练的语义特征提取器来提高生成质量和一致性。现有的 NVS 方法对于输入视图附近的视图表现良好，但是，它们往往会在长距离相机运动下生成语义上不可信且扭曲的图像，从而显示出严重的退化。我们推测这种退化是由于当前模型无法完全理解其条件或中间生成的场景内容。在这里，我们建议集成预先训练的语义特征提取器，以合并更强的场景语义作为条件，即使在远处的视点也能实现高质量的生成。我们研究了两种不同的策略，（1）扭曲的语义特征和（2）每个去噪步骤的理解和生成的交替方案。多个数据集的实验结果表明，与最先进的替代方案相比，有明显的定性和定量（FID 中为 4.69%-15.26%）改进。

- **2026-02-23** **Spherical Hermite Maps** [2602.20063](http://arxiv.org/abs/2602.20063)
  > 球面函数出现在整个计算机图形学中，从球面谐波照明和预先计算的辐射率传输到神经辐射场和程序行星渲染。高效评估对于实时应用至关重要，但现有方法面临质量与性能的权衡：双线性 LUT 采样速度很快，但会产生分面，而双三次过滤需要 16 个纹理样本。大多数实现对法线使用有限差分，需要额外的样本并引入噪声。本文提出了 Spherical Hermite Maps，这是一种解决这种权衡的导数增强 LUT 表示形式。通过在填充立方体贴图的每个纹理像素处存储函数值和缩放偏导数，只需四个纹理样本（2x2 足迹）即可实现双三次 Hermite 重建，同时提供来自相同样本的连续梯度。关键的见解是 Hermite 插值重建平滑导数作为值重建的副产品，使表面法线有效地自由。在受控实验中，球形 Hermite 贴图比双线性插值将 PSNR 提高了 8-41 dB，并以四分之一的成本匹配 16 抽头双三次质量。分析法线可将复杂表面上的平均角度误差减少 9-13%，同时产生稳定的镜面高光。三个应用程序展示了多功能性：球谐字形可视化、网格细节级别的径向深度图冒名顶替者以及具有球形高度场的程序行星/小行星渲染。

- **2026-02-23** **On the Spatial Consistency of Sub-Terahertz Channel Characteristics for Beyond-6G Systems** [2602.20039](http://arxiv.org/abs/2602.20039)
  > 在为超 6G 蜂窝系统设计新机制时，射线追踪是一种用于精确亚太赫兹（亚太赫兹，100-300 GHz）信道建模的通用方法。理论上，无线信道可能会随波长距离而变化。因此，在亚太赫兹频段，接近毫米的波长需要极其大量的计算工作来进行光线追踪建模。然而，在实践中，信道特征可能在更大的距离上保持定量相似，这可以大大减少计算工作量。本研究的目的是通过实验表征亚太赫兹通道特性的空间一致性程度。为此，我们在室内大厅 (InH) 环境中在 140-150 GHz 频段进行了大规模测量活动，并以 2.5 mm 至 1 m 的间隔距离表征了信道。我们的结果表明，包括延迟扩展、角度延迟扩展和 K 因子在内的信道特性在数十厘米距离内仅略有变化。这意味着，在所考虑的 InH 环境中，网格可以沿着稳定的视线 (LoS) 方向处于 10-50 个波长范围内（145 GHz），而在不受 LoS 支配的区域中需要更精细的分辨率。对于较粗糙的网格，需要高级插值来捕获快速变化的分散分量。

- **2026-02-23** **Token-UNet: A New Case for Transformers Integration in Efficient and Interpretable 3D UNets for Brain Imaging Segmentation** [2602.20008](http://arxiv.org/abs/2602.20008)
  > 我们提出了 Token-UNet，采用 TokenLearner 和 TokenFuser 模块将 Transformer 封装到 UNet 中。   虽然 Transformer 实现了医学成像中输入元素之间的全局交互，但当前的计算挑战阻碍了它们在通用硬件上的部署。 (Swin)UNETR 等模型通过合并 (Swin)Transformer 编码器来适应 UNet 架构，编码器处理每个表示输入的小子体积（ $8^3$ 体素）的标记。   Transformer 注意力机制与 token 数量成二次方缩放，这与 3D 输入分辨率的立方缩放相关。   这项工作重新考虑了卷积和注意力的作用，引入了 Token-UNet，这是一系列 3D 分割模型，可以在受限的计算环境和时间范围内运行。   为了减轻计算需求，我们的方法保留了类似 UNet 模型的卷积编码器，并将 TokenLearner 应用于 3D 特征图。该模块从本地和全局结构中汇集预设数量的代币。   我们的结果表明，这种标记化有效地编码了任务相关信息，产生了自然可解释的注意力图。我们最重模型的内存占用、推理计算时间和参数计数减少到 SwinUNETR 值的 33\%、10\% 和 35\%，具有更好的平均性能（SwinUNETR 的 Dice 得分为 86.75\% $\pm 0.19\%$ 与我们的 87.21\% $\pm 0.35\%$ 相比）。   这项工作为在计算资源有限的环境（例如 3D 医学成像）中进行更有效的培训开辟了道路。在有限的硬件设置中简化模型优化、微调和迁移学习可以加速方法的开发并使其多样化，从而造福研究界。

- **2026-02-23** **Discretization and regularization for the reconstruction of inhomogeneities by scattering measurements** [2602.19970](http://arxiv.org/abs/2602.19970)
  > 我们通过在时谐设置中执行有限数量的声学类型的散射测量来考虑重建不均匀性的逆问题。我们将重构设置为具有正则化的完全离散变分问题。这样的问题取决于各种参数，即测量次数、正则化参数和离散化参数，即我们对建模物理系统的亥姆霍兹型方程的未知系数进行离散化的网格的大小。我们通过收敛分析表明，人们可以仔细选择这些参数，使得离散正则化最小值问题的解是所寻找的逆问题解的良好近似。

- **2026-02-23** **Augmented Radiance Field: A General Framework for Enhanced Gaussian Splatting** [2602.19916](http://arxiv.org/abs/2602.19916)
  > 由于实时渲染性能，3D 高斯分布 (3DGS) 已成为辐射场重建的领先方法。然而，它对球谐函数进行颜色编码的依赖本质上限制了其分离漫反射和镜面反射分量的能力，使得准确表示复杂反射变得具有挑战性。为了解决这个问题，我们提出了一种新颖的增强高斯内核，它通过依赖于视图的不透明度来显式地模拟镜面反射效果。同时，我们引入了误差驱动补偿策略来提高现有 3DGS 场景中的渲染质量。我们的方法从二维高斯初始化开始，然后自适应地插入和优化增强型高斯核，最终产生增强的辐射场。实验表明，我们的方法不仅在渲染性能上超越了最先进的 NeRF 方法，而且还实现了更高的参数效率。项目页面：https://xiaoxinyyx.github.io/augs。

- **2026-02-23** **Monocular Mesh Recovery and Body Measurement of Female Saanen Goats** [2602.19896](http://arxiv.org/abs/2602.19896)
  > 萨能奶山羊以其高产奶量而闻名，其泌乳性能与其体型有着内在的联系，因此准确的 3D 身体测量对于评估产奶潜力至关重要，但现有的重建方法缺乏山羊特有的真实 3D 数据。为了解决这一限制，我们建立了 FemaleSaanenGoat 数据集，其中包含 55 只雌性 Saanen 山羊（6-18 个月）的同步八视图 RGBD 视频。使用多视图 DynamicFusion，我们将噪声、非刚性点云序列融合到高保真 3D 扫描中，克服了不规则表面和快速移动的挑战。基于这些扫描，我们开发了 SaanenGoat，这是一种专为雌性 Saanen 山羊设计的参数化 3D 形状模型。该模型具有一个精致的模板，具有 41 个骨骼关节和增强的乳房表示，并与我们的扫描数据一起注册。由 48 只山羊构建的综合形状空间可以精确呈现不同的个体差异。借助SaanenGoat模型，我们从单视图RGBD输入中获得高精度3D重建，并实现了六个关键身体尺寸的自动测量：身长、身高、胸宽、胸围、臀宽和臀高。实验结果证明了我们的方法在 3D 重建和身体测量方面的卓越准确性，为精准畜牧业中大规模 3D 视觉应用提供了一种新的范例。

- **2026-02-23** **BigMaQ: A Big Macaque Motion and Animation Dataset Bridging Image and 3D Pose Representations** [2602.19874](http://arxiv.org/abs/2602.19874)
  > 对动物动态和社会行为的认识是推进行为学、生态学、医学和神经科学的基础。深度学习的最新进展已经实现了视频中的自动行为识别，但三维 (3D) 姿势和形状的准确重建尚未集成到此过程中。特别是对于非人类灵长类动物，基于网格的跟踪工作落后于其他物种，使得姿势描述仅限于稀疏的关键点，无法完全捕捉动作动态的丰富性。为了解决这一差距，我们引入了 $\textbf{Big Ma}$ca$\textbf{Q}$ue 3D 运动和动画数据集 ($\texttt{BigMaQ}$)，这是一个大型数据集，包含 750 多个恒河猴互动场景，并具有详细的 3D 姿势描述。扩展了之前基于表面的动物跟踪方法，我们通过将高质量的猕猴模板网格应用于个体猴子来构建特定于主题的纹理化身。这使我们能够提供比以前最先进的基于表面的动物跟踪方法更准确的姿势描述。从原始数据集中，我们推导出 BigMaQ500，这是一种动作识别基准，它将基于表面的姿势向量链接到多个个体猴子的单个帧。通过将从已建立的图像和视频编码器中提取的特征与姿势描述符进行配对，我们证明了在包含姿势信息时平均精度（mAP）的显着改进。通过这些贡献，$\texttt{BigMaQ}$ 建立了第一个数据集，该数据集既将动态 3D 姿势形状表示集成到动物动作识别的学习任务中，又为推进非人类灵长类动物的视觉外观、姿势和社交互动的研究提供了丰富的资源。代码和数据可在 https://martinivis.github.io/BigMaQ/ 上公开获取。

- **2026-02-20** **Towards scalable multi-qubit optimal control via interaction decomposition in the diagonal frame** [2602.18375](http://arxiv.org/abs/2602.18375)
  > 在这项工作中，我们引入了控制目标的通用 n 量子位公式，该公式允许在对角坐标系中指定控制目标，以便仅必须表征对角线条目，从而与完整目标矩阵相比，以二次方方式降低成本函数的复杂性。我们通过将任何 n 量子位酉变换表示为计算基础状态上的对角相图来实现这一点，因为它们自然可以通过酉性对角化。通过使用离散导数算子来分析构建支持选择性相不变量，我们能够确定性地隔离和量化相图中编码的任何多量子位相互作用。这些相不变量形成了一个坐标系，用于根据任意所需的多量子位相互作用制定特定控制目标，而无需在优化过程中反转对角化，仅依赖于实验上可访问的对角相。为了说明该框架，我们合成了两个真正的三方纠缠门，都是对角线和非对角线的。这些是通过单一形状的微波脉冲获得的，针对具有三量子位核自旋寄存器的数值模拟室温氮空位中心，持续时间约为一微秒。与同时作用于两个以上量子位的最快的现有基于 NV 的纠缠器相比，这些结果表明操作时间减少了 10-100 倍。

- **2026-02-20** **A method to derive self-consistent NLTE astrophysical parameters for 4 million high-resolution 4MOST stellar spectra in half a day with invertible neural networks** [2602.18340](http://arxiv.org/abs/2602.18340)
  > 现代光谱勘测获得了数百万颗恒星的光谱。然而，经典的光谱方法通常计算成本高昂，使得它们对于大型数据集的分析不切实际。我们引入了一种新颖的基于模拟的深度学习方法，用于对即将推出的高分辨率 4MOST 摄谱仪获得的高分辨率恒星光谱进行有效分析。我们使用 Turbospectrum 生成的一套合成非局部热力学平衡 (NLTE) 光谱来模拟 4MOST 观测结果，并训练条件可逆神经网络 (cINN)，以预测自洽的恒星表面参数和化学丰度。 cINN 是一种神经网络架构，可估计目标恒星属性的完整后验分布，从而提供内在的不确定性估计。我们评估了训练后的 cINN 模型对合成数据和观测到的恒星光谱的预测性能。我们发现，在 NLTE 合成光谱上训练的新 cINN 能够恢复恒星参数，其中 $T_\mathrm{eff}$ 的平均误差 ($σ$) 为 $33$ K，$\log(g)$ 的平均误差为 $0.16$ dex，[Fe/H] 的 $0.12$ dex，[Ca/Fe] 的 $0.1$ dex，[Mg/Fe] 的 $0.11$ 和 $0.51$ dex 分别为 [Li/Fe]，信噪比为 250/埃。通过对 Gaia-ESO / 4MOST / PLATO 基准恒星观测光谱的分析，我们验证了我们对恒星参数和丰度的 NLTE 估计与独立代码 TSFitPy 获得的结果一致。我们得出的结论是，NLTE cINN 非常强大，理论上可以使用 GPU 加速在不到一天的时间内评估 400 万个高分辨率 4MOST 频谱。

- **2026-02-20** **Unifying Color and Lightness Correction with View-Adaptive Curve Adjustment for Robust 3D Novel View Synthesis** [2602.18322](http://arxiv.org/abs/2602.18322)
  > 由于复杂的照明变化和相机成像管道的固有限制，现实环境中的高质量图像采集仍然具有挑战性。这些问题在多视图捕获中更加严重，其中照明、传感器响应和图像信号处理器 (ISP) 配置的差异会引入光度和色彩不一致，违反现代 3D 新视图合成 (NVS) 方法（包括神经辐射场 (NeRF) 和 3D 高斯泼溅 (3DGS)）的光度一致性假设，从而导致重建和渲染质量下降。我们提出了 Luminance-GS++，这是一种基于 3DGS 的框架，可在不同的照明条件下实现稳健的 NVS。我们的方法将全局视图自适应亮度调整与局部像素级残差细化相结合，以实现精确的色彩校正。我们进一步设计了无监督目标，共同执行亮度校正和多视图几何和光度一致性。大量的实验证明了在具有挑战性的场景中的最先进的性能，包括低光、过度曝光以及复杂的亮度和色度变化。与修改底层表示的先前方法不同，我们的方法保留了显式 3DGS 公式，提高了重建保真度，同时保持了实时渲染效率。

- **2026-02-20** **Photonic-computing error correction through optical en-/decoder calibrations** [2602.18299](http://arxiv.org/abs/2602.18299)
  > 光子处理器已成为快速、节能的矩阵矢量乘法的有吸引力的平台。然而，由于其模拟性质，它们很容易出错。在这里，我们提出了一种纠错技术，可以对光子处理器的光学编码器/解码器实现校正偏移。我们提出的方法是通用的，不需要在光子网络中引入任何额外的组件，并且可以解决由不平衡损耗、50/50 分束器偏差、数模转换不准确和任何未知来源引起的错误。特别是，我们表明我们的方法在减轻不平衡损耗误差方面非常有效，这是以前任何纠错技术都没有解决的问题。使用这种方法，我们在大型三角网格中实现了超过 90% 的误差减少，克服了高精度光子处理器进行信息处理的一个关键障碍。

- **2026-02-20** **GR-Athena++: Binary Neutron Star Merger Simulations with Neutrino Transport** [2602.18290](http://arxiv.org/abs/2602.18290)
  > 我们提出了用 GR-Athena++ 进行的双中子星合并的广义相对论辐射磁流体动力学模拟。中微子输运采用基于矩的能量积分方案 (M1) 进行处理，并通过中微子数密度演化 (N0) 进行增强。我们的实现通过一系列广泛的标准测试进行了验证，并证明在自适应网格细化下可以稳健地执行。作为第一个应用，我们模拟了均匀旋转的磁化中子星的引力塌缩，使用基于视界内状态矢量演化逐渐变细的新型切除技术，通过视视界形成展示了稳定的辐射演化。为了进一步测试高度动态环境中的鲁棒性，我们将我们的代码应用于两个要求严格的双中子星合并场景。我们研究了 DD2 状态方程的长寿命残余物，该方程是通过完全广义相对论磁流体动力学和 M1 中微子输运演化而来的。接下来，探索使用 SFHo 状态方程的重力塌缩场景。我们展示了中微子冷却时间尺度的长期稳定演化，展示了在磁场和中微子辐射的三维合并中对切除的稳健处理和塌缩后吸积相的稳定演化。

- **2026-02-20** **SeedFlood: A Step Toward Scalable Decentralized Training of LLMs** [2602.18181](http://arxiv.org/abs/2602.18181)
  > 这项工作提出了一种去中心化训练的新方法——SeedFlood，旨在跨复杂网络拓扑扩展大型模型，并以最小的通信开销达成全球共识。传统的基于八卦的方法面临着消息通信成本随模型大小而增长的问题，而网络跳数上的信息衰减导致全局共识效率低下。 SeedFlood 与这些做法不同，它利用零阶更新的种子可重构结构，并有效地使消息大小接近于零，从而使它们能够洪泛到网络中的每个客户端。这种机制使得通信开销可以忽略不计并且与模型大小无关，从而消除了去中心化训练中的主要可扩展性瓶颈。因此，SeedFlood 可以在以前被认为不切实际的方案中进行训练，例如分布在数百个客户端的十亿参数模型。我们对去中心化 LLM 微调的实验表明，SeedFlood 在泛化性能和通信效率方面始终优于基于八卦的基线，甚至在大规模设置中取得了与一阶方法相当的结果。

- **2026-02-20** **Stable Long-Horizon Spatiotemporal Prediction on Meshes Using Latent Multiscale Recurrent Graph Neural Networks** [2602.18146](http://arxiv.org/abs/2602.18146)
  > 对复杂几何形状上的时空场进行准确的长期预测是科学机器学习中的一项基本挑战，其应用包括温度历史控制缺陷形成和机械性能的增材制造等。高保真模拟是准确的，但计算成本高昂，尽管最近取得了进展，机器学习方法仍然受到长范围温度和梯度预测的挑战。我们提出了一种深度学习框架，用于直接在网格上预测完整的温度历史记录，以几何结构和工艺参数为条件，同时保持数千个时间步长的稳定性并在异构几何结构中进行泛化。该框架采用时间多尺度架构，由两个在互补时间尺度上运行的耦合模型组成。两种模型都依赖于潜在的循环图神经网络来捕获网格上的时空动态，而变分图自动编码器提供了紧凑的潜在表示，可以减少内存使用并提高训练稳定性。模拟粉末床融合数据的实验证明了跨不同几何形状的准确且暂时稳定的长期预测，优于现有基线。尽管是在二维上进行评估，但该框架是通用的，并且可以扩展到具有多尺度动力学的物理驱动系统和三维几何结构。

- **2026-02-20** **Comparative study of different quadrature methods for cut elements** [2602.18130](http://arxiv.org/abs/2602.18130)
  > 切割元素的求积对于所有不应用边界拟合网格的有限元方法至关重要。它应该高效、准确且稳健。平衡这些要求的各种方法已经发布，其中一些可作为开源实现。这项工作回顾了这些开源代码和使用的方法。此外，还为 2D 和 3D 几何形状开发了基准测试示例。隐式和显式边界描述适用于所有模型。不同的示例测试了代码的效率、准确性、多功能性和鲁棒性。特别关注控制所需正交阶数的输入参数对实际积分误差的影响。对所讨论的代码进行了详细比较。基准测试可以进行结论性的比较，并为未来的代码开发提供了一个有价值的工具。所有测试都发布在随附的开源存储库中。

- **2026-02-20** **Beyond Individual Influence: The Role of Echo Chambers and Community Seeding in the Multilayer three state q-Voter Model** [2602.18088](http://arxiv.org/abs/2602.18088)
  > 在多层社交网络中，回音室和认知一致性机制严重阻碍了复杂意见的传播。我们研究了三态多层 q 选民模型中的影响力最大化策略。利用 mABCD 基准，我们模拟从集成开放世界到隔离堡垒世界的社交环境。我们的结果揭示了一个拓扑悖论，我们称之为“堡垒陷阱”。在高度模块化的网络中，最大化局部密度的策略（例如 Clique Influence Maximization (CIM) 和 k-Shell）无法触发全局级联，由于过度杀伤效应而创建了孤立的共识掩体。此外，我们在完美对齐的氏族拓扑中发现了一个冗余陷阱，其中各层的结构重叠创建了一个“完美监狱”，使其成为最能抵抗扩散的环境。我们证明，VoteRank 是一种优先考虑覆盖范围多样性而非局部强度的策略，其性能始终优于基于结构的方法。这些发现表明，对于复杂的传染，最大化​​拓扑熵比强化局部簇更有效。

- **2026-02-20** **AndroWasm: an Empirical Study on Android Malware Obfuscation through WebAssembly** [2602.18082](http://arxiv.org/abs/2602.18082)
  > 近年来，隐秘的 Android 恶意软件越来越多地采用复杂的技术来绕过自动检测机制并强化手动分析。攻击者通常依靠基于人工智能的工具的混淆、反重新打包、隐写术、中毒和规避技术以及内存中执行来隐藏恶意功能。   在本文中，我们研究了 WebAssembly（Wasm）作为一种隐藏恶意负载并逃避传统静态分析和签名匹配机制的新技术。虽然 Wasm 通常用于渲染特定的游戏活动并与 Web 浏览器中的本机组件交互，但我们对 Android 可能采用的在其执行管道中包含 Wasm 模块的机制进行了深入分析。此外，我们还提供概念验证来演示攻击者嵌入并执行恶意例程的威胁模型，有效绕过 VirusTotal 和 MobSF 等工业最先进工具的 IoC 检测。


<p align=right>(<a href=#updated-on-20260226>back to top</a>)</p>

## 具生智能&自动驾驶

- **2026-02-25** **Solaris: Building a Multiplayer Video World Model in Minecraft** [2602.22208](http://arxiv.org/abs/2602.22208)
  > 现有的动作条件视频生成模型（视频世界模型）仅限于单智能体视角，无法捕捉现实世界环境的多智能体交互。我们介绍 Solaris，这是一种模拟一致的多视图观察的多人视频世界模型。为了实现这一目标，我们开发了一个多人数据系统，专为《我的世界》等视频游戏的稳健、连续和自动化数据收集而设计。与之前为单人游戏设置构建的平台不同，我们的系统支持协调的多代理交互和同步视频+动作捕捉。使用该系统，我们收集了 1264 万个多人游戏帧，并提出了多人运动、记忆、接地、构建和视图一致性的评估框架。我们使用分阶段的管道来训练 Solaris，该管道逐渐从单人模式过渡到多人模式，结合了双向、因果和自我强迫训练。在最后阶段，我们引入了检查点自我强迫，这是一种内存高效的自我强迫变体，可以实现更长视野的教师。结果显示我们的架构和培训设计优于现有基线。通过开源我们的系统和模型，我们希望为新一代多智能体世界模型奠定基础。

- **2026-02-25** **Thermal activation drives a finite-size crossover from scale-free to runaway avalanches in amorphous solids** [2602.22198](http://arxiv.org/abs/2602.22198)
  > 我们使用具有局部激活规则且无外部驱动的弹塑性模型研究非晶固体中的热雪崩动力学。通过持久性测量和相关的四点磁化率 $χ_4$ 量化的动态异质性揭示了随着温度变化而出现的相关时空重排。随着温度升高，雪崩统计数据从具有指数截止的无标度行为演变为由跨系统失控事件主导的状态。我们确定了一个与系统尺寸相关的临界温度$T_c(L)$，它将间歇性雪崩动力学与热辅助流分开，其中自持雪崩使系统瞬时流化。我们表明，$T_c(L)$ 随着系统尺寸的增加而代数减小，这表明在热力学极限下，任意小但有限的温度可能会破坏间歇状态的稳定性。雪崩大小和持续时间之间的关系类似于剪切系统中的关系，而屈服最小距离的统计数据揭示了严格驱动的过阻尼动力学中不存在的温度驱动的边际稳定性重组。我们的结果表明，仅热激活就可以在无序弹性介质中产生有限尺寸控制的不稳定尺度。

- **2026-02-25** **Effects of realistic laser intensity and phase distribution on high-charge laser wakefield acceleration** [2602.22172](http://arxiv.org/abs/2602.22172)
  > 激光尾场加速（LWFA）可以在厘米长的等离子体中产生相对论电子束和各种二次粒子，使其成为有价值的粒子源，在许多学科中具有重要应用。在这项工作中，我们通过实验测量和细胞内颗粒模拟研究了激光脉冲的非理想横向强度和相位分布对 LWFA 的影响。与横向高斯激光相比，75 TW 激光脉冲的复杂横向轮廓降低了等离子体中的自聚焦强度。此外，现实激光脉冲激发的非线性等离子体尾流的鞘层结构比高斯激光器的鞘层结构更宽、更复杂。这些阻碍了等离子体电子的注入。当激光脉冲在等离子体中传播时，其强度分布逐渐变成椭圆形，并在主轴方位角附近驱动具有尖锐鞘的等离子体尾流，从而导致注入。当在模拟中使用真实的激光轮廓时，注入电子的电荷和能量与实验结果非常匹配（ $\sim200$ pC 电荷和 $\sim 200$ MeV 峰值能量），而高斯激光模拟产生更高的电荷（$\sim500$ pC）。我们的研究结果揭示了由非理想激光脉冲驱动的 LWFA 与由高斯脉冲驱动的 LWFA 之间的注入动力学差异，并且对于需要高电荷电子束的 LWFA 应用非常有用。

- **2026-02-25** **WeatherCity: Urban Scene Reconstruction with Controllable Multi-Weather Transformation** [2602.22096](http://arxiv.org/abs/2602.22096)
  > 可编辑的高保真 4D 场景对于自动驾驶至关重要，因为它们可以应用于端到端训练和闭环仿真。然而，现有的重建方法主要局限于复制观测场景，缺乏多样化天气模拟的能力。而图像级天气编辑方法往往会引入场景伪影，并且对天气效果的可控性较差。为了解决这些限制，我们提出了 WeatherCity，这是一种用于 4D 城市场景重建和天气编辑的新颖框架。具体来说，我们利用文本引导的图像编辑模型来实现图像天气背景的灵活编辑。为了应对多天气建模的挑战，我们引入了一种基于共享场景特征和专用天气特定解码器的新型天气高斯表示。通过内容一致性优化进一步增强了这种表示，确保不同天气条件下的连贯建模。此外，我们设计了一个物理驱动的模型，通过粒子和运动模式模拟动态天气效果。对多个数据集和各种场景的大量实验表明，WeatherCity在4D重建和天气编辑方面实现了灵活的可控性、高保真度和时间一致性。我们的框架不仅能够对天气条件（例如小雨和大雪）进行细粒度控制，而且还支持场景内的对象级操作。

- **2026-02-25** **Learning to Drive is a Free Gift: Large-Scale Label-Free Autonomy Pretraining from Unposed In-The-Wild Videos** [2602.22091](http://arxiv.org/abs/2602.22091)
  > 在线提供的以自我为中心的驾驶视频为自动驾驶提供了丰富的视觉数据源，但它们缺乏注释使得学习捕获语义结构和 3D 几何的表示变得困难。大型前馈空间模型的最新进展表明，可以在一次前向传递中推断出点图和自我运动，这为可扩展的驾驶感知提供了一个有希望的方向。因此，我们提出了一个无标签、教师指导的框架，用于直接从未摆出的视频中学习自动驾驶表示。与之前主要关注帧间一致性的自我监督方法不同，我们认为安全和反应性驾驶关键取决于时间背景。为此，我们利用配备轻量级自回归模块的前馈架构，使用多模态监督信号进行训练，引导模型联合预测当前和未来的点图、相机姿势、语义分割和运动掩模。多模态教师提供序列级伪监督，使 LFG 能够从原始 YouTube 视频中学习统一的伪 4D 表示，而无需姿势、标签或 LiDAR。由此产生的编码器不仅可以有效地转移到 NAVSIM 基准上的下游自动驾驶规划，超越多摄像头和仅使用单个单目摄像头的 LiDAR 基线，而且在一系列语义、几何和定性运动预测任务上进行评估时也能产生强大的性能。这些几何和运动感知功能使 LFG 成为引人注目的以视频为中心的自动驾驶基础模型。

- **2026-02-25** **IGR J12580+0134: A Candidate for Repeating Partial Tidal Disruption Events Supported by Multi-Wavelength Observations** [2602.22040](http://arxiv.org/abs/2602.22040)
  > 重复部分潮汐破坏事件（pTDE）可以直接探测超大质量黑洞周围的恒星轨道和偶发性质量损失，但可靠的识别需要多波段和多纪元的证据。我们使用多历元 Karl G. Jansky VLA 观测以及来自 Swift/XRT 和 NICER 的 X 射线约束，研究 NGC 4845 中核瞬变 IGR J12580+0134 的晚期射电再亮是否可以解释为重复的 pTDE。射电光曲线显示出两个不同的阶段，L 波段峰值相隔 $\approx1513$ 天。使用马尔可夫链蒙特卡罗拟合的同步加速器余辉框架对第二阶段进行建模有利于非相对论流出 $v\simeq0.03c$，其各向同性等效动能为 $10^{50}$ erg 在近似恒定密度的核周介质中传播。在 2016 年的射电耀斑期间，Swift/XRT 没有检测到明显的同期增亮，而 2023 年的微弱 NICER 耀斑表明存在间歇性低水平吸积。因此，复发时间尺度和无线电能量学使 IGR J12580+0134 成为重复 pTDE 系统的可能候选者，从而激励持续敏感的无线电和 X 射线监测来测试未来的重新激活。

- **2026-02-25** **World Guidance: World Modeling in Condition Space for Action Generation** [2602.22010](http://arxiv.org/abs/2602.22010)
  > 利用未来的观察模型来促进行动生成，为增强视觉-语言-行动（VLA）模型的能力提供了一条有前途的途径。然而，现有的方法很难在保持高效、可预测的未来表示和保留足够的细粒度信息以指导精确的动作生成之间取得平衡。为了解决这个限制，我们提出了 WoG（世界指导），这是一个框架，通过将未来的观察结果注入到动作推理管道中，将它们映射到紧凑的条件中。然后，VLA 经过训练，可以同时预测这些压缩条件和未来的动作，从而在条件空间内实现有效的世界建模以进行动作推理。我们证明，建模和预测这个条件空间不仅有利于细粒度动作的生成，而且还表现出卓越的泛化能力。此外，它还可以从大量的人类操作视频中有效地学习。模拟和现实环境中的大量实验验证了我们的方法显着优于基于未来预测的现有方法。项目页面位于：https://selen-suyue.github.io/WoGNet/

- **2026-02-25** **Are Foundation Models the Route to Full-Stack Transfer in Robotics?** [2602.22001](http://arxiv.org/abs/2602.22001)
  > 对于人类和机器人来说，迁移学习发生在不同的抽象层次上，从高级语言迁移到低级运动技能迁移。在本文中，我们概述了基础模型和变压器网络对这些不同级别的影响，使机器人比以往任何时候都更接近“全栈传输”。从机器人迁移学习的角度考虑 LLM、VLM 和 VLA，使我们能够强调除具体实现之外的重复出现的迁移概念。我们还考虑了基础模型时代机器人技术的数据收集和传输基准的挑战。基础模型是机器人全栈传输的途径吗？我们的期望是，他们一定会作为关键技术继续走这条路线。

- **2026-02-25** **PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning** [2602.21992](http://arxiv.org/abs/2602.21992)
  > 360 度全景图像越来越多地用于虚拟现实、自动驾驶和机器人技术中，以实现整体场景理解。然而，由于几何失真和有限的 3D 监督，当前的视觉语言模型 (VLM) 难以在等距柱状投影 (ERP) 图像上进行 3D 空间推理。我们推出了 PanoEnv，这是一个从合成 3D 环境构建的大型 VQA 基准测试，包含五个类别（例如相对位置、体积比较）的 14.8K 个问题，这些问题基于准确的 3D 注释，包括深度、分割和边界框。对 14 个最先进的 VLM 进行基准测试揭示了有限的 3D 理解，总体准确率仅为 49.34%，开放式 (OE) 问题的准确率为 8.36%。为了增强 3D 推理，我们提出了一种基于组相对策略优化 (GRPO) 的强化学习后训练框架，该框架具有基于事实指导的奖励，其中结合了距离容差和空间一致性等五种几何感知策略。两阶段课程进一步减轻灾难性遗忘：第一阶段训练结构化任务（真/假和多项选择），第二阶段对混合开放式数据进行微调以提高泛化能力。我们的 7B 模型实现了新的最先进的性能，将整体准确率提高到 52.93% (+3.59%)，将开放式准确率提高到 14.83%，同时保持结构化任务性能。它还取得了最高的语义评估分数（Q-Score 6.24，P-Score 5.95），超越了 32B 模型。这些结果表明，PanoEnv-QA 和我们基于课程的 RL 框架有效地将 3D 空间智能注入 VLM 中，以实现全方位感知。

- **2026-02-25** **MindDriver: Introducing Progressive Multimodal Reasoning for Autonomous Driving** [2602.21952](http://arxiv.org/abs/2602.21952)
  > 视觉语言模型（VLM）表现出强大的推理能力，显示出端到端自动驾驶系统的前景。思想链（CoT）作为VLM广泛使用的推理策略，正面临着严峻的挑战。现有的文本CoT在文本语义空间和轨迹物理空间之间存在较大差距。尽管最近的方法利用未来图像代替文本作为 CoT 过程，但它缺乏明确的面向规划的客观指导来生成具有准确场景演化的图像。为了解决这些问题，我们创新性地提出了 MindDriver，这是一种渐进式多模态推理框架，使 VLM 能够模仿人类的渐进式思维进行自动驾驶。 MindDriver 呈现语义理解、语义到物理空间想象以及物理空间轨迹规划。为了在 MindDriver 中实现对齐推理过程，我们开发了一个反馈引导的自动数据注释管道来生成对齐的多模态推理训练数据。此外，我们开发了一种渐进强化微调方法，通过渐进的高水平基于奖励的学习来优化对齐。 MindDriver 在 nuScences 开环和 Bench2Drive 闭环评估中展示了卓越的性能。代码可在 https://github.com/hotdogcheesewhite/MindDriver 获取。

- **2026-02-24** **NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning** [2602.21172](http://arxiv.org/abs/2602.21172)
  > 视觉-语言-动作（VLA）模型通过用统一的端到端架构取代模块化管道来推进自动驾驶。然而，当前的 VLA 面临两个昂贵的要求：（1）海量数据集收集，（2）密集推理注释。在这项工作中，我们用 \modelname 解决了这两个挑战（\textbf{No} \textbf{R}easoning for \textbf{D}riving）。与现有的 VLA 相比，\modelname 实现了具有竞争力的性能，同时对 $<$60\% 的数据进行了微调，并且没有推理注释，从而减少了 3$\times$ 的标记。我们发现，当标准组相对策略优化（GRPO）应用于在如此小的、无推理数据集上训练的策略时，无法产生显着的改进。我们表明，这种限制源于难度偏差，它不成比例地惩罚来自 GRPO 内产生高方差推出的场景的奖励信号。 \modelname 通过结合 Dr.~GRPO 克服了这个问题，Dr.~GRPO 是一种旨在减轻法学硕士难度偏差的最新算法。因此，\modelname 只需一小部分训练数据且无需推理开销，即可在 Waymo 和 NAVSIM 上实现具有竞争力的性能，从而实现更高效的自主系统。

- **2026-02-24** **ActionReasoning: Robot Action Reasoning in 3D Space with LLM for Robotic Brick Stacking** [2602.21161](http://arxiv.org/abs/2602.21161)
  > 经典的机器人系统通常依赖于为受限环境设计的定制规划器。虽然在有限的环境中有效，但这些系统缺乏泛化能力，限制了具体人工智能和通用机器人的可扩展性。最近的数据驱动的视觉-语言-行动（VLA）方法旨在从大规模模拟和现实世界数据中学习策略。然而，物理世界的连续动作空间显着超过了语言标记的表示能力，这使得人们不清楚仅扩展数据是否可以产生通用的机器人智能。为了解决这一差距，我们提出了 ActionReasoning，这是一个法学硕士驱动的框架，它执行显式的动作推理，为机器人操作生成物理一致的、先验指导的决策。 ActionReasoning 利用大型语言模型 (LLM) 中已编码的物理先验和现实世界知识，并将它们构建在多代理架构中。我们在砖堆垛的易处理案例研究中实例化了该框架，其中假设环境状态已经被准确测量。然后环境状态被序列化并传递到多代理 LLM 框架，该框架生成物理感知行动计划。实验表明，所提出的多代理 LLM 框架可以实现稳定的积木放置，同时将工作量从低级特定领域编码转移到高级工具调用和提示，突出了其更广泛泛化的潜力。这项工作引入了一种有前途的方法，通过将物理推理与法学硕士相结合，在机器人操作中桥接感知和执行。

- **2026-02-24** **HALO: A Unified Vision-Language-Action Model for Embodied Multimodal Chain-of-Thought Reasoning** [2602.21157](http://arxiv.org/abs/2602.21157)
  > 视觉-语言-动作（VLA）模型在机器人操作方面表现出了强大的性能，但由于缺乏多模态推理和预测世界在行动下如何演变的明确机制，常常在长期或分布外场景中表现不佳。最近的工作在VLA模型中引入文本思维链或视觉子目标预测来进行推理，但仍然未能为联合文本推理、视觉预见和动作预测提供统一的类人推理框架。为此，我们提出了 HALO，一个统一的 VLA 模型，它通过文本任务推理的顺序过程、细粒度指导的视觉子目标预测和 EM-CoT 增强动作预测来实现体现多模式思想链 (EM-CoT) 推理。我们使用 Mixture-of-Transformers (MoT) 架构实例化 HALO，该架构将语义推理、视觉预见和动作预测解耦给专业专家，同时允许无缝的跨专家协作。为了大规模实现 HALO 学习，我们引入了一个自动化管道来合成 EM-CoT 训练数据以及精心设计的训练方案。大量实验表明：（1）HALO 在模拟和现实环境中均实现了卓越的性能，在 RoboTwin 基准上超出了基线策略 pi_0 34.1%； (2) 训练方案和 EM-CoT 设计的所有建议组件都有助于提高任务成功率； (3) HALO 通过我们提出的 EM-CoT 推理在激进的看不见的环境随机化下表现出强大的泛化能力。

- **2026-02-24** **From Perception to Action: An Interactive Benchmark for Vision Reasoning** [2602.21015](http://arxiv.org/abs/2602.21015)
  > 了解物理结构对于现实世界的应用（例如具体代理、交互设计和长视野操作）至关重要。然而，流行的视觉语言模型（VLM）评估仍然集中在与结构无关的单轮设置（例如，VQA）上，无法评估智能体推理几何、接触和支持关系如何共同限制动态环境中可能采取的行动的能力。为了解决这一差距，我们引入了动作和交互的因果层次结构 (CHAIN) 基准，这是一个交互式 3D、物理驱动的测试台，旨在评估模型是否能够理解、规划和执行基于物理约束的结构化动作序列。 CHAIN 将评估从被动感知转变为主动解决问题，涵盖联锁机械谜题以及 3D 堆叠和包装等任务。我们在统一的交互设置下对最先进的 VLM 和基于扩散的模型进行了全面的研究。我们的结果表明，表现最好的模型仍然难以内化物理结构和因果约束，往往无法制定可靠的长期计划，并且无法将感知的结构强有力地转化为有效的行动。该项目可在 https://social-ai-studio.github.io/CHAIN/ 获取。

- **2026-02-24** **Notes-to-Self: Scratchpad Augmented VLAs for Memory Dependent Manipulation Tasks** [2602.21013](http://arxiv.org/abs/2602.21013)
  > 许多灵巧的操作任务本质上都是非马尔可夫的，但在最近兴起的视觉-语言-动作（VLA）范式中，这一事实却很少受到关注。尽管它们成功地将互联网规模的语义理解引入机器人技术，但现有的 VLA 主要是“无状态的”，并且难以处理依赖于内存的长期任务。在这项工作中，我们探索了一种通过结合语言暂存器来向 VLA 传递空间和时间记忆的方法。便签本可以记住特定于任务的信息，例如对象位置，并且允许模型跟踪计划以及该计划中子目标的进展情况。我们在 MemoryBench 上对来自 ClevrSkills 环境的内存相关任务的拆分以及具有挑战性的现实世界拾取和放置任务评估了这种方法。我们证明，结合语言暂存器可以显着提高非循环和循环模型的这些任务的泛化能力。

- **2026-02-24** **Toward an Agentic Infused Software Ecosystem** [2602.20979](http://arxiv.org/abs/2602.20979)
  > 在软件开发中充分利用人工智能代理的能力需要重新思考软件生态系统本身。为此，本文概述了基于三个支柱的代理注入软件生态系统 (AISE) 的创建。首先，当然是人工智能代理本身，在过去的五年里，人工智能代理已经从简单的代码完成转向复杂的独立开发任务，这一趋势只会持续下去。第二个支柱是这些代理用来完成任务的编程语言和 API（或工具），并且越来越多地充当人类和人工智能代理交互和协作的通信基础。最后一个支柱是代理运行的运行时环境和生态系统，它提供了编程代理用于与外部世界交互（并影响其中的操作）的功能。为了实现 AISE 的愿景，所有三个支柱都必须以整体方式推进，最重要的是，以一种对当前存在的、未来存在的人工智能代理以及与它们一起工作的人类开发人员来说具有协同作用的方式。

- **2026-02-24** **A Robotic Testing Platform for Pipelined Discovery of Resilient Soft Actuators** [2602.20963](http://arxiv.org/abs/2602.20963)
  > 高电场下的短寿命阻碍了线性介电弹性体致动器（DEA）在机器人中的广泛应用。由于每个样本测试耗时且高维参数空间影响性能，系统扫描很困难。为了解决这个问题，我们提出了一种由能够扫描 DEA 寿命的新型测试机器人启用的优化管道。该机器人集成了机电性能测量、可编程电压输入和多通道测试能力。使用它，我们扫描了基于 Elastosil 的线性执行器的寿命参数，包括输入电压幅度、频率、电极材料浓度和电连接填料。最佳参数组合将边界操作条件下的使用寿命提高了 100%，并随后按比例扩大以实现更高的力和位移输出。最终产品展示了模块化、可扩展的四足步行机器人的弹性，具有有效负载能力（> 100% 的自由体重，> 700% 的组合执行器重量）。这项工作首次将自动驾驶实验室方法引入机器人执行器设计中。

- **2026-02-24** **UFO: Unifying Feed-Forward and Optimization-based Methods for Large Driving Scene Modeling** [2602.20943](http://arxiv.org/abs/2602.20943)
  > 动态驾驶场景重建对于自动驾驶仿真和闭环学习至关重要。虽然最近的前馈方法已显示出 3D 重建的前景，但由于序列长度的二次复杂性以及长时间建模动态对象的挑战，它们在长距离驱动序列方面遇到了困难。我们提出了 UFO，一种新颖的循环范例，它结合了基于优化和前馈方法的优点，可实现高效的远程 4D 重建。我们的方法维护了 4D 场景表示，随着新观察的到来，该表示不断迭代地细化，使用基于可见性的过滤机制来选择信息丰富的场景标记并实现长序列的高效处理。对于动态对象，我们引入了一种对象姿势引导建模方法，支持精确的远程运动捕捉。 Waymo 开放数据集上的实验表明，我们的方法在各种序列长度上显着优于按场景优化和现有的前馈方法。值得注意的是，我们的方法可以在 0.5 秒内重建 16 秒的驾驶日志，同时保持卓越的视觉质量和几何精度。

- **2026-02-24** **Body-Reservoir Governance in Repeated Games: Embodied Decision-Making, Dynamic Sentinel Adaptation, and Complexity-Regularized Optimization** [2602.20846](http://arxiv.org/abs/2602.20846)
  > 标准博弈论通过诸如“一报还一报”（TfT）之类的条件策略来解释重复博弈中的合作，但这需要连续计算，从而给实体主体带来物理成本。我们提出了一个三层的身体储存库治理（BRG）架构：（1）一个身体储存库（回声状态网络），其 $d$维状态对交互历史进行隐式推理，充当决策者和异常检测器，（2）一个认知过滤器，提供按需激活的昂贵的策略工具，以及（3）一个具有感受性参数$α\in [0,1]$的元认知治理层。在全身治理（$α=1$）下，闭环动力学满足自洽方程：合作表示为水库的固定点，而不是计算。策略复杂度成本定义为水库状态分布与其习惯基线之间的 KL 散度。主体治理降低了这一成本，维度为 $d$ 的行动方差减少至 $1600\times$。动态哨兵根据储存库自身状态生成复合不适信号，驱动自适应 $α(t)$：合作期间接近基线，在背叛时迅速下降以激活认知报复。超越身体会产生与内部状态扭曲成比例的热力学成本。哨兵在所有条件下都获得了最高回报，优于静态机构治理、TfT 和 EMA 基线。维度扫描（$d \in \{5,\ldots,100\}$）显示隐式推理尺度与身体丰富度（$23\times$ 到 $1600\times$ 方差减少），归因于储层动态。 $(d, τ_{\mathrm{env}})$ 空间中的相图揭示了 $d \approx 20$ 附近的治理制度转变。该框架将合作重新解释为适应动力系统的最小耗散响应——从体现的动态而不是计算的动态中产生。

- **2026-02-24** **VGGDrive: Empowering Vision-Language Models with Cross-View Geometric Grounding for Autonomous Driving** [2602.20794](http://arxiv.org/abs/2602.20794)
  > 跨视角3D几何建模能力对于自动驾驶的重要性不言而喻，但现有的视觉语言模型（VLM）本身就缺乏这种能力，导致其性能表现平平。虽然一些有前途的方法试图通过构建用于辅助训练的问答数据来缓解这一问题，但它们仍然无法从根本上使 VLM 具备全面处理不同评估协议的能力。因此，我们制定了一条新路线，主张将成熟 3D 基础模型的交叉视图几何基础注入 VLM，从而缩小自动驾驶中的这一关键能力差距。本着这种精神，我们提出了一种新颖的架构 VGGDrive，它为视觉语言模型提供了跨视图几何基础，以实现自动驾驶。具体来说，为了将冻结视觉 3D 模型中的跨视图 3D 几何特征与 VLM 的 2D 视觉特征连接起来，我们引入了即插即用的跨视图 3D 几何启用器 (CVGE)。 CVGE解耦了基础VLM架构，并通过分层自适应注入机制有效地为VLM提供了3D功能。大量实验表明，VGGDrive 在五个自动驾驶基准测试中增强了基本 VLM 性能，包括跨视图风险感知、运动预测和轨迹规划等任务。我们相信，成熟的 3D 基础模型可以通过有效集成来赋能自动驾驶任务，我们希望我们的初步探索能够向自动驾驶社区展示这种范式的潜力。

- **2026-02-23** **Modeling Epidemiological Dynamics Under Adversarial Data and User Deception** [2602.20134](http://arxiv.org/abs/2602.20134)
  > 流行病学模型越来越依赖自我报告的行为数据，例如疫苗接种状况、口罩使用情况和社交距离遵守情况，以预测疾病传播并评估非药物干预措施 (NPI) 的影响。虽然这些数据提供了有价值的实时见解，但由于个人为了避免处罚、获得福利或表达对公共卫生当局的不信任而采取的动机，它们往往会受到战略误报的影响。为了解释这种人类行为，在本文中，我们引入了一种博弈论框架，该框架将人口与公共卫生当局之间的互动建模为信号博弈。个人（发送者）选择如何报告他们的行为，而公共卫生当局（接收者）则根据可能扭曲的信号更新他们的流行病学模型。我们重点关注围绕掩蔽和疫苗接种的欺骗行为，分析性地描述博弈均衡结果，并评估在通过政策干预维持流行病控制的同时，欺骗行为的容忍程度。我们的结果表明，随着时间的推移，以最小的欺骗程度实现分离平衡会将感染率降至接近于零。值得注意的是，即使在汇集均衡中普遍存在不诚实的情况下，精心设计的发送者和接收者策略仍然可以保持有效的流行病控制。这项工作增进了对流行病学中对抗性数据的理解，并提供了在存在战略用户行为的情况下设计更强大的公共卫生模型的工具。

- **2026-02-23** **NovaPlan: Zero-Shot Long-Horizon Manipulation via Closed-Loop Video Language Planning** [2602.20119](http://arxiv.org/abs/2602.20119)
  > 解决长期任务需要机器人将高级语义推理与低级物理交互相结合。虽然视觉语言模型 (VLM) 和视频生成模型可以分解任务并想象结果，但它们通常缺乏现实世界执行所需的物理基础。我们引入了 NovaPlan，这是一个分层框架，它将闭环 VLM 和视频规划与几何接地机器人执行相结合，以实现零样本长视野操作。在高层，VLM 规划器将任务分解为子目标，并在闭环中监控机器人的执行情况，使系统能够通过自主重新规划从单步故障中恢复。为了计算低级机器人动作，我们从生成的视频中提取并利用与任务相关的对象关键点和人手姿势作为运动学先验，并采用切换机制来选择更好的动作作为机器人动作的参考，即使在严重遮挡或深度不准确的情况下也能保持稳定的执行。我们展示了 NovaPlan 在三项长期任务和功能操作基准（FMB）上的有效性。我们的结果表明，NovaPlan 可以执行复杂的组装任务并表现出灵巧的错误恢复行为，而无需任何事先演示或培训。项目页面：https://nova-plan.github.io/

- **2026-02-23** **MeanFuser: Fast One-Step Multi-Modal Trajectory Generation and Adaptive Reconstruction via MeanFlow for End-to-End Autonomous Driving** [2602.20060](http://arxiv.org/abs/2602.20060)
  > 生成模型在轨迹规划方面显示出了巨大的潜力。最近的研究表明，锚引导生成模型可以有效地模拟驾驶行为的不确定性并提高整体性能。然而，这些方法依赖于离散的锚词汇，这些词汇必须在测试期间充分覆盖轨迹分布以确保鲁棒性，从而导致词汇大小和模型性能之间的固有权衡。为了克服这一限制，我们提出了 MeanFuser，一种端到端自动驾驶方法，通过三个关键设计提高效率和鲁棒性。 （1）我们引入高斯混合噪声（GMN）来指导生成采样，实现轨迹空间的连续表示并消除对离散锚词汇的依赖。 （2）我们将“MeanFlow Identity”应用于端到端规划，它对 GMN 和轨迹分布之间的平均速度场进行建模，而不是普通流匹配方法中使用的瞬时速度场，有效消除 ODE 求解器的数值误差并显着加速推理。（3）我们设计了一个轻量级自适应重建模块（ARM），使模型能够从所有采样提案中隐式选择，或者在通过注意力权重没有一个令人满意的情况下重建新轨迹。闭环基准测试表明，MeanFuser 在没有 PDM 分数监督的情况下实现了出色的性能，并且具有出色的推理效率，为端到端自动驾驶提供了强大而高效的解决方案。

- **2026-02-23** **AdaWorldPolicy: World-Model-Driven Diffusion Policy with Online Adaptive Learning for Robotic Manipulation** [2602.20057](http://arxiv.org/abs/2602.20057)
  > 有效的机器人操作需要能够预测物理结果并适应现实世界环境的策略。有效的机器人操作需要能够预测物理结果并适应现实世界环境的策略。在这项工作中，我们引入了一个统一的框架，即具有在线自适应学习的世界模型驱动扩散策略（AdaWorldPolicy），以在动态条件下以最少的人类参与增强机器人操作。我们的核心见解是，世界模型提供了强大的监督信号，使得动态环境中的在线自适应学习成为可能，并可以通过力-扭矩反馈来补充，以减轻动态力的变化。我们的 AdaWorldPolicy 集成了世界模型、动作专家和力预测器 - 所有这些都以互连的流量匹配扩散变压器 (DiT) 的形式实现。它们通过多模态自注意力层互连，实现联合学习的深度特征交换，同时保留其独特的模块化特征。我们进一步提出了一种新颖的在线自适应学习（AdaOL）策略，该策略可以在“行动生成”模式和“未来想象”模式之间动态切换，以驱动所有三个模块的反应性更新。这创建了一个强大的闭环机制，可以以最小的开销适应视觉和物理域的变化。在一系列模拟和真实机器人基准测试中，我们的 AdaWorldPolicy 实现了最先进的性能，具有对分布外场景的动态自适应能力。

- **2026-02-23** **Probabilistic Photonic Computing** [2602.19968](http://arxiv.org/abs/2602.19968)
  > 概率计算擅长近似组合问题和建模不确定性。然而，将传统的确定性硬件用于概率模型具有挑战性：（伪）随机数生成会引入计算开销和额外的数据混洗，这对于需要低延迟的安全关键应用（例如自动驾驶）尤其不利。因此，迫切需要创新的概率计算架构，以合理的能耗实现低延迟。物理计算提供了一个有前途的解决方案，因为这些系统不依赖于数据的抽象确定性表示，而是直接以物理量对信息进行编码。因此，它们可以与物理熵源无缝集成，从而实现固有的概率架构。由于可用带宽大、数据编码的多个正交自由度以及内存计算和并行数据传输的最佳特性，光子计算是一个突出的变体。在这里，我们重点介绍物理光子计算和光子随机数生成方面的关键进展。我们提供有关概率光子处理器实现的见解，并就其对人工智能系统的影响和未来挑战提供我们的观点。

- **2026-02-23** **Probing Dust in the MWC 480 Disk from Millimeter to Centimeter Wavelengths** [2602.19941](http://arxiv.org/abs/2602.19941)
  > 我们对 MWC 480 周围的圆盘进行了深度、高分辨率（ $\sim$100 mas）Karl G. Jansky 甚大阵列 (VLA) Ka 波段 (9.1 毫米) 观测，并通过与档案阿塔卡马大型毫米/亚毫米阵列 (ALMA) 0.87、1.17、1.33 和 3.0 毫米数据的组合分析推断尘埃属性。首次在 9.1 毫米处检测到 95 au (B95) 处突出的尘埃环，而 160 au 处微弱的外环并未显露出来。通过非参数可见度建模，我们确定了两个新的环形特征：所有波长范围内 20-50 au 内的平台，以及 B95 环外部 0.87、1.17 和 1.33 毫米处的肩部，与行星盘相互作用的特征一致。我们发现 B95 环的宽度在整个波长范围内保持恒定，这表明碎片在径向扩散中占主导地位，或者环内存在未解析的子结构。解析光谱模型产生了两类尘埃解决方案，它们同样能很好地再现观测结果：致密颗粒或高度多孔（90％）的颗粒，其中碳质成分分别以难熔有机物或无定形碳为主。推断的最大晶粒尺寸在两个环的位置达到峰值，并在 B95 环内达到厘米。两种灰尘混合物的总灰尘质量为 $860^{+95}_{-78}\rm~M_\oplus$/$1500^{+440}_{-330}\rm~M_\oplus$（内盘中的大/小颗粒溶液）和 $230^{+14}_{-13}\rm~M_\oplus$。仅 B95 环就分别包含 $100^{+5}_{-5}\rm~M_\oplus$ 和 $43^{+2}_{-2}\rm~M_\oplus$ ，足以组装巨行星的核心。最后，我们强调了宽带、多波长观测在更好地限制原行星盘中的尘埃成分和孔隙率方面的力量。

- **2026-02-23** **VGGT-MPR: VGGT-Enhanced Multimodal Place Recognition in Autonomous Driving Environments** [2602.19735](http://arxiv.org/abs/2602.19735)
  > 在自动驾驶中，强大的位置识别对于全局定位和闭环检测至关重要。虽然多模态位置识别 (MPR) 中相机和 LiDAR 数据的模态间融合在克服单模态对应方法的局限性方面表现出了希望，但现有的 MPR 方法基本上只关注手工制作的融合策略和需要昂贵的再训练的高度参数化的主干网。为了解决这个问题，我们提出了 VGGT-MPR，这是一种多模态地点识别框架，采用视觉几何接地变换器（VGGT）作为统一的几何引擎，用于全局检索和重新排序。在全局检索阶段，VGGT通过先前的深度感知和点图监督提取几何丰富的视觉嵌入，并用预测的深度图致密稀疏的LiDAR点云以改善结构表示。这增强了融合多模态特征的辨别能力，并生成用于快速检索的全局描述符。除了全局检索之外，我们还设计了一种免训练的重新排序机制，该机制利用 VGGT 的跨视图关键点跟踪功能。通过将掩模引导的关键点提取与置信感知对应评分相结合，我们提出的重新排序机制有效地细化了检索结果，而无需额外的参数优化。对大规模自动驾驶基准的大量实验和我们自行收集的数据表明，VGGT-MPR 实现了最先进的性能，对严重的环境变化、视角转换和遮挡表现出强大的鲁棒性。我们的代码和数据将公开。

- **2026-02-23** **Universal Pose Pretraining for Generalizable Vision-Language-Action Policies** [2602.19710](http://arxiv.org/abs/2602.19710)
  > 现有的视觉-语言-动作（VLA）模型经常遭受特征崩溃和训练效率低下的困扰，因为它们将高级感知与稀疏的、特定于实施例的动作监督纠缠在一起。由于这些模型通常依赖于针对视觉问答 (VQA) 进行优化的 VLM 主干，因此它们擅长语义识别，但经常忽略决定不同动作模式的微妙 3D 状态变化。   为了解决这些未对准问题，我们提出了 Pose-VLA，这是一种解耦范例，它将 VLA 训练分为预训练阶段，用于在统一的以相机为中心的空间中提取通用 3D 空间先验，以及后训练阶段，用于在机器人特定的动作空间内进行有效的实施例对齐。通过引入离散姿势标记作为通用表示，Pose-VLA 将来自不同 3D 数据集的空间基础与来自机器人演示的几何级轨迹无缝集成。我们的框架遵循两阶段预训练流程，通过姿势建立基本的空间基础，然后通过轨迹监督进行运动对齐。   广泛的评估表明，Pose-VLA 在 RoboTwin 2.0 上取得了最先进的结果，平均成功率为 79.5%，在 LIBERO 上的竞争表现为 96.0%。现实世界的实验进一步展示了跨不同对象的强大泛化能力，每个任务仅使用 100 个演示，验证了我们预训练范例的效率。

- **2026-02-23** **Compositional Planning with Jumpy World Models** [2602.19634](http://arxiv.org/abs/2602.19634)
  > 利用时间抽象进行规划的能力是智能决策的核心。我们不是对原始动作进行推理，而是研究将预先训练的策略组成为临时扩展动作的代理，从而能够解决任何一个成员无法单独解决的复杂任务。这种组合规划仍然难以捉摸，因为长期预测中的复合误差使得估计排序策略引起的访问分布变得具有挑战性。在 arXiv:2206.08736 中引入的几何政策组合框架的推动下，我们通过学习多步动态的预测模型（所谓的跳跃世界模型）来应对这些挑战，这些模型以非政策方式捕获跨多个时间尺度的预训练政策引起的状态占用。在时间差异流 (arXiv:2503.09817) 的基础上，我们通过新颖的一致性目标增强了这些模型，该目标可以跨时间尺度调整预测，从而提高长期预测准确性。我们进一步演示了如何结合这些生成预测来估计在不同时间尺度上执行任意策略序列的价值。根据经验，我们发现，在具有挑战性的操作和导航任务上，使用跳跃世界模型进行组合规划可以显着提高各种基本策略的零样本性能，平均比在长视野任务上使用原始操作进行规划相对提高了 200%。

- **2026-02-23** **HOCA-Bench: Beyond Semantic Perception to Predictive World Modeling via Hegelian Ontological-Causal Anomalies** [2602.19571](http://arxiv.org/abs/2602.19571)
  > 视频法学硕士在语义感知方面稳步提高，但在预测世界建模方面仍然存在不足，而预测世界建模是物理基础智能的核心。我们推出 HOCA-Bench，这是一个通过黑格尔透镜描述物理异常的基准。 HOCA-Bench 将异常分为两种类型：本体异常（实体违反其自身的定义或持久性）和因果异常（交互违反物理关系）。我们使用最先进的生成视频模型作为对抗模拟器，构建了一个包含 1,439 个视频（3,470 个 QA 对）的测试平台。对 17 个视频法学硕士的评估显示出明显的认知滞后：模型经常识别静态本体论违规（例如形状突变），但与因果机制（例如重力或摩擦）作斗争，因果任务的性能下降超过 20%。 System-2“思维”模式改善了推理，但并没有缩小差距，这表明当前的架构比应用基本物理定律更容易识别视觉模式。

- **2026-02-20** **Generated Reality: Human-centric World Simulation using Interactive Video Generation with Hand and Camera Control** [2602.18422](http://arxiv.org/abs/2602.18422)
  > 扩展现实（XR）需要生成模型来响应用户跟踪的现实世界运动，但当前的视频世界模型仅接受粗略的控制信号，例如文本或键盘输入，限制了它们在实体交互中的实用性。我们引入了一种以人为中心的视频世界模型，该模型以跟踪的头部姿势和关节级手部姿势为条件。为此，我们评估了现有的扩散变压器调节策略，并提出了一种有效的 3D 头部和手部控制机制，实现灵巧的手-物体交互。我们使用这种策略训练双向视频传播模型教师，并将其提炼成一个因果交互系统，生成以自我为中心的虚拟环境。我们用人类受试者评估了这个生成的现实系统，并证明了与相关基线相比，任务绩效得到了改善，并且对所执行的操作的感知控制程度显着提高。

- **2026-02-20** **How Fast Can I Run My VLA? Demystifying VLA Inference Performance with VLA-Perf** [2602.18397](http://arxiv.org/abs/2602.18397)
  > 视觉-语言-动作（VLA）模型最近在各种具体的人工智能任务中展示了令人印象深刻的能力。虽然在现实世界的机器人上部署 VLA 模型会施加严格的实时推理约束，但由于模型架构和推理系统的组合空间很大，人们对 VLA 的推理性能前景仍然知之甚少。在本文中，我们提出了一个基本的研究问题：我们应该如何设计未来的 VLA 模型和系统来支持实时推理？为了解决这个问题，我们首先引入VLA-Perf，一种分析性能模型，可以分析VLA模型和推理系统的任意组合的推理性能。使用 VLA-Perf，我们对 VLA 推理性能景观进行了首次系统研究。从模型设计的角度来看，我们研究了模型扩展、模型架构选择、长上下文视频输入、异步推理和双系统模型管道如何影响推理性能。从部署的角度来看，我们分析了 VLA 推理应该在哪里执行——设备上、边缘服务器上还是云端——以及硬件功能和网络性能如何共同决定端到端延迟。通过从综合评估中提炼出 15 个关键要点，我们希望这项工作能够为未来 VLA 模型和推理系统的设计提供实用指导。

- **2026-02-20** **Zero-shot Interactive Perception** [2602.18374](http://arxiv.org/abs/2602.18374)
  > 交互式感知 (IP) 使机器人能够提取工作空间中的隐藏信息，并通过与物体进行物理交互并改变环境状态来执行操作计划，这对于解决复杂、部分可观察场景中的遮挡和模糊性至关重要。我们提出了零射击 IP (ZS-IP)，这是一种新颖的框架，它将多策略操作（推动和抓取）与内存驱动的视觉语言模型 (VLM) 结合起来，以指导机器人交互并解决语义查询。 ZS-IP 集成了三个关键组件：(1) 增强观察 (EO) 模块，通过传统关键点和我们提出的推线来增强 VLM 的视觉感知——一种专为推动动作量身定制的新型 2D 视觉增强；(2) 记忆引导动作模块，通过上下文查找强化语义推理；(3) 机器人控制器，根据 VLM 输出执行推、拉或抓握。与针对拾取和放置进行优化的基于网格的增强功能不同，推送线捕获了丰富接触动作的可供性，从而大大提高了推送性能。我们在 7 自由度 Franka Panda 手臂上评估 ZS-IP，涵盖具有不同遮挡和任务复杂性的不同场景。我们的实验表明，ZS-IP 优于被动和基于视点的感知技术，例如基于标记的视觉提示 (MOKA)，特别是在推送任务方面，同时保留非目标元素的完整性。

- **2026-02-20** **"How Do I ...?": Procedural Questions Predominate Student-LLM Chatbot Conversations** [2602.18372](http://arxiv.org/abs/2602.18372)
  > 通过基于大型语言模型 (LLM) 的教育聊天机器人提供脚手架具有潜在的风险和好处，这仍然是一个开放的研究领域。当学生遇到僵局时，他们会通过提出僵局驱动的问题来寻求帮助。在与 LLM 聊天机器人的交互中，此类问题会形成用户提示并提高聊天机器人响应的教学有效性。本文重点关注来自不同学习环境的两个数据集的此类学生问题：形成性自学和总结性评估课程作业。我们分析了来自两种学习环境的 6,113 条消息，使用 11 名不同的法学硕士和 3 名人工评分员，使用四种现有模式对学生问题进行分类。关于使用法学硕士作为评估者的可行性，结果显示评估者间的可靠性为中等至良好，比人类评估者具有更高的一致性。数据显示，“程序性”问题在两种学习环境中都占主导地位，但当学生准备总结性评估时更是如此。这些结果为使用法学硕士对学生问题进行分类提供了基础。然而，我们发现使用模式进行分类的能力和这样做的价值都存在明显的局限性：模式是有限的，因此很难适应复合提示的语义丰富性，只能部分了解聊天机器人集成的更广泛的风险和好处。将来，我们推荐一种分析方法，例如通过应用话语心理学中的对话分析方法来捕捉对话的微妙、多轮性质。

- **2026-02-20** **SimVLA: A Simple VLA Baseline for Robotic Manipulation** [2602.18224](http://arxiv.org/abs/2602.18224)
  > 视觉-语言-动作（VLA）模型已成为通用机器人操作的一个有前途的范例，利用大规模预训练来实现强大的性能。随着额外的空间优先和多样化的建筑创新，该领域迅速发展。然而，这些进步通常伴随着不同的训练方法和实施细节，这使得理清经验收益的精确来源变得困难。在这项工作中，我们引入了 SimVLA，这是一个简化的基线，旨在为 VLA 研究建立透明的参考点。通过严格将感知与控制解耦，使用标准视觉语言骨干和轻量级动作头，以及标准化关键训练动态，我们证明了最小的设计可以实现最先进的性能。尽管只有 0.5B 个参数，SimVLA 在没有机器人预训练的情况下，在标准仿真基准上的性能优于数十亿参数模型。与 pi0.5 相比，SimVLA 还达到了与真实机器人相当的性能。我们的结果将 SimVLA 确立为稳健、可重复的基线，可以将经验收益明确归因于未来的架构创新。网站：https://frontierrobo.github.io/SimVLA

- **2026-02-20** **The GUAPOS project -- VII: Physical structure and molecular environment of the G31.41+0.31 HII region** [2602.18209](http://arxiv.org/abs/2602.18209)
  > OB型恒星周围的电离区域是在其演化的早期阶段形成的，对于研究这些天体的形成过程非常重要。然而，到目前为止，对其物理结构以及与母体分子云相互作用的观察很少。 ALMA 和升级版 VLA 等新仪器的高分辨率和灵敏度使我们能够填补这一知识空白。我们研究了众所周知的核晕超致密 HII 区域 G31.41+0.31 和周围的分子团，目的是确定电离气体和中性气体的密度和温度，并可能获得其空间分布的 3D 图片。我们利用 ALMA 为 GUAPOS 项目获得的 3 mm 处的全频带频率覆盖范围，对向 G31.41+0.31 HII 区域发射的大量氢复合线以及作为中等密度 ( $\sim$$10^4$--$10^6$ cm$^{-3}$) 气体示踪剂的几个分子跃迁进行成像。线数据由 VLA 在 1 厘米和 7 毫米处获得的连续测量数据进行补充。通过使用考虑非 LTE 效应的模型来拟合这些线，我们可以研究该区域的密度和温度结构以及速度场。我们的研究结果基于考虑非 LTE 效应的模型拟合，表明 HII 区域的电子温度大多在 5000 到 6000 K 之间，而密度在 2500 到 7500 cm$^{-3}$ 之间变化。总而言之，这些参数的分布以及相应的速度场暗示彗星形状的 HII 区域从观察者向西北方向扩展。分子气体似乎仍在向 UC HII 区域的峰值下降，其密度和温度与电离气体对 SE 的压力限制一致。

- **2026-02-20** **OODBench: Out-of-Distribution Benchmark for Large Vision-Language Models** [2602.18094](http://arxiv.org/abs/2602.18094)
  > 现有的视觉语言模型 (VLM) 通过在大规模数据集上进行训练，通常在数据独立同分布 (IID) 的假设下取得了重大进展。然而，在现实场景中，期望人工智能系统处理的所有数据都满足这一假设通常是不切实际的。此外，未能正确处理分布外（OOD）对象可能会在现实应用（例如自动驾驶或医疗援助）中引入安全风险。不幸的是，当前的研究尚未提供有效的基准来全面评估 VLM 响应 OOD 数据的性能。因此，我们提出了 OODBench，这是一种以最少的人工验证为主的自动化方法，用于构建新的基准并评估 VLM 处理 OOD 数据的能力。 OODBench 包含 40K 实例级 OOD 实例类别对，我们表明，即使底层图像类别很常见，当前的 VLM 在 OODBench 上仍然表现出显着的性能下降。此外，我们提出了一种可靠的自动评估指标，该指标采用从基础到高级的提示问题进展，更全面地评估 OOD 数据对不同难度问题的影响。最后，我们总结了重要的发现和见解，以促进 OOD 数据获取和评估的未来研究。

- **2026-02-20** **Dynamic Deception: When Pedestrians Team Up to Fool Autonomous Cars** [2602.18079](http://arxiv.org/abs/2602.18079)
  > 许多针对自动驾驶感知模型的对抗性攻击一旦部署在完整的驾驶堆栈中，就不会导致系统级故障。这种无效的主要原因是，一旦部署在系统中（例如，在模拟器中），由于车辆的动力学，攻击往往在空间或时间上是短暂的，因此很少影响车辆的行为。在本文中，我们通过引入系统级攻击来解决这两个限制，其中多个动态元素（例如，两个行人）携带对抗性补丁（例如，在衣服上），并通过协调和运动共同放大其效果。我们使用最先进的自动驾驶代理在 CARLA 模拟器中评估我们的攻击。在系统层面，单行人攻击在所有运行中都失败（满分 10 次），而两个行人的动态串谋会在高达 50% 的运行中导致车辆完全停止，静态串谋根本不会产生成功的攻击。这些结果表明，只有当对抗性信号持续存在并通过协调的参与者放大时，系统级故障才会出现，从而暴露出模型级稳健性和端到端安全性之间的差距。

- **2026-02-20** **Faster Training, Fewer Labels: Self-Supervised Pretraining for Fine-Grained BEV Segmentation** [2602.18066](http://arxiv.org/abs/2602.18066)
  > 密集鸟瞰 (BEV) 语义地图是自动驾驶的核心，但当前的多摄像头方法依赖于成本高昂且注释不一致的 BEV 地面实况。我们通过细粒度道路标记分割的两阶段训练策略来解决这一限制，该策略消除了预训练期间的全面监督，并将微调期间的训练数据量减半，同时仍然优于可比较的监督基线模型。在自监督预训练期间，BEVFormer 预测以可微分的方式重新投影到图像平面中，并针对广泛使用的语义分割模型 Mask2Former 生成的多视图语义伪标签进行训练。时间损失促进了跨帧的一致性。随后的监督微调阶段仅需要 50% 的数据集，并且训练时间显着减少。通过我们的方法，预训练过程中学到的丰富先验知识的微调可以提高 nuScenes 上的性能和 BEV 分割质量（在完全监督的基线上高达 +2.5pp mIoU）。它同时将注释数据的使用量减半，并将总训练时间减少多达三分之二。结果表明，可微分重投影加上相机视角伪标签可产生可转移的 BEV 特征和通往减少标签自主感知的可扩展路径。

- **2026-02-20** **UAOR: Uncertainty-aware Observation Reinjection for Vision-Language-Action Models** [2602.18020](http://arxiv.org/abs/2602.18020)
  > 视觉语言动作 (VLA) 模型利用预训练的视觉语言模型 (VLM) 作为骨干，将图像和指令映射到动作，展示了通用机器人操作的巨大潜力。为了提高性能，现有方法通常结合额外的观察线索（例如深度图、点云）或辅助模块（例如对象检测器、编码器）以实现更精确和可靠的任务执行，但这些通常需要昂贵的数据收集和额外的训练。受到语言模型中的前馈网络（FFN）可以充当“键值记忆”这一发现的启发，我们提出了不确定性感知观察重注入（UAOR），这是一种有效的、免训练的、即插即用的 VLA 模型模块。具体来说，当当前语言模型层表现出通过动作熵测量的高度不确定性时，它会通过注意力检索将关键观察信息重新注入到下一层的前馈网络（FFN）中。这种机制可以帮助 VLA 在推理过程中更好地关注观察结果，从而实现更加自信和忠实的行动生成。综合实验表明，我们的方法能够以最小的开销持续改进模拟和现实任务中的各种 VLA 模型。值得注意的是，UAOR 不需要额外的观察线索或模块，使其成为现有 VLA 管道的多功能且实用的插件。项目页面位于https://uaor.jiabingyang.cn。


<p align=right>(<a href=#updated-on-20260226>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

