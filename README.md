[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.03.23
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-03-21**|**HAC: Hash-grid Assisted Context for 3D Gaussian Splatting Compression**|三维高斯散射（3DGS）以其快速、高保真的渲染速度成为一种很有前途的新型视图合成框架。然而，大量的高斯及其相关属性需要有效的压缩技术。然而，高斯点云（或我们论文中的锚点）的稀疏和无组织性质给压缩带来了挑战。为了解决这一问题，我们利用无组织锚和结构化哈希网格之间的关系，利用它们的相互信息进行上下文建模，并提出了一种用于高度紧凑的3DGS表示的哈希网格辅助上下文（HAC）框架。我们的方法引入了一个二进制哈希网格来建立连续的空间一致性，使我们能够通过精心设计的上下文模型揭示锚点的固有空间关系。为了便于熵编码，我们利用高斯分布来准确估计每个量化属性的概率，其中提出了自适应量化模块来实现这些属性的高精度量化，以提高保真度恢复。此外，我们结合了一种自适应掩蔽策略来消除无效的高斯和锚点。重要的是，我们的工作是探索3DGS表示基于上下文的压缩的先驱，与普通3DGS相比，其尺寸显著减少了75美元，同时提高了保真度，并与SOTA 3DGS压缩方法Scaffold GS相比，尺寸减少了11美元。我们的代码如下：https://github.com/YihangChen-ee/HAC et.al.|[2403.14530](http://arxiv.org/abs/2403.14530)|**[link](https://github.com/yihangchen-ee/hac)**|
|**2024-03-21**|**CombiNeRF: A Combination of Regularization Techniques for Few-Shot Neural Radiance Field View Synthesis**|当有足够多的视图可用时，神经辐射场（NeRF）在新的视图合成中显示出令人印象深刻的结果。当处理少量镜头设置时，即使用一小组输入视图时，训练可能会过度拟合这些视图，导致生成的渲染中出现伪影以及几何和颜色不一致。正则化是一种有效的解决方案，有助于NeRF的泛化。另一方面，每一种最新的NeRF正则化技术都旨在缓解特定的渲染问题。从这一观察出发，在本文中，我们提出了CombiNeRF，这是一个协同结合了几种正则化技术的框架，其中一些是新颖的，以统一每种技术的优点。特别地，我们正则化单个和相邻射线分布，并添加平滑项来正则化近几何体。在这些几何方法之后，我们建议将Lipschitz正则化应用于NeRF密度和颜色网络，并使用编码掩码进行输入特征正则化。我们展示了CombiNeRF在几个公开可用的数据集中以较少的镜头设置优于最先进的方法。我们还对LLFF和NeRF合成数据集进行了消融研究，以支持所做的选择。我们在本文中发布了我们框架的开源实现。 et.al.|[2403.14412](http://arxiv.org/abs/2403.14412)|**[link](https://github.com/sarroccoluigi/combinerf)**|
|**2024-03-21**|**Zero123-6D: Zero-shot Novel View Synthesis for RGB Category-level 6D Pose Estimation**|通过视觉估计物体的姿态对于使机器人平台与环境交互至关重要。然而，它带来了许多挑战，往往与最先进的解决方案缺乏灵活性和可推广性有关。扩散模型是一种转换二维和三维计算机视觉的前沿神经结构，概述了零样本新颖视图合成的显著性能。这样的用例对于重建3D对象来说特别有趣。然而，在非结构化环境中定位对象是相当未被探索的。为此，这项工作提出了Zero123-6D，以展示基于扩散模型的新型视图合成器在通过将其与特征提取技术集成来增强类别级别的RGB 6D姿态估计方面的实用性。所概述的方法利用这种新颖的视图合成器来扩展用于零样本6D姿态估计任务的仅RGB参考视图的稀疏集合。在CO3D数据集上对实验进行了定量分析，显示出与基线相比性能有所提高，数据需求大幅减少，并消除了深度信息的必要性。 et.al.|[2403.14279](http://arxiv.org/abs/2403.14279)|null|
|**2024-03-21**|**Isotropic Gaussian Splatting for Real-Time Radiance Field Rendering**|三维高斯飞溅方法由于其在训练中的高性能和渲染图像的高质量而引起了人们的广泛关注。但是，它使用各向异性高斯核来表示场景。尽管这种各向异性核在表示几何体方面具有优势，但它们在计算方面导致困难，例如分裂或合并两个核。在本文中，我们建议使用各向同性高斯核来避免计算中的这些困难，从而获得更高性能的方法。实验证实，所提出的方法在不损失几何表示精度的情况下大约快100X。所提出的方法可以应用于需要辐射场的大范围应用，如三维重建、视图合成和动态对象建模。 et.al.|[2403.14244](http://arxiv.org/abs/2403.14244)|null|
|**2024-03-21**|**Leveraging Thermal Modality to Enhance Reconstruction in Low-Light Conditions**|神经辐射场（NeRF）通过从多视图图像中学习场景的隐式体积表示来实现照片逼真的新视图合成，从而忠实地传达色度信息。然而，传感器噪声将污染低值像素信号，并且有损相机图像信号处理器将在极暗的情况下进一步去除接近零的强度，从而恶化合成性能。现有的方法从原始图像重建低光场景，但难以恢复暗区域中的纹理和边界细节。此外，它们不适用于依赖显式表示的高速模型。为了解决这些问题，我们提出了Thermal NeRF，它将热和可见原始图像作为输入，考虑到热相机对照明变化是鲁棒的，并且原始图像在黑暗中保留了任何可能的线索，以同时完成可见和热视图合成。此外，建立了第一个多视图热可见光数据集（MVTV），以支持多模式NeRF的研究。Thermal NeRF实现了细节保留和噪声平滑之间的最佳折衷，并提供了比以前更好的合成性能。最后，我们证明了这两种模式在3D重建中是有益的。 et.al.|[2403.14053](http://arxiv.org/abs/2403.14053)|null|
|**2024-03-20**|**RadSplat: Radiance Field-Informed Gaussian Splatting for Robust Real-Time Rendering with 900+ FPS**|视图合成和实时渲染的最新进展以令人印象深刻的渲染速度实现了照片级的真实感。虽然基于辐射场的方法在具有挑战性的场景（如野外捕捉和大规模场景）中实现了最先进的质量，但它们通常会受到与体积渲染相关的过高计算要求的影响。另一方面，基于高斯散射的方法依赖于光栅化，自然实现实时渲染，但在更具挑战性的环境中，其优化启发式效果较差。在这项工作中，我们提出了RadSplat，这是一种用于复杂场景的鲁棒实时渲染的轻量级方法。我们的主要贡献有三方面。首先，我们使用辐射场作为先验信号和监督信号来优化基于点的场景表示，从而提高质量和更稳健的优化。接下来，我们开发了一种新的修剪技术，在保持高质量的同时减少总点数，从而以更快的推理速度实现更小、更紧凑的场景表示。最后，我们提出了一种新的测试时间过滤方法，该方法可以进一步加速渲染，并允许缩放到更大的房屋大小的场景。我们发现，我们的方法能够以900+FPS的速度合成最先进的复杂捕获。 et.al.|[2403.13806](http://arxiv.org/abs/2403.13806)|null|
|**2024-03-20**|**Learning Novel View Synthesis from Heterogeneous Low-light Captures**|神经辐射场在从固定正常照明下捕获的具有相同亮度水平的输入视图合成新视图方面取得了基本成功。不幸的是，对于在弱光条件下捕获的具有异质亮度水平的输入视图来说，合成新视图仍然是一个挑战。这种情况在现实世界中很常见。它会导致低对比度图像，其中细节被隐藏在黑暗中，相机传感器噪声会显著降低图像质量。为了解决这个问题，我们建议学习根据反射率在异构视图中保持不变来分解输入视图中的照明、反射率和噪声。为了应对多视图之间的异质亮度和噪声水平，我们学习了照明嵌入，并为每个视图单独优化噪声图。为了能够直观地编辑照明，我们设计了一个照明调整模块，以使照明组件变亮或变暗。综合实验表明，与最先进的方法相比，该方法能够对弱光多视图噪声图像进行有效的内在分解，并在合成新视图方面实现了卓越的视觉质量和数值性能。 et.al.|[2403.13337](http://arxiv.org/abs/2403.13337)|null|
|**2024-03-20**|**Gaussian Splatting on the Move: Blur and Rolling Shutter Compensation for Natural Camera Motion**|基于高斯散射（3DGS）的高质量场景重建和新颖的视图合成通常需要稳定、高质量的照片，而手持相机通常无法捕捉到这些照片。我们提出了一种适应相机运动的方法，并允许使用遭受运动模糊和滚动快门失真的手持视频数据进行高质量的场景重建。我们的方法基于物理图像形成过程的详细建模，并利用视觉惯性里程计（VIO）估计的速度。在单个图像帧的曝光时间期间，摄像机姿态被认为是非静态的，并且在重建过程中进一步优化摄像机姿态。我们制定了一个可微分的渲染管道，利用屏幕空间近似将滚动快门和运动模糊效果有效地结合到3DGS框架中。我们对合成和真实数据的结果表明，与现有方法相比，我们在减轻相机运动方面表现出了卓越的性能，从而在自然环境中推进了3DGS。 et.al.|[2403.13327](http://arxiv.org/abs/2403.13327)|**[link](https://github.com/spectacularai/3dgs-deblur)**|
|**2024-03-19**|**HUGS: Holistic Urban 3D Scene Understanding via Gaussian Splatting**|基于RGB图像对城市场景的整体理解是一个具有挑战性但又很重要的问题。它包括理解几何图形和外观，以实现新颖的视图合成、解析语义标签和跟踪移动对象。尽管取得了相当大的进展，但现有的方法往往侧重于这项任务的特定方面，并需要额外的输入，如激光雷达扫描或手动注释的3D边界框。在本文中，我们介绍了一种新的管道，该管道利用3D高斯散射进行整体城市场景理解。我们的主要想法涉及使用静态和动态3D高斯的组合对几何、外观、语义和运动进行联合优化，其中运动对象姿态通过物理约束进行正则化。我们的方法提供了实时渲染新视点的能力，以高精度生成2D和3D语义信息，并重建动态场景，即使在3D边界框检测具有高噪声的场景中也是如此。在KITTI、KITTI-360和Virtual KITTI 2上的实验结果证明了我们方法的有效性。 et.al.|[2403.12722](http://arxiv.org/abs/2403.12722)|null|
|**2024-03-19**|**IFFNeRF: Initialisation Free and Fast 6DoF pose estimation from a single image and a NeRF model**|我们引入IFFNeRF来估计给定图像的六自由度（6DoF）相机姿态，建立在神经辐射场（NeRF）公式的基础上。IFFNeRF专门设计用于实时操作，无需进行接近所寻求解决方案的初始姿势猜测。IFFNeRF利用Metropolis Hasting算法对NeRF模型内的表面点进行采样。从这些采样点，我们投射光线，并通过像素级视图合成推断每条光线的颜色。然后，可以通过选择查询图像和所得束之间的对应关系来估计相机姿态作为最小二乘问题的解决方案。我们通过学习注意力机制来促进这一过程，将查询图像嵌入与参数化射线的嵌入桥接起来，从而匹配与图像相关的射线。通过合成和真实评估设置，我们表明，与iNeRF相比，我们的方法可以分别将角度和平移误差精度提高80.1%和67.3%，同时在消费类硬件上以34fps的速度执行，并且不需要初始姿势猜测。 et.al.|[2403.12682](http://arxiv.org/abs/2403.12682)|null|

<p align=right>(<a href=#updated-on-20240323>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-03-21**|**GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation**|我们介绍了GRM，这是一种能够在大约0.1s内从稀疏视图图像中恢复3D资产的大规模重建器。GRM是一种基于前馈变换器的模型，它有效地结合了多视图信息，以将输入像素转换为像素对齐的高斯，这些高斯不被投影以创建一组代表场景的密集分布的3D高斯。我们的变压器架构和3D高斯的使用共同开启了一个可扩展且高效的重建框架。大量的实验结果表明，在重建质量和效率方面，我们的方法优于其他方法。我们还通过将GRM与现有的多视图扩散模型相集成，展示了它在生成任务（即文本到3D和图像到3D）中的潜力。我们的项目网站位于：https://justimyhxu.github.io/projects/grm/. et.al.|[2403.14621](http://arxiv.org/abs/2403.14621)|**[link](https://github.com/justimyhxu/grm)**|
|**2024-03-21**|**Isotropic Gaussian Splatting for Real-Time Radiance Field Rendering**|三维高斯飞溅方法由于其在训练中的高性能和渲染图像的高质量而引起了人们的广泛关注。但是，它使用各向异性高斯核来表示场景。尽管这种各向异性核在表示几何体方面具有优势，但它们在计算方面导致困难，例如分裂或合并两个核。在本文中，我们建议使用各向同性高斯核来避免计算中的这些困难，从而获得更高性能的方法。实验证实，所提出的方法在不损失几何表示精度的情况下大约快100X。所提出的方法可以应用于需要辐射场的大范围应用，如三维重建、视图合成和动态对象建模。 et.al.|[2403.14244](http://arxiv.org/abs/2403.14244)|null|
|**2024-03-21**|**Leveraging Thermal Modality to Enhance Reconstruction in Low-Light Conditions**|神经辐射场（NeRF）通过从多视图图像中学习场景的隐式体积表示来实现照片逼真的新视图合成，从而忠实地传达色度信息。然而，传感器噪声将污染低值像素信号，并且有损相机图像信号处理器将在极暗的情况下进一步去除接近零的强度，从而恶化合成性能。现有的方法从原始图像重建低光场景，但难以恢复暗区域中的纹理和边界细节。此外，它们不适用于依赖显式表示的高速模型。为了解决这些问题，我们提出了Thermal NeRF，它将热和可见原始图像作为输入，考虑到热相机对照明变化是鲁棒的，并且原始图像在黑暗中保留了任何可能的线索，以同时完成可见和热视图合成。此外，建立了第一个多视图热可见光数据集（MVTV），以支持多模式NeRF的研究。Thermal NeRF实现了细节保留和噪声平滑之间的最佳折衷，并提供了比以前更好的合成性能。最后，我们证明了这两种模式在3D重建中是有益的。 et.al.|[2403.14053](http://arxiv.org/abs/2403.14053)|null|
|**2024-03-20**|**T-Pixel2Mesh: Combining Global and Local Transformer for 3D Mesh Generation from a Single Image**|Pixel2Mesh（P2M）是一种通过粗网格到细网格变形从单色图像重建3D形状的经典方法。尽管P2M能够生成看似合理的全局形状，但其图形卷积网络（GCN）通常会产生过于平滑的结果，导致细粒度几何细节的丢失。此外，P2M为遮挡区域生成不可信的特征，并与从合成数据到真实世界图像的域差距作斗争，这是单视图3D重建方法的常见挑战。为了应对这些挑战，我们提出了一种新的Transformer增强架构，命名为T-Pixel2Mesh，其灵感来自P2M的从粗到细方法。具体而言，我们使用全局Transformer来控制整体形状，使用局部Transformer通过基于图的点上采样逐步细化局部几何细节。为了增强真实世界的重建，我们提出了简单而有效的线性尺度搜索（LSS），它在输入预处理过程中起到了及时调整的作用。我们在ShapeNet上的实验展示了最先进的性能，而在真实世界数据上的结果显示了泛化能力。 et.al.|[2403.13663](http://arxiv.org/abs/2403.13663)|null|
|**2024-03-20**|**MULAN-WC: Multi-Robot Localization Uncertainty-aware Active NeRF with Wireless Coordination**|本文提出了MULAN-WC，这是一种新颖的多机器人三维重建框架，利用了机器人和神经辐射场（NeRF）之间基于无线信号的协调。我们的方法解决了多机器人三维重建中的关键挑战，包括机器人间姿态估计、定位不确定性量化和主动最佳下一视图选择。我们介绍了一种使用无线到达角（AoA）和测距测量来估计机器人之间的相对姿态的方法，以及量化这些姿态估计的无线定位中嵌入的不确定性并将其纳入NeRF训练损失中，以减轻不准确的相机姿态的影响。此外，我们提出了一种主动视图选择方法，在确定下一个最佳视图时考虑机器人姿态的不确定性，以改进3D重建，从而通过智能视图选择实现更快的收敛。在合成数据集和真实世界数据集上进行的大量实验证明了我们的框架在理论和实践中的有效性。利用无线协调和定位不确定性感知训练，MULAN-WC可以实现高质量的三维重建，这接近于应用地面实况相机姿态。此外，通过向机器人推荐新的视图位置，对新视图的信息增益进行量化，可以在增量捕获图像的情况下实现一致的渲染质量改进。我们的硬件实验展示了将MULAN-WC部署到真实机器人系统的实用性。 et.al.|[2403.13348](http://arxiv.org/abs/2403.13348)|null|
|**2024-03-19**|**GVGEN: Text-to-3D Generation with Volumetric Representation**|近年来，3D高斯飞溅已成为一种强大的3D重建和生成技术，以其快速和高质量的渲染能力而闻名。为了解决这些缺点，本文介绍了一种新的基于扩散的框架GVGEN，旨在从文本输入中有效地生成3D高斯表示。我们提出了两种创新技术：（1）结构化体积表示。我们首先将无组织的三维高斯点排列为结构化形式的高斯体积。这种变换允许在由固定数量的高斯组成的体积内捕捉复杂的纹理细节。为了更好地优化这些细节的表示，我们提出了一种独特的修剪和加密方法，称为候选池策略，通过选择性优化提高细节保真度。（2） 粗至细发电管道。为了简化GaussianVolume的生成，并使模型能够生成具有详细三维几何结构的实例，我们提出了一种从粗到细的管道。它首先构建一个基本的几何结构，然后预测完整的高斯属性。与现有的3D生成方法相比，我们的框架GVGEN在定性和定量评估方面表现出卓越的性能。同时，它保持了快速的生成速度（ $\sim$ 7秒），有效地在质量和效率之间取得了平衡。 et.al.|[2403.12957](http://arxiv.org/abs/2403.12957)|null|
|**2024-03-19**|**PostoMETRO: Pose Token Enhanced Mesh Transformer for Robust 3D Human Mesh Recovery**|随着基于单图像的人体网格恢复的最新进展，人们对增强其在某些极端场景（如遮挡）中的性能越来越感兴趣，同时保持整体模型的准确性。尽管在遮挡条件下获得精确注释的3D人体姿势具有挑战性，但仍有大量丰富而精确的2D姿势注释可供利用。然而，现有的工作大多集中在直接利用二维姿态坐标来估计三维姿态和网格。在本文中，我们提出了PostoMETRO（ $\textbf｛Pos｝$e$\textbf｛to｝$ken-edvanced$\textbf｛ME｝$sh$\textbf｛TR｝$ansf$\textbf｛O｝$ rmer），它以令牌方式将遮挡弹性2D姿势表示集成到转换器中。利用专门的姿势标记器，我们有效地将2D姿势数据压缩为姿势标记的紧凑序列，并将它们与图像标记一起馈送到变换器。这一过程不仅确保了对图像纹理的丰富描述，而且促进了姿势和图像信息的强大集成。随后，通过顶点和关节令牌来查询这些组合令牌，以解码网格顶点和人体关节的3D坐标。在强大的姿势标记表示和有效组合的帮助下，即使在遮挡等极端情况下，我们也能够生成更精确的三维坐标。在标准和遮挡特定基准上的实验都证明了PostoMETRO的有效性。定性结果进一步说明了2D姿态如何帮助3D重建的清晰度。将提供代码。 et.al.|[2403.12473](http://arxiv.org/abs/2403.12473)|null|
|**2024-03-19**|**Self-learning Canonical Space for Multi-view 3D Human Pose Estimation**|多视角三维人体姿态估计自然优于单视角，得益于多视角图像提供的更全面的信息。该信息包括相机姿势、2D/3D人体姿势和3D几何体。然而，这些信息的准确注释很难获得，这使得从多视图图像中预测准确的3D人体姿势具有挑战性。为了解决这个问题，我们提出了一个完全自监督的框架，称为级联多视图聚合网络（CMANet），以构建规范的参数空间来全面集成和利用多视图信息。在我们的框架中，多视图信息被分为两类：1）视图内信息，2）视图间信息。因此，CMANet由两个组件组成：视图内模块（IRV）和视图间模块（IEV）。IRV用于提取每个视图的初始相机姿态和3D人体姿态；IEV是为了融合互补的姿态信息和交叉视图三维几何结构，以获得最终的三维人体姿态。为了便于视图内和视图间的聚合，我们定义了一个规范的参数空间，由SMPL模型的每个视图的相机姿势和人体姿势和形状参数（ $\theta$和$\beta$ ）来描述，并提出了一个两阶段的学习过程。在第一阶段，IRV学习估计相机姿态和由现成的2D关键点检测器的可靠输出监督的视图相关的3D人体姿态。在第二阶段，IRV被冻结，IEV通过隐式编码交叉视图互补和3D几何约束来进一步细化相机姿态并优化3D人体姿态，这是通过联合拟合预测的多视图2D关键点来实现的。综合实验证明，所提出的框架、模块和学习策略是有效的，并且CMANet在广泛的定量和定性分析中优于最先进的方法。 et.al.|[2403.12440](http://arxiv.org/abs/2403.12440)|null|
|**2024-03-18**|**LN3Diff: Scalable Latent Neural Fields Diffusion for Speedy 3D Generation**|随着生成模型和可微分绘制技术的进步，神经绘制领域取得了重大进展。尽管2D扩散已经取得了成功，但统一的3D扩散管道仍然悬而未决。本文介绍了一种称为LN3Diff的新框架来解决这一差距，并实现快速、高质量和通用的条件3D生成。我们的方法利用3D感知架构和变分自动编码器（VAE）将输入图像编码到结构化、紧凑和3D潜在空间中。潜像由基于变换器的解码器解码为高容量的3D神经场。通过在这个3D感知的潜在空间上训练扩散模型，我们的方法在ShapeNet上实现了最先进的3D生成性能，并在各种数据集的单目3D重建和条件3D生成中表现出卓越的性能。此外，它在推理速度方面超过了现有的3D扩散方法，不需要每实例优化。我们提出的LN3Diff在三维生成建模方面取得了重大进展，并有望在三维视觉和图形任务中应用。 et.al.|[2403.12019](http://arxiv.org/abs/2403.12019)|null|
|**2024-03-18**|**GeoWizard: Unleashing the Diffusion Priors for 3D Geometry Estimation from a Single Image**|我们介绍了GeoWizard，这是一种新的生成基础模型，用于从单个图像中估计几何属性，例如深度和法线。虽然已经在这一领域进行了大量研究，但由于公开数据集的多样性低和质量差，进展受到很大限制。因此，先前的作品要么局限于有限的场景，要么无法捕捉几何细节。在本文中，我们证明了生成模型与传统的判别模型（如细胞神经网络和变压器）相比，可以有效地解决固有的不适定问题。我们进一步证明，利用扩散先验可以显著提高泛化、细节保存和资源使用效率。具体来说，我们扩展了原始的稳定扩散模型，以联合预测深度和法线，从而允许两种表示之间的相互信息交换和高度一致性。更重要的是，我们提出了一种简单而有效的策略，将各种场景的复杂数据分布分离为不同的子分布。这种策略使我们的模型能够识别不同的场景布局，以非凡的保真度捕捉3D几何图形。GeoWizard为零样本深度和法线预测设置了新的基准，显著增强了许多下游应用，如3D重建、2D内容创建和新颖的视点合成。 et.al.|[2403.12013](http://arxiv.org/abs/2403.12013)|null|

<p align=right>(<a href=#updated-on-20240323>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-03-21**|**Simplified Diffusion Schrödinger Bridge**|本文介绍了扩散Schr“odinger桥（DSB）的一种新的理论简化，它有助于将其与基于分数的生成模型（SGM）相统一，解决了DSB在复杂数据生成中的局限性，并实现了更快的收敛和增强的性能。通过将SGM作为DSB的初始解决方案，我们的方法利用了这两个框架的优势，确保了更有效的训练过程，并提高了SGM的性能。我们还提出了一种重新参数化技术，尽管理论上近似，但它实际上提高了网络的拟合能力。我们广泛的实验评估证实了简化的DSB的有效性，证明了它的显著改进。我们相信这项工作的贡献为高级生成建模铺平了道路。代码可在获得https://github.com/tzco/Simplified-Diffusion-Schrodinger-Bridge. et.al.|[2403.14623](http://arxiv.org/abs/2403.14623)|**[link](https://github.com/tzco/simplified-diffusion-schrodinger-bridge)**|
|**2024-03-21**|**GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation**|我们介绍了GRM，这是一种能够在大约0.1s内从稀疏视图图像中恢复3D资产的大规模重建器。GRM是一种基于前馈变换器的模型，它有效地结合了多视图信息，以将输入像素转换为像素对齐的高斯，这些高斯不被投影以创建一组代表场景的密集分布的3D高斯。我们的变压器架构和3D高斯的使用共同开启了一个可扩展且高效的重建框架。大量的实验结果表明，在重建质量和效率方面，我们的方法优于其他方法。我们还通过将GRM与现有的多视图扩散模型相集成，展示了它在生成任务（即文本到3D和图像到3D）中的潜力。我们的项目网站位于：https://justimyhxu.github.io/projects/grm/. et.al.|[2403.14621](http://arxiv.org/abs/2403.14621)|**[link](https://github.com/justimyhxu/grm)**|
|**2024-03-21**|**Videoshop: Localized Semantic Video Editing with Noise-Extrapolated Diffusion Inversion**|我们介绍Videoshop，一种用于本地化语义编辑的无训练视频编辑算法。Videoshop允许用户使用任何编辑软件，包括Photoshop和生成修复，来修改第一帧；它通过语义、空间和时间上一致的运动，自动将这些变化传播到剩余的帧。与仅通过不精确的文本指令进行编辑的现有方法不同，Videoshop允许用户添加或删除对象、语义上更改对象、将库存照片插入视频等，并对位置和外观进行细粒度控制。我们通过基于图像的视频编辑来实现这一点，通过使用噪声外推法反转延迟，从中我们生成以编辑后的图像为条件的视频。Videoshop使用10个评估指标，在2个编辑基准上的6个基线上进行更高质量的编辑。 et.al.|[2403.14617](http://arxiv.org/abs/2403.14617)|null|
|**2024-03-21**|**DreamReward: Text-to-3D Generation with Human Preference**|通过文本提示创建3D内容最近取得了显著的成功。然而，当前的文本到3D的方法通常会生成与人类偏好不太一致的3D结果。在本文中，我们提出了一个综合框架，称为DreamReward，用于从人类偏好反馈中学习和改进文本到三维模型。首先，我们根据包括评级和排名在内的系统注释管道收集了25000个专家比较。然后，我们构建了Reward3D——第一个通用的文本到3D的人类偏好奖励模型，以有效地编码人类偏好。在3D奖励模型的基础上，我们最终进行了理论分析，并提出了Reward3D反馈学习（DreamFL），这是一种直接调整算法，可以通过重新定义的记分器来优化多视图扩散模型。基于理论证明和广泛的实验比较，我们的DreamReward成功地生成了高保真度和3D一致的结果，显著提高了与人类意图的一致性。我们的研究结果证明了从人类反馈中学习以改进文本到三维模型的巨大潜力。 et.al.|[2403.14613](http://arxiv.org/abs/2403.14613)|null|
|**2024-03-21**|**ReNoise: Real Image Inversion Through Iterative Noising**|文本引导扩散模型的最新进展释放了强大的图像处理能力。然而，将这些方法应用于真实图像需要将图像反演到预训练的扩散模型的域中。实现忠实的反演仍然是一个挑战，特别是对于最近训练来生成具有少量去噪步骤的图像的模型来说。在这项工作中，我们介绍了一种具有高质量与运算比的反演方法，在不增加运算次数的情况下提高了重建精度。在反转扩散采样过程的基础上，我们的方法在每个反转采样步骤都采用了迭代重化机制。该机制通过迭代应用预训练的扩散模型并对这些预测进行平均，来细化沿前向扩散轨迹的预测点的近似值。我们使用各种采样算法和模型来评估ReNoise技术的性能，包括最近的加速扩散模型。通过综合评估和比较，我们展示了它在准确性和速度方面的有效性。此外，我们通过在真实图像上演示文本驱动的图像编辑，证实了我们的方法保持了可编辑性。 et.al.|[2403.14602](http://arxiv.org/abs/2403.14602)|null|
|**2024-03-21**|**Click to Grasp: Zero-Shot Precise Manipulation via Visual Diffusion Descriptors**|可在场景和对象中推广的精确操作仍然是机器人技术中的一个持续挑战。目前这项任务的方法在很大程度上取决于是否有大量的训练实例来处理具有明显视觉和/或几何部分模糊性的对象。我们的工作探索了细粒度零件描述符的基础，通过利用基于网络训练的文本到图像扩散的生成模型，在零样本环境中进行精确操作。我们通过将其定义为一个密集的语义部分对应任务来解决这个问题。我们的模型返回用于操纵特定零件的抓取器姿势，使用来自同一对象的视觉不同实例的源图像的用户定义的点击作为参考。我们不需要手动抓取演示，因为我们利用了固有的对象几何结构和特征。在真实世界的桌面场景中进行的实际实验验证了我们方法的有效性，证明了其在推进语义感知机器人操作方面的潜力。网页https://tsagkas.github.io/click2grasp et.al.|[2403.14526](http://arxiv.org/abs/2403.14526)|null|
|**2024-03-21**|**Denoising Diffusion Models for 3D Healthy Brain Tissue Inpainting**|监测影响大脑结构完整性的疾病需要对磁共振（MR）图像进行自动分析，例如用于评估体积变化。然而，许多评估工具是为分析健康组织而优化的。因此，为了能够评估包含病理组织的扫描，需要恢复病理区域中的健康组织。在这项工作中，我们探索并扩展了去噪扩散模型，用于健康3D脑组织的一致修复。我们修改了在图像空间中工作的最先进的2D、伪3D和3D方法，以及3D潜在和3D小波扩散模型，并训练它们合成健康的脑组织。我们的评估表明，伪3D模型在结构相似性指数、峰值信噪比和均方误差方面表现最好。为了强调临床相关性，我们在包含合成MS病变的数据上微调该模型，并在下游脑组织分割任务中对其进行评估，从而使其优于已建立的FMRIB软件库（FSL）病变填充方法。 et.al.|[2403.14499](http://arxiv.org/abs/2403.14499)|**[link](https://github.com/aliciadurrer/dm_inpainting)**|
|**2024-03-21**|**Periodicity from X-ray sources within the inner Galactic disk**|多年来，人们一直声称银河中心（GC）的银河脊X射线发射在自然界中是真正的漫射。然而，随着现代X射线卫星的发展，人们发现大多数漫发射实际上是由数千个以前未解决的X射线点源组成的。此外，许多研究表明，这些X射线点源中的绝大多数是磁激变变量（mCV）和活动双星。识别这些mCV和其他来源的一种明确方法是检测它们的X射线周期性。因此，我们系统地在星系盘内部寻找周期性的X射线源，包括GC区域。我们使用了正在进行的XMM牛顿遗产内部星系盘调查的数据（ $350^｛\circ｝\lesssim l\lesssim+7^｛\circ｝$和$-1^｛\ circ｝\lesssimb\lesssim+1^｛\scirc｝$）加上GC的XMM Newton档案观测。我们计算了用于周期性搜索的光曲线的Lom-Scargle周期图。我们使用简单的幂律模型加上铁$K$发射复合体在6.4、6.7和6.9 keV下的三个高斯，拟合了源的能谱。我们在26个来源中检测到了周期性。对于其中的14个，这是第一次发现周期性。对于其他12个来源，我们发现了与已知周期相似的周期，表明没有显著的周期演变。我们还搜索了周期源的盖亚对应物，以使用盖亚视差来估计它们的距离。我们从七个来源找到了盖亚的可能对应物。我们根据Fe$K$ 线发射的周期性、硬度比和等效宽度将源分为四类。在我们首次探测到周期性的14个源中，4个可能是中间极，5个可能是极，2个是中子星X射线双星，3个性质未知。 et.al.|[2403.14480](http://arxiv.org/abs/2403.14480)|null|
|**2024-03-21**|**Analysing Diffusion Segmentation for Medical Images**|去噪扩散概率模型由于其提供概率建模和生成不同输出的能力而变得越来越受欢迎。这种多功能性激发了他们对图像分割的适应，在图像分割中，模型的多个预测可以产生分割结果，不仅可以实现高质量，还可以捕捉模型中固有的不确定性。在这里，提出了用于提高扩散分割性能的强大架构。然而，明显缺乏对扩散分割和图像生成之间的差异的分析和讨论，并且缺乏将这些架构为一般分割提供的改进与特别是对扩散分割的益处区分开来的全面评估。在这项工作中，我们批判性地分析和讨论了医学图像的扩散分割与扩散图像生成的区别，特别关注训练行为。此外，我们对所提出的扩散分割架构在直接训练用于分割时的表现进行了评估。最后，我们探讨了不同的医学分割任务如何影响扩散分割行为，并可以相应地调整扩散过程。通过这些分析，我们旨在深入了解扩散分割的行为，以便在未来更好地设计和评估扩散分割方法。 et.al.|[2403.14440](http://arxiv.org/abs/2403.14440)|null|
|**2024-03-21**|**Style-Extracting Diffusion Models for Semi-Supervised Histopathology Segmentation**|基于深度学习的图像生成在扩散模型方面取得了重大进展，显著提高了生成图像的质量。尽管有这些发展，但生成具有对下游任务有益的看不见特征的图像受到的关注有限。为了弥补这一差距，我们提出了具有两种条件机制的风格提取扩散模型。具体而言，我们利用1）风格调节机制，该机制允许在图像生成期间注入先前未见过的图像的风格信息，以及2）内容调节机制，其可以针对下游任务，例如，用于分割的布局。我们介绍了一种可训练的风格编码器，用于从图像中提取风格信息，以及一个聚合块，用于合并来自多个风格输入的风格信息。该架构通过利用未看到图像的样式，以零样本的方式生成具有未看到样式的图像，从而产生更多样化的生成。在这项工作中，我们使用图像布局作为目标条件，并首先在自然图像数据集上展示了我们的方法作为概念证明的能力。我们进一步证明了它在组织病理学中的多功能性，我们将组织成分的先验知识和未标记的数据相结合，创建具有已知布局的各种合成图像。这允许我们生成额外的合成数据，以半监督的方式训练分割网络。当在分割训练期间包括合成图像时，我们通过显示改进的分割结果和较低的患者之间的性能可变性来验证生成图像的附加值。我们的代码将在[LINK]上公开。 et.al.|[2403.14429](http://arxiv.org/abs/2403.14429)|null|

<p align=right>(<a href=#updated-on-20240323>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-03-20**|**Visual Imitation Learning of Task-Oriented Object Grasping and Rearrangement**|面向任务的物体抓取和重排是机器人完成不同现实操作任务的关键技能。然而，由于对物体的部分观察和分类物体的形状变化，它们仍然具有挑战性。在本文中，我们提出了多特征隐式模型（MIMO），这是一种新的对象表示，它在隐式神经场中对点和对象之间的多个空间特征进行编码。在多个特征上训练这样的模型可以确保它在不同方面一致地嵌入物体形状，从而提高其在从局部观察、形状相似性测量和建模物体之间的空间关系的物体形状重建中的性能。基于MIMO，我们提出了一个从单个或多个人类演示视频中学习面向任务的对象抓取和重排的框架。仿真评估表明，我们的方法在多视图和单视图观测方面优于最先进的方法。真实世界的实验证明了我们的方法在操纵任务的单次和少次模仿学习中的有效性。 et.al.|[2403.14000](http://arxiv.org/abs/2403.14000)|null|
|**2024-03-18**|**LN3Diff: Scalable Latent Neural Fields Diffusion for Speedy 3D Generation**|随着生成模型和可微分绘制技术的进步，神经绘制领域取得了重大进展。尽管2D扩散已经取得了成功，但统一的3D扩散管道仍然悬而未决。本文介绍了一种称为LN3Diff的新框架来解决这一差距，并实现快速、高质量和通用的条件3D生成。我们的方法利用3D感知架构和变分自动编码器（VAE）将输入图像编码到结构化、紧凑和3D潜在空间中。潜像由基于变换器的解码器解码为高容量的3D神经场。通过在这个3D感知的潜在空间上训练扩散模型，我们的方法在ShapeNet上实现了最先进的3D生成性能，并在各种数据集的单目3D重建和条件3D生成中表现出卓越的性能。此外，它在推理速度方面超过了现有的3D扩散方法，不需要每实例优化。我们提出的LN3Diff在三维生成建模方面取得了重大进展，并有望在三维视觉和图形任务中应用。 et.al.|[2403.12019](http://arxiv.org/abs/2403.12019)|null|
|**2024-03-15**|**NeuralOCT: Airway OCT Analysis via Neural Fields**|光学相干断层扫描（OCT）是眼科中一种流行的模式，也用于血管内。我们对这项工作的兴趣是在婴儿和儿童气道异常的背景下进行OCT，其中OCT的高分辨率和无辐射的事实很重要。气道OCT的目标是提供气道几何形状的准确估计（2D和3D），以评估气道异常，如声门下狭窄。我们提出 $\texttt｛NeuralOCT｝$，这是一种基于学习的方法来处理气道OCT图像。具体而言，$\texttt｛NeuralOCT｝$通过稳健地桥接两个步骤从OCT扫描中提取3D几何形状：通过2D分割提取点云和通过神经场从点云中重建3D。我们的实验表明，$\texttt｛NeuralOCT｝$ 可以产生准确而稳健的3D气道重建，平均A线误差小于70微米。我们的代码将在GitHub上提供。 et.al.|[2403.10622](http://arxiv.org/abs/2403.10622)|null|
|**2024-03-15**|**NECA: Neural Customizable Human Avatar**|人类化身已经成为一种具有各种应用的新型3D资产。理想情况下，人类化身应该是完全可定制的，以适应不同的设置和环境。在这项工作中，我们介绍了NECA，这是一种能够从单目或稀疏视图视频中学习多功能人体表示的方法，能够在姿势、阴影、形状、照明和纹理等方面进行细粒度定制。我们方法的核心是在互补的双空间中表示人类，并预测几何、反照率、阴影以及外部照明的解开神经场，从中我们能够通过体积渲染获得具有高频细节的真实感渲染。大量实验证明了我们的方法在真实感渲染以及各种编辑任务（如新颖的姿势合成和重新照明）方面优于最先进的方法。代码位于https://github.com/iSEE-Laboratory/NECA. et.al.|[2403.10335](http://arxiv.org/abs/2403.10335)|**[link](https://github.com/isee-laboratory/neca)**|
|**2024-03-13**|**Representing Anatomical Trees by Denoising Diffusion of Implicit Neural Fields**|解剖树在临床诊断和治疗计划中起着核心作用。然而，由于解剖树的拓扑结构和几何形状多变且复杂，因此准确地表示解剖树具有挑战性。使用医学成像捕获的表示树状结构的传统方法虽然对可视化血管和支气管网络非常宝贵，但在分辨率、灵活性和效率方面存在缺陷。最近，隐式神经表示（INRs）已经成为准确有效地表示形状的强大工具。我们提出了一种使用INR表示解剖树的新方法，同时还通过INR空间中的去噪扩散来捕捉一组树的分布。我们以任何所需的分辨率准确捕捉解剖树的复杂几何形状和拓扑结构。通过广泛的定性和定量评估，我们展示了高保真度树重建，具有任意分辨率但紧凑的存储，以及跨解剖部位和树复杂性的多功能性。 et.al.|[2403.08974](http://arxiv.org/abs/2403.08974)|**[link](https://github.com/sinashish/treediffusion)**|
|**2024-03-12**|**Scalable Spatiotemporal Prediction with Bayesian Neural Fields**|时空数据集由空间参考的时间序列组成，在许多科学和商业智能应用中无处不在，如空气污染监测、疾病跟踪和云需求预测。随着现代数据集的规模和复杂性不断增加，人们越来越需要新的统计方法，这些方法足够灵活，可以捕捉复杂的时空动态，并且可以扩展，可以处理大型预测问题。这项工作提出了贝叶斯神经场（BayesNF），这是一种用于推断时空域上丰富概率分布的域通用统计模型，可用于数据分析任务，包括预测、插值和变差法。BayesNF将一种用于高容量函数估计的新型深度神经网络架构与用于鲁棒不确定性量化的分层贝叶斯推理相结合。通过通过一系列平滑可微变换定义先验，使用通过随机梯度下降训练的变量学习代理对大规模数据进行后验推理。我们根据突出的统计和机器学习基线评估BayesNF，显示出在气候和公共卫生数据集的各种预测问题上的显著改进，这些数据集包含数万到数十万个测量值。该论文附有一个开源软件包(https://github.com/google/bayesnf)它易于使用，并与JAX机器学习平台上的现代GPU和TPU加速器兼容。 et.al.|[2403.07657](http://arxiv.org/abs/2403.07657)|**[link](https://github.com/google/bayesnf)**|
|**2024-03-11**|**SiLVR: Scalable Lidar-Visual Reconstruction with Neural Radiance Fields for Robotic Inspection**|我们提出了一种基于神经场的大规模重建系统，该系统融合激光雷达和视觉数据，生成几何精度高的高质量重建，并捕捉照片逼真的纹理。该系统采用了最先进的神经辐射场（NeRF）表示，还结合了激光雷达数据，这对深度和表面法线增加了强大的几何约束。我们利用实时激光雷达SLAM系统的轨迹来引导运动结构（SfM）过程，以显著减少计算时间，并提供对激光雷达深度损失至关重要的度量尺度。我们使用子映射将系统缩放到长轨迹上捕获的大规模环境。我们用多摄像头、激光雷达传感器套件的数据演示了重建系统，该套件安装在腿式机器人上，手持扫描600米的建筑场景，并安装在空中机器人上，测量多层模拟灾难现场建筑。网站https://ori-drs.github.io/projects/silvr/ et.al.|[2403.06877](http://arxiv.org/abs/2403.06877)|null|
|**2024-03-15**|**CoNFiLD: Conditional Neural Field Latent Diffusion Model Generating Spatiotemporal Turbulence**|本研究介绍了条件神经场潜在扩散（CoNFiLD）模型，这是一种新的生成学习框架，旨在快速模拟三维不规则域内混沌和湍流系统中复杂的时空动力学。传统的涡解析数值模拟，尽管提供了详细的流量预测，但由于其广泛的计算需求，遇到了很大的局限性，限制了其在更广泛的工程环境中的应用。相比之下，基于深度学习的代理模型有望提供高效、数据驱动的解决方案。然而，它们的有效性往往因依赖确定性框架而受到损害，而确定性框架在准确捕捉湍流的混沌和随机性质方面存在不足。CoNFiLD模型通过将条件神经场编码与潜在扩散过程协同集成来解决这些挑战，从而能够在不同条件下高效且稳健地生成时空湍流。利用贝叶斯条件采样，该模型可以无缝适应各种湍流生成场景，而无需再训练，涵盖从使用稀疏传感器测量的零样本全场流重建到超分辨率生成和时空流数据恢复的应用。已经对各种具有不规则几何形状的非均匀、各向异性湍流进行了全面的数值实验，以评估该模型的多功能性和有效性，展示了其在湍流生成和更广泛的时空动力学建模领域的变革潜力。 et.al.|[2403.05940](http://arxiv.org/abs/2403.05940)|null|
|**2024-03-09**|**Learned 3D volumetric recovery of clouds and its uncertainty for climate analysis**|气候预测和云物理的重大不确定性与浅层散射云的观测差距有关。应对这些挑战需要对其三维（3D）异质体积散射内容进行遥感。这就需要无源散射计算机断层扫描（CT）。我们设计了一个基于学习的模型（ProbeCT）来实现这种云的CT，基于有噪声的多视图星载图像。ProbeCT首次推断出每个3D位置的异质消光系数的后验概率分布。这产生了任意有价值的统计数据，例如，最可能灭绝的3D场及其不确定性。ProbeCT使用神经场表示，进行本质上实时的推理。ProbeCT通过一个新的基于物理的云体积场及其相应图像的标记多类数据库进行监督训练。为了改进分布外推理，我们通过差分渲染引入了自监督学习。我们在模拟和真实世界的数据中演示了该方法，并指出了3D恢复和不确定性与降水和可再生能源的相关性。 et.al.|[2403.05932](http://arxiv.org/abs/2403.05932)|null|
|**2024-03-06**|**ProxNF: Neural Field Proximal Training for High-Resolution 4D Dynamic Image Reconstruction**|精确的时空图像重建方法被广泛的生物医学研究领域所需要，但由于数据的不完整性和计算负担而面临挑战。数据不完整性源于增加帧速率和减少采集时间所需的欠采样，而计算负担则源于具有三维空间和扩展时间范围的高分辨率图像的内存占用。神经场是一类新兴的神经网络，充当时空对象的连续表示，以前已经引入它来通过将图像重建重新定义为估计网络参数的问题来解决这些动态成像问题。神经场可以通过利用这些时空对象中潜在的冗余来解决数据不完整和计算负担这两个挑战。这项工作提出了ProxNF，这是一种用于时空图像重建的新的神经场训练方法，利用近端分裂方法将涉及成像算子的计算与网络参数的更新分开。具体而言，ProxNF评估图像域中数据保真度项的（子采样）梯度，并使用完全监督学习方法来更新神经场参数。通过减少内存占用和评估成像算子的计算成本，所提出的ProxNF方法允许重建大的、高分辨率的时空图像。该方法在两项数值研究中得到了证明，这两项研究涉及解剖逼真的动态数值小鼠模型和肿瘤灌注的两室模型的虚拟动态对比增强光声计算机断层扫描成像。 et.al.|[2403.03860](http://arxiv.org/abs/2403.03860)|null|

<p align=right>(<a href=#updated-on-20240323>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

