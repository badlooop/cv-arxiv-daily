[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.11.08
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-11-07**|**UP-NeRF: Unconstrained Pose-Prior-Free Neural Radiance Fields**|神经辐射场（NeRF）实现了具有高保真度的给定图像和相机姿态的新颖视图合成。随后的工作甚至通过联合优化NeRF和相机姿态，成功地消除了姿态先验的必要性。然而，这些作品仅限于相对简单的设置，例如光度一致和无遮挡的图像集合或视频中的图像序列。因此，他们很难处理具有不同照明和瞬态遮挡的无约束图像。在本文中，我们提出\textbf{UP-NeRF}（\textbf{U}nconstrained\textbf{P}ose-prior-free\textbf{Ne}ural\textbf{R}adiance\textbf{F}ields)以在没有相机姿态先验的情况下利用无约束图像集合来优化NeRF。我们通过优化颜色不敏感特征场的代理任务和用于瞬态遮挡器的单独模块来解决这些挑战，以阻止它们对姿态估计的影响。此外，我们引入了一个候选头部，以实现更稳健的姿态估计和瞬态感知深度监督，从而最大限度地减少不正确先验的影响。在一个具有挑战性的互联网照片集\textit｛Phototourism｝数据集中，与包括BARF及其变体在内的基线相比，我们的实验验证了我们的方法的优越性能。UP NeRF的代码位于\url{https://github.com/mlvlab/UP-NeRF}。 et.al.|[2311.03784](http://arxiv.org/abs/2311.03784)|null|
|**2023-11-05**|**MuSHRoom: Multi-Sensor Hybrid Room Dataset for Joint 3D Reconstruction and Novel View Synthesis**|元宇宙技术要求在消费级硬件上对非人类感知（如无人机/机器人/自动汽车导航）和AR/VR等沉浸式技术进行准确、实时和沉浸式建模，同时要求结构准确性和逼真度。然而，在如何在统一的框架中应用几何重建和真实感建模（新颖的视图合成）方面存在知识差距。为了解决这一差距，并促进消费级设备的稳健和沉浸式建模和渲染的发展，首先，我们提出了一个真实世界的多传感器混合房间数据集（MuSHRoom）。我们的数据集提出了令人兴奋的挑战，需要最先进的方法具有成本效益，对噪声数据和设备具有鲁棒性，并且可以联合学习3D重建和新颖的视图合成，而不是将它们视为单独的任务，使其成为现实世界应用的理想选择。其次，我们在数据集上对几个著名的管道进行了基准测试，用于联合三维网格重建和新颖的视图合成。最后，为了进一步提高整体性能，我们提出了一种新的方法，在两个任务之间实现了良好的权衡。我们的数据集和基准测试在促进以稳健且计算高效的端到端方式融合3D重建和高质量渲染的改进方面显示出巨大潜力。 et.al.|[2311.02778](http://arxiv.org/abs/2311.02778)|null|
|**2023-11-05**|**3D-Aware Talking-Head Video Motion Transfer**|会说话的头部视频的运动转移涉及生成具有主题视频的外观和驾驶视频的运动模式的新视频。当前的方法主要依赖于有限数量的主题图像和2D表示，从而忽略了充分利用主题视频中固有的多视图外观特征。在本文中，我们提出了一种新的3D感知会说话的头部视频运动传输网络Head3D，该网络通过递归网络从2D主题帧生成可视觉解释的3D规范头部，充分利用了主题外观信息。我们方法的一个关键组成部分是一个自监督的3D头部几何学习模块，旨在从2D主题视频帧中预测头部姿势和深度图。该模块便于在规范空间中估计3D头部，然后可以对其进行变换以与驱动视频帧对准。此外，我们使用基于注意力的融合网络将主题帧的背景和其他细节与3D主题头部相结合，以产生合成目标视频。我们在两个公开演讲的头部视频数据集上进行的大量实验表明，Head3D在实际的交叉身份设置中优于2D和3D现有技术，有证据表明它可以很容易地适应姿势可控的新型视图合成任务。 et.al.|[2311.02549](http://arxiv.org/abs/2311.02549)|null|
|**2023-11-03**|**A Neural Radiance Field-Based Architecture for Intelligent Multilayered View Synthesis**|移动自组织网络由多个无线便携式节点组成，这些节点在途中自发地聚集在一起以建立不需要任何中央管理的临时网络。移动自组织网络（MANET）由一个相当大且密度合理的移动节点社区组成，这些节点跨越任何地形，仅依靠无线接口进行通信，而不是集中管理之前的任何井。此外，路由应该提供一种在任何两个节点之间通过网络即时传递数据的方法。然而，从整个基础设施中找到最佳的数据包路由是主要问题。所提出的协议的主要目标是确定成本最低的标称容量获取，以确保实际传输的传输，并确保其在任何节点故障的情况下的耐用性。这项研究提出了通过红色进口火蚁（RIFA）策略优化路线选择，作为改进按需源路由系统的一种方法。预测路由故障和能量利用率用于在路由阶段选择路径。拟议的工作基于性能参数评估比较结果，如能源使用、数据包传输速率（PDR）和端到端（E2E）延迟。结果表明，在大多数网络性能指标和因素下，所提出的策略是优选的，并增加了网络寿命，同时降低了节点能耗和典型的E2E延迟。 et.al.|[2311.01842](http://arxiv.org/abs/2311.01842)|null|
|**2023-11-03**|**PDF: Point Diffusion Implicit Function for Large-scale Scene Neural Representation**|隐式神经表示的最新进展通过在采样空间中沿着采样射线对单个点进行采样和融合，取得了令人印象深刻的结果。然而，由于采样空间的爆炸性增长，精细地表示和合成细节纹理对于无边界的大型户外场景来说仍然是一个挑战。为了缓解使用单个点感知整个庞大空间的困境，我们探索学习场景的表面分布以提供结构先验并减少可采样空间，并提出了一种用于大规模场景神经表示的点扩散隐函数PDF。我们方法的核心是一个大规模的点云超分辨率扩散模块，该模块将从几个训练图像重建的稀疏点云增强为密集点云作为显式先验。然后在渲染阶段，只保留采样半径内先前点的采样点。也就是说，采样空间从无界空间减少到场景曲面。同时，为了填充点云无法提供的场景背景，采用了基于Mip-NeRF 360的区域采样来对背景表示进行建模。昂贵的实验已经证明了我们的方法在大规模场景新视图合成中的有效性，它优于相关的最先进的基线。 et.al.|[2311.01773](http://arxiv.org/abs/2311.01773)|null|
|**2023-11-02**|**Novel View Synthesis from a Single RGBD Image for Indoor Scenes**|在本文中，我们提出了一种从单个RGBD（红-绿-蓝深度）输入合成新视图图像的方法。新颖视图合成（NVS）是一项有趣的计算机视觉任务，具有广泛的应用。使用多个图像的方法已经得到了很好的研究，示例性方法包括训练特定场景的神经辐射场（NeRF），或利用多视图立体（MVS）和3D渲染管道。然而，两者都是计算密集型的，或者在不同的场景中不可推广，限制了它们的实用价值。相反，嵌入RGBD图像中的深度信息从单一视角解锁了3D潜力，简化了NVS。紧凑、价格合理的立体相机，甚至智能手机等现代设备中的激光雷达的广泛可用性，使捕捉RGBD图像比以往任何时候都更容易。在我们的方法中，我们将RGBD图像转换为点云，并从不同的角度对其进行渲染，然后将NVS任务公式化为图像翻译问题。我们利用生成对抗性网络对渲染图像进行风格转换，获得了类似于从新视角拍摄的照片的结果。我们探索了使用CycleGAN的无监督学习和使用Pix2Pix的监督学习，并展示了定性结果。我们的方法避开了传统多图像技术的局限性，在NVS中的实际实时应用中具有重要的前景。 et.al.|[2311.01065](http://arxiv.org/abs/2311.01065)|null|
|**2023-11-01**|**Neural Implicit Field Editing Considering Object-environment Interaction**|基于神经隐场的三维场景编辑方法得到了广泛的关注。它在三维编辑任务中取得了优异的效果。然而，现有的方法通常将对象和场景环境之间的交互融合在一起。场景外观（如阴影）的更改无法在渲染视图中显示。在本文中，我们提出了一种对象和场景环境交互感知（OSI感知）系统，这是一种考虑对象和场景-环境交互的新型双流神经渲染系统。为了从混合汤中获得照明条件，该系统采用内分解方法成功地分离了物体与场景环境之间的相互作用。为了研究对象级编辑任务对场景外观的相应变化，我们引入了一种深度图引导的场景修复方法和点匹配策略的阴影渲染方法。大量实验表明，我们的新型流水线在场景编辑任务中产生了合理的外观变化。在新的视图合成任务中，它还实现了具有竞争力的渲染质量。 et.al.|[2311.00425](http://arxiv.org/abs/2311.00425)|null|
|**2023-10-31**|**An Implementation of Multimodal Fusion System for Intelligent Digital Human Generation**|随着人工智能（AI）的快速发展，数字人越来越受到关注，并有望在多个行业实现广泛应用。那么，现有的大多数数字人仍然依赖于设计师的手动建模，这是一个繁琐的过程，而且开发周期很长。因此，面对数字人的崛起，迫切需要一个与人工智能相结合的数字人生成系统来提高开发效率。本文提出了一种多模态融合的智能数字人生成系统的实现方案。具体地，将文本、语音和图像作为输入，并使用大语言模型（LLM）、声纹提取和文本到语音转换技术来合成交互式语音。然后对输入图像进行年龄变换，并选择合适的图像作为驾驶图像。然后，通过数字人驱动、新颖的视图合成和智能着装技术，实现了数字人视频内容的修改和生成。最后，我们通过风格转换、超分辨率和质量评估来增强用户体验。实验结果表明，该系统能够有效地实现数字人的生成。相关代码发布于https://github.com/zyj-2000/CUMT_2D_PhotoSpeaker. et.al.|[2310.20251](http://arxiv.org/abs/2310.20251)|**[link](https://github.com/zyj-2000/cumt_2d_photospeaker)**|
|**2023-10-30**|**CustomNet: Zero-shot Object Customization with Variable-Viewpoints in Text-to-Image Diffusion Models**|将定制对象合并到图像生成中是文本到图像生成的一个有吸引力的特征。然而，现有的基于优化和基于编码器的方法受到诸如耗时优化、身份保存不足和普遍的复制粘贴效应等缺点的阻碍。为了克服这些限制，我们引入了CustomNet，这是一种新的对象定制方法，它将3D新视图合成功能明确地结合到对象定制过程中。这种集成有助于调整空间位置关系和视点，产生不同的输出，同时有效地保持对象身份。此外，我们引入了精细的设计，通过文本描述或特定的用户定义图像实现位置控制和灵活的背景控制，克服了现有3D新颖视图合成方法的局限性。我们进一步利用数据集构建管道，可以更好地处理真实世界的对象和复杂的背景。有了这些设计，我们的方法方便了零样本对象的定制，而无需测试时间优化，可以同时控制视点、位置和背景。因此，我们的CustomNet确保增强身份保护，并产生多样化、和谐的输出。 et.al.|[2310.19784](http://arxiv.org/abs/2310.19784)|null|
|**2023-10-31**|**DynPoint: Dynamic Neural Point For View Synthesis**|神经辐射场的引入极大地提高了单目视频视图合成的有效性。然而，现有算法在处理不受控制或冗长的场景时面临困难，并且需要针对每个新场景的大量训练时间。为了解决这些限制，我们提出了DynPoint，这是一种算法，旨在促进无约束单眼视频的新视图的快速合成。DynPoint不是将整个场景信息编码为潜在表示，而是专注于预测相邻帧之间的显式3D对应关系，以实现信息聚合。具体地，这种对应预测是通过估计帧之间一致的深度和场景流信息来实现的。随后，通过构建分层神经点云，利用所获取的对应关系将信息从多个参考帧聚合到目标帧。所得到的框架使得能够对目标帧的期望视图进行快速且准确的视图合成。所获得的实验结果表明，与先前的方法相比，我们提出的方法大大加快了训练时间，通常是一个数量级，同时产生了可比的结果。此外，我们的方法在处理长持续时间视频时表现出强大的鲁棒性，而无需学习视频内容的规范表示。 et.al.|[2310.18999](http://arxiv.org/abs/2310.18999)|null|

<p align=right>(<a href=#updated-on-20231108>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-11-07**|**High-fidelity 3D Reconstruction of Plants using Neural Radiance Field**|在精准农业（PA）领域，植物表型的准确重建在优化可持续农业实践方面发挥着关键作用。目前，基于光学传感器的方法在该领域占据主导地位，但对非结构化农业环境中作物和植物的高保真3D重建的需求仍然具有挑战性。最近，神经辐射场（NeRF）的形式出现了一个有前景的发展，这是一种利用神经密度场的新方法。这项技术在各种新颖的视觉合成任务中表现出了令人印象深刻的性能，但在农业背景下仍相对未被探索。在我们的研究中，我们专注于植物表型的两项基本任务：（1）2D新视图图像的合成和（2）作物和植物模型的3D重建。我们探索了神经辐射场的世界，特别是两种SOTA方法：Instant NGP，它擅长以令人印象深刻的训练和推理速度生成高质量图像；Instant NSR，它通过在训练过程中结合符号距离函数（SDF）来改进重建的几何体。特别地，我们提出了一个新的植物表型数据集，包括来自生产环境的真实植物图像。该数据集是第一个旨在全面探索NeRF在农业环境中的优势和局限性的此类举措。我们的实验结果表明，NeRF在合成新视图图像方面表现出了值得称赞的性能，并且能够实现与Reality Capture竞争的重建结果，Reality Capture是一款领先的基于3D多视图立体（MVS）的重建商业软件。然而，我们的研究也强调了NeRF的某些缺点，包括训练速度相对较慢、采样不足时的性能限制，以及在复杂设置中获得几何质量的挑战。 et.al.|[2311.04154](http://arxiv.org/abs/2311.04154)|null|
|**2023-11-07**|**DeepPatent2: A Large-Scale Benchmarking Corpus for Technical Drawing Understanding**|计算机视觉（CV）和自然语言处理的最新进展是通过在实际应用中利用大数据来推动的。然而，这些研究领域仍然受到可用数据集的数量、多功能性和多样性的限制。简历任务，如图像字幕，主要在自然图像上进行，仍然很难在科学和技术文件中经常包含的草图图像上产生准确和有意义的字幕。诸如从2D图像进行3D重建之类的其他任务的推进需要具有多个视点的更大的数据集。我们介绍了DeepPatent2，这是一个大型数据集，提供了从14年的美国外观设计专利文件中提取的超过270万张技术图纸，132890个对象名称和22394个视点。我们通过概念字幕展示了DeepPatent2的实用性。我们进一步提供了我们的数据集的潜在有用性，以促进其他研究领域，如3D图像重建和图像检索。 et.al.|[2311.04098](http://arxiv.org/abs/2311.04098)|null|
|**2023-11-05**|**MuSHRoom: Multi-Sensor Hybrid Room Dataset for Joint 3D Reconstruction and Novel View Synthesis**|元宇宙技术要求在消费级硬件上对非人类感知（如无人机/机器人/自动汽车导航）和AR/VR等沉浸式技术进行准确、实时和沉浸式建模，同时要求结构准确性和逼真度。然而，在如何在统一的框架中应用几何重建和真实感建模（新颖的视图合成）方面存在知识差距。为了解决这一差距，并促进消费级设备的稳健和沉浸式建模和渲染的发展，首先，我们提出了一个真实世界的多传感器混合房间数据集（MuSHRoom）。我们的数据集提出了令人兴奋的挑战，需要最先进的方法具有成本效益，对噪声数据和设备具有鲁棒性，并且可以联合学习3D重建和新颖的视图合成，而不是将它们视为单独的任务，使其成为现实世界应用的理想选择。其次，我们在数据集上对几个著名的管道进行了基准测试，用于联合三维网格重建和新颖的视图合成。最后，为了进一步提高整体性能，我们提出了一种新的方法，在两个任务之间实现了良好的权衡。我们的数据集和基准测试在促进以稳健且计算高效的端到端方式融合3D重建和高质量渲染的改进方面显示出巨大潜力。 et.al.|[2311.02778](http://arxiv.org/abs/2311.02778)|null|
|**2023-11-05**|**Fast Point-cloud to Mesh Reconstruction for Deformable Object Tracking**|我们周围的世界充满了柔软的物体，作为人类，我们从小就学会用灵巧的手来感知和变形。为了使机器人手能够控制软物体，它需要获取变形物体的在线状态反馈。虽然RGB-D相机可以以30Hz的速率收集被遮挡的信息，但后者并不代表连续可跟踪的物体表面。因此，在这项工作中，我们开发了一种方法，可以为不同类别的对象以高于50Hz的速度创建变形点云的变形网格。从点云重建网格在计算机图形学领域的3D重建和4D重建下已经进行了长期的研究，但这两种方法都缺乏机器人应用所需的速度和可推广性。我们的模型是使用点云自动编码器和Real NVP架构设计的。后者是一个具有流形保持性质的连续流神经网络。我们的模型采用模板网格，该网格是处于规范状态的对象的网格，然后使模板网格变形以匹配对象的变形点云。我们的方法可以对六种不同ycb类别的变形以58Hz的速率执行网格重建和跟踪。下游应用的实例可以是用于机械手的控制算法，其需要来自被操纵物体的状态的在线反馈，这将允许以闭环方式进行在线抓取自适应。此外，我们的方法提供的跟踪能力可以帮助以无标记的方法对变形对象进行系统识别。在未来的工作中，我们将把我们的方法扩展到更多类别的物体和现实世界中变形的点云 et.al.|[2311.02749](http://arxiv.org/abs/2311.02749)|null|
|**2023-11-05**|**IPVNet: Learning Implicit Point-Voxel Features for Open-Surface 3D Reconstruction**|三维开放表面（例如非水密网格）的重建是计算机视觉中一个未被充分探索的领域。最近基于学习的内隐技术通过实现任意分辨率的重建，消除了以前的障碍。然而，这种方法通常依赖于区分表面的内部和外部，以便在重建目标时提取零水平集。在开放表面的情况下，这种区别通常会导致人为的表面间隙闭合。然而，真实世界的数据可能包含由显著的表面间隙定义的复杂细节。回归无符号距离场的隐函数在重建这种开放曲面方面显示出了前景。尽管如此，当前的无符号隐式方法依赖于原始数据的离散表示。这不仅将学习过程限制在表示的分辨率上，而且在重建中引入了异常值。为了在不引入异常值的情况下准确重建开放曲面，我们提出了一种基于学习的隐式点体素模型（IPVNet）。IPVNet通过利用原始点云数据及其离散体素对应物来预测三维空间中曲面和查询点之间的无符号距离。在合成和真实世界的公共数据集上进行的实验表明，IPVNet的性能优于现有技术，同时在最终的重建中产生的异常值要少得多。 et.al.|[2311.02552](http://arxiv.org/abs/2311.02552)|null|
|**2023-11-02**|**CADSim: Robust and Scalable in-the-wild 3D Reconstruction for Controllable Sensor Simulation**|逼真的模拟是实现%自动驾驶汽车安全和可扩展开发的关键。一个核心组件是模拟传感器，以便可以在模拟中测试整个自主系统。传感器模拟包括对具有高质量外观和铰接几何结构的交通参与者（如车辆）进行建模，并实时渲染。自动驾驶行业通常雇佣艺术家来构建这些资产。然而，这是昂贵的，缓慢的，并且可能不能反映现实。相反，根据野外收集的传感器数据自动重建资产将为生成具有良好真实世界覆盖率的多样化大型集合提供更好的途径。然而，由于传感器数据的稀疏性和噪声，目前的重建方法在野外传感器数据中举步维艰。为了解决这些问题，我们提出了CADSim，它通过一小组CAD模型将零件感知对象类先验与可微分渲染相结合，以自动重建具有高质量外观的车辆几何结构，包括铰接车轮。我们的实验表明，与现有方法相比，我们的方法从稀疏数据中恢复了更准确的形状。重要的是，它还能有效地训练和渲染。我们在几个应用中展示了我们重建的车辆，包括对自主感知系统的精确测试。 et.al.|[2311.01447](http://arxiv.org/abs/2311.01447)|null|
|**2023-11-02**|**Look at Robot Base Once: Hand-Eye Calibration with Point Clouds of Robot Base Leveraging Learning-Based 3D Vision**|手眼校准作为基于视觉的机器人系统的一项基本任务，旨在估计摄像机坐标系与机器人法兰之间的变换矩阵。大多数手眼校准方法都依赖于外部标记或人类辅助。我们提出了Look at Robot Base Once（LRBO），这是一种新的方法，可以在没有外部校准对象或人类支持的情况下，通过机器人底座来解决手眼校准问题。利用机器人底座的点云，建立了从相机坐标系到机器人底座的变换矩阵，即I=AXB。为此，我们利用基于学习的三维检测和配准算法来估计机器人基座的位置和方向。通过基于地面实况的评估对该方法的稳健性和准确性进行了量化，并将准确性结果与其他基于三维视觉的校准方法进行了比较。为了评估我们方法的可行性，我们在不同的关节配置和实验组中使用低成本的结构光扫描仪进行了实验。根据实验结果，所提出的手眼校准方法实现了0.930mm的平移偏差和0.265度的旋转偏差。此外，3D重建实验显示旋转误差为0.994度，位置误差为1.697毫米。此外，我们的方法具有在1秒内完成的潜力，与其他3D手眼校准方法相比，这是最快的。代码发布于github.com/leihui6/LRBO。 et.al.|[2311.01335](http://arxiv.org/abs/2311.01335)|**[link](https://github.com/leihui6/lrbo)**|
|**2023-11-02**|**Joint 3D Shape and Motion Estimation from Rolling Shutter Light-Field Images**|在本文中，我们提出了一种方法来解决由配备滚动快门传感器的光场相机捕获的单个图像进行场景的3D重建的问题。我们的方法利用了光场中存在的3D信息线索和滚动快门效果提供的运动信息。我们为该传感器的成像过程提出了一个通用模型，并提出了一种两阶段算法，该算法在运动形状束调整估计策略中考虑相机的位置和运动时，最大限度地减少了重新投影误差。因此，我们提供了一个即时三维形状和姿态以及速度传感范例。据我们所知，这是第一次利用这种类型的传感器实现这一目的的研究。我们还提出了一个新的基准数据集，该数据集由显示卷帘效果的不同光场组成，可作为改进评估和跟踪该领域进展的共同基础。我们通过针对不同场景和运动类型进行的几个实验来证明我们的方法的有效性和优势。源代码和数据集可在以下位置公开获取：https://github.com/ICB-Vision-AI/RSLF et.al.|[2311.01292](http://arxiv.org/abs/2311.01292)|null|
|**2023-11-01**|**DEFN: Dual-Encoder Fourier Group Harmonics Network for Three-Dimensional Macular Hole Reconstruction with Stochastic Retinal Defect Augmentation and Dynamic Weight Composition**|黄斑裂孔的空间和定量参数对诊断、手术选择和术后监测至关重要。黄斑的诊断和治疗在很大程度上依赖于空间和定量数据，但这些数据的稀缺阻碍了深度学习技术在有效分割和实时3D重建方面的进展。为了应对这一挑战，我们收集了世界上最大的黄斑裂孔数据集，用于黄斑裂孔增强的视网膜OCT（ROME-3914）和用于视网膜分割的综合档案（CARS-30k），这两个数据集都经过了专业注释。此外，我们还开发了一个创新的3D分割网络，即双编码器FuGH网络（DEFN），它集成了三个创新模块：傅立叶群谐波（FuGH）、简化三维空间注意力（S3DSA）和谐波挤压和激励模块（HSE）。这三个模块协同过滤噪声，降低计算复杂度，强调细节特征，增强网络的表示能力。我们还提出了一种新的数据增强方法，随机视网膜缺陷注入（SRDI）和网络优化策略DynamicWeightCompose（DWC），以进一步提高DEFN的性能。与13个基线相比，我们的DEFN显示出最佳性能。我们还提供精确的3D视网膜重建和定量指标，为眼科医生带来革命性的诊断和治疗决策工具，有望彻底重塑难以治疗的黄斑变性的诊断和处理模式。源代码可在以下位置公开获取：https://github.com/IIPL-HangzhouDianUniversity/DEFN-Pytorch. et.al.|[2311.00483](http://arxiv.org/abs/2311.00483)|**[link](https://github.com/iipl-hangzhoudianziuniversity/defn-pytorch)**|
|**2023-11-01**|**Single-view 3D Scene Reconstruction with High-fidelity Shape and Texture**|由于现有方法的局限性，从单视图图像重建详细的3D场景仍然是一项具有挑战性的任务，这些方法主要关注几何形状恢复，忽略对象外观和精细形状细节。为了应对这些挑战，我们提出了一种新的框架，用于从单视图图像中同时高保真地恢复对象形状和纹理。我们的方法利用所提出的单视图神经隐式形状和辐射场（SSR）表示来利用显式3D形状监督和颜色、深度和表面法线图像的体积渲染。为了克服部分观察下的形状-外观模糊性，我们引入了一个包含3D和2D监督的两阶段学习课程。我们的框架的一个显著特点是能够生成细粒度纹理网格，同时将渲染功能无缝集成到单视图3D重建模型中。这种集成不仅使3D-FRONT和Pix3D数据集上的纹理3D对象重建分别提高了27.7%和11.6%，而且还支持从新视点渲染图像。除了单个对象之外，我们的方法还有助于将对象级表示组合为灵活的场景表示，从而实现整体场景理解和3D场景编辑等应用。我们进行了大量的实验来证明我们的方法的有效性。 et.al.|[2311.00457](http://arxiv.org/abs/2311.00457)|null|

<p align=right>(<a href=#updated-on-20231108>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-11-07**|**I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models**|得益于扩散模型的快速发展，视频合成最近取得了显著进展。然而，它在语义准确性、清晰度和时空连续性方面仍然面临挑战。它们主要源于对齐良好的文本视频数据的稀缺性和视频的复杂固有结构，使模型难以同时确保语义和质量的卓越性。在本报告中，我们提出了一种级联I2VGen XL方法，该方法通过解耦这两个因素来增强模型性能，并通过利用静态图像作为一种重要的指导形式来确保输入数据的对齐。I2VGen XL由两个阶段组成：i）基础阶段通过使用两个层次编码器来保证连贯的语义并保留输入图像中的内容，以及ii）细化阶段通过合并额外的简短文本来增强视频的细节，并将分辨率提高到1280 $\times$ 720。为了提高多样性，我们收集了大约3500万个单镜头文本视频对和60亿个文本图像对来优化模型。通过这种方式，I2VGen XL可以同时增强生成视频的语义准确性、细节的连续性和清晰度。通过广泛的实验，我们研究了I2VGen XL的基本原理，并将其与当前的顶级方法进行了比较，这些方法可以在不同的数据上证明其有效性。源代码和模型将在\url上公开{https://i2vgen-xl.github.io}。 et.al.|[2311.04145](http://arxiv.org/abs/2311.04145)|null|
|**2023-11-07**|**Simple Bundles of Complex Networks**|复杂网络可以用来表示和建模大量多样的抽象和真实世界的系统和结构。对这些结构的大量研究集中在特定的拓扑性质上，包括节点度、最短路径和模块性。在目前的工作中，我们开发了一种方法，旨在识别和表征复杂网络中节点对（源和目的地）之间的简单互连束。更具体地说，简单束可以被理解为对应于在离开给定源节点之后穿过连续邻域时获得的路径束。因为在给定的束中没有节点出现不止一次，所以这些结构被认为是简单的，类似于简单路径的概念。除了描述简单的丛并为其识别提供一种可能的方法外，我们还考虑了如何根据扩散流和转移概率的指数熵来估计它们各自的有效宽度。然后，分别说明了本文中描述的概念和方法在模型理论网络的表征和分析中的潜力，并得出了几个有趣的结果。 et.al.|[2311.04133](http://arxiv.org/abs/2311.04133)|null|
|**2023-11-07**|**Precision Measurement of Sub-Continuum Gas Conduction within Micro-Confinements**|亚连续介质气体传导是从航空航天飞行器到生物医学传感器等不同应用领域中的一个重要现象，在过去几十年中一直是许多计算研究的焦点。这些研究预测，能量交换机制是由气体-表面相互作用驱动的，强烈依赖于气体和表面特性。尽管它具有基本和实际的重要性，但在非连续状态下通过气体传导的热传输大多未经实验验证。在这里，我们报道了平行微腔内亚连续气体传导的精确测量，并阐明了其对气体和表面特性的依赖性。更重要的是，我们展示了一种提取能量调节系数（EAC）的系统方法，这对于建立气体表面散射核或开发玻尔兹曼输运方程的扩散镜面解是必要的。EACs还需要用于计算近连续介质条件下的温度跳跃系数，以求解经典的流体动力学方程。我们首次通过提取表示克努森层内分子间碰撞的物理参数，对向近连续状态（特别是非单原子气体）过渡的动力学理论进行了修正。我们的结果与动力学理论预测一致，有望为热开关、气体传感器和光驱动致动器等技术的发展提供信息。 et.al.|[2311.04127](http://arxiv.org/abs/2311.04127)|null|
|**2023-11-07**|**Strong relaxation limit and uniform time asymptotics of the Jin-Xin model in the $L^{p}$ framework**|我们研究了在$\mathbb｛R｝^d$和$d\geq1$中，金新模型对粘性守恒定律的扩散弛豫极限和时间渐近稳定性。首先，对于混合Besov空间中的初始数据，基于一般的$L^{p}$范数，我们建立了关于时间和松弛参数$\varepsilon>0$的一致正则性估计。这种一致性使我们能够导出粘性守恒定律的解与其相关的金辛近似之间的差的$\mathcal｛O｝（\varepsilon）$界，从而证明了金辛双曲松弛的强收敛性。此外，在初始数据的附加条件下，例如，低频属于$L^｛p/2｝（\mathbb｛R｝^｛d｝）$，我们证明了金新模型解的$L^{p}（\mathbb｛R｝^d）$-范数以最优速率$（1+t）^{-d/｛2p｝｝$衰变，而其与相关粘性守恒定律解的差的$L^｛p}/{2p}-1/2}$ 。 et.al.|[2311.04105](http://arxiv.org/abs/2311.04105)|null|
|**2023-11-07**|**Generative Structural Design Integrating BIM and Diffusion Model**|使用人工智能进行智能结构设计可以有效地减少时间开销，提高效率。它有可能成为未来辅助甚至取代工程师的新设计范式，因此成为学术界的研究热点。然而，当前的方法有一些局限性需要解决，无论是在应用范围、生成结果的视觉质量还是结果的评估指标方面。这项研究提出了一个全面的解决方案。首先，我们将建筑信息建模（BIM）引入智能结构设计，并建立了一个集成BIM和生成人工智能的结构设计管道，这是对以前只考虑CAD图纸的框架的有力补充。为了提高几代人的感知质量和细节，本研究做出了3点贡献。首先，在生成框架方面，受人类绘图过程的启发，提出了一种新的两阶段生成框架来取代传统的端到端框架，以降低人工智能模型的生成难度。其次，在所采用的生成人工智能工具方面，引入了扩散模型（DM）来取代广泛使用的基于生成对抗性网络（GAN）的模型，并提出了一种新的基于物理的条件扩散模型（PCDM）来考虑不同的设计先决条件。第三，在神经网络方面，设计了一个由自注意块（SAB）和并行交叉注意块（PCAB）组成的注意块（AB），以促进跨域数据融合。定量和定性结果表明PCDM具有强大的生成和表示能力。进行必要的消融研究以检验方法的有效性。这项研究还表明，DM有潜力取代GANs，成为土木工程生成问题的新基准。 et.al.|[2311.04052](http://arxiv.org/abs/2311.04052)|null|
|**2023-11-07**|**Quantum reaction-limited reaction-diffusion dynamics of noninteracting Bose gases**|我们研究了一维量子反应扩散系统，其中玻色子粒子在晶格中相干跳跃，当进入范围时，会发生耗散反应。这样的反应涉及粒子在 $d$距离处的二元湮灭（$A+A\to emptyset$）和凝聚（$A+A+A\toA$）。我们考虑了反应受限的情况，其中耗散反应发生的速率比相干跳跃的速率小。在经典的反应扩散系统中，平均场近似可以正确地捕捉到这种状态。在量子反应扩散系统中，对于非相互作用的费米子系统，反应限制机制最近引起了相当大的关注，因为它已经证明，对于作为时间函数的粒子密度，它给出了超过平均场的普适幂律衰变。在这里，我们讨论了这样的普遍行为是否也存在于非相互作用玻色气体的情况下的问题。我们证明，玻色子的超平均场密度衰变只有在允许不同衰变通道相消干涉的反应中才有可能。此外，我们还研究了由分支$A\toA+A$、衰变$A\Toemptyset$和凝结$A+A\toA$ 之间的竞争引起的吸收态相变。我们发现了一个平稳相图，其中一阶和二阶过渡线在双临界点相遇，这用三临界定向渗流来描述。这些结果表明，量子统计对量子反应扩散系统的稳态和动力学普遍行为都有显著影响。 et.al.|[2311.04018](http://arxiv.org/abs/2311.04018)|null|
|**2023-11-07**|**A Method to Improve the Performance of Reinforcement Learning Based on the Y Operator for a Class of Stochastic Differential Equation-Based Child-Mother Systems**|本文介绍了一种新的算子，称为Y算子，用于提高随机微分方程（SDE）控制系统基于Actor-Critic（AC）的强化学习的控制性能。Y算子巧妙地将一类子母系统的随机性集成到Critic网络的损失函数中，使RL算法的控制性能有了实质性的提高。此外，Y算子优雅地将求解状态值函数的偏微分方程的挑战重新表述为系统SDE内漂移和扩散函数的并行问题。严格的数学证明证实了算子的有效性。这种转换使基于Y算子的强化学习（YORL）框架能够有效地解决基于模型和数据驱动系统中的最优控制问题。通过线性和非线性数值例子证明了YORL的优越性，表明其在收敛后比现有方法的性能有所提高。 et.al.|[2311.04014](http://arxiv.org/abs/2311.04014)|null|
|**2023-11-07**|**Unambiguous Simulation of Diffusive Charge Transport in Disordered Nanoribbons**|无序二维（2D）系统中的电荷输运展示了无数独特的现象，突出了潜在量子动力学的不同方面。在无序存在的情况下，2D电子从非局部弹道传播过渡到抑制传输的Anderson绝缘状态，这取决于系统的有效相干长度。在这两种状态之间，存在一种扩散交叉，其中传输变为局部的，可以用密集的电导率来适当地描述。这种丰富的物理学源于两个相关长度尺度的共存：弹性平均自由程和局域化长度。在弱无序的2D系统中，这些尺度呈指数发散，这为电荷传输仅由弹性平均自由程有效支配的平滑交叉打开了大门。在数值研究中，对扩散交叉的清晰观察仍然难以捉摸，因为它需要在足够大的系统中模拟完全相干的传输，以有意义地划分两个相关的长度尺度。在本文中，我们使用时间分辨电流模拟来解决具有显式包含（有限）引线的晶格系统中的这个问题。重要的是，我们引入了一种新的线性缩放方法，该方法将随机轨迹评估技术与有效的切比雪夫量子时间演化相结合，并引入了引线的带宽压缩方案，从而能够模拟足够大的系统尺寸。我们的发现在一个带有对角无序的方形晶格纳米带的玩具模型中得到了证明，该模型被插入到两接触介观器件中。在这个简单的设置中，可以明确地观察到所有三种预期的2D传输模式——弹道、扩散和局部。 et.al.|[2311.03983](http://arxiv.org/abs/2311.03983)|null|
|**2023-11-07**|**Relaxation dynamics of interacting bosons in a flat band system**|量子多体系统预计会随着时间的推移松弛到热态，但一些例外，例如具有非典型本征态的系统。在这项研究中，我们研究了空间局域化本征态的存在对加载到一维锯齿晶格中的相互作用玻色子的弛豫动力学的影响，该晶格通过调整跳跃率在单粒子光谱中显示出平坦的带。利用时变分块抽取算法，在不同初始条件下，基于Bose-Hubbard模型，模拟了局部密度分布的时变过程。我们的结果表明，平带的存在导致弱相互作用的扩散显著减慢。即使对于强相互作用，当初始状态在叠加中包括孤立的局域化单粒子本征态时，该状态的残余也会持续很长时间。这种特殊的弛豫动力学可以使用光学晶格中的超冷原子来测试。 et.al.|[2311.03979](http://arxiv.org/abs/2311.03979)|null|
|**2023-11-07**|**Persistence probabilities of a smooth self-similar anomalous diffusion process**|我们考虑在分数布朗运动的Mandelbrot-van-Ness表示中出现的某个分数高斯过程 $M^H$的持续概率。这个过程是自我相似和顺利的。我们证明了$M^H$的持久指数在Hurst参数$H$中是连续的。此外，还分别研究了$H\downarrow0$和$H\uparrow1$的持久性指数的渐近行为。最后，对于$H\到1/2$，适当的重整化过程收敛到具有非消失持久指数的非平凡极限，这与$M^｛1/2｝$ 消失的事实相反。 et.al.|[2311.03972](http://arxiv.org/abs/2311.03972)|null|

<p align=right>(<a href=#updated-on-20231108>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-11-06**|**Dynamic Neural Fields for Learning Atlases of 4D Fetal MRI Time-series**|我们提出了一种使用神经场快速构建生物医学图像图谱的方法。图谱是生物医学图像分析任务的关键，但传统的深度网络估计方法仍然耗时。在这项初步工作中，我们将特定主题的图谱构建框定为学习可变形时空观测的神经场。我们将我们的方法应用于学习子宫内胎儿动态BOLD MRI时间序列的受试者特异性图谱和运动稳定性。我们的方法产生了胎儿BOLD时间序列的高质量图谱，与现有工作相比，收敛速度更快。虽然我们的方法在解剖重叠方面稍逊于调整良好的基线，但它估计模板的速度要快得多，从而能够快速处理和稳定4D动态MRI采集的大型数据库。代码可在https://github.com/Kidrauh/neural-atlasing et.al.|[2311.02874](http://arxiv.org/abs/2311.02874)|**[link](https://github.com/kidrauh/neural-atlasing)**|
|**2023-11-04**|**LISNeRF Mapping: LiDAR-based Implicit Mapping via Semantic Neural Fields for Large-Scale 3D Scenes**|大规模语义映射对于户外自主代理完成规划和导航等高级任务至关重要。本文提出了一种通过单独的激光雷达测量的隐式表示进行大规模三维语义重建的新方法。我们首先利用基于八叉树的分层结构来存储隐式特征，然后通过浅层多层感知器（MLP）将这些隐式特征解码为语义信息和有符号距离值。我们采用现成的算法来预测点云的语义标签和实例ID。然后，我们使用点云几何的自监督范式和语义和全景标签的伪监督范式来联合优化隐含特征和MLP参数。随后，利用Marching Cubes算法对推理阶段的场景进行细分和可视化。对于内存受限的场景，还开发了一种地图拼接策略，将子地图合并为一个完整的地图。据我们所知，我们的方法是第一个从仅激光雷达的输入中重建语义隐含场景的工作。在SemanticKITTI、SemanticPOSS和nuScenes三个真实世界数据集上的实验证明了与当前最先进的3D映射方法相比，我们的框架的有效性和效率。 et.al.|[2311.02313](http://arxiv.org/abs/2311.02313)|null|
|**2023-11-03**|**EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision**|我们提出了EmerNeRF，这是一种简单而强大的方法，用于学习动态驾驶场景的时空表示。EmerNeRF以神经领域为基础，通过自举同时捕捉场景几何、外观、运动和语义。EmerNeRF取决于两个核心组件：首先，它将场景分为静态场和动态场。这种分解纯粹来自于自我监督，使我们的模型能够从一般的野外数据源中学习。其次，EmerNeRF将动态场中的感应流场参数化，并使用该流场进一步聚合多帧特征，从而提高动态对象的渲染精度。耦合这三个字段（静态、动态和流）使EmerNeRF能够自我充分地表示高度动态的场景，而不依赖于用于动态对象分割或光流估计的地面实况对象注释或预先训练的模型。我们的方法在传感器模拟中实现了最先进的性能，在重建静态（+2.93 PSNR）和动态（+3.70 PSNR）场景时显著优于以前的方法。此外，为了支持EmerNeRF的语义泛化，我们将2D视觉基础模型特征提升到4D时空中，并解决现代变形金刚中的普遍位置偏差，显著提高了3D感知性能（例如，占用预测准确率平均相对提高37.50%）。最后，我们构建了一个多样化且具有挑战性的120序列数据集，以在极端和高度动态的环境下对神经场进行基准测试。 et.al.|[2311.02077](http://arxiv.org/abs/2311.02077)|null|
|**2023-11-01**|**Neural Field Dynamics Model for Granular Object Piles Manipulation**|我们提出了一个基于学习的颗粒材料操纵动力学模型。受流体动力学中常用的欧拉方法的启发，我们的方法采用了一个全卷积神经网络，该网络对基于密度场的物体堆和推进器表示进行操作，使其能够通过卷积操作利用物体间相互作用的空间局部性以及平移等变性。此外，我们的可微动作渲染模块使模型完全可微，并可以直接与基于梯度的轨迹优化算法集成。我们在模拟和真实世界的实验中用大量的桩操作任务评估了我们的模型，并证明它在精度和计算效率方面显著超过了现有的潜在或基于粒子的方法，并在各种环境和任务中表现出零样本泛化能力。 et.al.|[2311.00802](http://arxiv.org/abs/2311.00802)|null|
|**2023-10-31**|**Latent Field Discovery In Interacting Dynamical Systems With Neural Fields**|交互对象的系统通常在控制其动力学的场效应的影响下进化，然而以前的工作已经从这种效应中抽象出来，并假设系统在真空中进化。在这项工作中，我们专注于发现这些场，并仅从观察到的动力学中推断它们，而不直接观察它们。我们将潜在力场的存在理论化，并提出神经场来学习它们。由于观测到的动力学构成了局部物体相互作用和全局场效应的净效应，最近流行的等变网络不适用，因为它们无法捕捉全局信息。为了解决这一问题，我们建议将局部对象交互（ $\mathrm｛SE｝（n）$ 等变并依赖于相对状态）与外部全局场效应（依赖于绝对状态）区分开来。我们用等变图网络对交互进行建模，并将它们与神经场结合在一个集成场力的新型图网络中。我们的实验表明，我们可以准确地发现带电粒子环境、交通场景和引力n体问题中的潜在场，并有效地利用它们来学习系统和预测未来的轨迹。 et.al.|[2310.20679](http://arxiv.org/abs/2310.20679)|**[link](https://github.com/mkofinas/aether)**|
|**2023-10-30**|**Generative Neural Fields by Mixtures of Neural Implicit Functions**|我们提出了一种新的方法来学习由隐式基网络的线性组合表示的生成神经场。我们的算法通过进行元学习或采用自动解码范式，在潜在空间中以隐式神经表示的形式学习基网络及其系数。所提出的方法通过增加基网络的数量来容易地扩大生成神经场的容量，同时通过加权模型平均来保持推理网络的大小较小。因此，使用该模型对实例进行采样在延迟和内存占用方面是有效的。此外，我们为目标任务定制了去噪扩散概率模型，以对潜在的混合系数进行采样，这使我们的最终模型能够有效地生成看不见的数据。实验表明，我们的方法在图像、体素数据和NeRF场景的不同基准上实现了有竞争力的生成性能，而无需对特定模态和域进行复杂的设计。 et.al.|[2310.19464](http://arxiv.org/abs/2310.19464)|null|
|**2023-10-24**|**LiCROM: Linear-Subspace Continuous Reduced Order Modeling with Neural Fields**|线性降阶建模（ROM）通过使用简化的运动学表示来近似系统的行为，从而简化了复杂的模拟。通常，ROM在使用特定空间离散化创建的输入模拟上进行训练，然后用于使用相同的离散化加速模拟。这种离散化依赖性是有限制的。独立于特定的离散化将提供在训练数据中混合和匹配网格分辨率、连通性和类型（四面体、六面体）的灵活性；以在训练过程中看不到的新颖离散化来加速模拟；以及加速在时间上或参数化地改变离散化的自适应模拟。我们提出了一种灵活的、独立于离散化的降阶建模方法。与传统ROM一样，我们将配置表示为位移场的线性组合。与传统的ROM不同，我们的位移场是从参考域上的每个点到相应位移矢量的连续映射；这些映射被表示为隐式神经场。使用线性连续ROM（LiCROM），我们的训练集可以包括经历多个加载条件的多个几何体，与它们的离散化无关。这为降阶建模的新应用打开了大门。我们现在可以加速在运行时修改几何体的模拟，例如通过切割、打孔，甚至交换整个网格。我们还可以加速对训练中看不见的几何形状的模拟。我们演示了一次性泛化，在单个几何体上进行训练，然后模拟各种看不见的几何体。 et.al.|[2310.15907](http://arxiv.org/abs/2310.15907)|null|
|**2023-10-12**|**S4C: Self-Supervised Semantic Scene Completion with Neural Fields**|三维语义场景理解是计算机视觉中的一个基本挑战。它使移动代理能够自主规划和导航任意环境。SSC将这一挑战形式化为从场景的稀疏观测中联合估计密集的几何结构和语义信息。当前的SSC方法通常基于聚合的激光雷达扫描在3D地面实况上进行训练。这一过程依赖于特殊的传感器和手工注释，这些传感器和注释成本高昂且规模不大。为了克服这个问题，我们的工作提出了第一种称为S4C的SSC自监督方法，该方法不依赖于3D地面实况数据。我们提出的方法可以从单个图像重建场景，并且只依赖于训练期间从现成的图像分割网络生成的视频和伪分割地面实况。与使用离散体素网格的现有方法不同，我们将场景表示为隐式语义场。该公式允许查询相机截锥体内的任何点的占用率和语义类。我们的架构是通过基于渲染的自监督损失进行训练的。尽管如此，我们的方法实现了接近于完全监督的最先进方法的性能。此外，我们的方法表现出强大的泛化能力，可以为遥远的视点合成准确的分割图。 et.al.|[2310.07522](http://arxiv.org/abs/2310.07522)|null|
|**2023-10-07**|**HI-SLAM: Monocular Real-time Dense Mapping with Hybrid Implicit Fields**|在这封信中，我们提出了一个基于神经场的实时单目映射框架，用于精确和密集的同时定位和映射（SLAM）。最近的神经映射框架显示出有希望的结果，但依赖于RGB-D或姿势输入，或者无法实时运行。为了解决这些局限性，我们的方法将密集SLAM与神经隐式场相结合。具体来说，我们的密集SLAM方法运行并行跟踪和全局优化，而基于神经场的映射是基于最新的SLAM估计逐步构建的。为了有效地构造神经场，我们采用了多分辨率网格编码和符号距离函数（SDF）表示。这使我们能够始终保持地图的最新状态，并通过循环关闭立即适应全球更新。为了全局一致性，我们提出了一种有效的基于Sim（3）的姿态图束调整（PGBA）方法来运行在线闭环并减轻姿态和尺度漂移。为了进一步提高深度精度，我们结合了学习的单目深度先验。我们提出了一种新的深度和尺度联合调整（JDSA）模块来解决深度先验中固有的尺度模糊性。对合成和真实世界数据集的广泛评估验证了我们的方法在准确性和地图完整性方面优于现有方法，同时保持了实时性能。 et.al.|[2310.04787](http://arxiv.org/abs/2310.04787)|null|
|**2023-10-05**|**Variational Barycentric Coordinates**|我们提出了一种变分技术来优化广义重心坐标，与现有模型相比，该技术提供了额外的控制。先前的工作使用网格或闭式公式表示重心坐标，在实践中限制了目标函数的选择。相反，我们使用神经场直接参数化连续函数，该函数将多面体内部的任何坐标映射到其重心坐标。这个公式是通过我们对重心坐标的理论表征实现的，这使我们能够构建将有效坐标的整个函数类参数化的神经场。我们使用各种目标函数展示了我们模型的灵活性，包括多重光滑性和变形感知能量；作为补充，我们还提出了数学上合理的方法来测量和最小化目标，如不连续神经场的总变化。我们提供了一个实用的加速策略，对我们的算法进行了彻底的验证，并展示了几个应用。 et.al.|[2310.03861](http://arxiv.org/abs/2310.03861)|null|

<p align=right>(<a href=#updated-on-20231108>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

