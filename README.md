[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.06.14
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-12**|**From Chaos to Clarity: 3DGS in the Dark**|与来自低动态范围RGB图像的重建相比，来自原始图像的新颖视图合成提供了优越的高动态范围（HDR）信息。然而，未处理的原始图像中的固有噪声损害了3D场景表示的准确性。我们的研究表明，3D高斯散射（3DGS）特别容易受到这种噪声的影响，导致许多细长的高斯形状过度拟合噪声，从而显著降低重建质量和推理速度，尤其是在视图有限的场景中。为了解决这些问题，我们引入了一种新颖的自监督学习框架，该框架旨在从有限数量的噪声原始图像中重建HDR 3DGS。该框架通过集成噪声提取器并采用利用噪声分布先验的噪声鲁棒重建损失来增强3DGS。实验结果表明，在RawNeRF数据集上，在广泛的训练视图中，我们的方法在重建质量和推理速度方面都优于LDR/HDR 3DGS和以前最先进的（SOTA）自监督和监督预训练模型。代码可以在\url中找到{https://lizhihao6.github.io/Raw3DGS}. et.al.|[2406.08300](http://arxiv.org/abs/2406.08300)|null|
|**2024-06-12**|**Spatial Annealing Smoothing for Efficient Few-shot Neural Rendering**|具有混合表示的神经辐射场（NeRF）在重建场景以进行视图合成方面表现出了令人印象深刻的能力，提供了高效率。尽管如此，由于过拟合的问题，它们的性能在稀疏视图输入的情况下显著下降。虽然已经设计了各种正则化策略来应对这些挑战，但它们往往依赖于低效的假设，或者与混合模型不兼容。显然需要一种在混合框架内保持效率并提高稀疏视图弹性的方法。在本文中，我们介绍了一种精确高效的少镜头神经渲染方法，称为空间退火平滑正则化NeRF（SANeRF），它是专门为预滤波驱动的混合表示架构设计的。我们实现了样本空间大小从最初的大值的指数减少。这种方法对于稳定训练阶段的早期阶段至关重要，并大大有助于加强后续的细节细化过程。我们的大量实验表明，与当前的少镜头NeRF方法相比，SANeRF只需添加一行代码，就可以提供卓越的渲染质量和更快的重建速度。值得注意的是，SANeRF在Blender数据集上的PSNR比FreeNeRF高0.3 dB，同时实现了700倍的更快重建速度。 et.al.|[2406.07828](http://arxiv.org/abs/2406.07828)|**[link](https://github.com/pulangk97/SANeRF)**|
|**2024-06-11**|**Cinematic Gaussians: Real-Time HDR Radiance Fields with Depth of Field**|辐射场方法代表了从多视图照片重建复杂场景的技术状态。然而，这些重建通常受到以下一个或两个限制：首先，它们通常代表低动态范围（LDR）的场景，这限制了它们在均匀照明的环境中的使用，并阻碍了沉浸式观看体验。其次，假设所有场景元素都在输入图像中聚焦，它们对针孔相机模型的依赖带来了实际挑战，并使新视图合成过程中的重新聚焦变得复杂。针对这些限制，我们提出了一种基于3D高斯散射的轻量级方法，该方法利用具有不同曝光时间、光圈和焦距的场景的多视图LDR图像作为输入，来重建高动态范围（HDR）辐射场。通过结合基于薄镜头相机模型的高斯分析卷积以及色调映射模块，我们的重建能够以灵活的重新聚焦功能渲染HDR内容。我们证明，我们对HDR和景深的组合处理有助于实时电影渲染，优于现有技术。 et.al.|[2406.07329](http://arxiv.org/abs/2406.07329)|null|
|**2024-06-10**|**IllumiNeRF: 3D Relighting without Inverse Rendering**|现有的可重新照明视图合成方法——使用一组未知照明下的对象图像来恢复可以在目标照明下从新视点渲染的3D表示——基于反向渲染，并试图解开解释输入图像的对象几何结构、材料和照明。此外，这通常涉及通过可微分蒙特卡罗渲染进行优化，这是脆弱的，并且计算成本很高。在这项工作中，我们提出了一种更简单的方法：我们首先使用以照明为条件的图像扩散模型重新照明每个输入图像，然后用这些重新照明的图像重建神经辐射场（NeRF），从中我们在目标照明下绘制新的视图。我们证明，这一战略具有惊人的竞争力，并在多个重新照明基准上取得了最先进的结果。请参阅我们的项目页面https://illuminerf.github.io/. et.al.|[2406.06527](http://arxiv.org/abs/2406.06527)|null|
|**2024-06-10**|**Lighting Every Darkness with 3DGS: Fast Training and Real-Time Rendering for HDR View Synthesis**|基于体积渲染的方法，如NeRF，擅长从RAW图像合成HDR视图，尤其是在夜间场景中。然而，它们的训练时间很长，并且由于密集的采样要求而无法执行实时渲染。3D高斯散射（3DGS）的出现实现了实时渲染和更快的训练。然而，由于其固有的缺点，直接使用3DGS实现基于RAW图像的视图合成是具有挑战性的：1）在夜间场景中，极低的SNR导致远景中的运动结构（SfM）估计较差；2） 球面谐波（SH）函数有限的表示能力不适合于RAW线性颜色空间；以及3）不准确的场景结构阻碍了诸如重新聚焦之类的下游任务。为了解决这些问题，我们提出了LE3D（用3DGS照亮每一个黑暗）。我们的方法提出了锥散射初始化来丰富SfM的估计，并用彩色MLP代替SH来表示RAW线性颜色空间。此外，我们引入了深度失真和远近正则化，以提高下游任务场景结构的准确性。这些设计使LE3D能够执行实时新颖的视图合成、HDR渲染、重新聚焦和色调映射更改。与以前基于体积渲染的方法相比，LE3D将训练时间减少到1%，并将2K分辨率图像的渲染速度提高了4000倍。代码和查看器可在中找到https://github.com/Srameo/LE3D . et.al.|[2406.06216](http://arxiv.org/abs/2406.06216)|**[link](https://github.com/srameo/le3d)**|
|**2024-06-09**|**Self-supervised Adversarial Training of Monocular Depth Estimation against Physical-World Attacks**|单目深度估计（MDE）在自动驾驶等应用中发挥着至关重要的作用。然而，各种攻击针对MDE模型，物理攻击对系统安全构成重大威胁。传统的对抗性训练方法需要地面实况标签，不能直接应用于缺乏地面实况深度的MDE模型。一些自监督模型强化技术（例如，对比学习）忽略了MDE的领域知识，导致性能次优。在这项工作中，我们为MDE模型引入了一种新的自监督对抗性训练方法，利用视图合成而不需要地面实况深度。我们通过在训练过程中引入L_0-norm-bounded扰动来增强对抗真实世界攻击的鲁棒性。我们根据专门为MDE设计的基于监督学习和基于对比学习的方法来评估我们的方法。我们对两个具有代表性的MDE网络的实验表明，它提高了对各种对抗性攻击的鲁棒性，对良性性能的影响最小。 et.al.|[2406.05857](http://arxiv.org/abs/2406.05857)|**[link](https://github.com/Bob-cheng/DepthModelHardening)**|
|**2024-06-09**|**RefGaussian: Disentangling Reflections from 3D Gaussian Splatting for Realistic Rendering**|三维高斯散射（3D-GS）在神经渲染、三维场景重建和新型视图合成等领域取得了显著的进展。然而，3D-GS在准确表示物理反射方面遇到了主要挑战，尤其是在真实世界场景中常见的全反射和半反射的情况下。这种限制导致反射被错误地视为具有物理存在的独立元素，从而导致不精确的重建。在此，为了应对这一挑战，我们建议RefGaussian将反射从3D-GS中分离出来，以便对反射进行逼真建模。具体来说，我们建议将场景划分为透射分量和反射分量，并使用两个球面谐波（SH）来表示这些分量。考虑到这种分解尚未完全确定，我们使用局部正则化技术来确保透射分量和反射分量的局部平滑，从而实现比3D-GS更合理的分解结果。实验结果表明，我们的方法实现了优越的新视图合成和准确的深度估计结果。此外，它能够利用场景编辑应用程序，确保高质量的结果和物理一致性。 et.al.|[2406.05852](http://arxiv.org/abs/2406.05852)|null|
|**2024-06-09**|**VCR-GauS: View Consistent Depth-Normal Regularizer for Gaussian Surface Reconstruction**|尽管3D高斯散射由于其逼真和高效的新颖视图合成而得到了广泛的研究，但从基于点的表示中提取高质量的曲面仍然是一项挑战。先前的工作通过结合现成法线估计器的几何先验来改进曲面。然而，存在两个主要限制：1）监督从3D高斯渲染的法线仅更新旋转参数，而忽略其他几何参数；2） 跨多个视图的预测法线图的不一致性可能导致严重的重建伪影。在本文中，我们提出了一种深度正则化子，它直接将法线与其他几何参数耦合，从而从法线正则化中得到几何参数的完全更新。我们进一步提出了一个置信项，以减轻多个视图中正常预测的不一致性。此外，我们还引入了一种致密化和分裂策略，以正则化3D高斯的大小和分布，从而实现更精确的表面建模。与基于高斯的基线相比，实验表明，我们的方法在更快的训练速度和100+FPS的渲染下获得了更好的重建质量，并保持了有竞争力的外观质量。我们的代码将在论文接受后开源。 et.al.|[2406.05774](http://arxiv.org/abs/2406.05774)|null|
|**2024-06-07**|**Multi-style Neural Radiance Field with AdaIN**|在这项工作中，我们提出了一种结合AdaIN和NeRF的新管道，用于风格化的小说视图合成任务。与以前的工作相比，我们做出了以下贡献：1）我们简化了管道。2） 我们扩展了模型的功能来处理多样式任务。3） 我们修改了模型架构，使其在具有强烈笔触的样式上表现良好。4） 我们在多样式模型上实现了样式插值，使我们能够控制任意两个样式之间的样式以及样式化输出和原始场景之间的样式强度，从而更好地控制样式化强度。 et.al.|[2406.04960](http://arxiv.org/abs/2406.04960)|**[link](https://github.com/paoyw/Stylized-NeRF-with-AdaIN)**|
|**2024-06-06**|**Flash3D: Feed-Forward Generalisable 3D Scene Reconstruction from a Single Image**|在本文中，我们提出了Flash3D，这是一种从单个图像进行场景重建和新颖视图合成的方法，它既非常通用又高效。为了通用性，我们从单目深度估计的“基础”模型开始，并将其扩展到全3D形状和外观重建器。为了提高效率，我们将这种扩展建立在前馈高斯散射的基础上。具体来说，我们在预测的深度预测第一层3D高斯，然后添加在空间上偏移的附加高斯层，使模型能够完成遮挡和截断后的重建。Flash3D非常高效，可以在一天内在单个GPU上进行训练，因此大多数研究人员都可以访问。在RealEstate10k上进行训练和测试时，它取得了最先进的成绩。当转移到像纽约大学这样看不见的数据集时，它的表现大大优于竞争对手。更令人印象深刻的是，当转移到KITTI时，Flash3D实现了比专门在该数据集上训练的方法更好的PSNR。在某些情况下，它甚至优于最近使用多个视图作为输入的方法。代码、模型、演示和更多结果可在https://www.robots.ox.ac.uk/~vgg/research/flash3d/。 et.al.|[2406.04343](http://arxiv.org/abs/2406.04343)|null|

<p align=right>(<a href=#updated-on-20240614>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-12**|**Human 3Diffusion: Realistic Avatar Creation via Explicit 3D Consistent Diffusion Models**|从单个RGB图像创建逼真的化身是一个有吸引力但具有挑战性的问题。由于其不适定性，最近的工作利用了在大型数据集上预训练的2D扩散模型的强大先验。尽管2D扩散模型表现出强大的泛化能力，但它们不能提供具有保证的3D一致性的多视图形状先验。我们提出了人类三维扩散：通过显式三维一致扩散创造真实的化身。我们的关键见解是，2D多视图扩散和3D重建模型为彼此提供了互补的信息，通过紧密耦合它们，我们可以充分利用这两个模型的潜力。我们介绍了一种新的图像条件生成的3D高斯飞溅重建模型，该模型利用了来自2D多视图扩散模型的先验，并提供了明确的3D表示，这进一步指导了2D反向采样过程，以获得更好的3D一致性。实验表明，我们提出的框架优于最先进的方法，能够从单个RGB图像中创建逼真的化身，实现几何和外观的高保真度。广泛的消融也验证了我们设计的有效性，（1）生成三维重建中的多视图二维先验条件和（2）通过显式三维表示对采样轨迹进行一致性细化。我们的代码和模型将于发布https://yuxuan-xue.com/human-3diffusion. et.al.|[2406.08475](http://arxiv.org/abs/2406.08475)|null|
|**2024-06-12**|**2.5D Multi-view Averaging Diffusion Model for 3D Medical Image Translation: Application to Low-count PET Reconstruction with CT-less Attenuation Correction**|正电子发射断层扫描（PET）是一种重要的临床成像工具，但不可避免地会给患者和医疗保健提供者带来辐射危害。减少示踪剂注射剂量和消除用于衰减校正的CT采集可以减少总辐射剂量，但通常会导致PET具有高噪声和偏差。因此，希望开发3D方法来将非衰减校正的低剂量PET（NAC-LDPET）转换为衰减校正的标准剂量PET（AC-SDPET）。最近，扩散模型已经成为一种新的最先进的图像到图像翻译的深度学习方法，优于传统的基于CNN的方法。然而，由于高计算成本和存储器负担，它在很大程度上局限于2D应用。为了应对这些挑战，我们开发了一种新的2.5D多视图平均扩散模型（MADM），用于3D图像到图像的翻译，并应用于NAC-LDPET到AC-SDPET的翻译。具体而言，MADM对轴向、冠状和矢状视图使用单独的扩散模型，在每个采样步骤中对其输出进行平均，以确保多个视图的3D生成质量。为了加快3D采样过程，我们还提出了一种策略，使用基于CNN的3D生成作为扩散模型的先验。我们对人类患者研究的实验结果表明，MADM可以生成高质量的3D翻译图像，优于以前基于CNN和基于扩散的基线方法。 et.al.|[2406.08374](http://arxiv.org/abs/2406.08374)|null|
|**2024-06-12**|**GPT4Rec: Graph Prompt Tuning for Streaming Recommendation**|在个性化推荐系统领域，适应不断变化的用户偏好以及不断涌入的新用户和项目的挑战至关重要。传统的模型通常依赖于静态训练测试方法，难以跟上这些动态需求的步伐。流式推荐，特别是通过连续图形学习，已经成为一种新颖的解决方案。然而，该领域的现有方法要么依赖于历史数据回放，由于严格的数据隐私规定，这越来越不切实际；或者无法有效解决过度稳定问题；或者依赖于模型隔离和扩展策略。为了解决这些困难，我们提出了GPT4Rec，一种用于流式推荐的图形提示调整方法。给定不断发展的用户-项目交互图，GPT4Rec首先将图模式分解为多个视图。在隔离不同视图中的特定交互模式和关系后，GPT4Rec利用轻量级图形提示，在用户项目图中的不同交互模式之间有效地指导模型。首先，采用节点级提示来指示模型适应图中单个节点的属性或属性的变化。其次，结构级提示指导模型适应图中更广泛的连接和关系模式。最后，创新性地设计了视图级提示，以便于聚合来自多个解纠缠视图的信息。这些提示设计使GPT4Rec能够综合对图形的全面理解，确保用户-项目交互的所有重要方面都得到考虑并有效集成。在四个不同的真实世界数据集上的实验证明了我们的建议的有效性和效率。 et.al.|[2406.08229](http://arxiv.org/abs/2406.08229)|null|
|**2024-06-12**|**Category-level Neural Field for Reconstruction of Partially Observed Objects in Indoor Environment**|通过各种成功案例，神经隐式表示在三维重建中引起了人们的关注。对于进一步的应用，如场景理解或编辑，一些作品已经显示出在对象组成重建方面的进展。尽管它们在观测区域具有优越的性能，但在重建部分观测到的对象时，它们的性能仍然有限。为了更好地处理这个问题，我们引入了类别级神经场，该神经场在场景中属于同一类别的对象之间学习有意义的公共3D信息。我们的主要想法是根据观察到的形状对对象进行子分类，以便更好地训练类别级模型。然后，我们利用神经场，通过选择基于射线的不确定性选择的代表性对象并与之对齐，来执行配准部分观测对象的挑战性任务。在模拟和真实世界数据集上的实验表明，我们的方法改进了几个类别的未观察零件的重建。 et.al.|[2406.08176](http://arxiv.org/abs/2406.08176)|null|
|**2024-06-12**|**FaithFill: Faithful Inpainting for Object Completion Using a Single Reference Image**|我们提出了FaithFill，一种基于扩散的修复对象完成方法，用于真实生成丢失的对象部分。通常，需要多个参考图像来实现这种逼真的生成，否则生成将不能忠实地保持形状、纹理、颜色和背景。在这项工作中，我们提出了一种仅使用单个输入参考图像的管道，该图像具有不同的照明、背景、对象姿态和/或视点。奇异参考图像用于生成待修复对象的多个视图。我们证明了FaithFill可以从单个参考图像中忠实地生成对象的缺失部分，并保留背景/场景。这可以通过标准相似性度量、人类判断和GPT评估来证明。我们的结果是在DreamBooth数据集和一个新提出的数据集上给出的。 et.al.|[2406.07865](http://arxiv.org/abs/2406.07865)|null|
|**2024-06-11**|**M-LRM: Multi-view Large Reconstruction Model**|尽管大型重建模型（LRM）的最新进展显示了令人印象深刻的结果，但当将其输入从单个图像扩展到多个图像时，它表现出效率低下、几何和纹理质量较差以及收敛速度低于预期。其原因是，LRM将3D重建公式化为一个天真的图像到3D的翻译问题，忽略了输入图像之间的强3D相干性。在本文中，我们提出了一种多视图大型重建模型（M-LRM），该模型旨在以3D感知的方式从多视图有效地重建高质量的3D形状。具体来说，我们引入了一种多视图一致交叉关注方案，使M-LRM能够准确地从输入图像中查询信息。此外，我们使用输入多视图图像的3D先验来初始化三平面标记。与LRM相比，所提出的M-LRM可以产生分辨率为128美元乘以128美元的三平面NeRF，并生成高保真度的3D形状。实验研究表明，我们的模型比LRM实现了显著的性能增益和更快的训练收敛。项目页面：https://murphylmf.github.io/M-LRM/ et.al.|[2406.07648](http://arxiv.org/abs/2406.07648)|null|
|**2024-06-11**|**NeRSP: Neural 3D Reconstruction for Reflective Objects with Sparse Polarized Images**|我们提出了NeRSP，一种用于稀疏偏振图像反射表面的神经3D重建技术。反射表面重建是极具挑战性的，因为镜面反射与视图相关，因此违反了多视图立体的多视图一致性。另一方面，稀疏图像输入作为一种实际的捕获设置，由于缺乏对应匹配，通常会导致结果不完整或失真。本文通过利用偏振图像，共同应对来自稀疏输入和反射表面的挑战。我们从偏振图像形成模型和多视角方位一致性中推导出光度和几何线索，这些线索通过隐式神经表示联合优化了建模的表面几何形状。基于在我们的合成和真实数据集上的实验，我们仅用6个视图作为输入就获得了最先进的表面重建结果。 et.al.|[2406.07111](http://arxiv.org/abs/2406.07111)|null|
|**2024-06-10**|**HO-Cap: A Capture System and Dataset for 3D Reconstruction and Pose Tracking of Hand-Object Interaction**|我们介绍了一个数据采集系统和一个名为HO Cap的新数据集，该数据集可用于研究视频中手和物体的三维重建和姿态跟踪。该捕获系统使用多个RGB-D相机和HoloLens耳机进行数据收集，避免了使用昂贵的3D扫描仪或mocap系统。我们提出了一种半自动的方法来获得收集视频中手和物体的形状和姿势的注释，与手动标记相比，这显著减少了所需的注释时间。有了这个系统，我们捕捉到了人类使用物体执行不同任务的视频数据集，以及物体从一只手到另一只手的简单拾取、放置和移交，这些数据集可以用作具体人工智能和机器人操纵研究的人类演示。社区可以使用我们的数据捕获设置和注释框架来重建物体和人手的3D形状，并在视频中跟踪它们的姿势。 et.al.|[2406.06843](http://arxiv.org/abs/2406.06843)|null|
|**2024-06-10**|**PatchRefiner: Leveraging Synthetic Data for Real-Domain High-Resolution Monocular Metric Depth Estimation**|本文介绍了PatchRefiner，这是一种针对高分辨率实域输入的度量单图像深度估计的高级框架。虽然深度估计对于自动驾驶、3D生成建模和3D重建等应用至关重要，但由于现有架构的限制和详细的真实世界深度数据的稀缺，在真实世界场景中实现准确的高分辨率深度具有挑战性。PatchRefiner采用了一种基于瓦片的方法，将高分辨率深度估计重新定义为一种细化过程，从而显著提高了性能。PatchRefiner利用利用合成数据的伪标记策略，结合了细节和尺度解纠缠（DSD）损失，以增强细节捕获，同时保持尺度准确性，从而促进知识从合成数据到真实世界数据的有效传输。我们的广泛评估表明，PatchRefiner具有卓越的性能，在均方根误差（RMSE）方面显著优于Unreal4KStereo数据集上的现有基准测试18.1%，并在CityScape、ScanNet++和ETH3D等不同真实世界数据集上显示出细节准确性和一致规模估计的显著提高。 et.al.|[2406.06679](http://arxiv.org/abs/2406.06679)|null|
|**2024-06-09**|**MAP-ADAPT: Real-Time Quality-Adaptive Semantic 3D Maps**|创建环境的3D语义重建是许多应用程序的基础，尤其是与自主代理操作（例如，面向目标的导航或对象交互和操作）相关的应用程序。通常，3D语义重建系统以相同的细节级别捕获整个场景。然而，某些任务（例如，对象交互）需要细粒度和高分辨率的地图，特别是当要交互的对象是小尺寸或复杂的几何体时。在最近的实践中，这导致整个地图具有相同的高质量分辨率，这导致计算和存储成本增加。为了应对这一挑战，我们提出了MAP-ADAPT，这是一种使用RGBD帧进行质量自适应语义3D重建的实时方法。MAP-ADAPT是第一种自适应语义3D映射算法，与之前的工作不同，它基于场景的语义信息和几何复杂性直接生成具有不同质量区域的单个地图。利用语义SLAM管道进行姿态和语义估计，我们在合成和真实世界的数据上实现了与最先进的方法相当或优越的结果，同时显著降低了存储和计算需求。 et.al.|[2406.05849](http://arxiv.org/abs/2406.05849)|null|

<p align=right>(<a href=#updated-on-20240614>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-12**|**Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation**|扩散模型是文本到图像生成的最新技术，但其感知可变性仍然研究不足。在本文中，我们研究了提示如何影响基于黑匣子扩散的模型中的图像可变性。我们提出了W1KP，这是一种基于现有图像对感知距离的人类校准的图像集可变性测量。目前的数据集没有涵盖最近的扩散模型，因此我们策划了三个测试集进行评估。我们的最佳感知距离在准确性上比九个基线高出18个点，我们的校准在78%的时间内与分级的人类判断相匹配。使用W1KP，我们研究了提示的可重用性，并表明在新图像与已经生成的图像过于相似之前，Imagen提示可以重用10-50个随机种子，而Stable Diffusion XL和DALL-E 3可以重用50-200次。最后，我们分析了真实提示的56个语言特征，发现提示的长度、CLIP嵌入规范、具体性和词义对变异性的影响最大。据我们所知，我们是第一个从视觉语言学角度分析扩散变异性的人。我们的项目页面位于http://w1kp.com et.al.|[2406.08482](http://arxiv.org/abs/2406.08482)|null|
|**2024-06-12**|**What If We Recaption Billions of Web Images with LLaMA-3?**|网络抓取的图像-文本对本质上是有噪声的。先前的研究表明，在语义上对齐和丰富这些对的文本描述可以显著增强各种视觉语言任务的模型训练，特别是文本到图像的生成。然而，该地区的大规模调查仍然主要是封闭来源。我们的论文旨在利用强大的、textit｛开源｝LLaMA-3，一种GPT-4级别的LLM，来弥合这一社区努力。我们的重新捕获管道很简单：首先，我们对LLaMA-3-8B供电的LLaVA-1.5进行微调，然后使用它从DataComp-1B数据集中重新捕获13亿张图像。我们的实证结果证实，这种增强的数据集Recap-DataComp-1B在训练高级视觉语言模型方面提供了巨大的好处。对于像CLIP这样的判别模型，我们观察到在跨模态检索任务中增强了零样本性能。对于像文本到图像扩散转换器这样的生成模型，生成的图像在与用户的文本指令一致性方面表现出显著的改进，尤其是在以下复杂查询中。我们的项目页面是https://www.haqtu.me/Recap-Datacomp-1B/ et.al.|[2406.08478](http://arxiv.org/abs/2406.08478)|null|
|**2024-06-12**|**Human 3Diffusion: Realistic Avatar Creation via Explicit 3D Consistent Diffusion Models**|从单个RGB图像创建逼真的化身是一个有吸引力但具有挑战性的问题。由于其不适定性，最近的工作利用了在大型数据集上预训练的2D扩散模型的强大先验。尽管2D扩散模型表现出强大的泛化能力，但它们不能提供具有保证的3D一致性的多视图形状先验。我们提出了人类三维扩散：通过显式三维一致扩散创造真实的化身。我们的关键见解是，2D多视图扩散和3D重建模型为彼此提供了互补的信息，通过紧密耦合它们，我们可以充分利用这两个模型的潜力。我们介绍了一种新的图像条件生成的3D高斯飞溅重建模型，该模型利用了来自2D多视图扩散模型的先验，并提供了明确的3D表示，这进一步指导了2D反向采样过程，以获得更好的3D一致性。实验表明，我们提出的框架优于最先进的方法，能够从单个RGB图像中创建逼真的化身，实现几何和外观的高保真度。广泛的消融也验证了我们设计的有效性，（1）生成三维重建中的多视图二维先验条件和（2）通过显式三维表示对采样轨迹进行一致性细化。我们的代码和模型将于发布https://yuxuan-xue.com/human-3diffusion. et.al.|[2406.08475](http://arxiv.org/abs/2406.08475)|null|
|**2024-06-12**|**$\texttt{DiffLense}$: A Conditional Diffusion Model for Super-Resolution of Gravitational Lensing Data**|由于仪器的限制和观测条件，引力透镜数据经常以低分辨率收集。基于机器学习的超分辨率技术提供了一种提高这些图像分辨率的方法，能够更精确地测量透镜效应，并更好地了解透镜系统中的物质分布。这种增强可以显著提高我们对透镜星系内质量分布及其环境的了解，以及被透镜化的背景源的性质。传统的超分辨率技术通常学习从较低分辨率到较高分辨率样本的映射函数。然而，这些方法往往受到对优化固定距离函数的依赖性的限制，这可能导致丢失对天体物理分析至关重要的复杂细节。在这项工作中，我们介绍了$\texttt｛DiffLense｝$，这是一种基于条件扩散模型的新型超分辨率管道，专门设计用于提高从超超高速凸轮斯巴鲁战略计划（HSC-SSP）中获得的引力透镜图像的分辨率。我们的方法采用了一个生成模型，利用哈勃太空望远镜（HST）对应物中的详细结构信息。经过训练以生成HST数据的扩散模型以使用去噪技术和阈值预处理的HSC数据为条件，以显著减少噪声和背景干扰。这一过程导致在模型的训练阶段产生更明显和更少重叠的条件分布。我们证明$\texttt｛DiffLense｝$ 优于现有最先进的单图像超分辨率技术，特别是在保留天体物理分析所需的精细细节方面。 et.al.|[2406.08442](http://arxiv.org/abs/2406.08442)|null|
|**2024-06-12**|**Effect of Cr Segregation on Grain Growth in Nanocrystalline α-Fe Alloy: A Multiscale Modelling Approach**|我们提出了一个多尺度建模框架，该框架将密度泛函理论（DFT）与相场模型（PFM）相结合，以探索在铬（Cr）偏析的情况下纳米晶｛\f5α｝-Fe单相合金中晶粒生长的复杂动力学。我们首先用Mclean等温线验证了静止GB中平衡偏析的模拟结果。以不同温度下的纳米晶体晶粒为特征的多晶体模拟表明，晶粒生长动力学取决于Cr扩散率与本征GB迁移率的比值。在没有偏析的情况下，平均晶粒尺寸的平方（d2）和时间（t）之间的关系表现出线性相关性。我们观察到，在达到阈值晶粒尺寸之前，d2与t的关系图显示出一致的线性趋势，与GB处的Cr偏析无关。然而，当Cr在GB下偏析时，在超过阈值尺寸的700K至900K的温度范围内，与该线性趋势的斜率递减的偏差是明显的。该阈值晶粒尺寸随着温度的升高而减小。值得注意的是，在1000K下，从具有偏析的晶粒生长的初始阶段观察到与线性趋势的偏差，尽管线性趋势表现出较小的斜率。我们还提出了一个基于Cahn溶质阻力理论的分析公式，以预测存在溶质偏析时的晶粒生长行为，我们的模拟结果与该分析公式很好地一致。 et.al.|[2406.08437](http://arxiv.org/abs/2406.08437)|null|
|**2024-06-12**|**Diffusion Soup: Model Merging for Text-to-Image Diffusion Models**|我们提出了Diffusion Soup，这是一种用于文本到图像生成的划分方法，它对在碎片数据上训练的扩散模型的权重进行平均。通过构建，我们的方法实现了无需训练的连续学习和遗忘，而无需额外的内存或推理成本，因为可以通过重新平均来添加或删除与数据碎片相对应的模型。我们展示了Diffusion Soup从权重空间中的一个点采样，该点近似于组成数据集分布的几何平均值，这提供了抗记忆保证，并实现了零样本式混合。从经验上讲，Diffusion Soup优于在所有数据碎片的并集上训练的paragon模型，在域碎片数据上实现了30%的图像奖励改进（.34 $\到.44美元），在美学数据上则实现了59%的IR改进（.37$\到.59美元）。在这两种情况下，搜刮在TIFA得分中也占主导地位（分别为85.5美元至86.5美元和85.6美元至86.8美元）。我们展示了强大的遗忘能力——删除任何单个域碎片只会在IR中降低1%的性能（.45$ \到.44美元）——并使用真实数据验证了我们对反记忆的理论见解。最后，我们展示了Diffusion Soup融合在不同碎片上微调的模型的不同风格的能力，从而产生了零样本混合风格。 et.al.|[2406.08431](http://arxiv.org/abs/2406.08431)|null|
|**2024-06-12**|**FontStudio: Shape-Adaptive Diffusion Model for Coherent and Consistent Font Effect Generation**|最近，基于现代扩散的文本到图像生成模型的应用，用于创建艺术字体，传统上是专业设计师的领域，已经引起了人们的极大兴趣。与大多数专注于生成艺术排版的现有研究不同，我们的研究旨在解决一个新颖且要求更高的挑战：为多语言字体生成文本效果。这项任务本质上需要在字体形状的画布范围内生成连贯一致的视觉内容，而不是传统的矩形画布。为了解决这一任务，我们引入了一种新的形状自适应扩散模型，该模型能够解释给定的形状并战略性地规划不规则画布内的像素分布。为了实现这一点，我们策划了一个高质量的形状自适应图像文本数据集，并将分割掩码作为一种视觉条件，以在不规则画布内引导图像生成过程。这种方法使得传统的基于矩形画布的扩散模型能够根据所提供的几何形状产生期望的概念。其次，为了保持多个字母之间的一致性，我们还提出了一种无训练、形状自适应的效果转移方法，用于将纹理从生成的参考字母转移到其他字母。关键的见解是预先构建字体效果噪声，并在级联的潜在空间中传播字体效果信息。我们的FontStudio系统的功效通过用户偏好研究得到了证实，这些研究表明，即使与最新的无与伦比的商业产品Adobe Firefly相比，我们的系统也有显著的偏好（78%的美学胜率）。 et.al.|[2406.08392](http://arxiv.org/abs/2406.08392)|null|
|**2024-06-12**|**Resetting by rescaling: exact results for a diffusing particle in one-dimension**|在本文中，我们研究了一个简单的模型，该模型是一条线上的扩散粒子，通过将其当前位置重新缩放因子 $a$（可以是正的，也可以是负的），以$r$的速率进行随机重置。对于$|a|<1$，位置分布在很长一段时间内是稳定的，我们精确地计算所有$|a|<1$的极限分布。这种对称分布在$x=0$的峰值附近具有高斯形状，但对于大的$|x|$呈指数衰减。我们还研究了到达距离粒子初始位置（原点）$L$距离处的目标的平均首次通过时间（MFPT）$T（0）$。作为初始位置$x$的函数，MFPT$T（x）$满足一个非局部二阶微分方程，我们已经明确地求解了$0\leqa<1$。对于$-1<a\leq0$，我们也对其进行了解析求解，但最高可达常数因子$\kappa$，其值可以独立于数值模拟来确定。我们的结果表明，对于所有的$-1<a<1$，MFPT$T（0）$（从原点开始）在$r=r^*（a）$处显示最小值。然而，对于$-1<a<1$，优化的MFPT$T_｛\rm-opt｝（a）$被证明是$a$的单调递增函数。这表明，与原点的标准重置（$a=0$ ）相比，虽然正重新缩放对目标的搜索没有好处，但负重新缩放是有益的。因此，通过重新缩放然后在原点周围反射进行重置，可以加快一维目标的搜索。 et.al.|[2406.08387](http://arxiv.org/abs/2406.08387)|null|
|**2024-06-12**|**Diff-A-Riff: Musical Accompaniment Co-creation via Latent Diffusion Models**|深度生成模型的最新进展为音乐制作提供了新的机会，但也带来了挑战，如高计算需求和有限的音频质量。此外，当前的系统通常仅依赖于文本输入，并且通常专注于制作完整的音乐作品，这与音乐制作中的现有工作流程不兼容。为了解决这些问题，我们引入了“Diff-A-Riff”，这是一种潜在的扩散模型，旨在生成适用于任何音乐背景的高质量乐器伴奏。该模型通过音频参考、文本提示或两者提供控制，并产生48kHz的伪立体声音频，同时显著减少推理时间和内存使用。我们通过客观指标和主观听力测试展示了该模型的能力，相关网站上提供了大量示例：sonycslparis.github.io/diffariff-companion/ et.al.|[2406.08384](http://arxiv.org/abs/2406.08384)|null|
|**2024-06-12**|**2.5D Multi-view Averaging Diffusion Model for 3D Medical Image Translation: Application to Low-count PET Reconstruction with CT-less Attenuation Correction**|正电子发射断层扫描（PET）是一种重要的临床成像工具，但不可避免地会给患者和医疗保健提供者带来辐射危害。减少示踪剂注射剂量和消除用于衰减校正的CT采集可以减少总辐射剂量，但通常会导致PET具有高噪声和偏差。因此，希望开发3D方法来将非衰减校正的低剂量PET（NAC-LDPET）转换为衰减校正的标准剂量PET（AC-SDPET）。最近，扩散模型已经成为一种新的最先进的图像到图像翻译的深度学习方法，优于传统的基于CNN的方法。然而，由于高计算成本和存储器负担，它在很大程度上局限于2D应用。为了应对这些挑战，我们开发了一种新的2.5D多视图平均扩散模型（MADM），用于3D图像到图像的翻译，并应用于NAC-LDPET到AC-SDPET的翻译。具体而言，MADM对轴向、冠状和矢状视图使用单独的扩散模型，在每个采样步骤中对其输出进行平均，以确保多个视图的3D生成质量。为了加快3D采样过程，我们还提出了一种策略，使用基于CNN的3D生成作为扩散模型的先验。我们对人类患者研究的实验结果表明，MADM可以生成高质量的3D翻译图像，优于以前基于CNN和基于扩散的基线方法。 et.al.|[2406.08374](http://arxiv.org/abs/2406.08374)|null|

<p align=right>(<a href=#updated-on-20240614>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-12**|**Category-level Neural Field for Reconstruction of Partially Observed Objects in Indoor Environment**|通过各种成功案例，神经隐式表示在三维重建中引起了人们的关注。对于进一步的应用，如场景理解或编辑，一些作品已经显示出在对象组成重建方面的进展。尽管它们在观测区域具有优越的性能，但在重建部分观测到的对象时，它们的性能仍然有限。为了更好地处理这个问题，我们引入了类别级神经场，该神经场在场景中属于同一类别的对象之间学习有意义的公共3D信息。我们的主要想法是根据观察到的形状对对象进行子分类，以便更好地训练类别级模型。然后，我们利用神经场，通过选择基于射线的不确定性选择的代表性对象并与之对齐，来执行配准部分观测对象的挑战性任务。在模拟和真实世界数据集上的实验表明，我们的方法改进了几个类别的未观察零件的重建。 et.al.|[2406.08176](http://arxiv.org/abs/2406.08176)|null|
|**2024-06-12**|**OpenObj: Open-Vocabulary Object-Level Neural Radiance Fields with Fine-Grained Understanding**|近年来，人们对由视觉语言模型（VLM）促进的开放词汇三维场景重建产生了浓厚的兴趣，VLM在开放集检索中展示了非凡的能力。然而，现有的方法面临一些局限性：它们要么专注于学习逐点特征，导致语义理解模糊，要么只处理对象级重建，从而忽略对象内部的复杂细节。为了应对这些挑战，我们引入了OpenObj，这是一种创新的方法，用于构建具有细粒度理解的开放词汇表对象级神经辐射场（NeRF）。从本质上讲，OpenObj建立了一个健壮的框架，用于在对象级别进行高效和严密的场景建模和理解。此外，我们将零件级特征融入神经领域，从而实现物体内部的细致入微的表示。这种方法捕获对象级实例，同时保持细粒度的理解。在多个数据集上的结果表明，OpenObj在零样本语义分割和检索任务中取得了优异的性能。此外，OpenObj支持多尺度的真实世界机器人任务，包括全局移动和局部操纵。 et.al.|[2406.08009](http://arxiv.org/abs/2406.08009)|**[link](https://github.com/BIT-DYN/OpenObj)**|
|**2024-06-11**|**Image Neural Field Diffusion Models**|扩散模型在对复杂数据分布建模方面表现出了令人印象深刻的能力，与GANs相比具有几个关键优势，例如稳定的训练、更好地覆盖训练分布的模式，以及在没有额外训练的情况下解决反问题的能力。然而，大多数扩散模型学习固定分辨率图像的分布。我们建议通过在图像神经场上训练扩散模型来学习连续图像的分布，该模型可以以任何分辨率渲染，并显示出其相对于固定分辨率模型的优势。为了实现这一点，一个关键的挑战是获得一个代表真实感图像神经场的潜在空间。受最近几项技术的启发，我们提出了一种简单有效的方法，但有一些关键的变化，使图像神经场具有真实感。我们的方法可以用于将现有的潜在扩散自动编码器转换为图像神经场自动编码器。我们证明，图像神经场扩散模型可以使用混合分辨率图像数据集进行训练，优于固定分辨率扩散模型和超分辨率模型，并且可以有效地解决不同尺度条件下的逆问题。 et.al.|[2406.07480](http://arxiv.org/abs/2406.07480)|null|
|**2024-06-10**|**Space-Time Continuous PDE Forecasting using Equivariant Neural Fields**|最近，条件神经场（NeF）通过将解学习为条件NeF的潜在空间中的流，已成为偏微分方程的强大建模范式。尽管受益于NeFs的有利特性，如网格不可知性和时空连续动力学建模，但这种方法限制了将PDE的已知约束强加给解决方案的能力，例如对称性或边界条件，有利于建模的灵活性。相反，我们提出了一种基于时空连续NeF的求解框架，该框架通过在潜在空间中保留几何信息，尊重PDE的已知对称性。我们表明，将解建模为感兴趣组 $G$ 上的点云流，可以提高泛化和数据效率。我们验证了我们的框架很容易推广到看不见的空间和时间位置，以及初始条件的几何变换——在其他基于NeF的PDE预测方法失败的地方——并在一些具有挑战性的几何结构中超过基线进行改进。 et.al.|[2406.06660](http://arxiv.org/abs/2406.06660)|null|
|**2024-06-11**|**LOP-Field: Brain-inspired Layout-Object-Position Fields for Robotic Scene Understanding**|空间认知使动物具有非常高效的导航能力，这在很大程度上取决于对空间环境的场景级理解。最近，人们发现，大鼠大脑嗅后皮层的神经群体比场景中的物体更能强烈地适应空间布局。受局部场景中空间布局表示的启发，我们提出了实现布局对象位置（LOP）关联的LOP域，以对机器人场景理解的层次表示进行建模。在基础模型和隐式场景表示的支持下，神经场被实现为机器人的场景存储器，存储具有位置、对象和布局信息的场景的可查询表示。为了验证所建立的LOP关联，对该模型进行了测试，以使用定量指标从3D位置推断区域信息，实现了超过88%的平均准确度。还表明，与最先进的定位方法相比，所提出的使用区域信息的方法可以在文本和RGB输入的情况下实现改进的对象和视图定位结果。 et.al.|[2406.05985](http://arxiv.org/abs/2406.05985)|null|
|**2024-06-11**|**Grounding Continuous Representations in Geometry: Equivariant Neural Fields**|最近，神经场已经成为表示连续信号的强大建模范式。在条件神经领域中，一个领域由一个潜在变量表示，该变量对NeF进行了调节，否则其参数化将在整个数据集上共享。我们提出了基于交叉注意力变换器的等变神经场，其中NeFs以几何条件变量，即潜在点云为条件，从而实现从潜在到场的等变解码。我们的等变方法引入了一个可操纵性性质，通过该性质，场和势能都以几何为基础，并服从变换定律。如果场变换，势能相应地表示变换，反之亦然。至关重要的是，等变关系确保潜在的能够（1）真实地表示几何模式，允许在潜在空间中进行几何推理，（2）在空间相似的模式上进行权重共享，允许有效地学习场的数据集。与其他非等变NeF方法相比，使用分类实验和拟合整个数据集的能力验证了这些主要特性。我们通过展示独特的局部场编辑特性，进一步验证了ENF的潜力。 et.al.|[2406.05753](http://arxiv.org/abs/2406.05753)|null|
|**2024-06-06**|**ReFiNe: Recursive Field Networks for Cross-modal Multi-scene Representation**|最先进的多形状表示方法（单个模型“打包”多个对象）的常见权衡包括将建模精度与内存和存储进行权衡。我们展示了如何以比以前更高的精度和低内存使用率对表示为连续神经场的多个形状进行编码。我们方法的关键是利用对象自相似性的递归层次公式，从而产生高度压缩和高效的形状潜在空间。由于递归公式，我们的方法支持空间和全局到局部的潜在特征融合，而无需初始化和维护辅助数据结构，同时仍允许连续的字段查询，以实现光线跟踪等应用。在一组不同数据集上的实验中，我们提供了令人信服的定性结果，并展示了每个数据集使用单个网络的最先进的多场景重建和压缩结果。 et.al.|[2406.04309](http://arxiv.org/abs/2406.04309)|null|
|**2024-06-06**|**Vectorized Conditional Neural Fields: A Framework for Solving Time-dependent Parametric Partial Differential Equations**|变压器模型越来越多地用于求解偏微分方程（PDE）。已经提出了几种自适应方法，所有这些方法都存在变压器的典型问题，如二次记忆和时间复杂性。此外，用于PDE求解的所有流行体系结构都缺乏理想代理模型的几个期望性质中的至少一个，例如（i）对训练期间未看到的PDE参数的泛化，（ii）空间和时间零样本超分辨率，（iii）连续时间外推，（iv）对1D、2D和3D PDE的支持，以及（v）对更长时间展开的有效推断。为了解决这些局限性，我们提出了矢量化条件神经场（VCNeFs），它将时间相关偏微分方程的解表示为神经场。然而，与先前的方法相反，对于一组多个时空查询点，VCNeF并行计算它们的解决方案，并通过注意力机制对它们的依赖性进行建模。此外，VCNeF可以根据偏微分方程的初始条件和参数来调节神经场。一组广泛的实验表明，VCNeF与现有的基于ML的代理模型具有竞争力，并且往往优于现有的代理模型。 et.al.|[2406.03919](http://arxiv.org/abs/2406.03919)|**[link](https://github.com/jhagnberger/vcnef)**|
|**2024-06-05**|**Dynamic 3D Gaussian Fields for Urban Areas**|我们提出了一种用于大规模动态城市区域的新型视图合成（NVS）的高效神经3D场景表示。现有作品由于其有限的视觉质量和非交互式渲染速度，不太适合混合现实或闭环模拟等应用。最近，基于光栅化的方法已经以令人印象深刻的速度实现了高质量的NVS。然而，这些方法仅限于小规模、同质的数据，即它们不能处理由于天气、季节和照明而引起的严重外观和几何变化，也不能扩展到具有数千张图像的更大的动态区域。我们提出了4DGF，这是一种神经场景表示，可扩展到大规模动态城市区域，处理异构输入数据，并显著提高渲染速度。我们使用3D高斯作为有效的几何支架，同时依赖神经场作为紧凑灵活的外观模型。我们在全局范围内通过场景图集成场景动力学，同时通过变形在局部范围内建模关节运动。这种分解方法实现了适用于真实世界应用程序的灵活场景合成。在实验中，我们的PSNR超过了最先进的3 dB，渲染速度超过了200倍。 et.al.|[2406.03175](http://arxiv.org/abs/2406.03175)|null|
|**2024-06-04**|**A fast neural emulator for interstellar chemistry**|天体化学模型是解释不同环境中分子和原子物种观测结果的重要工具。然而，这些模型非常耗时，妨碍了对参数空间的彻底探索，导致了不确定性和偏差结果。使用神经网络来模拟天体化学模型的行为是规避这一问题的一种方法，它可以基于真实的天体化学模型提供快速计算。在本文中，我们提出了一个基于条件神经场的天文化学代码Nautilus的快速神经模拟器。由此产生的模型在1到10 $^7$年之间的任意时间内产生了192种物种的丰度。所有物种的不确定性都远低于0.2 dex，而计算时间比Nautilus小10$^4$ 。这将为执行更复杂的正向模型以更好地了解星际介质的物理性质开辟可能性。作为这些模型威力的一个例子，我们对Nautilus预测的电子丰度进行了特征重要性分析。我们发现，在低密度气体中，电子密度与初始硫丰度有关。将初始硫丰度从贫化情景增加到宇宙丰度会导致电子密度增加一个数量级。这种增强可能会对恒星形成地点的气体动力学产生潜在影响。 et.al.|[2406.02387](http://arxiv.org/abs/2406.02387)|null|

<p align=right>(<a href=#updated-on-20240614>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

