[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.11.22
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-11-21**|**Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields**|神经辐射场（NeRF）的最新进展已经实现了用于新型视图合成的高保真场景重建。然而，NeRF需要每个像素数百次网络评估来近似体积渲染积分，这使得它的训练速度很慢。将NeRF缓存到显式数据结构中可以有效地提高渲染速度，但代价是更高的内存使用率。为了解决这些问题，我们提出了Hyb-NeRF，这是一种具有多分辨率混合编码的新型神经辐射场，可以实现高效的神经建模和快速渲染，还可以实现高质量的新视图合成。Hyb-NeRF的关键思想是使用从粗分辨率到精细分辨率的不同编码策略来表示场景。Hyb-NeRF利用了粗分辨率下的记忆效率可学习的位置特征，以及精细分辨率下基于哈希的特征网格的快速优化速度和局部细节。此外，为了进一步提高性能，我们在可学习的位置编码中嵌入了基于圆锥跟踪的特征，从而消除了编码的模糊性并减少了混叠伪影。在合成和真实世界数据集上进行的大量实验表明，与以前最先进的方法相比，Hyb-NeRF实现了更快的渲染速度、更好的渲染质量，甚至更低的内存占用。 et.al.|[2311.12490](http://arxiv.org/abs/2311.12490)|null|
|**2023-11-20**|**Holistic Inverse Rendering of Complex Facade via Aerial 3D Scanning**|在这项工作中，我们使用多视图航空图像，使用神经符号距离场（SDF）重建立面的几何结构、照明和材料。在不需要复杂设备的情况下，我们的方法只将无人机捕捉到的简单RGB图像作为输入，以实现基于物理和照片真实感的新颖视图渲染、重新照明和编辑。然而，现实世界中的立面通常具有复杂的外观，从具有细微细节的漫射岩石到具有镜面反射的大面积玻璃窗，这使得很难处理所有事情。因此，以前的方法可以保留几何细节，但无法重建光滑的玻璃窗或虎钳。为了应对这一挑战，我们引入了三种空间和语义自适应优化策略，包括基于零样本分割技术的语义正则化方法以提高材料一致性，频率软件几何正则化方法来平衡不同表面中的表面平滑度和细节，以及基于可见性探针的方案，以实现对大规模户外环境中的局部照明的有效建模。此外，我们还捕捉了真实世界的立面航空3D扫描图像集和相应的点云，用于训练和基准测试。实验证明，与最先进的基线相比，我们的方法在立面整体逆绘制、新颖的视图合成和场景编辑方面具有卓越的质量。 et.al.|[2311.11825](http://arxiv.org/abs/2311.11825)|null|
|**2023-11-18**|**Structure-Aware Sparse-View X-ray 3D Reconstruction**|X射线以其揭示物体内部结构的能力而闻名，有望为3D重建提供比可见光更丰富的信息。然而，现有的神经辐射场（NeRF）算法忽略了X射线的这一重要性质，导致它们在捕捉成像对象的结构内容方面存在局限性。在本文中，我们提出了一个用于稀疏视图X射线三维重建的框架，即结构感知X射线神经辐射密度场（SAX-NeRF）。首先，我们设计了一个基于线段的转换器（Lineformer）作为SAX NeRF的主干。Linefomer通过对X射线的每个线段内的相关性进行建模，捕捉三维空间中对象的内部结构。其次，我们提出了一种掩模局部全局（MLG）射线采样策略来提取二维投影中的上下文和几何信息。此外，我们还收集了一个更大规模的数据集X3D，涵盖了更广泛的X射线应用。在X3D上的实验表明，SAX-NeRF在新的视图合成和CT重建方面分别比以前的基于NeRF的方法高出12.56和2.49dB。代码、模型和数据将在https://github.com/caiyuanhao1998/SAX-NeRF et.al.|[2311.10959](http://arxiv.org/abs/2311.10959)|**[link](https://github.com/caiyuanhao1998/sax-nerf)**|
|**2023-11-16**|**Adaptive Shells for Efficient Neural Radiance Field Rendering**|神经辐射场在新视图合成中实现了前所未有的质量，但其体积公式仍然昂贵，需要大量样本才能渲染高分辨率图像。体积编码对于表示树叶和头发等模糊几何体至关重要，它们非常适合随机优化。然而，许多场景最终主要由固体表面组成，这些表面可以通过每个像素的单个采样精确渲染。基于这一见解，我们提出了一种神经辐射公式，可以在基于体积和表面的渲染之间平滑过渡，大大加快渲染速度，甚至提高视觉逼真度。我们的方法构造了一个显式网格包络，该包络在空间上限制了神经体积表示。在实体区域中，包络几乎收敛到曲面，并且通常可以使用单个采样进行渲染。为此，我们推广了NeuS公式，该公式具有学习的空间变化的核大小，该核大小对密度的扩展进行编码，将宽核与类体积区域拟合，将紧核与类表面区域拟合。然后，我们提取表面周围窄带的显式网格，其宽度由内核大小决定，并微调该窄带内的辐射场。在推断时，我们将光线投射到网格上，并仅在封闭区域内评估辐射场，从而大大减少了所需的样本数量。实验表明，我们的方法能够以非常高的保真度实现高效的渲染。我们还证明了提取的包络可以实现动画和模拟等下游应用。 et.al.|[2311.10091](http://arxiv.org/abs/2311.10091)|null|
|**2023-11-16**|**Reconstructing Continuous Light Field From Single Coded Image**|我们提出了一种从单个观测图像重建目标场景的连续光场的方法。我们的方法两全其美：用于压缩光场采集的联合孔径曝光编码和用于视图合成的神经辐射场（NeRF）。在相机中实现的联合孔径曝光编码能够将3D场景信息有效地嵌入到观察到的图像中，但在以前的工作中，它仅用于重建离散的光场视图。基于NeRF的神经渲染能够从连续视点对3D场景进行高质量的视图合成，但当只给出单个图像作为输入时，它很难实现令人满意的质量。我们的方法将这两种技术集成到一个高效且端到端可训练的管道中。经过对各种场景的训练，我们的方法可以准确高效地重建连续光场，而无需任何测试时间优化。据我们所知，这是第一项将两个世界连接起来的工作：有效获取三维信息的相机设计和神经渲染。 et.al.|[2311.09646](http://arxiv.org/abs/2311.09646)|null|
|**2023-11-11**|**Aria-NeRF: Multimodal Egocentric View Synthesis**|基于受神经辐射场（NeRFs）启发的可微分体积射线跟踪，我们寻求加快开发从以自我为中心的数据训练的丰富的多模式场景模型的研究。从以自我为中心的图像序列构建类似NeRF的模型在理解人类行为方面发挥着关键作用，并在VR/AR领域具有多种应用。这种以自我为中心的类NeRF模型可以用作现实模拟，对能够在现实世界中执行任务的智能代理的发展做出了重大贡献。以自我为中心的视图合成的未来可能会通过使用多模式传感器（如用于自我运动跟踪的IMU、用于捕捉表面纹理和人类语言上下文的音频传感器以及用于推断场景中人类注意力模式的眼睛凝视跟踪器）来增强视觉数据，从而产生超越当今NeRF的新环境表示。为了支持和促进以自我为中心的多模式场景建模的开发和评估，我们提出了一个全面的多模式自我中心视频数据集。该数据集提供了一个全面的感官数据集，包括RGB图像、眼动追踪相机镜头、麦克风录音、气压计的气压读数、GPS的位置坐标、Wi-Fi和蓝牙的连接细节，以及与磁力计配对的双频IMU数据集（1kHz和800Hz）的信息。数据集是使用Meta Aria Glasses可穿戴设备平台收集的。该数据集中捕获的各种数据模式和真实世界背景为我们进一步理解人类行为奠定了坚实的基础，并在VR、AR和机器人领域实现了更身临其境的智能体验。 et.al.|[2311.06455](http://arxiv.org/abs/2311.06455)|null|
|**2023-11-10**|**Improved Positional Encoding for Implicit Neural Representation based Compact Data Representation**|采用位置编码来捕获隐式神经表示（INR）中编码信号的高频信息。在本文中，我们提出了一种新的位置编码方法，该方法提高了INR的重建质量。所提出的嵌入方法对于紧凑的数据表示更有利，因为它比现有方法具有更多的频率基。我们的实验表明，该方法在压缩任务中没有引入任何额外的复杂性，并且在新的视图合成中具有更高的重建质量，从而在率失真性能上获得了显著的增益。 et.al.|[2311.06059](http://arxiv.org/abs/2311.06059)|null|
|**2023-11-09**|**Real-Time Neural Rasterization for Large Scenes**|提出了一种新的大场景真实感实时新视图合成方法。现有的神经渲染方法可以生成逼真的结果，但主要适用于小规模场景（<50平方米），在大规模场景（>10000平方米）中存在困难。传统的基于图形的光栅化渲染对于大型场景来说速度很快，但缺乏真实感，并且需要昂贵的手动创建资源。我们的方法结合了两全其美，将中等质量的脚手架网格作为输入，学习神经纹理场和着色器来建模与视图相关的效果，以增强真实感，同时仍然使用标准图形管道进行实时渲染。我们的方法优于现有的神经渲染方法，为大型自动驾驶和无人机场景提供了至少30倍的渲染速度和相当或更好的真实感。我们的工作是第一个实现大型真实世界场景的实时渲染。 et.al.|[2311.05607](http://arxiv.org/abs/2311.05607)|null|
|**2023-11-09**|**Reconstructing Objects in-the-wild for Realistic Sensor Simulation**|从真实世界的数据中重建物体并以新颖的视图渲染它们，对于为机器人训练和测试的模拟带来真实性、多样性和规模至关重要。在这项工作中，我们提出了NeuSim，这是一种新的方法，可以根据在距离和有限视点捕获的稀疏野外数据来估计精确的几何结构和逼真的外观。为了实现这一目标，我们将物体表面表示为神经符号距离函数，并利用激光雷达和相机传感器数据来重建平滑准确的几何体和法线。我们用一种稳健的、受物理启发的反射率表示法对物体外观进行建模，该表示法对野外数据有效。我们的实验表明，NeuSim在具有稀疏训练视图的具有挑战性的场景中具有强大的视图合成性能。此外，我们展示了将NeuSim资产组合到虚拟世界中，并生成用于评估自动驾驶感知模型的真实多传感器数据。 et.al.|[2311.05602](http://arxiv.org/abs/2311.05602)|null|
|**2023-11-09**|**BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis**|从视频中合成逼真的4D人头头像对于VR/AR、远程呈现和视频游戏应用至关重要。尽管现有的基于神经辐射场（NeRF）的方法实现了高保真度的结果，但计算费用限制了它们在实时应用中的使用。为了克服这一限制，我们引入了BakedAvatar，这是一种用于实时神经头部化身合成的新表示，可部署在标准多边形光栅化管道中。我们的方法从学习的头部等值面中提取可变形的多层网格，并计算与表情、姿势和视图相关的外观，这些外观可以烘焙到静态纹理中，以实现高效的光栅化。因此，我们提出了一种用于神经头化身合成的三阶段流水线，包括学习连续变形、流形和辐射场，提取分层网格和纹理，以及使用差分光栅化微调纹理细节。实验结果表明，我们的表示生成的合成结果质量与其他最先进的方法相当，同时显著减少了所需的推理时间。我们进一步展示了单眼视频中的各种头部化身合成结果，包括视图合成、面部再现、表情编辑和姿势编辑，所有这些都是以交互式帧率进行的。 et.al.|[2311.05521](http://arxiv.org/abs/2311.05521)|null|

<p align=right>(<a href=#updated-on-20231122>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-11-21**|**Physics-guided Shape-from-Template: Monocular Video Perception through Neural Surrogate Models**|动态场景的3D重建是计算机图形学中一个长期存在的问题，并且随着可用信息的减少而变得越来越困难。基于模板的形状（SfT）方法旨在从RGB图像或视频序列重建基于模板的几何体，通常只利用一个没有深度信息的单眼相机，例如常规的智能手机记录。不幸的是，现有的重建方法要么是非物理的、有噪声的，要么优化缓慢。为了解决这个问题，我们提出了一种新的布料SfT重建算法，该算法使用预先训练的神经代理模型，该模型快速评估、稳定，并且由于正则化的物理模拟而产生平滑的重建。模拟网格的可差分渲染实现了重建和目标视频序列之间的逐像素比较，该视频序列可用于基于梯度的优化过程，以不仅提取形状信息，还提取物理参数，例如布料的拉伸、剪切或弯曲刚度。与最先进的基于物理的SfT方法 $\phi$ -SfT相比，这允许保持精确、稳定和平滑的重建几何结构，同时将运行时间减少400-500倍。 et.al.|[2311.12796](http://arxiv.org/abs/2311.12796)|null|
|**2023-11-20**|**Uncertainty Estimation in Contrast-Enhanced MR Image Translation with Multi-Axis Fusion**|近年来，深度学习已被应用于广泛的医学成像和图像处理任务。在这项工作中，我们专注于3D医学图像到图像翻译的认知不确定性的估计。我们提出了一种新的模型不确定性量化方法，即多轴融合（MAF），该方法依赖于从体积图像数据的多个视图中获得的互补信息的集成。将所提出的方法应用于基于原生T1、T2和T2-FLAIR扫描合成对比度增强的T1加权图像的任务。定量结果表明，我们的MAF方法的平均绝对图像合成误差和平均不确定度得分之间存在很强的相关性（ $\rho_｛\text health｝=0.89$ ）。因此，我们认为MAF是一种很有前途的方法，可以解决在推理时检测合成失败这一高度相关的任务。 et.al.|[2311.12153](http://arxiv.org/abs/2311.12153)|null|
|**2023-11-20**|**Mixing-Denoising Generalizable Occupancy Networks**|虽然目前最先进的可推广隐式神经形状模型依赖于卷积的归纳偏差，但仍不完全清楚从这种偏差中产生的特性如何与从点云进行3D重建的任务兼容。在这种情况下，我们探索了一种可推广性的替代方法。我们放松了固有的模型偏差（即，使用MLP来编码局部特征，而不是卷积），并用与重建任务相关的辅助正则化来约束假设空间，即去噪。所得到的模型是第一个基于点云网络的具有快速前馈推理的唯一MLP局部条件隐式形状重建。点云承载的特征和去噪偏移是在单次前向通过中从完全MLP制造的网络中预测的。解码器通过在去噪相对位置编码的指导下，从点云顺序不变地汇集附近的特征来预测空间中任何地方的查询的占用概率。我们在使用一半数量的模型参数的同时，优于最先进的卷积方法。 et.al.|[2311.12125](http://arxiv.org/abs/2311.12125)|null|
|**2023-11-20**|**PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction**|我们提出了一种无姿态大型重建模型（PF-LRM），用于从一些未经处理的图像重建3D对象，即使视觉重叠很小，同时在单个A100 GPU上估计1.3秒内的相对相机姿态。PF-LRM是一种高度可扩展的方法，利用自关注块在3D对象令牌和2D图像令牌之间交换信息；我们为每个视图预测一个粗略的点云，然后使用可微分透视n-point（PnP）解算器来获得相机姿势。当在约1M个对象的大量多视图姿态数据上训练时，PF-LRM表现出强大的跨数据集泛化能力，并且在各种看不见的评估数据集上，在姿态预测精度和3D重建质量方面大大优于基线方法。我们还通过快速前馈推理证明了我们的模型在下游文本/图像到3D任务中的适用性。我们的项目网站位于：https://totoro97.github.io/pf-lrm。 et.al.|[2311.12024](http://arxiv.org/abs/2311.12024)|null|
|**2023-11-19**|**GaussianDiffusion: 3D Gaussian Splatting for Denoising Diffusion Probabilistic Models with Structured Noise**|文本到3D以其高效的生成方法和广阔的创作潜力而闻名，在AIGC领域引起了极大的关注。然而，Nerf和2D扩散模型的融合经常产生过饱和图像，由于像素绘制方法的限制，对下游工业应用造成了严重限制。高斯散射最近取代了基于NeRF的方法中流行的传统逐点采样技术，彻底改变了3D重建的各个方面。本文介绍了一种新的基于高斯飞溅的文本到3D内容生成框架，通过单个高斯球体透明度对图像饱和度进行精细控制，从而生成更逼真的图像。在三维生成中实现多视图一致性的挑战极大地阻碍了建模的复杂性和准确性。受SJC的启发，我们探索使用多视图噪声分布来干扰由3D高斯飞溅生成的图像，旨在纠正多视图几何中的不一致性。我们巧妙地设计了一种有效的方法来生成噪声，该方法从不同的角度产生高斯噪声，所有这些都源于共享的噪声源。此外，基于香草3D高斯的生成倾向于将模型困在局部极小值中，导致漂浮物、毛刺或增殖元素等伪影。为了缓解这些问题，我们提出了变分高斯飞溅技术来提高3D外观的质量和稳定性。据我们所知，我们的方法首次在整个3D内容生成过程中全面利用高斯飞溅。 et.al.|[2311.11221](http://arxiv.org/abs/2311.11221)|null|
|**2023-11-18**|**LOSTU: Fast, Scalable, and Uncertainty-Aware Triangulation**|三角测量算法通常旨在最小化重投影（ $L_2$）误差，但这仅在相机参数或相机姿态没有误差时提供最大似然估计。尽管最近的进步已经产生了估计相机参数的技术，考虑到3D点的不确定性，但大多数运动结构（SfM）管道仍然使用旧的三角测量算法。这项工作利用最近的发现，提供了一种快速、可扩展和统计优化的三角测量方法，称为LOSTU。结果表明，与传统的$L_2$ 三角测量方法相比，LOSTU始终产生较低的三维重建误差——通常允许LOSTU成功地三角测量更多的点。此外，除了提供更好的3D重建外，LOSTU可以比Levenberg-Marquardt（或类似）优化方案快得多。 et.al.|[2311.11171](http://arxiv.org/abs/2311.11171)|null|
|**2023-11-18**|**Invariant-based Mapping of Space During General Motion of an Observer**|本文探索了基于视觉运动的不变量，产生了一个新的瞬时域，其中：a）即使2D图像由于相机运动而发生连续变化，静止环境也被感知为不变，b）可以在特定的子空间中检测并潜在地避免障碍物，c）可以潜在地检测运动对象。为了实现这一点，我们使用了从可测量光流导出的非线性函数，这些函数与几何三维不变量相关联。我们展示的模拟涉及一台相对于3D对象平移和旋转的相机，捕捉相机投影图像的快照。我们表明，随着时间的推移，对象在新域中看起来没有变化。我们处理来自KITTI数据集的真实数据，并演示如何分割空间以识别自由导航区域并检测预定子空间内的障碍物。此外，我们还介绍了基于KITTI数据集的运动物体识别和分割以及形状恒定性可视化的初步结果。这种表示是直接的，依赖于用于光流的简单去旋转的函数。这种表示只需要一个相机，它是基于像素的，适合并行处理，并且它消除了3D重建技术的必要性。 et.al.|[2311.11130](http://arxiv.org/abs/2311.11130)|null|
|**2023-11-18**|**Multiple View Geometry Transformers for 3D Human Pose Estimation**|在这项工作中，我们旨在提高变形金刚在多视图三维人体姿态估计中的三维推理能力。最近的工作集中在基于端到端学习的转换器设计上，该设计难以准确地解析几何信息，尤其是在遮挡期间。相反，我们提出了一种新的混合模型MVGFormer，它具有一系列以迭代方式组织的几何和外观模块。几何模块是免学习的，并以几何方式处理所有与视点相关的3D任务，这显著提高了模型的泛化能力。外观模块是可学习的，专门用于从图像信号中端到端地估计2D姿态，这使它们即使在发生遮挡时也能实现准确的估计，从而形成一个既准确又可推广到新相机和几何结构的模型。我们针对域内和域外环境评估了我们的方法，在这些环境中，我们的模型始终优于最先进的方法，尤其是在域外环境中。我们将发布代码和模型：https://github.com/XunshanMan/MVGFormer. et.al.|[2311.10983](http://arxiv.org/abs/2311.10983)|null|
|**2023-11-18**|**Structure-Aware Sparse-View X-ray 3D Reconstruction**|X射线以其揭示物体内部结构的能力而闻名，有望为3D重建提供比可见光更丰富的信息。然而，现有的神经辐射场（NeRF）算法忽略了X射线的这一重要性质，导致它们在捕捉成像对象的结构内容方面存在局限性。在本文中，我们提出了一个用于稀疏视图X射线三维重建的框架，即结构感知X射线神经辐射密度场（SAX-NeRF）。首先，我们设计了一个基于线段的转换器（Lineformer）作为SAX NeRF的主干。Linefomer通过对X射线的每个线段内的相关性进行建模，捕捉三维空间中对象的内部结构。其次，我们提出了一种掩模局部全局（MLG）射线采样策略来提取二维投影中的上下文和几何信息。此外，我们还收集了一个更大规模的数据集X3D，涵盖了更广泛的X射线应用。在X3D上的实验表明，SAX-NeRF在新的视图合成和CT重建方面分别比以前的基于NeRF的方法高出12.56和2.49dB。代码、模型和数据将在https://github.com/caiyuanhao1998/SAX-NeRF et.al.|[2311.10959](http://arxiv.org/abs/2311.10959)|**[link](https://github.com/caiyuanhao1998/sax-nerf)**|
|**2023-11-17**|**Labeling Indoor Scenes with Fusion of Out-of-the-Box Perception Models**|图像注释阶段是训练和评估对象检测和语义分割模型所需的关键且通常是最耗时的部分。在新环境中部署现有模型通常需要检测训练数据中不存在的新语义类。此外，室内场景包含显著的视点变化，需要通过训练的感知模型来正确处理。我们建议利用最先进的自下而上分割（SAM）、对象检测（Detic）和语义分割（MaskFormer）模型的最新进展，所有这些都是在大规模数据集上训练的。我们的目标是开发一种具有成本效益的标记方法，以获得用于室内环境中的语义分割和对象实例检测的伪标签，最终目标是促进各种下游任务的轻量级模型的训练。我们还提出了一个多视图标记融合阶段，该阶段考虑了场景的多个视图可用的设置，并可用于识别和纠正单个视图的不一致性。我们在主动视觉数据集和ADE20K数据集上证明了所提出的方法的有效性。我们通过将标记过程与人工注释进行比较来评估标记过程的质量。此外，我们还证明了所获得的标签在下游任务（如目标导航和零件发现）中的有效性。在对象目标导航的背景下，与使用大型单片视觉语言预训练模型的零样本基线相比，我们描述了使用这种融合方法增强的性能。 et.al.|[2311.10883](http://arxiv.org/abs/2311.10883)|null|

<p align=right>(<a href=#updated-on-20231122>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-11-21**|**Systematically Measuring Ultra-Diffuse Galaxies (SMUDGes). VI. Nuclear Star Clusters**|作为SMUDGes目录的扩展，我们提出了对超扩散星系（UDG）中潜在核星团（NSC）的光度搜索。我们确定了325个具有NSC的SMUDGes星系，并且从已有距离估计的144个星系中，确定了33个NSC宿主为UDG（ $\mu_｛0，g｝$\ge$24 mag-arcsec$^｛-2｝$，$r_e\ge 1.5$kpc）。具有NSCs的SMUDGes位于星系红色序列上，满足NSC-宿主星系-恒星质量关系，平均NSC恒星质量分数为0.02但高达0.1，NSCs偏离宿主中心的标准偏差为0.10$r_e$ ，并且微弱地支持更高密度的环境。所有这些特性都与之前高表面亮度星系样本的结果一致，这使得NSC行为与宿主星系表面亮度的依赖性至多相对较弱。 et.al.|[2311.12795](http://arxiv.org/abs/2311.12795)|null|
|**2023-11-21**|**Bubble departure and sliding in high-pressure flow boiling of water**|低压流沸腾中气泡的生长、脱离和滑动在过去受到了相当大的关注。然而，沸腾传热的大多数应用都依赖于高压流动沸腾，由于实验数据稀少且很难获得，因此知之甚少。在这项工作中，我们使用高分辨率光学技术进行了一项实验。通过结合背光阴影成像和相位检测成像，我们以高空间（6 $\mu$m）和时间（33$\mu$ s）分辨率跟踪气泡形状和物理足迹，以及气泡在加热表面上成核和滑动时的气泡大小和位置。我们发现，在1MPa以上的压力下，气泡在热扩散控制的状态下生长，并在整个生长和滑动过程中保持球形。我们分析推导了无量纲数，以关联整个湍流边界层的气泡速度和液体速度，并仅从物理性质和气泡生长速率预测气泡在表面上的滑动。我们还表明，这些无量纲解可以用来制定基本标准，预测压力和流速对气泡离开直径和生长时间的影响。 et.al.|[2311.12749](http://arxiv.org/abs/2311.12749)|null|
|**2023-11-21**|**GPT4Motion: Scripting Physical Motions in Text-to-Video Generation via Blender-Oriented GPT Planning**|文本到视频生成的最新进展利用了扩散模型的力量，以文本提示为条件创建了视觉上引人注目的内容。然而，他们通常会遇到高昂的计算成本，并且经常难以制作出具有连贯物理运动的视频。为了解决这些问题，我们提出了GPT4Motion，这是一个无训练的框架，它利用了GPT等大型语言模型的规划能力、Blender的物理模拟能力以及文本到图像扩散模型的出色图像生成能力来提高视频合成的质量。具体而言，GPT4Motion使用GPT-4基于用户文本提示生成Blender脚本，该脚本命令Blender的内置物理引擎制作基本场景组件，封装跨帧的连贯物理运动。然后将这些分量输入到Stable Diffusion中，以生成与文本提示对齐的视频。在刚性物体掉落和碰撞、布料悬垂和摆动以及液体流动三种基本物理运动场景上的实验结果表明，GPT4Motion可以在保持运动连贯性和实体一致性的情况下高效生成高质量视频。GPT4Motion在文本到视频研究方面提供了新的见解，提高了其质量，拓宽了其未来探索的视野。 et.al.|[2311.12631](http://arxiv.org/abs/2311.12631)|null|
|**2023-11-21**|**HierSpeech++: Bridging the Gap between Semantic and Acoustic Representation of Speech by Hierarchical Variational Inference for Zero-shot Speech Synthesis**|基于大语言模型（LLM）的语音合成在零样本语音合成中得到了广泛的应用。然而，它们需要大规模的数据，并且具有与以前的自回归语音模型相同的局限性，包括推理速度慢和缺乏鲁棒性。本文提出了一种快速、强的零样本语音合成器HierSpeech++，用于文本到速度（TTS）和语音转换（VC）。我们验证了分层语音合成框架可以显著提高合成语音的鲁棒性和表达性。此外，即使在零样本语音合成场景中，我们也显著提高了合成语音的自然度和说话者相似性。对于文本到语音，我们采用文本到向量框架，该框架基于文本表示和韵律提示生成自监督语音表示和F0表示。然后，HierSpeech++根据生成的矢量F0和语音提示生成语音。我们进一步介绍了一种从16kHz到48kHz的高效语音超分辨率框架。实验结果表明，分层变分自动编码器优于基于LLM和基于扩散的模型，可以成为一种强大的零样本语音合成器。此外，我们实现了第一个人文素质零样本语音合成。音频样本和源代码可在https://github.com/sh-lee-prml/HierSpeechpp. et.al.|[2311.12454](http://arxiv.org/abs/2311.12454)|**[link](https://github.com/sh-lee-prml/hierspeechpp)**|
|**2023-11-21**|**Hydrodynamic limit of N-branching Markov processes**|我们考虑分支选择粒子系统在大种群极限下的行为。这些系统的动力学是以下三个组成部分的组合：（a）运动：粒子根据连续时间马尔可夫过程在实线上移动；（b） 分支：以速率1，每个粒子在其当前位置产生一个新粒子；（c） 选择：为了保持粒子总数不变，每个分支事件都会立即移除当前位于系统中最低位置的粒子。从N $\ge$1粒子开始，其在时间t=0时的位置形成具有分布$\mu$0的i.i.d.样本，我们研究了系统在进一步的时间t>0时的行为，在极限N$\rightarrow$+$\infty$ 内。我们的第一个主要结果是，在对底层马尔可夫过程的适当（但相当温和）正则性假设下，粒子群在时间t的经验分布收敛到确定性极限，其特征是马尔可夫过程在时间t处的分布，条件是直到时间t为止不跨越某个（确定性）移动边界。我们的第二个结果是，在附加的正则性假设下，时间t的最低粒子位置收敛到移动边界。这些结果扩展和完善了其他作者以前的工作，这些工作主要涉及粒子根据布朗运动运动的情况。例如，我们的结果适用于广泛的一类L｛e｝vy过程和扩散过程。此外，我们还得到了收敛速度的改进的非渐近界。 et.al.|[2311.12453](http://arxiv.org/abs/2311.12453)|null|
|**2023-11-21**|**Autoencoder-assisted study of directed percolation with spatial long-range interactions**|引入空间L｛\'｛e｝｝vy类飞行作为吸收相变以产生非局部相互作用的一种方式。我们利用自动编码器，一种无监督的学习方法，来预测具有这种空间长程相互作用的 $（1+1）$-d定向渗流的临界点。在对反应扩散距离进行全局覆盖并为参数\取一系列不同的值之后$｛\beta｝$\；分布中\$P（r）｛\sim｝1/r^｛\beta｝$\；，获得可以连续变化的临界点$P_ c$。并将临界点下粒子密度的动态衰减作为确定临界指数的一种方法$｛\delta｝$\；存活率的百分比。我们还研究了系统粒子在临界点下随时间步长增加的活跃行为，这使我们能够确定有限尺度系统的特征时间$t_f$。以及动态指数$z$\；使用比例关系获得$t_f｛\sim｝L^｛z｝$\；。我们发现，自动编码器可以很好地识别粒子的这种特征进化行为。最后，我们讨论了缩放形式\$1/｛\delta｝-（｛\beta｝-2）/｛\deleta｝z=2$\；在不同的\$｛\beta｝$ \；以及通过使用L｛\'｛e｝｝vy分布生成随机步进来引入全局缩放机制的方法。 et.al.|[2311.12426](http://arxiv.org/abs/2311.12426)|null|
|**2023-11-21**|**Spin current relaxation time in thermally evaporated naphthyl diamine derivative films**|用自旋泵诱导的自旋输运特性和a-NPD薄膜中的电流-电压特性评价了萘二胺衍生物N，N’-双（萘-1-基）-N，N’–双（苯基）-2，2’-二甲基联苯胺（a-NPD）在热蒸发薄膜中自旋输运的自旋弛豫时间（τ）。a-NPD膜中电荷的零偏压迁移率和扩散常数分别为约1.2*10-3cm2/Vs和约3.0*10-5cm2/s。使用这些值和先前评估的a-NPD膜中约62nm的自旋扩散长度，在a-NPD薄膜中自旋电流的扩散传输的假设下，在室温下，a-NPD电影中的τ估计为约1.9微秒。a-NPD膜中的这个估计的τ足够长，可以作为自旋电子分子材料实际使用。 et.al.|[2311.12406](http://arxiv.org/abs/2311.12406)|null|
|**2023-11-21**|**Stable Diffusion For Aerial Object Detection**|航空物体探测是一项具有挑战性的任务，其中一个主要障碍在于大规模数据收集的局限性和某些类别的长尾分布。合成数据提供了一个有前景的解决方案，特别是随着稳定扩散（SD）等基于扩散的方法的最新进展。然而，将扩散方法直接应用于航空领域带来了独特的挑战：稳定扩散对丰富的地面语义的优化与航空物体的稀疏性不一致，合成后物体坐标的提取仍然存在问题。为了应对这些挑战，我们引入了一个为航空图像量身定制的合成数据增强框架。它包括稀疏到密集的感兴趣区域（ROI）提取以弥合语义差距，用低秩自适应（LORA）微调扩散模型以避免穷举再训练，最后，使用复制粘贴方法将合成物体与背景组合在一起，为通过合成数据进行航空物体检测提供了一种细致入微的方法。 et.al.|[2311.12345](http://arxiv.org/abs/2311.12345)|null|
|**2023-11-21**|**LoCo: Locally Constrained Training-Free Layout-to-Image Synthesis**|最近的文本到图像扩散模型在生成高质量图像方面达到了前所未有的水平。然而，他们对文本提示的完全依赖往往无法准确传达细粒度的空间组成。在本文中，我们提出了LoCo，这是一种无需训练的布局到图像合成方法，擅长生成与文本提示和空间布局对齐的高质量图像。我们的方法引入了局部注意力约束来细化单个对象的交叉注意力，确保它们在指定区域的精确放置。我们进一步提出了一种填充令牌约束，以利用先前被忽略的填充令牌中嵌入的语义信息，从而防止合成对象的不期望的融合。LoCo无缝集成到现有的文本到图像和布局到图像模型中，显著提高了它们的性能，并有效地解决了在现有方法中观察到的语义故障。通过广泛的实验，我们展示了我们方法的优越性，在多个基准测试中，我们在质量和数量上都超过了现有的最先进的无训练布局图像方法。 et.al.|[2311.12342](http://arxiv.org/abs/2311.12342)|null|
|**2023-11-21**|**Overcoming Pathology Image Data Deficiency: Generating Images from Pathological Transformation Process**|组织病理学是医学诊断的金标准，但由于医疗资源短缺，其应用受到限制。利用深度学习，计算机辅助诊断有可能缓解病理学家的短缺，并提供及时的临床分析。然而，开发一个可靠的模型通常需要大量的数据来进行训练，这在病理学领域是具有挑战性的。作为回应，我们提出了一种用于图像数据生成的自适应深度控制双向扩散（ADBD）网络。域偏移方法可以在小训练集下工作，并通过源信息引导克服扩散过拟合。具体而言，我们制定了一种混合注意力策略，将全球和地方的注意力重点融合在一起，引导双向扩散，确保移民成功。此外，我们开发了自适应深度控制策略来模拟生理变换，能够产生具有相应软标签的无限跨域中间图像。ADBD有效地克服了病理学图像数据的不足，为进一步的病理学相关研究提供了支持。 et.al.|[2311.12316](http://arxiv.org/abs/2311.12316)|**[link](https://github.com/rowerliu/adbd)**|

<p align=right>(<a href=#updated-on-20231122>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-11-20**|**NePF: Neural Photon Field for Single-Stage Inverse Rendering**|我们提出了一种新的单级框架——神经光子场（NePF），以解决多视图图像的不适定逆绘制问题。与以前在多个阶段恢复几何、材料和照明并从不同神经场的各种多层感知器中提取特性的方法相反，我们质疑这种复杂性，并介绍了我们的方法-一个统一恢复所有特性的单阶段框架。NePF通过充分利用神经隐式曲面的权重函数背后的物理含义和与视图相关的辐射来实现这种统一。此外，我们还介绍了一种创新的基于坐标的照明模型，用于快速基于体积的物理渲染。为了正则化这种照明，我们实现了用于散射估计的次表面散射模型。我们在真实数据集和合成数据集上评估了我们的方法。结果证明了我们的方法在恢复高保真几何和视觉上合理的材料属性方面的优越性。 et.al.|[2311.11555](http://arxiv.org/abs/2311.11555)|null|
|**2023-11-15**|**RENI++ A Rotation-Equivariant, Scale-Invariant, Natural Illumination Prior**|反向渲染是一个不适定的问题。以前的工作试图通过关注对象或场景形状或外观的先验来解决这个问题。在这项工作中，我们转而关注自然照明的先验。目前的方法依赖于球面谐波照明或其他通用表示，充其量，依赖于参数的简单化先验。这导致在照明条件的表现力方面对反向设置的限制，尤其是在考虑镜面反射时。我们提出了一种基于变分自动解码器和变换器解码器的条件神经场表示。我们扩展了矢量神经元，将等方差直接构建到我们的架构中，并通过尺度不变损失函数利用深度估计的见解，实现了高动态范围（HDR）图像的精确表示。其结果是一个紧凑的、旋转等变的HDR神经照明模型，能够捕捉自然环境地图中复杂的高频特征。在一个由1.6K HDR自然场景环境图组成的精心策划的数据集上训练我们的模型，我们将其与传统表示进行比较，证明其适用于反向渲染任务，并显示部分观测的环境图完成情况。我们在https://github.com/JADGardner/ns_reni et.al.|[2311.09361](http://arxiv.org/abs/2311.09361)|**[link](https://github.com/jadgardner/ns_reni)**|
|**2023-11-15**|**Data Augmentations in Deep Weight Spaces**|在权重空间中学习，神经网络处理其他深度神经网络的权重，已成为一个很有前途的研究方向，在各个领域都有应用，从分析和编辑神经领域和隐式神经表示，到网络修剪和量化。最近的工作设计了在该空间中进行有效学习的架构，考虑到了其独特的置换等变结构。不幸的是，到目前为止，这些架构存在严重的过拟合问题，并被证明受益于大型数据集。这带来了重大挑战，因为为这种学习设置生成数据既费力又耗时，因为每个数据样本都是必须训练的一整套网络权重。在本文中，我们通过研究权重空间的数据增强来解决这一困难，这是一组能够在不需要训练额外输入权重空间元素的情况下实时生成新数据示例的技术。我们首先回顾了最近提出的几个数据增强方案%，并将其分为几类。然后，我们介绍了一种新的基于Mixup方法的增强方案。我们评估了这些技术在现有基准以及我们生成的新基准上的性能，这对未来的研究很有价值。 et.al.|[2311.08851](http://arxiv.org/abs/2311.08851)|null|
|**2023-11-14**|**Instant3D: Instant Text-to-3D Generation**|文本到三维生成，旨在通过文本提示合成生动的三维对象，引起了计算机视觉界的广泛关注。虽然已有的几项工作在这项任务上取得了令人印象深刻的成果，但它们主要依赖于耗时的优化范式。具体来说，这些方法为每个文本提示从头开始优化神经场，生成一个对象大约需要一个小时或更长时间。这种繁重和重复的培训成本阻碍了他们的实际部署。在本文中，我们提出了一种新的快速文本到三维生成框架，称为Instant3D。一旦经过训练，Instant3D就能够通过一次前馈网络运行，在不到一秒钟的时间内为看不见的文本提示创建一个3D对象。我们通过设计一个新的网络来实现这一惊人的速度，该网络直接从文本提示构建3D三平面。我们的Instant3D的核心创新在于探索将文本条件有效地注入网络的策略。此外，我们提出了一种简单而有效的激活函数，即缩放的sigmoid函数，以取代原始的sigmoid函数，它将训练收敛速度提高了十倍以上。最后，为了解决3D生成中的Janus（多头）问题，我们提出了一种自适应Perp-Neg算法，该算法可以在训练过程中根据Janus问题的严重程度动态调整其概念否定量表，有效地降低了多头效应。在各种基准数据集上进行的大量实验表明，所提出的算法在质量和数量上都优于最先进的方法，同时实现了显著更好的效率。项目页面位于https://ming1993li.github.io/Instant3DProj. et.al.|[2311.08403](http://arxiv.org/abs/2311.08403)|null|
|**2023-11-13**|**On the mathematical replication of the MacKay effect from redundant stimulation**|在这项研究中，我们研究了视觉感知与初级视觉皮层（V1）神经活动的数学建模之间的复杂联系，重点是复制麦凯效应[MacKay，Nature 1957]。虽然分叉理论一直是解决神经科学问题的一种突出的数学方法，特别是在描述V1中由于参数变化而自发形成的模式时，它在具有局部感觉输入的场景中面临挑战。例如，这一点在麦凯的心理物理学实验中很明显，在该实验中，视觉刺激信息的冗余导致了不规则的形状，使分叉理论和多尺度分析的效果较差。为了解决这个问题，我们遵循了一个基于Amari型神经场模型的输入输出可控性的数学观点。该框架将感觉输入视为一种控制功能，通过视觉刺激的视网膜-皮层图进行皮层表征，捕捉刺激的不同特征，特别是麦凯漏斗模式“麦凯射线”中的中心冗余。从控制理论的角度，讨论了Amari型方程对于线性和非线性响应函数的精确可控性。然后，应用于麦凯效应复制，我们调整了表示神经元内连接的参数，以确保在没有感觉输入的情况下，皮层活动指数稳定到静止状态，我们进行了定量和定性研究，以表明它捕捉到了麦凯报告的诱导后图像的所有基本特征 et.al.|[2311.07338](http://arxiv.org/abs/2311.07338)|null|
|**2023-11-10**|**Improved Positional Encoding for Implicit Neural Representation based Compact Data Representation**|采用位置编码来捕获隐式神经表示（INR）中编码信号的高频信息。在本文中，我们提出了一种新的位置编码方法，该方法提高了INR的重建质量。所提出的嵌入方法对于紧凑的数据表示更有利，因为它比现有方法具有更多的频率基。我们的实验表明，该方法在压缩任务中没有引入任何额外的复杂性，并且在新的视图合成中具有更高的重建质量，从而在率失真性能上获得了显著的增益。 et.al.|[2311.06059](http://arxiv.org/abs/2311.06059)|null|
|**2023-11-09**|**BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis**|从视频中合成逼真的4D人头头像对于VR/AR、远程呈现和视频游戏应用至关重要。尽管现有的基于神经辐射场（NeRF）的方法实现了高保真度的结果，但计算费用限制了它们在实时应用中的使用。为了克服这一限制，我们引入了BakedAvatar，这是一种用于实时神经头部化身合成的新表示，可部署在标准多边形光栅化管道中。我们的方法从学习的头部等值面中提取可变形的多层网格，并计算与表情、姿势和视图相关的外观，这些外观可以烘焙到静态纹理中，以实现高效的光栅化。因此，我们提出了一种用于神经头化身合成的三阶段流水线，包括学习连续变形、流形和辐射场，提取分层网格和纹理，以及使用差分光栅化微调纹理细节。实验结果表明，我们的表示生成的合成结果质量与其他最先进的方法相当，同时显著减少了所需的推理时间。我们进一步展示了单眼视频中的各种头部化身合成结果，包括视图合成、面部再现、表情编辑和姿势编辑，所有这些都是以交互式帧率进行的。 et.al.|[2311.05521](http://arxiv.org/abs/2311.05521)|null|
|**2023-11-08**|**Learning Robust Multi-Scale Representation for Neural Radiance Fields from Unposed Images**|我们介绍了一种改进的计算机视觉中基于神经图像的绘制问题的解决方案。给定一组在火车时刻从自由移动的相机拍摄的图像，所提出的方法可以在测试时刻从一个新颖的视角合成真实的场景图像。本文提出的关键思想是：（i）在神经新视图合成问题中，通过稳健的管道从未处理的日常图像中恢复准确的相机参数同样至关重要；（ii）以不同的分辨率对对象的内容进行建模更为实用，因为在日常的未渲染图像中，相机的剧烈运动极有可能发生。为了结合这些关键思想，我们利用了场景刚性、多尺度神经场景表示和单图像深度预测的基本原理。具体地说，所提出的方法使相机参数在基于神经场的建模框架中是可学习的。通过假设每个视图的深度预测是按比例进行的，我们限制了连续帧之间的相对姿态。根据相对姿态，通过多尺度神经场网络内的基于图神经网络的多运动平均来建模绝对相机姿态估计，从而产生单个损失函数。优化引入的损失函数提供了相机内在的、外在的以及从未聚焦的图像渲染的图像。我们通过例子证明，对于从日常获取的未聚焦多视图图像中精确建模多尺度神经场景表示的统一框架，在场景表示框架内进行精确的相机姿态估计同样重要。如果不考虑相机姿态估计管道中的鲁棒性措施，对多尺度混叠伪影进行建模可能会适得其反。我们在几个基准数据集上进行了大量实验，以证明我们的方法的适用性。 et.al.|[2311.04521](http://arxiv.org/abs/2311.04521)|null|
|**2023-11-06**|**Dynamic Neural Fields for Learning Atlases of 4D Fetal MRI Time-series**|我们提出了一种使用神经场快速构建生物医学图像图谱的方法。图谱是生物医学图像分析任务的关键，但传统的深度网络估计方法仍然耗时。在这项初步工作中，我们将特定主题的图谱构建框定为学习可变形时空观测的神经场。我们将我们的方法应用于学习子宫内胎儿动态BOLD MRI时间序列的受试者特异性图谱和运动稳定性。我们的方法产生了胎儿BOLD时间序列的高质量图谱，与现有工作相比，收敛速度更快。虽然我们的方法在解剖重叠方面稍逊于调整良好的基线，但它估计模板的速度要快得多，从而能够快速处理和稳定4D动态MRI采集的大型数据库。代码可在https://github.com/Kidrauh/neural-atlasing et.al.|[2311.02874](http://arxiv.org/abs/2311.02874)|**[link](https://github.com/kidrauh/neural-atlasing)**|
|**2023-11-04**|**LISNeRF Mapping: LiDAR-based Implicit Mapping via Semantic Neural Fields for Large-Scale 3D Scenes**|大规模语义映射对于户外自主代理完成规划和导航等高级任务至关重要。本文提出了一种通过单独的激光雷达测量的隐式表示进行大规模三维语义重建的新方法。我们首先利用基于八叉树的分层结构来存储隐式特征，然后通过浅层多层感知器（MLP）将这些隐式特征解码为语义信息和有符号距离值。我们采用现成的算法来预测点云的语义标签和实例ID。然后，我们使用点云几何的自监督范式和语义和全景标签的伪监督范式来联合优化隐含特征和MLP参数。随后，利用Marching Cubes算法对推理阶段的场景进行细分和可视化。对于内存受限的场景，还开发了一种地图拼接策略，将子地图合并为一个完整的地图。据我们所知，我们的方法是第一个从仅激光雷达的输入中重建语义隐含场景的工作。在SemanticKITTI、SemanticPOSS和nuScenes三个真实世界数据集上的实验证明了与当前最先进的3D映射方法相比，我们的框架的有效性和效率。 et.al.|[2311.02313](http://arxiv.org/abs/2311.02313)|null|

<p align=right>(<a href=#updated-on-20231122>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

