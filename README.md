[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.06.06
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-04**|**WE-GS: An In-the-wild Efficient 3D Gaussian Representation for Unconstrained Photo Collections**|在计算机图形学中，从不受约束的照片集合中进行新颖视图合成（NVS）是一项具有挑战性的工作。近年来，三维高斯散射（3DGS）在静态场景的真实感和实时NVS方面显示出了良好的前景。在3DGS的基础上，我们提出了一种有效的基于点的可微渲染框架，用于从照片集中重建场景。我们的关键创新是基于残差的球面谐波系数传递模块，该模块使3DGS适应不同的照明条件和光度后处理。这个轻量级模块可以预先计算，并确保从渲染图像到3D高斯属性的有效梯度传播。此外，我们观察到，外观编码器和瞬态掩模预测器，这两个来自无约束照片采集的NVS最关键的部分，可以是互利的。我们引入了一个即插即用的轻量级空间注意力模块，以同时预测每个图像的瞬态遮挡物和潜在外观表示。经过训练和预处理，我们的方法与标准3DGS格式和渲染管道保持一致，有助于无缝集成到各种3DGS应用程序中。在不同数据集上的大量实验表明，我们的方法在新视图和外观合成的渲染质量上优于现有方法，具有高收敛性和渲染速度。 et.al.|[2406.02407](http://arxiv.org/abs/2406.02407)|null|
|**2024-06-04**|**Learning Temporally Consistent Video Depth from Video Diffusion Priors**|这项工作解决了视频深度估计的挑战，它不仅期望每帧的准确性，而且更重要的是，期望跨帧的一致性。我们没有直接从头开始开发深度估计器，而是将预测任务重新表述为条件生成问题。这使我们能够利用嵌入现有视频生成模型中的先验知识，从而降低学习难度并增强可推广性。具体来说，我们研究了如何驯服公共的稳定视频扩散（SVD），以使用图像深度和视频深度数据集的混合从输入视频中预测可靠的深度。我们从经验上证实，程序训练策略——首先优化SVD的空间层，然后优化时间层，同时保持空间层冻结——在空间准确性和时间一致性方面产生了最佳结果。我们进一步研究了在任意长视频上进行推理的滑动窗口策略。我们的观察结果表明，效率和性能之间存在权衡，一帧重叠已经产生了有利的结果。大量的实验结果表明，与现有的替代方案相比，我们的方法（称为ChronoDepth）具有优势，特别是在估计深度的时间一致性方面。此外，我们强调了在两个实际应用中更一致的视频深度的好处：深度条件视频生成和新颖的视图合成。我们的项目页面位于https://jhaoshao.github.io/ChronoDepth/. et.al.|[2406.01493](http://arxiv.org/abs/2406.01493)|null|
|**2024-06-03**|**RaDe-GS: Rasterizing Depth in Gaussian Splatting**|高斯散射（GS）已被证明在新的视图合成中非常有效，可以实现高质量和实时的渲染。然而，它在重建详细的3D形状方面的潜力尚未得到充分探索。由于高斯飞溅的离散和非结构化性质，现有方法的形状精度往往有限，这使形状提取变得复杂。虽然最近的技术（如2D GS）试图改进形状重建，但它们经常以降低渲染质量和计算效率的方式重新表述高斯基元。为了解决这些问题，我们的工作引入了一种光栅化方法来渲染一般3D高斯飞溅的深度图和表面法线图。我们的方法不仅显著提高了形状重建的精度，而且保持了高斯散射固有的计算效率。我们的方法在DTU数据集上实现了与NeuraLangelo相当的切角距离误差，并且在Tanks&Temples数据集上获得了与传统高斯飞溅相似的训练和渲染时间。我们的方法是高斯飞溅的一个重大进步，可以直接集成到现有的基于高斯飞溅的方法中。 et.al.|[2406.01467](http://arxiv.org/abs/2406.01467)|null|
|**2024-06-03**|**Self-Calibrating 4D Novel View Synthesis from Monocular Videos Using Gaussian Splatting**|与神经辐射场（NeRF）相比，高斯散射（GS）显著提高了场景重建效率和新视图合成（NVS）精度，尤其是在动态场景中。然而，当前的4D NVS方法，无论是基于GS还是NeRF，主要依赖于COLMAP提供的相机参数，甚至利用COLMAP生成的稀疏点云进行初始化，这也缺乏准确性，并且是耗时的。这有时会导致较差的动态场景表示，尤其是在具有大对象移动或极端相机条件（例如小平移与大旋转相结合）的场景中。一些研究同时优化了相机参数和场景的估计，并通过从现成模型中获得的额外信息（如深度、光流等）进行监督。使用这些未经验证的信息作为基本事实会降低鲁棒性和准确性，这在长单目视频（例如>数百帧）中经常发生。我们提出了一种新的方法，该方法通过相机参数的自校准来学习高保真度4D GS场景表示。它包括提取稳健地表示3D结构的2D点特征，以及将其用于随后的相机参数和3D结构的联合优化，以实现整体4D场景优化。我们在几个标准基准上通过大量的定量和定性实验结果证明了我们方法的准确性和时间效率。结果表明，与最先进的4D新视图合成方法相比，有了显著的改进。源代码将很快在发布https://github.com/fangli333/SC-4DGS. et.al.|[2406.01042](http://arxiv.org/abs/2406.01042)|**[link](https://github.com/fangli333/sc-4dgs)**|
|**2024-06-02**|**Efficient Neural Light Fields (ENeLF) for Mobile Devices**|新颖视图合成（NVS）是计算机视觉和图形学中的一个挑战，它专注于在给定有限的真实输入图像集的情况下，从未观察到的相机姿势生成场景的真实图像。通过使用体积渲染，神经辐射场（NeRF）在渲染质量方面取得了令人印象深刻的效果。然而，由于体积渲染的计算成本高，NeRF及其变体不适合移动设备。神经光场（NeLF）的新兴研究通过直接学习从光线表示到像素颜色的映射，消除了对体积渲染的需求。NeLF已经证明了其实现类似于NeRF的结果的能力，但需要一个更广泛、计算密集的网络，该网络对移动不友好。与现有工作不同，这项研究建立在MobileR2L引入的新型网络架构的基础上，并积极应用压缩技术（信道结构修剪）来生成一个在移动设备上高效运行的模型，该模型具有更低的延迟和更小的尺寸，但性能略有下降。 et.al.|[2406.00598](http://arxiv.org/abs/2406.00598)|null|
|**2024-06-01**|**Bilateral Guided Radiance Field Processing**|神经辐射场（NeRF）利用多视图一致性，在合成新视图合成方面取得了前所未有的性能。在捕捉多个输入时，现代相机中的图像信号处理（ISP）会对其进行独立增强，包括曝光调整、颜色校正、局部色调映射等。这些处理虽然大大提高了图像质量，但往往会打破多视图一致性假设，导致重建的辐射场出现“漂浮物”。为了在不影响视觉美观的情况下解决这一问题，我们的目标是首先在NeRF训练阶段理清ISP的增强，并在完成阶段将用户期望的增强重新应用于重建的辐射场。此外，为了使重新应用的增强在新视图之间保持一致，我们需要在3D空间中执行成像信号处理（即“3D ISP”）。为此，我们采用双边网格，一种局部仿射模型，作为ISP处理的广义表示。具体来说，我们使用辐射场优化每个视图的3D双边网格，以近似每个输入视图的相机管道的效果。为了实现用户可调节的3D精加工，我们建议从给定的单视图编辑中学习低阶4D双边网格，将照片增强提升到整个3D场景。我们展示了我们的方法可以通过有效地去除漂浮物和执行用户修饰的增强来提高新视图合成的视觉质量。源代码和我们的数据位于：https://bilarfpro.github.io. et.al.|[2406.00448](http://arxiv.org/abs/2406.00448)|null|
|**2024-05-31**|**GS-Phong: Meta-Learned 3D Gaussians for Relightable Novel View Synthesis**|三维场景中的照明解耦对于新颖的视图合成和重新照明至关重要。在本文中，我们提出了一种新的方法，使用一组可重新照明的3D高斯点来表示点光源照明的场景。受Blinn Phong模型的启发，我们的方法将场景分解为环境光、漫反射和镜面反射组件，从而能够合成逼真的照明效果。为了便于独立于光照条件的几何信息的分解，我们引入了一种新的基于双层优化的元学习框架。其基本思想是将不同光照位置下的渲染任务视为一个多任务学习问题，我们的元学习方法不仅在不同的视点上，而且在不同的光照位置上推广所学习的高斯几何，从而有效地解决了这一问题。实验结果表明，与现有的自由视点重新照明方法相比，我们的方法在训练效率和渲染质量方面是有效的。 et.al.|[2405.20791](http://arxiv.org/abs/2405.20791)|null|
|**2024-05-31**|**ContextGS: Compact 3D Gaussian Splatting with Anchor Level Context Model**|近年来，三维高斯散射（3DGS）以其快速的渲染速度和高保真度，成为一种很有前途的新型视图合成框架。然而，大量的高斯及其相关属性需要有效的压缩技术。现有的方法主要单独和独立地压缩神经高斯，即同时对所有神经高斯进行编码，对它们的相互作用和空间依赖性几乎没有设计。受上下文模型在图像压缩中的有效性的启发，我们在这项工作中提出了第一个用于3DGS压缩的锚级别的自回归模型。我们将锚划分为不同的级别，并且可以在所有较粗级别中基于已经编码的锚来预测尚未编码的锚，从而实现更准确的建模和更高的编码效率。为了进一步提高熵编码的效率，例如，在没有已经编码的锚的情况下对最粗级别进行编码，我们建议引入低维量化特征作为每个锚的超优先级，该特征可以被有效压缩。我们的工作开创了3DGS表示的锚级别的上下文模型，与普通3DGS相比，尺寸缩小了100多倍，与最新的最先进的作品Scaffold GS相比，缩小了15倍，同时实现了相当甚至更高的渲染质量。 et.al.|[2405.20721](http://arxiv.org/abs/2405.20721)|**[link](https://github.com/wyf0912/contextgs)**|
|**2024-06-03**|**A Pixel Is Worth More Than One 3D Gaussians in Single-View 3D Reconstruction**|从单视图图像中学习3D场景表示是计算机视觉中一个长期存在的基本问题，在预测输入视图中看不到的内容时存在固有的模糊性。Splatter Image方法建立在最近提出的3D高斯Splatting（3DGS）的基础上，通过基于输入图像的U-Net特征图为每个像素学习单个3D高斯，在快速单图像新视图合成方面取得了有希望的进展。然而，表示在输入视图中无法观察到的遮挡组件的表达能力有限。为了解决这个问题，本文提出了一种分层飞溅图像方法，其中一个像素值超过一个三维高斯。具体地，每个像素由父3D高斯和少量子3D高斯表示。父3D高斯像在香草飞溅图像中一样学习。通过轻量级多层感知器（MLP）学习子3D高斯，MLP将父3D高斯的投影图像特征和目标相机视图的嵌入作为输入。父母和孩子的3D高斯都是以阶段性的方式端到端学习的。来自父母高斯人眼睛的输入图像特征和目标相机位置的联合条件有助于学习分配子高斯人“看不见的东西”，恢复父母高斯人经常错过的被遮挡的细节。在实验中，所提出的方法在ShapeNet SRN和CO3D数据集上进行了测试，获得了最先进的性能，特别是显示了在输入视图中重建被遮挡内容的良好能力。 et.al.|[2405.20310](http://arxiv.org/abs/2405.20310)|null|
|**2024-05-31**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|神经辐射场（NeRF）是一种开创性的计算机视觉技术，能够从多个视点生成高质量、身临其境的视觉内容。这种能力在虚拟/增强现实、3D建模以及电影和娱乐行业的内容创作等应用中具有显著优势。然而，NeRF方法的评估带来了一些挑战，包括缺乏全面的数据集、可靠的评估方法和客观的质量指标。本文通过进行严格的主观质量评估测试，全面解决了NeRF质量评估的问题，该测试考虑了几个场景类别和最近提出的NeRF视图合成方法。此外，根据主观研究的主观得分来评估各种最先进的传统和基于学习的全参考2D图像和视频质量评估指标的性能。对实验结果进行了深入分析，对不同类别的视觉场景中的几种NeRF方法和客观质量指标进行了比较评估，包括正面和360度相机轨迹的真实和合成内容。 et.al.|[2405.20078](http://arxiv.org/abs/2405.20078)|null|

<p align=right>(<a href=#updated-on-20240606>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-03**|**MultiPly: Reconstruction of Multiple People from Monocular Video in the Wild**|我们提出了MultiPly，这是一种新颖的框架，可以从野生视频中的单眼重建3D多人。在野外视频中，重建多个自然移动和互动的个体是一项具有挑战性的任务。解决这一问题需要在没有任何受试者先验知识的情况下，对个体进行精确的像素级解纠缠。此外，它还需要从短视频序列中恢复复杂完整的3D人形，这增加了难度。为了应对这些挑战，我们首先定义了整个场景的分层神经表示，由单个人类和背景模型合成。我们通过分层可微体绘制从视频中学习分层神经表示。我们的混合实例分割方法进一步增强了这一学习过程，该方法结合了自监督的3D分割和可提示的2D分割模块，即使在密切的人类互动下也能产生可靠的实例分割监督。引入置信度引导的优化公式来交替优化人体姿势和形状/外观。我们结合了有效的目标，通过光度信息来完善人体姿态，并对人体动力学施加物理上合理的约束，从而实现高保真度的时间一致的3D重建。对我们方法的评估表明，在公开可用的数据集和野生视频中，我们的方法优于现有技术。 et.al.|[2406.01595](http://arxiv.org/abs/2406.01595)|null|
|**2024-06-03**|**Reconstructing and Simulating Dynamic 3D Objects with Mesh-adsorbed Gaussian Splatting**|3D重建和模拟虽然相互关联，但有着不同的目标：重建需要灵活的3D表示，以适应不同的场景，而模拟则需要结构化的表示来有效地建模运动原理。本文介绍了网格吸附高斯散射（MaGS）方法来解决这一难题。MaGS将3D高斯约束为悬停在网格表面上，从而创建相互吸附的网格高斯3D表示，该表示将3D高斯的渲染灵活性与网格的空间连贯性相结合。利用这种表示，我们引入了一个可学习的相对变形场（RDF）来对网格和3D高斯之间的相对位移进行建模，扩展了仅依赖ARAP先验的传统网格驱动变形范式，从而更准确地捕捉每个3D高斯的运动。通过联合优化网格、3D高斯和RDF，MaGS实现了高渲染精度和逼真变形。在D-NeRF和NeRF DS数据集上的大量实验表明，MaGS可以在重建和模拟中产生有竞争力的结果。 et.al.|[2406.01593](http://arxiv.org/abs/2406.01593)|null|
|**2024-06-03**|**Improved Three-Dimensional Reconstructions in Electron Ptychography through Defocus Series Measurements**|对厚标本三维相位重建的ptychography进行了详细分析。我们引入了多焦点ptychography，它结合了4D-STEM散焦系列，以通过更高的过分辨率提高沿光束方向的3D重建质量。将该方法与已建立的多切片ptychography技术进行比较，如常规ptychographic、正则ptychograph和多模式ptychology。此外，我们将多焦点ptychography与另一种方法进行了对比，该方法通过重建的散射矩阵（ $\mathcal{S}$ 矩阵）使用虚拟光学切片，与传统ptychographic相比，该方法提供了更精确的3D结构信息。我们基于模拟和实验数据进行的多次3D重建的结果表明，多焦点ptychography优于其他技术，尤其是在准确重建厚标本的表面和界面区域方面。 et.al.|[2406.01141](http://arxiv.org/abs/2406.01141)|null|
|**2024-06-01**|**Details Enhancement in Unsigned Distance Field Learning for High-fidelity 3D Surface Reconstruction**|虽然有符号距离域（SDF）已被公认用于对水密曲面进行建模，但无符号距离域将范围扩大到包括开放曲面和具有复杂内部结构的模型。尽管UDF具有灵活性，但它们在高保真3D重建中遇到了重大挑战，例如在零水平集的不可微性、难以实现精确的零值、许多局部极小值、消失梯度和零水平集附近的振荡梯度方向。为了应对这些挑战，我们提出了细节增强型UDF（DEUDF）学习，它集成了法线对齐和SIREN网络来捕捉精细的几何细节，自适应加权Eikonal约束来解决目标表面附近的消失梯度，基于无条件MLP的UDF表示来放松非负性约束，以及一种UDF定制的方法来提取具有非恒定等参值的等参表面。这些策略共同稳定了来自无方向点云的学习过程，并提高了UDF的准确性。我们的计算结果表明，DEUDF在重建表面的精度和质量方面都优于现有的UDF学习方法。我们将公开源代码。 et.al.|[2406.00346](http://arxiv.org/abs/2406.00346)|null|
|**2024-06-03**|**Physically Compatible 3D Object Modeling from a Single Image**|我们提出了一个计算框架，将单个图像转换为3D物理对象。图像中物理对象的视觉几何图形由三个正交属性决定：机械特性、外力和静止形状几何图形。现有的单视图3D重建方法往往忽略了这种潜在的组成，假定刚性或忽略外力。因此，重建的物体无法承受现实世界中的物理力，导致不稳定或不希望的变形——偏离了图像中所示的预期设计。我们的优化框架通过在重建过程中嵌入物理兼容性来解决这一问题。我们明确地分解了这三个物理属性，并通过静态平衡将它们联系起来，这是一个硬约束，确保优化的物理形状表现出所需的物理行为。对从Objaverse收集的数据集的评估表明，与现有方法相比，我们的框架始终增强了3D模型的物理真实性。我们的框架的实用性扩展到动态模拟和3D打印的实际应用，在这些应用中，遵守物理兼容性至关重要。 et.al.|[2405.20510](http://arxiv.org/abs/2405.20510)|null|
|**2024-05-30**|**Geometric Characterization of Rat Urinary Bladder Wall During Ex-Vivo Filling Using Micro-Computed Tomography (Micro-CT)**|本研究采用微型计算机断层扫描（micro-CT）来揭示大鼠膀胱壁在各种体外充盈状态下的几何复杂性，与通常理想化的均匀膀胱几何形状形成鲜明对比。通过分辨率在10-20微米之间的精确3D重建，这项研究仔细记录了膀胱在不同填充压力下的形态变化。这些发现说明了与均匀厚度的球形囊状物的理论模型的实质性偏差，特别是在从空隙状态到填充状态的过渡过程中，壁厚和囊状物体积的变化突出了这一点。这些结果对于完善膀胱功能的力学模型至关重要，传统上膀胱功能的机械模型过于简化了膀胱复杂的几何和生物力学行为。此外，这项研究强调了显微CT在深入了解膀胱力学方面的潜力，这对于推进膀胱出口梗阻（BOO）等疾病的治疗策略至关重要，从而增强手术和药物治疗模式。 et.al.|[2405.20454](http://arxiv.org/abs/2405.20454)|null|
|**2024-05-30**|**Learning 3D Robotics Perception using Inductive Priors**|深度学习的最新进展导致了以数据为中心的智能，即人工智能模型释放了吸收大量数据的潜力，并真正擅长执行数字任务，如文本到图像生成、机器-人类对话和图像识别。本文涵盖了利用结构化归纳偏见和先验知识进行学习的主题，以设计方法和算法来释放以原则为中心的智能的潜力。先验知识（简称先验）通常以过去的经验以及对世界如何运作的假设为依据，有助于自主主体更好地进行概括，并根据过去的经验调整其行为。在这篇论文中，我展示了先验知识在三个不同的机器人感知问题中的应用。1.以对象为中心的三维重建，2。决策的愿景和语言，以及3。3D场景理解。为了解决这些具有挑战性的问题，我提出了各种先验知识来源，包括1。来自合成数据的几何和外观先验，2。模块化和语义映射先验和3。语义、结构和上下文先验。我研究了解决机器人三维感知任务的这些先验，并提出了在深度学习模型中有效编码它们的方法。一些先验用于暖启动网络进行迁移学习，另一些则用作硬约束来限制机器人代理的动作空间。虽然经典技术很脆弱，无法推广到看不见的场景，并且以数据为中心的方法需要大量的标记数据，但本文旨在构建智能代理，这些智能代理需要很少的真实世界数据或仅从模拟中获取的数据，以推广到新模拟（即sim2sim）或真实世界看不见环境（即sim2real）中的高度动态和杂乱环境，从而对3D世界进行整体场景理解。 et.al.|[2405.20364](http://arxiv.org/abs/2405.20364)|null|
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|真实感街道场景的三维重建是开发自动驾驶真实世界模拟器的关键技术。尽管神经辐射场（NeRF）对驾驶场景很有效，但3D高斯散射（3DGS）由于其更快的速度和更明确的表示而成为一个有前途的方向。然而，大多数现有的街道3DGS方法需要跟踪的3D车辆边界框来分解静态和动态元素以进行有效的重建，这限制了它们在野外场景中的应用。为了在没有昂贵注释的情况下促进高效的3D场景重建，我们提出了一种自监督街道高斯（$\textit{S}^3$Gaussian）方法来从4D一致性分解动态和静态元素。我们用3D高斯表示每个场景，以保持其明确性，并进一步用时空场网络对其进行紧凑建模。我们在具有挑战性的Waymo Open数据集上进行了广泛的实验，以评估我们方法的有效性。我们的$\textit｛S｝^3$ Gaussian演示了分解静态和动态场景的能力，并在不使用3D注释的情况下实现了最佳性能。代码位于：https://github.com/nnanhuang/S3Gaussian/. et.al.|[2405.20323](http://arxiv.org/abs/2405.20323)|**[link](https://github.com/nnanhuang/s3gaussian)**|
|**2024-06-03**|**A Pixel Is Worth More Than One 3D Gaussians in Single-View 3D Reconstruction**|从单视图图像中学习3D场景表示是计算机视觉中一个长期存在的基本问题，在预测输入视图中看不到的内容时存在固有的模糊性。Splatter Image方法建立在最近提出的3D高斯Splatting（3DGS）的基础上，通过基于输入图像的U-Net特征图为每个像素学习单个3D高斯，在快速单图像新视图合成方面取得了有希望的进展。然而，表示在输入视图中无法观察到的遮挡组件的表达能力有限。为了解决这个问题，本文提出了一种分层飞溅图像方法，其中一个像素值超过一个三维高斯。具体地，每个像素由父3D高斯和少量子3D高斯表示。父3D高斯像在香草飞溅图像中一样学习。通过轻量级多层感知器（MLP）学习子3D高斯，MLP将父3D高斯的投影图像特征和目标相机视图的嵌入作为输入。父母和孩子的3D高斯都是以阶段性的方式端到端学习的。来自父母高斯人眼睛的输入图像特征和目标相机位置的联合条件有助于学习分配子高斯人“看不见的东西”，恢复父母高斯人经常错过的被遮挡的细节。在实验中，所提出的方法在ShapeNet SRN和CO3D数据集上进行了测试，获得了最先进的性能，特别是显示了在输入视图中重建被遮挡内容的良好能力。 et.al.|[2405.20310](http://arxiv.org/abs/2405.20310)|null|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|我们介绍了TetSphere splatting，这是一种显式的拉格朗日表示，用于重建具有高质量几何结构的3D形状。传统的对象重建方法主要使用欧拉表示，包括神经隐式（如NeRF、NeuS）和显式表示（如DMET），并且经常难以满足高计算要求和次优网格质量，与此相反，TetSphere splating使用了一种未充分使用但高效的几何基元——四面体网格。这种方法直接产生优越的网格质量，而不依赖于神经网络或后处理。它通过可微分渲染和几何能量优化的组合，使多个初始四面体球体变形，以准确重建3D形状，从而提高计算效率。作为一种强大而通用的几何表示，Tet Sphere splatting无缝集成到各种应用程序中，包括单视图3D重建、图像/文本到3D内容生成。实验结果表明，TetSphere飞溅优于现有的表示，提供了更快的优化速度、增强的网格质量和可靠的薄结构保存。 et.al.|[2405.20283](http://arxiv.org/abs/2405.20283)|null|

<p align=right>(<a href=#updated-on-20240606>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-04**|**Dreamguider: Improved Training free Diffusion-based Conditional Generation**|扩散模型已经成为训练自由条件生成的强大工具。然而，推理时间制导技术中的一个关键障碍是需要通过扩散网络计算大量反向传播来估计制导方向。此外，这些技术通常需要根据具体情况手工调整参数。尽管最近的一些工作已经引入了线性反问题的最小计算方法，但仍然缺少线性和非线性制导问题的通用轻量级制导解决方案。为此，我们提出了Dreamguider，这是一种无需通过扩散网络计算大量反向传播就能实现推理时间引导的方法。其关键思想是通过时变因子调节梯度流。此外，我们提出了一种适用于各种任务的经验指导量表，从而消除了手工参数调整的需要。我们进一步引入了一种有效的轻量级增强策略，该策略显著提高了推理时间引导期间的性能。我们在多个数据集和模型的多个任务上使用Dreamguider进行实验，以显示所提出模块的有效性。为了便于进一步研究，我们将在审查过程结束后公布该准则。 et.al.|[2406.02549](http://arxiv.org/abs/2406.02549)|null|
|**2024-06-05**|**Enhancing Temporal Consistency in Video Editing by Reconstructing Videos with 3D Gaussian Splatting**|零样本视频扩散模型的最新进展显示了文本驱动视频编辑的前景，但在实现高时间一致性方面仍然存在挑战。为了解决这一问题，我们介绍了Video-3DGS，这是一种基于3DGS的视频细化器，旨在增强零样本视频编辑器中的时间一致性。我们的方法采用了两阶段的3D高斯优化过程，专门用于编辑动态单目视频。在第一阶段，Video-3DGS采用了COLMAP的改进版本，称为MC-COLMAP，该版本使用屏蔽和剪辑方法处理原始视频。对于每个视频剪辑，MC-COLMAP生成动态前景对象和复杂背景的点云。这些点云用于初始化两组3D高斯（Frg-3DGS和Bkg-3DGS），旨在表示前景和背景视图。然后将前景视图和背景视图与2D可学习参数图合并以重建完整视图。在第二阶段中，我们利用第一阶段中开发的重建能力对视频扩散模型施加时间约束。为了证明Video-3DGS在两个阶段的有效性，我们在两个相关任务上进行了广泛的实验：视频重建和视频编辑。在DAVIS数据集上，与基于NeRF和基于3DGS的现有方法相比，用3k次迭代训练的视频-3DGS分别显著提高了视频重建质量（增加了+3 PSNR，增加了+7 PSNR）和训练效率（快x1.9，x4.5倍）。此外，它还通过确保58个动态单眼视频的时间一致性来增强视频编辑。 et.al.|[2406.02541](http://arxiv.org/abs/2406.02541)|null|
|**2024-06-04**|**ViDiT-Q: Efficient and Accurate Quantization of Diffusion Transformers for Image and Video Generation**|扩散变换器（DiTs）在视觉生成任务中表现出显著的性能，例如基于文本指令生成逼真的图像或视频。然而，用于视频生成的更大的模型尺寸和多帧处理导致计算和内存成本增加，对边缘设备的实际部署提出了挑战。训练后量化（PTQ）是降低内存成本和计算复杂度的有效方法。在量化扩散变换器时，我们发现应用为U-Net设计的现有扩散量化方法在保持质量方面面临挑战。在分析了量化扩散变换器的主要挑战后，我们设计了一种改进的量化方案：“ViDiT-Q”：视频和图像扩散变换器量化）来解决这些问题。此外，我们识别出高度敏感的层和时间步长阻碍了较低比特宽度的量化。为了解决这个问题，我们用一种新的度量解耦混合精度量化方法（ViDiT-Q-MP）改进了ViDiT-Q。我们在各种文本到图像和视频模型中验证了ViDiT-Q的有效性。当基线量化方法在W8A8处失败并且在W4A8处产生不可读内容时，ViDiT-Q实现了无损的W8A8量化。ViDiTQ MP实现了W4A8，视觉质量下降可以忽略不计，从而实现了2.5倍的内存优化和1.5倍的延迟加速。 et.al.|[2406.02540](http://arxiv.org/abs/2406.02540)|null|
|**2024-06-04**|**CamCo: Camera-Controllable 3D-Consistent Image-to-Video Generation**|最近，视频扩散模型已经成为普通用户容易获得的用于高质量视频内容创建的表达性生成工具。然而，这些模型通常不能为视频生成提供对相机姿势的精确控制，从而限制了电影语言和用户控制的表达。为了解决这个问题，我们介绍了CamCo，它允许细粒度的相机姿态控制用于图像到视频的生成。我们为预先训练好的图像到视频生成器配备了使用Pl“ucker坐标精确参数化的相机姿势输入。为了增强所生成视频的3D一致性，我们在每个注意力块中集成了一个极核注意力模块，该模块对特征图实施极核约束。此外，我们在真实世界的视频中微调CamCo，通过运动算法的结构估计相机姿势，以更好地合成物体运动。我们的实验表明，与以前的模型相比，CamCo显著提高了3D一致性和相机控制能力，同时有效地生成看似合理的物体运动。项目页面：https://ir1d.github.io/CamCo/ et.al.|[2406.02509](http://arxiv.org/abs/2406.02509)|null|
|**2024-06-04**|**Guiding a Diffusion Model with a Bad Version of Itself**|图像生成扩散模型中感兴趣的主轴是图像质量、结果的变化量以及结果与给定条件（例如类标签或文本提示）的一致性。流行的无分类器引导方法使用无条件模型来引导条件模型，以减少变化为代价，同时实现更好的即时对齐和更高质量的图像。这些影响似乎天生就纠缠在一起，因此很难控制。我们做出了令人惊讶的观察，即通过使用较小、训练较少的模型本身而不是无条件模型来指导生成，可以在不影响变化量的情况下获得对图像质量的解纠缠控制。这导致ImageNet生成的显著改进，使用公共网络，64x64和512x512的FID分别创下1.01和1.25的记录。此外，该方法也适用于无条件扩散模型，大大提高了它们的质量。 et.al.|[2406.02507](http://arxiv.org/abs/2406.02507)|null|
|**2024-06-04**|**Tensor Network Space-Time Spectral Collocation Method for Solving the Nonlinear Convection Diffusion Equation**|谱方法为偏微分方程提供了高精度的数值解，表现出随谱节点数量的指数收敛性。传统上，在处理含时非线性问题时，注意力集中在时间离散化的低阶有限差分格式和空间变量的谱元格式上。然而，我们最近的发展已经将谱方法应用于空间和时间变量，在这两个领域都保持了谱收敛性。利用张量训练技术，我们的方法解决了时空方法中固有的维度诅咒。在这里，我们将这种方法推广到非线性含时对流扩散方程。我们的离散化方案表现出低秩结构，便于转换为张量序列（TT）格式。然而，处理非线性所需的牛顿迭代中的TT秩的控制是一个挑战，导致我们设计了“阶跃截断TT牛顿”方法。我们通过各种基准示例展示了我们的方法的指数收敛性。重要的是，与全网格方案相比，我们的方案提供了显著降低的内存需求。 et.al.|[2406.02505](http://arxiv.org/abs/2406.02505)|null|
|**2024-06-04**|**Singular Subspace Perturbation Bounds via Rectangular Random Matrix Diffusions**|给定奇异值为 $\sigma_1\geq\cdots\geq\sigma_d$的矩阵$a\in\mathbb｛R｝^｛m\times d｝$，以及一些$T>0$的具有iid$N（0，T）$项的随机矩阵$G\in\math bb｛R｝^｝m\ttimes d｝$，我们导出了由$a$和$a+G$的顶部-$k$（右）奇异向量跨越的子空间之间的Frobenius距离的新界。这个问题出现在统计学中的许多应用中，其中数据矩阵可能被高斯噪声破坏，以及在差分隐私中的高斯机制的分析中，其中高斯噪声被添加到数据中以保存私有信息。我们证明，对于矩阵$A$，其中顶部-$k$奇异值中的间隙大约为$\Omega（\sigma_k-\sigma_｛k+1｝。为了获得我们的边界，我们将奇异向量的扰动视为一个扩散过程——戴森-贝塞尔过程——并使用随机微积分中的工具来跟踪顶部-$k$ 奇异向量所跨越的子空间的演化。 et.al.|[2406.02502](http://arxiv.org/abs/2406.02502)|null|
|**2024-06-04**|**Stable-Pose: Leveraging Transformers for Pose-Guided Text-to-Image Generation**|可控文本到图像（T2I）扩散模型在通过结合各种条件生成高质量视觉内容方面表现出了令人印象深刻的性能。然而，当前的方法在由骨架人体姿势引导时表现出有限的性能，特别是在复杂的姿势条件下，如人体的侧面或后方视角。为了解决这个问题，我们提出了稳定姿势，这是一种新的适配器模型，它在视觉转换器（ViT）中引入了从粗到细的注意力掩蔽策略，以获得T2I模型的精确姿势指导。Stable Pose旨在熟练处理预训练的Stable Diffusion中的姿势条件，为图像合成过程中对齐姿势表示提供了一种精细高效的方法。我们利用ViTs的查询键自注意机制来探索人体姿势骨骼中不同解剖部分之间的相互联系。遮罩姿势图像用于以分层方式基于目标姿势相关特征平滑地细化注意力图，从粗略级别过渡到精细级别。此外，我们的损失函数被公式化，以增加对姿势区域的重视，从而提高模型捕捉复杂姿势细节的精度。我们在五个公共数据集上评估了在各种室内和室外人体姿势场景下稳定姿势的性能。在LAION Human数据集中，Stable Pose的AP得分为57.1，比已建立的技术ControlNet提高了约13%。项目链接和代码位于https://github.com/ai-med/StablePose. et.al.|[2406.02485](http://arxiv.org/abs/2406.02485)|null|
|**2024-06-04**|**Inpainting Pathology in Lumbar Spine MRI with Latent Diffusion**|由于人群中病理学的低表示性和专家注释的成本，放射学中用于自动诊断的数据驱动模型存在数据集不足和不平衡的问题。数据集可以通过数据扩充得到支持。然而，即使在模型训练期间使用全套转换，典型的数据增强也不能解决人体解剖结构的变化。另一个方向是使用生成模型合成数据，该模型可以潜在地构建具有特定属性的数据集。虽然这是有希望的，但通常使用的生成模型，如生成对抗性网络，可能会无意中产生解剖学上不准确的特征。另一方面，提供更大稳定性的扩散模型倾向于记忆训练数据，这引发了人们对隐私和生成多样性的担忧。或者，修复有可能通过直接在医学图像中插入病理来增加数据。然而，这种方法带来了一个新的挑战：准确地将生成的病理特征与周围的解剖环境相融合。虽然修复是一种公认的解决简单病变的方法，但其在涉及复杂结构变化的病理学中的应用仍相对未被探索。我们提出了一种在MRI中通过潜在扩散模型中的体素噪声调度将病理特征修复到健康解剖结构上的有效方法。我们评估了该方法在腰椎矢状面T2 MRI中插入椎间盘突出和中央管狭窄的能力，与最先进的方法相比，它实现了优越的Frechet起始距离。 et.al.|[2406.02477](http://arxiv.org/abs/2406.02477)|null|
|**2024-06-04**|**Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems**|扩散模型可以从底层数据分布中学习强图像先验，并使用它们来解决逆问题，但训练过程计算成本高昂，需要大量数据。这样的瓶颈阻碍了大多数现有工作对于诸如3D图像的高维和高分辨率数据是可行的。本文提出了一种通过仅在图像块上训练扩散模型来学习整个图像的有效数据先验的方法。具体来说，我们提出了一种基于补丁的位置感知扩散逆求解器，称为PaDIS，其中我们通过补丁的分数及其位置编码来获得整个图像的分数函数，并将其作为求解逆问题的先验。首先，我们展示了这种扩散模型实现了改进的存储效率和数据效率，同时仍然保持了通过位置编码生成整个图像的能力。此外，所提出的PaDIS模型具有高度的灵活性，可以插入不同的扩散逆解器（DIS）。我们证明，所提出的PaDIS方法能够解决自然和医学图像领域的各种逆问题，包括CT重建、去模糊和超分辨率，仅在给定基于补丁的先验的情况下。值得注意的是，在训练数据有限的情况下，PaDIS优于之前在整个图像先验上训练的DIS方法，证明了我们通过学习基于补丁的先验提出的方法的数据效率。 et.al.|[2406.02462](http://arxiv.org/abs/2406.02462)|null|

<p align=right>(<a href=#updated-on-20240606>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-04**|**A fast neural emulator for interstellar chemistry**|天体化学模型是解释不同环境中分子和原子物种观测结果的重要工具。然而，这些模型非常耗时，妨碍了对参数空间的彻底探索，导致了不确定性和偏差结果。使用神经网络来模拟天体化学模型的行为是规避这一问题的一种方法，它可以基于真实的天体化学模型提供快速计算。在本文中，我们提出了一个基于条件神经场的天文化学代码Nautilus的快速神经模拟器。由此产生的模型在1到10 $^7$年之间的任意时间内产生了192种物种的丰度。所有物种的不确定性都远低于0.2 dex，而计算时间比Nautilus小10$^4$ 。这将为执行更复杂的正向模型以更好地了解星际介质的物理性质开辟可能性。作为这些模型威力的一个例子，我们对Nautilus预测的电子丰度进行了特征重要性分析。我们发现，在低密度气体中，电子密度与初始硫丰度有关。将初始硫丰度从耗尽的情况增加到宇宙丰度会导致电子密度增加一个数量级。这种增强可能会对恒星形成地点的气体动力学产生潜在影响。 et.al.|[2406.02387](http://arxiv.org/abs/2406.02387)|null|
|**2024-06-05**|**AROMA: Preserving Spatial Structure for Latent PDE Modeling with Local Neural Fields**|我们提出了AROMA（带注意力的注意力降阶模型），这是一个旨在使用局部神经场增强偏微分方程（PDE）建模的框架。我们灵活的编码器-解码器架构可以从各种数据类型中获得空间物理场的平滑潜在表示，包括不规则网格输入和点云。这种多功能性消除了打补丁的需要，并允许高效处理各种几何形状。我们的潜在表示的顺序性质可以在空间上进行解释，并允许使用条件转换器来建模偏微分方程的时间动力学。通过采用基于扩散的公式，与传统的MSE训练相比，我们实现了更大的稳定性，并实现了更长的推广时间。AROMA在模拟1D和2D方程方面的卓越性能突显了我们的方法在捕捉复杂动力学行为方面的有效性。 et.al.|[2406.02176](http://arxiv.org/abs/2406.02176)|null|
|**2024-06-04**|**Activity patterns in ring networks of quadratic integrate-and-fire neurons with synaptic and gap junction coupling**|我们考虑具有非局部突触和间隙连接耦合的二次积分和激发神经元的环形网络。相应的神经场模型支持驻波和行波以及倾斜波等解决方案。我们证明了这些解中的许多都满足自洽方程，当参数变化时，自洽方程可以用来跟随它们。我们对神经场模型进行了数值分叉分析，重点研究了不同间隙结耦合强度的影响。我们的方法通常适用于各种各样的二次积分和激发神经元网络。 et.al.|[2406.01881](http://arxiv.org/abs/2406.01881)|null|
|**2024-06-03**|**Enhancing Dynamic CT Image Reconstruction with Neural Fields Through Explicit Motion Regularizers**|具有高度欠采样数据的动态逆问题的图像重建提出了一个主要挑战：不考虑过程的动力学会导致没有时间规律的不真实运动。已经提出了惩罚时间导数或引入运动模型正则化子的变分方法，以使用基于网格的离散化来关联后续帧并提高图像质量。神经场通过深度神经网络提供了所需时空量的替代参数化，这是一种轻量级、连续且偏向于平滑表示的网络。归纳偏差已被用于增强动态逆问题的时间规律性，从而仅通过最小化数据保真度项来优化神经场。在本文中，我们研究并展示了在2D+时间计算机断层扫描中引入基于显式PDE的运动正则化子，即光流方程，用于优化神经场的好处。我们还将神经场与基于网格的求解器进行了比较，并表明前者的性能优于后者。 et.al.|[2406.01299](http://arxiv.org/abs/2406.01299)|null|
|**2024-06-03**|**Pattern Formation in a Spiking Neural-Field of Renewal Neurons**|阐明神经模式形成背后的神经生理学机制仍然是计算神经科学中的一个突出挑战。在这篇论文中，我们通过考虑更新神经元网络来解决理解神经模式出现的问题，更新神经元是一类公认的尖峰细胞。在热力学极限下，网络的动力学可以精确地用一个偏微分方程和一个非局部微分方程来表示。确定了非局部系统的稳态，并进行了扰动分析，以分析表征图灵不稳定性发生的条件。考虑到突触耦合和外部驱动等神经网络参数，我们用数值方法获得了将异步状态与模式出现分开的分叉线。我们的理论发现为尖峰神经网络中图灵模式的出现提供了一个新的、有见地的视角。从长远来看，我们的形式主义将能够研究神经模式，同时保持微观细胞特性、网络耦合和图灵不稳定性的出现之间的联系。 et.al.|[2406.01167](http://arxiv.org/abs/2406.01167)|null|
|**2024-06-02**|**Representing Animatable Avatar via Factorized Neural Fields**|对于从单眼视频中重建高保真度的人体3D模型，保持一致的大规模体型以及精细匹配的细微皱纹至关重要。本文探讨了以下观察结果，即每帧渲染结果可以分解为与姿势无关的分量和相应的与姿势相关的等价物，以促进帧一致性。通过限制这两个分量的频带，可以进一步改进姿态自适应纹理。详细地说，与姿势无关的输出预计是低频的，而高频信息与姿势相关因素有关。我们通过具有不同频率分量的双分支网络实现了整个输入视频的粗体轮廓和时变的细粒度纹理特征的连贯保存。第一分支以规范空间中的坐标作为输入，而第二分支另外考虑由第一分支输出的特征和每个帧的姿态信息。我们的网络整合了两个分支预测的信息，并利用体积渲染生成照片逼真的3D人体图像。通过实验，我们证明了我们的网络在保留高频细节和确保身体轮廓一致方面超越了基于神经辐射场（NeRF）的最先进方法。 et.al.|[2406.00637](http://arxiv.org/abs/2406.00637)|null|
|**2024-05-31**|**Neural Gaussian Scale-Space Fields**|高斯尺度空间是信号表示和处理的基石，在滤波、多尺度分析、抗混叠等方面都有应用。然而，获得这样的尺度空间是昂贵和繁琐的，特别是对于诸如神经场的连续表示。我们提出了一种有效且轻量级的方法来学习任意信号的全连续、各向异性高斯尺度空间。基于傅立叶特征调制和Lipschitz边界，我们的方法是自监督训练的，即训练不需要任何手动滤波。我们的神经高斯尺度空间场忠实地捕捉各种模态的多尺度表示，并支持多种应用。其中包括图像、几何、光台数据、纹理抗锯齿和多尺度优化。 et.al.|[2405.20980](http://arxiv.org/abs/2405.20980)|null|
|**2024-05-30**|**Gated Fields: Learning Scene Reconstruction from Gated Videos**|根据时间观测重建户外3D场景是一项挑战，最近在神经领域的工作为其提供了一条新的途径。然而，仅从RGB捕获恢复场景属性（如几何体、外观或辐射）的现有方法在处理光线不足或纹理不足的区域时往往会失败。同样，使用扫描激光雷达传感器恢复场景也很困难，因为它们的角采样率较低，这使得恢复广阔的真实世界场景变得困难。为了解决这些差距，我们介绍了门控场——一种利用主动门控视频序列的神经场景重建方法。为此，我们提出了一种无缝结合时间门控捕获和照明的神经渲染方法。我们的方法利用了门控视频中的内在深度线索，无论环境照明条件如何，都能实现精确而密集的几何重建。我们在昼夜场景中验证了该方法，并发现门控场与RGB和激光雷达重建方法相比是有利的。我们的代码和数据集可在https://light.princeton.edu/gatedfields/. et.al.|[2405.19819](http://arxiv.org/abs/2405.19819)|null|
|**2024-06-04**|**Extreme Compression of Adaptive Neural Images**|隐式神经表示（INRs）和神经场是一种新的信号表示范式，从图像和音频到3D场景和视频。其基本思想是将信号表示为连续且可微分的神经网络。这一思想提供了前所未有的优势，如连续分辨率和存储效率，从而实现了新的压缩技术。然而，将数据表示为神经网络带来了新的挑战。例如，给定一个2D图像作为神经网络，我们如何进一步压缩这样的神经图像？。在这项工作中，我们提出了一种新的压缩神经场的分析，重点是图像。我们还介绍了自适应神经图像（ANI），这是一种有效的神经表示，能够适应不同的推理或传输要求。我们提出的方法可以将神经图像的每像素比特数（bpp）减少4倍，而不会丢失敏感细节或损害保真度。我们之所以能做到这一点，是因为我们成功地实现了4位神经表示。我们的工作为开发压缩神经场提供了一个新的框架。 et.al.|[2405.16807](http://arxiv.org/abs/2405.16807)|null|
|**2024-05-24**|**Blaze3DM: Marry Triplane Representation with Diffusion for 3D Medical Inverse Problem Solving**|解决图像恢复和重建等三维医学逆问题在现代医学领域至关重要。然而，3D医疗数据中的维度诅咒导致主流的体积方法遭受高资源消耗，并挑战模型成功捕捉自然分布，导致不可避免的体积不一致和伪影。最近的一些工作试图简化潜在空间中的生成，但缺乏对复杂图像细节进行有效建模的能力。为了解决这些局限性，我们提出了Blaze3DM，这是一种新的方法，通过集成紧凑的三平面神经场和强大的扩散模型，实现了快速高保真的生成。在技术上，Blaze3DM首先同时优化数据相关的三平面嵌入和共享解码器，将每个三平面重建回相应的3D体积。为了进一步增强3D一致性，我们引入了一个轻量级的3D感知模块来对三个垂直平面的相关性进行建模。然后，在潜在的三平面嵌入上训练扩散模型，并实现无条件和有条件的三平面生成，最终解码为任意大小的体积。对零样本三维医学逆问题求解的大量实验，包括稀疏视图CT、有限角度CT、压缩传感MRI和MRI各向同性超分辨率，表明Blaze3DM不仅实现了最先进的性能，而且显著提高了现有方法的计算效率（比以前的工作快22~40倍）。 et.al.|[2405.15241](http://arxiv.org/abs/2405.15241)|null|

<p align=right>(<a href=#updated-on-20240606>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

