[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.09.02
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-08-30**|**Autonomous damage assessment of structural columns using low-cost micro aerial vehicles and multi-view computer vision**|结构柱是建筑和桥梁的重要承载构件。柱损坏的早期检测对于评估剩余性能和防止系统级崩溃非常重要。本研究提出了一种创新的基于端到端微型飞行器（MAV）的方法来自动扫描和检查立柱。首先，提出了一种基于MAV的图像自动采集方法。MAV被编程为感应结构柱及其周围环境。在导航过程中，MAV首先检测并接近结构柱。然后，它开始收集每个检测到的列周围多个视点的图像数据。其次，收集的图像将用于评估损坏类型和损坏位置。第三，将通过融合多个摄像机视图的评估结果来确定结构柱的损伤状态。在本研究中，选择钢筋混凝土（RC）柱来证明该方法的有效性。实验结果表明，所提出的基于MAV的检测方法可以有效地从多个视角采集图像，并准确评估RC柱的临界损伤。该方法提高了检查期间的自主权水平。此外，评估结果比现有的2D视觉方法更全面。所提出的检查方法的概念可以扩展到其他结构柱，如桥墩。 et.al.|[2308.16278](http://arxiv.org/abs/2308.16278)|null|
|**2023-08-30**|**Learning Structure-from-Motion with Graph Attention Networks**|在本文中，我们通过使用图注意力网络来解决从运动中学习结构（SfM）的问题。SfM是一个经典的计算机视觉问题，通过迭代最小化重投影误差来解决，称为束调整（BA），从良好的初始化开始。为了获得对BA足够好的初始化，传统方法依赖于一系列子问题（如成对姿态估计、姿态平均或三角测量），这些子问题提供了一个初始解决方案，然后可以使用BA进行细化。在这项工作中，我们通过学习一个模型来替换这些子问题，该模型将在多个视图中检测到的2D关键点作为输入，并输出相应的相机姿势和3D关键点坐标。我们的模型利用图神经网络来学习SfM特定的基元，并表明它可以用于新的和看不见的序列的重建的快速推理。实验结果表明，所提出的模型优于竞争的基于学习的方法，并在具有较低运行时间的同时挑战了COLMAP。 et.al.|[2308.15984](http://arxiv.org/abs/2308.15984)|null|
|**2023-08-29**|**3D-MuPPET: 3D Multi-Pigeon Pose Estimation and Tracking**|动物姿势跟踪的无标记方法最近得到了发展，但在3D中跟踪大型动物群体的框架和基准仍然缺乏。为了克服文献中的这一空白，我们提出了3D MuPPET，这是一个使用多个视图以交互式速度估计和跟踪多达10只鸽子的3D姿势的框架。我们训练姿势估计器来推断多只鸽子的2D关键点和边界框，然后将关键点三角化为3D。对于对应匹配，我们首先将2D检测与第一帧中的全局身份动态匹配，然后使用2D跟踪器来维护后续帧中跨视图的对应关系。对于均方根误差（RMSE）和正确关键点百分比（PCK），我们实现了与现有技术的3D姿态估计器相当的精度。我们还展示了一个新颖的用例，其中我们的模型用单个鸽子的数据训练，在包含多只鸽子的数据上提供了可比较的结果。这可以简化向新物种的领域转移，因为注释单个动物数据比注释多动物数据劳动密集度低。此外，我们对3D MuPPET的推理速度进行了基准测试，在2D中高达10fps，在3D中高达1.5fps，并进行了定量跟踪评估，这产生了令人鼓舞的结果。最后，我们展示了3D MuPPET在自然环境中也能工作，而无需对附加注释进行模型微调。据我们所知，我们是第一个提出适用于室内和室外环境的2D/3D姿势和轨迹跟踪框架的公司。 et.al.|[2308.15316](http://arxiv.org/abs/2308.15316)|null|
|**2023-08-29**|**Pose-Free Neural Radiance Fields via Implicit Pose Regularization**|无姿态神经辐射场（NeRF）旨在用未经处理的多视图图像训练NeRF，近年来取得了令人印象深刻的成功。大多数现有工作共享一个管道，首先用渲染图像训练粗略的姿态估计器，然后联合优化估计的姿态和神经辐射场。然而，由于姿态估计器仅用渲染图像进行训练，由于真实图像和渲染图像之间的域间隙，姿态估计通常对真实图像有偏差或不准确，导致真实图像的姿态估计鲁棒性差，并且在联合优化中存在进一步的局部最小值。我们设计了IR NeRF，这是一种创新的无姿态NeRF，它引入了隐式姿态正则化来改进未聚焦真实图像的姿态估计器，并提高了真实图像姿态估计的鲁棒性。通过特定场景的2D图像的集合，IR NeRF构建了一个场景码本，该场景码本存储场景特征，并隐式地捕捉特定场景的姿势分布作为先验。因此，根据只有当2D真实图像的估计姿势位于姿势分布内时才可以从场景码本很好地重建2D真实图像这一原理，可以利用场景先验来提高姿势估计的鲁棒性。大量实验表明，IR NeRF实现了卓越的新视图合成，并在多个合成和真实数据集上始终优于最先进的视图合成。 et.al.|[2308.15049](http://arxiv.org/abs/2308.15049)|null|
|**2023-08-28**|**CLNeRF: Continual Learning Meets NeRF**|新颖的视图合成旨在呈现给定一组校准图像的看不见的视图。在实际应用中，场景的覆盖范围、外观或几何结构可能会随着时间的推移而变化，不断捕捉新的图像。有效地整合这种持续的变化是一个公开的挑战。标准NeRF基准测试仅涉及场景覆盖范围的扩展。为了研究其他实际的场景变化，我们提出了一个新的数据集，即跨时间世界（WAT），由外观和几何结构随时间变化的场景组成。我们还提出了一种简单而有效的方法CLNeRF，它将连续学习（CL）引入到神经辐射场（NeRF）中。CLNeRF结合了生成回放和即时神经图形原件（NGP）架构，以有效防止灾难性遗忘，并在新数据到达时有效更新模型。我们还向NGP添加了可训练的外观和几何嵌入，允许单个紧凑模型处理复杂的场景变化。在不需要存储历史图像的情况下，在变化场景的多次扫描上顺序训练的CLNeRF与在一次所有扫描上训练的上界模型性能相当。与其他CL基线相比，CLNeRF在标准基准和WAT上的表现要好得多。源代码和WAT数据集可在https://github.com/IntelLabs/CLNeRF.视频演示可在以下网址获得：https://youtu.be/nLRt6OoDGq0?si=8yD6k-8MMBJInQP et.al.|[2308.14816](http://arxiv.org/abs/2308.14816)|**[link](https://github.com/intellabs/clnerf)**|
|**2023-08-28**|**Flexible Techniques for Differentiable Rendering with 3D Gaussians**|快速、可靠的形状重建是许多计算机视觉应用中的重要组成部分。Neural Radiance Fields证明，真实感的新视图合成是触手可及的，但受到真实场景和对象快速重建性能要求的限制。最近的一些方法建立在替代形状表示的基础上，特别是3D高斯。我们开发了这些渲染器的扩展，例如集成可微分光流、导出防水网格和渲染每光线法线。此外，我们还展示了最近的两种方法是如何相互操作的。这些重建快速、稳健，并且可以在GPU或CPU上轻松执行。有关代码和可视化示例，请参见https://leonidk.github.io/fmb-plus et.al.|[2308.14737](http://arxiv.org/abs/2308.14737)|null|
|**2023-08-27**|**Depth self-supervision for single image novel view synthesis**|在本文中，我们解决了在给定单个帧作为输入的情况下从任意视点生成新图像的问题。虽然在这种设置中操作的现有方法旨在预测目标视图深度图以指导合成，但在没有明确监督此类任务的情况下，我们共同优化了新视图合成和深度估计的框架，以最大限度地释放两者之间的协同作用。具体地，以自监督的方式训练共享深度解码器，以预测在源视图和目标视图中一致的深度图。我们的结果证明了我们的方法在解决这两项任务的挑战方面的有效性，这两项工作允许生成更高质量的图像，并为目标视点提供更准确的深度。 et.al.|[2308.14108](http://arxiv.org/abs/2308.14108)|**[link](https://github.com/johnminelli/twowaysynth)**|
|**2023-08-27**|**Sparse3D: Distilling Multiview-Consistent Diffusion for Object Reconstruction from Sparse Views**|从极其稀疏的视图重建3D对象是一个长期存在且具有挑战性的问题。虽然最近的技术使用图像扩散模型来在新视点生成看似合理的图像，或者使用分数蒸馏采样（SDS）将预先训练的扩散先验提取到3D表示中，但这些方法通常难以同时实现新视点合成（NVS）和几何体的高质量、一致和详细的结果。在这项工作中，我们提出了Sparse3D，这是一种为稀疏视图输入量身定制的新型3D重建方法。我们的方法从多视点一致扩散模型中提取鲁棒先验，以细化神经辐射场。具体来说，我们使用了一个控制器，该控制器利用输入视图中的核线特征，引导预先训练的扩散模型，如稳定扩散，以生成与输入保持3D一致性的新视图图像。通过利用强大的图像扩散模型中的2D先验，我们的集成模型即使在面对开放世界对象时也能始终如一地提供高质量的结果。为了解决传统SDS引入的模糊性，我们引入了类别分数蒸馏采样（C-SDS）来增强细节。我们在CO3DV2上进行了实验，这是一个真实世界对象的多视图数据集。定量和定性评估都表明，我们的方法在NVS和几何重建方面优于以往最先进的工作。 et.al.|[2308.14078](http://arxiv.org/abs/2308.14078)|null|
|**2023-08-25**|**ReST: A Reconfigurable Spatial-Temporal Graph Model for Multi-Camera Multi-Object Tracking**|多摄像机多目标跟踪（MC-MOT）利用来自多个视图的信息来更好地处理遮挡和拥挤场景的问题。最近，使用基于图的方法来解决跟踪问题变得非常流行。然而，当前许多基于图的方法不能有效地利用关于空间和时间一致性的信息。相反，它们依赖于单摄像头跟踪器作为输入，这很容易出现碎片和ID切换错误。在本文中，我们提出了一种新的可重构图模型，该模型首先在空间上关联摄像机上所有检测到的对象，然后将其重新配置为用于时间关联的时间图。这种两阶段关联方法使我们能够提取强大的空间和时间感知特征，并解决碎片化轨迹的问题。此外，我们的模型是为在线跟踪而设计的，适用于现实世界中的应用。实验结果表明，所提出的图模型能够提取更多的判别特征用于对象跟踪，并且我们的模型在几个公共数据集上达到了最先进的性能。 et.al.|[2308.13229](http://arxiv.org/abs/2308.13229)|**[link](https://github.com/chengche6230/rest)**|
|**2023-08-24**|**NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes**|最近的隐式神经表示在新的视图合成中显示出了很好的结果。然而，现有的方法需要从许多视图进行昂贵的每场景优化，因此限制了它们在真实世界的无边界城市环境中的应用，在这些环境中，从极少数视图观察到感兴趣的对象或背景。为了缓解这一挑战，我们引入了一种名为NeO360的新方法，用于户外场景稀疏视图合成的神经场。NeO 360是一种可推广的方法，它从单个或几个摆出姿势的RGB图像重建360｛\deg｝场景。我们方法的本质是捕捉复杂的真实世界户外3D场景的分布，并使用可以从任何世界点查询的混合图像条件三平面表示。我们的表示结合了基于体素和鸟瞰图（BEV）的最佳表示，比每种表示都更有效、更具表现力。NeO 360的表示使我们能够从大量无界3D场景中学习，同时在推理过程中从一张图像中提供对新视图和新场景的可推广性。我们在所提出的具有挑战性的360｛\deg｝无界数据集NeRDS 360上演示了我们的方法，并表明NeO 360在新视图合成方面优于最先进的可推广方法，同时还提供编辑和合成功能。项目页面：https://zubair-irshad.github.io/projects/neo360.html et.al.|[2308.12967](http://arxiv.org/abs/2308.12967)|**[link](https://github.com/zubair-irshad/NeO-360)**|
|**2023-08-24**|**Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis**|静息状态功能性MRI（rs-fMRI）越来越多地用于多部位研究，以帮助神经系统疾病分析。现有研究通常存在由站点效应（如扫描仪/协议的差异）引起的显著跨站点/领域数据异质性。已经提出了许多方法来减少源域和目标域之间的fMRI异质性，这在很大程度上依赖于源数据的可用性。但是，由于多站点研究中的隐私问题和/或数据存储负担，获取源数据具有挑战性。为此，我们设计了一个用于fMRI分析的无源协作域自适应（SCDA）框架，其中只有预训练的源模型和未标记的目标数据是可访问的。具体而言，开发了一种用于目标fMRI分析的多视角特征富集方法（MFE），该方法由多个协作分支组成，用于从多个视图动态捕获未标记目标数据的fMRI特征。每个分支都有一个数据馈送模块、一个时空特征编码器和一个类预测器。设计了相互一致性约束，以鼓励从这些分支生成的相同输入的潜在特征的成对一致性，用于鲁棒表示学习。为了在没有源数据的情况下促进有效的跨领域知识转移，我们使用预训练的源模型的参数初始化MFE。我们还介绍了一种无监督预训练策略，使用来自三个大型辅助数据库的3806个未标记的fMRI，旨在获得通用特征编码器。在三个公共数据集和一个私人数据集上的实验结果证明了我们的方法在交叉扫描和交叉研究预测任务中的有效性。在大规模rs fMRI数据上预训练的模型已经向公众发布。 et.al.|[2308.12495](http://arxiv.org/abs/2308.12495)|**[link](https://github.com/yqfang9199/scda)**|
|**2023-08-23**|**ARF-Plus: Controlling Perceptual Factors in Artistic Radiance Fields for 3D Scene Stylization**|辐射场风格转移是一个新兴的领域，由于神经辐射场在三维重建和视图合成中的出色表现，作为三维场景风格化的一种手段，它最近受到了欢迎。我们强调了在辐射场风格转移方面的研究空白，即缺乏足够的感知可控性，这是由2D图像风格转移中的现有概念所驱动的。在本文中，我们提出了ARF Plus，一个对感知因素提供可管理控制的3D神经风格转移框架，以系统地探索3D场景风格化中的感知可控性。提出了四种不同类型的控制——颜色保持控制、（风格模式）比例控制、空间（选择性风格化区域）控制和深度增强控制——并将其集成到该框架中。来自真实世界数据集的定量和定性结果表明，在对3D场景进行风格化时，我们的ARF Plus框架中的四种类型的控件成功地实现了相应的感知控件。这些技术适用于单个样式输入以及场景中多个样式的同时应用。这开启了一个无限可能性的领域，允许对风格化效果进行定制修改，并灵活融合不同风格的优势，最终能够在3D场景中创造新颖而引人注目的风格效果。 et.al.|[2308.12452](http://arxiv.org/abs/2308.12452)|null|
|**2023-08-24**|**A Visualization System for Hexahedral Mesh Quality Study**|在本文中，我们介绍了一种新的三维十六进制网格视觉分析系统，该系统通过聚合字形强调质量较差的区域，突出重叠元素，并以三种形式提供详细的边界误差检查。通过支持多视图的多级分析，我们的系统有效地评估了各种网格模型，并比较了六面体网格的网格生成和优化算法的性能。 et.al.|[2308.12158](http://arxiv.org/abs/2308.12158)|null|
|**2023-08-22**|**Enhancing NeRF akin to Enhancing LLMs: Generalizable NeRF Transformer with Mixture-of-View-Experts**|跨场景可推广的NeRF模型可以直接合成看不见场景的新视图，已成为NeRF领域的一个新焦点。现有的几种尝试依赖于越来越端到端的“神经化”架构，即用变压器等高性能神经网络取代场景表示和/或渲染模块，并将新颖的视图合成转化为前馈推理管道。虽然这些前馈“神经化”架构仍然不能很好地开箱即用地适应不同的场景，但我们建议将它们与来自大型语言模型（LLM）的强大的专家混合（MoE）思想联系起来，该思想通过在更大的整体模型容量和灵活的每实例专业化之间进行平衡，展示了卓越的泛化能力。从最近一种名为GNT的可推广NeRF架构开始，我们首先证明了MoE可以巧妙地插入以增强模型。我们进一步定制了共享的永久专家和几何体感知的一致性损失，以分别增强跨场景一致性和空间平滑性，这对于可推广的视图合成至关重要。我们提出的模型被称为GNT with Mixture-of-View-Experts（GNT-MOVE），在转移到看不见的场景时，实验显示了最先进的结果，表明在零样本和少拍摄设置中都有更好的跨场景泛化。我们的代码可在https://github.com/VITA-Group/GNT-MOVE. et.al.|[2308.11793](http://arxiv.org/abs/2308.11793)|**[link](https://github.com/vita-group/gnt-move)**|
|**2023-08-22**|**IT3D: Improved Text-to-3D Generation with Explicit View Synthesis**|从强大的大型文本到图像扩散模型（LDM）中提取知识，推动了文本到3D技术的最新进展。尽管如此，现有的文本到3D方法经常会遇到诸如过度饱和、细节不足和不切实际的输出等挑战。这项研究提出了一种新的策略，利用显式合成的多视图图像来解决这些问题。我们的方法涉及利用LDM授权的图像到图像管道，以基于粗略3D模型的渲染生成高质量的图像。尽管生成的图像在很大程度上缓解了上述问题，但由于大扩散模型固有的生成性质，诸如视图不一致和显著的内容差异等挑战仍然存在，这给有效利用这些图像带来了巨大的困难。为了克服这一障碍，我们主张将鉴别器与新的扩散GAN双重训练策略相结合，以指导3D模型的训练。对于合并的鉴别器，合成的多视图图像被视为真实数据，而优化的3D模型的渲染则充当假数据。我们进行了一系列全面的实验，证明了我们的方法相对于基线方法的有效性。 et.al.|[2308.11473](http://arxiv.org/abs/2308.11473)|**[link](https://github.com/buaacyw/it3d-text-to-3d)**|
|**2023-08-22**|**ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes**|我们展示了ScanNet++，这是一个大规模的数据集，将室内场景的高质量和商品级几何图形和颜色的捕捉结合在一起。每个场景都是用亚毫米分辨率的高端激光扫描仪拍摄的，还有来自单反相机的3300万像素图像和来自iPhone的RGB-D流。场景重建进一步用开放的语义词汇表进行注释，明确注释标签模糊场景以进行全面的语义理解。ScanNet++为新视图合成提供了一个新的现实世界基准，既有高质量的RGB捕获，也有重要的商品级图像，此外还有一个全面封装多样和模糊语义标记场景的3D语义场景理解新基准。目前，ScanNet++包含460个场景、28万张单反图像和370多万个iPhone RGBD帧。 et.al.|[2308.11417](http://arxiv.org/abs/2308.11417)|null|
|**2023-08-22**|**Enhancing Interpretable Object Abstraction via Clustering-based Slot Initialization**|使用槽的以对象为中心的表示显示了从合成场景中的低级感知特征向高效、灵活和可解释的抽象的发展。当前的方法随机化时隙的初始状态，然后进行迭代细化。正如我们在本文中所展示的，随机时隙初始化显著影响最终时隙预测的准确性。此外，当前的方法需要来自数据的先验知识的预定数量的时隙，这限制了在现实世界中的适用性。在我们的工作中，我们使用以感知输入特征为条件的聚类算法来初始化槽表示。这需要体系结构中的一个附加层来初始化给定已识别集群的插槽。我们设计了该层的置换不变和置换等变版本，以实现聚类后的可交换槽表示。此外，我们使用均值偏移聚类来自动识别给定场景的槽数。我们评估了我们在各种数据集的对象发现和新视图合成任务上的方法。结果表明，我们的方法始终优于先前的工作，尤其是在复杂场景下。 et.al.|[2308.11369](http://arxiv.org/abs/2308.11369)|null|
|**2023-08-22**|**Novel-view Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views**|在沉浸式通信中，手与物体的交互理解和几乎没有解决的新颖视角合成是非常需要的，而由于手的高度变形和手与物体之间的严重遮挡，这是具有挑战性的。在本文中，我们提出了一种用于稀疏视图中手-物体交互的神经渲染和姿态估计系统，该系统还可以实现3D手-物体的交互编辑。我们分享了最近场景理解工作的灵感，该工作表明，预先建立的特定场景模型可以显著改善和解锁视觉任务，尤其是在输入稀疏的情况下，并将其扩展到动态手-物交互场景中，并提出分两个阶段解决问题。我们首先在离线阶段使用神经表示分别学习手和物体的形状和外观先验知识。在在线阶段，我们设计了一个基于渲染的联合模型拟合框架，以了解手与对象的动态交互与预先构建的手与对象模型以及交互先验，从而克服了手与对象之间的渗透和分离问题，并实现了新的视图合成。为了在一个序列中的手-物体交互过程中获得稳定的接触，我们提出了一个稳定的接触损失，以使接触区域一致。实验表明，我们的方法优于最先进的方法。项目网页中提供了代码和数据集https://iscas3dv.github.io/HO-NeRF. et.al.|[2308.11198](http://arxiv.org/abs/2308.11198)|null|
|**2023-08-22**|**Efficient View Synthesis with Neural Radiance Distribution Field**|最近对神经辐射场（NeRF）的研究表明，在高质量视图合成方面取得了重大进展。NeRF的一个主要限制是由于需要多个网络转发来渲染单个像素，因此其渲染效率较低。现有的改进NeRF的方法要么减少所需样本的数量，要么优化实现以加速网络转发。尽管做出了这些努力，但由于辐射场的固有表示，多次采样的问题仍然存在。相反，神经光场（NeLF）通过每像素仅查询一个单个网络转发来降低NeRF的计算成本。为了实现与NeRF接近的视觉质量，现有的NeLF方法需要更大的网络容量，这限制了它们在实践中的渲染效率。在这项工作中，我们提出了一种称为神经辐射分布场（NeRDF）的新表示，该表示以实时有效的视图合成为目标。具体来说，我们使用类似于NeRF的小型网络，同时通过像NeLF中那样的每像素单个网络转发来保持渲染速度。关键是用频率基对每条射线的辐射分布进行建模，并使用网络预测频率权重。然后通过对辐射分布进行体积渲染来计算像素值。实验表明，与现有方法相比，我们提出的方法在速度、质量和网络大小之间提供了更好的权衡：在类似网络大小的情况下，我们比NeRF实现了~254倍的加速，性能仅略有下降。我们的项目页面位于yushung-wu.github.io/NeRDF。 et.al.|[2308.11130](http://arxiv.org/abs/2308.11130)|null|
|**2023-08-23**|**Information Theory-Guided Heuristic Progressive Multi-View Coding**|多视图表示学习旨在从共享上下文的多个视图中获取综合信息。最近的工作以成对的方式将对比学习直观地应用于不同的视图，这仍然是可扩展的：在学习视图共享表示时，视图特定的噪声没有被过滤；假负对，其中负项实际上与正项在同一类中，而真负对被同等对待；均匀地测量术语之间的相似性可能会干扰优化。重要的是，很少有作品研究广义自监督多视角学习的理论框架，尤其是两种以上的视角。为此，我们从信息论的角度重新思考了现有的多视角学习范式，并提出了一个新的广义多视角学习的信息理论框架。在此基础上，我们构建了一种具有三层渐进结构的多视图编码方法，即信息论引导的分层渐进多视图编码（IPMC）。在分布层中，IPMC将视图之间的分布对齐，以减少视图特定的噪声。在设置层中，IPMC构建自调整对比池，并通过视图过滤器进行自适应修改。最后，在实例层，我们采用设计的统一损失来学习表示，并减少梯度干扰。从理论和经验上，我们证明了IPMC优于最先进的方法。 et.al.|[2308.10522](http://arxiv.org/abs/2308.10522)|null|

<p align=right>(<a href=#updated-on-20230902>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-08-29**|**Intensity correlation holography for remote phase sensing and 3D imaging**|全息是一种通过与参考波的干涉组合来测量光学信号波前的既定技术。传统上，全息图的积分时间受到干涉仪相干时间的限制，因此制备远程物体的全息图具有挑战性，尤其是使用弱照明。在这里，我们通过使用强度相关干涉测量法来规避这一限制。尽管单个全息图的曝光时间必须短于干涉仪相干时间，但我们表明，任何数量的随机相移全息图都可以组合成单个强度相关全息图。在原理验证实验中，我们使用该技术在弱照明和无主动相位稳定的情况下，对距离约3m的物体进行相位成像和3D重建。 et.al.|[2308.15619](http://arxiv.org/abs/2308.15619)|null|
|**2023-08-28**|**R3D3: Dense 3D Reconstruction of Dynamic Scenes from Multiple Cameras**|密集的三维重建和自我运动估计是自动驾驶和机器人技术的关键挑战。与当今部署的复杂、多模态系统相比，多摄像头系统提供了一种更简单、低成本的替代方案。然而，基于相机的复杂动态场景的3D重建已被证明是极其困难的，因为现有的解决方案往往会产生不完整或不连贯的结果。我们提出了R3D3，一种用于密集3D重建和自我运动估计的多摄像机系统。我们的方法在利用来自多个相机的时空信息的几何估计和单目深度细化之间迭代。我们集成了多相机特征相关性和密集束调整算子，以产生稳健的几何深度和姿态估计。为了改进几何深度不可靠的重建，例如对于移动对象或低纹理区域，我们通过深度细化网络引入了可学习的场景先验。我们展示了这种设计能够对具有挑战性的动态户外环境进行密集、一致的3D重建。因此，我们在DDAD和NuScenes基准上实现了最先进的密集深度预测。 et.al.|[2308.14713](http://arxiv.org/abs/2308.14713)|null|
|**2023-08-27**|**Sparse3D: Distilling Multiview-Consistent Diffusion for Object Reconstruction from Sparse Views**|从极其稀疏的视图重建3D对象是一个长期存在且具有挑战性的问题。虽然最近的技术使用图像扩散模型来在新视点生成看似合理的图像，或者使用分数蒸馏采样（SDS）将预先训练的扩散先验提取到3D表示中，但这些方法通常难以同时实现新视点合成（NVS）和几何体的高质量、一致和详细的结果。在这项工作中，我们提出了Sparse3D，这是一种为稀疏视图输入量身定制的新型3D重建方法。我们的方法从多视点一致扩散模型中提取鲁棒先验，以细化神经辐射场。具体来说，我们使用了一个控制器，该控制器利用输入视图中的核线特征，引导预先训练的扩散模型，如稳定扩散，以生成与输入保持3D一致性的新视图图像。通过利用强大的图像扩散模型中的2D先验，我们的集成模型即使在面对开放世界对象时也能始终如一地提供高质量的结果。为了解决传统SDS引入的模糊性，我们引入了类别分数蒸馏采样（C-SDS）来增强细节。我们在CO3DV2上进行了实验，这是一个真实世界对象的多视图数据集。定量和定性评估都表明，我们的方法在NVS和几何重建方面优于以往最先进的工作。 et.al.|[2308.14078](http://arxiv.org/abs/2308.14078)|null|
|**2023-08-27**|**Multi-plane denoising diffusion-based dimensionality expansion for 2D-to-3D reconstruction of microstructures with harmonized sampling**|获得可靠的微观结构数据集是借助集成计算材料工程（ICME）方法进行材料系统设计的关键一步。然而，由于高实验成本或技术限制，获得三维（3D）微观结构数据集通常具有挑战性，而获得二维（2D）显微照片相对更容易。为了解决这个问题，本研究提出了一种使用基于扩散的生成模型（DGM）进行微观结构二维到三维重建的新框架，称为Micro3Diff。具体而言，这种方法仅需要预先训练的DGM来生成2D样本，并且维度扩展（2D到3D）仅在生成过程（即反向扩散过程）中发生。所提出的框架结合了一个称为多平面去噪扩散的新概念，该概念将来自不同平面的噪声样本（即潜在变量）转换为数据结构，同时保持3D空间中的空间连通性。此外，还开发了一个协调的采样过程，以解决在维度扩展过程中DGM的反向马尔可夫链的可能偏差。结合起来，我们证明了Micro3Diff在重建具有连接切片的3D样本方面的可行性，这些切片在形态学上与原始2D图像保持等效。为了验证Micro3Diff的性能，重建了各种类型的微观结构（合成和实验观察），并对生成的样品的质量进行了定性和定量评估。成功的重建结果激发了Micro3Diff在即将到来的ICME应用中的潜在应用，同时在理解和操纵DGM的潜在空间方面取得了突破。 et.al.|[2308.14035](http://arxiv.org/abs/2308.14035)|null|
|**2023-08-26**|**HoloPOCUS: Portable Mixed-Reality 3D Ultrasound Tracking, Reconstruction and Overlay**|超声（US）成像为手术指导和诊断成像提供了一种安全、易用的解决方案。传统2D US用于介入引导的有效使用需要丰富的经验来将图像平面投影到患者身上，并且诊断中的图像解释存在高的用户内和用户间可变性。3D US重建允许更一致的诊断和解释，但现有的解决方案在设备和实时导航的适用性方面受到限制。为了解决这些问题，我们提出了HoloPOCUS——一种混合现实的US系统（MR-US），它在护理点环境中将丰富的US信息覆盖在用户的视觉上。HoloPOCUS扩展了现有的MR-US方法，不仅将US平面放置在用户的视野中，还包括3D重建和投影，可以帮助使用传统探针进行程序指导。我们验证了一个跟踪管道，该管道与现有的MR-US工作相比具有更高的准确性。此外，通过幻影任务进行的用户研究表明，当使用我们提出的方法时，导航持续时间显著改善。 et.al.|[2308.13823](http://arxiv.org/abs/2308.13823)|null|
|**2023-08-25**|**Textureless Deformable Surface Reconstruction with Invisible Markers**|重建和跟踪很少或没有纹理的可变形表面一直是一个挑战。从根本上说，这些挑战源于无纹理表面缺乏建立跨图像对应的特征。在这项工作中，我们提出了一种新型的标记，以主动丰富物体的表面特征，从而简化三维表面重建和对应跟踪。我们的标记是由荧光染料制成的，只有在紫外线下才能看到，在正常的照明条件下是看不见的。利用这些标记，我们设计了一个多摄像头系统，以时间复用的方式捕捉紫外线和可见光下的表面变形。在紫外线下，物体上的标记会出现，以丰富其表面纹理，从而实现高质量的3D形状重建和跟踪。在可见光下，标记变得不可见，使我们能够捕捉到物体原始的未受影响的外观。我们在各种具有挑战性的场景中进行实验，包括手势、面部表情、挥舞布料和手物交互。在所有这些情况下，我们证明了我们的系统能够产生稳健、高质量的3D重建和跟踪。 et.al.|[2308.13678](http://arxiv.org/abs/2308.13678)|null|
|**2023-08-23**|**ARF-Plus: Controlling Perceptual Factors in Artistic Radiance Fields for 3D Scene Stylization**|辐射场风格转移是一个新兴的领域，由于神经辐射场在三维重建和视图合成中的出色表现，作为三维场景风格化的一种手段，它最近受到了欢迎。我们强调了在辐射场风格转移方面的研究空白，即缺乏足够的感知可控性，这是由2D图像风格转移中的现有概念所驱动的。在本文中，我们提出了ARF Plus，一个对感知因素提供可管理控制的3D神经风格转移框架，以系统地探索3D场景风格化中的感知可控性。提出了四种不同类型的控制——颜色保持控制、（风格模式）比例控制、空间（选择性风格化区域）控制和深度增强控制——并将其集成到该框架中。来自真实世界数据集的定量和定性结果表明，在对3D场景进行风格化时，我们的ARF Plus框架中的四种类型的控件成功地实现了相应的感知控件。这些技术适用于单个样式输入以及场景中多个样式的同时应用。这开启了一个无限可能性的领域，允许对风格化效果进行定制修改，并灵活融合不同风格的优势，最终能够在3D场景中创造新颖而引人注目的风格效果。 et.al.|[2308.12452](http://arxiv.org/abs/2308.12452)|null|
|**2023-08-21**|**Coordinate Quantized Neural Implicit Representations for Multi-view Reconstruction**|近年来，在从多视图图像中学习用于三维重建的神经隐式表示方面取得了巨大进展。作为补充坐标的额外输入，使用正弦函数作为位置编码在利用基于坐标的神经网络揭示高频细节方面发挥着关键作用。然而，高频位置编码使优化不稳定，这导致了有噪声的重建和空空间中的伪影。为了在一般意义上解决这个问题，我们引入了学习具有量化坐标的神经隐式表示，这减少了优化过程中该领域的不确定性和模糊性。代替连续坐标，我们使用量化坐标之间的最近插值将连续坐标离散为离散坐标，这些量化坐标是通过以极高分辨率离散场而获得的。我们使用离散坐标及其位置编码来通过体积渲染学习隐式函数。这显著减少了采样空间中的变化，并对来自不同视图的光线的交点触发了更多的多视图一致性约束，从而能够以更有效的方式推断隐式函数。我们的量化坐标不会带来任何计算负担，并且可以无缝地使用最新的方法。我们根据广泛使用的基准进行的评估表明，我们优于最先进的基准。我们的代码可在https://github.com/MachinePerceptionLab/CQ-NIR. et.al.|[2308.11025](http://arxiv.org/abs/2308.11025)|**[link](https://github.com/machineperceptionlab/cq-nir)**|
|**2023-08-19**|**Root Pose Decomposition Towards Generic Non-rigid 3D Reconstruction with Monocular Videos**|这项工作专注于基于单目RGB视频序列的非刚性物体的3D重建。具体来说，我们的目标是为通用对象类别和随意捕捉的场景构建高保真度模型。为此，我们不假设对象的已知根姿势，也不使用特定类别的模板或密集姿势先验。我们的根姿势分解（RPD）方法的关键思想是保持每帧根姿势变换，同时通过局部变换建立密集场来校正根姿势。局部变换的优化是通过对规范空间的点配准来执行的。我们还将RPD应用于具有对象遮挡和个体差异的多对象场景。因此，RPD允许对包含具有大变形、复杂运动模式、遮挡和不同个体的尺度多样性的对象的复杂场景进行非刚性3D重建。这样的管道可能会扩展到野外的各种物体。我们的实验表明，RPD在具有挑战性的DAVIS、OVIS和AMA数据集上超越了最先进的方法。 et.al.|[2308.10089](http://arxiv.org/abs/2308.10089)|null|
|**2023-08-19**|**TSAR-MVS: Textureless-aware Segmentation and Correlative Refinement Guided Multi-View Stereo**|由于图像之间缺乏可靠的像素对应关系，无纹理区域的重建长期以来一直是MVS中具有挑战性的问题。在本文中，我们提出了无纹理感知分割和相关细化引导的多视图立体（TSAR-MVS），这是一种通过滤波、细化和分割有效解决三维重建中无纹理区域带来的挑战的新方法。首先，我们实现了联合假设滤波，这是一种将置信度估计器与视差不连续检测器相结合的技术，以消除不正确的深度估计。其次，为了以置信深度扩展像素，我们引入了一种迭代相关细化策略，该策略利用RANSAC生成超像素，然后是中值滤波器，以扩大准确确定的像素的影响。最后，我们提出了一种无纹理感知分割方法，该方法利用边缘检测和线检测来准确识别要使用3D平面拟合的大的无纹理区域。在大量数据集上的实验表明，我们的方法显著优于大多数非学习方法，并且在保留精细细节的同时，对无纹理区域表现出鲁棒性。 et.al.|[2308.09990](http://arxiv.org/abs/2308.09990)|null|
|**2023-08-19**|**A Theory of Topological Derivatives for Inverse Rendering of Geometry**|我们介绍了一个可微曲面演化的理论框架，该框架允许通过使用拓扑导数对图像泛函进行变分优化来实现离散拓扑变化。虽然先前的几何体反向渲染方法依赖于拓扑变化的轮廓梯度，但这种信号是稀疏的。相反，我们的理论推导了拓扑导数，这些导数将消失空穴和相位的引入与图像强度的变化联系起来。因此，我们能够以空穴或相成核的形式实现可微分的形状扰动。我们通过优化2D中的闭合曲线和3D中的曲面来验证所提出的理论，以深入了解当前方法的局限性，并实现改进的应用，如图像矢量化、从文本提示生成矢量图形、形状模糊图的单图像重建和多视图3D重建。 et.al.|[2308.09865](http://arxiv.org/abs/2308.09865)|null|
|**2023-08-18**|**On the three-dimensional relation between the coronal dimming, erupting filament and CME. Case study of the 28 October 2021 X1.0 event**|我们研究了太阳轨道飞行器、STEREO-A、SDO和SOHO从多个角度观测到的2021年10月28日X1.0耀斑/CME事件中，变暗区域的时空演化与细丝喷发和CME传播的主导方向之间的关系。我们提出了一种通过跟踪其面积演变来估计主调光方向的方法，并通过计算每个像素的球体表面积来强调其精确估计。为了确定早期通量绳的传播方向，我们通过分级圆柱壳建模（GCS）和细丝的连接点对CME进行了三维重建。调光最初呈放射状扩展，后来向东南移动。喷发细丝在太阳表面上重建的高度演化的正交投影位于主要变暗增长的扇区中，而GCS重建的内部的正交投影与总变暗区域对齐。灯丝在约180 Mm的高度达到约250 km/s的最大速度。其运动方向从径向强烈倾斜（向东64 $^\circ$，向南32$^\icrc$）。CME和细丝腿之间在3D方向上的50$^\circ$ 差异与重建确定的CME半宽度密切对应，这表明重建的细丝与CME体的相关腿之间存在潜在关系。我们的发现强调，变暗增长的主导传播反映了太阳大气中喷发磁结构（细丝）的方向，尽管细丝的演化与全球CME膨胀的方向没有直接关系。整体变暗形态与CME重建的内部非常相似，验证了使用变暗观测来深入了解CME方向。 et.al.|[2308.09815](http://arxiv.org/abs/2308.09815)|null|
|**2023-08-18**|**A deep learning approach for the 3D reconstruction of dust density and temperature in star-forming regions**|目的：我们介绍了一种新的深度学习方法，用于从单个恒星形成云核心（<0.2pc）的多波长尘埃发射观测中重建三维尘埃密度和温度分布。方法：我们通过使用POLARIS辐射传输代码处理云工厂模拟的云芯来构建训练数据集，以产生12至1300 $\mu$m之间23个波长的合成尘埃发射观测值。我们通过沿着单个视线重建云结构来简化任务，并为此目的训练条件可逆神经网络（cNN）。cNN属于归一化流方法组，能够预测目标灰尘特性的完全后验分布。我们测试了不同的cNN设置，从包括所有23个波长的场景到仅在7个波长进行观测的更现实的有限情况。我们在综合测试数据上评估了这些模型的预测性能。结果：我们报道了23个波长的cNN模型的良好重建性能，在$\log（n_{dust}/m^{-3}）$中实现了约1.8%的中值绝对相对误差，在$\log（T_{dust}/K）$中获得了约1%的中值绝对绝对相对误差。我们确定了在密度范围的低端高估和在密度和温度的高端低估的趋势，这可能与训练数据中的偏差有关。将覆盖范围限制为仅七个波长的组合，我们仍然发现令人满意的性能，在$\log（n_{dust}/m^{-3}）$和$\lod（T_{dust}/K）$ 中的平均绝对相对误差约为3.3%和2.5%。结论：这项概念验证研究表明，在现实的观测约束下，基于cNN的灰尘密度和温度三维重建方法非常有前景，甚至是可行的。 et.al.|[2308.09657](http://arxiv.org/abs/2308.09657)|null|
|**2023-08-18**|**O^2-Recon: Completing 3D Reconstruction of Occluded Objects in the Scene with a Pre-trained 2D Diffusion Model**|遮挡是RGB-D视频三维重建中的一个常见问题，通常会阻碍对象的完整重建，并带来持续的问题。在本文中，我们提出了一种新的框架，通过基于2D扩散的绘画模型来重建物体隐藏部分的完整表面。具体来说，我们利用预先训练的扩散模型来填充2D图像的隐藏区域。然后，我们在绘制的图像中使用这些来优化用于3D重建的每个实例的神经隐式表面表示。由于制作这一过程所需的彩绘面具很棘手，我们采用了一种“人在环”的策略，只需要很少的人参与就可以制作出高质量的面具。此外，物体的某些部分可能被完全隐藏，因为视频通常是从有限的视角拍摄的。为了确保恢复这些不可见区域，我们开发了一种级联网络架构，用于预测有符号距离场，利用位置编码的不同频带并保持整体平滑。除了常用的渲染损失、Eikonal损失和轮廓损失外，我们还采用了基于CLIP的语义一致性损失来从看不见的相机角度引导曲面。在ScanNet场景上的实验表明，我们提出的框架在场景级RGB-D视频的对象级重建中实现了最先进的准确性和完整性。 et.al.|[2308.09591](http://arxiv.org/abs/2308.09591)|null|
|**2023-08-18**|**DMCVR: Morphology-Guided Diffusion Model for 3D Cardiac Volume Reconstruction**|通过电影磁共振成像（cMRI）进行精确的3D心脏重建对于改善心血管疾病诊断和了解心脏运动至关重要。然而，目前在临床环境中使用的基于心脏MRI的重建技术是2D的，通过平面的分辨率有限，导致重建的心脏体积质量低。为了从稀疏的2D图像堆栈中更好地重建3D心脏体积，我们提出了一种用于3D心脏体积重建的形态学引导扩散模型DMCVR，该模型综合了高分辨率2D图像和相应的3D重建体积。我们的方法优于以前的方法，因为它将心脏形态限制在生成模型上，消除了潜在代码耗时的迭代优化过程，并提高了生成质量。所学习的潜在空间为重建3D心脏形状提供了具有高度可解释价值的每个2D cMRI切片的全局语义、局部心脏形态和细节。我们的实验表明，DMCVR在二维生成和三维重建性能等方面都非常有效。有了DMCVR，我们可以制作高分辨率的3D心脏MRI重建，超越了目前的技术。我们提出的框架在提高心脏病诊断和治疗计划的准确性方面具有巨大潜力。代码可访问https://github.com/hexiaoxiao-cs/DMCVR. et.al.|[2308.09223](http://arxiv.org/abs/2308.09223)|**[link](https://github.com/hexiaoxiao-cs/dmcvr)**|
|**2023-08-17**|**A Fusion of Variational Distribution Priors and Saliency Map Replay for Continual 3D Reconstruction**|单图像三维重建是一项研究挑战，重点是从单视图图像中预测三维物体形状。这项任务需要大量的数据采集来预测形状的可见部分和遮挡部分。此外，基于学习的方法面临着为所有可能的类创建综合训练数据集的困难。为此，我们提出了一种基于连续学习的3D重建方法，其中我们的目标是使用变分先验设计一个模型，即使在对新类进行训练后，该模型仍然可以合理地重建以前看到的类。变分先验表示抽象形状和战斗遗忘，而显著性映射则以较少的内存使用来保留对象属性。由于存储大量训练数据的资源限制，这一点至关重要。此外，我们引入了基于显著性地图的体验回放，以捕捉全局和不同的对象特征。与已建立的方法相比，全面的实验在定量和定性方面都显示出有竞争力的结果。 et.al.|[2308.08812](http://arxiv.org/abs/2308.08812)|null|
|**2023-08-17**|**Long-Range Grouping Transformer for Multi-View 3D Reconstruction**|如今，变压器网络在许多计算机视觉任务中表现出了优越的性能。在遵循这种范式的多视图3D重建算法中，当面对大量视图输入时，自注意处理必须处理复杂的图像标记，包括大量信息。信息内容的诅咒导致了模型学习的极端困难。为了缓解这个问题，最近的方法压缩了表示每个视图的令牌编号，或者放弃了来自不同视图的令牌之间的注意力操作。显然，它们会对性能产生负面影响。因此，我们提出了基于分治原则的长程分组注意力（LGA）。来自所有视图的令牌都被分组以进行单独的注意力操作。每组中的标记都是从所有视图中采样的，并且可以为驻留的视图提供宏表示。不同群体之间的多样性保证了特征学习的丰富性。可以建立一种有效且高效的编码器，该编码器使用LGA连接视图间特征，并使用标准自注意层提取视图内特征。此外，还设计了一种新颖的渐进上采样解码器，用于相对高分辨率的体素生成。在此基础上，我们构建了一个强大的基于变压器的网络，称为LRGT。在ShapeNet上的实验结果验证了我们的方法在多视图重建中达到了SOTA的精度。代码将在https://github.com/LiyingCV/Long-Range-Grouping-Transformer. et.al.|[2308.08724](http://arxiv.org/abs/2308.08724)|**[link](https://github.com/liyingcv/long-range-grouping-transformer)**|
|**2023-08-16**|**DeDoDe: Detect, Don't Describe -- Describe, Don't Detect for Local Feature Matching**|关键点检测是3D重建中的关键步骤，通过该步骤可以在场景的每个视图中检测到（最多）K个点的集合。至关重要的是，检测到的点需要在视图之间保持一致，即对应于场景中的同一3D点。关键点检测的主要挑战之一是学习目标的制定。以前基于学习的方法通常将描述符与关键点联合学习，并将关键点检测视为对相互最近邻居的二元分类任务。然而，基于描述符最近邻居的关键点检测是一项代理任务，不能保证产生3D一致的关键点。此外，这将关键点与特定描述符联系在一起，使下游使用变得复杂。在这项工作中，我们直接从3D一致性中学习关键点。为此，我们训练检测器来检测大规模SfM中的轨道。由于这些点通常过于稀疏，我们导出了一个半监督的双视图检测目标，以将该集扩展到所需的检测数量。为了训练描述符，我们使用单独的网络在关键点上最大化相互最近邻目标。结果表明，我们的方法DeDoDe在多个几何基准上实现了显著的增益。代码提供于https://github.com/Parskatt/DeDoDe。 et.al.|[2308.08479](http://arxiv.org/abs/2308.08479)|**[link](https://github.com/parskatt/dedode)**|
|**2023-08-17**|**Deep Learning Framework for Spleen Volume Estimation from 2D Cross-sectional Views**|异常脾脏肿大（脾肿大）被认为是一系列疾病的临床指标，包括肝脏疾病、癌症和血液疾病。虽然从超声图像中测量的脾脏长度是脾脏大小的常用替代品，但脾脏体积仍然是评估脾肿大和相关临床状况严重程度的金标准。计算机断层扫描是测量脾脏体积的主要成像方式，但在脾肿大发病率高的地区（如全球南部），它不太容易获得。我们的目标是通过二维横截面分割实现脾脏体积的自动测量，这可以从超声成像中获得。在这项研究中，我们描述了一种基于变分自动编码器的框架，用于从单视图或双视图2D脾脏分割中测量脾脏体积。我们在此框架内提出并评估了三种体积估计方法。我们还展示了如何产生体积估计的95%置信区间，使我们的方法在临床上更有用。我们的最佳模型在单视图和双视图分割中分别实现了86.62%和92.58%的平均相对体积准确率，超过了使用手动测量的线性回归临床标准方法和基于比较深度学习的2D-3D重建方法的性能。所提出的脾脏体积估计框架可以集成到目前使用2D超声图像来测量脾脏长度的标准临床工作流程中。据我们所知，这是第一项从2D脾脏分割中直接实现3D脾脏体积估计的工作。 et.al.|[2308.08038](http://arxiv.org/abs/2308.08038)|null|
|**2023-08-17**|**ObjectSDF++: Improved Object-Compositional Neural Implicit Surfaces**|近年来，神经隐式表面重建已成为多视图三维重建的一种流行范式。与传统的多视图立体方法不同，基于神经隐式表面的方法利用神经网络将3D场景表示为符号距离函数（SDF）。然而，它们往往忽略场景中单个对象的重建，这限制了它们的性能和实际应用。为了解决这个问题，以前的工作ObjectSDF引入了一个很好的对象组合神经隐式曲面框架，该框架利用2D实例掩码来监督单个对象的SDF。在本文中，我们提出了一个名为ObjectSDF++的新框架来克服ObjectSDF的局限性。首先，与ObjectSDF相比，ObjectSDF的性能主要受其转换的语义场的限制，我们模型的核心组件是一个感知遮挡的对象不透明度渲染公式，该公式直接对要使用实例掩码进行监督的对象不透明进行体绘制。其次，我们设计了一个新的正则化项来区分对象，它可以有效地缓解ObjectSDF由于缺乏防止碰撞的约束而可能在不可见区域中导致意外重建的问题。我们的大量实验表明，我们的新框架不仅产生了优越的对象重建结果，而且显著提高了场景重建的质量。可以在\url中找到代码和更多资源{https://qianyiwu.github.io/objectsdf++} et.al.|[2308.07868](http://arxiv.org/abs/2308.07868)|**[link](https://github.com/qianyiwu/objectsdf_plus)**|

<p align=right>(<a href=#updated-on-20230902>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-08-31**|**Robust Variational Physics-Informed Neural Networks**|我们引入了变分物理知情神经网络（RVPINN）的鲁棒版本来近似偏微分方程（PDE）的解。我们从问题的一个弱Petrov-Galerkin公式开始，选择一个离散的测试空间，并定义一个二次损失函数，如在VPINNs中。而在VPINN中，损失取决于给定测试空间的选定基函数，在此，我们基于离散对偶范数中的残差来最小化损失，该残差与测试空间对测试基函数的选择无关。我们证明了这种损失是能量范数中真实误差的可靠和有效的估计量。所提出的损失函数需要计算Gram矩阵逆，类似于传统的残差最小化方法。为了验证我们的理论发现，我们在一个空间维度上测试了我们的算法在几个平流主导的扩散问题中的性能和稳健性。我们得出结论，RVPINN是一种稳健的方法。 et.al.|[2308.16910](http://arxiv.org/abs/2308.16910)|null|
|**2023-08-31**|**InterDiff: Generating 3D Human-Object Interactions with Physics-Informed Diffusion**|本文提出了一项预测三维人机交互（HOI）的新任务。大多数现有的HOI合成研究缺乏与动态对象的全面全身交互，例如，通常仅限于操纵小对象或静态对象。我们的任务更具挑战性，因为它需要建模各种形状的动态对象，捕捉全身运动，并确保物理有效的交互。为此，我们提出了InterDiff，该框架包括两个关键步骤：（i）交互扩散，其中我们利用扩散模型对未来人机交互的分布进行编码；（ii）相互作用校正，其中我们引入了一个基于物理的预测器来校正扩散步骤中的去噪HOI。我们的关键见解是注入先验知识，即参考中关于接触点的交互遵循一个简单的模式，并且很容易预测。在多个人机交互数据集上的实验证明了我们的方法在这项任务中的有效性，能够产生逼真、生动和显著的长期3D HOI预测。 et.al.|[2308.16905](http://arxiv.org/abs/2308.16905)|**[link](https://github.com/Sirui-Xu/InterDiff)**|
|**2023-08-31**|**GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields**|开发能够在非结构化现实世界环境中通过视觉观察执行各种操作任务的代理是机器人技术中的一个长期问题。为了实现这一目标，机器人需要对场景的3D结构和语义有全面的了解。在这项工作中，我们提出了 $\textbf｛GNFactor｝$，一种用于多任务机器人操作的视觉行为克隆代理，具有$\textbf｛G｝$通用$\textbf｛N｝$eural功能$\textbf｛F｝$字段。GNFactor联合优化了作为重建模块的可推广神经场（GNF）和作为决策模块的感知转换器，利用了共享的深度3D体素表示。为了在3D中结合语义，重建模块利用视觉语言基础模型（$\textit｛例如｝$ ，Stable Diffusion）将丰富的语义信息提取到深度3D体素中。我们在3个真实机器人任务中评估了GNFactor，并在10个RLBench任务中进行了详细的消融，演示次数有限。我们观察到GNFactor在可见和不可见任务中比当前最先进的方法有了实质性的改进，证明了GNFactor强大的泛化能力。我们的项目网站是https://yanjieze.com/GNFactor/。 et.al.|[2308.16891](http://arxiv.org/abs/2308.16891)|**[link](https://github.com/YanjieZe/GNFactor)**|
|**2023-08-31**|**Prediction of Diblock Copolymer Morphology via Machine Learning**|提出了一种机器学习方法来加速长时间尺度上大域嵌段聚合物形态演化的计算。该策略利用了单体尺度上的粗颗粒进化和介观尺度上的缓慢形态进化之间的特征时间分离。与经验连续体模型相比，所提出的方法直接从基于粒子的模拟中学习随机驱动的缺陷湮灭过程。采用了尊重不同边界条件的UNet架构，从而允许任意形状的周期性和固定的衬底边界条件。物理概念也通过损失函数引入，对称性通过数据扩充引入。该模型使用三个不同的用例进行了验证。可解释的人工智能方法被应用于可视化形态随时间的演变。这种方法能够生成大系统尺寸和长轨迹，以研究缺陷密度及其在不同类型约束下的演变。作为一个应用，我们证明了获取后期形态对于理解单个块体内颗粒扩散的重要性。这项工作对微电子、电池材料和膜中的定向自组装和材料设计具有启示意义。 et.al.|[2308.16886](http://arxiv.org/abs/2308.16886)|null|
|**2023-08-31**|**Constraining the geometry of the reflection nebula NGC 2023 with [O I]: Emission & Absorption**|我们已经使用SOFIA上的外差接收器upGREAT绘制了NGC 2023反射星云在[OI]的63和145微米跃迁以及158微米[CII]谱线中的映射图。观察结果用于识别分别由[C II]和[O I]发射追踪的PDR的扩散和密集成分。速度分辨观测揭示了低激发原子氧的显著柱的存在，在[OI]63微米光谱中的吸收中可见，约占[OI]145微米光谱中发射中可见的氧柱的20-60%。在[CII]中也可以看到一些自我吸收，但在大多数情况下几乎不明显。[C II]和[O I]63微米的光谱显示，由于光蒸发流，特别是在反射星云的东南部和南部，翅膀发生了强烈的红色和蓝色偏移，与中J和高J CO发射相比，表明C++区域正在扩展成致密的分子云。使用两片玩具模型，在[OI]63微米中看到的大规模自吸收很容易被解释为起源于与源相关的前景低激发气体。最近在其他银河系光子主导区域（PDR）也观察到了类似的柱状物。这些结果有两个含义：对于速度未解决的银河系外观测，这可能会影响使用[OI]63微米作为大质量恒星形成的示踪剂；其次，[OI]62微米中广泛的自吸收导致低估了从该示踪剂中获得的原子氧的柱密度，因此需要使用替代的间接方法。 et.al.|[2308.16872](http://arxiv.org/abs/2308.16872)|null|
|**2023-08-31**|**Diffusion Models for Interferometric Satellite Aperture Radar**|概率扩散模型（PDMs）最近成为一类非常有前途的生成模型，在自然图像生成中实现了高性能。然而，它们相对于非自然图像（如基于雷达的卫星数据）的性能在很大程度上仍然未知。生成大量合成（尤其是标记）卫星数据对于实施深度学习方法处理和分析（干涉）卫星孔径雷达数据至关重要。在这里，我们利用PDM生成几个基于雷达的卫星图像数据集。我们表明，PDM成功地生成了具有复杂和逼真结构的图像，但采样时间仍然是一个问题。事实上，在MNIST等简单图像数据集上运行良好的加速采样策略在我们的雷达数据集上失败了。我们提供一个简单而通用的开源https://github.com/thomaskerdreux/PDM_SAR_InSAR_generation使用单个GPU上的任何数据集来训练、采样和评估PDM。 et.al.|[2308.16847](http://arxiv.org/abs/2308.16847)|null|
|**2023-08-31**|**Irregular Traffic Time Series Forecasting Based on Asynchronous Spatio-Temporal Graph Convolutional Network**|智能交通信号控制交叉口的准确交通预测对于有效的智能交通信号系统的发展至关重要。然而，由于智能交叉口产生的不规则交通时间序列，交通预测任务变得更加棘手，并提出了三个主要的新挑战：1）异步空间相关性，2）交通数据之间的不规则时间相关性，以及3）待预测的变长序列，这严重阻碍了当前交通预测方法的性能。为此，我们提出了一种异步时空图卷积nTwoRk（ASeer）来预测未来时间窗口内进入智能交叉口的车道的交通状态。具体来说，通过通过交通扩散图连接车道，我们首先提出了一个异步图扩散网络来对车道的时间错位交通状态测量之间的异步空间依赖性进行建模。然后，为了捕捉不规则交通状态序列中的时间依赖性，设计了一种可学习的个性化时间编码来嵌入每条车道的连续时间。然后，我们提出了一种可变换时间感知卷积网络，该网络学习元滤波器，以导出具有可变换滤波器大小的时间感知卷积滤波器，用于在不规则序列上进行有效的时间卷积。此外，设计了一个由状态演化单元和半自回归预测器组成的半自回归预测网络，以有效地预测可变长度的交通状态序列。在两个真实世界数据集上进行的大量实验证明了ASeer在六个指标上的有效性。 et.al.|[2308.16818](http://arxiv.org/abs/2308.16818)|null|
|**2023-08-31**|**Ref-Diff: Zero-shot Referring Image Segmentation with Generative Models**|零样本参考图像分割是一项具有挑战性的任务，因为它旨在根据给定的参考描述找到一个实例分割掩码，而无需对这种类型的配对数据进行训练。当前的零样本方法主要集中于使用预先训练的判别模型（例如CLIP）。然而，我们观察到生成模型（例如，稳定扩散）可能已经理解了各种视觉元素和文本描述之间的关系，而这在本任务中很少进行研究。在这项工作中，我们为这项任务引入了一种新的参考扩散分割器（Ref-Diff），它利用了生成模型中的细粒度多模态信息。我们证明，如果没有提议生成器，单独的生成模型可以实现与现有SOTA弱监督模型相当的性能。当我们将生成模型和判别模型相结合时，我们的Ref-Diff显著优于这些竞争方法。这表明生成模型也有利于这项任务，并且可以补充判别模型以更好地进行参考分割。我们的代码可在https://github.com/kodenii/Ref-Diff. et.al.|[2308.16777](http://arxiv.org/abs/2308.16777)|null|
|**2023-08-31**|**Unsupervised CT Metal Artifact Reduction by Plugging Diffusion Priors in Dual Domains**|在计算机断层扫描（CT）过程中，金属植入物通常会在重建图像中造成破坏性伪影，阻碍准确诊断。已经提出了几种基于监督深度学习的方法来减少金属伪影（MAR）。然而，这些方法在很大程度上依赖于模拟数据的训练，因为在临床环境中获得成对的金属伪影CT和干净的CT数据是具有挑战性的。当在临床实践中应用这些方法时，这种限制可能会导致性能下降。现有的无监督MAR方法，无论是否基于学习，通常在图像域或正弦图域的单个域内操作。在本文中，我们提出了一种基于扩散模型的无监督MAR方法，这是一种具有高容量表示数据分布的生成模型。具体来说，我们首先使用没有金属伪影的CT图像来训练扩散模型。随后，我们在正弦图和图像域中迭代地利用嵌入在预训练的扩散模型中的先验来恢复由金属伪影引起的退化部分。这种双域处理使我们的方法优于现有的无监督MAR方法，包括另一种基于扩散模型的MAR方法。我们已经使用合成数据集对其进行了定性和定量验证。此外，与临床数据集上的监督和非监督方法相比，我们的方法显示出优越的视觉结果。 et.al.|[2308.16742](http://arxiv.org/abs/2308.16742)|**[link](https://github.com/deepxuan/dudodp-mar)**|
|**2023-08-31**|**Terrain Diffusion Network: Climatic-Aware Terrain Generation with Geological Sketch Guidance**|基于草图的地形生成旨在为计算机游戏、动画和虚拟现实等各种应用中的虚拟环境创建逼真的景观。最近，出现了基于深度学习的地形生成，尤其是基于生成对抗性网络（GAN）的地形生成。然而，这些方法往往难以满足灵活的用户控制要求，并保持现实地形的生成多样性。因此，我们提出了一种新的基于扩散的方法，即地形扩散网络（TDN），该方法积极结合用户指导，以增强可控性，同时考虑河流、山脊、盆地和山峰等地形特征。提出了一种多级去噪方案，通过考虑细粒度细节，特别是与受侵蚀和构造活动影响的气候模式相关的细节，来生成更真实的地形，而不是坚持传统的单片去噪过程，这通常会损害地形细节的保真度或与用户控制的一致性。具体而言，三个地形合成器是为结构、中间和细粒度级别的去噪目的而设计的，这使得每个合成器都能专注于不同的地形方面。此外，为了最大限度地提高TDN的效率，我们进一步为具有预训练地形自动编码器的合成器引入地形和草图潜在空间。在由NASA拓扑图像构建的新数据集上进行的综合实验清楚地证明了我们提出的方法的有效性，实现了最先进的性能。我们的代码和数据集将公开。 et.al.|[2308.16725](http://arxiv.org/abs/2308.16725)|null|
|**2023-08-31**|**Joint H.E.S.S. and Fermi-LAT analysis of the region around PSR J1813-1749**|HESS J1813-178是在第一次HESS银河平面探测中探测到的最亮的光源之一。MAGIC也探测到了这个紧凑的源，据信是一个脉冲星风星云，由银河系中已知的最强大的脉冲星之一PSR J1813-1749提供动力，其自转光度为 $\dot｛\mathrm｛E｝｝＝5.6\cdot 10^｛37｝\，\mathrm｝erg｝\和\mathrm{s｝^｛-1｝$。由于其极端的物理性质，以及脉冲星5.6千焦的年轻年龄，在该区域探测到的$\gamma$-射线使我们能够研究一个高度非典型系统的演化。先前对GeV能量范围内区域的研究表明，发射超出了紧凑型H.E.S.S.源的大小。利用H.E.S.S.档案数据和改进的背景方法，我们对该区域进行了详细的形态和光谱分析。除了紧凑、明亮的发射部件外，我们还发现了显著的扩展发射，其位置与HESS J1813-178一致。我们重新分析了GeV中的区域，并导出了一个联合模型，以便找到从GeV到TeV区域发射的连续描述。利用该分析得出的结果，以及该地区的X射线和无线电数据，我们进行了多波长光谱建模。研究了$\gamma$ 射线发射的可能强子或轻子起源，并检验了解释扩展发射所需的扩散参数。 et.al.|[2308.16717](http://arxiv.org/abs/2308.16717)|null|
|**2023-08-31**|**Carrier diffusion in semiconductor nanoscale resonators**|结果表明，具有极端介电约束的半导体纳米谐振器加速了由非线性吸收激发的电子-空穴对的扩散。这些新颖的腔设计可以导致与传统几何形状相比具有优异调制速度的光学开关。通过有效的本征模展开技术计算了有效载流子密度的响应函数。扩散方程的一些本征模可以方便地捕捉长时间尺度的载流子衰变率，这与时域模拟相比是有利的。值得注意的是，本征模方法阐明了平面内和平面外腔几何结构对载流子扩散的贡献，这可能会指导未来的设计。 et.al.|[2308.16715](http://arxiv.org/abs/2308.16715)|null|
|**2023-08-31**|**Dynamics at the edge for independent diffusing particles**|我们在一维中研究了大量独立布朗粒子的异常值的动力学。我们通过两种不同的方法推导了最右边粒子位置的多次联合分布。我们得到了最大值和第二个最大值位置的两次联合分布，并研究了边缘的计数统计。最后，我们导出了运行最大值的多时间联合分布，以及第一个粒子在几个空间点的到达时间的联合分布。 et.al.|[2308.16709](http://arxiv.org/abs/2308.16709)|null|
|**2023-08-31**|**Spatio-temporal boundary dissipation measurement in Taylor-Couette flow using Diffusing-Wave Spectroscopy**|扩散波光谱学（DWS）允许直接测量应变率张量的平方。当与常用的高速相机相结合时，我们发现DWS可以直接访问牛顿流体流粘性耗散率的时空变化。使用填充有脂质乳液或TiO2悬浮液的Taylor Couette（TC）细胞来证明该方法。我们通过向实验单元照射相干光并测量散斑图案的局部相关时间，以定量和时间分辨的方式对边界耗散率进行成像。通过与理想TC流的理论预测以及使用光电倍增管和光子相关器的全局测量进行比较，验证了结果。我们通过表征超过Taylor Couette不稳定阈值的边界耗散率的空间组织，以及其在超过二次不稳定阈值后出现的波浪涡流中的时空动力学来说明该方法。这项研究为包括湍流在内的各种流动中的耗散率的直接成像铺平了道路。 et.al.|[2308.16693](http://arxiv.org/abs/2308.16693)|null|
|**2023-08-31**|**On the nature of the energy-dependent morphology of the composite multi-TeV gamma-ray source HESS J1702-420**|HESS J1702-420是一种具有不同寻常的能量依赖形态的多TeV伽马射线源。最近的H.E.S.S.观测表明，该发射由点状HESS J1702-420A（在最高能量下占主导地位， $\gtrsim$30TeV）和扩散（$\sim$0.3$^\circ$）HESS J1701-420B（在$\lesssim$5TeV以下占主导地位）的组合很好地描述，分别具有非常硬（${\Gamma}\sim1.5$）和软（${\ Gamma}$~2.6）的幂律谱。在这里，我们提出了一个模型，假设质子加速器位于HESS J1702-420A的位置，并嵌入与HESS J1702-420B重合的致密分子云中。在所提出的模型中，HESS J1702-420的VHE辐射是通过连续注入的相对论质子在稠密云中传播的π衰变发射来解释的。依赖于能量的形态由低能质子传播的扩散性质定义，在较高能量下急剧转变为（准）弹道传播。采用扩散系数$D\protoE^\beta$与$\beta.geq1$的强能量依赖性，我们认为HESS J1702-420作为两个伽马射线源的系统是传播效应的结果。单个加速器以$Q_0\simeq 10^{38}，（n_0/100\，\rm-cm^{-3}）^{-1}，（d/\，0.25\，kpc）^{-1}\rm-erg/s$ 的速率注入的质子可以合理地再现两个伽马射线分量的形态和通量。 et.al.|[2308.16685](http://arxiv.org/abs/2308.16685)|null|
|**2023-08-31**|**Diffusion Inertial Poser: Human Motion Reconstruction from Arbitrary Sparse IMU Configurations**|来自有限数量惯性测量单元（IMU）的运动捕捉在健康、人体性能和虚拟现实中具有重要应用。现实世界的限制和特定应用的目标决定了不同的IMU配置（即IMU的数量和选择的附件主体部分），从而权衡准确性和实用性。尽管最近的工作成功地从六个IMU精确重建了全身运动，但这些系统仅适用于特定的IMU配置。在这里，我们提出了一个单一的扩散生成模型，即扩散惯性姿态（DiffIP），它可以从任意IMU配置实时重建人体运动。我们表明，DiffIP在IMU配置方面具有灵活性，同时与常用的六IMU配置的最先进配置一样准确。我们的系统能够为不同的应用程序选择最佳配置，而无需重新训练模型。例如，当只有四个IMU可用时，DiffIP发现，最大限度地减少关节运动学误差的配置会影响大腿和前臂。然而，当使用脚而不是大腿时，全局平移重建效果更好。尽管我们的方法对基础模型是不可知的，但我们基于生理上逼真的肌肉骨骼模型构建了DiffIP，以便在生物医学研究和健康应用中使用。 et.al.|[2308.16682](http://arxiv.org/abs/2308.16682)|null|
|**2023-08-31**|**Modelling of highly extended Gamma-ray emission around the Geminga Pulsar as detected with H.E.S.S**|Geminga是一颗神秘的无线电静默伽马射线脉冲星，距离地球只有250pc的距离。多台基于水-切伦科夫探测器的仪器已经探测到脉冲星周围扩展的高能伽马射线发射。然而，由于角尺度超过了典型的视场，探测Geminga脉冲星周围的扩展TeV伽马射线发射对IACT来说具有挑战性。通过对背景估计技术的详细研究和系统效应的表征，H.E.S.S.IACT阵列可以证实对高度扩展的TeV伽马射线发射的探测。在之前宣布的探测基础上，在这篇文章中，我们进一步表征了发射，并将电子扩散模型应用于H.E.S.S.和HAWC实验的组合伽马射线数据，以及XMM Newton的X射线数据。 et.al.|[2308.16669](http://arxiv.org/abs/2308.16669)|null|
|**2023-08-31**|**The Orion-Taurus ridge: a synchrotron radio loop at the edge of the Orion-Eridanus superbubble**|大规模同步加速器环被认为是银河系中高纬度地区散射无线电连续辐射的主要来源。然而，它们的起源仍然无法解释。在这封信中，我们首次结合了总强度和偏振强度无线电波段的多频率数据，将一条弧（以下称为猎户座-金牛座山脊）与太阳系最突出的恒星反馈吹制外壳的壁联系起来，即猎户座-厄利达努斯超级气泡。我们使用星际尘埃灭绝的3D图和分子气体 $N_｛\rmH_2｝$的柱密度图来追踪猎户座-金牛座山脊。我们在400\，pc的距离处发现了猎户座-金牛座山脊，其天空范围为180$\，pc。其中值$N_｛\rmH_2｝$为$（1.4^｛+2.6｝_｛-0.6｝）乘以10^｛21｝$cm$^｛-2｝$。由于长波阵列在100MHz以下的宽带观测，我们还计算了猎户座-金牛座山脊同步辐射率$\beta$的低频光谱指数图。我们发现$\beta$的平坦分布，中值为$-2.24^{+0.03}_{-0.02}$，我们根据最近超新星遗迹中低能量（$<$GeV）宇宙线电子的损耗来解释（$10^5$-$10^6$yrs）。我们的结果与猎户座-金牛座山脊中大于几十$\mu$G（$>30-40\，\mu$ G）的天平面磁场强度一致。我们报道了首次探测到猎户座Eridanus超级气泡周围冷中性部分分子气体的扩散同步辐射。随着未来高灵敏度无线电设施的出现，如C波段全天巡天和平方公里阵列，这一观测为研究多相磁化星际介质开辟了一个新的视角。 et.al.|[2308.16663](http://arxiv.org/abs/2308.16663)|null|
|**2023-08-31**|**Generate Your Own Scotland: Satellite Image Generation Conditioned on Maps**|尽管最近在图像生成方面取得了进展，但在地球观测中，扩散模型仍在很大程度上未得到充分探索。在本文中，我们展示了最先进的预训练扩散模型可以以地图数据为条件来生成真实的卫星图像。我们提供了两个大型数据集，分别是苏格兰大陆和中央地带的成对OpenStreetMap图像和卫星视图。我们训练了一个ControlNet模型，并对结果进行了定性评估，证明了图像质量和地图保真度都是可能的。最后，我们对将这些模型应用于遥感的机遇和挑战提供了一些见解。我们的模型权重和创建数据集的代码可在https://github.com/miquel-espinosa/map-sat. et.al.|[2308.16648](http://arxiv.org/abs/2308.16648)|**[link](https://github.com/miquel-espinosa/map-sat)**|
|**2023-08-31**|**MFR-Net: Multi-faceted Responsive Listening Head Generation via Denoising Diffusion Model**|面对面交流是一种常见的场景，包括演讲者和听众的角色。大多数现有的研究方法都集中在制作扬声器视频上，而听众头部的生成在很大程度上仍然被忽视。响应式监听头生成是一项重要任务，旨在通过在给定扬声器视频和监听头图像的情况下生成监听头视频来对面对面通信场景进行建模。一个理想的生成的响应收听视频应该以表达态度或观点的方式对说话者做出响应，同时保持互动模式的多样性和听众身份信息的准确性。为了实现这一目标，我们提出了\textbf｛M｝ulti-\textbf｛F｝aceted\textbf{R｝esponsive Listening Head Generation Network（MFR-Net）。具体而言，MFR-Net采用概率去噪扩散模型来预测不同的头部姿态和表情特征。为了对扬声器视频进行多方面响应，同时保持准确的听众身份保存，我们设计了特征聚合模块来增强听众身份特征，并将其与其他扬声器相关特征融合。最后，通过身份一致性损失进行微调的渲染器生成最终的监听头部视频。我们的大量实验表明，MFR-Net不仅在多样性和说话人身份信息方面实现了多方面的响应，而且在态度和观点表达方面也实现了多层面的响应。 et.al.|[2308.16635](http://arxiv.org/abs/2308.16635)|null|

<p align=right>(<a href=#updated-on-20230902>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-08-31**|**GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields**|开发能够在非结构化现实世界环境中通过视觉观察执行各种操作任务的代理是机器人技术中的一个长期问题。为了实现这一目标，机器人需要对场景的3D结构和语义有全面的了解。在这项工作中，我们提出了 $\textbf｛GNFactor｝$，一种用于多任务机器人操作的视觉行为克隆代理，具有$\textbf｛G｝$通用$\textbf｛N｝$eural功能$\textbf｛F｝$字段。GNFactor联合优化了作为重建模块的可推广神经场（GNF）和作为决策模块的感知转换器，利用了共享的深度3D体素表示。为了在3D中结合语义，重建模块利用视觉语言基础模型（$\textit｛例如｝$ ，Stable Diffusion）将丰富的语义信息提取到深度3D体素中。我们在3个真实机器人任务中评估了GNFactor，并在10个RLBench任务中进行了详细的消融，演示次数有限。我们观察到GNFactor在可见和不可见任务中比当前最先进的方法有了实质性的改进，证明了GNFactor强大的泛化能力。我们的项目网站是https://yanjieze.com/GNFactor/。 et.al.|[2308.16891](http://arxiv.org/abs/2308.16891)|**[link](https://github.com/YanjieZe/GNFactor)**|
|**2023-08-30**|**Active Neural Mapping**|我们用不断学习的神经场景表示来解决主动映射的问题，即主动神经映射。关键在于通过有效的代理移动积极找到要探索的目标空间，从而最大限度地减少在以前看不见的环境中飞行中的地图不确定性。在本文中，我们检验了连续学习神经场的权重空间，并从经验上表明，神经变异性，即对随机权重扰动的预测鲁棒性，可以直接用于测量神经映射的瞬时不确定性。结合神经映射中继承的连续几何信息，可以引导agent找到一条可遍历的路径，以逐渐获得环境知识。我们首次提出了一种用于在线场景重建的具有基于坐标的隐式神经表示的主动映射系统。在视觉逼真的Gibson和Matterport3D环境中的实验证明了所提出方法的有效性。 et.al.|[2308.16246](http://arxiv.org/abs/2308.16246)|null|
|**2023-08-29**|**Canonical Factors for Hybrid Neural Fields**|因子特征量提供了一种简单的方法来构建更紧凑、高效和可积分的神经场，但也引入了对真实世界数据不一定有益的偏差。在这项工作中，我们（1）描述了这些架构对轴对准信号的不希望有的偏差——它们可能导致高达2 PSNR的辐射场重建差异——以及（2）探索了学习一组规范化变换如何通过消除这些偏差来改进表示。我们在二维模型问题中证明，同时学习这些变换和场景外观是成功的，效率大大提高。我们使用图像、符号距离和辐射场重建任务验证了最终的架构，我们称之为TILTED，在这些任务中，我们观察到了质量、稳健性、紧凑性和运行时间方面的改进。结果表明，TILTED可以实现比基线大2倍的能力，同时突出神经场评估程序的弱点。 et.al.|[2308.15461](http://arxiv.org/abs/2308.15461)|null|
|**2023-08-30**|**NSF: Neural Surface Fields for Human Modeling from Monocular Depth**|从单眼相机获得个性化的3D可动画化化身在游戏、虚拟试穿、动画和VR/XR等领域有几个现实世界的应用。然而，从这种稀疏的数据中建模动态和细粒度的服装变形是非常具有挑战性的。现有的从深度数据建模3D人类的方法在计算效率、网格一致性以及分辨率和拓扑结构的灵活性方面具有局限性。例如，使用隐式函数重建形状和每帧提取显式网格在计算上是昂贵的，并且不能确保跨帧的连贯网格。此外，在具有离散表面的预先设计的人类模板上预测每个顶点的变形在分辨率和拓扑结构上缺乏灵活性。为了克服这些局限性，我们提出了一种新的方法“关键特征：神经表面场”，用于从单目深度对穿着3D衣服的人类进行建模。NSF仅在基底表面上定义了一个神经场，该神经场对连续和灵活的位移场进行建模。NSF可以适应不同分辨率和拓扑结构的基面，而无需在推理时进行重新训练。与现有方法相比，我们的方法在保持网格一致性的同时消除了昂贵的每帧表面提取，并且能够在不重新训练的情况下重建任意分辨率的网格。为了促进这方面的研究，我们在项目页面上发布了我们的代码：https://yuxuan-xue.com/nsf. et.al.|[2308.14847](http://arxiv.org/abs/2308.14847)|null|
|**2023-08-28**|**A Transformer-Conditioned Neural Fields Pipeline with Polar Coordinate Representation for Astronomical Radio Interferometric Data Reconstruction**|在射电天文学中，能见度数据是对射电望远镜波信号的测量，被转换成图像，用于观测遥远的天体。然而，由于信号稀疏性和其他因素，这些结果图像通常包含真实源和伪影。获得更干净图像的一种方法是在成像之前将样本重建成致密的形式。不幸的是，现有的可见性重建方法可能会错过频率数据的一些分量，因此模糊的对象边缘和持久的伪影仍然存在于图像中。此外，由于数据偏斜，在不规则可见性样本上的计算开销很高。为了解决这些问题，我们提出了PolarRec，这是一种干涉能见度数据的重建方法，它由具有极坐标表示的变压器条件神经场管道组成。这种表示与望远镜在地球自转时观察天体区域的方式相匹配。我们进一步提出了径向频率损失函数，使用极坐标系中的径向坐标与频率信息进行关联，以帮助重建完整的可见性。我们还根据极坐标系中的角坐标对可见性采样点进行分组，并使用分组作为随后使用Transformer编码器进行编码的粒度。因此，我们的方法可以有效地捕捉可见性数据的固有特征。我们的实验表明，PolarRec通过忠实地重建可见性域中的所有频率分量，显著提高了成像结果，同时显著降低了计算成本。 et.al.|[2308.14610](http://arxiv.org/abs/2308.14610)|null|
|**2023-08-24**|**NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes**|最近的隐式神经表示在新的视图合成中显示出了很好的结果。然而，现有的方法需要从许多视图进行昂贵的每场景优化，因此限制了它们在真实世界的无边界城市环境中的应用，在这些环境中，从极少数视图观察到感兴趣的对象或背景。为了缓解这一挑战，我们引入了一种名为NeO360的新方法，用于户外场景稀疏视图合成的神经场。NeO 360是一种可推广的方法，它从单个或几个摆出姿势的RGB图像重建360｛\deg｝场景。我们方法的本质是捕捉复杂的真实世界户外3D场景的分布，并使用可以从任何世界点查询的混合图像条件三平面表示。我们的表示结合了基于体素和鸟瞰图（BEV）的最佳表示，比每种表示都更有效、更具表现力。NeO 360的表示使我们能够从大量无界3D场景中学习，同时在推理过程中从一张图像中提供对新视图和新场景的可推广性。我们在所提出的具有挑战性的360｛\deg｝无界数据集NeRDS 360上演示了我们的方法，并表明NeO 360在新视图合成方面优于最先进的可推广方法，同时还提供编辑和合成功能。项目页面：https://zubair-irshad.github.io/projects/neo360.html et.al.|[2308.12967](http://arxiv.org/abs/2308.12967)|**[link](https://github.com/zubair-irshad/NeO-360)**|
|**2023-08-23**|**Semantic-Aware Implicit Template Learning via Part Deformation Consistency**|学习隐式模板作为神经场最近在无监督形状对应方面表现出了令人印象深刻的性能。尽管取得了成功，但我们观察到，目前仅依赖几何信息的方法往往会在具有高结构可变性的通用物体形状中学习次优变形。在本文中，我们强调了零件变形一致性的重要性，并提出了一个语义感知的隐式模板学习框架，以实现语义上合理的变形。通过利用自监督特征提取器的语义先验，我们建议使用新的语义感知变形代码进行局部条件调节，并对零件变形、全局变形和全局缩放进行变形一致性正则化。我们的大量实验证明了所提出的方法在各种任务中优于基线：关键点转移、零件标签转移和纹理转移。更有趣的是，我们的框架在更具挑战性的环境下显示出更大的性能提升。我们还提供了定性分析来验证语义感知变形的有效性。代码可在https://github.com/mlvlab/PDC. et.al.|[2308.11916](http://arxiv.org/abs/2308.11916)|null|
|**2023-08-22**|**Approaching human 3D shape perception with neurally mappable models**|人类毫不费力地推断出物体的三维形状。这种能力的基础是什么计算？尽管已经提出了各种计算模型，但它们都没有捕捉到人类在不同视点之间匹配物体形状的能力。在这里，我们询问是否以及如何缩小这一差距。我们从一类相对新颖的计算模型3D神经场开始，它通过深度神经网络（DNN）中的合成封装了经典分析的基本原理。首先，我们发现3D光场网络（3D-LFN）支持与人类完全一致的3D匹配判断，用于类别内比较、强调标准DNN模型的3D失败情况的对抗性定义比较，以及用于无类别结构的算法生成形状的对抗性定义比较。然后，我们通过一系列计算实验研究了3D-LFN实现人类对齐性能的能力来源。在训练过程中暴露于物体的多个视角和多视角学习目标是模型-人对齐背后的主要因素；当使用多视图目标进行训练时，即使是传统的DNN架构也更接近人类行为。最后，我们发现，虽然用多视图学习目标训练的模型能够部分推广到新的对象类别，但它们不能达到人类的一致性。这项工作为理解可神经映射的计算架构中的人形推断提供了基础，并突出了未来工作的重要问题。 et.al.|[2308.11300](http://arxiv.org/abs/2308.11300)|null|
|**2023-08-21**|**Canonical Cortical Field Theories**|我们根据场论，使用放置在皮层表面2D晶格上的神经单元来表征神经元活动的动力学。分析神经元单元的电活动，目的是推导出一个具有简单功能形式的神经场模型，该模型仍然能够预测或重现经验发现。使用神经质量对每个神经单元进行建模，并在连续极限中导出伴随的场论。场论包括耦合的（真实的）克莱因-戈登场，其中模型的预测属于实验结果的范围。这些预测包括从皮层测量的电活动频谱，该频谱是使用能量对神经场本征函数的平分得出的。此外，神经场模型在一组参数内对用于建模每个神经元质量的动力学系统是不变的。具体而言，拓扑等效的动力学系统在连接到晶格中时产生相同的神经场模型；这表明所导出的场可以被解读为典型的皮层场论。我们专门研究了为传入信息的编码（或表示）提供结构的非分散场。进一步阐述随后的神经场理论，包括分散力的影响，对于理解皮层对信息的处理可能具有重要意义。 et.al.|[2308.10645](http://arxiv.org/abs/2308.10645)|null|
|**2023-08-14**|**S3IM: Stochastic Structural SIMilarity and Its Unreasonable Effectiveness for Neural Fields**|最近，神经辐射场（NeRF）通过学习仅使用姿态RGB图像的隐式表示，在渲染给定场景的新视图图像方面取得了巨大成功。NeRF和相关的神经场方法（例如，神经表面表示）通常优化逐点损失并进行逐点预测，其中一个数据点对应于一个像素。不幸的是，这一研究未能使用对远处像素的集体监督，尽管已知图像或场景中的像素可以提供丰富的结构信息。据我们所知，我们是第一个通过一种新的随机结构相似性（S3IM）损失为NeRF和相关神经场方法设计非局部多重训练范式的人，该损失将多个数据点作为一个整体处理，而不是独立处理多个输入。我们的大量实验证明了S3IM在几乎免费改进NeRF和神经表面表示方面的不合理有效性。质量度量的改进对于那些相对困难的任务可能特别显著：例如，TensoRF和DVGO在八个新的视图合成任务中的测试MSE损失意外下降了90%以上；在八个表面重建任务中，NeuS的198%F分数增益和64%的倒角$L_。此外，即使在稀疏输入、损坏图像和动态场景的情况下，S3IM也始终是稳健的。 et.al.|[2308.07032](http://arxiv.org/abs/2308.07032)|**[link](https://github.com/madaoer/s3im_nerf)**|
|**2023-08-11**|**Zero-shot Text-driven Physically Interpretable Face Editing**|本文提出了一种基于任意文本提示的人脸编辑新方法，该方法具有物理可解释性。与以前基于GAN反转的人脸编辑方法（操纵GAN的潜在空间）或基于扩散的方法（将图像操纵建模为反向扩散过程）不同，我们将人脸编辑过程视为在人脸图像上施加矢量流场，表示每个图像像素的空间坐标和颜色的偏移。在上述提出的范式下，我们用两种方式表示矢量流场：1）用光栅化张量显式表示流矢量，2）通过利用隐式神经表示的最新进展，将流矢量隐式参数化为连续、平滑和分辨率不可知的神经场。在预先训练的对比语言图像预训练（CLIP）模型的指导下，通过最大化编辑后的图像和文本提示之间的相关性，迭代优化流向量。我们还提出了一种基于学习的一次性人脸编辑框架，该框架快速且适用于任何文本提示输入。我们的方法还可以灵活地扩展到实时视频人脸编辑。与最先进的文本驱动的人脸编辑方法相比，我们的方法可以生成具有高身份一致性和图像质量的物理可解释的人脸编辑结果。我们的代码将公开。 et.al.|[2308.05976](http://arxiv.org/abs/2308.05976)|null|
|**2023-08-07**|**Explicifying Neural Implicit Fields for Efficient Dynamic Human Avatar Modeling via a Neural Explicit Surface**|本文提出了一种通过神经显式表面（NES）来解释隐式神经场来有效地建模动态人类的技术。在根据稀疏观测对动态3D内容进行建模以及有效地表示复杂的几何形状和外观方面，隐式神经场比传统的显式表示具有优势。然而，由于在体积渲染过程中需要密集采样，在3D空间中定义的隐式神经场的渲染成本很高。此外，当对稀疏3D空间进行建模时，可以进一步优化它们的存储效率。为了克服这些问题，本文提出利用神经显式曲面（NES）来显式表示隐式神经场，以提高记忆和计算效率。为了实现这一点，本文利用隐式和显式方法的优势，在NES的隐式神经场和显式渲染接口之间创建了一个完全可微分的转换。这种转换能够使用隐式方法有效地训练混合表示，并通过将显式渲染接口与新提出的基于光栅化的神经渲染器集成来实现高效渲染，该神经渲染器对于与显式表面的初始光线交互只产生一次纹理颜色查询，从而提高推理效率。NES在2D空间中描述了具有姿态相关神经隐式表面变形场的动态人体几何结构及其动态神经纹理，这是传统3D方法的一种更具记忆效率的替代方法，减少了冗余和计算负载。综合实验表明，NES的性能与以前的3D方法类似，大大提高了渲染速度，降低了内存成本。 et.al.|[2308.05112](http://arxiv.org/abs/2308.05112)|null|
|**2023-08-15**|**Neural Field Movement Primitives for Joint Modelling of Scenes and Motions**|本文提出了一种新的从演示中学习（LfD）方法，该方法使用神经场来高效准确地学习新技能。它通过利用共享嵌入以生成的方式学习场景和运动表示来实现这一点。我们的方法将每个专家演示平滑地映射到场景运动嵌入，并学习对它们进行建模，而不需要手工制作的任务参数或大型数据集。它通过强制场景和运动生成相对于嵌入空间的变化是平滑的来实现数据效率。在推理时，我们的方法可以使用测试时间优化来检索场景运动嵌入，并为新场景生成精确的运动轨迹。所提出的方法是通用的，可以使用图像、3D形状和任何其他可以使用神经场建模的场景表示。此外，它还可以生成末端效应器位置和基于关节角度的轨迹。我们的方法是在需要精确运动轨迹生成的任务上进行评估的，其中基本任务参数化是基于对象位置和几何场景变化的。实验结果表明，该方法优于基线方法，可推广到新的场景中。此外，在真实世界的实验中，我们表明我们的方法可以成功地对多值轨迹进行建模，它对推理时引入的干扰对象是鲁棒的，并且它可以生成6D运动。 et.al.|[2308.05040](http://arxiv.org/abs/2308.05040)|null|
|**2023-08-10**|**InstantAvatar: Efficient 3D Head Reconstruction via Surface Rendering**|通过可微分表面或体积渲染来优化神经场以表示单个场景，从而获得了全头部重建的最新进展。虽然这些技术达到了前所未有的精度，但由于需要昂贵的优化过程，它们需要几分钟甚至几个小时。在这项工作中，我们介绍了InstantAvatar，一种在商品硬件上几秒钟内从几张图像（减少到一张）中恢复全头头像的方法。为了加快重建过程，我们首次提出了一种将体素网格神经场表示与曲面渲染器相结合的系统。值得注意的是，这两种技术的天真组合会导致不稳定的优化，无法收敛到有效的解决方案。为了克服这一限制，我们提出了一种新的统计模型，该模型使用基于体素网格的架构来学习3D头部符号距离函数上的先验分布。该现有模型的使用，与其他设计选择相结合，形成了一个系统，该系统以与现有技术相当的精度实现3D头部重建，速度提高了100倍。 et.al.|[2308.04868](http://arxiv.org/abs/2308.04868)|null|
|**2023-08-07**|**DNFOMP: Dynamic Neural Field Optimal Motion Planner for Navigation of Autonomous Robots in Cluttered Environment**|动态变化环境中的运动规划是自动驾驶中最复杂的挑战之一。除了驾驶舒适性和速度限制外，安全性也是一项至关重要的要求。虽然经典的基于采样、基于网格和基于优化的规划方法可以生成平滑而短的路径，但它们通常不考虑环境的动力学。一些技术确实考虑了这一点，但它们依赖于在旅途中更新环境，而不是明确考虑动态，这不适合自动驾驶。为了解决这一问题，我们提出了一种基于神经场最优运动规划器（NFOMP）的新方法，该方法在归一化曲率和尖端数量方面优于最先进的方法。我们的方法将先前已知的移动障碍物嵌入到神经场碰撞模型中，以考虑环境的动力学。我们还通过在轨迹损失函数中添加拉格朗日乘子，引入了轨迹的时间剖面和非线性速度约束。我们使用BeamNG.tech驾驶模拟器，将我们的方法应用于解决城市环境中的最优运动规划问题。一辆自动驾驶汽车在三个城市场景中驾驶生成的轨迹，同时与障碍车共享道路。我们的评估表明，乘客能立即体验到的最大加速度为-7.5 m/s ^2，89.6%的驾驶时间用于加速度低于3.5 m/s ^2的正常驾驶。驾驶风格的特点是，轻轨交通风格和适度驾驶风格分别占驾驶时间的46.0%和31.4%。 et.al.|[2308.03539](http://arxiv.org/abs/2308.03539)|null|
|**2023-08-04**|**DTF-Net: Category-Level Pose Estimation and Shape Reconstruction via Deformable Template Field**|从RGB深度图像对估计开放世界场景中物体的6D姿态和重建物体的3D形状是具有挑战性的。许多现有的方法依赖于学习与特定模板相对应的几何特征，而忽略同一类别中对象之间的形状变化和姿态差异。因此，在复杂环境中处理看不见的对象实例时，这些方法表现不佳。相比之下，其他方法旨在通过利用归一化的几何结构先验来实现类别级别的估计和重建，但基于静态先验的重建难以应对大量的类内变化。为了解决这些问题，我们提出了DTF-Net，这是一种基于对象类别的隐式神经场的姿态估计和形状重建的新框架。在DTF-Net中，我们设计了一个可变形模板域来表示一般类别的形状潜在特征和类别内的几何变形特征。该字段建立连续的形状对应关系，将类别模板变形为任意观察到的实例，以完成形状重建。我们引入了一个姿态回归模块，该模块共享来自场的变形特征和模板代码，以估计场景中每个对象的精确6D姿态。我们集成了一个多模态表示提取模块来提取对象特征和语义掩码，从而实现端到端推理。此外，在训练过程中，我们实现了形状不变的训练策略和视点采样方法，以进一步增强模型提取物体姿态特征的能力。在REAL275和CAMERA25数据集上进行的大量实验证明了DTF-Net在合成场景和真实场景中的优越性。此外，我们还证明了DTF-Net可以有效地支持真实机械臂的抓取任务。 et.al.|[2308.02239](http://arxiv.org/abs/2308.02239)|null|
|**2023-08-03**|**NeuroSwarm: Multi-Agent Neural 3D Scene Reconstruction and Segmentation with UAV for Optimal Navigation of Quadruped Robot**|四足机器人具有独特的能力，可以调整自己的身体和步幅高度，在杂乱的环境中导航。尽管如此，这些机器人要想在现实世界中充分发挥其潜力，就需要了解其环境和障碍物的几何形状。我们提出了一种新的多智能体机器人系统，该系统融合了尖端技术。所提出的解决方案具有3D神经重建算法，该算法能够在静态和半静态环境中对四足机器人进行导航。环境的先前区域也根据四足机器人通过它们的能力进行分割。此外，我们还开发了一种自适应神经场最优运动规划器（ANFOMP），该规划器同时考虑了二维空间中的碰撞概率和障碍物高度。我们的新导航和映射方法使四足机器人能够调整自己的高度和行为，在拱门下导航，并穿过较小尺寸的障碍物。多智能体映射操作已被证明是高度准确的，障碍物重建精度为82%。此外，四足机器人可以利用3D障碍物信息和ANFOMP系统进行导航，从而使路径长度减少33.3%，导航时间减少70%。 et.al.|[2308.01725](http://arxiv.org/abs/2308.01725)|**[link](https://github.com/iana-zhura/neuroswarm)**|
|**2023-07-31**|**DiVA-360: The Dynamic Visuo-Audio Dataset for Immersive Neural Fields**|神经领域的进步使得能够高保真地捕捉静态和动态场景的形状和外观。然而，由于算法挑战和缺乏大规模的真实世界数据集，它们的能力落后于像素或网格等表示所提供的能力。我们用DiVA-360解决了数据集的局限性，DiVA-36是一个真实世界的360动态视觉音频数据集，具有关于表级场景的同步多模式视觉、音频和文本信息。它包含46个动态场景、30个静态场景和95个静态对象，跨越11个类别，使用一个新的硬件系统捕获，该系统使用53个120 FPS的RGB相机和6个麦克风，总共获得8.6M图像帧和1360 s的动态数据。我们提供了所有场景的详细文本描述、前景背景分割遮罩、静态对象的特定类别3D姿势对齐，以及用于比较的指标。我们的数据、硬件和软件以及代码可在https://diva360.github.io/. et.al.|[2307.16897](http://arxiv.org/abs/2307.16897)|null|
|**2023-07-25**|**INFINITY: Neural Field Modeling for Reynolds-Averaged Navier-Stokes Equations**|对于数值设计来说，开发高效准确的替代模型至关重要。它们使我们能够近似复杂的物理现象，从而减少直接数值模拟的计算负担。我们提出了INFINITY，这是一种利用隐式神经表征（INRs）来应对这一挑战的深度学习模型。我们的框架将几何信息和物理场编码为紧凑表示，并学习它们之间的映射来推断物理场。我们使用翼型设计优化问题作为示例任务，并在具有挑战性的AirfRANS数据集上评估我们的方法，该数据集与现实世界的工业用例非常相似。实验结果表明，我们的框架通过准确推断整个体积和表面的物理场，实现了最先进的性能。此外，我们还证明了它在设计探索和形状优化等环境中的适用性：我们的模型可以在遵守方程的同时正确预测阻力和升力系数。 et.al.|[2307.13538](http://arxiv.org/abs/2307.13538)|null|
|**2023-08-24**|**Strivec: Sparse Tri-Vector Radiance Fields**|我们提出了Strivec，这是一种新的神经表示，它将3D场景建模为具有稀疏分布和紧凑因子分解的局部张量特征网格的辐射场。在最近的工作TensoRF之后，我们的方法利用张量分解来对张量网格进行建模。与使用全局张量并专注于向量矩阵分解的TensoRF不同，我们建议使用局部张量云，并应用经典的CANDECOMP/PARAFAC（CP）分解将每个张量分解为三个向量，这些向量表示沿空间轴的局部特征分布，并对局部神经场进行紧凑编码。我们还应用多尺度张量网格来发现几何和外观的共性，并在多个局部尺度上利用三向量分解来利用空间相干性。通过聚集来自所有尺度上的多个局部张量的神经特征来回归最终的辐射场特性。我们的三向量张量稀疏地分布在实际场景表面周围，这是通过利用3D场景的稀疏性进行快速粗略重建发现的。我们证明，我们的模型可以实现更好的渲染质量，同时使用比以前的方法（包括TensoRF和Instant NGP）更少的参数。 et.al.|[2307.13226](http://arxiv.org/abs/2307.13226)|**[link](https://github.com/zerg-overmind/strivec)**|

<p align=right>(<a href=#updated-on-20230902>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

