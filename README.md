[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.12.05
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-01**|**Gaussian Grouping: Segment and Edit Anything in 3D Scenes**|最近的Gaussian Splatting实现了3D场景的高质量实时新颖视图合成。然而，它只专注于外观和几何建模，而缺乏细粒度的对象级场景理解。为了解决这个问题，我们提出了高斯分组，它扩展了高斯飞溅，以联合重建和分割开放世界3D场景中的任何内容。我们用紧凑的身份编码来增强每个高斯，允许高斯根据其在3D场景中的对象实例或物质成员身份进行分组。我们没有求助于昂贵的3D标签，而是通过利用SAM的2D掩模预测以及引入的3D空间一致性正则化，在可微分渲染期间监督身份编码。与隐式NeRF表示相比，我们表明离散和分组的3D高斯可以以高视觉质量、细粒度和效率重建、分割和编辑3D中的任何内容。在高斯分组的基础上，我们进一步提出了一种局部高斯编辑方案，该方案在多功能场景编辑应用中显示了有效性，包括3D对象去除、修复、着色和场景重组。我们的代码和模型将在https://github.com/lkeab/gaussian-grouping. et.al.|[2312.00732](http://arxiv.org/abs/2312.00732)|**[link](https://github.com/lkeab/gaussian-grouping)**|
|**2023-12-01**|**EvE: Exploiting Generative Priors for Radiance Field Enrichment**|从野外不受约束的图像采集中建模大规模场景已被证明是计算机视觉的一大挑战。现有的处理野生神经渲染的方法在封闭世界环境中运行，其中知识仅限于训练集中场景的捕获图像。我们提出了EvE，据我们所知，这是第一种利用生成先验来改进野生场景建模的方法。我们使用预先训练的生成网络来用外部知识丰富K-Plane表示。为此，我们定义了一个交替训练程序，以对在训练集上训练的K-Planes进行优化指导。我们进行了广泛的实验，并在合成数据和真实的旅游照片集上验证了我们的方法的优点。EvE以更丰富的细节增强渲染场景，并在野外新颖的视图合成任务上优于现有技术。我们的项目页面可以在https://eve-nvs.github.io。 et.al.|[2312.00639](http://arxiv.org/abs/2312.00639)|null|
|**2023-11-30**|**MD-Splatting: Learning Metric Deformation from 4D Gaussians in Highly Deformable Scenes**|在具有遮挡和阴影的高度可变形场景中进行精确的3D跟踪可以促进机器人、增强现实和生成人工智能的新应用。然而，由于大变形、阴影和遮挡会产生模糊性，在这些条件下进行跟踪极具挑战性。我们介绍了MD Splatting，这是一种同时进行3D跟踪和新颖视图合成的方法，使用来自各种相机姿势的动态场景的视频捕捉。MD飞溅建立在高斯飞溅的最新进展之上，高斯飞溅是一种学习大量高斯特性的方法，用于最先进、快速的新视图合成。MD Splatting学习变形函数，将一组具有非度量性质的高斯投影到度量空间中。变形函数使用神经体素编码和多层感知器（MLP）来推断高斯位置、旋转和阴影标量。我们基于局部刚度、动量守恒和等距来执行受物理启发的正则化项，这导致轨迹误差较小。MD Splatting在具有阴影和遮挡的高度可变形场景上实现高质量的3D跟踪。与最先进的技术相比，我们将3D跟踪平均提高了23.9%，同时实现了高质量的新视图合成。有了足够的纹理，例如在场景6中，MD Splatting在1 x 1米大小的布料上实现了3.39毫米的中值跟踪误差。项目网站：https://md-splatting.github.io/. et.al.|[2312.00583](http://arxiv.org/abs/2312.00583)|null|
|**2023-12-01**|**FSGS: Real-Time Few-shot View Synthesis using Gaussian Splatting**|从有限的观测中合成新的观点仍然是一项重要而持久的任务。然而，为了获得准确的3D表示，现有的基于NeRF的少镜头视图合成中的高效率经常受到损害。为了应对这一挑战，我们提出了一种基于3D高斯散射的多镜头视图合成框架，该框架能够在只有三个训练视图的情况下进行实时和照片逼真的视图合成。所提出的方法被称为FSGS，通过精心设计的高斯去极化过程来处理极稀疏的初始化SfM点。我们的方法迭代地将新的高斯分布在最具代表性的位置周围，随后在空置区域填充局部细节。我们还在Gaussians优化过程中集成了一个大规模的预训练单目深度估计器，利用在线增强视图来引导几何优化走向最优解。从有限输入视点观察到的稀疏点开始，我们的FSGS可以准确地生长到看不见的区域，全面覆盖场景，提高新视图的渲染质量。总体而言，FSGS在各种数据集（包括LLFF、Mip-NeRF360和Blender）的准确性和渲染效率方面都达到了最先进的性能。项目网站：https://zehaozhu.github.io/fsgs/. et.al.|[2312.00451](http://arxiv.org/abs/2312.00451)|null|
|**2023-11-30**|**SparseGS: Real-Time 360° Sparse View Synthesis using Gaussian Splatting**|最近，随着神经辐射场（NeRFs）和其他隐式场景表示方法的引入，新颖视图合成问题显著流行起来。最近的一个进步，3D高斯飞溅（3DGS），利用显式表示实现实时渲染和高质量的结果。然而，3DGS仍然需要大量的训练视图来生成连贯的场景表示。在少数镜头设置中，与NeRF类似，3DGS倾向于过度拟合训练视图，导致背景塌陷和过多浮动，尤其是在训练视图数量减少的情况下。我们提出了一种从稀疏训练视图训练360场景的基于3DGS的相干辐射场的方法。我们发现，使用朴素的深度先验是不够的，并将深度先验与生成和显式约束相结合，以减少背景塌陷，消除漂浮物，并增强来自看不见的视点的一致性。实验表明，在MipNeRF-360数据集上，我们的方法在LPIPS中比基本3DGS高达30.5%，比基于NeRF的方法高达15.6%，训练和推理成本显著降低。 et.al.|[2312.00206](http://arxiv.org/abs/2312.00206)|null|
|**2023-11-30**|**DynMF: Neural Motion Factorization for Real-time Dynamic View Synthesis with 3D Gaussian Splatting**|由于时间动力学和运动复杂性，准确有效地建模动态场景和运动被认为是一项极具挑战性的任务。为了应对这些挑战，我们提出了DynMF，这是一种紧凑高效的表示方法，可以将动态场景分解为几个神经轨迹。我们认为，动态场景的每点运动可以分解为一小组明确的或学习的轨迹。我们精心设计的神经框架由一小组仅在时间上查询的学习基础组成，允许类似于3D高斯飞溅的渲染速度，超过120 FPS，同时与静态场景相比，只需要两倍的存储空间。我们的神经表示充分约束了动态场景中固有的欠约束运动场，从而实现了有效而快速的优化。这是通过将每个点与运动系数进行比较来实现的，该运动系数强制基本轨迹的每个点共享。通过仔细地将稀疏性损失应用于运动系数，我们能够解开构成场景的运动，独立地控制它们，并生成以前从未见过的新的运动组合。我们可以在训练的5分钟内达到最先进的渲染质量，在不到半小时的时间内，我们可以合成具有卓越照片真实感质量的动态场景的新颖视图。我们的表示具有可解释性、高效性和表达性，足以在单目和多视图场景中提供复杂动态场景运动的实时视图合成。 et.al.|[2312.00112](http://arxiv.org/abs/2312.00112)|null|
|**2023-11-30**|**Periodic Vibration Gaussian: Dynamic Urban Scene Reconstruction and Real-time Rendering**|由于其高度复杂的几何结构和在空间和时间上不受约束的动力学，建模动态的、大规模的城市场景具有挑战性。先前的方法通常采用高级架构先验，将静态和动态元素分离，从而导致对其协同交互的次优捕获。为了应对这一挑战，我们提出了一个统一的表示模型，称为周期振动高斯（PVG）。PVG建立在高效的3D高斯飞溅技术的基础上，该技术最初是为静态场景表示而设计的，通过引入基于周期振动的时间动力学。这一创新使PVG能够在动态的城市场景中优雅、统一地表现各种物体和元素的特征。为了利用稀疏训练数据增强时间相干表示学习，我们引入了一种新的基于流的时间平滑机制和位置感知自适应控制策略。在Waymo开放数据集和KITTI基准上进行的大量实验表明，PVG在动态和静态场景的重建和新视图合成方面都超过了最先进的替代方案。值得注意的是，PVG实现了这一点，而不依赖于手动标记的对象边界框或昂贵的光流估计。此外，与最佳替代方案相比，PVG在训练/渲染中表现出50/6000倍的加速。 et.al.|[2311.18561](http://arxiv.org/abs/2311.18561)|null|
|**2023-11-30**|**ZeST-NeRF: Using temporal aggregation for Zero-Shot Temporal NeRFs**|在媒体制作领域，视频编辑技术起着举足轻重的作用。最近的方法在执行静态场景的新颖视图图像合成方面取得了巨大成功。但是，添加时间信息会增加额外的复杂性。以前的模型专注于使用NeRF隐式地表示静态和动态场景。这些模型取得了令人印象深刻的结果，但在训练和推理时代价高昂。它们过拟合MLP以将场景隐含地描述为位置的函数。本文提出了ZeST NeRF，这是一种新的方法，可以在不进行再训练的情况下为新场景生成时间NeRF。我们可以使用多视图合成技术和场景流场估计来准确地重建新视图，只使用不相关的场景进行训练。我们展示了来自一系列领域的现有最先进方法如何无法充分解决这一新任务，并展示了我们的解决方案的有效性。所得到的网络在数量上提高了15%，并产生了明显更好的视觉效果。 et.al.|[2311.18491](http://arxiv.org/abs/2311.18491)|null|
|**2023-11-30**|**Language Embedded 3D Gaussians for Open-Vocabulary Scene Understanding**|三维空间中的开放式词汇查询具有挑战性，但对于对象定位和分割等场景理解任务至关重要。通过将语言特征结合到3D空间中，嵌入语言的场景表示已经取得了进展。然而，它们的功效在很大程度上取决于在训练和渲染中资源密集型的神经网络。尽管最近的3D Gaussians提供了高效和高质量的新颖视图合成，但直接在其中嵌入语言特征会导致令人望而却步的内存使用和性能下降。在这项工作中，我们介绍了一种用于开放式词汇查询任务的新型场景表示语言嵌入式三维高斯。我们没有在3D高斯上嵌入高维原始语义特征，而是提出了一种专门的量化方案，大大降低了内存需求，并提出了一个新的嵌入过程，实现了更平滑但高精度的查询，对抗了基于点的表示中的多视图特征不一致和高频归纳偏差。我们的综合实验表明，我们的表示在当前语言嵌入式表示中实现了最佳的视觉质量和语言查询准确性，同时在单个桌面GPU上保持实时渲染帧率。 et.al.|[2311.18482](http://arxiv.org/abs/2311.18482)|null|
|**2023-11-30**|**Anisotropic Neural Representation Learning for High-Quality Neural Rendering**|神经辐射场（NeRFs）通过从多视图图像中学习隐式体积表示，获得了令人印象深刻的视图合成结果。为了将隐式表示投影到图像中，NeRF采用体积渲染，该渲染将光线的连续积分近似为采样点的颜色和密度的累积。尽管这种近似可以实现高效渲染，但它忽略了点间隔中的方向信息，导致特征不明确，重建质量有限。在本文中，我们提出了一种各向异性神经表示学习方法，该方法利用可学习的视图相关特征来改进场景表示和重建。我们将体积函数建模为球面谐波（SH）引导的各向异性特征，通过多层感知器进行参数化，有助于消除模糊，同时保持渲染效率。为了在没有各向异性过拟合的情况下实现稳健的场景重建，我们在训练过程中正则化各向异性特征的能量。我们的方法是灵活的，可以插入到基于NeRF的框架中。大量实验表明，所提出的表示可以提高各种NeRF的渲染质量，并在合成场景和真实世界场景中实现最先进的渲染性能。 et.al.|[2311.18311](http://arxiv.org/abs/2311.18311)|null|

<p align=right>(<a href=#updated-on-20231205>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-01**|**UAVs and Birds: Enhancing Short-Range Navigation through Budgerigar Flight Studies**|这项研究深入研究了布吉鸟的飞行行为，以深入了解它们的飞行轨迹和运动。利用立体摄像机记录的三维重建，我们仔细检查了起飞、飞行和着陆三个飞行运动过程中的速度和加速度模式。这些发现不仅有助于我们理解鸟类的行为，而且对无人机算法的发展具有重要意义。这项研究旨在弥合在鸟类身上观察到的生物学原理与这些见解在开发更高效、更自主的无人机方面的应用之间的差距。在无人机使用日益增多的背景下，本研究重点关注从鸟类行为中汲取的生物学启发原理，特别是在起飞、飞行和着陆飞行过程中，以增强无人机的能力。为这项研究创建的数据集揭示了布吉鸟的起飞、飞行和着陆技术，强调了它们在不同情况和表面上控制速度的能力。这项研究强调了将这些原理纳入无人机算法的潜力，以应对与短程导航、起飞、飞行和着陆相关的挑战。 et.al.|[2312.00597](http://arxiv.org/abs/2312.00597)|null|
|**2023-12-01**|**MultiView Independent Component Analysis with Delays**|线性独立分量分析（ICA）是一种盲源分离技术，已在各个领域用于从观测信号中识别独立的潜在源。为了获得更高的信噪比，可以使用相同源的多个视图的存在。在这项工作中，我们提出了具有延迟的多视图独立分量分析（MVICAD）。该算法建立在多视图ICA模型的基础上，允许源是某些共享源的延迟版本：源在视图之间共享，直到一些特定于视图和源的未知延迟。通过模拟，我们证明了MVICAD可以更好地分解源。此外，由于ICA经常用于神经科学，我们表明，当应用于大规模脑磁图（MEG）数据集Cam CAN时，潜伏期与年龄有关。这些结果表明，MVICAD模型可以在没有人类监督的情况下揭示对神经信号的丰富影响。 et.al.|[2312.00484](http://arxiv.org/abs/2312.00484)|null|
|**2023-12-01**|**Towards Aligned Canonical Correlation Analysis: Preliminary Formulation and Proof-of-Concept Results**|规范相关分析（CCA）已被广泛应用于将数据的多个视图联合嵌入到最大相关的潜在空间中。然而，传统方法所要求的各种数据视角之间的一致性在许多实际情况下并不明确。在这项工作中，我们提出了一个新的框架——对齐规范相关分析（ACCA），通过迭代求解对齐和多视图嵌入来应对这一挑战。 et.al.|[2312.00296](http://arxiv.org/abs/2312.00296)|null|
|**2023-11-30**|**Fool the Hydra: Adversarial Attacks against Multi-view Object Detection Systems**|对抗性补丁举例说明了在现实世界场景中，对抗性攻击对机器学习（ML）模型构成的威胁的具体表现。在设计计算机视觉应用程序时，尤其是在CCTV系统等安全关键领域，抵御这些攻击的稳健性至关重要。在大多数实际情况下，监控开放空间需要多视图系统来克服诸如遮挡处理之类的采集挑战。多视图对象系统能够组合来自多个视图的数据，即使在困难的环境中也能获得可靠的检测结果。尽管多视角系统在现实世界的视觉应用中很重要，但它对对抗性补丁的脆弱性没有得到充分的研究。在本文中，我们提出了以下问题：提高的性能和跨视图的信息共享是否作为对抗性补丁的副产品提供了鲁棒性？我们首先进行了初步分析，显示了对现成的对抗性补丁的良好鲁棒性，即使在我们考虑Wildtrack基准中所有人应用于所有视图的极端情况下也是如此。然而，我们通过提出两种新的攻击来挑战这一观察结果：（i）在第一种攻击中，针对多视图CNN，我们通过向不同视图提出梯度投影并聚合获得的局部梯度来最大化全局损失。（ii）在第二个攻击中，我们重点关注基于Transformer的多视图框架。除了焦点损耗之外，我们还通过耗散其注意力块来最大化变压器的特定损耗。我们的结果表明，受害者多视角系统的检测性能大幅下降，我们的第一次补丁攻击的攻击成功率达到73%，而我们提出的第二次攻击使其目标检测器的性能降低了62% et.al.|[2312.00173](http://arxiv.org/abs/2312.00173)|null|
|**2023-11-30**|**Learning One-Shot 4D Head Avatar Synthesis using Synthetic Data**|现有的单镜头4D头部合成方法通常在3DMM重建的帮助下从单眼视频中学习，但后者同样具有挑战性，这限制了它们进行合理的4D头部合成。我们提出了一种通过大规模合成数据学习一次4D头部合成的方法。关键是首先通过对抗性学习从单眼图像中学习部分4D生成模型，将不同身份和全动作的多视角图像合成为训练数据；然后利用基于变换器的可动画三平面重建器来学习使用合成数据的4D头部重建。提出了一种新的学习策略，通过分解三维重建和再现的学习过程来增强对真实图像的可推广性。实验证明了我们优于现有技术。 et.al.|[2311.18729](http://arxiv.org/abs/2311.18729)|null|
|**2023-11-30**|**Multi-task learning with cross-task consistency for improved depth estimation in colonoscopy**|结肠镜检查是评估结肠和直肠异常（如溃疡和癌性息肉）的金标准程序。测量异常粘膜面积及其三维重建有助于量化测量面积并客观评估疾病负担。然而，由于这些器官的复杂拓扑结构和可变的物理条件，例如，照明、大的均匀纹理和估计与相机的距离（即深度）的图像模态是极具挑战性的。此外，大多数结肠镜视频采集都是单目的，这使得深度估计成为一个不平凡的问题。虽然已经在自然场景数据集上提出并改进了计算机视觉中的深度估计方法，但这些技术的功效尚未在结肠镜检查数据集上得到广泛量化。由于结肠粘膜有几个不太明显的低纹理区域，从辅助任务中学习表征可以改进显著特征提取，从而能够估计准确的相机深度。在这项工作中，我们提出开发一种新的多任务学习（MTL）方法，该方法具有共享编码器和两个解码器，即表面法线解码器和深度估计器解码器。我们的深度估计器结合了注意力机制来增强全球上下文意识。我们利用曲面法线预测来改进几何特征提取。此外，我们在两个几何相关的任务，表面法线和相机深度之间应用了跨任务一致性损失。我们证明，与最准确的基线最先进的BTS方法相比，相对误差提高了14.17%， $\delta_｛1｝$ 精度提高了10.4%。所有实验都是在最近发布的C3VD数据集上进行的；因此，我们提供了最先进方法的第一个基准。 et.al.|[2311.18664](http://arxiv.org/abs/2311.18664)|null|
|**2023-11-30**|**HOLD: Category-agnostic 3D Reconstruction of Interacting Hands and Objects from Video**|由于人类每天都与不同的物体互动，因此对这些互动的整体3D捕捉对于理解和模拟人类行为非常重要。然而，大多数现有的从RGB重建手对象的方法要么假设预先扫描的对象模板，要么严重依赖有限的3D手对象数据，这限制了它们缩放和推广到更不受约束的交互设置的能力。为此，我们介绍了HOLD——第一种不可知类别的方法，它可以从单目交互视频中联合重建关节手和物体。我们开发了一个组合铰接隐式模型，可以从2D图像中重建解开纠缠的3D手和物体。我们还进一步结合了手对象约束，以提高手对象姿态，从而提高重建质量。我们的方法不依赖于3D手对象注释，同时在实验室和野外环境中都优于完全监督的基线。此外，我们定性地展示了它在野外视频重建中的稳健性。代码：https://github.com/zc-alexfan/hold et.al.|[2311.18448](http://arxiv.org/abs/2311.18448)|**[link](https://github.com/zc-alexfan/hold)**|
|**2023-11-30**|**Dispersed Structured Light for Hyperspectral 3D Imaging**|高光谱三维成像旨在获取场景的深度和光谱信息。然而，现有的方法要么过于昂贵和庞大，要么在光谱和深度精度上妥协。在这项工作中，我们提出了分散结构光（DSL），这是一种用于精确高光谱3D成像的成本效益高且紧凑的方法。DSL通过在投影仪前面放置亚毫米厚的衍射光栅膜来修改传统的投影仪相机系统。光栅基于光波长对结构光进行散射。为了利用分散的结构光，我们设计了一种分散投影图像形成模型和每像素高光谱三维重建方法。我们通过实例化一个紧凑的实验原型来验证DSL。DSL实现了18.8nm全宽半峰（FWHM）的光谱精度和1mm的深度误差。我们证明DSL在实际高光谱3D成像方面优于先前的工作。DSL承诺为不同的应用领域提供准确实用的高光谱3D成像，包括计算机视觉和图形、文化遗产、地质学和生物学。 et.al.|[2311.18287](http://arxiv.org/abs/2311.18287)|null|
|**2023-11-29**|**Meta Co-Training: Two Views are Better than One**|在许多实际的计算机视觉场景中，未标记的数据是丰富的，但标签稀缺且难以获得。因此，利用未标记数据来提高监督分类器性能的半监督学习在最近的文献中受到了极大的关注。半监督算法的一个主要类别是协同训练。在联合训练中，两个不同的模型利用不同的独立和充分的数据“视图”来联合做出更好的预测。在联合训练期间，每个模型在未标记的点上创建伪标签，用于改进另一个模型。我们证明，在通常情况下，当独立视图不可用时，我们可以使用预先训练的模型廉价地构建这样的视图。在构建的视图上进行联合训练，与我们构建的任何单个视图相比，都能提高性能，并且性能与半监督学习中的最新方法相当，但具有一些不可取的特性。为了缓解共同训练中存在的问题，我们提出了元共同训练，这是成功的元伪标签方法对多个视图的扩展。我们的方法在ImageNet-10%上实现了最先进的性能，只需很少的训练资源，并且在其他几个细粒度图像分类数据集上优于先前的半监督工作。 et.al.|[2311.18083](http://arxiv.org/abs/2311.18083)|**[link](https://github.com/jayrothenberger/meta-co-training)**|
|**2023-11-29**|**Volumetric Cloud Field Reconstruction**|云和雾等体积现象由于其半透明性质及其与光的复杂相互作用，给3D重建系统带来了重大挑战。重建散射体积的传统技术依赖于受控设置，限制了实际应用。本文介绍了一种从几个输入立体声对重建体积的方法。我们提出了一种新的深度学习框架，该框架将深度立体模型与3D卷积神经网络（3D CNN）和平流模块集成在一起，能够捕捉体积的形状和动力学。立体深度用于在体积周围雕刻空白空间，为3D CNN提供了应对输入视图不足的先验知识。对我们的输出进行细化后，平流模块利用了介质的时间演变，提供了一种推断运动和提高时间一致性的机制。我们的系统通过其从一组稀疏的立体图像对中估计大规模体积（在这种情况下是云）的密度和速度场的能力来证明其有效性。 et.al.|[2311.17657](http://arxiv.org/abs/2311.17657)|null|

<p align=right>(<a href=#updated-on-20231205>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-01**|**MorpheuS: Neural Dynamic 360° Surface Reconstruction from Monocular RGB-D Video**|神经渲染在动态场景重建中取得了显著的成功。由于神经表示的表现力，先前的工作可以准确地捕捉运动，并实现目标对象的高保真重建。尽管如此，真实世界的视频场景通常以大的未观察到的区域为特征，在这些区域中，神经表示难以实现真实的完成。为了应对这一挑战，我们介绍了MorpheuS，这是一种从随意捕获的RGB-D视频中进行动态360°表面重建的框架。我们的方法将目标场景建模为对其几何体和外观进行编码的规范场，以及将点从当前帧扭曲到规范空间的变形场。我们利用依赖于视图的扩散先验并从中提取知识，以实现未观测区域的现实完成。在各种真实世界和合成数据集上的实验结果表明，我们的方法可以从单目RGB-D视频中实现可变形物体的高保真360度表面重建。 et.al.|[2312.00778](http://arxiv.org/abs/2312.00778)|null|
|**2023-12-01**|**VideoBooth: Diffusion-based Video Generation with Image Prompts**|文本驱动的视频生成取得了快速进展。然而，仅仅使用文本提示不足以描绘出与用户意图准确一致的所需主题外观，尤其是对于定制内容创建而言。在本文中，我们研究了带有图像提示的视频生成任务，它在文本提示之外提供了更准确、更直接的内容控制。具体来说，我们提出了一个前馈框架VideoBooth，有两个专门的设计：1）我们建议以从粗到细的方式嵌入图像提示。来自图像编码器的粗略视觉嵌入提供图像提示的高级编码，而来自所提出的注意力注入模块的精细视觉嵌入提供了图像提示的多尺度和详细编码。这两个互补的嵌入可以忠实地捕捉期望的外观。2） 在精细级别的注意力注入模块中，将多尺度图像提示作为附加的关键点和值输入到不同的跨帧注意力层中。这种额外的空间信息细化了第一帧中的细节，然后将其传播到其余帧，从而保持了时间一致性。大量实验表明，VideoBooth在生成具有图像提示中指定主题的定制高质量视频方面实现了最先进的性能。值得注意的是，VideoBooth是一个可推广的框架，其中单个模型通过前馈处理适用于各种图像提示。 et.al.|[2312.00777](http://arxiv.org/abs/2312.00777)|null|
|**2023-12-01**|**CompuCell3D Model of Cell Migration Reproduces Chemotaxis**|趋化结合了三个过程：方向感测、极性重新定向和迁移。定向迁移在免疫反应、转移、伤口愈合和发育中起着重要作用。为了描述趋化性，我们扩展了先前发表的3D单细胞的计算模型，该模型具有三个隔间（瓣状体、细胞核和细胞质），其在平坦表面上的迁移定量地描述了实验。该仿真是在CompuCell3D的框架下构建的，CompuCell三维是一个基于细胞Potts模型的环境。在我们的扩展中，我们将趋化性视为一个复合过程，而不是对潜在力量的反应。我们提出了稳健的协议来测量细胞持久性、漂移速度、末端速度、趋化效率、趋化时间，并从位置和极化记录通过时间分析细胞参考系中的细胞迁移动力学。我们的指标可以应用于实验结果，并允许在模拟和实验之间进行定量比较。我们发现，我们模拟的细胞在极化稳定性和趋化效率之间表现出权衡。具体来说，我们发现突起力较低、片状足较小的细胞表现出更强的趋化能力。我们还注意到，在分析细胞参考系中的细胞位移时，由于外部化学梯度，细胞运动没有显著变化。我们的结果证明了在整个细胞轨迹中测量细胞极性的重要性，并在细胞运动以短时间间隔扩散时仔细处理速度量。我们开发的模拟足以开发新的测量协议，它有助于为更复杂的多细胞模拟铺平道路，以模拟集体迁移及其与外部场的相互作用，这些模拟目前正在开发中。 et.al.|[2312.00776](http://arxiv.org/abs/2312.00776)|null|
|**2023-12-01**|**Effects of three-dimensional slit geometry on flashback of premixed hydrogen flames in perforated burners**|鉴于人们对氢作为住宅和商业供暖的清洁燃料越来越感兴趣，因此越来越需要开发最终用户设备的新设计，这必须确保效率和安全。在这项研究中，首次使用3D模拟来研究狭缝长度如何影响穿孔燃烧器中氢气预混火焰的回火极限，穿孔燃烧器通常用于冷凝锅炉等最终用户设备。在三个当量比（ $\phi=0.6$、$0.8$和$1.0$ ）下计算氢火焰的回火极限，研究长度增加至8mm的圆孔和狭缝。进行瞬态和稳态模拟以全面捕捉回火动力学并研究广泛的参数变化。将结果与2D模拟进行比较，发现2D模拟大大低估了回火速度。对于足够长的狭缝，观察到回火速度实际上不受狭缝长度的影响，并基于对狭缝远端回火开始的观察给出了解释。重点讨论了优先扩散效应，阐明了它们在倒叙动力学中狭缝末端的重要性中的作用。 et.al.|[2312.00744](http://arxiv.org/abs/2312.00744)|null|
|**2023-12-01**|**Functional Renormalization Group Study of Thermodynamic Geometry Around the Phase Transition of Quantum Chromodynamic**|我们研究了夸克介子模型在有限温度 $T$和夸克数化学势$\mu$下的热力学几何。我们通过利用函数重整化群方法包含波动来扩展先前的工作。我们利用最近的发展将流动方程重新定义为平流-扩散方程。我们对有效平均作用采用局部势近似。我们关注在手性交叉附近的$（\mu，T）$平面中的热力学曲率$R$，直到相图的临界点。我们发现，包含波动导致$R$在手性交叉附近的行为更平滑。此外，对于较小的$\mu$，$R$保持负值，这表明玻色子波动降低了系统完全克服夸克的费米子统计排斥的能力。我们通过分析一个系统来更详细地研究小$\mu$区域，在该系统中，我们人为地降低了π介子的质量，从而接近了手性极限，在该极限中，交叉实际上是二阶相变。另一方面，随着$\mu$的增加和临界点的接近，我们发现$R$增加并发生符号变化，这与平均场研究一致。因此，我们完全支持$R$ 对交叉和相变敏感的观点，并提供了关于系统在相变时的有效行为的信息。 et.al.|[2312.00665](http://arxiv.org/abs/2312.00665)|null|
|**2023-12-01**|**Resource-constrained knowledge diffusion processes inspired by human peer learning**|我们考虑一个环境，在该环境中，给定了一群人工学习者，目标是在训练资源的限制下，优化绩效的总体衡量标准。这个问题的动机是对人类教育系统中的同伴学习的研究。在这种背景下，我们研究了交互人工学习者网络中的自然知识扩散过程。所谓“自然”，我们指的是反映人类同伴学习的过程，其中学生的内部状态和学习过程大多是不透明的，主要的自由度在于由协调员组成同伴学习小组，协调员可以在将学习者分配到同伴小组之前对其进行潜在的评估。除此之外，我们的经验表明，这样的过程确实有效地利用了训练资源，并能够设计出模块化神经模型，该模型具有泛化能力，而不容易过拟合噪声标签。 et.al.|[2312.00660](http://arxiv.org/abs/2312.00660)|null|
|**2023-12-01**|**TrackDiffusion: Multi-object Tracking Data Generation via Diffusion Models**|扩散模型在为感知任务（如图像分类和物体检测）生成数据方面已经获得了突出地位。然而，作为视频感知领域的一个关键方面，生成高质量跟踪序列的潜力尚未得到充分研究。为了解决这一差距，我们提出了TrackDiffusion，这是一种新的架构，旨在从Tracklet生成连续的视频序列。TrackDiffusion通过使图像扩散模型能够包含动态和连续的跟踪轨迹，从而捕捉复杂的运动细微差别，并确保视频帧之间的实例一致性，显著偏离了传统的图像布局（L2I）生成和复制粘贴合成，重点关注边界框等静态图像元素。我们首次证明，生成的视频序列可以用于训练多目标跟踪（MOT）系统，从而显著提高跟踪器的性能。实验结果表明，我们的模型显著增强了生成的视频序列中的实例一致性，从而改进了感知度量。在YTVIS数据集上，我们的方法在TrackAP中实现了8.7的改进，在TrackAP $_{50}$ 中实现了11.8的改进，强调了其重新定义MOT任务及其他任务的视频数据生成标准的潜力。 et.al.|[2312.00651](http://arxiv.org/abs/2312.00651)|null|
|**2023-12-01**|**How the zebra got its stripes: Curvature-dependent diffusion orients Turing patterns on 3D surfaces**|许多动物都有花纹的皮毛、羽毛或鳞片，比如斑马的条纹。图灵模型，或称反应扩散系统，是一类相互作用物种的数学模型，已成功用于为许多物种生成类似动物的模式。当抑制剂的扩散相对于活化剂足够高时，扩散驱动的不稳定性可以自发地形成图案。然而，重要的不仅仅是模式的类型，还有方向，目前尚不清楚在实践中是如何做到这一点的。在这里，我们提出了一种机制，通过该机制，表面的曲率会影响扩散速率，并可以在数值模拟中重新获得斑马和猫模型上条纹的正确方向。先前的工作已经表明，各向异性扩散如何使条纹形成反应扩散系统在取向上产生偏差。根据斑马条纹在最高曲率方向上运行的观察结果，即在躯干和腿部周围，我们通过修改基于局部曲率的方向上的扩散率来应用这一结果。这些结果显示了局部几何形状如何影响反应动力学，从而给出稳健的全局尺度模式。总的来说，该模型提出了系统几何形状和反应扩散动力学之间的耦合，可以通过仅使用局部曲率信息来对图案进行全局控制。这样的模型可以在动物发育中提供形状和定位信息，而不需要空间依赖的形态发生梯度。 et.al.|[2312.00637](http://arxiv.org/abs/2312.00637)|null|
|**2023-12-01**|**Stopper vs. singular-controller games with degenerate diffusions**|当底层受控扩散过程的（状态相关）扩散矩阵退化时，我们研究了奇异控制器和停止器之间的零和随机对策。特别地，我们证明了博弈值的存在性，并确定了塞子的最优策略。动力学的退化性阻碍了基于索博列夫空间中合适的变分问题的解的分析方法的使用。因此，我们采用了一种基于由参数 $\gamma>0$调制的底层扩散扰动的概率方法。对于每个$\gamma>0$，近似对策是非退化的，并且允许值$u^\gamma$和塞子的最优策略$\tau^\gamma _*$。让$\gamma\为0$，我们证明$u^\gamma$收敛于函数$v$，该函数确定了原始游戏的值。我们还构造了$u^\gamma$的显式最优停止时间$\theta^\gamma _*$，与$\tau^\gamma_*$相关但不等于$\tau^ \gamma_*$。对于退化动力学的博弈，它们几乎肯定收敛到最优停止时间$\theta_*$ 上。 et.al.|[2312.00613](http://arxiv.org/abs/2312.00613)|null|
|**2023-12-01**|**New Continuum Observations of the Andromeda galaxy M31 with FAST**|我们提出了一张新的M31总强度图像，该图像是用500米口径球面射电望远镜（FAST）在1.248 GHz下观测到的，角分辨率为4 arcmin，灵敏度约为16 mK。新的FAST图像清楚地显示了由于其对大型结构的高灵敏度，环外发射较弱。我们推导出宇宙线电子的标度长度为2.7kpc，并通过比较4.8GHz的标度长发现宇宙线电子主要通过扩散传播。总强度的光谱指数沿环变化，这可归因于同步辐射光谱的变化。这种变化很可能是由环上恒星形成率的变化引起的。我们发现，非热发射的方位角分布可以通过沿环变化节距角的轴对称大尺度磁场来解释，这表明M31中存在复杂的磁场配置。 et.al.|[2312.00441](http://arxiv.org/abs/2312.00441)|null|

<p align=right>(<a href=#updated-on-20231205>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-11-29**|**Accelerating Neural Field Training via Soft Mining**|我们提出了一种通过有效选择采样位置来加速神经场训练的方法。虽然神经场最近变得很流行，但它通常是通过对训练域进行统一采样或通过手工启发式进行训练的。我们证明，通过基于重要性采样的软挖掘技术可以提高收敛性和最终训练质量：我们不是完全考虑或忽略一个像素，而是用标量来衡量相应的损失。为了实现我们的想法，我们使用Langevin蒙特卡罗采样。我们表明，通过这样做，具有更高误差的区域被更频繁地选择，导致收敛速度提高了2倍以上。本研究的代码和相关资源可在https://ubc-vision.github.io/nf-soft-mining/. et.al.|[2312.00075](http://arxiv.org/abs/2312.00075)|null|
|**2023-11-29**|**Neural Fields with Thermal Activations for Arbitrary-Scale Super-Resolution**|最近的任意尺度单图像超分辨率（ASSR）方法已经使用局部神经场来表示可以以不同速率采样的连续信号。然而，在这样的公式中，场值的逐点查询并不自然地与给定像素的点扩散函数（PSF）匹配。在这项工作中，我们提出了一种设计神经场的新方法，使得可以使用高斯PSF来查询点，该函数在ASSR的分辨率之间移动时起到抗混叠的作用。我们使用从傅立叶理论和热方程导出的新激活函数来实现这一点。这不需要额外的成本：与图像域中的滤波不同，在我们的框架中使用高斯PSF查询点不会影响计算成本。与超网络相结合，我们的方法不仅提供了理论上有保证的抗混叠，而且为ASSR设置了一个新的标准，同时也比以前的方法更具参数效率。 et.al.|[2311.17643](http://arxiv.org/abs/2311.17643)|null|
|**2023-11-28**|**In Search of a Data Transformation That Accelerates Neural Field Training**|神经场是数据表示中一种新兴的范式，它训练神经网络来逼近给定的信号。阻碍其广泛采用的一个关键障碍是编码速度——生成神经场需要神经网络的过拟合，这可能需要大量的SGD步骤才能达到所需的保真度水平。在本文中，我们深入研究了数据转换对神经场训练速度的影响，特别是关注像素位置的排列如何影响SGD的收敛速度。与直觉相反，我们发现随机排列像素位置可以显著加速训练。为了解释这一现象，我们通过PSNR曲线、损失景观和误差模式来检验神经场训练。我们的分析表明，随机像素排列去除了易于拟合的模式，这有助于在早期阶段进行简单的优化，但阻碍了捕捉信号的精细细节。 et.al.|[2311.17094](http://arxiv.org/abs/2311.17094)|null|
|**2023-11-28**|**HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting**|根据文本提示生成逼真的三维人体是一项理想但具有挑战性的任务。现有的方法通过分数蒸馏采样（SDS）优化3D表示，如网格或神经场，其存在细节不足或训练时间过长的问题。在本文中，我们提出了一个高效而有效的框架HumanGaussian，它可以生成具有细粒度几何结构和逼真外观的高质量3D人。我们的关键见解是，3D高斯飞溅是一种具有周期性高斯收缩或增长的高效渲染器，其中这种自适应密度控制可以由内在的人体结构自然引导。具体而言，1）我们首先提出了一种结构感知SDS，它可以同时优化人体外观和几何形状。利用RGB和深度空间的多模态得分函数来提取高斯致密化和修剪过程。2） 此外，我们通过将SDS分解为更嘈杂的生成分数和更干净的分类器分数，设计了一种退火的负提示引导，很好地解决了过饱和问题。在仅修剪阶段中，基于高斯大小进一步消除浮动伪影，以增强生成平滑度。大量实验证明了我们的框架具有卓越的效率和竞争力，在不同的场景下呈现了生动的3D人类。项目页面：https://alvinliu0.github.io/projects/humangaussian et.al.|[2311.17061](http://arxiv.org/abs/2311.17061)|null|
|**2023-11-28**|**SplitNeRF: Split Sum Approximation Neural Field for Joint Geometry, Illumination, and Material Estimation**|我们提出了一种新的方法，通过从一组具有固定照明的姿势图像中估计真实世界物体的几何结构、材料特性和环境照明来数字化它们。我们的方法将分割和近似与基于图像的照明结合到神经辐射场（NeRF）管道中，用于基于物理的实时渲染。我们建议使用单个场景特定的MLP来建模场景的照明，该MLP表示任意分辨率的预集成的基于图像的照明。我们通过开发一种基于有效蒙特卡罗采样的新型正则化子来实现预集成照明的精确建模。此外，我们还提出了一种新的方法，通过利用基于蒙特卡罗采样的类似正则化子来监督自遮挡预测。实验结果证明了我们的方法在估计场景几何、材料特性和照明方面的效率和有效性。我们的方法能够在单个NVIDIA A100 GPU中仅经过 ${\sim}1$ 小时的训练后就获得最先进的重新照明质量。 et.al.|[2311.16671](http://arxiv.org/abs/2311.16671)|null|
|**2023-11-27**|**MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers**|我们介绍了MeshGPT，这是一种生成三角形网格的新方法，它反映了艺术家创建的网格的典型紧凑性，而不是通过等表面方法从神经场中提取的密集三角形网格。受强大的大型语言模型最近进展的启发，我们采用了一种基于序列的方法来自回归生成三角形网格作为三角形序列。我们首先使用图卷积来学习潜在量化嵌入的词汇表，图卷积为这些嵌入提供了局部网格几何和拓扑的信息。这些嵌入被解码器排序并解码为三角形，确保它们能够有效地重建网格。然后在这个学习的词汇表上训练转换器，以在给定先前嵌入的情况下预测下一个嵌入的索引。一旦训练好，我们的模型就可以进行自回归采样以生成新的三角形网格，直接生成具有尖锐边缘的紧凑网格，更接近于模仿手工网格的有效三角测量模式。与最先进的网格生成方法相比，MeshGPT有了显著的改进，形状覆盖率提高了9%，各种类别的FID得分提高了30分。 et.al.|[2311.15475](http://arxiv.org/abs/2311.15475)|null|
|**2023-11-26**|**Distributed Delay and Desynchronization in a Brain Network Model**|我们考虑一个神经场模型，该模型由任意数量的Wilson Cowan节点的网络组成，该网络具有抑制性耦合强度和延时兴奋性耦合的稳态调节。我们扩展了以前对该模型的研究，将具有常用核分布的分布式时延包括在内：德尔塔函数、均匀分布和伽玛分布。重点讨论满足常行和条件的网络，我们展示了连通矩阵的每个特征值如何与Hopf分支相关，并且特征值决定了分支是导致同步还是去同步的振荡行为。我们考虑两个示例网络，一个具有所有实特征值（双向环），另一个具有一些复特征值（单向环）。在双向环中，Hopf曲线被组织起来，使得只有同步的Hopf才会导致渐近稳定的行为。因此，网络中的行为总是同步的。然而，在单向环网络中，异步和同步Hopf曲线的交点可能会出现双Hopf分岔点。因此，可以出现渐近稳定的同步和异步极限环，以及结合同步和异步行为的类环面解。增加网络的大小或平均时延会使这些交叉点和相关的异步行为更有可能发生。数值方法用于证实这一发现，并使用Wolfram Mathematica绘制了Hopf分岔曲线。这些见解提供了对大型振荡器网络中去同步机制的更深入理解。 et.al.|[2311.15329](http://arxiv.org/abs/2311.15329)|null|
|**2023-11-25**|**Coordinate-Aware Modulation for Neural Fields**|将低维输入坐标映射到相应信号的神经场在表示各种信号方面显示出了有希望的结果。已经提出了许多方法，并且使用MLP和网格表示的技术已经取得了实质性的成功。MLP允许紧凑和高表达性，但经常受到光谱偏差和缓慢收敛速度的影响。另一方面，使用网格的方法不受光谱偏差的影响，并且以高空间复杂度为代价实现了快速的训练速度。在这项工作中，我们提出了一种在神经领域中利用MLP和网格表示的新方法。与顺序组合它们（首先从网格中提取特征并将其提供给MLP）的流行方法不同，我们将无光谱偏差的网格表示注入MLP中的中间特征。更具体地说，我们提出了一种坐标感知调制（CAM），它使用从网格表示中提取的比例和偏移参数来调制中间特征。这可以保持MLP的优势，同时减轻任何剩余的潜在偏差，促进高频成分的快速学习。此外，我们根据经验发现，在神经领域文献中尚未成功的特征归一化，在与所提出的CAM结合应用时被证明是有效的。实验结果表明，CAM增强了神经表示的性能，并提高了一系列信号的学习稳定性。特别是在新颖的视图合成任务中，我们以最少的参数数量和快速的训练速度实现了最先进的动态场景性能，并在1MB内存下实现了静态场景的最佳性能。CAM的性能也大大优于使用神经场的最佳视频压缩方法。 et.al.|[2311.14993](http://arxiv.org/abs/2311.14993)|null|
|**2023-11-22**|**Compact 3D Gaussian Representation for Radiance Field**|神经辐射场（NeRFs）在高保真度捕捉复杂三维场景方面显示出非凡的潜力。然而，阻碍NeRFs广泛采用的一个持续挑战是体积绘制造成的计算瓶颈。另一方面，3D高斯飞溅（3DGS）最近作为一种替代表示出现，它利用了基于3D高斯的表示，并采用光栅化流水线来渲染图像，而不是体积渲染，实现了非常快的渲染速度和有希望的图像质量。然而，一个显著的缺点出现了，因为3DGS需要大量的3D高斯来维持渲染图像的高保真度，这需要大量的存储器和存储。为了解决这一关键问题，我们特别强调两个关键目标：在不牺牲性能的情况下减少高斯点的数量，以及压缩高斯属性，如与视图相关的颜色和协方差。为此，我们提出了一种可学习的掩码策略，该策略在保持高性能的同时显著减少高斯数。此外，我们通过使用基于网格的神经场而不是依赖于球面谐波，提出了一种紧凑但有效的视图相关颜色表示。最后，我们学习码本，通过矢量量化来紧凑地表示高斯的几何属性。在我们广泛的实验中，我们一致表明，与3DGS相比，存储空间减少了10美元，渲染速度提高，同时保持了场景表示的质量。我们的工作为3D场景表示提供了一个全面的框架，实现了高性能、快速训练、紧凑性和实时渲染。我们的项目页面位于https://maincold2.github.io/c3dgs/. et.al.|[2311.13681](http://arxiv.org/abs/2311.13681)|null|
|**2023-11-21**|**3D Compression Using Neural Fields**|神经场（NFs）作为一种压缩各种数据模式（如图像和视频）的工具，已经获得了发展势头。这项工作利用了先前的进展，并提出了一种新的基于NF的3D数据压缩算法。我们推导出了两个版本的方法——一个是基于有符号距离域（SDF）的水密形状，更一般地说，一个是使用无符号距离场（UDF）的任意非水密形状。我们证明了我们的方法在三维点云和网格上的几何压缩方面表现出色。此外，我们表明，由于NF公式，可以直接扩展我们的压缩算法来压缩3D数据的几何结构和属性（例如颜色）。 et.al.|[2311.13009](http://arxiv.org/abs/2311.13009)|null|

<p align=right>(<a href=#updated-on-20231205>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

