[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.01.24
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-01-23**|**IRIS: Inverse Rendering of Indoor Scenes from Low Dynamic Range Images**|尽管许多3D重建和新颖的视图合成方法允许从消费者相机轻松捕捉的多视图图像中真实地渲染场景，但它们在表示中烘焙照明，无法支持高级应用程序，如材质编辑、重新照明和虚拟对象插入。通过反向渲染重建基于物理的材料特性和照明有望实现此类应用。然而，大多数反向渲染技术都需要高动态范围（HDR）图像作为输入，这是大多数用户无法访问的设置。我们提出了一种方法，从多视图、低动态范围（LDR）图像中恢复场景的基于物理的材料特性和空间变化的HDR照明。我们在反向渲染管道中对LDR图像形成过程进行建模，并提出了一种新的材料、照明和相机响应模型的优化策略。与采用LDR或HDR输入的最先进的反向渲染方法相比，我们使用合成场景和真实场景来评估我们的方法。我们的方法优于以LDR图像作为输入的现有方法，并允许高度逼真的重新照明和对象插入。 et.al.|[2401.12977](http://arxiv.org/abs/2401.12977)|null|
|**2024-01-23**|**RGBD Objects in the Wild: Scaling Real-World 3D Object Learning from RGB-D Videos**|我们介绍了一种新的在野外捕获的RGB-D对象数据集，称为WildRGB-D。与大多数现有的仅带有RGB捕获的以对象为中心的真实世界数据集不同，深度通道的直接捕获允许更好的3D注释和更广泛的下游应用。WildRGB-D包括大型类别级RGB-D对象视频，这些视频是用iPhone 360度环绕对象拍摄的。它包含大约8500个记录对象和近20000个RGB-D视频，涉及46个常见对象类别。这些视频是在三种设置的不同杂乱背景下拍摄的，以覆盖尽可能多的真实世界场景：（i）一个视频中的单个对象；（ii）一个视频中的多个对象；以及（iii）在一个视频中具有静止手的对象。该数据集由对象遮罩、真实世界比例的相机姿态和RGBD视频中重建的聚合点云进行注释。我们用WildRGB-D对四个任务进行了基准测试，包括新颖的视图合成、相机姿态估计、物体6d姿态估计和物体表面重建。我们的实验表明，RGB-D对象的大规模捕获为推进3D对象学习提供了巨大的潜力。我们的项目页面是https://wildrgbd.github.io/. et.al.|[2401.12592](http://arxiv.org/abs/2401.12592)|null|
|**2024-01-23**|**Methods and strategies for improving the novel view synthesis quality of neural radiation field**|神经辐射场（NeRF）技术可以从2D图像中学习场景的3D隐式模型，并合成逼真的新视图图像。该技术得到了业界的广泛关注，具有良好的应用前景。针对NeRF图像渲染质量需要提高的问题，近三年来，许多研究人员提出了各种方法来提高渲染质量。对最新的相关论文进行了分类和综述，分析了质量改进背后的技术原理，并讨论了质量改进方法的未来发展方向。这项研究可以帮助研究人员快速了解该领域技术的现状和发展脉络，有助于激发更高效算法的发展，促进NeRF技术在相关领域的应用。 et.al.|[2401.12451](http://arxiv.org/abs/2401.12451)|null|
|**2024-01-22**|**HG3-NeRF: Hierarchical Geometric, Semantic, and Photometric Guided Neural Radiance Fields for Sparse View Inputs**|神经辐射场（NeRF）作为一种通过从离散观测中学习场景表示的新型视图合成范式，已经引起了人们的极大关注。然而，当面对稀疏视图输入时，NeRF表现出明显的性能退化，从而限制了其进一步的适用性。在这项工作中，我们介绍了层次几何、语义和光度引导的NeRF（HG3-NeRF），这是一种新的方法，可以解决上述限制，并增强不同视图中几何、语义内容和外观的一致性。我们提出了分层几何制导（HGG），将运动结构的附加（SfM），即稀疏深度先验，纳入场景表示中。与直接深度监督不同，HGG从局部几何区域到全局几何区域对体积点进行采样，减轻了深度先验中固有偏差引起的偏差。此外，我们从不同分辨率的图像中观察到的语义一致性的显著变化中获得了灵感，并提出了层次语义引导（HSG）来学习粗到细的语义内容，该内容对应于粗到细场景表示。实验结果表明，HG3-NeRF可以在不同的标准基准上优于其他最先进的方法，并实现稀疏视图输入的高保真度合成结果。 et.al.|[2401.11711](http://arxiv.org/abs/2401.11711)|null|
|**2024-01-18**|**Explaining the Implicit Neural Canvas: Connecting Pixels to Neurons by Tracing their Contributions**|隐式神经表示（INRs）的许多变体，其中神经网络被训练为信号的连续表示，对于下游任务具有巨大的实用性，包括新颖的视图合成、视频压缩和图像超分辨率。不幸的是，对这些网络的内部运作方式的研究严重不足。我们的工作，即解释隐式神经画布（XINC），是一个统一的框架，用于通过检查每个神经元对每个输出像素的贡献强度来解释INRs的特性。我们将这些贡献图的集合称为隐式神经画布，并使用这一概念来证明我们研究的INR学会了以令人惊讶的方式“观察”它们所代表的帧。例如，INR往往具有高度分布的表示。虽然缺乏高级对象语义，但它们对颜色和边缘有很大的偏见，而且几乎完全是空间不可知的。我们通过研究视频INR中对象在时间上的表现方式得出了我们的结论，使用聚类来可视化跨层和架构的相似神经元，并表明这是由运动主导的。这些见解证明了我们的分析框架的普遍有用性。我们的项目页面位于https://namithap10.github.io/xinc. et.al.|[2401.10217](http://arxiv.org/abs/2401.10217)|null|
|**2024-01-18**|**GPAvatar: Generalizable and Precise Head Avatar from Image(s)**|头部化身重建对于虚拟现实、在线会议、游戏和电影行业的应用至关重要，在计算机视觉界引起了极大的关注。该领域的基本目标是忠实地再现头部化身，并精确地控制表情和姿势。现有的方法分为基于2D的扭曲、基于网格和神经渲染方法，在保持多视图一致性、结合非面部信息和推广到新身份方面存在挑战。在本文中，我们提出了一个名为GPAvatar的框架，该框架可以在单个前向通道中从一个或多个图像重建3D头部化身。这项工作的关键思想是引入一个由点云驱动的动态基于点的表情场，以精确有效地捕捉表情。此外，我们在三平面规范场中使用多三平面注意力（MTA）融合模块来利用来自多个输入图像的信息。所提出的方法实现了忠实的身份重建、精确的表达控制和多视图一致性，在自由视点渲染和新颖视图合成方面显示了良好的效果。 et.al.|[2401.10215](http://arxiv.org/abs/2401.10215)|**[link](https://github.com/xg-chu/gpavatar)**|
|**2024-01-17**|**Objects With Lighting: A Real-World Dataset for Evaluating Reconstruction and Rendering for Object Relighting**|从照片中重建对象并将其虚拟地放置在新环境中超出了标准的新颖视图合成任务，因为对象的外观不仅要适应新颖的视点，还要适应新的照明条件，而且反向渲染方法的评估依赖于新颖的视图合成数据或用于定量分析的简单合成数据集。这项工作提供了一个真实世界的数据集，用于测量重新照明对象的重建和渲染。为此，我们捕获了多个环境中相同对象的环境照明和地面实况图像，从而可以从一个环境中拍摄的图像中重建对象，并量化看不见的照明环境的渲染视图的质量。此外，我们介绍了一个由现成方法组成的简单基线，并在重新照明任务中测试了几种最先进的方法，表明新的视图合成不是衡量性能的可靠指标。代码和数据集可在https://github.com/isl-org/objects-with-lighting. et.al.|[2401.09126](http://arxiv.org/abs/2401.09126)|**[link](https://github.com/isl-org/objects-with-lighting)**|
|**2024-01-17**|**ICON: Incremental CONfidence for Joint Pose and Radiance Field Optimization**|在给定一组2D图像的情况下，神经辐射场（NeRF）在新视图合成（NVS）中表现出显著的性能。然而，NeRF训练需要每个输入视图的精确相机姿势，通常通过运动结构（SfM）管道获得。最近的作品试图放松这种限制，但它们仍然经常依赖于可以改进的体面的初始姿势。在这里，我们旨在消除姿势初始化的要求。我们提出了增量置信（ICON），这是一种从2D视频帧中训练NeRF的优化过程。ICON仅假设相机运动平滑，以估计姿势的初始猜测。此外，ICON引入了“置信度”：一种用于动态重加权梯度的模型质量自适应度量。ICON依赖于高置信度姿势来学习NeRF，并依赖于高置信度3D结构（由NeRF编码）来学习姿势。我们表明，与使用SfM姿势的方法相比，ICON在没有预先初始化姿势的情况下，在CO3D和HO3D中都实现了卓越的性能。 et.al.|[2401.08937](http://arxiv.org/abs/2401.08937)|null|
|**2024-01-16**|**Fast Dynamic 3D Object Generation from a Single-view Video**|由于缺乏4D标记的数据，从单视图视频生成动态三维（3D）对象是具有挑战性的。现有方法通过传输现成的图像生成模型（如分数蒸馏采样）来扩展文本到3D管道，但由于需要通过大型预训练模型反向传播信息有限的监督信号，这些方法的扩展速度慢且成本高（例如，每个对象150分钟）。为了解决这一限制，我们提出了一种高效的视频到4D对象生成框架，称为Efficient4D。它在不同的相机视图下生成高质量的时空一致图像，然后将其用作标记数据，直接训练具有显式点云几何结构的新型4D高斯飞溅模型，实现在连续相机轨迹下的实时渲染。对合成视频和真实视频的广泛实验表明，与现有技术的替代方案相比，Efficient4D的速度显著提高了10倍，同时保持了相同水平的创新视图合成质量。例如，Efficient4D只需14分钟即可对动态对象进行建模。 et.al.|[2401.08742](http://arxiv.org/abs/2401.08742)|null|
|**2024-01-18**|**ProvNeRF: Modeling per Point Provenance in NeRFs as a Stochastic Process**|神经辐射场（NeRFs）在各种应用中越来越受欢迎。然而，它们在稀疏视图设置中面临挑战，缺乏来自体积渲染的足够约束。在具有多种应用的经典计算机视觉中，从稀疏和无约束的相机重建和理解3D场景是一个长期存在的问题。虽然最近的工作在稀疏、无约束的视图场景中探索了NeRF，但他们的重点主要是增强重建和新颖的视图合成。我们的方法从更广泛的角度出发，提出了一个问题：“从哪里看到了每个点？”——这决定了我们对它的理解和重建程度。换句话说，我们的目标是在稀疏、无约束的视图下确定每个3D点及其相关信息的起源或出处。我们介绍了ProvNeRF，这是一个模型，通过合并每个点的来源，为每个点的可能源位置建模，丰富了传统的NeRF表示。我们通过扩展随机过程的隐式最大似然估计（IMLE）来实现这一点。值得注意的是，我们的方法与任何预先训练的NeRF模型和相关的训练相机姿势兼容。我们证明，与最先进的方法相比，逐点源建模提供了几个优势，包括不确定性估计、基于标准的视图选择和改进的新视图合成。请访问我们的项目页面https://provnerf.github.io et.al.|[2401.08140](http://arxiv.org/abs/2401.08140)|null|

<p align=right>(<a href=#updated-on-20240124>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-01-23**|**IRIS: Inverse Rendering of Indoor Scenes from Low Dynamic Range Images**|尽管许多3D重建和新颖的视图合成方法允许从消费者相机轻松捕捉的多视图图像中真实地渲染场景，但它们在表示中烘焙照明，无法支持高级应用程序，如材质编辑、重新照明和虚拟对象插入。通过反向渲染重建基于物理的材料特性和照明有望实现此类应用。然而，大多数反向渲染技术都需要高动态范围（HDR）图像作为输入，这是大多数用户无法访问的设置。我们提出了一种方法，从多视图、低动态范围（LDR）图像中恢复场景的基于物理的材料特性和空间变化的HDR照明。我们在反向渲染管道中对LDR图像形成过程进行建模，并提出了一种新的材料、照明和相机响应模型的优化策略。与采用LDR或HDR输入的最先进的反向渲染方法相比，我们使用合成场景和真实场景来评估我们的方法。我们的方法优于以LDR图像作为输入的现有方法，并允许高度逼真的重新照明和对象插入。 et.al.|[2401.12977](http://arxiv.org/abs/2401.12977)|null|
|**2024-01-23**|**Consistency Enhancement-Based Deep Multiview Clustering via Contrastive Learning**|多视图聚类（MVC）通过综合多个视图中的信息，将数据样本分离成有意义的聚类。此外，基于深度学习的方法已经在MVC场景中展示了强大的特征学习能力。然而，在保持一致性的同时有效地泛化特征表示仍然是一个棘手的问题。此外，大多数现有的基于对比学习的深度聚类方法在聚类过程中忽视了聚类表示的一致性。在本文中，我们展示了如何克服上述问题，并通过对比学习（CCEC）提出了一种基于一致增强的深度MVC方法。具体而言，语义连接块被合并到特征表示中，以保持多个视图之间的一致信息。此外，通过光谱聚类增强了聚类的表示过程，并提高了多个视图之间的一致性。在五个数据集上进行的实验证明了与最先进的（SOTA）方法相比，我们的方法的有效性和优越性。此方法的代码可以访问https://anonymous.4open.science/r/CCEC-E84E/. et.al.|[2401.12648](http://arxiv.org/abs/2401.12648)|null|
|**2024-01-21**|**A Survey on African Computer Vision Datasets, Topics and Researchers**|计算机视觉包括一系列任务，如对象检测、语义分割和3D重建。尽管它与非洲社区有关，但在过去十年中，非洲国内这一领域的研究仅占顶级出版物的0.06%。这项研究对2012年至2022年来自非洲的63000份Scopus索引的计算机视觉出版物进行了彻底分析。其目的是提供对非洲计算机视觉主题、数据集和研究人员的调查。我们研究的一个关键方面是使用自动解析这些出版物摘要的大型语言模型对非洲计算机视觉数据集进行识别和分类。我们还提供了通过挑战或数据托管平台分发的非官方非洲计算机视觉数据集的汇编，并提供了数据集类别的完整分类。我们的调查还指出了不同非洲地区的计算机视觉主题趋势，表明了它们独特的关注领域。此外，我们进行了一项广泛的调查，以了解非洲研究人员对非洲大陆计算机视觉研究现状的看法，以及他们认为迫切需要关注的结构性障碍。总之，这项研究对非洲机构贡献或发起的计算机视觉数据集和主题进行了编目和分类，并确定了在顶级计算机视觉场所出版的障碍。这项调查强调了鼓励非洲研究人员和机构推进非洲大陆计算机视觉研究的重要性。它还强调研究主题需要与非洲社区的需求更加一致。 et.al.|[2401.11617](http://arxiv.org/abs/2401.11617)|null|
|**2024-01-21**|**Multi-View Neural 3D Reconstruction of Micro-/Nanostructures with Atomic Force Microscopy**|原子力显微镜（AFM）是一种广泛应用于微/纳米形貌成像的工具。然而，由于不完整的样品形貌捕获和尖端样品卷积伪影等限制，传统的AFM扫描难以精确重建复杂的3D微/纳米结构。在这里，我们提出了一种基于多视角神经网络的AFM框架（MVN-AFM），它可以准确地重建复杂的微米/纳米结构的表面模型。与以前的工作不同，MVN-AFM不依赖于任何特殊形状的探针或对AFM系统的昂贵修改。为了实现这一点，MVN-AFM独特地采用迭代方法来对齐多视图数据并同时消除AFM伪影。此外，我们率先将神经隐式表面重建应用于纳米技术，并取得了显著改善的结果。大量实验表明，MVN-AFM有效地消除了原始AFM图像中存在的伪影，并重建了各种微/纳米结构，包括通过双光子光刻印刷的复杂几何微观结构和纳米颗粒，如PMMA纳米球和ZIF-67纳米晶体。这项工作为微米/纳米级三维分析提供了一种具有成本效益的工具。 et.al.|[2401.11541](http://arxiv.org/abs/2401.11541)|null|
|**2024-01-21**|**Deformable Endoscopic Tissues Reconstruction with Gaussian Splatting**|外科三维重建是机器人外科的一个关键研究领域，最近的工作采用了动态辐射场的变体，从单视点视频中成功地重建了可变形组织。然而，这些方法往往存在耗时的优化或质量较差的问题，限制了它们在下游任务中的采用。受3D高斯散射（一种最近流行的3D表示）的启发，我们提出了EndoGS，将高斯散射应用于可变形的内窥镜组织重建。具体而言，我们的方法结合了变形场来处理动态场景，深度引导监督来优化具有单个视点的3D目标，以及时空权重掩码来减轻工具遮挡。因此，EndoGS从单个视点视频、估计的深度图和标记的工具遮罩重建并渲染高质量的可变形内窥镜组织。在DaVinci机器人手术视频上的实验表明，EndoGS实现了卓越的渲染质量。代码位于https://github.com/HKU-MedAI/EndoGS. et.al.|[2401.11535](http://arxiv.org/abs/2401.11535)|null|
|**2024-01-19**|**Dense 3D Reconstruction Through Lidar: A Comparative Study on Ex-vivo Porcine Tissue**|新的传感技术和更先进的处理算法正在改变计算机集成手术。尽管研究人员正在积极研究基于视觉的手术辅助的深度传感和3D重建，但仍难以实现微创手术腹腔的实时、准确和稳健的3D表示。因此，这项工作使用对新鲜离体猪组织的定量测试来彻底表征基于3D激光的飞行时间传感器（激光雷达）执行解剖表面重建的质量。使用商用激光扫描仪捕捉地面实况表面形状，并使用严格的统计工具分析由此产生的符号误差场。与来自内窥镜图像的基于现代学习的立体匹配相比，飞行时间传感表现出更高的精度、更低的处理延迟、更高的帧速率以及对传感器距离和较差照明的超强鲁棒性。此外，我们报告了近红外光穿透对不同组织样本的激光雷达测量精度的潜在负面影响，确定了肌肉与脂肪和肝脏相比的显著测量深度偏移。我们的发现突出了激光雷达在术中3D感知方面的潜力，并指出了结合互补飞行时间和光谱成像的新方法。 et.al.|[2401.10709](http://arxiv.org/abs/2401.10709)|null|
|**2024-01-17**|**POE: Acoustic Soft Robotic Proprioception for Omnidirectional End-effectors**|由于软机器人具有复杂的变形行为和无限的自由度，软机器人的形状估计和本体感觉具有挑战性。软机器人不断变形的身体使其难以集成刚性传感器并可靠地估计其形状。在这项工作中，我们提出了本体感知全向末端效应器（POE），它在肌腱驱动的软机器人表面上有六个嵌入式麦克风。我们首先介绍了先前提出的3D重建方法对来自麦克风的声学信号的新应用，用于软机器人形状本体感觉。为了提高本体感觉管道的训练效率和模型预测的一致性，我们提出了POE-M。POE-M首先利用嵌入式麦克风阵列从声学信号观测中预测关键点位置。然后，在给定估计的关键点的情况下，我们利用能量最小化方法来重建物理上可容许的高分辨率POE网格。我们用模拟数据评估了网格重建模块，并用真实世界的实验评估了完整的POE-M管道。我们证明，POE-M在网格重建过程中对关键点的明确指导为消融研究的管道提供了鲁棒性和稳定性。与最先进的端到端软机器人本体感觉模型相比，POE-M将最大倒角距离误差降低了23.10%，并在评估过程中实现了4.91mm的平均倒角距离误差。 et.al.|[2401.09382](http://arxiv.org/abs/2401.09382)|null|
|**2024-01-17**|**3D Scene Geometry Estimation from 360 $^\circ$ Imagery: A Survey**|本文对基于在全向光学系统下捕获的单个、两个或多个图像的先驱和最先进的3D场景几何估计方法进行了全面的综述。我们首先回顾了球面相机模型的基本概念，并回顾了适用于全向（也称为360$^\circ$ ，球面或全景）图像和视频的最常见的采集技术和表示格式。然后，我们调查了单目布局和深度推理方法，重点介绍了适用于球形数据的基于学习的解决方案的最新进展。然后在球面域上修改经典的立体匹配，其中检测和描述稀疏和密集特征的方法变得至关重要。然后，将立体匹配概念外推到多视图相机设置中，将其分类为光场、多视图立体和运动结构（或视觉同时定位和映射）。我们还汇编和讨论了常用的数据集和针对每种目的指出的优缺点，并列出了最新的结果以确保完整性。最后，我们指出了当前和未来的趋势。 et.al.|[2401.09252](http://arxiv.org/abs/2401.09252)|null|
|**2024-01-16**|**Learning Implicit Representation for Reconstructing Articulated Objects**|在没有关于物体结构的附加信息的情况下对运动的关节物体进行三维重建是一个具有挑战性的问题。当前的方法通过使用特定类别的骨架模型来克服这些挑战。因此，它们不能很好地推广到野外的铰接对象。我们将铰接物体视为未知的半刚性骨骼结构，由非刚性材料（如皮肤）包围。我们的方法在没有3D监督的情况下，根据对象视频中的运动线索，同时估计可见（显式）表示（3D形状、颜色、相机参数）和隐式骨架表示。我们的隐含表示由四个部分组成。（1） 骨架，用于指定半刚性零件的连接方式。（2） \textcolor｛black｝｛Skinning Weights｝，它将每个曲面顶点与半刚性零件概率关联起来。（3） 刚性系数，指定局部曲面的关节。（4） 时变变换，用于指定骨骼运动和曲面变形参数。我们介绍了一种使用物理约束作为正则化项并迭代估计隐式和显式表示的算法。我们的方法与类别无关，因此消除了对特定类别骨架的需求，我们表明我们的方法在标准视频数据集中优于最先进的方法。 et.al.|[2401.08809](http://arxiv.org/abs/2401.08809)|null|
|**2024-01-20**|**Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis**|一次拍摄3D会说话的肖像生成旨在从看不见的图像中重建3D化身，然后用参考视频或音频将其动画化，以生成会说话的人像视频。现有的方法无法同时实现准确的三维化身重建和稳定的人脸动画。此外，虽然现有的作品主要集中在合成头部，但生成自然的躯干和背景片段以获得逼真的说话肖像视频也是至关重要的。为了解决这些限制，我们提出了Real3D Potrait，该框架（1）通过从3D人脸生成模型中提取3D先验知识的大图像到平面模型提高了单次3D重建能力；（2） 利用高效的运动适配器促进精确的运动条件动画；（3） 使用头部-躯干背景超分辨率模型来合成具有自然躯干运动和可切换背景的逼真视频；以及（4）支持具有可推广的音频到运动模型的单镜头音频驱动的谈话面部生成。大量实验表明，与以前的方法相比，Real3D Portrait很好地概括了看不见的身份，并生成了更逼真的谈话肖像视频。视频样本和源代码可在https://real3dportrait.github.io. et.al.|[2401.08503](http://arxiv.org/abs/2401.08503)|null|

<p align=right>(<a href=#updated-on-20240124>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-01-23**|**GALA: Generating Animatable Layered Assets from a Single Scan**|我们提出了GALA，这是一个框架，它以单层衣服的3D人体网格为输入，并将其分解为完整的多层3D资产。然后可以将输出与其他资产组合，以创建具有任何姿势的新颖的穿着衣服的人类化身。现有的重建方法通常将穿着衣服的人类视为单层几何体，并忽略了人类与发型、衣服和配饰的固有组成性，从而限制了网格在下游应用中的效用。将单层网格分解为单独的层是一项具有挑战性的任务，因为它需要为严重遮挡的区域合成合理的几何结构和纹理。此外，即使分解成功，网格也不能在姿势和体型方面进行归一化，从而无法实现具有新身份和姿势的连贯合成。为了应对这些挑战，我们建议利用预训练的2D扩散模型的一般知识作为人类和其他资产的几何和外观先验。我们首先使用从多视图2D分割中提取的3D表面分割来分离输入网格。然后，我们使用一种新的姿态引导的分数蒸馏采样（SDS）损失来合成姿态空间和规范空间中不同层的缺失几何。一旦我们完成了高保真3D几何体的修复，我们还将相同的SDS损失应用于其纹理，以获得包括初始遮挡区域在内的完整外观。通过一系列分解步骤，我们在一个共享的规范空间中获得了多层3D资产，这些资产根据姿势和人体形状进行了归一化，从而支持轻松合成新的身份，并用新的姿势进行复活。我们的实验证明了与现有解决方案相比，我们的方法在分解、规范化和组合任务方面的有效性。 et.al.|[2401.12979](http://arxiv.org/abs/2401.12979)|null|
|**2024-01-23**|**Zero-Shot Learning for the Primitives of 3D Affordance in General Objects**|人工智能的主要挑战之一是教会机器准确地响应和利用环境功能，从而实现人类所拥有的启示意识。尽管它很重要，但该领域在学习方面一直落后，尤其是在3D领域，因为由于人机交互的多种变化，注释可供性伴随着一个费力的过程。可供性数据的低可用性限制了对象类别泛化方面的学习，也简化了可供性的表示，只捕获了可供度的一小部分。为了克服这些挑战，我们提出了一种新颖的自监督方法来生成仅给定3D对象的3D启示示例，而不需要任何手动注释。该方法首先将3D对象捕获到图像中，并通过修复扩散模型将人类插入图像中来创建2D可供性图像，其中我们提出了自适应掩码算法，以实现人类插入，而不会改变对象的原始细节。因此，该方法将插入的人类提升回3D，以创建3D人-物对，其中在深度优化框架内解决深度模糊性，该深度优化框架利用来自多个视点的预先生成的人类姿势。我们还提供了一种新的可供性表示，该表示定义在密集的人和物点之间的相对方向和接近度上，可以从任何3D HOI数据集轻松聚合。所提出的表示作为一种原语，可以通过简单的转换，从物理施加的可供性到非物理可供性，表现为传统的可供表示。我们通过生成3D可供性样本并从表示中导出高质量的可供性示例，包括接触、方向和空间占用，来证明我们的方法和表示的有效性。 et.al.|[2401.12978](http://arxiv.org/abs/2401.12978)|null|
|**2024-01-23**|**Measure transport with kernel mean embeddings**|卡尔曼滤波器构成了一种可扩展且稳健的近似贝叶斯推理方法，匹配目标后验的一阶矩和二阶矩。为了提高非线性和非高斯设置中的精度，我们将这一原理扩展到包括更多或不同的特征，基于概率测度的核均值嵌入（KME）到其相应的希尔伯特空间中。专注于连续时间设置，我们开发了一系列相互作用的粒子系统（称为 $\textit{KME动力学}$ ），这些系统连接了先验和后验，并将卡尔曼-布西滤波器作为特例。Maurais和Marzouk最近从最优传输的角度推导了KME动力学的一个变体，我们揭示了与（核化）扩散图的进一步联系，从而得出了回归类型的变分公式。最后，我们在玩具示例和Lorenz-63模型上进行了数值实验，后者显示出混合修改（称为卡尔曼调整的KME动力学）的特殊前景。 et.al.|[2401.12967](http://arxiv.org/abs/2401.12967)|null|
|**2024-01-23**|**Lumiere: A Space-Time Diffusion Model for Video Generation**|我们介绍了Lumiere——一种文本到视频的扩散模型，旨在合成描绘逼真、多样和连贯运动的视频——这是视频合成中的一个关键挑战。为此，我们引入了一种时空U-Net架构，该架构通过模型中的一次传递，一次生成视频的整个时间持续时间。这与现有的视频模型形成了鲜明对比，现有视频模型先合成远处的关键帧，然后再合成时间超分辨率——这种方法固有地使全局时间一致性难以实现。通过部署空间和（重要的）时间下采样和上采样，并利用预先训练的文本到图像扩散模型，我们的模型学会了通过在多个时空尺度上处理来直接生成全帧率、低分辨率的视频。我们展示了最先进的文本到视频生成结果，并表明我们的设计可以轻松地促进广泛的内容创建任务和视频编辑应用程序，包括图像到视频、视频修复和风格化生成。 et.al.|[2401.12945](http://arxiv.org/abs/2401.12945)|null|
|**2024-01-23**|**Long-range three-dimensional tracking of nanoparticles using interferometric scattering (iSCAT) microscopy**|跟踪纳米颗粒的运动在许多科学领域都是非常理想的，并且已经采用了各种成像方法来实现这一目标。干涉散射（iSCAT）显微镜在结合非常高的空间和时间分辨率来跟踪所有三维中的小纳米颗粒方面特别成功。然而，以前的工作仅限于几百纳米的轴向范围。在这里，我们提出了一种强大而有效的策略，用于将高速iSCAT视频中记录的纳米颗粒定位在几十微米以上的三维空间中。我们通过跟踪在水中扩散的小到10纳米的金纳米颗粒，同时保持5｛\mu｝s的时间分辨率和纳米轴向定位精度，展示了我们算法的性能。我们的研究结果有望应用于细胞生物学和材料科学，其中纳米颗粒在复杂介质中的三维运动令人感兴趣。 et.al.|[2401.12939](http://arxiv.org/abs/2401.12939)|null|
|**2024-01-23**|**Thermal transport of Li $_3$PS$_4$ solid electrolytes with ab initio accuracy**|关于固态电解质中导电性的大量计算研究并没有反映在解决热传导的可比努力中，尽管热传导与电池的热管理和（过热）有关，但很少进行研究。原因在于计算的复杂性：一方面，离子电荷载流子的扩散使晶格方法在形式上不合适，因为缺乏正常模式扩展所需的平衡原子位置。另一方面，在从头算水平上对大系统中的热传输进行大规模分子动力学（MD）模拟的成本过高，阻碍了基于MD的方法的使用。在这项工作中，我们利用最近开发的针对不同从头算泛函（PBEsol，r$^2$SCAN，PBE0）的机器学习潜力和多组分系统中热传输的Green Kubo理论的最新公式来计算有前景的固态电解质Li$_3$PS$_4$的热导率，~在其所有多晶型物中（$\alpha$、$\beta$和$\gamma$）。通过将MD估计与晶格方法在低温、非扩散$\gamma$-Li$_3$PS$_4$上进行比较，我们强调了强的非谐性和可忽略的核量子效应，从而进一步证明了即使对于非扩散相，基于MD的方法也是合理的。最后，对于离子传导$\alpha$和$\beta$ 相，其中多组分Green Kubo MD方法是强制性的，我们的模拟表明热导率的温度依赖性较弱，这是由于表征这些Li扩散相的有效局部无序而导致的玻璃状行为。 et.al.|[2401.12936](http://arxiv.org/abs/2401.12936)|null|
|**2024-01-23**|**A hypocoercivity-exploiting stabilised finite element method for Kolmogorov equation**|对于经典的Kolmogorov方程，我们提出了一种新的稳定有限元方法。后者是大类动力学类型方程的基本模型问题，关键是其特征是退化扩散。构造稳定是为了使所得方法具有类似于PDE问题的相应性质的\emph｛数值次共沸性｝性质。更具体地说，尽管Kolmogorov中的扩散具有退化性质，但稳定化的构造使得在所产生的“强于能量”的稳定范数中可能存在谱隙，从而当“时间”变量变为无穷大时，该方法具有可证明的鲁棒性。我们考虑了稳定有限元方法的空间离散版本和完全离散版本，其中时间离散化通过不连续的Galerkin时间步长实现。在所有情况下都证明了稳定性和先验误差界。数值实验验证了理论结果。 et.al.|[2401.12921](http://arxiv.org/abs/2401.12921)|null|
|**2024-01-23**|**Propagation reversal on trees in the large diffusion regime**|在这项工作中，我们研究了扩散参数大的连续区域中双无限 $k$ -ary树上双稳态反应扩散方程的行波解。采用Bates及其同事提出的谱收敛方法，我们得到了行进前沿解速度的渐近预测。此外，我们还证明了相关轮廓收敛于一个合适的极限反应扩散PDE的解。最后，对于标准三次非线性，我们给出了明确的公式来约束参数空间中传播方向发生逆转的薄区域。 et.al.|[2401.12899](http://arxiv.org/abs/2401.12899)|null|
|**2024-01-23**|**An Efficient Algorithm for Spatial-Spectral Partial Volume Compartment Mapping with Applications to Multicomponent Diffusion and Relaxation MRI**|先前已经表明，通过将多参数对比度编码的MRI数据采集方法与空间正则化的光谱图像估计技术相结合，可以获得高质量的部分体积组织隔室图。然而，这种组合方法的优势通常是以巨大的计算复杂性为代价的。在这项工作中，我们提出了一种新的算法来更有效地解决这类估计问题。我们的算法基于乘法器的线性交替方向法（LADMM），并依靠引入新的二次罚项来大大简化每次迭代时必须解决的子问题。我们在各种不同的估计问题（扩散弛豫、弛豫弛豫、松弛测量和磁共振指纹）上评估了该算法，在这些问题上，我们一致观察到显著的（大约5 $\times$-80$\times$ ）速度改进。我们预计，这种新的更快算法将降低使用空间正则化和多参数对比度编码的MRI数据采集方法进行部分体积隔室映射的实际障碍。 et.al.|[2401.12890](http://arxiv.org/abs/2401.12890)|null|
|**2024-01-23**|**Optimal Stopping of Branching Diffusion Processes**|本文探讨了分支扩散过程的一个最优停止问题。它包括寻找最佳停止线，这是一种保持分析过程分支结构的停止时间。通过使用动态规划方法，我们刻画了取决于粒子标签的乘性代价的值函数。我们通过设置分支属性并在有限维上下文中定义问题来降低问题的维数。在这个框架内，我们专注于值函数，建立多项式增长和局部Lipschitz性质，以及创新的动态规划原理。这一结果导致了在非线性椭圆PDE的帮助下的分析表征。我们通过证明值函数是该PDE的唯一粘度解来得出结论，并将比较原理推广到该设置。 et.al.|[2401.12811](http://arxiv.org/abs/2401.12811)|null|

<p align=right>(<a href=#updated-on-20240124>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-01-17**|**Reproducibility via neural fields of visual illusions induced by localized stimuli**|本文研究了Billock和Tsou[PNAS，2007]使用Amari型神经场的可控性对初级视皮层（V1）皮层活动进行建模的实验复制，重点关注中央凹或外周视野中的规则漏斗模式。其目的是理解和模拟在这些实验中观察到的视觉现象，强调其非线性性质。这项研究包括设计模拟Billock和Tsou实验中视觉刺激的感官输入。然后从理论和数值上研究这些输入引起的后图像，以确定它们复制实验观察到的视觉效果的能力。这项研究的一个关键方面是研究神经反应的非线性性质所引起的影响。特别是，通过强调兴奋性和抑制性神经元在某些视觉现象出现中的重要性，这项研究表明，这两种类型的神经元活动的相互作用在视觉过程中发挥着重要作用，挑战了后者主要由兴奋性活动单独驱动的假设。 et.al.|[2401.09108](http://arxiv.org/abs/2401.09108)|null|
|**2024-01-12**|**Motion2VecSets: 4D Latent Vector Set Diffusion for Non-rigid Shape Reconstruction and Tracking**|我们介绍了Motion2VecSets，这是一种用于从点云序列进行动态曲面重建的4D扩散模型。虽然现有的最先进的方法已经证明在使用神经场表示重建非刚性对象方面取得了成功，但传统的前馈网络遇到了来自噪声、部分或稀疏点云的模糊观测的挑战。为了应对这些挑战，我们引入了一种扩散模型，该模型通过压缩潜在表示的迭代去噪过程来显式学习非刚性对象的形状和运动分布。当处理模糊输入时，基于扩散的先验能够进行更合理和概率的重建。我们用潜在向量集参数化4D动力学，而不是使用全局潜在。这种新颖的4D表示使我们能够学习局部表面形状和变形模式，从而实现更准确的非线性运动捕捉，并显著提高对看不见的运动和身份的可推广性。对于更具时间连贯性的目标跟踪，我们同步地对变形潜集进行去噪，并在多个帧之间交换信息。为了避免计算开销，我们设计了一个交错的空间和时间注意力块，以沿着空间和时间域交替聚集变形潜伏期。与最先进的方法进行了广泛的比较，证明了我们的Motion2VenSets在从各种不完美的观测进行4D重建方面的优势，特别是在从DeformingThings4D Animals数据集上的稀疏点云重建看不见的个体方面，与CaDex相比，交集优于并集（IoU）提高了19%。更多详细信息，请访问https://vveicao.github.io/projects/Motion2VecSets/. et.al.|[2401.06614](http://arxiv.org/abs/2401.06614)|null|
|**2024-01-05**|**Denoising Vision Transformers**|我们深入研究了视觉转换器（ViTs）固有的一个细微但重大的挑战：这些模型的特征图显示出网格状的伪影，这对ViTs在下游任务中的性能造成了不利影响。我们的研究将这个基本问题追溯到输入阶段的位置嵌入。为了解决这一问题，我们提出了一种新的噪声模型，该模型普遍适用于所有的ViT。具体来说，噪声模型将ViT输出分解为三个部分：一个没有噪声伪影的语义术语和两个以像素位置为条件的伪影相关术语。这种分解是通过在每幅图像的基础上加强与神经场的交叉视图特征一致性来实现的。这种逐图像优化过程从原始ViT输出中提取无伪影特征，为离线应用程序提供干净的特征。扩大了我们的解决方案的范围，以支持在线功能，我们引入了一种可学习的去噪器，直接从未处理的ViT输出中预测无伪影特征，这显示出对新数据的显著泛化能力，而无需对每张图像进行优化。我们的两阶段方法，称为去噪视觉转换器（DVT），不需要重新训练现有的预先训练的ViT，并且立即适用于任何基于转换器的架构。我们在各种具有代表性的ViT（DINO、MAE、DeiT III、EVA02、CLIP、DINOv2、DINOv2-reg）上评估了我们的方法。广泛的评估表明，我们的DVT在多个数据集（例如+3.84mIoU）的语义和几何任务中持续显著地改进了现有的最先进的通用模型。我们希望我们的研究将鼓励对ViT设计进行重新评估，特别是关于位置嵌入的天真使用。 et.al.|[2401.02957](http://arxiv.org/abs/2401.02957)|null|
|**2023-12-30**|**PlanarNeRF: Online Learning of Planar Primitives with Neural Radiance Fields**|从视觉数据中识别空间完整的平面基元是计算机视觉中的一项关键任务。现有的方法在很大程度上局限于2D片段恢复或简化3D结构，即使具有广泛的平面注释。我们提出了PlanarNeRF，这是一种能够通过在线学习检测密集3D平面的新框架。PlanarNeRF利用神经场表示，带来了三个主要贡献。首先，它利用并行的外观和几何知识增强了三维平面检测。其次，提出了一种轻量级的平面拟合模块来估计平面参数。第三，引入了一种具有更新机制的新的全局内存库结构，确保了跨帧一致性。PlanarNeRF的灵活架构使其能够在二维监督和自监督解决方案中发挥作用，在每种解决方案中，它都可以有效地从稀疏的训练信号中学习，显著提高训练效率。通过广泛的实验，我们证明了PlanarNeRF在各种场景下的有效性，并比现有工作有了显著的改进。 et.al.|[2401.00871](http://arxiv.org/abs/2401.00871)|null|
|**2024-01-01**|**Deblurring 3D Gaussian Splatting**|最近对辐射场的研究为具有照片级真实感渲染质量的新颖视图合成铺平了坚实的道路。然而，它们通常使用神经网络和体积绘制，这两种方法的训练成本很高，并且由于绘制时间长，阻碍了它们在各种实时应用中的广泛使用。最近，人们提出了一种基于3D高斯散射的方法来对3D场景进行建模，并在实时渲染图像的同时实现了显著的视觉质量。然而，如果训练图像模糊，则渲染质量会严重下降。模糊通常是由于镜头散焦、物体运动和相机抖动而产生的，它不可避免地会干扰干净图像的获取。先前的几项研究试图使用神经场从模糊的输入图像中渲染干净清晰的图像。然而，这些工作中的大多数仅设计用于基于体积渲染的神经辐射场，并不直接适用于基于光栅化的3D高斯散射方法。因此，我们提出了一种新的实时去模糊框架，即去模糊3D高斯散点，使用小型多层感知器（MLP）来操纵每个3D高斯的协方差来对场景模糊度进行建模。虽然去模糊的3D高斯飞溅仍然可以享受实时渲染，但它可以从模糊的图像中重建精细和清晰的细节。在基准上进行了各种实验，结果表明了我们的去模糊方法的有效性。定性结果可在https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/ et.al.|[2401.00834](http://arxiv.org/abs/2401.00834)|null|
|**2023-12-22**|**Fluid Simulation on Neural Flow Maps**|我们介绍了神经流图，这是一种新的模拟方法，将新兴的隐式神经表示范式与基于流图理论的流体模拟相结合，以实现最先进的无粘流体现象模拟。我们设计了一种新的混合神经场表示，空间稀疏神经场（SSNF），它将小型神经网络与重叠、多分辨率和空间稀疏网格的金字塔相融合，以高精度紧凑地表示长期时空速度场。有了这个神经速度缓冲器，我们以机械对称的方式计算长期双向流图及其雅可比矩阵，以促进对现有解决方案的大幅精度提高。这些长程双向流图实现了低耗散的高平流精度，进而促进了高保真度的不可压缩流模拟，显示了复杂的旋涡结构。我们展示了我们的神经流体模拟在各种具有挑战性的模拟场景中的有效性，包括跳跃涡流、碰撞涡流、涡流重新连接，以及移动障碍物和密度差异产生的涡流。我们的例子表明，在能量守恒、视觉复杂性、对实验观测的遵守以及详细旋涡结构的保存方面，与现有方法相比，性能有所提高。 et.al.|[2312.14635](http://arxiv.org/abs/2312.14635)|null|
|**2023-12-21**|**Geometric Awareness in Neural Fields for 3D Human Registration**|将模板与三维人体点云对齐是一个长期存在的问题，对于动画、重建和启用监督学习管道等任务至关重要。最近的数据驱动方法利用了预测的表面对应关系；然而，它们对不同的姿态或分布并不鲁棒。相比之下，工业解决方案往往依赖于昂贵的手动注释或多视图捕获系统。最近，神经场已经显示出有希望的结果，但它们纯粹的数据驱动性质缺乏几何意识，通常导致模板配准的微小错位。在这项工作中，我们提出了两种解决方案：LoVD，一种新的神经场模型，它预测朝向目标表面上的局部SMPL顶点的方向；和INT，这是第一个专门用于神经领域的自监督任务，在测试时，它利用目标几何结构来细化主干。我们将它们组合到INLoVD中，这是一个在大型MoCap数据集上训练的强大的3D人体注册管道。INLoVD是高效的（不到一分钟），在公共基准上稳定地达到了最先进的水平，并对分布外的数据提供了前所未有的概括。我们将在\url｛url｝中发布代码和检查点。 et.al.|[2312.14024](http://arxiv.org/abs/2312.14024)|null|
|**2023-12-20**|**Neural feels with neural fields: Visuo-tactile perception for in-hand manipulation**|为了实现人类水平的灵活性，机器人必须从多模式感知推断空间意识，以推理接触互动。在新物体的手操作过程中，这种空间意识包括估计物体的姿势和形状。手内感知的现状主要采用视觉，并局限于跟踪先验已知对象。此外，在操作过程中，手上物体的视觉遮挡迫在眉睫，这阻止了当前系统在没有遮挡的情况下超越任务。我们将多指手的视觉和触摸传感相结合，在手内操作过程中估计物体的姿势和形状。我们的方法NeuralFeels通过在线学习神经场来编码对象几何，并通过优化姿态图问题来联合跟踪它。我们研究了模拟和现实世界中的多模式手部感知，通过本体感觉驱动的策略与不同的物体进行交互。我们的实验显示，使用已知的CAD模型，最终重建F分数为 $81$%，平均姿势漂移为$4.7\，\text｛mm｝$，进一步降低到$2.3\，\text{mm｝$。此外，我们观察到，与仅使用视觉的方法相比，在严重的视觉遮挡下，我们可以实现高达94$ %的跟踪改进。我们的研究结果表明，在手部操作过程中，触摸至少可以改善视觉估计，并在最好的情况下消除视觉估计的歧义。我们发布了70个实验的评估数据集FeelSight，作为在该领域进行基准测试的一步。我们由多模态感知驱动的神经表示可以作为提高机器人灵活性的感知支柱。视频可以在我们的项目网站上找到https://suddhu.github.io/neural-feels/ et.al.|[2312.13469](http://arxiv.org/abs/2312.13469)|null|
|**2023-12-20**|**Deep Learning on 3D Neural Fields**|近年来，神经场（NFs）已成为编码各种连续信号（如图像、视频、音频和3D形状）的有效工具。当应用于3D数据时，NFs提供了一种解决方案来解决与流行的离散表示相关的碎片化和局限性。然而，鉴于神经网络本质上是神经网络，目前尚不清楚它们是否以及如何无缝集成到深度学习管道中，以解决下游任务。本文解决了这一研究问题，并介绍了nf2vec，这是一个能够在单个推理过程中为输入NF生成紧凑的潜在表示的框架。我们证明了nf2vec有效地嵌入了由输入NF表示的3D对象，并展示了如何在深度学习管道中使用由此产生的嵌入来成功地处理各种任务，同时只处理NF。我们在几个用于表示3D曲面的NFs上测试了这个框架，例如无符号/有符号距离和占用字段。此外，我们用更复杂的NFs证明了我们的方法的有效性，这些NFs包括3D对象的几何形状和外观，如神经辐射场。 et.al.|[2312.13277](http://arxiv.org/abs/2312.13277)|null|
|**2023-12-16**|**How to Train Neural Field Representations: A Comprehensive Study and Benchmark**|神经场（NeFs）最近已成为一种用于对各种模态（包括图像、形状和场景）的信号进行建模的通用方法。随后，许多工作探索了使用NeF作为下游任务的表示，例如，根据适合的NeF的参数对图像进行分类。然而，NeF超参数对其作为下游表示的质量的影响很少被理解，而且在很大程度上仍未被探索。这在一定程度上是由于拟合神经场数据集所需的大量时间造成的。在这项工作中，我们提出了 $\verb|fit-a-nef|$ ，这是一个基于JAX的库，它利用并行化来实现大规模nef数据集的快速优化，从而显著加快速度。有了这个库，我们进行了一项全面的研究，研究了不同超参数——包括初始化、网络架构和优化策略——对下游任务的NeF拟合的影响。我们的研究为如何训练NeF提供了宝贵的见解，并为优化其在下游应用中的有效性提供了指导。最后，基于所提出的库和我们的分析，我们提出了Neural Field Arena，这是一个由流行视觉数据集的神经场变体组成的基准，包括MNIST、CIFAR、ImageNet和ShapeNetv2的变体。我们的图书馆和神经领域竞技场将是开源的，以引入标准化的基准测试，并促进对神经领域的进一步研究。 et.al.|[2312.10531](http://arxiv.org/abs/2312.10531)|**[link](https://github.com/samuelepapa/fit-a-nef)**|

<p align=right>(<a href=#updated-on-20240124>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

