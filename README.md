[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.12.20
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-17**|**PNeRFLoc: Visual Localization with Point-based Neural Radiance Fields**|由于能够合成高质量的新视图，神经辐射场（NeRF）最近被用来改善已知环境中的视觉定位。然而，现有的方法大多利用NeRFs进行数据扩充来改进回归模型的训练，并且由于缺乏几何约束，在新的视点和外观上的性能仍然有限。在本文中，我们提出了一种新的基于统一点表示的视觉定位框架，即PNeRFLoc。一方面，PNeRFLoc像传统的基于结构的方法一样，通过匹配2D和3D特征点来支持初始姿态估计；另一方面，它还通过使用基于渲染的优化的新颖视图合成来实现姿态细化。具体来说，我们提出了一种新的特征自适应模块来缩小视觉定位和神经渲染特征之间的差距。为了提高基于神经渲染的优化的有效性和效率，我们还开发了一个具有扭曲损失函数的高效基于渲染的框架。此外，还开发了几种鲁棒性技术来处理室外场景的照明变化和动态对象。实验表明，当NeRF模型可以很好地学习时，PNeRFLoc在合成数据上表现最好，并且在视觉定位基准数据集上表现与SOTA方法相当。 et.al.|[2312.10649](http://arxiv.org/abs/2312.10649)|null|
|**2023-12-15**|**SlimmeRF: Slimmable Radiance Fields**|神经辐射场（NeRF）及其变体最近已成为新型视图合成和3D场景重建的成功方法。然而，大多数当前的NeRF模型要么使用大的模型尺寸来实现高精度，要么通过权衡精度来实现高存储效率。这限制了任何单个模型的适用范围，因为高精度模型可能不适合低内存设备，而高效内存模型可能无法满足高质量要求。为此，我们提出了SlimmeRF模型，该模型允许通过精简在模型大小和准确性之间进行即时测试时间权衡，从而使模型同时适用于具有不同计算预算的场景。我们通过一种新提出的名为张量秩增量（TRaIn）的算法来实现这一点，该算法在训练过程中逐渐增加模型张量表示的秩。我们还观察到，我们的模型允许在稀疏视图场景中进行更有效的权衡，有时甚至在精简后实现更高的精度。我们将此归功于这样一个事实，即错误信息（如浮动信息）往往存储在与更高级别相对应的组件中。我们的实施可在https://github.com/shiran-yuan/slimmerf. et.al.|[2312.10034](http://arxiv.org/abs/2312.10034)|**[link](https://github.com/shiran-yuan/slimmerf)**|
|**2023-12-15**|**RANRAC: Robust Neural Scene Representations via Random Ray Consensus**|我们介绍了RANRAC，这是一种用于处理遮挡和分心图像的3D对象的鲁棒重建算法，这是现有鲁棒重建方法无法处理的一个特别具有挑战性的场景。我们的解决方案通过涉及光场网络支持单镜头重建，也适用于基于神经辐射场的真实世界图像的照片逼真、鲁棒、多视图重建。虽然该算法对场景表示以及支持的场景类型施加了一定的限制，但它可靠地检测并排除了不一致的视角，从而产生了没有浮动伪影的干净图像。我们的解决方案基于随机样本一致性范式的模糊自适应，使其能够应用于大规模模型。我们将确定模型参数的最小样本数解释为可调超参数。这是适用的，因为更干净的样本集提高了重建质量。此外，此过程还处理异常值。特别是对于条件模型，它可以在潜在空间中产生与完全干净集相同的局部最小值。我们报告了在遮挡场景中新视图合成的显著改进，与基线相比，PSNR高达8dB。 et.al.|[2312.09780](http://arxiv.org/abs/2312.09780)|null|
|**2023-12-15**|**SLS4D: Sparse Latent Space for 4D Novel View Synthesis**|神经辐射场（NeRF）在静态场景的新视图合成和三维表示方面取得了巨大成功。现有的动态NeRF通常利用局部密集网格来拟合变形场；然而，它们未能捕捉到全局动力学，并随之产生重参数模型。我们观察到4D空间本质上是稀疏的。首先，由于运动的连续性，变形场在空间上是稀疏的，但在时间上是密集的。其次，辐射场仅在底层场景的表面有效，通常只占整个空间的一小部分。因此，我们建议使用可学习的稀疏潜在空间（也称为SLS4D）来表示4D场景。具体而言，SLS4D首先使用密集的可学习时隙特征来描述时间空间，从该时间空间中，变形场与线性多层感知（MLP）相拟合，以预测任何时候3D位置的位移。然后，它使用另一个稀疏的潜在空间来学习3D位置的空间特征。这是通过利用注意力机制学习每个潜在代码的自适应权重来实现的。大量实验证明了我们的SLS4D的有效性：它仅使用最近工作的大约 $6\%$ 参数就实现了最佳的4D新视图合成。 et.al.|[2312.09743](http://arxiv.org/abs/2312.09743)|null|
|**2023-12-15**|**TIFace: Improving Facial Reconstruction through Tensorial Radiance Fields and Implicit Surfaces**|本报告描述了在ICCV 2023研讨会上获得“人类头部视图综合挑战（VSCHH）”第一名的解决方案。考虑到人类头部的稀疏视图图像，这一挑战的目标是从新的视点合成图像。由于面部纹理的复杂性和光线的影响，基线方法TensoRF产生的结果具有显著的伪影，严重影响了面部重建。为了解决这个问题，我们提出了TI Face，它分别通过张量辐射场（T-Face）和隐式曲面（I-Face）来改进面部重建。具体来说，我们采用基于SAM的方法来获得前景遮罩，从而过滤掉背景中的强烈照明。此外，我们还设计了基于掩模的约束和稀疏性约束，以有效地消除渲染伪影。实验结果证明了所提出的改进方法的有效性和我们的方法在人脸重建方面的优越性能。代码将在https://github.com/ruijiezhu94/ti-face. et.al.|[2312.09527](http://arxiv.org/abs/2312.09527)|**[link](https://github.com/ruijiezhu94/ti-face)**|
|**2023-12-18**|**LatentEditor: Text Driven Local Editing of 3D Scenes**|虽然神经领域在视图合成和场景重建方面取得了重大进展，但由于其对来自多视图输入的几何和纹理信息的隐式编码，编辑它们带来了巨大的挑战。在本文中，我们介绍了\textsc｛LatentEditor｝，这是一个创新的框架，旨在让用户能够使用文本提示对神经字段进行精确和本地控制的编辑。利用去噪扩散模型，我们成功地将真实世界的场景嵌入到潜在空间中，与传统方法相比，产生了更快、更具适应性的NeRF主干进行编辑。为了提高编辑精度，我们引入了一个delta分数来计算潜在空间中的2D掩模，该分数可以作为局部修改的指南，同时保留不相关的区域。我们新颖的像素级评分方法利用InstructPix2Pix（IP2P）的能力来辨别潜在空间中IP2P条件和无条件噪声预测之间的差异。然后在训练集中迭代地更新以2D掩码为条件的编辑的潜伏时间，以实现3D局部编辑。与现有的3D编辑模型相比，我们的方法实现了更快的编辑速度和卓越的输出质量，弥合了文本指令和潜在空间中高质量3D场景编辑之间的差距。我们在LLFF、IN2N、NeRFStudio和NeRFArt四个基准3D数据集上展示了我们的方法的优势。 et.al.|[2312.09313](http://arxiv.org/abs/2312.09313)|**[link](https://github.com/umarkhalidAI/LatentEditor)**|
|**2023-12-15**|**ColNeRF: Collaboration for Generalizable Sparse Input Neural Radiance Field**|神经辐射场（NeRF）在从密集输入合成新视图方面表现出了令人印象深刻的潜力，然而，在处理稀疏输入时，其有效性受到了挑战。现有的方法结合了额外的深度或语义监督，可以在一定程度上缓解这一问题。然而，监督收集的过程不仅成本高昂，而且可能不准确，导致在不同场景下的表现和泛化能力较差。在我们的工作中，我们介绍了一种新的模型：协作神经辐射场（ColNeRF），设计用于处理稀疏输入。ColNeRF中的协作包括稀疏输入图像之间的协作和神经辐射场的输出之间的协作。通过这一点，我们构建了一个新的协作模块，该模块将来自不同视图的信息对齐，同时施加自监督约束，以确保多视图在几何和外观上的一致性。提出了一种协作跨视图体积集成模块（CCVI）来捕捉复杂的遮挡并隐含地推断对象的空间位置。此外，我们引入了对多个方向上投影的目标射线的自监督，以确保相邻区域的几何和颜色一致性。得益于输入端和输出端的协作，ColNeRF能够捕捉更丰富、更通用的场景表示，从而促进新视图合成的更高质量结果。大量实验表明，ColNeRF优于最先进的稀疏输入可推广NeRF方法。此外，与基于场景优化的NeRF方法相比，我们的方法在微调以适应新场景方面表现出优势，实现了有竞争力的性能，同时显著降低了计算成本。我们的代码位于：https://github.com/eezkni/colnerf. et.al.|[2312.09095](http://arxiv.org/abs/2312.09095)|**[link](https://github.com/eezkni/colnerf)**|
|**2023-12-15**|**ProSGNeRF: Progressive Dynamic Neural Scene Graph with Frequency Modulated Auto-Encoder in Urban Scenes**|隐式神经表示在大型复杂场景的视图合成中已显示出有希望的结果。然而，现有的方法要么无法捕捉快速移动的对象，要么需要在没有相机自我运动的情况下构建场景图，导致场景的合成视图质量低。我们旨在共同解决大规模城市场景和快速移动车辆的视图合成问题，这更具实用性和挑战性。为此，我们首先利用图结构来学习动态对象和背景的局部场景表示。然后，我们设计了一个渐进方案，该方案动态地分配用时间窗口内的帧训练的新的局部场景图，允许我们将表示放大到任意大的场景。此外，城市场景的训练视图相对稀疏，这导致动态对象的重建精度显著下降。因此，我们设计了一个频率自动编码器网络来对潜在代码进行编码，并正则化对象的频率范围，这可以增强动态对象的表示，解决图像输入稀疏的问题。此外，我们使用激光雷达点投影来保持大规模城市场景中的几何一致性。实验结果表明，我们的方法实现了最先进的视图合成精度、对象操纵和场景漫游能力。该代码将在论文验收后开源。 et.al.|[2312.09076](http://arxiv.org/abs/2312.09076)|null|
|**2023-12-14**|**Scene 3-D Reconstruction System in Scattering Medium**|随着新模型和扩展的发展，用于新视图合成的神经辐射场研究经历了爆炸式增长。适用于水下场景或散射介质的NERF算法也在不断发展。现有的水下三维重建系统仍然面临训练时间长、渲染效率低等挑战。本文提出了一种改进的水下三维重建系统来解决这些问题，并实现快速、高质量的三维重建。首先，我们增强了单眼相机拍摄的水下视频，以纠正水介质物理特性造成的图像质量差的问题，同时确保相邻帧增强的一致性。随后，我们对视频帧进行关键帧选择，以优化资源利用率，消除动态对象对重建结果的影响。所选关键帧在使用COLMAP进行姿态估计后，使用基于多分辨率哈希编码的神经辐射场进行三维重建改进过程，用于模型构建和渲染。 et.al.|[2312.09005](http://arxiv.org/abs/2312.09005)|null|
|**2023-12-14**|**VaLID: Variable-Length Input Diffusion for Novel View Synthesis**|新视图合成（NVS）是3D视觉中的一个基本问题，它试图在给定源视图图像及其相应姿态的情况下，在目标视图上生成逼真的图像。由于这项任务严重受限，最近的一些工作，如Zero123，试图通过生成建模来解决这个问题，特别是使用预先训练的扩散模型。尽管这种策略很好地适用于新场景，但与基于神经辐射场的方法相比，它提供的灵活性很低。例如，尽管现实应用程序通常提供多个输入图像，但它只能接受单个视图图像作为输入。这是因为源视图图像和相应的姿势是单独处理的，并在不同阶段注入到模型中。因此，一旦模型可用，将其推广到多视图源图像中并非易事。为了解决这个问题，我们试图分别处理每个姿势图像对，然后将它们融合为统一的视觉表示，将其注入模型中，以指导目标视图的图像合成。然而，不一致性和计算成本随着输入源视图图像的数量的增加而增加。为了解决这些问题，提出了多视图交叉形成器模块，该模块将可变长度的输入数据映射到固定大小的输出数据。为了进一步提高训练时间的效率，引入了两阶段训练策略。在多个数据集上进行的定性和定量评估证明了所提出的方法相对于以前的方法的有效性。代码将根据验收结果发布。 et.al.|[2312.08892](http://arxiv.org/abs/2312.08892)|null|

<p align=right>(<a href=#updated-on-20231220>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-17**|**Primitive-based 3D Human-Object Interaction Modelling and Programming**|在三维环境中嵌入人与关节对象交互（HAOI）是深入理解人类活动的一个重要方向。与以往使用参数化和CAD模型来表示人和物体的工作不同，在这项工作中，我们提出了一种新的基于三维几何图元的语言来对人和物体进行编码。在我们的新范式下，人和物体都是原语的组成部分，而不是异构实体。因此，可以在人类的有限3D数据和不同对象类别之间实现相互信息学习。此外，考虑到表达式的简单性和所包含信息的丰富性，我们选择超二次曲面作为原始表示。为了探索机器的HAOI的有效嵌入，我们在由基元及其图像组成的3D HAOI上建立了一个新的基准，并提出了一项任务，要求机器使用图像中的基元恢复三维HAOI。此外，我们提出了基于HAOI的单视图三维重建的基线。我们相信，这种基于原始的3D HAOI表示将为3D HAOI研究铺平道路。我们的代码和数据可在https://mvig-rhos.com/p3haoi. et.al.|[2312.10714](http://arxiv.org/abs/2312.10714)|null|
|**2023-12-16**|**Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D Reconstruction with Transformers**|生成模型的发展推动了从单个图像进行3D重建的最新进展。其中最突出的是基于分数蒸馏采样（SDS）的方法和3D域中扩散模型的自适应。尽管这些技术取得了进展，但由于优化或渲染过程缓慢，导致训练和优化时间过长，这些技术往往面临限制。在本文中，我们介绍了一种新的单视图重建方法，该方法通过前馈推理从单个图像有效地生成3D模型。我们的方法利用两个基于变换器的网络，即点解码器和三平面解码器，使用混合三平面高斯中间表示来重建3D对象。这种混合表示实现了平衡，与隐式表示相比，实现了更快的渲染速度，同时提供了比显式表示更高的渲染质量。点解码器被设计用于从单个图像生成点云，提供显式表示，然后由三平面解码器使用该显式表示来查询每个点的高斯特征。这种设计选择解决了与直接回归以其非结构性质为特征的显式三维高斯属性相关的挑战。随后，通过MLP对3D高斯进行解码，以实现通过飞溅的快速渲染。这两个解码器都建立在可扩展的、基于转换器的架构上，并在大规模3D数据集上进行了有效的训练。对合成数据集和真实世界图像进行的评估表明，与以前最先进的技术相比，我们的方法不仅实现了更高的质量，而且确保了更快的运行时间。请参阅我们的项目页面https://zouzx.github.io/triplanegaussian/. et.al.|[2312.09147](http://arxiv.org/abs/2312.09147)|null|
|**2023-12-14**|**Living Scenes: Multi-object Relocalization and Reconstruction in Changing 3D Environments**|对动态3D场景理解的研究主要集中在密集观测的短期变化跟踪上，而很少关注稀疏观测的长期变化。我们用MoRE解决了这一差距，MoRE是一种在进化环境中进行多对象重新定位和重建的新方法。我们将这些环境视为“真实场景”，并考虑将在不同时间点进行的扫描转换为对象实例的3D重建的问题，其准确性和完整性会随着时间的推移而提高。我们方法的核心是在合成数据上训练的单个编码器-解码器网络中的SE（3）-等变表示。这种表示使我们能够无缝地处理实例匹配、注册和重建。我们还引入了一种联合优化算法，该算法有助于在不同时间点进行的多次扫描中积累源自同一实例的点云。我们在合成和真实世界的数据上验证了我们的方法，并在端到端性能和单个子任务中展示了最先进的性能。 et.al.|[2312.09138](http://arxiv.org/abs/2312.09138)|null|
|**2023-12-14**|**Learned Fusion: 3D Object Detection using Calibration-Free Transformer Feature Fusion**|使用传感器融合的3D对象检测的现有技术在很大程度上依赖于校准质量，这在实验室环境之外的大规模部署中很难维持。我们提出了第一种用于三维物体检测的无校准方法。因此，消除了对复杂且昂贵的校准程序的需要。我们的方法使用转换器在多个抽象级别上映射不同传感器的多个视图之间的特征。在对物体检测的广泛评估中，我们不仅表明我们的方法在BEV mAP中比单模态设置好14.1%，而且转换器确实学习了映射。通过表明传感器融合不需要校准，我们希望激励其他研究人员遵循无校准融合的方向。此外，由此产生的方法对旋转和平移变化具有相当大的弹性。 et.al.|[2312.09082](http://arxiv.org/abs/2312.09082)|null|
|**2023-12-14**|**Scene 3-D Reconstruction System in Scattering Medium**|随着新模型和扩展的发展，用于新视图合成的神经辐射场研究经历了爆炸式增长。适用于水下场景或散射介质的NERF算法也在不断发展。现有的水下三维重建系统仍然面临训练时间长、渲染效率低等挑战。本文提出了一种改进的水下三维重建系统来解决这些问题，并实现快速、高质量的三维重建。首先，我们增强了单眼相机拍摄的水下视频，以纠正水介质物理特性造成的图像质量差的问题，同时确保相邻帧增强的一致性。随后，我们对视频帧进行关键帧选择，以优化资源利用率，消除动态对象对重建结果的影响。所选关键帧在使用COLMAP进行姿态估计后，使用基于多分辨率哈希编码的神经辐射场进行三维重建改进过程，用于模型构建和渲染。 et.al.|[2312.09005](http://arxiv.org/abs/2312.09005)|null|
|**2023-12-13**|**ProNeRF: Learning Efficient Projection-Aware Ray Sampling for Fine-Grained Implicit Neural Radiance Fields**|神经渲染的最新进展表明，尽管速度较慢，但隐式紧凑模型可以从多个视图中学习场景的几何图形和视图相关外观。为了保持如此小的内存占用，但实现更快的推理时间，最近的工作采用了“采样器”网络，该网络自适应地对隐式神经辐射场中沿每条射线的一小部分点进行采样。尽管这些方法在渲染时间上减少了10美元\倍，但与香草NeRF相比，它们的质量仍有相当大的下降。相反，我们提出了ProNeRF，它在内存占用（类似于NeRF）、速度（比HyperReel快）和质量（比K-Planes好）之间提供了最佳折衷。ProNeRF配备了一种新的投影感知采样（PAS）网络，以及一种用于射线探测和利用的新训练策略，从而实现高效的细粒度粒子采样。我们的ProNeRF产生了最先进的指标，比NeRF快15-23倍，PSNR比NeRF高0.65dB，比已发表的最佳基于采样器的方法HyperReel高0.95dB。我们的探索和开发训练策略使ProNeRF能够学习完整场景的颜色和密度分布，同时学习聚焦于最高密度区域的高效光线采样。我们提供了广泛的实验结果，分别在广泛采用的前向和360数据集LLFF和Blender上支持我们的方法的有效性。 et.al.|[2312.08136](http://arxiv.org/abs/2312.08136)|null|
|**2023-12-13**|**Denoising diffusion-based synthetic generation of three-dimensional (3D) anisotropic microstructures from two-dimensional (2D) micrographs**|集成计算材料工程（ICME）显著增强了对微观结构与材料性能之间关系的系统分析，为高性能材料的发展铺平了道路。然而，由于缺乏三维（3D）微观结构数据集，分析微观结构敏感材料的行为仍然具有挑战性。此外，如果微观结构是各向异性的，这一挑战会被放大，因为这也会导致材料的各向异性。在本文中，我们提出了一种仅基于二维（2D）显微照片使用基于条件扩散的生成模型（DGM）重建各向异性微观结构的框架。所提出的框架涉及多个2D条件DGM的空间连接，每个条件DGM都经过训练以生成三个不同正交平面的2D微观结构样本。连接的多个反向扩散过程使得能够对马尔可夫链进行有效建模，以将噪声转换为3D微观结构样本。此外，采用改进的协调采样来提高样本质量，同时在3D空间中保持各向异性微观结构样本切片之间的空间连接。为了验证所提出的框架，根据空间相关函数和物理材料行为对二维到三维重建的各向异性微观结构样品进行了评估。结果表明，该框架不仅能够再现材料相的统计分布，而且能够再现三维空间中的材料性质。这突出了所提出的二维到三维重建框架在建立微观结构-性能联系方面的潜在应用，这可能有助于未来研究的高通量材料设计 et.al.|[2312.07832](http://arxiv.org/abs/2312.07832)|null|
|**2023-12-12**|**Adaptive Confidence Multi-View Hashing for Multimedia Retrieval**|多视图哈希方法将多个视图中的异构数据转换为二进制哈希码，是多媒体检索的关键技术之一。然而，目前的方法主要探讨多个观点之间的互补性，而缺乏信心学习和融合。此外，在实际应用场景中，单视图数据包含冗余噪声。为了进行置信度学习并消除不必要的噪声，我们提出了一种新的自适应置信度多视图哈希（ACMVH）方法。首先，开发了置信网络来从各种单视图特征中提取有用信息并去除噪声信息。此外，采用自适应置信度多视图网络来测量每个视图的置信度，然后通过加权求和来融合多视图特征。最后，设计了一个扩展网络来进一步增强融合特征的特征表示。据我们所知，我们率先将置信学习应用于多媒体检索领域。在两个公共数据集上进行的大量实验表明，所提出的ACMVH比最先进的方法性能更好（最大增加了3.24%）。源代码可在https://github.com/hackerhyper/acmvh. et.al.|[2312.07327](http://arxiv.org/abs/2312.07327)|**[link](https://github.com/hackerhyper/acmvh)**|
|**2023-12-11**|**Gaussian Splatting SLAM**|我们首次将3D高斯散射应用于使用单个移动单目或RGB-D相机的增量3D重建。我们的同步定位和映射（SLAM）方法以3fps实时运行，使用高斯作为唯一的3D表示，统一了所需的表示，以实现准确、高效的跟踪、映射和高质量渲染。需要一些创新来从现场摄像机连续重建具有高保真度的3D场景。首先，为了超越最初的3DGS算法，该算法需要来自离线运动结构（SfM）系统的精确姿态，我们使用针对3D高斯的直接优化来制定3DGS的相机跟踪，并表明这能够实现快速而稳健的跟踪，并具有广泛的收敛范围。其次，通过利用高斯的显式性质，我们引入了几何验证和正则化来处理增量三维密集重建中出现的模糊性。最后，我们介绍了一个完整的SLAM系统，它不仅在新的视图合成和轨迹估计方面取得了最先进的结果，而且还重建了微小甚至透明的物体。 et.al.|[2312.06741](http://arxiv.org/abs/2312.06741)|null|
|**2023-12-11**|**Nuvo: Neural UV Mapping for Unruly 3D Representations**|现有的UV映射算法被设计为在性能良好的网格上操作，而不是由最先进的3D重建和生成技术产生的几何表示。因此，将这些方法应用于由神经辐射场和相关技术（或从这些场三角化的网格）恢复的体积密度会导致纹理图谱过于分散，无法用于视图合成或外观编辑等任务。我们提出了一种UV映射方法，旨在对通过3D重建和生成技术产生的几何体进行操作。我们的方法Nuvo不是计算在网格顶点上定义的映射，而是使用神经场来表示连续的UV映射，并将其优化为仅针对一组可见点（即仅影响场景外观的点）的有效且性能良好的映射。我们展示了我们的模型对不良几何体带来的挑战是稳健的，并且它生成了可以表示详细外观的可编辑UV映射。 et.al.|[2312.05283](http://arxiv.org/abs/2312.05283)|null|

<p align=right>(<a href=#updated-on-20231220>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-18**|**A novel diffusion recommendation algorithm based on multi-scale cnn and residual lstm**|顺序推荐旨在从历史交互序列中推断用户偏好，并预测用户未来可能感兴趣的下一个项目。当前的主流设计方法是将项目表示为固定向量，根据交互顺序捕捉项目和用户偏好之间的潜在关系。然而，依赖于单一的固定项目嵌入可能会削弱系统的建模能力，并且需要区分用户偏好所表现出的全局动态性和局部显著性。为了解决这些问题，本文提出了一种新的基于多尺度cnn和残差lstm的扩散推荐算法（AREAL）。我们在推荐系统中引入了扩散模型，将项目表示为概率分布，而不是固定向量。这种方法能够自适应地反映项目的多个方面，并以去噪的方式生成项目分布。我们使用多尺度cnn和残差lstm方法来提取用户历史交互的局部和全局依赖特征，并使用注意力机制来区分权重作为反向扩散恢复的指导特征。通过在两个真实世界数据集上进行的实验验证了所提出方法的有效性。具体而言，AREAL在以下方面比最佳基线分别提高了2.63%和4.25%hr@20和5.05%和3.94%ndcg@20在所有数据集上。 et.al.|[2312.10885](http://arxiv.org/abs/2312.10885)|null|
|**2023-12-18**|**Dirac walks on regular trees**|研究随机几何集合上的物质场是一个仍然需要新方法和新思想的难题。我们将遵循受概率论技术启发的观点，该技术依赖于两点函数在随机游动上的和的展开。费米子在非欧几里得几何上的类似展开仍然缺乏。Casiday等人[\textit{图上的拉普拉斯和狄拉克算子}，线性和多线性代数（2022）1]提出了一种经典的“狄拉克行走”，它在具有图拉普拉斯平方根的有向图的顶点和边上扩散。与简单的随机行走不同，行走的每一步都有一个标志，这取决于它所经过的边缘的方向。在一个玩具模型中，我们建议研究这种“狄拉克行走”在Bethe格（一个 $d$-正则树）上的格林函数、谱和谱维。图的递归结构使问题完全可解。值得注意的是，我们发现谱产生了一个间隙，并且狄拉克行走的谱维数与简单随机行走的谱维相匹配（$d=2$为$d_s=1$，$d\geq3$为$d-s=3$ ）。 et.al.|[2312.10881](http://arxiv.org/abs/2312.10881)|null|
|**2023-12-17**|**Hydrodynamic interactions in anomalous rheology of active suspensions**|我们通过使用模型推手游泳运动员的流体动力学模拟，探索了主动悬浮液异常流变的机制。我们的模拟表明，剪切流下的流体动力学相互作用使游泳者沿着延伸方向系统地定向，这是决定全局游泳状态和由此产生的显著粘度降低的原因。目前的结果表明，流体动力学相互作用在控制活性悬浮液流变特性的基本过程中起着重要作用。此外，这种过程可能是先前提出的基于旋转扩散率和外部剪切流之间的相互作用的异常流变性场景的实质。 et.al.|[2312.10852](http://arxiv.org/abs/2312.10852)|null|
|**2023-12-17**|**Your Student is Better Than Expected: Adaptive Teacher-Student Collaboration for Text-Conditional Diffusion Models**|最近，知识提取方法已被证明是一个很有前途的方向，可以通过只需要几个推理步骤来加速大规模扩散模型的合成。虽然最近提出了几种强大的蒸馏方法，但与教师样品相比，学生样品的总体质量通常较低，这阻碍了它们的实际使用。在这项工作中，我们研究了教师文本到图像扩散模型及其提取的学生版本产生的样本的相对质量。作为我们的主要实证发现，我们发现，尽管学生具有“近似”性质，但与教师样本相比，学生样本中有相当一部分表现出更高的保真度。基于这一发现，我们提出了一种学生和教师之间的自适应协作扩散模型，用于有效的文本到图像合成。具体来说，提取的模型产生初始样本，然后由oracle决定是否需要使用慢速教师模型进行进一步改进。大量实验表明，在人类偏好方面，所设计的管道在各种推理预算方面超过了最先进的文本到图像的替代方案。此外，所提出的方法可以自然地用于流行的应用，如文本引导的图像编辑和可控生成。 et.al.|[2312.10835](http://arxiv.org/abs/2312.10835)|**[link](https://github.com/yandex-research/adaptive-diffusion)**|
|**2023-12-17**|**Nernst Sign-Reversal in the Hexatic Vortex Phase of Weakly Disordered a-MoGe Thin Films**|由于拓扑缺陷，六方相是2D晶体熔化过程中的中间阶段。最近，通过扫描隧道显微镜测量，在二维弱无序超导MoGe的涡旋晶格中实验发现了这种奇异相。在这里，我们通过能斯特效应研究了这种涡旋状态，这是一种有效而灵敏的检测涡旋运动的工具，尤其是在超导涨落区。我们发现在六方相的熔化转变处出现了令人惊讶的能斯特符号反转。我们提出，它们是六角态涡旋位错的结果，这些位错优选地从冷扩散到热。 et.al.|[2312.10805](http://arxiv.org/abs/2312.10805)|null|
|**2023-12-17**|**Surface quantum critical phenomena in disordered Dirac semimetals**|我们研究了具有平坦边界的半无限Dirac半金属中非Anderson无序驱动的量子相变。保形不变边界条件，包括那些时间反转不变的边界条件，导致边界上的节点状表面状态。在这种情况下，边界在临界无序下变成金属，该临界无序比体中的半金属扩散金属过渡的临界无序弱。后一种转变发生在存在金属表面的情况下；在表面批判现象的语言中，这对应于所谓的非同寻常的转变。曲面的线条和非同寻常的过渡在特殊的过渡点处相交。为了阐明相图上不同跃迁的普遍性质，我们采用重整化群方法，并使用 $\varepsilon$ 展开计算相应的表面临界指数。 et.al.|[2312.10790](http://arxiv.org/abs/2312.10790)|null|
|**2023-12-17**|**From mixing to displacement of miscible phases in porous media: The role of heterogeneity and inlet pressure**|多孔介质中的混相多相流是各种工业和自然过程中的一个关键现象，如储氢和地质固碳。然而，控制这些流动中的位移和混合模式的参数并没有完全解决。本研究深入研究了非均质性和入口压力对低粘度混溶相侵入高粘度驻留相（即饱和多孔介质）的混合和驱替模式的影响。研究结果强调了入口压力和非均质性水平在孔隙尺度上从均匀模式转变为指进模式的重大影响。这些现象在达西尺度上是可以检测到的，并且通过修改的舍伍德数可以有效地量化它们从均匀前沿到手指形成的转变。这种量化将微观尺度模式与速度分布、扩散和粘度对比等物理特性联系起来。此外，该研究采用突破曲线（BTC）分析来说明更高的非均质性和入口压力在拓宽流体速度分布、导致指进模式方面的作用。这些研究见解为未来多孔介质中混溶相流的模型提供了一种无量纲的方法，将孔隙尺度动力学与宏观尺度达西尺度观测联系起来 et.al.|[2312.10722](http://arxiv.org/abs/2312.10722)|null|
|**2023-12-17**|**CogCartoon: Towards Practical Story Visualization**|最先进的故事可视化方法显示了对训练数据和存储的巨大需求，以及故事呈现的有限灵活性，从而使它们在现实世界的应用中不切实际。我们介绍了CogCartoon，一种基于预先训练的扩散模型的实用故事可视化方法。为了减轻对数据和存储的依赖，我们提出了一种字符插件生成的创新策略，该策略可以通过使用一些训练样本将特定字符表示为紧凑的316KB插件。为了增强灵活性，我们采用了插件引导和布局引导推理的策略，使用户能够在方便的时候将新字符和自定义布局无缝地结合到生成的图像结果中。我们进行了全面的定性和定量研究，为CogCartoon优于现有方法提供了令人信服的证据。此外，CogCartoon展示了其在应对挑战性任务方面的能力，包括长篇故事可视化和现实主义风格的故事可视化。 et.al.|[2312.10718](http://arxiv.org/abs/2312.10718)|null|
|**2023-12-17**|**Stability Analysis of Degenerate Einstein Model of Brownian Motion**|我们在随机过程方面的最新进展揭示了与布朗运动的爱因斯坦模型相关的一个悖论。该模型预测了无限的传播速度，与热力学第二定律相矛盾。改进的模型成功地解决了这个问题，通过引入浓度相关的扩散矩阵建立了有限的传播速度。在本文中，我们通过一个反例概述了这个性质的必要条件。论文的第二部分主要研究退化爱因斯坦模型解的稳定性分析。我们引入了对满足特定常微分不等式的解的函数依赖性。我们的研究探索了解对原始问题的边界和初始数据的依赖性，证明了在各种条件下的渐近稳定性。这些结果在理解有界域内的随机过程中具有实际应用。 et.al.|[2312.10682](http://arxiv.org/abs/2312.10682)|null|
|**2023-12-17**|**A Framework of Full-Process Generation Design for Park Green Spaces Based on Remote Sensing Segmentation-GAN-Diffusion**|人工智能算法驱动的生成设计发展迅速。目前的研究存在两个研究空白：1）大多数研究只关注设计元素之间的关系，很少关注场地的外部信息；2） GAN和其他传统的生成算法生成的结果分辨率低，细节不足。为了解决这两个问题，我们集成了GAN，稳定扩散多模式大规模图像预训练模型，构建了一种全过程公园生成设计方法：1）首先，构建高精度遥感目标提取系统，用于城市环境信息的自动提取；2） 其次，利用GAN构建基于外部环境的公园设计生成系统，可以从城市环境信息中快速推断和生成设计方案；3） 最后，引入Stable Diffusion对设计方案进行优化，填写细节，并将方案的分辨率扩展64倍。这种方法可以实现完全无人化的设计自动化工作流程。研究结果表明：1）站点内外的关系会影响算法的生成结果。2） 与传统的GAN算法相比，稳定扩散显著提高了生成结果的信息丰富度。 et.al.|[2312.10674](http://arxiv.org/abs/2312.10674)|null|

<p align=right>(<a href=#updated-on-20231220>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-16**|**How to Train Neural Field Representations: A Comprehensive Study and Benchmark**|神经场（NeFs）最近已成为一种用于对各种模态（包括图像、形状和场景）的信号进行建模的通用方法。随后，许多工作探索了使用NeF作为下游任务的表示，例如，根据适合的NeF的参数对图像进行分类。然而，NeF超参数对其作为下游表示的质量的影响很少被理解，而且在很大程度上仍未被探索。这在一定程度上是由于拟合神经场数据集所需的大量时间造成的。在这项工作中，我们提出了 $\verb|fit-a-nef|$ ，这是一个基于JAX的库，它利用并行化来实现大规模nef数据集的快速优化，从而显著加快速度。有了这个库，我们进行了一项全面的研究，研究了不同超参数——包括初始化、网络架构和优化策略——对下游任务的NeF拟合的影响。我们的研究为如何训练NeF提供了宝贵的见解，并为优化其在下游应用中的有效性提供了指导。最后，基于所提出的库和我们的分析，我们提出了Neural Field Arena，这是一个由流行视觉数据集的神经场变体组成的基准，包括MNIST、CIFAR、ImageNet和ShapeNetv2的变体。我们的图书馆和神经领域竞技场将是开源的，以引入标准化的基准测试，并促进对神经领域的进一步研究。 et.al.|[2312.10531](http://arxiv.org/abs/2312.10531)|**[link](https://github.com/samuelepapa/fit-a-nef)**|
|**2023-12-18**|**LatentEditor: Text Driven Local Editing of 3D Scenes**|虽然神经领域在视图合成和场景重建方面取得了重大进展，但由于其对来自多视图输入的几何和纹理信息的隐式编码，编辑它们带来了巨大的挑战。在本文中，我们介绍了\textsc｛LatentEditor｝，这是一个创新的框架，旨在让用户能够使用文本提示对神经字段进行精确和本地控制的编辑。利用去噪扩散模型，我们成功地将真实世界的场景嵌入到潜在空间中，与传统方法相比，产生了更快、更具适应性的NeRF主干进行编辑。为了提高编辑精度，我们引入了一个delta分数来计算潜在空间中的2D掩模，该分数可以作为局部修改的指南，同时保留不相关的区域。我们新颖的像素级评分方法利用InstructPix2Pix（IP2P）的能力来辨别潜在空间中IP2P条件和无条件噪声预测之间的差异。然后在训练集中迭代地更新以2D掩码为条件的编辑的潜伏时间，以实现3D局部编辑。与现有的3D编辑模型相比，我们的方法实现了更快的编辑速度和卓越的输出质量，弥合了文本指令和潜在空间中高质量3D场景编辑之间的差距。我们在LLFF、IN2N、NeRFStudio和NeRFArt四个基准3D数据集上展示了我们的方法的优势。 et.al.|[2312.09313](http://arxiv.org/abs/2312.09313)|**[link](https://github.com/umarkhalidAI/LatentEditor)**|
|**2023-12-14**|**ZeroRF: Fast Sparse View 360° Reconstruction with Zero Pretraining**|我们提出了ZeroRF，这是一种新的每场景优化方法，解决了神经场表示中稀疏视图360重建的挑战。目前的突破，如神经辐射场（NeRF）已经证明了高保真度的图像合成，但难以处理稀疏的输入视图。现有的方法，如可泛化的NeRF和每场景优化方法，在数据依赖性、计算成本和跨不同场景的泛化方面面临限制。为了克服这些挑战，我们提出了ZeroRF，其关键思想是将定制的深度图像先验集成到因子分解的NeRF表示中。与传统方法不同，ZeroRF使用神经网络生成器对特征网格进行参数化，从而实现高效的稀疏视图360重建，而无需任何预训练或额外的正则化。大量实验展示了ZeroRF在质量和速度方面的多功能性和优势，在基准数据集上取得了最先进的结果。ZeroRF的意义延伸到3D内容生成和编辑的应用。项目页面：https://sarahweiii.github.io/zerorf/ et.al.|[2312.09249](http://arxiv.org/abs/2312.09249)|null|
|**2023-12-12**|**SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration**|最近的实时视图合成技术在保真度和速度上迅速进步，现代方法能够以交互式帧速率渲染接近照片级真实感的场景。与此同时，在易于光栅化的显式场景表示和基于射线行进的神经场之间出现了紧张关系，后者的最先进实例在质量上超过了前者，同时对于实时应用来说成本高得令人望而却步。在这项工作中，我们介绍了SMERF，这是一种视图合成方法，在占地面积高达3亿 $^2$、体积分辨率为3.5毫米$^3$ 的大型场景中，它实现了实时方法中最先进的精度。我们的方法建立在两个主要贡献之上：一个是分层模型划分方案，它在限制计算和内存消耗的同时增加了模型容量，另一个是蒸馏训练策略，它同时产生高保真度和内部一致性。我们的方法能够在网络浏览器中实现全六自由度（6DOF）导航，并在商品智能手机和笔记本电脑上实时渲染。大量实验表明，我们的方法在实时新视图合成方面，在标准基准上超过了当前最先进的0.78 dB，在大型场景上超过了1.78 dB，渲染帧的速度比最先进的辐射场模型快三个数量级，并在包括智能手机在内的各种商品设备上实现了实时性能。我们鼓励读者在我们的项目网站上亲自探索这些模型：https://smerf-3d.github.io. et.al.|[2312.07541](http://arxiv.org/abs/2312.07541)|null|
|**2023-12-09**|**Robo360: A 3D Omnispective Multi-Material Robotic Manipulation Dataset**|长期以来，制造能够自动化劳动密集型任务的机器人一直是计算机视觉和机器人界进步的核心动力。最近人们对利用3D算法，特别是神经领域的兴趣，导致了机器人在操作场景中的感知和物理理解方面的进步。然而，现实世界的复杂性带来了重大挑战。为了应对这些挑战，我们提出了Robo360，这是一个以机器人操作为特征的数据集，具有密集的视图覆盖范围，能够实现高质量的3D神经表示学习，以及一组具有各种物理和光学特性的不同对象，有助于各种对象操作和物理世界建模任务的研究。我们使用现有的动态NeRF来确认我们的数据集的有效性，并评估其在学习多视图策略方面的潜力。我们希望Robo360能够在理解3D物理世界和机器人控制的交叉点上开辟新的研究方向。 et.al.|[2312.06686](http://arxiv.org/abs/2312.06686)|null|
|**2023-12-11**|**Representing stimulus motion with waves in adaptive neural fields**|神经活动的行波在皮层网络中自发出现，并对刺激做出反应。波的时空结构可以指示它们编码的信息以及维持它们的生理过程。在这里，我们研究了作为视觉运动处理模型的自适应神经场中出现的行波的刺激响应关系。神经场方程将皮层组织的活动建模为连续的可兴奋介质，自适应过程提供负反馈，产生局部活动模式。在我们的模型中，突触连接由一个积分核来描述，该积分核由于依赖于活动的突触抑制而动态减弱，导致边缘稳定的行进前沿（具有衰减的后部）或固定速度的脉冲。我们的分析量化了弱刺激如何随着时间的推移改变这些波的相对位置，其特征是我们扰动地获得的波响应函数。持续和连续可见的刺激模拟移动的视觉对象。在视觉空间中跳跃的间歇性闪光可以产生流畅的视觉运动体验。我们的理论和数值模拟很好地描述了波对两种运动刺激的夹带，提供了视觉运动感知的机制描述。 et.al.|[2312.06100](http://arxiv.org/abs/2312.06100)|null|
|**2023-12-10**|**Accurate Differential Operators for Hybrid Neural Fields**|神经场已广泛应用于从形状表示到神经渲染以及求解偏微分方程（PDE）的各个领域。随着混合神经场表示的出现，如利用小MLP和显式表示的即时NGP，这些模型训练迅速，可以适应大型场景。然而，在渲染和模拟等许多应用中，混合神经场可能会导致明显且不合理的伪影。这是因为它们不能产生这些下游应用所需的精确的空间导数。在这项工作中，我们提出了两种规避这些挑战的方法。我们的第一种方法是一种事后算子，它使用局部多项式拟合从预先训练的混合神经场中获得更准确的导数。此外，我们还提出了一种自监督微调方法，该方法在保留初始信号的同时，对神经场进行细化，以直接产生准确的导数。我们展示了我们的方法在渲染、碰撞模拟和求解偏微分方程中的应用。我们观察到，使用我们的方法可以产生更准确的导数，减少伪影，并在下游应用中实现更准确的模拟。 et.al.|[2312.05984](http://arxiv.org/abs/2312.05984)|null|
|**2023-12-11**|**Nuvo: Neural UV Mapping for Unruly 3D Representations**|现有的UV映射算法被设计为在性能良好的网格上操作，而不是由最先进的3D重建和生成技术产生的几何表示。因此，将这些方法应用于由神经辐射场和相关技术（或从这些场三角化的网格）恢复的体积密度会导致纹理图谱过于分散，无法用于视图合成或外观编辑等任务。我们提出了一种UV映射方法，旨在对通过3D重建和生成技术产生的几何体进行操作。我们的方法Nuvo不是计算在网格顶点上定义的映射，而是使用神经场来表示连续的UV映射，并将其优化为仅针对一组可见点（即仅影响场景外观的点）的有效且性能良好的映射。我们展示了我们的模型对不良几何体带来的挑战是稳健的，并且它生成了可以表示详细外观的可编辑UV映射。 et.al.|[2312.05283](http://arxiv.org/abs/2312.05283)|null|
|**2023-12-08**|**Dynamic LiDAR Re-simulation using Compositional Neural Fields**|我们介绍了DyNFL，这是一种新的基于神经场的方法，用于动态驾驶场景中激光雷达扫描的高保真度重新模拟。DyNFL处理来自动态环境的激光雷达测量，并伴随着移动物体的边界框，以构建可编辑的神经场。该字段包括单独重建的静态背景和动态对象，允许用户在重新模拟的场景中修改视点、调整对象位置以及无缝添加或删除对象。我们方法的一个关键创新是神经场合成技术，该技术通过光线下降测试有效地集成了来自各种场景的重建神经资产，考虑到了遮挡和透明表面。我们对合成和真实世界环境的评估表明，\ShortName大大改进了基于激光雷达扫描的动态场景模拟，提供了物理保真度和灵活编辑功能的组合。 et.al.|[2312.05247](http://arxiv.org/abs/2312.05247)|null|
|**2023-12-08**|**TriHuman : A Real-time and Controllable Tri-plane Representation for Detailed Human Geometry and Appearance Synthesis**|仅从视频数据中创建可控、逼真和几何细节的真人数字替身是计算机图形学和视觉领域的一个关键挑战，尤其是在需要实时性能的情况下。最近的方法将神经辐射场（NeRF）连接到关节结构，例如身体模型或骨骼，以将点映射到姿势规范空间中，同时将NeRF调节在骨骼姿势上。这些方法通常使用多层感知器（MLP）对神经场进行参数化，导致运行时间缓慢。为了解决这一缺点，我们提出了一种新的人体定制、可变形和高效的三平面表示TriHuman，它实现了实时性能、最先进的姿态可控几何合成以及逼真的渲染质量。在核心，我们将全局光线样本非刚性地扭曲到未变形的三平面纹理空间中，这有效地解决了全局点映射到相同三平面位置的问题。然后，我们展示了如何将这种三平面特征表示以骨骼运动为条件，以考虑动态外观和几何结构的变化。我们的研究结果表明，在人类的几何形状和外观建模以及运行时性能方面，朝着更高质量迈出了明确的一步。 et.al.|[2312.05161](http://arxiv.org/abs/2312.05161)|null|

<p align=right>(<a href=#updated-on-20231220>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

