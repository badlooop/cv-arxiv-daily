[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.09.18
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-09-14**|**Viewpoint Textual Inversion: Unleashing Novel View Synthesis with Pretrained 2D Diffusion Models**|文本到图像的扩散模型理解物体之间的空间关系，但它们是否仅从2D监督中代表了世界的真实3D结构？我们证明，是的，3D知识被编码在2D图像扩散模型中，如稳定扩散，我们证明这种结构可以用于3D视觉任务。我们的方法，视点神经纹理反演（ViewNeTI），控制从冻结扩散模型生成的图像中对象的3D视点。我们训练一个小型神经映射器来获取相机视点参数并预测文本编码器延迟；潜伏时间然后调节扩散生成过程以产生具有期望的相机视点的图像。ViewNeTI自然地解决了新颖视图合成（NVS）问题。通过利用冻结扩散模型作为先验，我们可以用很少的输入视图来解决NVS；我们甚至可以做单一视角的小说视角合成。与先前的方法相比，我们的单视图NVS预测具有良好的语义细节和真实感。我们的方法非常适合对稀疏三维视觉问题中固有的不确定性进行建模，因为它可以有效地生成不同的样本。我们的视图控制机制是通用的，甚至可以更改用户定义提示生成的图像中的相机视图。 et.al.|[2309.07986](http://arxiv.org/abs/2309.07986)|null|
|**2023-09-14**|**CoRF : Colorizing Radiance Fields using Knowledge Distillation**|基于神经辐射场（NeRF）的方法能够实现多视图图像的高质量新视图合成。本文提出了一种从输入的灰度多视图图像中合成彩色新视图的方法。当我们在生成的灰度级新视图上应用基于图像或视频的着色方法时，我们会观察到由于视图之间的不一致而产生的伪影。在彩色灰度图像序列上训练辐射场网络也不能解决3D一致性问题。我们提出了一种基于蒸馏的方法，将颜色知识从在自然图像上训练的着色网络转移到辐射场网络。具体来说，我们的方法使用辐射场网络作为3D表示，并从现有的2D着色方法中转移知识。实验结果表明，与基线相比，该方法在保持跨视图一致性的同时，为室内和室外场景生成了更好的彩色新视图。此外，我们展示了我们的方法在应用中的有效性，如从1.）红外（IR）多视图图像和2.）旧灰度多视图图像序列训练的辐射场网络的彩色化。 et.al.|[2309.07668](http://arxiv.org/abs/2309.07668)|null|
|**2023-09-13**|**Dynamic NeRFs for Soccer Scenes**|新颖视角合成这个长期存在的问题有很多应用，尤其是在体育广播中。特别是足球动作的逼真新颖视角合成，引起了广播业的极大兴趣。然而，只有少数几个工业解决方案被提出，甚至很少能达到合成回放的近广播质量。除了在操场周围设置多个静态摄像头外，最好的专有系统几乎没有透露任何关于其内部工作的信息。由于缺乏公共数据集，利用多个静态相机执行这样的任务确实是一个文献中很少解决的挑战：用小而快速的元素重建大规模的、主要是静态的环境。最近，神经辐射场的出现在许多新颖的视图合成应用中取得了惊人的进展，利用深度学习原理在最具挑战性的环境中产生逼真的结果。在这项工作中，我们研究了基于动态NeRF的任务解决方案的可行性，即旨在重建一般动态内容的神经模型。我们构建了合成足球环境，并使用它们进行了多项实验，确定了有助于用动态NeRF重建足球场景的关键组件。我们表明，尽管这种方法不能完全满足目标应用程序的质量要求，但它为实现成本效益高的自动解决方案提供了有希望的途径。我们还公开了我们的工作数据集和代码，目的是鼓励研究界进一步致力于动态足球场景的新颖视图合成任务。有关代码、数据和视频结果，请参阅https://soccernerfs.isach.be. et.al.|[2309.06802](http://arxiv.org/abs/2309.06802)|null|
|**2023-09-13**|**SAMPLING: Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image**|最近的新颖视图合成方法对于相对较小的场景（例如，室内环境和具有少数对象的场景）获得了有希望的结果，但对于具有单个图像作为输入的无边界室外场景往往失败。在本文中，我们介绍了SAMPLING，这是一种基于改进的多平面图像（MPI）的场景自适应分层多平面图像表示，用于从单个图像合成新视图。观察到无边界户外场景的深度分布变化很大，我们为MPI采用了自适应仓策略，根据每个场景图像排列平面。为了表示复杂的几何结构和多尺度细节，我们进一步引入了一个层次细化分支，它可以产生高质量的合成新视图。我们的方法在KITTI数据集上使用单个图像合成大规模无界户外场景时表现出了相当大的性能提升，并很好地推广到了看不见的Tanks和Temples数据集。代码和模型将很快提供。 et.al.|[2309.06323](http://arxiv.org/abs/2309.06323)|null|
|**2023-09-11**|**FlowIBR: Leveraging Pre-Training for Efficient Neural Image-Based Rendering of Dynamic Scenes**|我们介绍了一种用于动态场景的单目新颖视图合成的新方法。现有技术已经显示出令人印象深刻的渲染质量，但倾向于在不利用先验知识的情况下专注于单个场景内的优化。这种限制主要归因于缺乏可用于训练的动态场景数据集以及场景动力学的多样性。我们的方法FlowIBR通过集成基于神经图像的渲染方法来规避这些问题，该方法在广泛可用的静态场景的大型语料库上进行了预训练，并具有每个场景优化的场景流场。利用该流场，我们弯曲摄影机光线以抵消场景动力学，从而将动态场景呈现为渲染网络的静态场景。所提出的方法将每个场景的优化时间减少了一个数量级，实现了与现有方法相当的结果——所有这些都在单个消费级GPU上。 et.al.|[2309.05418](http://arxiv.org/abs/2309.05418)|null|
|**2023-09-11**|**Towards Viewpoint Robustness in Bird's Eye View Segmentation**|自动驾驶汽车（AV）要求用于感知的神经网络对不同的视点具有鲁棒性，如果它们要部署在许多类型的车辆上，而不需要为每种车辆重复数据收集和标记的成本。AV公司通常专注于从不同的场景和地点收集数据，但由于成本原因，不关注摄像机设备配置。因此，大多数震源组中只存在少量的钻机变体。在本文中，我们研究了AV感知模型如何受到摄像机视点变化的影响，并提出了一种在不重复数据收集和标记的情况下跨车辆类型缩放它们的方法。使用鸟瞰图（BEV）分割作为一项激励任务，我们通过大量实验发现，现有的感知模型对相机视点的变化非常敏感。当使用来自一个相机装备的数据进行训练时，在推断时相机的俯仰、偏航、深度或高度的微小变化会导致性能大幅下降。我们引入了一种新的视图合成技术，并使用它将收集的数据转换为目标钻机的视点，使我们能够为不同的目标钻机训练BEV分割模型，而无需任何额外的数据收集或标记成本。为了分析观点变化的影响，我们利用合成数据来缓解其他差距（内容、ISP等）。然后，我们的方法在真实数据上进行训练，并在合成数据上进行评估，从而能够对不同的目标钻机进行评估。我们发布所有数据以供未来工作使用。我们的方法能够回收部署到新钻机时损失的IoU的平均14.7%。 et.al.|[2309.05192](http://arxiv.org/abs/2309.05192)|null|
|**2023-09-10**|**SC-NeRF: Self-Correcting Neural Radiance Field with Sparse Views**|在最近的研究中，神经辐射场的泛化在新的视图合成任务中得到了广泛的探索。然而，现有的方法仅限于对象和室内场景。在这项工作中，我们将泛化任务扩展到户外场景，仅在对象级数据集上进行训练。这种方法提出了两个挑战。首先，训练和测试场景之间的显著分布变化导致渲染结果中出现黑色伪影。其次，室外场景中的视点变化会导致渲染图像中出现重影或区域丢失。为了应对这些挑战，我们提出了一个基于多头注意力机制的几何校正模块和外观校正模块。我们将渲染深度标准化，并将其与光方向组合，作为注意力机制中的查询。我们的网络有效地纠正了户外场景中不同的场景结构和几何特征，从物体层面很好地推广到看不见的户外场景。此外，我们使用外观校正模块来校正外观特征，防止由于视点更改而导致的渲染伪影，如空白边界和重影。通过结合这些模块，我们的方法成功地解决了户外场景泛化的挑战，产生了高质量的渲染结果。当在四个数据集（Blender、DTU、LLFF、Spaces）上进行评估时，我们的网络优于以前的方法。值得注意的是，与MVSNeRF相比，我们的网络将Spaces户外场景的平均PSNR从19.369提高到25.989，SSIM从0.838提高到0.889，并将LPIPS从0.265降低到0.224。 et.al.|[2309.05028](http://arxiv.org/abs/2309.05028)|null|
|**2023-09-14**|**SimpleNeRF: Regularizing Sparse Input Neural Radiance Fields with Simpler Solutions**|神经辐射场（NeRF）在场景的真实感自由视图渲染中表现出令人印象深刻的性能。然而，NeRF需要对给定场景中的图像进行密集采样，并且当只有稀疏的视图集可用时，其性能会显著下降。研究人员发现，监督NeRF估计的深度有助于用更少的视图有效地训练它。深度监督是使用经典方法或在大型数据集上预先训练的神经网络来获得的。前者可能只提供稀疏的监督，而后者可能存在泛化问题。与早期的方法不同，我们试图通过设计增强模型并将其与NeRF一起训练来学习深度监督。我们设计了增强模型，通过探索位置编码和视图相关辐射在训练少镜头NeRF中的作用，鼓励更简单的解决方案。由这些更简单的模型估计的深度用于监督NeRF深度估计。由于增强模型在某些区域可能不准确，我们设计了一种机制，只选择可靠的深度估计进行监督。最后，我们在NeRF的粗糙和精细多层感知器之间添加了一致性损失，以确保更好地利用分层采样。通过采用上述正则化，我们在两个流行的数据集上实现了最先进的视图合成性能。我们模型的源代码可以在我们的项目页面上找到：https://nagabhushansn95.github.io/publications/2023/SimpleNeRF.html et.al.|[2309.03955](http://arxiv.org/abs/2309.03955)|null|
|**2023-09-07**|**BluNF: Blueprint Neural Field**|神经辐射场（NeRF）彻底改变了场景新颖的视图合成，提供了视觉逼真、精确和稳健的隐式重建。虽然最近的方法允许NeRF编辑，例如对象删除、3D形状修改或材料特性操纵，但在这种编辑之前的手动注释使该过程变得乏味。此外，传统的2D交互工具缺乏对3D空间的准确感知，阻碍了对场景的精确操作和编辑。在本文中，我们介绍了一种新的方法，称为蓝图神经场（BluNF），以解决这些编辑问题。BluNF提供了一个强大且用户友好的2D蓝图，实现了直观的场景编辑。通过利用隐式神经表示，BluNF使用先前的语义和深度信息构建场景的蓝图。生成的蓝图可以轻松编辑和操作NeRF表示。我们通过直观的点击和更改机制展示了BluNF的可编辑性，实现了3D操作，如遮罩、外观修改和对象移除。我们的方法对视觉内容创作做出了重大贡献，为该领域的进一步研究铺平了道路。 et.al.|[2309.03933](http://arxiv.org/abs/2309.03933)|null|
|**2023-09-07**|**SyncDreamer: Generating Multiview-consistent Images from a Single-view Image**|在本文中，我们提出了一种新的扩散模型，称为，从单视图图像生成多视图一致图像。最近的工作Zero123使用预先训练的大规模2D扩散模型，展示了从物体的单视图图像生成看似新颖的视图的能力。然而，为生成的图像保持几何图形和颜色的一致性仍然是一个挑战。为了解决这个问题，我们提出了一种同步多视点扩散模型，该模型对多视点图像的联合概率分布进行建模，从而能够在单个反向过程中生成多视点一致图像。SyncDreamer通过3D感知特征注意力机制在反向过程的每一步同步所有生成图像的中间状态，该机制将不同视图中的相应特征关联起来。实验表明，SyncDreamer生成的图像在不同视图之间具有高度一致性，因此非常适合各种3D生成任务，如新颖的视图合成、文本到3D和图像到3D。 et.al.|[2309.03453](http://arxiv.org/abs/2309.03453)|null|

<p align=right>(<a href=#updated-on-20230918>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-09-15**|**Uncertainty-Aware Multi-View Visual Semantic Embedding**|图像文本检索的关键挑战是有效地利用语义信息来测量视觉和语言数据之间的相似性。然而，使用实例级二进制标签，即每个图像与单个文本配对，无法捕捉不同语义单元之间的多个对应关系，导致多模态语义理解的不确定性。尽管最近的研究通过更复杂的模型结构或预训练技术捕获了细粒度的信息，但很少有研究直接建模对应关系的不确定性，以充分利用二进制标签。为了解决这个问题，我们提出了一个不确定性感知的多视图视觉语义嵌入（UAMVSE）}框架，该框架将整个图像-文本匹配分解为多视图-文本匹配。我们的框架引入了一个不确定性感知损失函数（UALoss），通过自适应地建模每个视图文本对应关系中的不确定性来计算每个视图文本损失的权重。不同的权重引导模型关注不同的语义信息，增强了模型理解图像和文本对应关系的能力。我们还通过对相似度矩阵进行归一化，设计了一种优化的图像-文本匹配策略，以提高模型性能。在Flicker30k和MS-COCO数据集上的实验结果表明，UAMVSE的性能优于最先进的模型。 et.al.|[2309.08154](http://arxiv.org/abs/2309.08154)|null|
|**2023-09-14**|**High-fidelity 3D Reconstruction of Solar Coronal Physics with the Updated CROBAR Method**|我们提出了一种将冠状重建到B对齐区域（CROBAR）方法扩展到线性无力场（LFFF）外推的方法，并将其应用于AIA、MDI和STEREO EUVI数据集的重建。结果表明，CROBAR不仅可以重建日冕发射结构，而且可以通过LFFF的螺旋度 $\alpha$ 参数帮助约束日冕场外推。他们还提供了一个真实世界的例子，说明CROBAR如何轻松地从多个角度整合信息，以改进其重建，我们还使用其他角度来帮助验证重建。我们还谈到了使用真实世界的发射通带，而不是使用DEM的理想化幂律型通带。最后，我们将CROBAR产生的发射与观测到的发射以及基于理想DEM的幂律产生的发射进行了比较。这些结果进一步说明了CROBAR在现实世界应用中的前景，我们提供了该软件的初步版本供下载。 et.al.|[2309.08053](http://arxiv.org/abs/2309.08053)|null|
|**2023-09-14**|**Combining Multiple View Components for Exploratory Visualization**|结构化复杂数据的分析，如基于聚类图的数据集，通常应用各种视觉表示技术和格式。目前大多数可用的探索性可视化工具和方法都建立在集成方案之上，用于同时显示研究对象和过程的多个方面。通常，这种方案将由多个视图组成的屏幕空间进行分区，并采用交互模式来关注数据驱动的项目。众所周知的概念，如概述加细节和重点加上下文，在用技术术语解释时是模棱两可的。因此，UI设计从业者需要对图形表示模块的视觉合成的基本方法进行审查和分类。我们建议对视图和焦点的基本组成部分进行描述，并概述它们的多种组合。 et.al.|[2309.07580](http://arxiv.org/abs/2309.07580)|null|
|**2023-09-13**|**Exploiting Multiple Priors for Neural 3D Indoor Reconstruction**|神经隐式建模允许在小物体上实现令人印象深刻的3D重建结果，而在大型室内场景中表现出显著的局限性。在这项工作中，我们提出了一种新的神经隐式建模方法，该方法利用多种正则化策略来实现大型室内环境的更好重建，同时仅依赖于图像。稀疏但准确的深度先验用于将场景锚定到初始模型。还引入了密集但不太准确的深度先验，它足够灵活，仍然可以让模型偏离它，以改进估计的几何结构。然后，提出了一种新的自监督策略来正则化估计的曲面法线。最后，可学习的曝光补偿方案允许应对具有挑战性的照明条件。实验结果表明，我们的方法在具有挑战性的室内场景中产生了最先进的3D重建。 et.al.|[2309.07021](http://arxiv.org/abs/2309.07021)|null|
|**2023-09-12**|**Semantic and Articulated Pedestrian Sensing Onboard a Moving Vehicle**|由于车辆的大的向前运动，很难从车载采集的视频执行3D重建。与标准基准相比，即使是物体检测和人体感应模型在板载视频上的表现也明显较差，因为与标准物体检测基准相比，物体经常出现在远离相机的地方，图像质量经常因运动模糊而降低，并且经常发生遮挡。这导致了交通数据特定基准的普及。最近，光探测和测距（LiDAR）传感器已经变得流行起来，可以直接估计深度，而无需执行3D重建。然而，与基于图像的方法相比，基于激光雷达的方法仍然缺乏远距离的关节式人体检测。我们假设，从激光雷达数据中针对关节式人体感知的基准可以增加对交通中人体感知和预测的研究，并可以改善行人的交通安全。 et.al.|[2309.06313](http://arxiv.org/abs/2309.06313)|null|
|**2023-09-12**|**SoccerNet 2023 Challenges Results**|SoccerNet 2023挑战赛是SoccerNet团队组织的第三届年度视频理解挑战赛。在第三版中，挑战由七项基于愿景的任务组成，分为三个主题。第一个主题，广播视频理解，由三个与描述视频广播中发生的事件相关的高级任务组成：（1）动作识别，专注于检索与足球全局动作相关的所有时间戳，专注于用自然语言和锚定时间戳描述广播。第二个主题，场理解，涉及（4）相机校准的单一任务，重点是从图像中检索内在和外在的相机参数。第三个也是最后一个主题，球员理解，由三个与提取球员信息相关的低级任务组成：（5）重新识别，重点是在多个视图中检索相同的球员，（6）多对象跟踪，重点是通过未经编辑的视频流跟踪球员和球，以及（7）球衣号码识别，专注于从tracklets中识别球员的球衣号码。与以前版本的SoccerNet挑战相比，任务（2-3-7）是新颖的，包括新的注释和数据，任务（4）用更多的数据和注释进行了增强，任务（6）现在专注于端到端方法。有关任务、挑战和排行榜的更多信息，请访问https://www.soccer-net.org.基线和开发工具包可在https://github.com/SoccerNet. et.al.|[2309.06006](http://arxiv.org/abs/2309.06006)|**[link](https://github.com/lRomul/ball-action-spotting)**|
|**2023-09-11**|**A survey on real-time 3D scene reconstruction with SLAM methods in embedded systems**|同时定位和映射（SLAM）的3D重建是无人机、服务机器人和移动AR/VR设备等运输系统领域的一个重要课题。与点云表示相比，基于网格和体素的3D重建对于高级功能特别有用，如避障或与物理环境的交互。本文介绍了在资源受限的硬件平台上实现基于视觉的三维场景重建流水线。实时性能、内存管理和低功耗对嵌入式系统至关重要。描述了从传感器到3D重建的传统SLAM管道，包括深度学习的潜在用途。详细介绍了在资源有限的情况下执行高级功能的情况。最近的系统提出了具有不同粒度的3D重建方法的嵌入式实现。实时定位和重建所需的精度和资源消耗之间的权衡是本文确定和讨论的开放研究问题之一。 et.al.|[2309.05349](http://arxiv.org/abs/2309.05349)|null|
|**2023-09-09**|**Cryo-Electron Ptychography: Applications and Potential in Biological Characterisation**|显然需要发展表征技术，提供生物学中结构-功能关系的详细信息。使用电子显微镜在保持宽视场的同时实现高分辨率仍然是一个挑战，特别是对于辐射敏感样品，其中保持结构完整性所需的信噪比受到低电子注量的限制。在这篇综述中，我们探索了低温电子ptychography作为一种在低通量条件下表征生物系统的替代方法的潜力。使用这种方法，增加了来自多个感兴趣采样区域的信息含量，有可能使用比传统冷冻电子显微镜所需更少的粒子进行3D重建。这对于难以获得均匀单粒子分布的系统实现更高的分辨率是重要的。我们讨论了这种方法在单粒子分析和异构大型物体应用中的进展、局限性和未来发展的潜在领域。 et.al.|[2309.04881](http://arxiv.org/abs/2309.04881)|null|
|**2023-09-07**|**A Food Package Recognition and Sorting System Based on Structured Light and Deep Learning**|基于视觉算法的机械臂抓取系统是一种可以应用于各种场景的机械臂系统。它使用算法自动识别目标的位置，并引导机械臂抓取目标，这比可教的机械臂抓取系统具有更灵活的特点。然而，对于一些食品包装来说，其透明包装或反射材料给视觉算法的识别带来了挑战，传统的视觉算法无法实现这些包装的高精度。此外，在机械臂抓取过程中，在z轴高度上的定位仍然需要手动设置参数，这可能会导致错误。基于上述两个问题，我们使用深度学习算法和结构光三维重建技术设计了一个食品包装分拣系统。使用预先训练好的MASK-R-CNN模型识别图像中物体的类别并获得其二维坐标，然后使用结构光三维重建技术计算其三维坐标，最后经过坐标系转换来引导机械臂进行抓取。经过测试表明，该方法可以实现对不同种类食品包装的全自动识别和抓取，具有较高的精度。使用这种方法，可以帮助食品制造商降低生产成本，提高生产效率。 et.al.|[2309.03704](http://arxiv.org/abs/2309.03704)|null|
|**2023-09-06**|**SADIR: Shape-Aware Diffusion Models for 3D Image Reconstruction**|从有限数量的2D图像重建3D图像一直是计算机视觉和图像分析中的一个长期挑战。虽然基于深度学习的方法在这一领域取得了令人印象深刻的性能，但现有的深度网络往往无法有效利用图像中呈现的对象的形状结构。因此，重建对象的拓扑结构可能无法很好地保存，导致不同部分之间存在诸如不连续性、孔洞或不匹配连接之类的伪影。在本文中，我们提出了一种基于扩散模型的三维图像重建形状感知网络，称为SADIR，以解决这些问题。与之前主要依赖图像强度的空间相关性进行3D重建的方法不同，我们的模型利用从训练数据中学习的形状先验来指导重建过程。为了实现这一点，我们开发了一个联合学习网络，该网络可以同时学习变形模型下的平均形状。然后，每个重建的图像被认为是平均形状的变形变体。我们在大脑和心脏磁共振成像（MRI）上验证了我们的模型SADIR。实验结果表明，我们的方法优于基线，具有更低的重建误差和更好地保留图像中物体的形状结构。 et.al.|[2309.03335](http://arxiv.org/abs/2309.03335)|null|

<p align=right>(<a href=#updated-on-20230918>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-09-15**|**Projected Langevin dynamics and a gradient flow for entropic optimal transport**|经典的（过阻尼的）Langevin动力学提供了一种从其不变测度采样的自然算法，该算法在概率测度空间上唯一地最小化能量函数，并且当噪声参数小时，该算法集中在相关电势的最小化器周围。我们引入了类似的扩散动力学，该扩散动力学从熵正则化的最优输运中采样，该输运唯一地最小化相同的能量泛函，但约束于 $\mathbb｛R｝^d$上两个给定边际概率测度$\mu$和$\nu$的耦合的集合$\Pi（\mu，\nu）$，并且集中在小正则化参数的最优输送耦合周围。更具体地说，我们的过程满足两个关键性质：首先，如果解在$\Pi（\mu，\nu）$中初始化，则解的定律在每次都保持在$\Pi$中。其次，长期极限是熵最优运输问题的唯一解。此外，我们通过一个新的log-Sobolev型不等式证明，对于足够大的正则化参数和一类严格包括所有强log-凹测度的边值，收敛性保持指数快速。通过研究子流形$\Pi（\mu，\nu）$的诱导Wasserstein几何，我们认为SDE可以被视为耦合空间上的Wasserstein梯度流，至少当$d=1$时是这样，并且我们确定了$d\ge2$的推测梯度流。主要的技术困难源于条件期望项的出现，这些条件期望项用于将动力学约束为$\Pi（\mu，\nu）$ 。 et.al.|[2309.08598](http://arxiv.org/abs/2309.08598)|null|
|**2023-09-15**|**Confirmation of an anomalously low dark matter content for the galaxy NGC1052-DF4 from deep, high resolution continuum spectroscopy**|NGC1052-DF4被发现是NGC1052星系群中第二个“缺乏暗物质的星系”，根据其七个球状星团的径向速度测量，其速度色散为 $\sigma_{\rm-gc}=4.2^{+4.4}_{-2.2}$km/s。在这里，我们通过测量星系的恒星速度色散来验证这一结果。我们用Keck宇宙网络成像仪（KCWI）在NGC1052-DF4中观察到了漫射恒星光，其最高分辨率模式为$\sigma_｛\mathrm｛instr｝｝约为7$km/s。科学+天空总曝光时间为34小时，由此产生的光谱在其光谱分辨率和23\r｛a｝$^｛-1｝$的S/N比方面都是非凡的。我们发现$\sima_｛\rm stars｝=8.0^｛+2.3｝_｛-1.9｝$km/s的恒星速度色散，与之前从球状星团中测量到的一致。将这两种测量结果相结合，可得出$\sigma_｛\rm f｝=6.3_｛-1.6｝^｛+2.5｝$km/s的基准离散度。半光半径内的隐含动力学质量为$8_｛-4｝^｛+6｝\乘以10^7 M_｛odot｝$。NGC1052-DF4仅从恒星质量出发的预期速度色散为$7\pm 1$km/s，对于遵循恒星质量-晕质量关系和晕质量-浓度关系的NFW晕，预期为$\sim 30$ km/s。低速色散排除了正常的NFW暗物质晕，我们证实NGC1052-DF4是NGC1052星系群中至少两个暗物质含量异常低的星系之一。虽然任何可行的星系形成模型都应该解释这两个星系的性质，但我们注意到NGC1052-DF4现在面临着最大的挑战，因为它对其动力学质量有着最严格的约束。 et.al.|[2309.08592](http://arxiv.org/abs/2309.08592)|null|
|**2023-09-15**|**Compositional Foundation Models for Hierarchical Planning**|为了在具有长期目标的新环境中做出有效的决策，在空间和时间尺度上进行分层推理至关重要。这需要规划抽象的子目标序列，对基本计划进行视觉推理，并通过视觉运动控制根据设计的计划执行行动。我们提出了分层规划的组合基础模型（HiP），这是一种基础模型，它利用在语言、视觉和动作数据上单独训练的多个专家基础模型，共同解决长期任务。我们使用大型语言模型通过大型视频扩散模型构建基于环境的符号计划。生成的视频计划随后通过反向动力学模型基于视觉运动控制，该模型从生成的视频中推断动作。为了在这个层次结构中实现有效的推理，我们通过迭代精化来加强模型之间的一致性。我们展示了我们的方法在三种不同的长期桌面操作任务中的有效性和适应性。 et.al.|[2309.08587](http://arxiv.org/abs/2309.08587)|null|
|**2023-09-15**|**Norm Growth, Non-uniqueness, and Anomalous Dissipation in Passive Scalars**|我们构造了一个无散度速度场 $u:[0，T]\times\mathbb｛T｝^2到\mathbb｛R｝^2$，满足C^\infty（[0，T]；C^\alpha（\mathbb{T｝^ 2））\quad\forall\alpha\[0,1）$$，使得对应的漂移-扩散方程对于每个光滑的初始数据都表现出异常耗散。我们还证明，给定任何$\alpha_0<1$，可以修改流，使其仅在$C^｛\alpha:0｝（\mathbb｛T｝^2）$中一致有界，并且解的正则性满足sharp（时间积分）Obukhov-Corrsin理论预测的边界。该证明基于一个一般原则，该原则意味着运输方程的所有解都有$H^1$ 的增长，这可能具有独立的意义。 et.al.|[2309.08576](http://arxiv.org/abs/2309.08576)|null|
|**2023-09-15**|**Denoising Diffusion Probabilistic Models for Hardware-Impaired Communications**|由于深度生成模型（如生成预训练变换器（GPT）和扩散模型）取得的卓越成果，生成人工智能在一系列不同的工业和学术领域中受到了极大的关注。在本文中，我们探讨了在硬件损伤（HWI）、低信噪比状态和量化误差等实际假设下，去噪扩散概率模型（DDPM）在无线通信系统中的应用。扩散模型是一类最先进的生成模型，在OpenAI和Google Brain的一些流行例子中已经取得了显著的成功。DDPM背后的直觉是将数据生成过程分解为小的“去噪”步骤。受此启发，我们建议将基于去噪扩散模型的接收器用于实际的无线通信方案，同时在低SNR状态、非高斯噪声、不同HWI水平和量化误差下提供网络弹性。我们根据误码率（BER）和均方误差（MSE）来评估我们的方案的重建性能。我们的结果表明，在AWGN和非高斯场景中，与基于深度神经网络（DNN）的接收机相比，BER分别可以提高30%和20%。 et.al.|[2309.08568](http://arxiv.org/abs/2309.08568)|null|
|**2023-09-15**|**Breathing New Life into 3D Assets with Generative Repainting**|基于扩散的文本到图像模型引发了视觉社区、艺术家和内容创作者的巨大关注。这些模型的广泛采用是由于世代质量的显著提高以及对各种模式的有效调节，而不仅仅是文本。然而，将这些2D模型的丰富生成先验提升到3D中是具有挑战性的。最近的工作提出了由扩散模型和神经场的纠缠提供动力的各种管道。我们探索了预训练的2D扩散模型和标准3D神经辐射场作为独立工具的威力，并展示了它们以非学习方式协同工作的能力。这种模块化具有易于部分升级的内在优势，这在这样一个快节奏的领域中成为了一个重要的特性。我们的管道接受任何遗留的可渲染几何体，如纹理或无纹理网格，协调2D生成细化和3D一致性强制工具之间的交互，并以多种格式输出绘制的输入几何体。我们对ShapeNetSem数据集中的广泛对象和类别进行了大规模研究，并从定性和定量两个方面展示了我们方法的优势。项目页面：https://www.obukhov.ai/repainting_3d_assets et.al.|[2309.08523](http://arxiv.org/abs/2309.08523)|**[link](https://github.com/toshas/remesh_isotropic_planar)**|
|**2023-09-15**|**Generalised Probabilistic Diffusion Scale-Spaces**|概率扩散模型擅长从学习的分布中采样新图像。最初受物理学中漂移扩散概念的启发，他们在前向过程中应用图像扰动，如噪声和模糊，从而产生可处理的概率分布。相应的学习反向过程生成图像，并且可以以辅助信息为条件，这导致了各种各样的实际应用。目前，大多数研究重点都集中在面向实践的扩展上。相比之下，理论背景在很大程度上仍未被探索，特别是与漂移扩散的关系。为了阐明这些与经典图像滤波的联系，我们提出了概率扩散模型的广义尺度空间理论。此外，我们展示了与扩散和渗透过滤器的概念和经验联系。 et.al.|[2309.08511](http://arxiv.org/abs/2309.08511)|null|
|**2023-09-15**|**Diffuse-illumination holographic optical coherence tomography**|全息光学相干断层扫描（OCT）是一种强大的成像技术，但其揭示低反射率特征的能力有限。在这项研究中，我们通过非相干平均体积进行了全息OCT，数值孔径（NA）的漫射照明变化等于检测NA。虽然单散射光的散斑减少幅度不大，但我们发现多散射光的斑点可以任意减少，从而显著提高了图像质量。该技术还提供了抑制由空间相干引起的噪声的优点，并且可以用部分空间非相干光源来实现，以进一步减轻多重散射。最后，我们表明，尽管全息重建能力随着空间相干性的降低而越来越丧失，但它们可以在足以满足标准OCT应用的轴向范围内保留。 et.al.|[2309.08486](http://arxiv.org/abs/2309.08486)|null|
|**2023-09-15**|**Isotropic active colloids: explicit vs. implicit descriptions of propulsion mechanisms**|对活性粒子之间的耦合进行建模往往忽略了控制推进机制的可能的多体效应。考虑到这种影响，需要对活动起源处的分子细节进行明确的建模。在这里，我们利用了最近各向同性活性粒子的二维模型，其推进源于浴中溶质粒子之间的相互作用。胶体在其附近催化化学反应，导致溶质颗粒的局部相分离，溶质颗粒的密度波动导致胶体的扩散增强。在本文中，我们使用（i）显式模型研究了这种活性颗粒的组装，其中考虑了溶质颗粒的微观动力学；和（ii）隐式模型，其参数是在无限稀释时从显式模型推断的。在显式溶质模型中，活性胶体的有效扩散系数随着密度的增加而强烈降低，这一效应在推导的隐式模型中没有得到体现。这表明，通常将对相互作用与活性解耦的经典模型无法描述由溶质-溶质相互作用驱动的活性胶体系统中的集体动力学。 et.al.|[2309.08455](http://arxiv.org/abs/2309.08455)|null|
|**2023-09-15**|**Fractional Advection Diffusion Asymmetry Equation, derivation, solution and application**|非马尔可夫连续时间随机行走模型是一个研究得很好的异常扩散模型，它具有胖尾等待时间和非零均值的窄分布位移。使用分析方法，我们最近证明了分数空间平流-扩散不对称方程（通常与马尔可夫L’evy飞行有关）如何描述粒子包的扩散。由于我们通过等待时间的胖尾分布使用高斯统计来计算跳跃长度，因此动力学方程中分数空间导数的出现需要在本文中进行解释。作为应用，我们分析了示踪剂的二维扩散，在水文污染扩散领域研究的突破曲线和首次通过时间统计。我们提出了一种适用于平均等待时间有限且方差发散的情况的隶属方案，该方案与过程中续订次数的L’evy统计有关。 et.al.|[2309.08391](http://arxiv.org/abs/2309.08391)|null|

<p align=right>(<a href=#updated-on-20230918>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-09-15**|**Breathing New Life into 3D Assets with Generative Repainting**|基于扩散的文本到图像模型引发了视觉社区、艺术家和内容创作者的巨大关注。这些模型的广泛采用是由于世代质量的显著提高以及对各种模式的有效调节，而不仅仅是文本。然而，将这些2D模型的丰富生成先验提升到3D中是具有挑战性的。最近的工作提出了由扩散模型和神经场的纠缠提供动力的各种管道。我们探索了预训练的2D扩散模型和标准3D神经辐射场作为独立工具的威力，并展示了它们以非学习方式协同工作的能力。这种模块化具有易于部分升级的内在优势，这在这样一个快节奏的领域中成为了一个重要的特性。我们的管道接受任何遗留的可渲染几何体，如纹理或无纹理网格，协调2D生成细化和3D一致性强制工具之间的交互，并以多种格式输出绘制的输入几何体。我们对ShapeNetSem数据集中的广泛对象和类别进行了大规模研究，并从定性和定量两个方面展示了我们方法的优势。项目页面：https://www.obukhov.ai/repainting_3d_assets et.al.|[2309.08523](http://arxiv.org/abs/2309.08523)|**[link](https://github.com/toshas/remesh_isotropic_planar)**|
|**2023-09-14**|**Neural Field Representations of Articulated Objects for Robotic Manipulation Planning**|传统的操作规划方法依赖于环境的显式几何模型来将给定任务公式化为优化问题。然而，从原始传感器输入推断准确的模型本身就是一个难题，尤其是对于铰接物体（例如壁橱、抽屉）。在本文中，我们提出了一种关节对象的神经场表示（NFR），可以直接从图像中进行操作规划。具体来说，在拍摄了一个新的关节物体的几张照片后，我们可以向前模拟它可能的运动，因此，可以直接使用该神经模型进行轨迹优化规划。此外，这种表示可以用于形状重建、语义分割和图像渲染，这在训练和泛化过程中提供了强大的监督信号。我们表明，我们的模型仅在合成图像上训练，能够在模拟和真实图像中为同类看不见的物体提取有意义的表示。此外，我们证明了该表示能够直接从图像中对现实世界中的关节物体进行机器人操作。 et.al.|[2309.07620](http://arxiv.org/abs/2309.07620)|null|
|**2023-09-13**|**Generalizable Neural Fields as Partially Observed Neural Processes**|神经场将信号表示为由神经网络参数化的函数，是传统离散矢量或基于网格的表示的一种很有前途的替代方案。与离散表示相比，神经表示既能很好地扩展分辨率，又是连续的，并且可以是多次可微的。然而，给定我们想要表示的信号数据集，必须为每个信号优化单独的神经场是低效的，并且不能利用信号之间的共享信息或结构。现有的泛化方法将其视为元学习问题，并采用基于梯度的元学习来学习初始化，然后通过测试时间优化对初始化进行微调，或者学习超网络来产生神经场的权重。相反，我们提出了一种新的范式，将神经表征的大规模训练视为部分观察到的神经过程框架的一部分，并利用神经过程算法来解决这一任务。我们证明，这种方法优于最先进的基于梯度的元学习方法和超网络方法。 et.al.|[2309.06660](http://arxiv.org/abs/2309.06660)|null|
|**2023-09-08**|**Single View Refractive Index Tomography with Neural Fields**|折射率层析成像是一个反问题，我们试图从2D投影图像测量中重建场景的3D折射场。折射场本身是不可见的，而是影响光线在空间中传播时路径的连续弯曲。折射场出现在各种各样的科学应用中，从显微镜中的半透明细胞样本到弯曲来自遥远星系的光的暗物质场。这个问题带来了一个独特的挑战，因为折射场直接影响光的路径，使其恢复成为一个非线性问题。此外，与传统的层析成像相比，我们试图通过利用散射在整个介质中的光源的知识，仅从单个视点使用投影图像来恢复折射场。在这项工作中，我们介绍了一种使用基于坐标的神经网络对场景中潜在的连续折射场进行建模的方法。然后，我们使用射线三维空间曲率的显式建模来优化该网络的参数，通过综合分析方法重建折射场。通过在模拟中恢复折射场，并分析光源分布对恢复的影响，证明了我们方法的有效性。然后，我们在模拟暗物质映射问题上测试了我们的方法，在该问题中，我们恢复了真实模拟暗物质分布下的折射场。 et.al.|[2309.04437](http://arxiv.org/abs/2309.04437)|null|
|**2023-09-07**|**BluNF: Blueprint Neural Field**|神经辐射场（NeRF）彻底改变了场景新颖的视图合成，提供了视觉逼真、精确和稳健的隐式重建。虽然最近的方法允许NeRF编辑，例如对象删除、3D形状修改或材料特性操纵，但在这种编辑之前的手动注释使该过程变得乏味。此外，传统的2D交互工具缺乏对3D空间的准确感知，阻碍了对场景的精确操作和编辑。在本文中，我们介绍了一种新的方法，称为蓝图神经场（BluNF），以解决这些编辑问题。BluNF提供了一个强大且用户友好的2D蓝图，实现了直观的场景编辑。通过利用隐式神经表示，BluNF使用先前的语义和深度信息构建场景的蓝图。生成的蓝图可以轻松编辑和操作NeRF表示。我们通过直观的点击和更改机制展示了BluNF的可编辑性，实现了3D操作，如遮罩、外观修改和对象移除。我们的方法对视觉内容创作做出了重大贡献，为该领域的进一步研究铺平了道路。 et.al.|[2309.03933](http://arxiv.org/abs/2309.03933)|null|
|**2023-09-07**|**SimNP: Learning Self-Similarity Priors Between Neural Points**|用于3D对象重建的现有神经场表示要么（1）利用对象级表示，但由于对全局潜在代码的限制而遭受低质量细节，要么（2）能够完美地重建观测，但未能利用对象级先验知识来推断未观察到的区域。我们提出了一种学习类别级自相似性的方法SimNP，它通过将神经点辐射场与类别级自类似性表示相连接，结合了两个世界的优点。我们的贡献是双重的。（1） 我们利用相干点云的概念设计了第一个类别级别的神经点表示。由此产生的神经点辐射场为局部支持的对象区域存储了高级别的细节。（2） 我们了解了如何以无约束和无监督的方式在神经点之间共享信息，这允许在重建过程中根据给定的观测值导出对象的未观察区域。我们表明，SimNP在重建对称的看不见物体区域方面优于以前的方法，超过了建立在类别级或像素对齐辐射场上的方法，同时提供了实例之间的语义对应 et.al.|[2309.03809](http://arxiv.org/abs/2309.03809)|null|
|**2023-09-06**|**CoNeS: Conditional neural fields with shift modulation for multi-sequence MRI translation**|多序列磁共振成像（MRI）在现代临床研究和深度学习研究中都有广泛的应用。然而，在临床实践中，由于患者的不同图像采集协议或造影剂禁忌症，经常会出现一个或多个MRI序列缺失的情况，这限制了在多序列数据上训练的深度学习模型的使用。一种很有前途的方法是利用生成模型来合成缺失的序列，这可以作为替代获取。解决这一问题的最先进方法是基于卷积神经网络（CNN），该网络通常存在频谱偏差，导致高频精细细节的重建较差。在本文中，我们提出了具有移位调制的条件神经场（CoNeS），这是一种以体素坐标为输入并学习用于多序列MRI平移的目标图像的表示的模型。所提出的模型使用多层感知器（MLP）代替CNN作为像素到像素映射的解码器。因此，每个目标图像被表示为神经场，该神经场通过利用学习的潜码的移位调制而被调节在源图像上。在BraTS 2018和前庭神经鞘瘤患者的内部临床数据集上进行的实验表明，所提出的方法在视觉和定量上都优于最先进的多序列MRI翻译方法。此外，我们进行了光谱分析，表明CoNeS能够克服传统CNN模型中常见的光谱偏差问题。为了进一步评估合成图像在临床下游任务中的使用，我们在推理时使用合成图像测试了分割网络。 et.al.|[2309.03320](http://arxiv.org/abs/2309.03320)|**[link](https://github.com/cyjdswx/cones)**|
|**2023-09-06**|**ResFields: Residual Neural Fields for Spatiotemporal Signals**|神经场是一类被训练来表示高频信号的神经网络，近年来由于其在复杂三维数据建模方面的出色性能，特别是通过单个多层感知器（MLP）的大神经符号距离（SDFs）或辐射场（NeRFs），而受到了极大的关注。然而，尽管用MLP表示信号的能力和简单性很强，但由于MLP的容量有限，这些方法在建模大而复杂的时间信号时仍然面临挑战。在本文中，我们提出了一种有效的方法来解决这一限制，将时间残差层纳入神经场，称为ResFields，这是一类专门设计用于有效表示复杂时间信号的新型网络。我们对ResFields的性质进行了全面的分析，并提出了一种矩阵分解技术来减少可训练参数的数量并增强泛化能力。重要的是，我们的公式与现有技术无缝集成，并在各种具有挑战性的任务中持续改进结果：2D视频近似、通过时间SDF的动态形状建模和动态NeRF重建。最后，我们通过展示ResFields在从轻量级捕捉系统的稀疏感官输入捕捉动态3D场景方面的有效性，展示了它的实用性。 et.al.|[2309.03160](http://arxiv.org/abs/2309.03160)|**[link](https://github.com/markomih/ResFields)**|
|**2023-09-01**|**GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields**|开发能够在非结构化现实世界环境中通过视觉观察执行各种操作任务的代理是机器人技术中的一个长期问题。为了实现这一目标，机器人需要对场景的3D结构和语义有全面的了解。在这项工作中，我们提出了 $\textbf｛GNFactor｝$，一种用于多任务机器人操作的视觉行为克隆代理，具有$\textbf｛G｝$通用$\textbf｛N｝$eural功能$\textbf｛F｝$字段。GNFactor联合优化了作为重建模块的可推广神经场（GNF）和作为决策模块的感知转换器，利用了共享的深度3D体素表示。为了在3D中结合语义，重建模块利用视觉语言基础模型（$\textit｛例如｝$ ，Stable Diffusion）将丰富的语义信息提取到深度3D体素中。我们在3个真实机器人任务中评估了GNFactor，并在10个RLBench任务中进行了详细的消融，演示次数有限。我们观察到GNFactor在可见和不可见任务中比当前最先进的方法有了实质性的改进，证明了GNFactor强大的泛化能力。我们的项目网站是https://yanjieze.com/GNFactor/。 et.al.|[2308.16891](http://arxiv.org/abs/2308.16891)|**[link](https://github.com/YanjieZe/GNFactor)**|
|**2023-08-30**|**Active Neural Mapping**|我们用不断学习的神经场景表示来解决主动映射的问题，即主动神经映射。关键在于通过有效的代理移动积极找到要探索的目标空间，从而最大限度地减少在以前看不见的环境中飞行中的地图不确定性。在本文中，我们检验了连续学习神经场的权重空间，并从经验上表明，神经变异性，即对随机权重扰动的预测鲁棒性，可以直接用于测量神经映射的瞬时不确定性。结合神经映射中继承的连续几何信息，可以引导agent找到一条可遍历的路径，以逐渐获得环境知识。我们首次提出了一种用于在线场景重建的具有基于坐标的隐式神经表示的主动映射系统。在视觉逼真的Gibson和Matterport3D环境中的实验证明了所提出方法的有效性。 et.al.|[2308.16246](http://arxiv.org/abs/2308.16246)|null|

<p align=right>(<a href=#updated-on-20230918>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

