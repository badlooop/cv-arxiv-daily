[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.03.28
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-03-27**|**MetaCap: Meta-learning Priors from Multi-View Imagery for Sparse-view Human Performance Capture and Rendering**|在视觉和图形学中，从稀疏的RGB观测中获取真实的人类性能和自由视图渲染是一个长期存在的问题。主要挑战是缺乏观察和环境的固有模糊性，例如遮挡和深度模糊。因此，辐射场在密集设置中捕捉高频外观和几何细节方面显示出巨大的前景，na时表现不佳\“在稀疏摄像机视图上对其进行有效监督，因为场只是过度适应稀疏视图输入。为了解决这一问题，我们提出了MetaCap，这是一种在人类非常稀疏甚至单个视图的情况下进行高效高质量几何恢复和新视图合成的方法。我们的关键思想是仅从潜在的稀疏多视图视频中元学习辐射场权重，这可以作为在描绘人类的稀疏图像上微调辐射场权重的先验。这种先验提供了良好的网络权重初始化，从而有效地解决稀疏视图捕获中的模糊性。由于人体的关节结构和运动引起的表面变形，学习这种先验是不容易的。因此，我们建议在姿势规范化空间中元学习场权重。”，这减少了空间特征范围，使特征学习更加有效。因此，人们可以微调我们的场参数，以快速推广到看不见的姿势，即我们ll作为新颖且稀疏（甚至是单目）的相机视图。为了在不同的场景下评估我们的方法，我们收集了一个新的数据集WildDynaCap，其中包含在密集摄像机圆顶和野生稀疏摄像机平台中拍摄的受试者，并在公共和WildDynaCap数据集上展示了与最新最先进的方法相比优越的结果。 et.al.|[2403.18820](http://arxiv.org/abs/2403.18820)|null|
|**2024-03-27**|**SplatFace: Gaussian Splat Face Reconstruction Leveraging an Optimizable Surface**|我们提出了SplatFace，这是一种新的高斯飞溅框架，用于三维人脸重建，而不依赖于精确的预定几何结构。我们的方法旨在同时提供高质量的新颖视图渲染和精确的3D网格重建。我们结合了一个通用的3D变形模型（3DMM）来提供表面几何结构，从而可以用有限的一组输入图像重建人脸。我们引入了一种联合优化策略，该策略通过协同的非刚性对齐过程来细化高斯曲面和可变形曲面。提出了一种新的距离度量，即飞溅到表面，通过考虑高斯位置和协方差来改进对准。表面信息还被用于结合世界空间致密化过程，从而获得卓越的重建质量。我们的实验分析表明，在生成具有高几何精度的三维人脸网格方面，所提出的方法在新的视图合成中与其他高斯飞溅技术和其他三维重建方法都具有竞争力。 et.al.|[2403.18784](http://arxiv.org/abs/2403.18784)|null|
|**2024-03-27**|**Modeling uncertainty for Gaussian Splatting**|我们提出了随机高斯散射（SGS）：第一个使用高斯散射（GS）进行不确定性估计的框架。GS最近以神经辐射场（NeRF）的一小部分计算成本实现了令人印象深刻的重建质量，从而推进了新的视图合成领域。然而，与后者相反，它仍然缺乏提供与产出相关的置信度信息的能力。为了解决这一局限性，在本文中，我们引入了一种基于变分推理的方法，该方法将不确定性预测无缝集成到GS的公共渲染管道中。此外，我们引入稀疏误差下面积（AUSE）作为损失函数中的一个新项，从而能够在图像重建的同时优化不确定性估计。在LLFF数据集上的实验结果表明，我们的方法在图像渲染质量和不确定性估计精度方面都优于现有方法。总的来说，我们的框架为从业者提供了对合成视图可靠性的宝贵见解，有助于在现实世界的应用程序中进行更安全的决策。 et.al.|[2403.18476](http://arxiv.org/abs/2403.18476)|null|
|**2024-03-26**|**2D Gaussian Splatting for Geometrically Accurate Radiance Fields**|3D高斯散射（3DGS）最近彻底改变了辐射场重建，实现了高质量的新颖视图合成和快速的无烘焙渲染速度。然而，由于3D高斯的多视图不一致性，3DGS无法准确地表示曲面。我们提出了二维高斯散射（2DGS），这是一种从多视图图像中建模和重建几何精确辐射场的新方法。我们的关键思想是将三维体积压缩为一组二维平面高斯圆盘。与3D高斯模型不同，2D高斯模型在对曲面进行本质建模的同时，提供了视图一致的几何图形。为了准确地恢复薄表面并实现稳定的优化，我们引入了一种利用射线散射相交和光栅化的透视精确二维散射过程。此外，我们结合了深度失真和法线一致性项，以进一步提高重建的质量。我们证明，我们的可微分渲染器允许无噪声和详细的几何重建，同时保持有竞争力的外观质量、快速训练速度和实时渲染。我们的代码将公开。 et.al.|[2403.17888](http://arxiv.org/abs/2403.17888)|null|
|**2024-03-26**|**DN-Splatter: Depth and Normal Priors for Gaussian Splatting and Meshing**|3D高斯飞溅是一种新的可微分绘制技术，以高的绘制速度和相对较低的训练时间获得了最先进的新视图合成结果。然而，由于优化过程中缺乏几何约束，它在室内数据集中常见的场景上的性能较差。我们扩展了具有深度和法线线索的3D高斯飞溅，以应对具有挑战性的室内数据集，并展示了高效网格提取技术，这是一个重要的下游应用。具体来说，我们用深度信息正则化优化过程，增强附近高斯的局部平滑性，并使用由法线线索监督的3D高斯的几何结构来实现与真实场景几何结构的更好对齐。我们在基线上改进了深度估计和新的视图合成结果，并展示了如何使用这种简单而有效的正则化技术直接从高斯表示中提取网格，从而在室内场景上产生更精确的物理重建。我们的代码将于发布https://github.com/maturk/dn-splatter. et.al.|[2403.17822](http://arxiv.org/abs/2403.17822)|null|
|**2024-03-26**|**Learning with Unreliability: Fast Few-shot Voxel Radiance Fields with Relative Geometric Consistency**|我们提出了一种基于体素的优化框架ReVoRF，用于少镜头辐射场，从战略上解决了伪新视图合成中的不可靠性问题。我们的方法基于这样一个观点，即相邻区域内的相对深度关系比未遮挡区域中的绝对颜色值更可靠。因此，我们设计了一种双边几何一致性损失，在不确定区域的深度一致性的背景下，谨慎地处理颜色保真度和几何精度之间的权衡。此外，我们提出了一种可靠性引导的学习策略，以识别和利用合成视图中的可变质量，并辅以可靠性感知的体素平滑算法，该算法可以平滑可靠和不可靠数据块之间的转换。我们的方法允许对所有可用数据进行更细致的使用，促进从以前被认为不适合高质量重建的地区加强学习。在不同数据集上进行的大量实验表明，我们的方法在效率和准确性方面取得了显著的提高，提供了3 FPS、7分钟的渲染速度来训练一个360美元的场景，并且与现有的少镜头方法相比，PSNR提高了5%。代码位于https://github.com/HKCLynn/ReVoRF. et.al.|[2403.17638](http://arxiv.org/abs/2403.17638)|null|
|**2024-03-26**|**NeRF-HuGS: Improved Neural Radiance Fields in Non-static Scenes Using Heuristics-Guided Segmentation**|神经辐射场（NeRF）因其在新视图合成和三维场景重建方面的卓越性能而得到广泛认可。然而，它们的有效性本质上与静态场景的假设有关，这使得它们在面对移动物体或阴影等瞬态干扰时容易受到不希望的伪影的影响。在这项工作中，我们提出了一种新的范式，即“启发式引导分割”（HuGS），它通过将手工制作的启发式和最先进的分割模型的优势和谐地结合起来，显著增强了静态场景与瞬态干扰物的分离，从而显著超越了以前解决方案的局限性。此外，我们深入研究了启发式的细致设计，引入了基于运动结构（SfM）的启发式和颜色残差启发式的无缝融合，以适应各种纹理轮廓。大量实验证明了我们的方法在减轻非静态场景中训练的NeRF的瞬态干扰方面的优越性和稳健性。项目页面：https://cnhaox.github.io/NeRF-HuGS/. et.al.|[2403.17537](http://arxiv.org/abs/2403.17537)|null|
|**2024-03-25**|**CVT-xRF: Contrastive In-Voxel Transformer for 3D Consistent Radiance Fields from Sparse Inputs**|当在密集输入上训练时，神经辐射场（NeRF）在真实感新颖视图合成方面表现出了令人印象深刻的能力。然而，当在稀疏输入上进行训练时，NeRF通常会遇到密度或颜色预测不正确的问题，这主要是由于场景覆盖不足导致部分和稀疏监督，从而导致性能显著下降。虽然现有工作主要考虑射线级一致性来构建基于图像平面上渲染的颜色、深度或语义的2D学习正则化，但在本文中，我们提出了一种新的方法，对3D空间场一致性进行建模，以提高具有稀疏输入的NeRF的性能。具体来说，我们首先采用基于体素的射线采样策略，以确保采样的射线与三维空间中的某个体素相交。然后，我们对体素中的其他点进行随机采样，并应用Transformer来推断每条射线上其他点的属性，然后将这些属性合并到体积渲染中。通过对渲染损失进行反向传播，我们增强了相邻点之间的一致性。此外，我们建议在Transformer的编码器输出上使用对比损失，以进一步提高每个体素内的一致性。实验表明，在稀疏输入设置下，我们的方法对不同的辐射场产生了显著的改进，并实现了与当前工作相当的性能。 et.al.|[2403.16885](http://arxiv.org/abs/2403.16885)|null|
|**2024-03-25**|**INPC: Implicit Neural Point Clouds for Radiance Field Rendering**|我们介绍了一种新的方法来重建和合成无界的真实世界场景。与以前使用体积场、基于网格的模型或离散点云代理的方法不同，我们提出了一种混合场景表示，它在连续的基于八叉树的概率场和多分辨率哈希网格中隐式编码点云。在这样做的过程中，我们通过在优化过程中保持良好的行为，结合了两个世界的好处：我们新颖的隐式点云表示和可微分双线性光栅化器能够快速渲染，同时保持精细的几何细节，而不依赖于运动点云的初始先验结构。我们的方法在几个常见的基准数据集上实现了最先进的图像质量。此外，我们在交互式帧速率下实现了快速推理，并可以提取显式点云以进一步提高性能。 et.al.|[2403.16862](http://arxiv.org/abs/2403.16862)|null|
|**2024-03-25**|**REFRAME: Reflective Surface Real-Time Rendering for Mobile Devices**|这项工作解决了在各种场景上实现实时新颖视图合成的挑战性任务，包括高反射物体和无边界户外场景。现有的实时渲染方法，尤其是基于网格的方法，在对具有丰富的视图相关外观的曲面进行建模时，通常性能较差。我们的关键思想在于利用网格来加速渲染，同时结合一种新的方法来参数化视图相关信息。我们将颜色分解为漫反射和镜面反射，并基于神经环境图对反射方向上的镜面反射颜色进行建模。我们的实验表明，与最先进的离线方法相比，我们的方法在高反射表面上实现了相当的重建质量，同时也有效地实现了智能手机等边缘设备上的实时渲染。 et.al.|[2403.16481](http://arxiv.org/abs/2403.16481)|null|

<p align=right>(<a href=#updated-on-20240328>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-03-27**|**Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction**|随着对自动化3D内容创建管道的需求不断增长，我们解决了从单个图像高效重建3D资产的挑战。以前的方法主要依赖于分数蒸馏采样（SDS）和神经辐射场（NeRF）。尽管这些方法取得了显著的成功，但由于漫长的优化和大量的内存使用，它们遇到了实际的局限性。在本报告中，我们介绍了Gamba，一种基于单视图图像的端到端摊销3D重建模型，强调了两个主要见解：（1）3D表示：利用大量的3D高斯进行高效的3D高斯飞溅过程；（2） 骨干设计：引入基于Mamba的序列网络，该网络有助于上下文相关推理和序列（令牌）长度的线性可伸缩性，可容纳大量高斯。Gamba在数据预处理、正则化设计和训练方法方面取得了重大进展。我们使用真实世界扫描的OmniObject3D数据集，对照现有的基于优化和前馈的3D生成方法对Gamba进行了评估。在这里，Gamba在质量和数量上都展示了具有竞争力的生成能力，同时在单个NVIDIA A100 GPU上实现了约0.6秒的惊人速度。 et.al.|[2403.18795](http://arxiv.org/abs/2403.18795)|null|
|**2024-03-27**|**SplatFace: Gaussian Splat Face Reconstruction Leveraging an Optimizable Surface**|我们提出了SplatFace，这是一种新的高斯飞溅框架，用于三维人脸重建，而不依赖于精确的预定几何结构。我们的方法旨在同时提供高质量的新颖视图渲染和精确的3D网格重建。我们结合了一个通用的3D变形模型（3DMM）来提供表面几何结构，从而可以用有限的一组输入图像重建人脸。我们引入了一种联合优化策略，该策略通过协同的非刚性对齐过程来细化高斯曲面和可变形曲面。提出了一种新的距离度量，即飞溅到表面，通过考虑高斯位置和协方差来改进对准。表面信息还被用于结合世界空间致密化过程，从而获得卓越的重建质量。我们的实验分析表明，在生成具有高几何精度的三维人脸网格方面，所提出的方法在新的视图合成中与其他高斯飞溅技术和其他三维重建方法都具有竞争力。 et.al.|[2403.18784](http://arxiv.org/abs/2403.18784)|null|
|**2024-03-27**|**Breaking the Limitations with Sparse Inputs by Variational Frameworks (BLIss) in Terahertz Super-Resolution 3D Reconstruction**|数据采集、图像处理和图像质量是太赫兹（THz）3D重建成像的长期问题。考虑到与获得超分辨率（SR）数据相关的挑战以及传统计算机断层扫描（CT）中缺乏有效的SR 3D重建框架，现有方法主要针对2D场景设计。在这里，我们演示了BLIss，这是一种使用稀疏2D数据输入进行THz-SR 3D重建的新方法。BLIss将传统的CT技术和变分框架与基于Euler Elastica的自适应模型的核心无缝集成。定量的3D图像评估指标，包括高斯的标准差、平均曲率和多尺度结构相似性指数测度（MS-SSIM），验证了与传统的THz-CT模态相比，我们的变分框架方法所实现的优越的平滑度和保真度。除了对推进THz-SR 3D重建的贡献外，BLIss还展示了其在其他成像模式（如X射线和MRI）中的潜在适用性。这表明它对更广泛的成像应用领域产生了广泛的影响。 et.al.|[2403.18776](http://arxiv.org/abs/2403.18776)|null|
|**2024-03-27**|**SAT-NGP : Unleashing Neural Graphics Primitives for Fast Relightable Transient-Free 3D reconstruction from Satellite Imagery**|当前的立体视觉管道在使用多对或三组卫星图像时产生高精度的3D重建。然而，这些管道对多日期采集可能导致的图像之间的变化很敏感。这种变化主要是由于可变的阴影、反射和瞬态物体（汽车、植被）。为了考虑到这些变化，神经辐射场（NeRF）最近被应用于多日期卫星图像。然而，神经方法是计算密集型的，需要几十个小时才能学习，而标准立体视觉管道需要几分钟。遵循即时神经图形原语的思想，我们建议使用有效的采样策略和多分辨率哈希编码来加速学习。我们的模型，卫星神经图形原件（SAT-NGP）将学习时间减少到15分钟，同时保持3D重建的质量。 et.al.|[2403.18711](http://arxiv.org/abs/2403.18711)|null|
|**2024-03-27**|**MonoHair: High-Fidelity Hair Modeling from a Monocular Video**|毫无疑问，高保真度的3D头发对于实现真实感、艺术表达和沉浸在计算机图形中至关重要。虽然现有的3D头发建模方法已经取得了令人印象深刻的性能，但实现高质量头发重建的挑战仍然存在：它们要么需要严格的捕捉条件，使实际应用变得困难，要么严重依赖于学习的先验数据，模糊了图像中的细粒度细节。为了应对这些挑战，我们提出了MonoHair，这是一种通用框架，用于从单眼视频中实现高保真头发重建，而无需对环境提出特定要求。我们的方法将头发建模过程分为两个主要阶段：精确的外部重建和内部结构推断。外部使用我们的基于补丁的多视图优化（PMVO）精心制作。该方法独立于先前的数据，从多个视图战略性地收集和集成头发信息，以生成高保真的外部3D线图。这张地图不仅捕捉到了复杂的细节，而且有助于推断头发的内部结构。对于内部，我们采用了数据驱动的多视图3D头发重建方法。该方法利用从重建的外部导出的2D结构渲染，镜像训练期间使用的合成2D输入。这种对齐有效地弥合了我们的训练数据和真实世界数据之间的领域差距，从而提高了我们内部结构推断的准确性和可靠性。最后，我们生成了一个头发束模型，并通过我们的头发生长算法解决了方向模糊问题。我们的实验表明，我们的方法在各种发型中都表现出了稳健性，并实现了最先进的性能。有关更多结果，请参阅我们的项目页面https://keyuwu-cs.github.io/MonoHair/. et.al.|[2403.18356](http://arxiv.org/abs/2403.18356)|null|
|**2024-03-26**|**EgoLifter: Open-world 3D Segmentation for Egocentric Perception**|在本文中，我们介绍了EgoLifter，这是一种新的系统，可以自动将从以自我为中心的传感器捕获的场景分割为单个3D对象的完整分解。该系统专门为以自我为中心的数据而设计，其中场景包含数百个从自然（非扫描）运动中捕获的对象。EgoLifter采用3D高斯作为3D场景和对象的底层表示，并使用来自Segment Anything Model（SAM）的分割掩码作为弱监督，以学习对象实例的灵活和可提示的定义，而不需要任何特定的对象分类法。为了应对以自我为中心的视频中动态对象的挑战，我们设计了一个瞬态预测模块，该模块学习在3D重建中过滤掉动态对象。其结果是一个完全自动的管道，能够将3D对象实例重建为共同组成整个场景的3D高斯集合。我们在Aria Digital Twin数据集上创建了一个新的基准，该数据集定量展示了其在自然自我中心输入的开放世界3D分割中的最先进性能。我们在各种以自我为中心的活动数据集上运行了EgoLifter，这表明了该方法在规模上实现3D自我中心感知的前景。 et.al.|[2403.18118](http://arxiv.org/abs/2403.18118)|null|
|**2024-03-26**|**Mesoscale Polymer Arrays: High Aspect Ratio Surface Structures and Their Digital Reconstruction**|受细菌菌毛等粘性生物丝状结构的启发，这项工作详细介绍了用于制造和表征长厚比高达100000的薄、柔性和形状响应性中尺度聚合物带表面锚定阵列的方法。所得结构表现出与弹性毛细管弯曲一致的几何复杂和动态形态，弹性毛细管弯曲由于蠕变而在老化数小时内经历曲率增加。我们开发了一个计算图像分析框架，以生成这些密集几何结构的3D重建，并提取定量描述符，以证明衰老引起的形态学变化。我们通过表征老化带状阵列形状的蠕变引起的变化来证明这种定量方法的稳健性，并建立了一个比例关系来描述带状厚度对形状和动力学观测的重要性。这些方法证明了在多种环境中探测由各种材料制成的中尺度聚合物带阵列的形态-性能关系的重要基线。通过引入全氟代杯液滴，我们展示了这些带状阵列在粘合剂、微型机器人和生物医学设备中的应用潜力。 et.al.|[2403.17283](http://arxiv.org/abs/2403.17283)|null|
|**2024-03-25**|**Creating a Digital Twin of Spinal Surgery: A Proof of Concept**|手术数字化是创建真实世界手术的虚拟复制品的过程，也称为手术数字孪生（SDT）。它在教育和培训、手术计划和手术任务自动化等各个领域都有重要应用。鉴于其对外科手术的详细描述，SDT是机器学习方法的理想基础，能够自动生成训练数据。在机器人手术中，SDT可以提供逼真的虚拟环境，机器人可以在其中通过试错进行学习。在本文中，我们提出了一种手术数字化的概念验证（PoC），该概念验证应用于在现实条件下进行的离体脊柱手术。拟议的数字化侧重于整个手术场景的几何形状和外观的获取和建模。我们使用了五台RGB-D相机用于外科医生的动态三维重建，一台高端相机用于解剖结构的三维重建，另一台红外立体相机用于手术器械跟踪，以及一台激光扫描仪用于手术室的三维重建和数据融合。我们对所提出的方法进行了论证，讨论了所面临的挑战以及原型的进一步扩展。虽然我们的PoC部分依赖于手动数据管理，但其高质量和巨大的潜力推动了创建SDT的自动化方法的发展。我们的SDT的质量可以在渲染视频中进行评估，该视频可在https://youtu.be/LqVaWGgaTMY . et.al.|[2403.16736](http://arxiv.org/abs/2403.16736)|null|
|**2024-03-25**|**Spike-NeRF: Neural Radiance Field Based On Spike Camera**|作为一种具有高时间分辨率的神经形态传感器，在高速光学估计、深度估计和物体跟踪等高速视觉应用中，尖峰相机比传统相机具有显著优势。受尖峰相机成功的启发，我们提出了第一个基于尖峰数据的神经辐射场spike NeRF，以实现高速场景的3D重建和新颖的视点合成。与NeRF同时的多视图图像不同，Spike NeRF的输入是由移动的Spike相机在很短的时间内捕获的连续Spike流。为了从高频但不稳定的尖峰数据中重建正确稳定的3D场景，我们设计了具有独特损失函数的尖峰掩模。我们对我们的方法进行了定性和数值评估，这些方法是通过搅拌器和spike相机模拟器生成的几个具有挑战性的合成场景。我们的结果表明，与我们在高速场景中提出的现有方法和基线相比，Spike NeRF产生了更具视觉吸引力的结果。我们的代码和数据将很快发布。 et.al.|[2403.16410](http://arxiv.org/abs/2403.16410)|null|
|**2024-03-25**|**Elite360D: Towards Efficient 360 Depth Estimation via Semantic- and Distance-Aware Bi-Projection Fusion**|360深度估计由于其全向视场（FoV），最近在3D重建中受到了极大的关注。最近的方法主要集中在基于几何的重投影的交叉投影融合：它们将360幅图像与等矩形投影（ERP）和另一种投影类型（例如立方体映射投影）融合，以使用ERP格式估计深度。然而，这些方法存在以下问题：1）局部感受野有限，难以捕捉大型FoV场景；2）复杂的交叉投影融合模块设计导致计算成本过高。在本文中，我们提出了Elite360D，这是一种新的框架，它输入ERP图像和二十面体投影（ICOSAP）点集，该点集是不失真的，在空间上是连续的。Elite360D在从本地和全球视角学习代表性方面具有卓越的能力。它具有灵活的ERP图像编码器，包括ICOSAP点编码器和双投影双注意力融合（B2F）模块（总共约1M个参数）。具体而言，ERP图像编码器可以采用各种经过透视图像训练的主干（例如，ResNet、Transformer）来提取局部特征。点编码器从ICOSAP中提取全局特征。然后，B2F模块捕获ERP特征的每个像素与整个ICOSAP特征集之间的语义和距离感知依赖关系。在没有特定的主干设计和明显的计算成本增加的情况下，Elite360D在几个基准数据集上优于现有技术。 et.al.|[2403.16376](http://arxiv.org/abs/2403.16376)|null|

<p align=right>(<a href=#updated-on-20240328>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-03-27**|**ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion**|扩散模型已经彻底改变了图像编辑，但通常会生成违反物理定律的图像，特别是场景中对象的效果，例如遮挡、阴影和反射。通过分析自监督方法的局限性，我们提出了一个以反事实数据集为中心的实用解决方案。我们的方法包括在移除单个对象之前和之后捕捉场景，同时最大限度地减少其他更改。通过在该数据集上微调扩散模型，我们不仅可以移除对象，还可以移除它们在场景中的效果。然而，我们发现将这种方法应用于照片真实感对象插入需要不切实际的大数据集。为了应对这一挑战，我们建议进行引导监督；利用在一个小的反事实数据集上训练的对象移除模型，我们对该数据集进行了相当大的综合扩展。我们的方法在照片级真实感对象的移除和插入方面显著优于现有方法，尤其是在对场景中对象的效果建模方面。 et.al.|[2403.18818](http://arxiv.org/abs/2403.18818)|null|
|**2024-03-27**|**Garment3DGen: 3D Garment Stylization and Texture Generation**|我们介绍了Garment3DGen，这是一种在给定单个输入图像作为指导的情况下，从基础网格合成3D服装资产的新方法。我们提出的方法允许用户基于真实图像和合成图像生成3D纹理衣服，例如通过文本提示生成的图像。生成的资源可以直接覆盖并模拟在人体上。首先，我们利用图像到3D扩散方法的最新进展来生成3D服装几何形状。然而，由于这些几何形状不能直接用于下游任务，我们建议将它们用作伪地面实况，并建立网格变形优化程序，使基础模板网格变形以匹配生成的3D目标。其次，我们引入了精心设计的损耗，允许输入基础网格向所需目标自由变形，同时保持网格质量和拓扑结构，以便对其进行模拟。最后，纹理估计模块生成全局和局部一致的高保真度纹理图，并忠实地捕捉输入引导，使我们能够渲染生成的3D资产。使用Garment3DGen，用户可以生成自己选择的纹理3D服装，而无需艺术家干预。可以提供描述他们想要生成模拟就绪3D资产的服装的文本提示。我们对各种资产（包括真实资产和生成资产）进行了大量的定量和定性比较，并提供了如何生成模拟3D服装的用例。 et.al.|[2403.18816](http://arxiv.org/abs/2403.18816)|null|
|**2024-03-27**|**ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation**|在没有视差提示的情况下，基于学习的单图像深度估计（SIDE）模型在很大程度上依赖于图像中的阴影和上下文提示。虽然这种简单性很有吸引力，但有必要在难以捕获的大型和多样化的数据集上训练此类模型。已经表明，在一些应用中，使用来自预先训练的基础模型（如CLIP）的嵌入可以改善零发射转移。从中获得灵感，在我们的论文中，我们探索了使用从预先训练的ViT模型生成的全局图像先验来提供更详细的上下文信息。我们认为，来自ViT模型的嵌入向量，在大型数据集上预先训练，比通常的生成伪图像字幕的方法，以及基于CLIP的文本嵌入，为SIDE捕获了更多的相关信息。基于这一思想，我们提出了一种新的SIDE模型，该模型使用以ViT嵌入为条件的扩散骨架。我们提出的设计在NYUv2数据集上为SIDE建立了一个新的最先进的（SOTA），与当前的SOTA（VPD）的0.069相比，实现了0.059的Abs-Rel误差（提高了14%）。在KITTI数据集上，与当前SOTA（GEDepth）的0.142相比，Sq-Rel误差达到0.139（提高2%）。对于在NYUv2上训练模型的零样本传输，我们报告了（Sun-RGBD、iBims1、DIODE、HyperSim）数据集上与NeWCRF相比（16%、18%、45%、9%）的平均相对改进（20%、23%、81%、25%）。代码位于https://github.com/Aradhye2002/EcoDepth. et.al.|[2403.18807](http://arxiv.org/abs/2403.18807)|**[link](https://github.com/aradhye2002/ecodepth)**|
|**2024-03-27**|**Dimension-independent functional inequalities by tensorization and projection arguments**|我们研究了度量空间上马氏半群的梯度型估计和其他函数不等式在张量化和投影型运算下的稳定性。利用F.Baudoin和N.Eldredge在2021年获得的运输型不等式，我们证明了梯度估计中的常数可以选择为独立于维数。我们的结果适用于亚黎曼流形上的次椭圆扩散和一些次过盈扩散。作为副产品，我们获得了具有横向对称性的李群和非各向同性的海森堡群的维度无关的反庞加莱、反对数索博列夫和梯度界。 et.al.|[2403.18799](http://arxiv.org/abs/2403.18799)|null|
|**2024-03-27**|**Object Pose Estimation via the Aggregation of Diffusion Features**|从图像中估计物体的姿态是3D场景理解的一项关键任务，最近的方法在非常大的基准上显示出了有希望的结果。然而，当处理看不见的对象时，这些方法的性能会显著下降。我们认为这是由于图像特征的可推广性有限。为了解决这个问题，我们深入分析了扩散模型的特征，例如稳定扩散，它在建模看不见的物体方面具有很大的潜力。在此分析的基础上，我们创新性地将这些扩散特征引入到物体姿态估计中。为了实现这一点，我们提出了三种不同的架构，它们可以有效地捕捉和聚合不同粒度的扩散特征，大大提高了物体姿态估计的可推广性。我们的方法在三个流行的基准数据集LM、O-LM和T-LESS上以相当大的优势优于最先进的方法。特别是，我们的方法在看不见的物体上实现了比以前最好的技术更高的精度：98.2%对93.5%在看不到的LM上，85.9%对76.3%在看不清楚的O-LM上，显示了我们方法的强大可推广性。我们的代码发布于https://github.com/Tianfu18/diff-feats-pose. et.al.|[2403.18791](http://arxiv.org/abs/2403.18791)|**[link](https://github.com/tianfu18/diff-feats-pose)**|
|**2024-03-27**|**ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object**|我们为视觉感知的稳健性建立了严格的基准。合成图像，如ImageNet-C、ImageNet-9和样式化ImageNet，提供了对合成损坏、背景和纹理的特定类型的评估，然而这些鲁棒性基准仅限于特定的变化，并且合成质量较低。在这项工作中，我们引入生成模型作为合成硬图像的数据源，以衡量深度模型的稳健性。利用扩散模型，我们能够生成具有比以往任何工作都更多样化的背景、纹理和材料的图像，我们将该基准称为ImageNet-D。实验结果表明，ImageNet-D导致一系列视觉模型的精度显著下降，从标准的ResNet视觉分类器到最新的基础模型，如CLIP和MiniGPT-4，其精度显著降低了60%。我们的工作表明，扩散模型可以成为测试视觉模型的有效来源。代码和数据集可在https://github.com/chenshuang-zhang/imagenet_d. et.al.|[2403.18775](http://arxiv.org/abs/2403.18775)|**[link](https://github.com/chenshuang-zhang/imagenet_d)**|
|**2024-03-27**|**Convergence rates under a range invariance condition with application to electrical impedance tomography**|本文致力于证明线性化满足范围不变条件的逆问题的变分和迭代正则化方法在变分源条件下的收敛速度。为了实现这一点，通常需要找到问题的适当松弛，该松弛通常基于未知数集的增加，并导致反问题的特别结构化的重新表述。我们分析了利用这种结构的三种方法，即变分格式和牛顿型格式，它们的无速率收敛性已经在{ranginvar}中建立；此外，我们还提出了一种分裂最小化方法，该方法可以满足相同的速率结果对于来自边界观测的偏微分方程的几个系数识别问题，距离不变条件已经得到验证，这些问题与各种断层成像模式有关。我们的动机特别来自于电阻抗断层成像EIT的经典逆问题，我们研究了扩散型方程的原始公式及其作为Schr方程的公式化。对于这两种方程，我们都发现了可以证明满足范围不变性条件的松弛。将来自Diss-Weidling的VSCs结果与上述三种方法的抽象框架相结合，我们得出了EIT中变分法、分裂最小化法和牛顿型方法的收敛速度结果。 et.al.|[2403.18704](http://arxiv.org/abs/2403.18704)|null|
|**2024-03-27**|**A Diffusion-Based Generative Equalizer for Music Restoration**|本文提出了一种新的音频恢复方法，重点是增强低质量的音乐记录，尤其是历史记录。在之前的算法BABE（即盲音频带宽扩展）的基础上，我们引入了BABE-2，它提出了一系列显著的改进。这项研究将带宽扩展的概念扩展到生成均衡，这是一项新任务，据我们所知，在以前的研究中尚未明确解决。BABE-2是围绕一种优化算法构建的，该算法利用来自扩散模型的先验，这些先验是使用一组精心策划的高质量音乐曲目进行训练或微调的。该算法同时执行两个关键任务：估计滤波器退化幅度响应和恢复音频的幻觉。所提出的方法在历史钢琴录音上得到了客观的评价，与之前的版本相比有了显著的改进。这种方法在复兴著名声乐家恩里科·卡鲁索和内莉·梅尔巴的作品方面也产生了同样令人印象深刻的效果。这项研究代表着在历史音乐的实际修复方面的一个进步。 et.al.|[2403.18636](http://arxiv.org/abs/2403.18636)|null|
|**2024-03-27**|**FlexEdit: Flexible and Controllable Diffusion-based Object-centric Image Editing**|我们的工作解决了以前以对象为中心的编辑问题方法中的局限性，例如由于形状差异导致的不现实的结果，以及对象替换或插入的控制有限。为此，我们引入了FlexEdit，这是一个灵活可控的对象编辑框架，我们使用FlexEdit块在每个去噪步骤迭代调整延迟。最初，我们在测试时优化延迟，以与指定的对象约束保持一致。然后，我们的框架使用自适应掩模，在去噪过程中自动提取，以保护背景，同时将新内容无缝地混合到目标图像中。我们展示了FlexEdit在各种对象编辑任务中的多功能性，并利用真实图像和合成图像的样本，以及为以对象为中心的编辑设计的新评估指标，策划了一个评估测试套件。我们在不同的编辑场景上进行了广泛的实验，证明了我们的编辑框架相对于最近先进的文本引导图像编辑方法的优越性。我们的项目页面发布在https://flex-edit.github.io/. et.al.|[2403.18605](http://arxiv.org/abs/2403.18605)|null|
|**2024-03-27**|**HandBooster: Boosting 3D Hand-Mesh Reconstruction by Conditional Synthesis and Sampling of Hand-Object Interactions**|由于现有真实世界数据集缺乏多样性，从单个图像稳健地重建3D手网格是非常具有挑战性的。虽然数据合成有助于缓解这一问题，但syn-to-real的差距仍然阻碍了它的使用。在这项工作中，我们提出了HandBooster，这是一种新的方法，通过训练手-对象交互的条件生成空间并有意对该空间进行采样以合成有效的数据样本，来提高数据多样性并提高3D手网格重建性能。首先，我们构建了多功能的内容感知条件，以引导扩散模型生成具有不同手部外观、姿势、视图和背景的逼真图像；有利地，可以免费获得准确的3D注释。然后，我们基于我们的相似性感知分布采样策略设计了一个新颖的条件创建者，以故意找到与训练集不同的新颖而现实的交互姿势。使用我们的方法，在HO3D和DexYCB基准上，几个基线可以显著提高到SOTA之外。我们的代码将于发布https://github.com/hxwork/HandBooster_Pytorch. et.al.|[2403.18575](http://arxiv.org/abs/2403.18575)|**[link](https://github.com/hxwork/handbooster_pytorch)**|

<p align=right>(<a href=#updated-on-20240328>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-03-22**|**LATTE3D: Large-scale Amortized Text-To-Enhanced3D Synthesis**|最近的文本到3D生成方法产生了令人印象深刻的3D结果，但需要耗时的优化，每次提示可能需要一个小时。ATT3D等摊销方法同时优化多个提示以提高效率，实现快速的文本到三维合成。然而，它们无法捕捉高频几何体和纹理细节，并且难以缩放到大型提示集，因此泛化能力较差。我们引入LATTE3D，解决了这些限制，以在更大的提示集上实现快速、高质量的生成。我们方法的关键是1）构建可扩展的体系结构，2）在优化过程中通过3D感知扩散先验、形状正则化和模型初始化来利用3D数据，以实现对各种复杂训练提示的鲁棒性。LATTE3D对神经场和纹理表面生成进行摊销，以在单个正向过程中生成高度详细的纹理网格。LATTE3D在400ms内生成3D对象，并可通过快速测试时间优化进一步增强。 et.al.|[2403.15385](http://arxiv.org/abs/2403.15385)|null|
|**2024-03-20**|**Visual Imitation Learning of Task-Oriented Object Grasping and Rearrangement**|面向任务的物体抓取和重排是机器人完成不同现实操作任务的关键技能。然而，由于对物体的部分观察和分类物体的形状变化，它们仍然具有挑战性。在本文中，我们提出了多特征隐式模型（MIMO），这是一种新的对象表示，它在隐式神经场中对点和对象之间的多个空间特征进行编码。在多个特征上训练这样的模型可以确保它在不同方面一致地嵌入物体形状，从而提高其在从局部观察、形状相似性测量和建模物体之间的空间关系的物体形状重建中的性能。基于MIMO，我们提出了一个从单个或多个人类演示视频中学习面向任务的对象抓取和重排的框架。仿真评估表明，我们的方法在多视图和单视图观测方面优于最先进的方法。真实世界的实验证明了我们的方法在操纵任务的单次和少次模仿学习中的有效性。 et.al.|[2403.14000](http://arxiv.org/abs/2403.14000)|null|
|**2024-03-18**|**LN3Diff: Scalable Latent Neural Fields Diffusion for Speedy 3D Generation**|随着生成模型和可微分绘制技术的进步，神经绘制领域取得了重大进展。尽管2D扩散已经取得了成功，但统一的3D扩散管道仍然悬而未决。本文介绍了一种称为LN3Diff的新框架来解决这一差距，并实现快速、高质量和通用的条件3D生成。我们的方法利用3D感知架构和变分自动编码器（VAE）将输入图像编码到结构化、紧凑和3D潜在空间中。潜像由基于变换器的解码器解码为高容量的3D神经场。通过在这个3D感知的潜在空间上训练扩散模型，我们的方法在ShapeNet上实现了最先进的3D生成性能，并在各种数据集的单目3D重建和条件3D生成中表现出卓越的性能。此外，它在推理速度方面超过了现有的3D扩散方法，不需要每实例优化。我们提出的LN3Diff在三维生成建模方面取得了重大进展，并有望在三维视觉和图形任务中应用。 et.al.|[2403.12019](http://arxiv.org/abs/2403.12019)|null|
|**2024-03-15**|**NeuralOCT: Airway OCT Analysis via Neural Fields**|光学相干断层扫描（OCT）是眼科中一种流行的模式，也用于血管内。我们对这项工作的兴趣是在婴儿和儿童气道异常的背景下进行OCT，其中OCT的高分辨率和无辐射的事实很重要。气道OCT的目标是提供气道几何形状的准确估计（2D和3D），以评估气道异常，如声门下狭窄。我们提出 $\texttt｛NeuralOCT｝$，这是一种基于学习的方法来处理气道OCT图像。具体而言，$\texttt｛NeuralOCT｝$通过稳健地桥接两个步骤从OCT扫描中提取3D几何形状：通过2D分割提取点云和通过神经场从点云中重建3D。我们的实验表明，$\texttt｛NeuralOCT｝$ 可以产生准确而稳健的3D气道重建，平均A线误差小于70微米。我们的代码将在GitHub上提供。 et.al.|[2403.10622](http://arxiv.org/abs/2403.10622)|null|
|**2024-03-15**|**NECA: Neural Customizable Human Avatar**|人类化身已经成为一种具有各种应用的新型3D资产。理想情况下，人类化身应该是完全可定制的，以适应不同的设置和环境。在这项工作中，我们介绍了NECA，这是一种能够从单目或稀疏视图视频中学习多功能人体表示的方法，能够在姿势、阴影、形状、照明和纹理等方面进行细粒度定制。我们方法的核心是在互补的双空间中表示人类，并预测几何、反照率、阴影以及外部照明的解开神经场，从中我们能够通过体积渲染获得具有高频细节的真实感渲染。大量实验证明了我们的方法在真实感渲染以及各种编辑任务（如新颖的姿势合成和重新照明）方面优于最先进的方法。代码位于https://github.com/iSEE-Laboratory/NECA. et.al.|[2403.10335](http://arxiv.org/abs/2403.10335)|**[link](https://github.com/isee-laboratory/neca)**|
|**2024-03-13**|**Representing Anatomical Trees by Denoising Diffusion of Implicit Neural Fields**|解剖树在临床诊断和治疗计划中起着核心作用。然而，由于解剖树的拓扑结构和几何形状多变且复杂，因此准确地表示解剖树具有挑战性。使用医学成像捕获的表示树状结构的传统方法虽然对可视化血管和支气管网络非常宝贵，但在分辨率、灵活性和效率方面存在缺陷。最近，隐式神经表示（INRs）已经成为准确有效地表示形状的强大工具。我们提出了一种使用INR表示解剖树的新方法，同时还通过INR空间中的去噪扩散来捕捉一组树的分布。我们以任何所需的分辨率准确捕捉解剖树的复杂几何形状和拓扑结构。通过广泛的定性和定量评估，我们展示了高保真度树重建，具有任意分辨率但紧凑的存储，以及跨解剖部位和树复杂性的多功能性。 et.al.|[2403.08974](http://arxiv.org/abs/2403.08974)|**[link](https://github.com/sinashish/treediffusion)**|
|**2024-03-12**|**Scalable Spatiotemporal Prediction with Bayesian Neural Fields**|时空数据集由空间参考的时间序列组成，在许多科学和商业智能应用中无处不在，如空气污染监测、疾病跟踪和云需求预测。随着现代数据集的规模和复杂性不断增加，人们越来越需要新的统计方法，这些方法足够灵活，可以捕捉复杂的时空动态，并且可以扩展，可以处理大型预测问题。这项工作提出了贝叶斯神经场（BayesNF），这是一种用于推断时空域上丰富概率分布的域通用统计模型，可用于数据分析任务，包括预测、插值和变差法。BayesNF将一种用于高容量函数估计的新型深度神经网络架构与用于鲁棒不确定性量化的分层贝叶斯推理相结合。通过通过一系列平滑可微变换定义先验，使用通过随机梯度下降训练的变量学习代理对大规模数据进行后验推理。我们根据突出的统计和机器学习基线评估BayesNF，显示出在气候和公共卫生数据集的各种预测问题上的显著改进，这些数据集包含数万到数十万个测量值。该论文附有一个开源软件包(https://github.com/google/bayesnf)它易于使用，并与JAX机器学习平台上的现代GPU和TPU加速器兼容。 et.al.|[2403.07657](http://arxiv.org/abs/2403.07657)|**[link](https://github.com/google/bayesnf)**|
|**2024-03-11**|**SiLVR: Scalable Lidar-Visual Reconstruction with Neural Radiance Fields for Robotic Inspection**|我们提出了一种基于神经场的大规模重建系统，该系统融合激光雷达和视觉数据，生成几何精度高的高质量重建，并捕捉照片逼真的纹理。该系统采用了最先进的神经辐射场（NeRF）表示，还结合了激光雷达数据，这对深度和表面法线增加了强大的几何约束。我们利用实时激光雷达SLAM系统的轨迹来引导运动结构（SfM）过程，以显著减少计算时间，并提供对激光雷达深度损失至关重要的度量尺度。我们使用子映射将系统缩放到长轨迹上捕获的大规模环境。我们用多摄像头、激光雷达传感器套件的数据演示了重建系统，该套件安装在腿式机器人上，手持扫描600米的建筑场景，并安装在空中机器人上，测量多层模拟灾难现场建筑。网站https://ori-drs.github.io/projects/silvr/ et.al.|[2403.06877](http://arxiv.org/abs/2403.06877)|null|
|**2024-03-15**|**CoNFiLD: Conditional Neural Field Latent Diffusion Model Generating Spatiotemporal Turbulence**|本研究介绍了条件神经场潜在扩散（CoNFiLD）模型，这是一种新的生成学习框架，旨在快速模拟三维不规则域内混沌和湍流系统中复杂的时空动力学。传统的涡解析数值模拟，尽管提供了详细的流量预测，但由于其广泛的计算需求，遇到了很大的局限性，限制了其在更广泛的工程环境中的应用。相比之下，基于深度学习的代理模型有望提供高效、数据驱动的解决方案。然而，它们的有效性往往因依赖确定性框架而受到损害，而确定性框架在准确捕捉湍流的混沌和随机性质方面存在不足。CoNFiLD模型通过将条件神经场编码与潜在扩散过程协同集成来解决这些挑战，从而能够在不同条件下高效且稳健地生成时空湍流。利用贝叶斯条件采样，该模型可以无缝适应各种湍流生成场景，而无需再训练，涵盖从使用稀疏传感器测量的零样本全场流重建到超分辨率生成和时空流数据恢复的应用。已经对各种具有不规则几何形状的非均匀、各向异性湍流进行了全面的数值实验，以评估该模型的多功能性和有效性，展示了其在湍流生成和更广泛的时空动力学建模领域的变革潜力。 et.al.|[2403.05940](http://arxiv.org/abs/2403.05940)|null|
|**2024-03-09**|**Learned 3D volumetric recovery of clouds and its uncertainty for climate analysis**|气候预测和云物理的重大不确定性与浅层散射云的观测差距有关。应对这些挑战需要对其三维（3D）异质体积散射内容进行遥感。这就需要无源散射计算机断层扫描（CT）。我们设计了一个基于学习的模型（ProbeCT）来实现这种云的CT，基于有噪声的多视图星载图像。ProbeCT首次推断出每个3D位置的异质消光系数的后验概率分布。这产生了任意有价值的统计数据，例如，最可能灭绝的3D场及其不确定性。ProbeCT使用神经场表示，进行本质上实时的推理。ProbeCT通过一个新的基于物理的云体积场及其相应图像的标记多类数据库进行监督训练。为了改进分布外推理，我们通过差分渲染引入了自监督学习。我们在模拟和真实世界的数据中演示了该方法，并指出了3D恢复和不确定性与降水和可再生能源的相关性。 et.al.|[2403.05932](http://arxiv.org/abs/2403.05932)|null|

<p align=right>(<a href=#updated-on-20240328>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

