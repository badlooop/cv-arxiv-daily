[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.02.26
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-02-22**|**FrameNeRF: A Simple and Efficient Framework for Few-shot Novel View Synthesis**|我们提出了一种新的框架，称为FrameNeRF，旨在将现成的快速高保真NeRF模型应用于少镜头的新颖视图合成任务，该模型具有快速训练速度和高渲染质量。快速高保真度模型的训练稳定性通常局限于密集视图，这使得它们不适合于少镜头的新颖视图合成任务。为了解决这一限制，我们利用正则化模型作为数据生成器，从稀疏输入中生成密集视图，从而促进快速高保真模型的后续训练。由于这些密集视图是由正则化模型生成的伪地面实况，因此使用原始稀疏图像来微调快速高保真度模型。这个过程有助于模型学习真实的细节，并更正早期阶段引入的工件。通过利用现成的正则化模型和快速高保真度模型，我们的方法在各种基准数据集上实现了最先进的性能。 et.al.|[2402.14586](http://arxiv.org/abs/2402.14586)|null|
|**2024-02-22**|**TaylorGrid: Towards Fast and High-Quality Implicit Field Learning via Direct Taylor-based Grid Optimization**|基于坐标的神经隐式表示或隐式场已被广泛研究用于3D几何表示或新颖视图合成。近年来，人们致力于加快基于坐标的内隐场学习的速度和提高其质量。代替学习重MLP来预测查询坐标的神经隐式值，已经提出了与浅MLP相结合的神经体素或网格来实现具有减少的优化时间的高质量隐式场学习。另一方面，为了进一步提高学习速度，已经提出了诸如线性网格之类的轻量级场表示。在本文中，我们的目标是快速和高质量的隐场学习，并提出了TaylorGrid，这是一种新的隐场表示，可以在2D或3D网格上通过直接泰勒展开优化有效地计算。一般来说，TaylorGrid可以适用于不同的内隐场学习任务，如SDF学习或NeRF。通过广泛的定量和定性比较，TaylorGrid实现了线性网格和神经体素之间的平衡，显示了其在快速和高质量的内隐场学习中的优势。 et.al.|[2402.14415](http://arxiv.org/abs/2402.14415)|null|
|**2024-02-20**|**Improving Robustness for Joint Optimization of Camera Poses and Decomposed Low-Rank Tensorial Radiance Fields**|在本文中，我们提出了一种算法，该算法允许仅使用2D图像作为监督，对由分解的低秩张量表示的相机姿态和场景几何进行联合细化。首先，我们基于1D信号进行了一项试点研究，并将我们的发现与3D场景联系起来，在3D场景中，基于体素的NeRF上的初始关节姿态优化可以很容易地导致次优解。此外，基于频谱分析，我们建议在2D和3D辐射场上应用卷积高斯滤波器，以实现从粗到细的训练计划，从而实现联合相机姿态优化。利用分解后的低秩张量中的分解特性，我们的方法实现了与强力3D卷积等效的效果，只需很少的计算开销。为了进一步提高联合优化的鲁棒性和稳定性，我们还提出了平滑的2D监督、随机缩放的核参数和边缘引导的损失掩模技术。广泛的定量和定性评估表明，我们提出的框架在新的视图合成方面取得了卓越的性能，并实现了快速收敛的优化。 et.al.|[2402.13252](http://arxiv.org/abs/2402.13252)|**[link](https://github.com/nemo1999/joint-tensorf)**|
|**2024-02-20**|**Real-time High-resolution View Synthesis of Complex Scenes with Explicit 3D Visibility Reasoning**|绘制复杂场景的照片逼真的新颖视图图像一直是计算机图形学中的一个长期挑战。近年来，在视图合成领域，在提高渲染质量和加快渲染速度方面取得了很大的研究进展。然而，当使用稀疏视图渲染复杂的动态场景时，由于遮挡问题，渲染质量仍然有限。此外，对于在动态场景中渲染高分辨率图像，渲染速度仍远未达到实时性。在这项工作中，我们提出了一种可推广的视图合成方法，该方法可以从稀疏视图实时渲染复杂静态和动态场景的高分辨率新视图图像。为了解决由输入视图的稀疏性和捕获场景的复杂性引起的遮挡问题，我们引入了一种显式3D可见性推理方法，该方法可以有效地估计采样的3D点对输入视图的可见性。所提出的可见性推理方法是完全可微分的，可以很好地适应体绘制管道，使我们能够在训练网络时只使用多视图图像作为监督，同时细化几何体和纹理。此外，我们管道中的每个模块都经过精心设计，以绕过耗时的MLP查询过程，提高高分辨率图像的渲染质量，使我们能够实时渲染高分辨率的新视图图像。实验结果表明，我们的方法在渲染质量和速度上都优于以前的视图合成方法，尤其是在处理具有稀疏视图的复杂动态场景时。 et.al.|[2402.12886](http://arxiv.org/abs/2402.12886)|null|
|**2024-02-20**|**MVDiffusion++: A Dense High-resolution Multi-view Diffusion Model for Single or Sparse-view 3D Object Reconstruction**|本文提出了一种用于3D对象重建的神经结构MVDiffusion++，该结构在给定一张或几张没有相机姿势的图像的情况下合成对象的密集和高分辨率视图。MVDiffusion++通过两个令人惊讶的简单想法实现了卓越的灵活性和可扩展性：1）“无姿势架构”，其中2D潜在特征之间的标准自关注在任意数量的条件视图和生成视图中学习3D一致性，而无需显式使用相机姿势信息；和2）一种“视图丢弃策略”，在训练期间丢弃大量输出视图，这减少了训练时间内存占用，并在测试时实现了密集和高分辨率的视图合成。我们使用Ob厌恶对象进行训练，使用谷歌扫描对象进行评估，并使用标准的新视图合成和3D重建指标，其中MVDiffusion++显著优于当前的技术状态。我们还通过将MVDiffusion++与文本到图像生成模型相结合，展示了一个文本到3D应用程序示例。 et.al.|[2402.12712](http://arxiv.org/abs/2402.12712)|null|
|**2024-02-19**|**Binary Opacity Grids: Capturing Fine Geometric Detail for Mesh-Based View Synthesis**|虽然基于表面的视图合成算法由于其低计算要求而很有吸引力，但它们往往难以再现薄结构。相比之下，将场景的几何体建模为体积密度场（例如NeRF）的更昂贵的方法擅长于重建精细的几何细节。然而，密度场通常以“模糊”的方式表示几何体，这阻碍了曲面的精确定位。在这项工作中，我们修改了密度场，以鼓励它们向表面会聚，而不影响它们重建薄结构的能力。首先，我们使用离散的不透明度网格表示，而不是连续的密度场，这允许不透明度值在曲面上从零不连续地过渡到一。其次，我们通过每个像素投射多条光线来消除混叠，这允许在不使用半透明体素的情况下对遮挡边界和亚像素结构进行建模。第三，我们最小化不透明度值的二元熵，这通过鼓励不透明度值在训练结束时进行二元化来促进表面几何的提取。最后，我们开发了一种基于融合的网格划分策略，然后进行网格简化和外观模型拟合。与现有的基于网格的方法相比，我们的模型生成的紧凑网格可以在移动设备上实时渲染，并实现显著更高的视图合成质量。 et.al.|[2402.12377](http://arxiv.org/abs/2402.12377)|null|
|**2024-02-15**|**GES: Generalized Exponential Splatting for Efficient Radiance Field Rendering**|3D高斯散射的进步显著加速了3D重建和生成。然而，它可能需要大量的高斯，这会产生大量的内存占用。本文介绍了GES（Generalized Exponential Splatting），这是一种利用广义指数函数（GEF）对3D场景进行建模的新表示，需要更少的粒子来表示场景，因此在效率上显著优于高斯飞溅方法，并具有基于高斯的实用程序的即插即用替换能力。GES在原理性1D设置和逼真的3D场景中都得到了理论和实证验证。它被证明可以更准确地表示具有尖锐边缘的信号，由于其固有的低通特性，这对高斯人来说通常是具有挑战性的。我们的实证分析表明，GEF在拟合自然发生的信号（如正方形、三角形和抛物线信号）方面优于高斯，从而减少了对增加高斯飞溅的内存占用的广泛拆分操作的需要。借助调频损耗，GES在新的视图合成基准中实现了有竞争力的性能，同时所需的内存存储量不到高斯飞溅的一半，并将渲染速度提高了39%。代码可在项目网站上获得https://abdullahamdi.com/ges . et.al.|[2402.10128](http://arxiv.org/abs/2402.10128)|**[link](https://github.com/ajhamdi/ges-splatting)**|
|**2024-02-14**|**PC-NeRF: Parent-Child Neural Radiance Fields Using Sparse LiDAR Frames in Autonomous Driving Environments**|大规模的3D场景重建和新颖的视图合成对于自动驾驶汽车至关重要，尤其是利用时间稀疏的激光雷达帧。然而，传统的显式表示仍然是以无限分辨率表示重建和合成场景的一个重要瓶颈。尽管最近开发的神经辐射场（NeRF）在隐式表示中显示出令人信服的结果，但使用稀疏激光雷达帧进行大规模3D场景重建和新的视图合成的问题仍未得到探索。为了弥补这一差距，我们提出了一种3D场景重建和新的视图合成框架，称为父子神经辐射场（PC NeRF）。该框架基于父NeRF和子NeRF两个模块，实现了分层空间划分和多级场景表示，包括场景、分段和点级别。多级场景表示增强了稀疏激光雷达点云数据的有效利用，并能够快速获取近似体积场景表示。经过大量实验，PC NeRF被证明可以在大规模场景中实现高精度的新型激光雷达视图合成和三维重建。此外，PC NeRF可以有效地处理稀疏激光雷达帧的情况，并在有限的训练时期内表现出较高的部署效率。我们的方法实施和预先培训的模型可在https://github.com/biter0088/pc-nerf. et.al.|[2402.09325](http://arxiv.org/abs/2402.09325)|**[link](https://github.com/biter0088/pc-nerf)**|
|**2024-02-11**|**BioNeRF: Biologically Plausible Neural Radiance Fields for View Synthesis**|本文介绍了BioNeRF，这是一种生物学上合理的架构，它以3D表示对场景进行建模，并通过辐射场合成新的视图。由于NeRF依赖于网络权重来存储场景的三维表示，BioNeRF实现了一种受认知启发的机制，该机制将来自多个来源的输入融合到类似记忆的结构中，提高了存储容量，并提取了更多内在和相关的信息。BioNeRF还模拟了在锥体细胞中观察到的与上下文信息有关的行为，其中记忆作为上下文提供，并与两个后续神经模型的输入相结合，一个负责产生体积密度，另一个负责渲染场景所用的颜色。实验结果表明，BioNeRF在两个数据集（真实世界图像和合成数据）中对人类感知进行编码的质量测量方面优于最先进的结果。 et.al.|[2402.07310](http://arxiv.org/abs/2402.07310)|**[link](https://github.com/leandropassosjr/bionerf)**|
|**2024-02-11**|**3D Gaussian as a New Vision Era: A Survey**|3D高斯散射（3D-GS）已成为计算机图形学领域的一个重大进步，它提供了明确的场景表示和新颖的视图合成，而不依赖于神经网络，如神经辐射场（NeRF）。这项技术在机器人、城市地图、自主导航和虚拟现实/增强现实等领域有着不同的应用。鉴于三维高斯散射的日益流行和研究的不断扩展，本文对过去一年的相关论文进行了全面的综述。我们根据特征和应用对分类法进行了调查，介绍了3D高斯飞溅的理论基础。我们通过这项调查的目标是让新的研究人员熟悉3D高斯飞溅，为该领域的开创性工作提供宝贵的参考，并启发未来的研究方向，正如我们的结论部分所讨论的那样。 et.al.|[2402.07181](http://arxiv.org/abs/2402.07181)|null|

<p align=right>(<a href=#updated-on-20240226>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-02-22**|**Cameras as Rays: Pose Estimation via Ray Diffusion**|估计相机姿态是3D重建的一项基本任务，并且在稀疏视图（<10）的情况下仍然具有挑战性。与现有的对相机外部全局参数化进行自上而下预测的方法不同，我们提出了一种相机姿态的分布式表示，将相机视为一束光线。该表示允许与空间图像特征的紧密耦合，从而提高姿态精度。我们观察到，这种表示自然适合于设置级别的变换器，并开发了一种基于回归的方法，将图像块映射到相应的射线。为了捕捉稀疏视图姿态推断中固有的不确定性，我们采用这种方法来学习去噪扩散模型，该模型允许我们对合理的模式进行采样，同时提高性能。我们提出的方法，包括基于回归和扩散的方法，在CO3D上展示了最先进的相机姿态估计性能，同时推广到看不见的物体类别和野外捕捉。 et.al.|[2402.14817](http://arxiv.org/abs/2402.14817)|null|
|**2024-02-22**|**Workspace Analysis for Laparoscopic Rectal Surgery : A Preliminary Study**|医学成像、计算分析和机器人技术的集成为微创外科手术带来了重大变革，尤其是在腹腔镜直肠手术（LRS）领域。这种专门的外科技术旨在解决直肠癌症，需要深入理解骨盆狭窄空间内的空间动力学。本研究利用磁共振成像（MRI）扫描作为基础数据集，将其纳入计算机辅助设计（CAD）软件，以生成患者解剖结构的精确三维（3D）重建。这项研究的核心是对手术工作空间的分析，这是机器人干预优化的一个关键方面。复杂的计算算法在CAD环境中处理MRI数据，仔细计算骨盆内部区域的尺寸和轮廓。结果是，考虑到曲率、直径变化和潜在障碍等因素，对LRS期间的可行区域和限制区域进行了细致的理解。本文深入研究了机器人LRS工作空间分析的复杂性，说明了医学成像、CAD软件和外科机器人之间的无缝协作。通过这种跨学科的方法，这项研究旨在超越传统的手术方法，为在复杂的骨盆环境中优化机器人干预的范式转变提供新的见解。 et.al.|[2402.14386](http://arxiv.org/abs/2402.14386)|null|
|**2024-02-22**|**MVD $^2$: Efficient Multiview 3D Reconstruction for Multiview Diffusion**|多视点扩散（MVD）作为一种很有前途的三维生成技术，由于其在可推广性、质量和效率方面的优势而受到广泛关注。通过用3D数据微调预训练的大图像扩散模型，MVD方法首先基于图像或文本提示生成3D对象的多个视图，然后用多视图3D重建来重建3D形状。然而，生成的图像中的稀疏视图和不一致的细节使得3D重建具有挑战性。我们提出了一种有效的多视点扩散（MVD）图像三维重建方法MVD$^2$。MVD$^2$通过投影和卷积将图像特征聚合为3D特征体积，然后将体积特征解码为3D网格。我们使用3D形状集合和由3D形状的渲染视图提示的MVD图像来训练MVD$^2$。为了解决生成的多视点图像和3D形状的真实视图之间的差异，我们设计了一种简单而有效的视图相关训练方案。MVD$^2$提高了MVD的3D生成质量，并且对各种MVD方法快速且稳健。经过训练后，它可以在一秒内有效地从多视点图像中解码3D网格。我们使用Zero-123++和ObjectVerse LVIS 3D数据集训练MVD$^2$ ，并展示了其在使用合成图像和真实图像作为提示，从不同MVD方法生成的多视点图像生成3D模型方面的卓越性能。 et.al.|[2402.14253](http://arxiv.org/abs/2402.14253)|null|
|**2024-02-20**|**MVDiffusion++: A Dense High-resolution Multi-view Diffusion Model for Single or Sparse-view 3D Object Reconstruction**|本文提出了一种用于3D对象重建的神经结构MVDiffusion++，该结构在给定一张或几张没有相机姿势的图像的情况下合成对象的密集和高分辨率视图。MVDiffusion++通过两个令人惊讶的简单想法实现了卓越的灵活性和可扩展性：1）“无姿势架构”，其中2D潜在特征之间的标准自关注在任意数量的条件视图和生成视图中学习3D一致性，而无需显式使用相机姿势信息；和2）一种“视图丢弃策略”，在训练期间丢弃大量输出视图，这减少了训练时间内存占用，并在测试时实现了密集和高分辨率的视图合成。我们使用Ob厌恶对象进行训练，使用谷歌扫描对象进行评估，并使用标准的新视图合成和3D重建指标，其中MVDiffusion++显著优于当前的技术状态。我们还通过将MVDiffusion++与文本到图像生成模型相结合，展示了一个文本到3D应用程序示例。 et.al.|[2402.12712](http://arxiv.org/abs/2402.12712)|null|
|**2024-02-19**|**Real-time 3D Semantic Scene Perception for Egocentric Robots with Binocular Vision**|在室内移动时感知具有多个对象的三维（3D）场景对于基于视觉的移动机器人至关重要，尤其是对于增强其操作任务而言。在这项工作中，我们为具有双目视觉的以自我为中心的机器人提出了一种具有实例分割、特征匹配和点集配准的端到端流水线，并通过所提出的流水线展示了机器人的抓取能力。首先，我们设计了一种用于单视图3D语义场景分割的基于RGB图像的分割方法，利用2D数据集中的常见对象类，通过相应的深度图将3D点封装到对象实例的点云中。接下来，基于来自先前步骤的RGB图像中的感兴趣对象之间的匹配关键点来提取两个连续分割的点云的3D对应关系。此外，为了了解3D特征分布的空间变化，我们还使用核密度估计（KDE）基于估计的分布对每个3D点对进行加权，这随后在解决点云之间的刚性变换的同时，提供了具有较少中心对应性的鲁棒性。最后，我们在安装了Intel RealSense D435i RGB-D相机的7自由度双臂Baxter机器人上测试了我们提出的管道。结果表明，我们的机器人可以分割感兴趣的对象，在移动时配准多个视图，并抓住目标对象。源代码位于https://github.com/mkhangg/semantic_scene_perception. et.al.|[2402.11872](http://arxiv.org/abs/2402.11872)|**[link](https://github.com/mkhangg/semantic_scene_perception)**|
|**2024-02-18**|**A Robust Error-Resistant View Selection Method for 3D Reconstruction**|为了解决在运动结构（SFM）视图选择中选择具有小相机基线的视图导致三角测量不确定性增加的问题，本文提出了一种稳健的抗误差视图选择方法。该方法利用基于三角测量的计算来获得抗误差模型，然后用于构建抗误差矩阵。抗误差矩阵中每行的排序结果确定每个视图的候选视图集。通过遍历所有视图的候选视图集，并基于容错矩阵完成缺失的视图，确保了三维重建的完整性。根据重建结果中的平均重投影误差和绝对轨迹误差，将该方法与COLMAP程序中精度最高的穷举方法进行了实验比较。所提出的方法在TUM数据集和DTU数据集上的重投影误差精度平均降低了29.40%，绝对轨迹误差平均降低了5.07%。 et.al.|[2402.11431](http://arxiv.org/abs/2402.11431)|null|
|**2024-02-17**|**Dense Matchers for Dense Tracking**|光流是各种应用的有用输入，包括3D重建、姿态估计、跟踪和运动结构。尽管它很有用，但密集的长期跟踪领域，特别是在宽基线上，尚未得到广泛探索。本文扩展了MFT提出的在对数间隔上组合多个光流的概念。我们展示了MFT与不同光流网络的兼容性，产生的结果超过了它们各自的性能。此外，我们在MFT框架内提出了这些网络的简单而有效的组合。在位置预测精度方面，这种方法被证明与更复杂的非因果方法具有竞争力，突出了MFT在增强长期跟踪应用方面的潜力。 et.al.|[2402.11287](http://arxiv.org/abs/2402.11287)|null|
|**2024-02-17**|**DiffPoint: Single and Multi-view Point Cloud Reconstruction with ViT Based Diffusion Model**|随着二维到三维重建的任务在各种现实场景中获得了极大的关注，能够生成高质量的点云变得至关重要。尽管最近深度学习模型在生成点云方面取得了成功，但由于图像和点云之间的差异，在生成高保真度结果方面仍然存在挑战。虽然视觉变换器（ViT）和扩散模型在各种视觉任务中显示出了前景，但它们在从图像重建点云方面的好处尚未得到证明。在本文中，我们首先提出了一种称为DiffPoint的简洁而强大的架构，该架构将ViT和扩散模型相结合，用于点云重建任务。在每个扩散步骤，我们将有噪声的点云划分为不规则的斑块。然后，使用将所有输入视为标记（包括时间信息、图像嵌入和噪声补丁）的标准ViT主干，我们训练我们的模型以基于输入图像预测目标点。我们在单视图和多视图重建任务上对DiffPoint进行了评估，并取得了最先进的结果。此外，我们还引入了一个统一灵活的特征融合模块，用于聚合来自单个或多个输入图像的图像特征。此外，我们的工作证明了跨语言和图像应用统一架构以改进3D重建任务的可行性。 et.al.|[2402.11241](http://arxiv.org/abs/2402.11241)|null|
|**2024-02-15**|**Evaluating NeRFs for 3D Plant Geometry Reconstruction in Field Conditions**|我们评估了不同的神经辐射场（NeRF）技术，用于在从室内环境到室外环境的不同环境中重建（3D）植物。传统技术往往难以捕捉植物的复杂细节，这对植物学和农业理解至关重要。我们评估了三种日益复杂的场景，并将结果与使用激光雷达作为地面实况数据获得的点云进行了比较。在最现实的现场场景中，NeRF模型在GPU上进行30分钟的训练，获得了74.65%的F1成绩，突出了NeRF在具有挑战性的环境中的效率和准确性。这些发现不仅证明了NeRF在详细逼真的3D植物建模中的潜力，而且为提高3D重建过程的速度和效率提供了实用的方法。 et.al.|[2402.10344](http://arxiv.org/abs/2402.10344)|null|
|**2024-02-15**|**GES: Generalized Exponential Splatting for Efficient Radiance Field Rendering**|3D高斯散射的进步显著加速了3D重建和生成。然而，它可能需要大量的高斯，这会产生大量的内存占用。本文介绍了GES（Generalized Exponential Splatting），这是一种利用广义指数函数（GEF）对3D场景进行建模的新表示，需要更少的粒子来表示场景，因此在效率上显著优于高斯飞溅方法，并具有基于高斯的实用程序的即插即用替换能力。GES在原理性1D设置和逼真的3D场景中都得到了理论和实证验证。它被证明可以更准确地表示具有尖锐边缘的信号，由于其固有的低通特性，这对高斯人来说通常是具有挑战性的。我们的实证分析表明，GEF在拟合自然发生的信号（如正方形、三角形和抛物线信号）方面优于高斯，从而减少了对增加高斯飞溅的内存占用的广泛拆分操作的需要。借助调频损耗，GES在新的视图合成基准中实现了有竞争力的性能，同时所需的内存存储量不到高斯飞溅的一半，并将渲染速度提高了39%。代码可在项目网站上获得https://abdullahamdi.com/ges . et.al.|[2402.10128](http://arxiv.org/abs/2402.10128)|**[link](https://github.com/ajhamdi/ges-splatting)**|

<p align=right>(<a href=#updated-on-20240226>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-02-22**|**Cameras as Rays: Pose Estimation via Ray Diffusion**|估计相机姿态是3D重建的一项基本任务，并且在稀疏视图（<10）的情况下仍然具有挑战性。与现有的对相机外部全局参数化进行自上而下预测的方法不同，我们提出了一种相机姿态的分布式表示，将相机视为一束光线。该表示允许与空间图像特征的紧密耦合，从而提高姿态精度。我们观察到，这种表示自然适合于设置级别的变换器，并开发了一种基于回归的方法，将图像块映射到相应的射线。为了捕捉稀疏视图姿态推断中固有的不确定性，我们采用这种方法来学习去噪扩散模型，该模型允许我们对合理的模式进行采样，同时提高性能。我们提出的方法，包括基于回归和扩散的方法，在CO3D上展示了最先进的相机姿态估计性能，同时推广到看不见的物体类别和野外捕捉。 et.al.|[2402.14817](http://arxiv.org/abs/2402.14817)|null|
|**2024-02-22**|**GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion**|在这项工作中，我们解决了手-物体交互（HOI）去噪这一具有挑战性的问题。给定错误的交互序列，目标是细化不正确的手轨迹，以去除感知现实序列的交互伪影。这一挑战涉及复杂的交互噪声，包括不自然的手姿势和不正确的手-物关系，以及对新的交互和不同噪声模式进行稳健概括的必要性。我们通过一种新的方法GeneOH Diffusion来应对这些挑战，该方法结合了两个关键设计：一种名为GeneOH的创新的以接触为中心的HOI表示法和一种新型的领域可推广去噪方案。以接触为中心的表示GeneOH以信息方式参数化了HOI过程，有助于增强各种HOI场景的泛化能力。新的去噪方案由一个规范去噪模型和一个“通过扩散去噪”策略组成，该模型被训练为将噪声数据样本从白化噪声空间投影到干净的数据流形，该策略可以通过首先扩散它们以与白化噪声空间对齐并通过规范去噪器进行清洁来处理具有各种噪声模式的输入轨迹。在四个具有显著域变化的基准上进行的大量实验证明了我们方法的优越有效性。GeneOH Diffusion也显示出对各种下游应用的前景。项目网站：https://meowuu7.github.io/GeneOH-Diffusion/. et.al.|[2402.14810](http://arxiv.org/abs/2402.14810)|**[link](https://github.com/meowuu7/geneoh-diffusion)**|
|**2024-02-22**|**Consolidating Attention Features for Multi-view Image Editing**|大规模的文本到图像模型使用文本提示甚至空间控件实现了广泛的图像编辑技术。然而，将这些编辑方法应用于描绘单个场景的多视图图像会导致3D不一致的结果。在这项工作中，我们专注于基于空间控制的几何操作，并介绍了一种在各种视图中整合编辑过程的方法。我们基于两个见解：（1）在整个生成过程中保持一致的特征有助于在多视图编辑中实现一致性；（2）自关注层中的查询显著影响图像结构。因此，我们建议通过增强查询的一致性来提高编辑图像的几何一致性。为此，我们引入了QNeRF，这是一种基于编辑图像的内部查询特征训练的神经辐射场。经过训练后，QNeRF可以呈现3D一致性查询，然后在生成过程中将这些查询轻轻地注入到自关注层中，大大提高了多视图的一致性。我们通过一种渐进的迭代方法来完善流程，该方法可以更好地整合跨扩散时间步长的查询。我们将我们的方法与一系列现有技术进行了比较，并证明它可以实现更好的多视图一致性和对输入场景的更高保真度。这些优势使我们能够训练具有较少视觉伪影的NeRF，这些伪影与目标几何体更好地对齐。 et.al.|[2402.14792](http://arxiv.org/abs/2402.14792)|null|
|**2024-02-22**|**Customize-A-Video: One-Shot Motion Customization of Text-to-Video Diffusion Models**|图像定制在文本到图像（T2I）扩散模型中得到了广泛的研究，取得了令人印象深刻的成果和应用。随着文本到视频（T2V）扩散模型的出现，其时间对应物运动定制尚未得到很好的研究。为了应对单镜头运动定制的挑战，我们提出了Customize-A-Video，它从单个参考视频中对运动进行建模，并将其适应具有空间和时间变化的新主题和场景。它利用时间注意力层上的低秩自适应（LoRA）来为参考视频中的特定运动建模定制预先训练的T2V扩散模型。为了在训练过程中理清空间和时间信息，我们引入了一个新的外观吸收器概念，该概念在运动学习之前将原始外观从单个参考视频中分离出来。我们提出的方法可以以即插即用的方式轻松扩展到各种下游任务，包括自定义视频生成和编辑、视频外观自定义和多个运动组合。我们的项目页面可以在https://anonymous-314.github.io. et.al.|[2402.14780](http://arxiv.org/abs/2402.14780)|null|
|**2024-02-22**|**Two-stage Cytopathological Image Synthesis for Augmenting Cervical Abnormality Screening**|自动薄层细胞学检查（TCT）筛查可以帮助病理学家发现宫颈异常，从而准确有效地诊断癌症。目前的自动TCT筛查系统大多涉及异常宫颈细胞检测，这通常需要具有高质量注释的大规模和多样化的训练数据才能实现有希望的性能。病理图像合成被自然地提高，以最大限度地减少数据收集和注释方面的工作。然而，在合成小尺寸异常宫颈细胞的视觉上看似合理的外观的同时，生成逼真的大尺寸细胞病理学图像是一项挑战。在本文中，我们提出了一个两阶段的图像合成框架，以创建用于增强宫颈异常筛查的合成数据。在第一个全局图像生成阶段，设计了一个正常图像生成器来生成充满正常宫颈细胞的细胞病理学图像。在第二局部细胞编辑阶段，从生成的图像中随机选择正常细胞，然后使用所提出的异常细胞合成器将其转换为不同类型的异常细胞。正常图像生成器和异常细胞合成器都建立在预先训练的稳定扩散基础上，通过参数有效的微调方法分别定制细胞病理学图像内容和扩展空间布局可控性。我们的实验证明了所提出的合成框架的合成图像质量、多样性和可控性，并验证了其数据增强在提高异常宫颈细胞检测性能方面的有效性。 et.al.|[2402.14707](http://arxiv.org/abs/2402.14707)|null|
|**2024-02-22**|**PeriodGrad: Towards Pitch-Controllable Neural Vocoder Based on a Diffusion Probabilistic Model**|本文提出了一种基于去噪扩散概率模型（DDPM）的神经声码器，该模型将显式周期信号作为辅助条件信号。最近，基于DDPM的神经声码器作为能够生成高质量波形的非自回归模型而备受关注。基于DDPM的神经声码器具有训练时域损失简单的优点。在实际应用中，如歌声合成，需要神经声码器来生成具有灵活音调控制的高保真语音波形。然而，传统的基于DDPM的神经声码器在这种条件下难以生成语音波形。我们提出的模型旨在通过引入显式周期信号来准确捕捉语音波形的周期结构。实验结果表明，与传统的基于DDPM的神经声码器相比，我们的模型提高了音质，并提供了更好的音高控制。 et.al.|[2402.14692](http://arxiv.org/abs/2402.14692)|null|
|**2024-02-22**|**Error Estimates for First- and Second-Order Lagrange-Galerkin Moving Mesh Schemes for the One-Dimensional Convection-Diffusion Equation**|提出了对流扩散问题的二阶质量守恒拉格朗日-伽辽金格式，并在 $L^2$-理论框架下证明了该格式的收敛性和最优误差估计。所引入的方案保持了拉格朗日-伽辽金方法的优点，即对流控制问题的无CFL鲁棒性和离散化后的对称正系数矩阵。此外，该方案在离散水平上保持了质量。利用保守形式的材料导数截断误差和多步方法的离散Gronwall不等式的两个新的关键引理，证明了二阶时间的无条件稳定性和误差估计。Rui和Tabata在2010年引入的Jacobian乘法技术实现了质量守恒性质，并基于Ewing和Russel在1981年最初引入的多步Galerkin方法的思想沿着特性获得了时间上的二阶精度。对于第一个时间步长，采用Rui和Tabata在2010年提出的一阶时间质量守恒格式，该格式是有效的，并且在$\ell^\infty（L^2）$-和$\ell^2（H^1_0）$-范数中不会导致收敛阶的损失。对于时间增量~$\Delta t$、网格大小~$h$和多项式次~$k\in\mathbb｛N｝$的相容有限元空间，如果可以使用对偶参数，则收敛阶为$\ell^\infty（L^2）\cap\ell^2（h^1_0。进一步证明了$L^\infty（h^1_0）$-和$h^1（L^2）$-范数的离散形式中$O（Δt^{3/2}+h^k）$ 的误差估计。数值结果证实了一维、二维和三维的理论收敛阶数。 et.al.|[2402.14691](http://arxiv.org/abs/2402.14691)|null|
|**2024-02-22**|**Structure and thermodynamics of defects in Na-feldspar from a neural network potential**|长石是地壳中的一种常见矿物，其发生的扩散相变对于重建岩浆和变质岩的热历史至关重要。由于这些转变进行的时间跨度很长，钠扩散的机制及其可能的各向异性一直是一个争论的话题。为了阐明这一缺陷控制过程，我们开发了一种神经网络电位（NNP），该电位基于钠长石（阿尔比石）及其带电缺陷的第一原理计算进行训练。这种新的力场再现了长石的各种实验已知性质，包括其晶格参数、弹性常数以及热容和DFT计算的缺陷形成能。发现一种新型哑铃形间隙缺陷是最有利的，并利用热力学积分计算了其在有限温度下的形成自由能。通过预测更一致的缺陷形成能量，证明了在训练NNP之前包括静电校正的必要性。 et.al.|[2402.14640](http://arxiv.org/abs/2402.14640)|null|
|**2024-02-22**|**Debiasing Text-to-Image Diffusion Models**|基于学习的文本到图像（TTI）模型，如稳定扩散，已经彻底改变了在各个领域生成视觉内容的方式。然而，最近的研究表明，在当前最先进的TTI系统中存在不可忽视的社会偏见，这引起了人们的重要关注。在这项工作中，我们的目标是解决TTI扩散模型中的社会偏见。我们首先将问题设置形式化，并使用偏见群体的文本描述来建立指导扩散过程的不安全方向。接下来，我们将该问题简化为一个权重优化问题，并尝试使用一个强化求解器Policy Gradient，它显示出收敛缓慢的次优性能。此外，为了克服局限性，我们提出了一种迭代分布对齐（IDA）方法。尽管IDA很简单，但我们发现它在解决TTI扩散模型中的社会偏见方面表现出高效和快速的收敛性。我们的代码将会发布。 et.al.|[2402.14577](http://arxiv.org/abs/2402.14577)|null|
|**2024-02-22**|**DynGMA: a robust approach for learning stochastic differential equations from data**|从观测数据中学习未知随机微分方程是一项重要而富有挑战性的任务，在各个领域都有应用。目前的方法通常使用神经网络来表示漂移和扩散函数，并通过近似过渡密度来构建基于似然的损失来训练这些网络。然而，这些方法通常依赖于一步随机数值格式，需要具有足够高的时间分辨率的数据。在本文中，我们引入了参数化SDE跃迁密度的新近似：一种受动力系统随机微扰理论启发的高斯密度近似，及其扩展，动态高斯混合近似（DynGMA）。得益于稳健的密度近似，与基线方法相比，我们的方法在学习完全未知的漂移和扩散函数以及从轨迹数据计算不变分布方面表现出优越的精度。它能够处理低时间分辨率和可变甚至不可控的时间步长的轨迹数据，例如Gillespie随机模拟生成的数据。然后，我们在各种场景中进行了几个实验，以验证所提出方法的优势和稳健性。 et.al.|[2402.14475](http://arxiv.org/abs/2402.14475)|**[link](https://github.com/aiqing-zhu/dyngma)**|

<p align=right>(<a href=#updated-on-20240226>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-02-21**|**Geometry-Informed Neural Networks**|我们引入了几何知情神经网络（GINN）的概念，它包括（i）在几何约束下的学习，（ii）作为适当表示的神经场，以及（iii）为几何任务中经常遇到的不确定系统生成不同的解决方案。值得注意的是，GINN公式不需要训练数据，因此可以被视为纯粹由约束驱动的生成建模。我们添加了一个明确的多样性损失来缓解模式崩溃。我们考虑了几个约束，特别是分量的连通性，我们通过Morse理论将其转化为可微损失。在实验上，我们展示了GINN学习范式在一系列二维和三维场景中的有效性，这些场景的复杂性不断增加。 et.al.|[2402.14009](http://arxiv.org/abs/2402.14009)|null|
|**2024-02-18**|**Pattern Recognition Facilities of Extended Kalman Filtering in Stochastic Neural Fields**|在数学神经科学中，人们特别关注在存在模型不确定性的情况下，由动态神经场（DNF）建模的神经组织中的工作记忆机制。工作记忆设施意味着，由于网络中反复的相互作用，在去除外部刺激后，神经元的活动保持自我维持，并允许系统处理丢失的传感器信息。在我们之前的工作中，我们已经根据传感器提供的不完整数据开发了两种神经膜电位的重建方法。这些方法是在扩展卡尔曼滤波方法中通过使用Euler Maruyama方法和\^{o}-Taylor订单1.5的扩展。它表明\^{o}-Taylor基于EKF的恢复过程比基于Euler Maruyama的替代方案更准确。在传感器信息不完整的情况下，它提高了膜电位重建的质量。本文的目的是研究它们的模式识别功能，即在模型不确定和信息不完整的情况下，模式形成重建的质量。数值实验是以神经组织中出现多个活动区的随机DNF为例提供的。 et.al.|[2402.11551](http://arxiv.org/abs/2402.11551)|null|
|**2024-02-15**|**Reg-NF: Efficient Registration of Implicit Surfaces within Neural Fields**|神经场，即基于坐标的神经网络，最近因隐含地表示场景而广受欢迎。与基于点云等显式表示的经典方法相比，神经场提供了连续的场景表示，能够以紧凑且理想的机器人应用方式表示3D几何结构和外观。然而，有限的现有方法已经研究了通过直接利用这些连续的隐式表示来配准多个神经场。在本文中，我们提出了Reg-NF，这是一种基于神经场的配准，它优化了两个任意神经场之间的相对6-DoF变换，即使这两个场具有不同的比例因子。Reg NF的关键组成部分包括双向配准损失、多视图表面采样和体积符号距离函数（SDF）的利用。我们在一个新的神经场数据集上展示了我们的方法，用于评估配准问题。我们提供了一组详尽的实验和消融研究，以确定我们的方法的性能，同时也讨论了局限性，为研究界在无约束环境中利用神经场的开放挑战提供了未来的方向。 et.al.|[2402.09722](http://arxiv.org/abs/2402.09722)|null|
|**2024-02-12**|**Unsupervised Discovery of Object-Centric Neural Fields**|我们研究从单个图像中推断3D以对象为中心的场景表示。虽然最近的方法在从简单的合成图像中无监督地发现3D对象方面显示出了潜力，但它们未能推广到具有视觉丰富和多样化对象的真实世界场景。这种限制源于它们的对象表示，它将对象的内在属性（如形状和外观）与外在的、以观察者为中心的属性（如3D位置）纠缠在一起。为了解决这一瓶颈，我们提出了以对象为中心的神经场的无监督发现（uOCF）。uOCF专注于学习对象的内在，并分别对外在进行建模。我们的方法显著提高了系统泛化能力，从而能够从稀疏的真实世界图像中无监督地学习高保真的以对象为中心的场景表示。为了评估我们的方法，我们收集了三个新的数据集，包括两个真实的厨房环境。大量实验表明，uOCF能够在无监督的情况下从单个真实图像中发现视觉丰富的对象，从而实现3D对象分割和场景操作等应用。值得注意的是，uOCF演示了对单个真实图像中看不见的物体的零样本泛化。项目页面：https://red-fairy.github.io/uOCF/ et.al.|[2402.07376](http://arxiv.org/abs/2402.07376)|null|
|**2024-02-06**|**Improved Generalization of Weight Space Networks via Augmentations**|在深度权重空间（DWS）中学习，神经网络处理其他神经网络的权重，是一个新兴的研究方向，应用于2D和3D神经领域（INRs、NeRFs），以及对其他类型的神经网络进行推断。不幸的是，权重空间模型往往存在严重的过拟合问题。我们实证分析了这种过拟合的原因，发现一个关键原因是DWS数据集缺乏多样性。虽然给定的对象可以用许多不同的权重配置来表示，但典型的INR训练集无法捕捉表示同一对象的INR之间的可变性。为了解决这一问题，我们探索了在权重空间中增加数据的策略，并提出了一种适用于权重空间的MixUp方法。我们在两个设置中展示了这些方法的有效性。在分类方面，它们可以提高性能，类似于拥有10倍以上的数据。在自我监督的对比学习中，它们在下游分类中产生了5-10%的显著收益。 et.al.|[2402.04081](http://arxiv.org/abs/2402.04081)|null|
|**2024-01-31**|**BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation**|我们介绍了BlockFusion，这是一种基于扩散的模型，它将3D场景生成为单元块，并无缝地合并新的块来扩展场景。BlockFusion使用从完整的3D场景网格中随机裁剪的3D块的数据集进行训练。通过逐块拟合，所有训练块都被转换为混合神经场：具有包含几何特征的三平面，然后是用于解码有符号距离值的多层感知器（MLP）。采用变分自动编码器将三平面压缩到潜在的三平面空间中，在该空间上进行去噪扩散处理。应用于潜在表示的扩散允许高质量和多样化的3D场景生成。要在生成过程中扩展场景，只需附加空块以与当前场景重叠，并外推现有的潜在三平面以填充新块。外推是通过在去噪迭代过程中使用来自重叠三平面的特征样本来调节生成过程来完成的。潜在的三平面外推法产生语义和几何上有意义的过渡，与现有场景和谐融合。2D布局调节机制用于控制场景元素的放置和布置。实验结果表明，BlockFusion能够在室内和室外场景中生成具有前所未有的高质量形状的多样化、几何一致和无边界的大型3D场景。 et.al.|[2401.17053](http://arxiv.org/abs/2401.17053)|null|
|**2024-01-26**|**Learning Neural Radiance Fields of Forest Structure for Scalable and Fine Monitoring**|这项工作利用神经辐射场和遥感技术用于林业应用。在这里，我们展示了神经辐射场为改进森林监测中现有的遥感方法提供了广泛的可能性。我们提出的实验证明了它们的潜力：（1）表达森林三维结构的精细特征，（2）融合可用的遥感模式，（3）改进三维结构衍生的森林指标。总之，这些特性使神经场成为一种有吸引力的计算工具，具有进一步提高森林监测程序的可扩展性和准确性的巨大潜力。 et.al.|[2401.15029](http://arxiv.org/abs/2401.15029)|null|
|**2024-01-25**|**Learning Robust Generalizable Radiance Field with Visibility and Feature Augmented Point Representation**|本文介绍了广义神经辐射场（NeRF）的一种新范式。以前的通用NeRF方法将多视点立体技术与基于图像的神经渲染相结合进行泛化，产生了令人印象深刻的结果，同时存在三个问题。首先，遮挡常常导致不一致的特征匹配。然后，由于采样点和粗略特征聚合的单独过程，它们在几何不连续性和局部尖锐形状中传递失真和伪影。第三，当源视图离目标视图不够近时，它们基于图像的表示会发生严重退化。为了应对挑战，我们提出了第一个基于点而不是基于图像的渲染构建可泛化神经场的范式，我们称之为可泛化神经点场（GPF）。我们的方法通过几何先验显式地建模可见性，并用神经特征增强它们。我们提出了一种新的非均匀对数采样策略，以提高渲染速度和重建质量。此外，我们提出了一种可学习的内核，该内核在空间上增加了用于特征聚合的特征，减轻了几何结构急剧变化的地方的失真。此外，我们的表现很容易被操纵。实验表明，在泛化和微调设置中，我们的模型可以在三个数据集上提供比所有对应模型和基准更好的几何结构、视图一致性和渲染质量，初步证明了可泛化NeRF新范式的潜力。 et.al.|[2401.14354](http://arxiv.org/abs/2401.14354)|null|
|**2024-01-24**|**Unified neural field theory of brain dynamics underlying oscillations in Parkinson's disease and generalized epilepsies**|通过皮质丘脑基底神经节（CTBG）系统的神经场模型，联合探讨了帕金森病（PD）和全身性癫痫的病理同步神经振荡的机制。基底神经节（BG）被近似为一个单一的有效群体，并分析了它们在调节振荡皮质丘脑（CT）动力学中的作用，反之亦然。除了正常的脑电图节律外，模型中还存在4 Hz和20 Hz左右的增强活动，这与PD的特征频率一致。这些节律是由BG和CT人群之间回路中的共振引起的，类似于先前CT模型中潜在的癫痫振荡。多巴胺耗竭被认为削弱了对PD中这些共振的抑制，网络连接解释了在4-8Hz和20Hz左右BG、丘脑和皮层活动之间的显著一致性。丘脑网状核（TRN）和BG的传入和传出连接位点之间的相似性预测低多巴胺对应于强直-阵挛（大发作）癫痫发作的可能性降低，这与实验结果一致。此外，该模型预测，与实验结果相匹配的低多巴胺水平会增加缺席（轻微）癫痫发作的可能性。与其他CTBG建模研究一致，当传入和传出BG与CT系统的连接增强时，表现出对缺席发作活动的抑制。BG被证明在强直-阵挛发作状态附近抑制CTBG系统的活性，从而深入了解BG回路中目前治疗的疗效。TRN的睡眠状态也被发现可以抑制病理性PD活动匹配观察。总的来说，这些发现证明了广泛性癫痫和帕金森病的相干振荡之间有很强的相似性，并为可能的合并症提供了见解。 et.al.|[2401.13467](http://arxiv.org/abs/2401.13467)|null|
|**2024-01-17**|**Reproducibility via neural fields of visual illusions induced by localized stimuli**|本文研究了Billock和Tsou[PNAS，2007]使用Amari型神经场的可控性对初级视皮层（V1）皮层活动进行建模的实验复制，重点关注中央凹或外周视野中的规则漏斗模式。其目的是理解和模拟在这些实验中观察到的视觉现象，强调其非线性性质。这项研究包括设计模拟Billock和Tsou实验中视觉刺激的感官输入。然后从理论和数值上研究这些输入引起的后图像，以确定它们复制实验观察到的视觉效果的能力。这项研究的一个关键方面是研究神经反应的非线性性质所引起的影响。特别是，通过强调兴奋性和抑制性神经元在某些视觉现象出现中的重要性，这项研究表明，这两种类型的神经元活动的相互作用在视觉过程中发挥着重要作用，挑战了后者主要由兴奋性活动单独驱动的假设。 et.al.|[2401.09108](http://arxiv.org/abs/2401.09108)|null|

<p align=right>(<a href=#updated-on-20240226>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

