[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.04.03
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-04-02**|**Surface Reconstruction from Gaussian Splatting via Novel Stereo Views**|最近，高斯散射辐射场渲染方法作为一种精确场景表示的有效方法出现了。它优化了3D高斯元素云的位置、大小、颜色和形状，以便在投影或飞溅后，在视觉上匹配从不同观看方向拍摄的一组给定图像。然而，尽管高斯元素接近形状边界，但场景中对象的直接表面重建是一个挑战。我们提出了一种从高斯飞溅模型重建表面的新方法。我们利用3DGS优越的新型视图合成能力，而不是依赖高斯元素的位置作为表面重建的先验。为此，我们使用高斯飞溅模型来渲染成对的立体校准的新视图，并使用立体匹配方法从中提取深度轮廓。然后，我们将提取的RGB-D图像组合成几何一致的曲面。与从高斯飞溅模型进行表面重建的其他方法相比，所得到的重建更准确，并且显示出更精细的细节，同时与其他表面重建方法相比，需要更少的计算时间。我们在智能手机拍摄的野外场景中对所提出的方法进行了广泛的测试，展示了其卓越的重建能力。此外，我们在Tanks and Temples基准上测试了所提出的方法，它已经超过了目前从高斯飞溅模型进行表面重建的领先方法。项目页面：https://gs2mesh.github.io/. et.al.|[2404.01810](http://arxiv.org/abs/2404.01810)|null|
|**2024-04-01**|**NVINS: Robust Visual Inertial Navigation Fused with NeRF-augmented Camera Pose Regressor and Uncertainty Quantification**|近年来，神经辐射场（NeRF）已成为三维重建和新型视图合成的强大工具。然而，NeRF渲染的计算成本和由于伪影的存在而导致的质量下降，对其在实时和鲁棒机器人任务中的应用，特别是在嵌入式系统中的应用提出了重大挑战。本文介绍了一种新的框架，该框架将NeRF导出的定位信息与视觉惯性里程计（VIO）相结合，为机器人实时导航提供了一个稳健的解决方案。通过使用NeRF渲染的增强图像数据训练绝对姿态回归网络并量化其不确定性，我们的方法有效地对抗了位置漂移并提高了系统可靠性。考虑到贝叶斯框架下的不确定性，我们还为将视觉惯性导航与相机定位神经网络相结合奠定了数学上坚实的基础。在真实感仿真环境中的实验验证表明，与传统的VIO方法相比，精度显著提高。 et.al.|[2404.01400](http://arxiv.org/abs/2404.01400)|null|
|**2024-04-02**|**SurMo: Surface-based 4D Motion Modeling for Dynamic Human Rendering**|通过将视频序列的动态人体渲染公式化为从静态姿势到人体图像的映射，该渲染已经取得了显著的进展。然而，现有的方法侧重于每一帧的人脸重建，而时间运动关系并没有得到充分的探索。在本文中，我们提出了一种新的4D运动建模范式SurMo，它在一个统一的框架中用三个关键设计联合建模时间动力学和人类外观：1）基于表面的运动编码，它用一个高效的紧凑的基于表面的三平面来建模4D人类运动。它在统计身体模板的稠密表面流形上编码空间和时间运动关系，该模板继承了身体拓扑先验，用于具有稀疏训练观测的可推广新视图合成。2） 物理运动解码，其被设计为通过在训练阶段中对时间步长t处的运动三平面特征进行解码以预测下一时间步长t+1处的空间导数和时间导数来鼓励物理运动学习。3） 4D外观解码，通过高效的体积表面条件渲染器将运动三平面渲染成图像，该渲染器专注于利用运动学习条件渲染身体表面。大量实验验证了我们新范式的最先进性能，并说明了基于表面的运动三板的表现力，可以通过快速运动甚至依赖于运动的阴影来呈现与人类一致的高保真度视图。我们的项目页面位于：https://taohuumd.github.io/projects/SurMo/ et.al.|[2404.01225](http://arxiv.org/abs/2404.01225)|null|
|**2024-04-01**|**Mirror-3DGS: Incorporating Mirror Reflections into 3D Gaussian Splatting**|三维高斯散射（3DGS）技术在三维场景重建和新颖视图合成领域取得了重大突破。然而，3DGS与其前身神经辐射场（NeRF）非常相似，很难准确地对物理反射进行建模，尤其是在现实世界场景中无处不在的镜子中。这种疏忽错误地将反射视为物理存在的独立实体，导致不准确的重建和不同视点的反射特性不一致。为了应对这一关键挑战，我们引入了Mirror-3DGS，这是一种创新的渲染框架，旨在掌握镜子几何形状和反射的复杂性，为生成逼真的镜子反射铺平了道路。mirror-3DGS巧妙地将镜像属性融入3DGS，并利用平面镜像成像的原理，制作了一个镜像视点，从镜子后面进行观察，丰富了场景渲染的真实感。广泛的评估涵盖了合成场景和真实世界场景，展示了我们的方法能够实时渲染逼真度更高的新视图，特别是在具有挑战性的镜像区域内，超过了最先进的Mirror NeRF。我们的代码将公开用于可重复的研究。 et.al.|[2404.01168](http://arxiv.org/abs/2404.01168)|null|
|**2024-04-01**|**CityGaussian: Real-time High-quality Large-Scale Scene Rendering with Gaussians**|三维高斯散射（3DGS）极大地推动了实时三维场景重建和新视图合成的发展。然而，有效地训练大规模3DGS并在各种尺度上实时渲染它仍然具有挑战性。本文介绍了CityGaussian（CityGS），它采用了一种新的分而治之的训练方法和细节层次（LoD）策略来进行高效的大规模3DGS训练和渲染。具体来说，全局场景先验和自适应训练数据选择使训练和无缝融合成为可能。基于融合的高斯基元，我们通过压缩生成不同的细节级别，并通过所提出的逐块细节级别选择和聚合策略实现跨不同尺度的快速渲染。在大规模场景上的大量实验结果表明，我们的方法达到了最先进的渲染质量，能够在截然不同的尺度上对大规模场景进行一致的实时渲染。我们的项目页面位于https://dekuliutesla.github.io/citygs/. et.al.|[2404.01133](http://arxiv.org/abs/2404.01133)|null|
|**2024-04-01**|**SGCNeRF: Few-Shot Neural Rendering via Sparse Geometric Consistency Guidance**|神经辐射场（NeRF）技术在创造新观点方面取得了重大进展。然而，当使用稀疏可用的视图时，它的有效性会受到阻碍，通常会由于过拟合而导致性能下降。FreeNeRF试图通过集成隐式几何正则化来克服这一限制，该正则化可以逐步改进几何体和纹理。尽管如此，初始的低位置编码带宽导致排除了高频元件。寻求一种同时解决过度拟合和保留高频细节的整体方法仍在进行中。本文介绍了一种新的基于特征匹配的稀疏几何正则化模块。该模块擅长精确定位高频关键点，从而保护精细细节的完整性。通过在NeRF迭代中逐步细化几何体和纹理，我们推出了一种有效的少镜头神经渲染架构，称为SGCNeRF，用于增强新视图合成。我们的实验表明，SGCNeRF不仅实现了卓越的几何一致性结果，而且超过了FreeNeRF，在LLFF和DTU数据集上的PSNR分别提高了0.7dB和0.6dB。 et.al.|[2404.00992](http://arxiv.org/abs/2404.00992)|null|
|**2024-03-31**|**Knowledge NeRF: Few-shot Novel View Synthesis for Dynamic Articulated Objects**|我们提出了知识NeRF来合成动态场景的新颖视图。从少数稀疏视图重建动态3D场景并从任意角度渲染它们是各个领域应用中的一个具有挑战性的问题。以前的动态NeRF方法从单目视频中学习关节物体的变形。然而，他们重建的场景的质量是有限的。为了清晰地重建动态场景，我们提出了一个新的框架，每次考虑两个帧。我们为铰接对象预训练NeRF模型。当铰接对象移动时，Knowledge NeRF通过将过去的知识结合到预训练的NeRF模型中来学习在新状态下生成新的视图，在当前状态下具有最小的观测值。我们提出了一个投影模块，使NeRF适应动态场景，学习预训练的知识库和当前状态之间的对应关系。实验结果证明了该方法在一种状态下用5幅输入图像重建动态三维场景的有效性。知识NeRF是动态关节对象中新的视图合成的一种新的管道和有前途的解决方案。数据和实施情况可在https://github.com/RussRobin/Knowledge_NeRF. et.al.|[2404.00674](http://arxiv.org/abs/2404.00674)|**[link](https://github.com/russrobin/knowledge_nerf)**|
|**2024-03-29**|**Multi-Level Neural Scene Graphs for Dynamic Urban Environments**|我们根据不同环境条件下的多个车辆捕获来估计大规模动态区域的辐射场。该领域以前的作品要么局限于静态环境，不扩展到多个短视频，要么难以单独表示动态对象实例。为此，我们提出了一种适用于动态城市环境的新的可分解辐射场方法。我们提出了一种多级神经场景图表示，该表示可扩展到数百个快速移动对象的数十个序列中的数千幅图像。为了能够有效地训练和渲染我们的表示，我们开发了一种快速的复合光线采样和渲染方案。为了在城市驾驶场景中测试我们的方法，我们引入了一个新的、新颖的视图合成基准。我们表明，我们的方法在已建立的和提出的基准上都显著优于现有技术，同时在训练和渲染方面更快。 et.al.|[2404.00168](http://arxiv.org/abs/2404.00168)|null|
|**2024-03-29**|**InstantSplat: Unbounded Sparse-view Pose-free Gaussian Splatting in 40 Seconds**|虽然新型视图合成（NVS）在3D计算机视觉中取得了实质性进展，但它通常需要从密集的视点对相机的内在和外在进行初步估计。这种预处理通常通过运动结构（SfM）管道进行，这一过程可能缓慢且不可靠，尤其是在稀疏视图场景中，匹配特征不足以进行准确重建。在这项工作中，我们将基于点的表示（例如，3D高斯飞溅，3D-GS）的优势与端到端密集立体模型（DUSt3R）相结合，以解决无约束设置下NVS中复杂但尚未解决的问题，包括无姿态和稀疏视图挑战。我们的框架InstantSplat将密集的立体先验与3D-GS相结合，在不到1分钟的时间内从稀疏和无姿势的图像中构建大规模场景的3D高斯。具体而言，InstantSplat包括一个粗略几何初始化（CGI）模块，该模块利用从预先训练的密集立体管道中导出的全局对齐3D点图，在所有训练视图中快速建立初步场景结构和相机参数。随后是快速三维高斯优化（F-3DGO）模块，该模块通过姿态正则化联合优化三维高斯属性和初始化姿态。在大型户外坦克和寺庙数据集上进行的实验表明，InstantSplat显著提高了SSIM（32%），同时将绝对轨迹误差（ATE）降低了80%。这些使InstantSplat成为涉及无偏序和稀疏视图条件的场景的可行解决方案。项目页面：instansplat.github.io。 et.al.|[2403.20309](http://arxiv.org/abs/2403.20309)|null|
|**2024-03-29**|**Snap-it, Tap-it, Splat-it: Tactile-Informed 3D Gaussian Splatting for Reconstructing Challenging Surfaces**|触觉和视觉齐头并进，相互增强我们理解世界的能力。从研究的角度来看，触摸和视觉的混合问题还没有得到充分的探索，并提出了有趣的挑战。为此，我们提出了触觉知情3DGS，这是一种将触摸数据（局部深度图）与多视图视觉数据相结合的新方法，以实现表面重建和新的视图合成。我们的方法优化了3D高斯基元，以准确地对物体在接触点的几何结构进行建模。通过创建一个降低触摸位置透射率的框架，我们实现了精细的表面重建，确保了均匀平滑的深度图。当考虑非朗伯物体（例如有光泽或反射的表面）时，触摸尤其有用，因为现代方法往往无法用逼真的镜面高光进行重建。通过将视觉和触觉相结合，我们可以用比现有方法更少的图像实现更准确的几何重建。我们对具有光泽和反射表面的物体进行评估，并证明了我们的方法的有效性，显著提高了重建质量。 et.al.|[2403.20275](http://arxiv.org/abs/2403.20275)|null|

<p align=right>(<a href=#updated-on-20240403>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-04-01**|**Neural Implicit Representation for Building Digital Twins of Unknown Articulated Objects**|我们解决了从物体在不同关节状态下的两次RGBD扫描中构建未知关节物体的数字双胞胎的问题。我们将问题分解为两个阶段，每个阶段都涉及不同的方面。我们的方法首先在每个状态下重建对象级别的形状，然后恢复基本的关节模型，包括将两种状态关联起来的部分分割和关节关节。通过明确建模点级对应关系，并利用图像、3D重建和运动学中的线索，与之前的工作相比，我们的方法产生了更准确、更稳定的结果。它还处理多个可移动部件，不依赖于任何物体形状或结构先验。项目页面：https://github.com/NVlabs/DigitalTwinArt et.al.|[2404.01440](http://arxiv.org/abs/2404.01440)|**[link](https://github.com/nvlabs/digitaltwinart)**|
|**2024-04-01**|**NVINS: Robust Visual Inertial Navigation Fused with NeRF-augmented Camera Pose Regressor and Uncertainty Quantification**|近年来，神经辐射场（NeRF）已成为三维重建和新型视图合成的强大工具。然而，NeRF渲染的计算成本和由于伪影的存在而导致的质量下降，对其在实时和鲁棒机器人任务中的应用，特别是在嵌入式系统中的应用提出了重大挑战。本文介绍了一种新的框架，该框架将NeRF导出的定位信息与视觉惯性里程计（VIO）相结合，为机器人实时导航提供了一个稳健的解决方案。通过使用NeRF渲染的增强图像数据训练绝对姿态回归网络并量化其不确定性，我们的方法有效地对抗了位置漂移并提高了系统可靠性。考虑到贝叶斯框架下的不确定性，我们还为将视觉惯性导航与相机定位神经网络相结合奠定了数学上坚实的基础。在真实感仿真环境中的实验验证表明，与传统的VIO方法相比，精度显著提高。 et.al.|[2404.01400](http://arxiv.org/abs/2404.01400)|null|
|**2024-04-01**|**FPGA-Accelerated Correspondence-free Point Cloud Registration with PointNet Features**|点云配准是视觉和机器人应用（包括3D重建和映射）的基础。尽管在结果质量上有了显著的改进，但最近的深度学习方法在计算上昂贵且耗电，使其难以部署在资源受限的边缘设备上。为了解决这个问题，在本文中，我们提出了一种快速、准确和稳健的低成本嵌入式FPGA注册方法。基于并行和流水线的PointNet特征提取器，我们为两种不同的基于学习的方法开发了自定义加速器核心，即PointLKCore和ReAgentCore。它们既没有对应关系，又在计算上高效，因为它们避免了涉及最近邻居搜索的代价高昂的特征匹配步骤。所提出的核心在Xilinx ZCU104板上实现，并使用合成和真实世界的数据集进行评估，显示了运行时间和注册质量之间的权衡有了实质性的改进。它们比ARM Cortex-A53 CPU运行速度快44.08-45.75倍，比Intel Xeon CPU和Nvidia Jetson板提供1.98-11.13倍的加速，同时与Nvidia GeForce GPU相比，功耗不到1W，能效达到163.11-213.58倍。与经典方法相比，所提出的核心对噪声和大的初始偏差更具鲁棒性，并在不到15ms的时间内快速找到合理的解决方案，展示了实时性能。 et.al.|[2404.01237](http://arxiv.org/abs/2404.01237)|null|
|**2024-04-02**|**Few-shot point cloud reconstruction and denoising via learned Guassian splats renderings and fine-tuned diffusion features**|现有的用于点云重建和去噪的深度学习方法依赖于3D形状的小数据集。我们通过利用在数十亿张图像上训练的深度学习方法来规避这个问题。我们提出了一种方法，通过利用从基于图像的深度学习模型中提取的先验知识，从少量图像中重建点云，并从渲染中对点云进行去噪。为了改进约束设置中的重建，我们通过引入语义一致性监督来规范具有混合表面和外观的可微渲染器的训练。此外，我们提出了一种微调稳定扩散的管道，以对噪声点云的渲染进行去噪，并演示了如何使用这些学习的滤波器来去除无需3D监督的点云噪声。我们将我们的方法与DSS和PointRadiance进行了比较，并在Sketchfab测试集和SCUT数据集上实现了更高质量的3D重建。 et.al.|[2404.01112](http://arxiv.org/abs/2404.01112)|null|
|**2024-04-01**|**Interpretable Multi-View Clustering Based on Anchor Graph Tensor Factorization**|基于锚图的聚类方法因其卓越的聚类性能和处理大规模数据的能力而受到广泛关注。一种常见的方法是学习具有K连通分量的二部图，这有助于避免后处理的需要。然而，这种方法有严格的参数要求，并且可能并不总是得到K连通分量。为了解决这个问题，一种替代方法是通过对锚图执行非负矩阵分解（NMF）来直接获得聚类标签矩阵。然而，现有的基于锚图分解的多视图聚类方法对分解后的矩阵缺乏足够的聚类可解释性，并且经常忽略视图间信息。我们通过使用非负张量分解来分解结合多个视图的锚图的锚图张量来解决这一限制。这种方法使我们能够全面考虑视图间信息。分解后的张量，即样本指标张量和锚指标张量，增强了因子分解的可解释性。大量实验验证了该方法的有效性。 et.al.|[2404.00883](http://arxiv.org/abs/2404.00883)|null|
|**2024-03-30**|**DiffHuman: Probabilistic Photorealistic 3D Reconstruction of Humans**|我们提出了DiffHuman，这是一种从单个RGB图像进行真实感3D人体重建的概率方法。尽管这个问题具有不适定性，但大多数方法都是确定性的，并输出单一的解决方案，通常导致在看不见或不确定的区域缺乏几何细节和模糊性。相反，DiffHuman预测了以输入2D图像为条件的3D重建的概率分布，这允许我们对与图像一致的多个详细3D化身进行采样。DiffHuman被实现为条件扩散模型，该模型对底层3D形状表示的像素对齐的2D观测值进行去噪。在推断期间，我们可以通过迭代地对预测的3D表示的2D渲染进行去噪来对3D化身进行采样。此外，我们引入了一种生成器神经网络，该网络以显著降低的运行时间（55倍的速度）近似渲染，从而产生了一种新的双分支扩散框架。我们的实验表明，DiffHuman可以对输入图像中看不见或不确定的人的部位进行多样化和详细的重建，同时在重建可见表面时与最先进的技术保持竞争力。 et.al.|[2404.00485](http://arxiv.org/abs/2404.00485)|null|
|**2024-03-30**|**3DGSR: Implicit Surface Reconstruction with 3D Gaussian Splatting**|在本文中，我们提出了一种具有3D高斯散射（3DGS）的隐式表面重建方法，即3DGSR，该方法在继承3DGS的高效性和渲染质量的同时，允许具有复杂细节的精确3D重建。关键的见解是在3D高斯中加入隐式符号距离场（SDF），使其能够对齐并联合优化。首先，我们引入了一个可微分的SDF到不透明度转换函数，该函数将SDF值转换为相应的高斯不透明度。此功能连接SDF和三维高斯，允许统一优化并对三维高斯执行曲面约束。在学习过程中，优化3D高斯为SDF学习提供监督信号，从而能够重建复杂的细节。然而，这只在高斯人占据的位置向SDF提供稀疏的监控信号，这不足以学习连续的SDF。然后，为了解决这一限制，我们结合了体积渲染，并将渲染的几何属性（深度、法线）与从3D高斯导出的几何属性对齐。这种一致性正则化将监督信号引入离散三维高斯未覆盖的位置，有效地消除了高斯采样范围外的冗余表面。我们广泛的实验结果表明，我们的3DGSR方法能够实现高质量的3D表面重建，同时保持3DGS的效率和渲染质量。此外，我们的方法在提供更高效的学习过程和更好的渲染质量的同时，与领先的表面重建技术竞争激烈。代码将在https://github.com/CVMI-Lab/3DGSR. et.al.|[2404.00409](http://arxiv.org/abs/2404.00409)|null|
|**2024-03-29**|**Sparse Views, Near Light: A Practical Paradigm for Uncalibrated Point-light Photometric Stereo**|神经方法在基于相机的重建方面取得了重大进展。但它们要么需要对观察范围进行相当密集的采样，要么需要在现有数据集上进行预训练，从而限制了它们的可推广性。相比之下，光度立体（PS）方法在稀疏视点下实现高质量重建方面显示出巨大的潜力。然而，它们是不切实际的，因为它们通常需要乏味的实验室条件，仅限于暗室，而且往往是多阶段的，这使它们容易出现累积的错误。为了解决这些缺点，我们提出了一种端到端的未校准多视图PS框架，用于在真实世界环境中重建从稀疏视点获取的高分辨率形状。我们放宽了暗室假设，允许将静态环境照明和动态近LED照明相结合，从而能够在实验室外轻松捕获数据。实验验证证实，在稀疏视点的情况下，它在很大程度上优于现有的基线方法。这允许将高精度的3D重建从暗室带到现实世界，同时保持合理的数据捕获复杂性。 et.al.|[2404.00098](http://arxiv.org/abs/2404.00098)|null|
|**2024-03-29**|**NeSLAM: Neural Implicit Mapping and Self-Supervised Feature Tracking With Depth Completion and Denoising**|近年来，在3D重建和密集RGB-D SLAM系统方面取得了重大进展。一个值得注意的发展是神经辐射场（NeRF）在这些系统中的应用，它利用隐式神经表示对3D场景进行编码。将NeRF扩展到SLAM已经显示出有希望的结果。然而，从消费级RGB-D传感器获得的深度图像往往是稀疏和有噪声的，这对3D重建提出了重大挑战，并影响了场景几何结构的表示精度。此外，具有占用值的原始层次特征网格对于场景几何表示是不准确的。此外，现有的方法选择随机像素进行相机跟踪，这导致定位不准确，并且在真实的室内环境中不鲁棒。为此，我们提出了NeSLAM，这是一种先进的框架，可以实现精确而密集的深度估计、稳健的相机跟踪和新颖视图的逼真合成。首先，设计了一个深度完成和去噪网络，以提供密集的几何先验，并指导神经隐式表示优化。其次，用符号距离场（SDF）分层场景表示代替占用场景表示，以实现高质量的重建和视图合成。此外，我们还提出了一种基于NeRF的自监督特征跟踪算法，用于鲁棒实时跟踪。在各种室内数据集上的实验证明了该系统在重建、跟踪质量和新视图合成方面的有效性和准确性。 et.al.|[2403.20034](http://arxiv.org/abs/2403.20034)|**[link](https://github.com/dtc111111/neslam)**|
|**2024-03-29**|**A Semiparametric Gaussian Mixture Model for Chest CT-based 3D Blood Vessel Reconstruction**|自20世纪70年代出现以来，计算机断层扫描（CT）一直是一种强大的诊断工具。使用CT数据，可以使用专业软件重建人体内部器官和组织（如血管）的三维（3D）结构。这种三维重建对外科手术至关重要，可以作为生动的医学教学实例。然而，传统的3D重建在很大程度上依赖于手动操作，这是耗时的、主观的，并且需要大量的经验。为了解决这个问题，我们开发了一种新的半参数高斯混合模型，用于血管的三维重建。该模型通过根据体素位置实现感兴趣的分量参数的非参数变化来扩展经典高斯混合模型。我们开发了一种基于核的期望最大化算法来估计模型参数，并辅以一个支持的渐近理论。此外，我们还提出了一种新的优化带宽选择的回归方法。与传统的基于交叉验证的（CV）方法相比，回归方法在计算和统计效率方面优于CV方法。在应用中，这种方法有助于以显著的精度实现3D血管结构的全自动重建。 et.al.|[2403.19929](http://arxiv.org/abs/2403.19929)|null|

<p align=right>(<a href=#updated-on-20240403>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-04-02**|**Diffusion $^2$: Dynamic 3D Content Generation via Score Composition of Orthogonal Diffusion Models**|3D生成的最新进展主要是由3D感知图像扩散模型的改进推动的，该模型在互联网规模的图像数据上进行预训练，并在海量3D数据上进行微调，从而提供生成高度一致的多视图图像的能力。然而，由于同步多视图视频数据的稀缺性，将这种模式直接应用于4D生成是不切实际的。尽管如此，可用的视频和3D数据足以训练视频和多视图扩散模型，它们可以分别提供令人满意的动态和几何先验。在本文中，我们提出了Diffusion$^2$ ，这是一种用于动态3D内容创建的新框架，它利用这些模型中关于几何一致性和时间平滑性的知识来直接采样密集的多视图和多帧图像，可用于优化连续4D表示。具体来说，我们通过视频的分数合成和基于待生成图像的概率结构的多视图扩散模型，设计了一种简单而有效的去噪策略。由于图像生成的高度并行性和现代4D重建管道的效率，我们的框架可以在几分钟内生成4D内容。此外，我们的方法避免了对4D数据的依赖，从而有可能受益于基础视频和多视图扩散模型的可扩展性。大量实验证明了我们提出的框架的有效性及其灵活适应各种类型提示的能力。 et.al.|[2404.02148](http://arxiv.org/abs/2404.02148)|**[link](https://github.com/fudan-zvg/diffusion-square)**|
|**2024-04-02**|**A Stabilized Parametric Finite Element Method for Surface Diffusion with an Arbitrary Surface Energy**|我们提出了一种保结构稳定参数有限元方法（SPFEM），用于求解具有任意表面能 $\hat｛\gamma｝（\theta）$的各向异性表面扩散下闭合曲线的演化。通过引入依赖于$\hat｛\gamma｝（\theta）$的非负稳定函数$k（\thetta）$，我们得到了各向异性表面扩散的一个新的稳定保守弱公式。针对这一弱公式的离散化问题，提出了一种SPFEM。我们构造了一个综合框架来分析和证明在$\hat｛\gamma｝（\theta）$上的非常温和条件下SPFEM的无条件能量稳定性。该方法可用于模拟具有各向异性表面扩散和接触线迁移特征的任意表面能薄膜的固态脱湿。据报道，大量的数值结果证明了所提出的具有各向异性表面能$\hat｛\gamma｝（\theta）$ 的SPFEM的效率、精度和结构保持特性，这些表面能是由不同的应用引起的。 et.al.|[2404.02083](http://arxiv.org/abs/2404.02083)|null|
|**2024-04-02**|**WcDT: World-centric Diffusion Transformer for Traffic Scene Generation**|在本文中，我们介绍了一种新的自动驾驶轨迹生成方法，该方法利用扩散概率模型（也称为扩散模型）和变换器的互补优势。我们提出的框架被称为“以世界为中心的扩散转换器”（WcDT），优化了从特征提取到模型推理的整个轨迹生成过程。为了增强场景的多样性和随机性，首先使用用Diffusion with Transformer（DiT）块增强的去噪扩散概率模型（DDPM）对历史轨迹数据进行预处理并将其编码到潜在空间中。然后，利用各种基于变换器的编码器融合潜在特征、历史轨迹、高清地图特征和历史交通信号信息。然后由轨迹解码器对编码的交通场景进行解码，以生成多模式的未来轨迹。综合实验结果表明，该方法在生成逼真和多样化的轨迹方面表现出优越的性能，显示出其集成到自动驾驶仿真系统中的潜力。 et.al.|[2404.02082](http://arxiv.org/abs/2404.02082)|**[link](https://github.com/yangchen1997/wcdt)**|
|**2024-04-02**|**Brownian Particles and Matter Waves**|鉴于微观流变学在监测小到几纳米的布朗粒子的随机运动方面取得了显著进展，同时，已经在相当纳米尺寸的大分子中实验观察到了德布罗意物质波；我们研究了布朗粒子是否可以在不使用量子退相干的先验论证的情况下表现出粒子波对偶性。首先，我们研究了布朗粒子浸入具有时间无关扩散系数的无记忆粘性流体中的情况；并且对布朗粒子表现出粒子波对偶性的要求导致了扩散系数必须与逆时间成比例的不成立的结果；因此在早期就分化了。这一发现与过去的结论一致，即量子力学不等同于马尔可夫扩散过程。接下来，我们研究布朗粒子被困在有耗散和无耗散的谐波势阱中的情况。对于有耗散的情况，Fokker-Plank方程的解和对于没有耗散的情况的Schrodinger方程的解都导致了相同的物理可接受的结果，即对于布朗粒子来说，要表现出粒子-波的对偶性，其平均动能需要是量子谐振子基态能量的一半。我们的一维计算表明，要实现这一点，捕获需要非常强，这样布朗纳米颗粒就需要嵌入极其坚硬的固体中。 et.al.|[2404.02016](http://arxiv.org/abs/2404.02016)|null|
|**2024-04-02**|**Superionic Fluoride Gate Dielectrics with Low Diffusion Barrier for Advanced Electronics**|当传统电介质面临接近击穿极限的泄漏问题时，探索具有大电容耦合的新型电介质是现代电子学中的一个重要课题。为了应对这一迫在眉睫的挑战，我们证明，具有极低离子迁移势垒的稀土金属氟化物通常可以表现出超过20 $\mu$F-cm$^{-2}$的优异电容耦合（等效氧化物厚度约为0.15nm，有效介电常数接近30），并与可扩展的器件制造工艺具有良好的兼容性。超离子氟化物的这种静态介电能力的例子是MoS$_2$晶体管，其表现出超过10$^8$的高导通/关断电流比、65mV dec$^{-1}$的超低亚阈值摆幅和约10$^{-6}$A cm$^{-2}$的极低漏电流密度。因此，与传统电介质相比，氟化物门控逻辑反相器可以实现显著更高的静态电压增益值，超过~167。此外，氟化物门控的应用使得能够以低静态能耗演示NAND、NOR、AND和OR逻辑电路。值得注意的是，在清洁极限Bi$_2$Sr$_2$CaCu$_2$O$_{8+\delta}$ 下的超导体到绝缘体的转变也可以通过氟化物门控来实现。我们的发现突出了氟化物电介质作为先进电子应用和调整凝聚态中涌现电子态的先驱平台。 et.al.|[2404.02011](http://arxiv.org/abs/2404.02011)|null|
|**2024-04-02**|**AUTODIFF: Autoregressive Diffusion Modeling for Structure-based Drug Design**|基于结构的药物设计（SBDD）旨在产生能够与靶蛋白紧密结合的分子，是药物发现中的一个重要问题，以前的方法已经取得了初步成功。然而，大多数现有的方法仍然存在无效的局部结构或不切实际的构象问题，这主要是由于键角或扭转角的倾斜不良。为了缓解这些问题，我们提出了AUTODIFF，一种基于扩散的分段自回归生成模型。具体而言，我们设计了一种新的分子组装策略，称为共形基序，该策略首先保持分子局部结构的构象，然后我们用SE（3）-等变卷积网络编码蛋白质-配体复合物的相互作用，并通过扩散建模逐基序生成分子。此外，我们还通过将生成的分子的分子量限制在同一范围内，以及一些新的指标，改进了SBDD的评估框架，使评估更加公平和实用。在CrossDocked2020上的大量实验表明，我们的方法在生成具有有效结构和构象的真实分子同时保持高结合亲和力方面优于现有模型。 et.al.|[2404.02003](http://arxiv.org/abs/2404.02003)|null|
|**2024-04-02**|**Rigorous derivation of an effective model for coupled Stokes advection, reaction and diffusion with freely evolving microstructure**|我们考虑了在具有尺寸为 $\varepsilon$的演化微观结构的穿孔域中耦合的Stokes流和平流-反应-扩散的均匀化问题。微观界面边界处的反应导致形成具有可变的、先验未知厚度的固体层。这导致固相的生长或收缩，因此，域演化不是先验的，而是由平流-反应-扩散过程引起的。这项工作的成就是弱微观解的存在性和唯一性，以及基于$\varepsilon$-一致先验估计，严格推导了$\varepilon\~0$ 的有效模型。作为极限通道的结果，宏观尺度上的过程由平流-反应-扩散问题描述，该问题与达西方程耦合，有效系数（孔隙率、扩散率和渗透率）取决于局部单元问题。这些局部问题是在细胞上形成的，细胞取决于宏观位置并在时间上进化。特别地，这些细胞的进化取决于宏观浓度。因此，单元问题（分别为有效系数）与宏观未知数耦合，反之亦然，导致了强耦合的微观-宏观模型。对于纯反应扩散输运，结合微观域演化，但没有平流输运，最近给出了均匀化结果。我们通过平流传输扩展了这些模型，平流传输由先验未知演化孔隙域中的斯托克斯方程驱动。 et.al.|[2404.01983](http://arxiv.org/abs/2404.01983)|null|
|**2024-04-02**|**Bi-LORA: A Vision-Language Approach for Synthetic Image Detection**|深度图像合成技术的进步，如生成对抗性网络（GANs）和扩散模型（DM），开创了生成高度逼真图像的时代。虽然这一技术进步引起了人们的极大兴趣，但它也引发了人们对区分真实图像与合成图像的潜在困难的担忧。本文的灵感来源于视觉和语言之间强大的收敛能力，以及视觉语言模型（VLM）的零样本性质。我们介绍了一种称为Bi-LORA的创新方法，该方法利用VLM与低秩自适应（LORA）调谐技术相结合，提高了对看不见的模型生成图像的合成图像检测精度。我们方法中的关键概念转变围绕着将二进制分类重新定义为图像字幕任务，利用尖端VLM的独特功能，特别是引导语言图像预训练（BLIP2）。进行了严格而全面的实验来验证我们提出的方法的有效性，特别是在训练期间从未知的基于扩散的生成模型中检测不可见的扩散生成图像，展示了对噪声的鲁棒性，并展示了对GANs的泛化能力。所获得的结果显示，在看不见的生成模型上，合成图像检测的平均准确率为93.41%，令人印象深刻。与这项研究相关的代码和模型可以在上公开访问https://github.com/Mamadou-Keita/VLM-DETECT. et.al.|[2404.01959](http://arxiv.org/abs/2404.01959)|null|
|**2024-04-02**|**Nonlinear stability for active suspensions**|本文致力于对Saintillan和Shelley提出的描述粘性流中活性杆状颗粒悬浮的动力学模型进行非线性分析。我们研究了常态 $\Psi（t，x，p）=\frac｛1｝｛4\pi｝$的稳定性，该常态对应于在空间上均匀的粒子分布（变量$x\in\mathbb｛t｝^3$）和在方向上均匀的颗粒分布（变量$p\in\math bb｛S｝^2$）。在线性化谱稳定性的最优条件下，在不增加任何空间扩散的情况下，我们证明了它的非线性稳定性。与以前的线性研究相比，数学上的新颖性和难度来自于$x$中由于非线性对流而存在的拟线性项。我们的工作的一个关键特征是，对于给定的适当小的矢量场$u$，分析平流-扩散算子$$\partial_t+（p+u（t，x））\cdot\nabla_x-\nu\Delta_p$$在$\mathbb｛t｝^3\times\mathbb｛S｝^2$ 上的增强耗散和混合性质，这是我们希望独立感兴趣的。 et.al.|[2404.01906](http://arxiv.org/abs/2404.01906)|null|
|**2024-04-02**|**On the surface helium abundance of B-type hot subdwarf stars from the WD+MS channel of Type Ia supernovae**|中间富氦热亚矮星的起源尚不清楚。先前的研究表明，来自白矮星主序（WD+MS）通道的一些幸存的Ia型超新星（SNe-Ia）伴星可能有助于形成中间的富氦热亚矮星。然而，先前的研究忽略了原子扩散对SNe Ia幸存伴星爆炸后演化的影响，导致它们无法解释观测到的富含He的中间热亚矮星的表面He丰度。在这项工作中，通过考虑原子扩散和恒星风，我们使用一维恒星演化代码\textsc{MESA}从WD+MS通道追踪SNe-Ia的幸存伴星，直到它们演化成热的亚矮星。我们发现，我们幸存的伴星模型在其核心He燃烧阶段的表面He丰度在 $-1\lesssim｛\rm-log｝（N_｛\rm-He｝/N_{\rm-H｝）\lesssim-0$ 的范围内，这与在中间富He热亚矮星中观察到的丰度一致。这似乎进一步支持了在WD+MS通道中幸存的SNe-Ia同伴有可能形成一些富含He的中间热亚矮星。 et.al.|[2404.01905](http://arxiv.org/abs/2404.01905)|null|

<p align=right>(<a href=#updated-on-20240403>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-04-01**|**NeRF-MAE : Masked AutoEncoders for Self Supervised 3D representation Learning for Neural Radiance Fields**|神经领域在计算机视觉和机器人领域表现出色，因为它们能够理解3D视觉世界，如推断语义、几何和动力学。考虑到神经场在从2D图像密集表示3D场景方面的能力，我们提出了一个问题：我们是否可以扩展它们的自监督预训练，特别是使用掩蔽的自动编码器，从姿态RGB图像中生成有效的3D表示。由于将转换器扩展到新型数据模式的惊人成功，我们采用了标准的3D视觉转换器来适应NeRF的独特配方。我们利用NeRF的体积网格作为变压器的密集输入，将其与其他3D表示（如点云）进行对比，在点云中，信息密度可能不均匀，并且表示不规则。由于将掩蔽的自动编码器应用于隐式表示（如NeRF）很困难，我们选择提取通过使用相机轨迹进行采样来规范化跨域场景的显式表示。我们的目标是通过从NeRF的辐射和密度网格中屏蔽随机补丁，并使用标准的3D Swin Transformer来重建屏蔽的补丁。通过这样做，模型可以学习完整场景的语义和空间结构。我们在我们提出的精心策划的姿势RGB数据上对这种表示进行了大规模的预训练，总共超过160万张图像。一旦经过预训练，编码器就用于有效的3D迁移学习。我们针对NeRF的新型自监督预训练NeRF-MAE可扩展性非常好，并提高了在各种具有挑战性的3D任务中的性能。利用未标记的姿态2D数据进行预训练，在Front3D和ScanNet数据集上，NeRF MAE显著优于自监督3D预训练和NeRF场景理解基线，在3D对象检测方面的绝对性能提高超过20%AP50和8%AP25。 et.al.|[2404.01300](http://arxiv.org/abs/2404.01300)|null|
|**2024-03-29**|**Grounding and Enhancing Grid-based Models for Neural Fields**|当代许多研究利用基于网格的模型来表示神经场，但仍然缺乏对基于网格模型的系统分析，阻碍了这些模型的改进。因此，本文介绍了一个基于网格的模型的理论框架。该框架指出，这些模型的逼近和泛化行为是由网格切线核（GTK）决定的，GTK是基于网格的模型的固有性质。所提出的框架有助于对各种基于网格的模型进行一致和系统的分析。此外，引入的框架推动了一种新的基于网格的模型的开发，该模型名为乘法傅立叶自适应网格（MulFAGrid）。数值分析表明，MulFAGrid表现出比其前身更低的泛化界，表明其具有鲁棒的泛化性能。实证研究表明，MulFAGrid在各种任务中都取得了最先进的性能，包括2D图像拟合、3D符号距离场（SDF）重建和新颖的视图合成，表现出了卓越的表示能力。项目网站位于https://sites.google.com/view/cvpr24-2034-submission/home. et.al.|[2403.20002](http://arxiv.org/abs/2403.20002)|null|
|**2024-04-01**|**Efficient 3D Instance Mapping and Localization with Neural Fields**|我们解决了从一系列摆姿势的RGB图像中学习用于3D实例分割的隐式场景表示的问题。为此，我们引入了3DIML，这是一种新的框架，可以有效地学习可以从新的视点渲染的标签字段，以产生视图一致的实例分割掩码。3DIML显著改进了现有的基于隐式场景表示的方法的训练和推理运行时。与现有技术相反，现有技术以自我监督的方式优化神经场，需要复杂的训练过程和损失函数设计，3DIML利用了两阶段过程。第一阶段InstanceMap将前端实例分割模型生成的图像序列的2D分割掩码作为输入，并将图像上的相应掩码与3D标签相关联。然后，在第二阶段InstanceLift中使用这些几乎视图一致的伪标签掩码来监督神经标签字段的训练，该字段对InstanceMap遗漏的区域进行插值并解决歧义。此外，我们介绍了InstanceLoc，它能够在给定训练过的标签字段和现成的图像分割模型的情况下，通过融合两者的输出，实现实例掩码的近实时定位。我们在Replica和ScanNet数据集的序列上评估了3DIML，并证明了在图像序列的温和假设下3DIML的有效性。与现有的质量相当的隐式场景表示方法相比，我们实现了巨大的实际加速，展示了其促进更快、更有效的3D场景理解的潜力。 et.al.|[2403.19797](http://arxiv.org/abs/2403.19797)|null|
|**2024-03-28**|**Neural Fields for 3D Tracking of Anatomy and Surgical Instruments in Monocular Laparoscopic Video Clips**|腹腔镜视频跟踪主要关注两种目标类型：手术器械和解剖结构。前者可用于技能评估，而后者对于虚拟覆盖的投影是必要的。在仪器和解剖跟踪通常被视为两个独立的问题的情况下，在本文中，我们提出了一种同时对所有结构进行联合跟踪的方法。基于单个2D单眼视频剪辑，我们训练神经场来表示连续的时空场景，用于创建至少一帧中可见的所有表面的3D轨迹。由于仪器尺寸较小，它们通常只覆盖图像的一小部分，导致跟踪精度下降。因此，我们建议增强类权重以改善仪器轨迹。我们评估了对腹腔镜胆囊切除术视频片段的跟踪，发现解剖结构和器械的平均跟踪准确率分别为92.4%和87.4%。此外，我们还评估了从该方法的场景重建中获得的深度图的质量。我们表明，这些伪深度具有与最先进的预训练深度估计器相当的质量。在SCARED数据集中的腹腔镜视频上，该方法预测深度的MAE为2.9 mm，相对误差为9.2%。这些结果表明了使用神经场进行腹腔镜场景的单目3D重建的可行性。 et.al.|[2403.19265](http://arxiv.org/abs/2403.19265)|null|
|**2024-03-28**|**From Activation to Initialization: Scaling Insights for Optimizing Neural Fields**|在计算机视觉领域，神经场作为一种利用神经网络进行信号表示的现代工具，已经获得了突出地位。尽管在调整这些网络以解决各种问题方面取得了显著进展，但该领域仍然缺乏一个全面的理论框架。本文旨在通过深入研究初始化和激活之间复杂的相互作用来解决这一差距，为神经领域的稳健优化提供基础。我们的理论见解揭示了网络初始化、架构选择和优化过程之间的深层次联系，强调在设计尖端神经场时需要整体方法。 et.al.|[2403.19205](http://arxiv.org/abs/2403.19205)|null|
|**2024-03-22**|**LATTE3D: Large-scale Amortized Text-To-Enhanced3D Synthesis**|最近的文本到3D生成方法产生了令人印象深刻的3D结果，但需要耗时的优化，每次提示可能需要一个小时。ATT3D等摊销方法同时优化多个提示以提高效率，实现快速的文本到三维合成。然而，它们无法捕捉高频几何体和纹理细节，并且难以缩放到大型提示集，因此泛化能力较差。我们引入LATTE3D，解决了这些限制，以在更大的提示集上实现快速、高质量的生成。我们方法的关键是1）构建可扩展的体系结构，2）在优化过程中通过3D感知扩散先验、形状正则化和模型初始化来利用3D数据，以实现对各种复杂训练提示的鲁棒性。LATTE3D对神经场和纹理表面生成进行摊销，以在单个正向过程中生成高度详细的纹理网格。LATTE3D在400ms内生成3D对象，并可通过快速测试时间优化进一步增强。 et.al.|[2403.15385](http://arxiv.org/abs/2403.15385)|null|
|**2024-03-20**|**Visual Imitation Learning of Task-Oriented Object Grasping and Rearrangement**|面向任务的物体抓取和重排是机器人完成不同现实操作任务的关键技能。然而，由于对物体的部分观察和分类物体的形状变化，它们仍然具有挑战性。在本文中，我们提出了多特征隐式模型（MIMO），这是一种新的对象表示，它在隐式神经场中对点和对象之间的多个空间特征进行编码。在多个特征上训练这样的模型可以确保它在不同方面一致地嵌入物体形状，从而提高其在从局部观察、形状相似性测量和建模物体之间的空间关系的物体形状重建中的性能。基于MIMO，我们提出了一个从单个或多个人类演示视频中学习面向任务的对象抓取和重排的框架。仿真评估表明，我们的方法在多视图和单视图观测方面优于最先进的方法。真实世界的实验证明了我们的方法在操纵任务的单次和少次模仿学习中的有效性。 et.al.|[2403.14000](http://arxiv.org/abs/2403.14000)|null|
|**2024-03-18**|**LN3Diff: Scalable Latent Neural Fields Diffusion for Speedy 3D Generation**|随着生成模型和可微分绘制技术的进步，神经绘制领域取得了重大进展。尽管2D扩散已经取得了成功，但统一的3D扩散管道仍然悬而未决。本文介绍了一种称为LN3Diff的新框架来解决这一差距，并实现快速、高质量和通用的条件3D生成。我们的方法利用3D感知架构和变分自动编码器（VAE）将输入图像编码到结构化、紧凑和3D潜在空间中。潜像由基于变换器的解码器解码为高容量的3D神经场。通过在这个3D感知的潜在空间上训练扩散模型，我们的方法在ShapeNet上实现了最先进的3D生成性能，并在各种数据集的单目3D重建和条件3D生成中表现出卓越的性能。此外，它在推理速度方面超过了现有的3D扩散方法，不需要每实例优化。我们提出的LN3Diff在三维生成建模方面取得了重大进展，并有望在三维视觉和图形任务中应用。 et.al.|[2403.12019](http://arxiv.org/abs/2403.12019)|null|
|**2024-03-15**|**NeuralOCT: Airway OCT Analysis via Neural Fields**|光学相干断层扫描（OCT）是眼科中一种流行的模式，也用于血管内。我们对这项工作的兴趣是在婴儿和儿童气道异常的背景下进行OCT，其中OCT的高分辨率和无辐射的事实很重要。气道OCT的目标是提供气道几何形状的准确估计（2D和3D），以评估气道异常，如声门下狭窄。我们提出 $\texttt｛NeuralOCT｝$，这是一种基于学习的方法来处理气道OCT图像。具体而言，$\texttt｛NeuralOCT｝$通过稳健地桥接两个步骤从OCT扫描中提取3D几何形状：通过2D分割提取点云和通过神经场从点云中重建3D。我们的实验表明，$\texttt｛NeuralOCT｝$ 可以产生准确而稳健的3D气道重建，平均A线误差小于70微米。我们的代码将在GitHub上提供。 et.al.|[2403.10622](http://arxiv.org/abs/2403.10622)|null|
|**2024-03-15**|**NECA: Neural Customizable Human Avatar**|人类化身已经成为一种具有各种应用的新型3D资产。理想情况下，人类化身应该是完全可定制的，以适应不同的设置和环境。在这项工作中，我们介绍了NECA，这是一种能够从单目或稀疏视图视频中学习多功能人体表示的方法，能够在姿势、阴影、形状、照明和纹理等方面进行细粒度定制。我们方法的核心是在互补的双空间中表示人类，并预测几何、反照率、阴影以及外部照明的解开神经场，从中我们能够通过体积渲染获得具有高频细节的真实感渲染。大量实验证明了我们的方法在真实感渲染以及各种编辑任务（如新颖的姿势合成和重新照明）方面优于最先进的方法。代码位于https://github.com/iSEE-Laboratory/NECA. et.al.|[2403.10335](http://arxiv.org/abs/2403.10335)|**[link](https://github.com/isee-laboratory/neca)**|

<p align=right>(<a href=#updated-on-20240403>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

