[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.08.06
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-08-05**|**UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization**|三维超声成像是一项广泛应用于医学诊断的关键技术。然而，传统的3D超声成像方法具有固定分辨率、低存储效率和上下文连接不足等局限性，导致处理复杂伪影和反射特性的性能较差。最近，基于NeRF（神经辐射场）的技术在视图合成和3D重建方面取得了重大进展，但在高质量超声成像方面仍存在研究差距。为了解决这些问题，我们提出了一种新的模型UlRe-NeRF，它将隐式神经网络和显式超声体积渲染结合到一个超声神经渲染架构中。该模型结合了反射方向参数化和谐波编码，使用方向MLP模块生成视图相关的高频反射强度估计，并使用空间MLP模块产生介质的物理特性参数。这些参数用于体绘制过程中，以准确再现超声波在介质中的传播和反射行为。实验结果表明，UlRe-NeRF模型显著提高了高保真超声图像重建的真实性和准确性，特别是在处理复杂介质结构时。 et.al.|[2408.00860](http://arxiv.org/abs/2408.00860)|null|
|**2024-08-01**|**EmoTalk3D: High-Fidelity Free-View Synthesis of Emotional 3D Talking Head**|我们提出了一种合成具有可控情绪的3D对话头的新方法，该方法具有增强的嘴唇同步和渲染质量。尽管在该领域取得了重大进展，但现有方法仍然存在多视图一致性和缺乏情感表达的问题。为了解决这些问题，我们收集了带有校准的多视图视频、情感注释和每帧3D几何的EmoTalk3D数据集。通过在EmoTalk3D数据集上进行训练，我们提出了一个\textit{“语音到几何到外观”}映射框架，该框架首先从音频特征预测忠实的3D几何序列，然后从预测的几何中合成由4D高斯表示的3D说话头的外观。该外观进一步被分解为规范高斯和动态高斯，从多视图视频中学习，并融合以渲染自由视图说话的头部动画。此外，我们的模型能够在生成的说话头中实现可控的情绪，并且可以在宽范围的视图中呈现。我们的方法在嘴唇运动生成中表现出改进的渲染质量和稳定性，同时捕获了动态面部细节，如皱纹和微妙的表情。实验证明了我们的方法在生成高保真度和情绪可控的3D对话头方面的有效性。代码和EmoTalk3D数据集发布于https://nju-3dv.github.io/projects/EmoTalk3D. et.al.|[2408.00297](http://arxiv.org/abs/2408.00297)|null|
|**2024-08-01**|**Head360: Learning a Parametric 3D Full-Head for Free-View Synthesis in 360°**|创建人类头部的360度参数模型是一项非常具有挑战性的任务。虽然最近的进展已经证明了利用合成数据构建此类参数化头部模型的有效性，但它们在表情驱动动画、发型编辑和基于文本的修改等关键领域的性能仍然不足。在本文中，我们构建了一个艺术家设计的高保真人头数据集，并提出从中创建一个新的参数化360度可渲染参数化人头模型。我们的方案将面部运动/形状和面部外观解耦，分别由经典的参数化3D网格模型和附加的神经纹理表示。我们进一步提出了一种分解发型和面部外观的训练方法，允许自由交换发型。提出了一种基于单图像输入的具有高泛化和保真度的反演拟合方法。据我们所知，我们的模型是第一个在单个模型中实现360度自由视图合成、基于图像的拟合、外观编辑和动画的参数化3D全头模型。实验表明，面部运动和外观在参数空间中很好地解耦，从而在渲染和动画质量方面提高了SOTA的性能。代码和SynHead100数据集发布于https://nju-3dv.github.io/projects/Head360. et.al.|[2408.00296](http://arxiv.org/abs/2408.00296)|null|
|**2024-08-01**|**LoopSparseGS: Loop Based Sparse-View Friendly Gaussian Splatting**|尽管原始的3D高斯散点（3DGS）实现了逼真的新视图合成（NVS）性能，但其渲染质量在稀疏输入视图下会显著降低。这种性能下降主要是由于稀疏输入生成的初始点数量有限、训练过程中的监督不足以及超大高斯椭球体的正则化不足造成的。为了解决这些问题，我们提出了LoopSparseGS，这是一个基于循环的3DGS框架，用于稀疏新颖视图合成任务。具体来说，我们提出了一种基于循环的渐进高斯初始化（PGI）策略，该策略可以在训练过程中使用渲染的伪图像迭代加密初始化的点云。然后，利用运动结构的稀疏可靠深度和基于窗口的密集单眼深度，通过提出的深度对齐正则化（DAR）提供精确的几何监督。此外，我们引入了一种新的稀疏友好采样（SFS）策略来处理导致大像素误差的超大高斯椭球。在四个数据集上的综合实验表明，在各种图像分辨率的室内、室外和对象级场景中，LoopSparseGS在稀疏输入新视图合成方面优于现有的最先进方法。 et.al.|[2408.00254](http://arxiv.org/abs/2408.00254)|null|
|**2024-08-02**|**Forecasting Future Videos from Novel Views via Disentangled 3D Scene Representation**|空间和时间视频外推（VEST）使观众能够预测未来的3D场景，并从新颖的视角观看。最近的方法提出学习纠缠表示，旨在将分层场景几何、运动预测和新颖的视图合成建模在一起，同时假设每个场景层都有简化的仿射运动和基于单应性的扭曲，导致视频外推不准确。我们的方法不是纠缠的场景表示和渲染，而是选择通过将2D场景提升到3D点云来将场景几何体与场景运动分离，从而能够从新颖的视角对未来的视频进行高质量的渲染。为了模拟未来的3D场景运动，我们提出了一种解纠缠的两阶段方法，该方法首先预测自我运动，然后预测动态对象（如汽车、人）的残余运动。这种方法通过减少自我运动与动态物体运动纠缠的不准确性来确保更精确的运动预测，更好的自我运动预测可以显著提高视觉效果。对两个城市场景数据集的广泛实验分析表明，与强基线相比，我们提出的方法具有更优的性能。 et.al.|[2407.21450](http://arxiv.org/abs/2407.21450)|null|
|**2024-07-30**|**Dynamic Scene Understanding through Object-Centric Voxelization and Neural Rendering**|从无监督视频中学习以对象为中心的表示是具有挑战性的。与之前大多数专注于分解2D图像的方法不同，我们提出了一个名为DynaVol-S的3D生成模型，用于动态场景，该模型在可微体绘制框架内实现了以对象为中心的学习。其关键思想是执行以对象为中心的体素化，以捕捉场景的3D特性，从而推断单个空间位置的每个对象占用概率。这些体素特征通过规范空间变形函数演变，并在具有组合NeRF的逆渲染管道中进行优化。此外，我们的方法整合了2D语义特征来创建3D语义网格，通过多个解纠缠的体素网格来表示场景。DynaVol-S在动态场景的新颖视图合成和无监督分解任务中都明显优于现有模型。通过联合考虑几何结构和语义特征，它有效地解决了涉及复杂对象交互的具有挑战性的现实世界场景。此外，一旦经过训练，显式有意义的体素特征能够实现2D场景分解方法无法实现的额外功能，例如通过编辑几何形状或操纵对象的运动轨迹来生成新的场景。 et.al.|[2407.20908](http://arxiv.org/abs/2407.20908)|**[link](https://github.com/zyp123494/dynavol)**|
|**2024-07-29**|**Radiance Fields for Robotic Teleoperation**|神经辐射场（NeRFs）或3D高斯散斑（3DGS）等辐射场方法彻底改变了图形和新颖的视图合成。它们能够合成具有照片级真实感的新视点，以及捕捉复杂的体积和镜面场景，使其成为机器人遥操作设置的理想可视化工具。直接摄像机遥操作以牺牲机动性为代价提供高保真度操作，而基于重建的方法提供了保真度较低的可控场景。考虑到这一点，我们建议用在线辐射场取代机器人遥操作管道的传统重建可视化组件，提供具有照片级真实感的高度可操作场景。因此，对现有技术有三个主要贡献：（1）使用来自多个相机的实时数据对辐射场进行在线训练，（2）支持包括NeRF和3DGS在内的各种辐射方法，（3）这些方法的可视化套件，包括虚拟现实场景。为了实现与现有设置的无缝集成，这些组件在多种配置下用多个机器人进行了测试，并使用传统工具和VR耳机进行了显示。将不同方法和机器人的结果与网格重建的基线进行了定量比较，并进行了一项用户研究来比较不同的可视化方法。有关视频和代码，请查看https://leggedrobotics.github.io/rffr.github.io/. et.al.|[2407.20194](http://arxiv.org/abs/2407.20194)|**[link](https://github.com/leggedrobotics/rf_ros)**|
|**2024-07-25**|**Towards the Spectral bias Alleviation by Normalizations in Coordinate Networks**|最近，使用坐标网络表示信号主导了逆问题领域，并广泛应用于各种科学计算任务中。尽管如此，坐标网络中仍存在光谱偏差的问题，限制了学习高频分量的能力。这个问题是由坐标网络的神经切线核（NTK）特征值的病理分布引起的。我们发现，使用经典归一化技术（批归一化和层归一化）可以改善这种病理分布，这些技术通常用于卷积神经网络，但很少用于坐标网络。我们证明，归一化技术大大降低了NTK特征值的最大值和方差，同时略微修改了均值，考虑到最大特征值远大于最大值，这种方差变化导致特征值分布从较低的分布向较高的分布偏移，因此可以减轻谱偏差。此外，我们通过以不同的方式组合这两种技术，提出了两种新的归一化技术。通过将基于归一化的坐标网络应用于各种任务，包括图像压缩、计算机断层扫描重建、形状表示、磁共振成像、新视图合成和多视图立体重建，这些归一化技术的有效性得到了显著改进和最新技术水平的证实。 et.al.|[2407.17834](http://arxiv.org/abs/2407.17834)|**[link](https://github.com/aiolus-x/norm-inr)**|
|**2024-07-24**|**SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency**|我们提出了稳定视频4D（SV4D），这是一种用于多帧和多视图一致动态3D内容生成的潜在视频扩散模型。与之前依赖于单独训练的生成模型进行视频生成和新颖视图合成的方法不同，我们设计了一个统一的扩散模型来生成动态3D对象的新颖视图视频。具体来说，给定单眼参考视频，SV4D为每个视频帧生成时间上一致的新视图。然后，我们使用生成的新颖视图视频来有效地优化隐式4D表示（动态NeRF），而不需要大多数先前工作中使用的繁琐的基于SDS的优化。为了训练我们的统一新颖视图视频生成模型，我们从现有的Objaverse数据集中策划了一个动态3D对象数据集。多个数据集和用户研究的广泛实验结果表明，与先前的工作相比，SV4D在新视图视频合成和4D生成方面具有最先进的性能。 et.al.|[2407.17470](http://arxiv.org/abs/2407.17470)|null|
|**2024-07-24**|**Pose Estimation from Camera Images for Underwater Inspection**|高精度定位是水下复验任务的关键。惯性导航系统、多普勒速度记录仪和声学定位等传统定位方法面临着重大挑战，对于某些应用来说成本效益不高。在这种情况下，视觉定位是一种经济高效的替代方案，利用检查车辆上已经配备的摄像头从周围场景的图像中估计姿态。其中，基于机器学习的图像姿态估计在水下环境中显示出前景，使用基于先前映射场景训练的模型进行高效的重新定位。我们探索了基于学习的姿态估计器在清水和浑浊水检查任务中的有效性，评估了图像格式、模型架构和训练数据多样性的影响。我们通过采用新颖的视图合成模型来生成增强训练数据，从而显著增强了未探索区域的姿态估计。此外，我们通过扩展卡尔曼滤波器将姿态估计器输出与传感器数据相结合，提高了定位精度，证明了轨迹平滑度和精度的提高。 et.al.|[2407.16961](http://arxiv.org/abs/2407.16961)|null|

<p align=right>(<a href=#updated-on-20240806>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-08-02**|**IG-SLAM: Instant Gaussian SLAM**|3D高斯散点最近显示出有希望的结果，作为SLAM系统中神经隐式表示的替代场景表示。然而，目前的方法要么缺乏密集的深度图来监督绘图过程，要么缺乏考虑环境规模的详细训练设计。为了解决这些缺点，我们提出了IG-SLAM，这是一种仅包含RGB的密集SLAM系统，它采用鲁棒的密集SLAN方法进行跟踪，并将其与高斯散斑相结合。使用跟踪提供的精确姿态和密集深度构建环境的3D地图。此外，我们在地图优化中利用深度不确定性来改进3D重建。我们在映射优化中的衰减策略增强了收敛性，并允许系统在单个过程中以每秒10帧的速度运行。我们通过最先进的仅RGB SLAM系统展示了具有竞争力的性能，同时实现了更快的运行速度。我们展示了在Replica、TUM-RGBD、ScanNet和EuRoC数据集上的实验。该系统在大规模序列中实现了逼真的3D重建，特别是在EuRoC数据集中。 et.al.|[2408.01126](http://arxiv.org/abs/2408.01126)|null|
|**2024-08-02**|**Structure from Motion-based Motion Estimation and 3D Reconstruction of Unknown Shaped Space Debris**|随着近几十年来航天器发射数量的增加，空间碎片问题日益变得至关重要。为了实现可持续的空间利用，持续清除空间碎片是人类面临的最严峻问题。为了最大限度地提高轨道碎片捕获任务的可靠性，对目标进行精确的运动估计至关重要。空间碎片已经失去了姿态和轨道控制能力，由于断裂，其形状未知。本文提出了一种基于运动结构的算法，用于在资源有限的情况下进行未知形状空间碎片运动估计，其中只需要2D图像作为输入。然后，该方法同时输出未知物体的重建形状和目标与相机之间的相对姿态轨迹，用于估计目标的运动。该方法通过二维气浮试验台微重力实验和三维运动学模拟生成的真实图像数据集进行了定量验证。 et.al.|[2408.01035](http://arxiv.org/abs/2408.01035)|null|
|**2024-08-05**|**UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization**|三维超声成像是一项广泛应用于医学诊断的关键技术。然而，传统的3D超声成像方法具有固定分辨率、低存储效率和上下文连接不足等局限性，导致处理复杂伪影和反射特性的性能较差。最近，基于NeRF（神经辐射场）的技术在视图合成和3D重建方面取得了重大进展，但在高质量超声成像方面仍存在研究差距。为了解决这些问题，我们提出了一种新的模型UlRe-NeRF，它将隐式神经网络和显式超声体积渲染结合到一个超声神经渲染架构中。该模型结合了反射方向参数化和谐波编码，使用方向MLP模块生成视图相关的高频反射强度估计，并使用空间MLP模块产生介质的物理特性参数。这些参数用于体绘制过程中，以准确再现超声波在介质中的传播和反射行为。实验结果表明，UlRe-NeRF模型显著提高了高保真超声图像重建的真实性和准确性，特别是在处理复杂介质结构时。 et.al.|[2408.00860](http://arxiv.org/abs/2408.00860)|null|
|**2024-07-30**|**NIS-SLAM: Neural Implicit Semantic RGB-D SLAM for 3D Consistent Scene Understanding**|近年来，神经内隐表示范式在同步定位和映射（SLAM）领域引起了广泛关注。然而，在场景理解方面，现有的方法存在明显的差距。本文介绍了NIS-SLAM，这是一种高效的神经隐式语义RGB-D SLAM系统，它利用预训练的2D分割网络来学习一致的语义表示。具体来说，为了实现高保真表面重建和空间一致的场景理解，我们将基于高频多分辨率四面体的特征和低频位置编码结合起来作为隐式场景表示。此外，为了解决多视图二维分割结果的不一致性，我们提出了一种融合策略，将先前非关键帧的语义概率整合到关键帧中，以实现一致的语义学习。此外，我们实现了一种基于置信度的像素采样和渐进优化权重函数，用于鲁棒的相机跟踪。在各种数据集上的广泛实验结果表明，与其他现有的神经密集隐式RGB-D SLAM方法相比，我们的系统具有更好或更具竞争力的性能。最后，我们还表明我们的方法可以用于增强现实应用。项目页面：\href{https://zju3dv.github.io/nis_slam}{https://zju3dv.github.io/nis\_砰。 et.al.|[2407.20853](http://arxiv.org/abs/2407.20853)|null|
|**2024-07-29**|**X-ray nano-holotomography reconstruction with simultaneous probe retrieval**|在传统的断层重建中，预处理步骤包括平场校正，其中探测器上的每个样本投影都除以没有样本的参考图像。当使用相干X射线作为探针时，这种方法忽略了照明场（探针）的相位分量，导致相位检索投影图像中的伪影，然后将伪影传播到重建的3D样本表示中。在使用聚焦光学元件的纳米全息断层扫描中，由于各种缺陷，探头功能中会产生高频分量，这一问题更加严重。在这里，我们提出了一种新的全断层摄影迭代重建方案，同时检索复值探测函数。该算法在GPU上实现，可实现3D重建，分辨率为使用纳米全息断层扫描测量的3D ALD标准样品中的两倍薄层。 et.al.|[2407.20304](http://arxiv.org/abs/2407.20304)|null|
|**2024-07-29**|**TeleOR: Real-time Telemedicine System for Full-Scene Operating Room**|远程医疗的出现代表了利用技术将专业医疗专业知识扩展到远程手术的变革性发展，在这个领域，专家指导的即时性至关重要。然而，手术室（OR）场景的复杂动态给远程医疗带来了独特的挑战，特别是在障碍物和带宽限制下实现高保真、实时的场景重建和传输。本文介绍了TeleOR，这是一个开创性的系统，旨在通过远程干预的实时OR场景重建来应对这些挑战。TeleOR以三种创新方法脱颖而出：动态自校准，利用固有的场景特征进行校准，无需预设标记，允许避障和实时调整相机；选择性OR重建，侧重于动态变化的场景片段，以降低重建复杂度；基于实时客户端反馈优化数据传输以在带宽限制内有效地提供高质量的3D重建。4D-OR手术场景数据集的综合实验证明了TeleOR的优越性和适用性，阐明了通过克服远程手术指导固有的空间和技术障碍来彻底改变远程干预的潜力。 et.al.|[2407.19763](http://arxiv.org/abs/2407.19763)|null|
|**2024-07-29**|**SALVE: A 3D Reconstruction Benchmark of Wounds from Consumer-grade Videos**|管理慢性伤口是一项全球性挑战，可以通过采用消费级视频的临床伤口评估自动系统来缓解。虽然2D图像分析方法不足以处理伤口的3D特征，但利用3D重建方法的现有方法尚未得到彻底评估。为了解决这一差距，本文对消费级视频的3D伤口重建进行了全面的研究。具体来说，我们介绍了SALVE数据集，其中包括用不同相机拍摄的逼真伤口幻影的视频记录。使用此数据集，我们评估了最先进的3D重建方法的准确性和精度，从传统的摄影测量管道到先进的神经渲染方法。在我们的实验中，我们观察到摄影测量方法不能提供适合精确临床测量伤口的光滑表面。神经渲染方法在解决这一问题方面显示出希望，推动了这项技术在伤口护理实践中的应用。 et.al.|[2407.19652](http://arxiv.org/abs/2407.19652)|null|
|**2024-07-28**|**Cycle3D: High-quality and Consistent Image-to-3D Generation via Generation-Reconstruction Cycle**|最近的3D大型重建模型通常采用两阶段过程，包括首先通过多视图扩散模型生成多视图图像，然后利用前馈模型将图像重建为3D内容。然而，多视图扩散模型通常会产生低质量和不一致的图像，对最终3D重建的质量产生不利影响。为了解决这个问题，我们提出了一种名为Cycle3D的统一3D生成框架，该框架在多步扩散过程中循环利用基于2D扩散的生成模块和前馈3D重建模块。具体而言，2D扩散模型用于生成高质量的纹理，重建模型保证了多视图的一致性。此外，2D扩散模型可以进一步控制生成的内容，并为看不见的视图注入参考视图信息，从而增强去噪过程中3D生成的多样性和纹理一致性。大量实验证明，与最先进的基线相比，我们的方法具有创建高质量和一致性的3D内容的卓越能力。 et.al.|[2407.19548](http://arxiv.org/abs/2407.19548)|null|
|**2024-07-27**|**A Bayesian Approach Toward Robust Multidimensional Ellipsoid-Specific Fitting**|这项工作提出了一种新颖有效的方法，用于在噪声和异常值污染的情况下将多维椭球体拟合到散射数据中。我们将该问题视为贝叶斯参数估计过程，并在给定数据的情况下最大化某个椭球解的后验概率。我们基于贝叶斯框架内的预测分布在这些点之间建立了更稳健的相关性。我们采用均匀的先验分布来约束在椭球域内搜索原始参数，确保无论输入如何，都能得到椭球特定的结果。然后，我们通过贝叶斯规则建立测量点和模型数据之间的连接，以增强该方法对噪声的鲁棒性。由于与空间维度无关，所提出的方法不仅为具有挑战性的细长椭球体提供了高质量的拟合，而且很好地推广到多维空间。为了解决以往方法经常忽视的异常值干扰，我们在预测分布的基础上进一步引入了均匀分布，以显著增强算法对异常值的鲁棒性。我们引入了一种加速技术，大大加快了EM的收敛速度。据我们所知，这是第一种能够在各种干扰下在贝叶斯优化范式内进行多维椭球体特定拟合的综合方法。我们在存在强噪声、异常值和轴比大幅变化的情况下，在低维和高维空间中对其进行评估。此外，我们将其应用于广泛的实际应用，如显微镜细胞计数、3D重建、几何形状近似和磁力计校准任务。 et.al.|[2407.19269](http://arxiv.org/abs/2407.19269)|**[link](https://github.com/zikai1/bayfit)**|
|**2024-07-26**|**Floating No More: Object-Ground Reconstruction from a Single Image**|从单个图像重建3D对象的最新进展主要集中在提高对象形状的准确性上。然而，这些技术往往无法准确捕捉物体、地面和相机之间的相互关系。因此，当放置在平面上时，重建的对象通常会出现浮动或倾斜。这一限制严重影响了3D感知图像编辑应用程序，如阴影渲染和对象姿态操纵。为了解决这个问题，我们引入了ORG（地面对象重建），这是一项旨在结合地面重建3D对象几何的新任务。我们的方法使用两个紧凑的像素级表示来描述相机、物体和地面之间的关系。实验表明，与传统的单图像3D重建技术相比，所提出的ORG模型可以在看不见的数据上有效地重建目标地面几何，显著提高了阴影生成和姿态操纵的质量。 et.al.|[2407.18914](http://arxiv.org/abs/2407.18914)|null|

<p align=right>(<a href=#updated-on-20240806>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-08-02**|**Conditional LoRA Parameter Generation**|生成模型在图像、视频和文本领域取得了显著成功。受此启发，研究人员探索了利用生成模型生成神经网络参数。然而，这些努力受到参数大小和生成高性能参数的实用性的限制。在本文中，我们提出了COND P-DIFF，这是一种新方法，证明了在微调过程中可控高性能参数生成的可行性，特别是对于LoRA（低秩自适应）权重。具体来说，我们采用自动编码器来提取参数的有效潜在表示。然后，我们训练一个条件潜在扩散模型，根据特定的任务条件从随机噪声中合成高性能的模型参数。计算机视觉和自然语言处理领域的实验结果一致表明，COND P-DIFF可以生成基于给定任务的高性能参数。此外，我们观察到，COND P-DIFF生成的参数分布与通过常规优化方法获得的分布存在差异，表明具有一定的泛化能力。我们的工作为进一步探索条件驱动参数生成铺平了道路，为神经网络的任务特定适应提供了有前景的方向。 et.al.|[2408.01415](http://arxiv.org/abs/2408.01415)|null|
|**2024-08-02**|**Harmonized connectome resampling for variance in voxel sizes**|迄今为止，还没有全面的研究来表征扩散加权磁共振成像体素分辨率对高分辨率受试者数据的连接组的影响。即使在初始下采样之后，结果的相似性也随着分辨率的提高而提高。为确保可靠的纤维束成像和连接体，将数据重新采样至1mm各向同性分辨率。 et.al.|[2408.01351](http://arxiv.org/abs/2408.01351)|null|
|**2024-08-02**|**TexGen: Text-Guided 3D Texture Generation with Multi-view Sampling and Resampling**|给定一个3D网格，我们的目标是合成与任意文本描述相对应的3D纹理。从采样视图生成和组装纹理的当前方法通常会导致明显的接缝或过度平滑。为了解决这些问题，我们提出了TexGen，这是一种利用预训练的文本到图像扩散模型进行纹理生成的新型多视图采样和重采样框架。对于视图一致性采样，首先我们在RGB空间中维护一个纹理图，该纹理图由去噪步骤参数化，并在扩散模型的每个采样步骤后更新，以逐步减少视图差异。利用注意力引导的多视图采样策略在视图之间广播外观信息。为了保留纹理细节，我们开发了一种噪声重采样技术，该技术有助于估计噪声，根据文本提示和当前纹理图的指示，为后续的去噪步骤生成输入。通过大量的定性和定量评估，我们证明我们提出的方法为各种3D对象产生了明显更好的纹理质量，具有高度的视图一致性和丰富的外观细节，优于当前最先进的方法。此外，我们提出的纹理生成技术也可以应用于纹理编辑，同时保留原始身份。更多实验结果请访问https://dong-huo.github.io/TexGen/ et.al.|[2408.01291](http://arxiv.org/abs/2408.01291)|null|
|**2024-08-02**|**A General Framework to Boost 3D GS Initialization for Text-to-3D Generation by Lexical Richness**|文本到3D内容创作最近受到了广泛关注，特别是随着3D高斯飞溅的流行。一般来说，基于GS的方法包括两个关键阶段：初始化和渲染优化。为了实现初始化，现有的工作直接应用随机球体初始化或3D扩散模型，例如Point-e，来推导初始形状。然而，这些策略存在两个关键但具有挑战性的问题：1）即使在训练后，最终的形状仍然与初始形状相似；2） 形状只能从简单的文本中产生，例如“狗”，而不能从词汇丰富的文本中生成，例如“一只狗坐在飞机顶部”。为了解决这些问题，本文提出了一种新的通用框架，在词汇丰富性的基础上，增强文本到3D生成的3D GS初始化。我们的核心思想是将3D高斯集合成空间均匀的体素来表示复杂的形状，同时实现3D高斯之间的空间交互以及高斯与文本之间的语义交互。具体来说，我们首先构建一个体素化表示，其中每个体素都包含一个位置、比例和旋转固定的3D高斯模型，同时将不透明度设置为确定位置占用率的唯一因素。然后，我们设计了一个初始化网络，主要由两个新组件组成：1）全局信息感知（GIP）块和2）高斯文本融合（GTF）块。这样的设计使每个3D高斯模型能够吸收来自其他区域的空间信息和来自文本的语义信息。大量的实验表明，我们的高质量3D GS初始化框架通过处理词汇简单、中等和硬文本，比现有的方法（如Shap-e）具有优越性。此外，我们的框架可以无缝地插入SoTA训练框架，例如LucidDreamer，用于语义一致的文本到3D生成。 et.al.|[2408.01269](http://arxiv.org/abs/2408.01269)|null|
|**2024-08-02**|**CLIP4Sketch: Enhancing Sketch to Mugshot Matching through Dataset Augmentation using Diffusion Models**|法医草图与面部照片的匹配是人脸识别中一项具有挑战性的任务，主要受到注释法医草图稀缺以及草图和照片之间模态差异的阻碍。为了解决这个问题，我们提出了CLIP4Sketch，这是一种利用扩散模型生成大量不同草图图像的新方法，有助于提高面部识别系统在草图到面部照片匹配中的性能。我们的方法利用去噪扩散概率模型（DDPM）来生成对身份和风格进行显式控制的草图。我们结合了CLIP和Adaface对参考照片的嵌入，以及风格的文本描述，作为扩散模型的条件。我们通过生成与面部照片相对应的草图的综合数据集，并在我们的合成数据上训练面部识别模型，来证明我们的方法的有效性。我们的结果表明，与在现有的有限数量的真实人脸草图数据上进行训练相比，草图到面部照片的匹配精度有了显著提高，验证了扩散模型在提高跨模态人脸识别系统性能方面的潜力。我们还将我们的数据集与使用基于GAN的方法生成的数据集进行了比较，以展示其优越性。 et.al.|[2408.01233](http://arxiv.org/abs/2408.01233)|null|
|**2024-08-02**|**Origin of unexpected weak Gilbert damping in the LSMO/Pt bilayer system**|我们使用第一性原理计算和Wannier插值技术研究了La $_{0.7}$Sr$_{0.3}$MnO$_3$（LSMO）和La$_{0.7}$Sr$_{0.3}$MnO$_3$/Pt（LSMO/Pt）异质结构中的吉尔伯特阻尼。我们的工作受到最近实验观察的启发，这些观察表明，与参考单层LSMO薄膜相比，LSMO/Pt薄膜中的吉尔伯特阻尼较小，尽管人们期望前者具有增强的自旋泵浦效应。我们分析了电子结构和输运行为，发现LSMO薄膜具有高自旋霍尔角（$|{theta{\mathrm{SH}}|$）。然而，在LSMO/Pt中，铂的存在显著增加了纵向电导率，降低了$|theta{\mathrm{SH}|$。尽管$|theta_{\mathrm{SH}}|$较低，但由于自旋扩散长度较大，LSMO/Pt对吉尔伯特阻尼显示出显著的抗阻尼贡献。相比之下，如最近的一项实验所述，由于通过自诱导逆自旋霍尔效应（ISHE）进行有效的自旋到电荷转换，具有大$|theta{\mathrm{SH}|$ 的纯LSMO薄膜表现出更高的阻尼。最后，这项工作表明，通过微调自旋霍尔电导率与纵向电荷电导率的比率，即使在自旋轨道耦合较弱的情况下，也有可能设计出具有所需自旋到电荷或电荷到自旋转换效率的异质结构。 et.al.|[2408.01209](http://arxiv.org/abs/2408.01209)|null|
|**2024-08-02**|**Dipole orientation reveals single-molecule interactions and dynamics on 2D crystals**|在原位直接观察单分子相互作用和动态构型是一项艰巨的挑战，但对化学和生物系统都至关重要。然而，由于溶液中分子的快速扩散和反应系统的复杂性，依赖于体积测量的光学显微镜无法满足这些要求。在这项工作中，我们利用有机溶剂中原始六方氮化硼（h-BN）的荧光激活作为分子传感平台，将分子限制在二维（2D）界面并减缓其运动。通过偏振单分子定位显微镜（SMLM）测量荧光发射体的3D取向，同时实现了构象识别和动态跟踪。我们发现平面内发射体的取向与h-BN晶格的对称性一致，它们的构象受到h-BN局部条件和电化学环境调节的影响。此外，与固态发射体相比，荧光发射体在固液界面的横向扩散显示出更丰富的动力学。这项研究为同时进行分子构象和光物理测量打开了大门，有助于理解单分子水平的相互作用和通过二维材料的实时传感。 et.al.|[2408.01207](http://arxiv.org/abs/2408.01207)|null|
|**2024-08-02**|**Sustainable Diffusion-based Incentive Mechanism for Generative AI-driven Digital Twins in Industrial Cyber-Physical Systems**|工业网络物理系统（ICPS）是现代制造业和工业不可或缺的组成部分。通过在整个产品生命周期中数字化数据，ICP中的数字孪生（DT）实现了从当前工业基础设施到智能和自适应基础设施的转变。得益于数据处理能力，生成型人工智能（GAI）可以推动DT的构建和更新，以提高预测精度，为多样化的智能制造做好准备。然而，利用传感工业物联网（IIoT）设备共享数据以构建DT的机制易受逆向选择问题的影响。本文首先为ICPS开发了一种GAI驱动的DT架构。为了解决信息不对称引起的逆向选择问题，我们提出了一个契约理论模型，并开发了基于可持续扩散的软行动者批评算法来识别最优可行契约。具体来说，我们利用动态结构化剪枝技术来减少参与者网络的参数数量，从而实现所提出算法的可持续性和高效性。最后，数值结果证明了所提出方案的有效性。 et.al.|[2408.01173](http://arxiv.org/abs/2408.01173)|null|
|**2024-08-02**|**Machine learning topological energy braiding of non-Bloch bands**|机器学习已被用于识别各种物理系统中的相变。然而，关于非厄米系统中的非布洛赫能量编织，目前还缺乏相关研究。在这项工作中，我们使用无监督和有监督的方法研究了一维非厄米系统中的非布洛赫能量编织。在无监督学习中，我们使用扩散图在没有任何先验知识的情况下成功识别非布洛赫能量编织，并将其与k-means相结合，将不同的拓扑元素聚类成簇，如Unlink和Hopf link。在监督学习中，我们基于布洛赫能量数据训练了一个卷积神经网络（CNN），不仅可以预测布洛赫能量编织，还可以预测非布洛赫能量针织，准确率接近100%。通过分析CNN，我们可以确定该网络已经成功地获得了识别能带编织拓扑的能力。本研究展示了机器学习在识别非厄米拓扑相和能量编织方面的巨大潜力。 et.al.|[2408.01141](http://arxiv.org/abs/2408.01141)|null|
|**2024-08-02**|**Inverse Raman scattering and the diffuse interstellar bands: an exploration of the systemic interconnections between spontaneous and inverse Raman scattering and extended red emission, Red Rectangle bands, and diffuse interstellar bands**|逆拉曼散射（IRS）于1964年首次被发现，是一种非线性受激现象，在预期拉曼发射的地方诱导拉曼散射吸收。虽然IRS不如受激拉曼散射（SRS）和相干反斯托克斯拉曼散射（CARS）为人所知，但这项研究强调了它在分析HI星际云中遥远背景恒星光谱方面的意义。具体来说，在共生恒星和星云的光谱中，通常在宽散射角下观察到的由氢原子拉曼散射的紫外发射线应在背景恒星的光谱中表现为IRS吸收特征。我证明了所有已知的H-alpha波长区域的星际拉曼散射发射线都是在吸收过程中被检测到的，在红恒星的光谱中是弥漫的星际带（DIB），并得出结论，氢原子的IRS解决了产生这些带过程中长期存在的难题，也许也解释了同样神秘的2200A紫外消光曲线凸起。将DIB识别为IRS HI吸收，为DIB与红色矩形星云发射带（RRBs）之间复杂的关系提供了新的线索。探测DIB的条件突显了在观测HI星际物质时考虑观察者、HI介质和照明辐射场方向（即观测的几何形状）之间的物理关系的重要性。在辐射场方向或其侧面进行观察，可以确定是否会观察到IRS，产生DIB和2200A凸起，或在宽散射角下的自发拉曼散射，导致ERE、拉曼散射发射线（包括RRB）和未识别的红外带。 et.al.|[2408.01103](http://arxiv.org/abs/2408.01103)|null|

<p align=right>(<a href=#updated-on-20240806>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-08-01**|**Neural Octahedral Field: Octahedral prior for simultaneous smoothing and sharp edge regularization**|神经隐式表示，将距离函数参数化为坐标神经场，已成为解决无方向点云表面重建的有前景的前沿。为了确保方向一致，现有的方法侧重于正则化距离函数的梯度，例如将其约束为单位范数，最小化其散度，或将其与对应于零特征值的Hessian特征向量对齐。然而，在存在大扫描噪声的情况下，它们往往要么过拟合噪声输入，要么产生过于平滑的重建。在这项工作中，我们建议利用六面体网格中产生的八面体框架的球谐表示，在一种新的神经场变体——八面体场下指导曲面重建。当约束为平滑时，该字段会自动捕捉到几何特征，并在折痕上插值时自然保留锐角。通过同时拟合和平滑隐式几何旁边的八面体场，它的行为类似于双边滤波，从而在保持锐边的同时实现平滑重建。尽管是纯逐点操作，但我们的方法在广泛的实验中表现优于各种传统和神经方法，并且与需要正常和数据先验的方法非常有竞争力。我们的全面实施可在以下网址获得：https://github.com/Ankbzpx/frame-field. et.al.|[2408.00303](http://arxiv.org/abs/2408.00303)|null|
|**2024-07-30**|**Neural Fields for Continuous Periodic Motion Estimation in 4D Cardiovascular Imaging**|时间分辨三维血流MRI（4D血流MRI）提供了一种独特的非侵入性解决方案，用于可视化和量化主动脉弓等血管中的血流动力学。然而，由于难以获得完整的周期分割，目前大多数动脉4D血流MRI分析方法使用静态动脉壁。为了克服这一局限性，我们提出了一种基于神经场的方法，可以直接估计整个心动周期中连续的周期性壁变形。对于3D+时间成像数据集，我们优化了表示时间依赖速度矢量场（VVF）的隐式神经表示（INR）。ODE求解器用于将VVF集成到变形矢量场（DVF）中，该矢量场可以随着时间的推移使图像、分割掩模或网格变形，从而可视化和量化局部壁运动模式。为了正确反映3D+时间心血管数据的周期性，我们以两种方式施加周期性。首先，通过定期对输入到INR的时间进行编码，从而对VVF进行编码。其次，通过规范DVF。我们证明了这种方法在不同周期模式的合成数据、心电图门控CT和4D血流MRI数据上的有效性。所获得的方法可用于改进4D血流MRI分析。 et.al.|[2407.20728](http://arxiv.org/abs/2407.20728)|null|
|**2024-07-29**|**Aero-Nef: Neural Fields for Rapid Aircraft Aerodynamics Simulations**|本文提出了一种基于隐式神经表示（INR）在网格域上学习稳态流体动力学模拟替代模型的方法。所提出的模型可以直接应用于不同流动条件下的非结构化域，处理非参数3D几何变化，并推广到测试时看不见的形状。基于坐标的公式自然会导致离散化的鲁棒性，从而在计算成本（内存占用和训练时间）和精度之间实现了极好的权衡。该方法在两个工业相关应用中得到了验证：跨音速翼型上二维可压缩流的RANS数据集和三维机翼上表面压力分布的数据集，包括形状、流入条件和控制表面偏转变化。在所考虑的测试用例中，与最先进的图神经网络架构相比，我们的方法实现了三倍多的测试误差，并显著改善了看不见的几何形状的泛化误差。值得注意的是，该方法在RANS跨音速翼型数据集上的推理速度比高保真求解器快五个数量级。代码可在以下网址获得https://gitlab.isae-supaero.fr/gi.catalani/aero-nepf et.al.|[2407.19916](http://arxiv.org/abs/2407.19916)|null|
|**2024-07-26**|**ObjectCarver: Semi-automatic segmentation, reconstruction and separation of 3D objects**|隐式神经场在从多幅图像重建3D表面方面取得了显著进展；然而，在分离场景中的单个对象时，他们遇到了挑战。之前的工作试图通过引入一个框架来解决这个问题，该框架为N个对象中的每一个同时训练单独的带符号距离场（SDF），并使用正则化项来防止对象重叠。然而，所有这些方法都需要提供分割掩模，这并不总是容易获得的。我们介绍了我们的方法ObjectCarver，来解决在单个视图中从点击输入中分离对象的问题。给定摆出的多视图图像和一组用户输入点击来提示分割单个对象，我们的方法将场景分解为单独的对象，并为每个对象重建高质量的3D表面。我们引入了一个损失函数，可以防止漂浮物，避免因遮挡而造成不适当的雕刻。此外，我们引入了一种新的场景初始化方法，与之前的方法相比，该方法在保留几何细节的同时显著加快了过程。尽管不需要地面真实掩模或单眼线索，但我们的方法在定性和定量上都优于基线。此外，我们引入了一个新的基准数据集进行评估。 et.al.|[2407.19108](http://arxiv.org/abs/2407.19108)|null|
|**2024-07-24**|**Neural field equations with time-periodic external inputs and some applications to visual processing**|这项工作的目的是为研究视觉处理任务中的闪烁输入提供一个数学框架。当与几何图案结合时，这些输入会影响并诱发有趣的心理物理现象，如麦凯效应和比洛克-邹效应，在这些效应中，受试者感知到通常由闪烁频率调制的特定余像。由于输入的对称破缺结构，经典分叉理论和多尺度分析技术在我们的背景下不是很有效。因此，我们采用了一种基于Amari型神经场控制理论的输入-输出框架的方法。这使我们能够证明，当受到周期性输入的驱动时，动态会收敛到周期性状态。此外，我们研究了在哪些假设下，这些非线性动力学可以有效地线性化，在这种情况下，我们提出了短程兴奋性和远程抑制性神经元相互作用的积分核的精确近似值。最后，对于集中在具有闪烁背景的视野中心的输入，我们直接将余像中出现的虚幻轮廓的宽度与闪烁频率和抑制强度联系起来。 et.al.|[2407.17294](http://arxiv.org/abs/2407.17294)|null|
|**2024-07-23**|**Fluorescence Diffraction Tomography using Explicit Neural Fields**|从荧光图像中求解3D折射率（RI）可以提供有关生物样本的荧光和相位信息。然而，在大体积、高分辨率和反射模式下准确检索部分相干光的相位以重建无标签相位物体的未知RI仍然具有挑战性。为了应对这一挑战，我们开发了具有显式神经场的荧光衍射断层扫描（FDT），可以从散焦荧光散斑图像重建3D RI。使用FDT成功重建3D RI依赖于四个关键组件：粗到细建模、自校准、差分多层渲染模型和部分相干掩模。具体而言，显式表示与粗到细建模有效地集成在一起，以实现高速、高分辨率的重建。此外，我们将多层方程推进到微分多层渲染模型，这使得系统的外部和内部参数能够进行自校准。自校准有助于高精度的正向图像预测和RI重建。部分相干掩模是数字掩模，用于准确有效地解决相干光模型和部分相干光数据之间的差异。FDT成功地从荧光图像中重建了24个z $层上1024$×1024像素的530$×530$×300$μm^3$ 体积的3D培养无标记3D MuSCs管的RI，证明了在体外对体积庞大和异质的生物样本进行高保真3D RI重建。 et.al.|[2407.16657](http://arxiv.org/abs/2407.16657)|null|
|**2024-07-22**|**Iterative approach to reconstructing neural disparity fields from light-field data**|本研究提出了一种神经视差场（NDF），该场基于神经场建立了场景视差的隐式连续表示，并采用迭代方法解决了从光场数据重建NDF的逆问题。NDF能够无缝和精确地表征三维场景中的视差变化，并可以以任何任意分辨率对视差进行离散化，克服了传统视差图容易出现采样误差和插值不准确的局限性。所提出的NDF网络架构利用哈希编码结合多层感知器来捕获纹理级别的详细差异，从而增强其表示复杂场景几何信息的能力。通过利用光场数据中固有的空间角度一致性，开发了一种可微分正向模型，用于从光场数据生成中心视图图像。基于正向模型，建立了一种使用可微传播算子的NDF重建逆问题的优化方案。此外，在优化方案中，采用迭代求解方法重建NDF，该方法不需要训练数据集，适用于各种采集方法捕获的光场数据。实验结果表明，使用所提出的方法可以从光场数据中重建高质量的NDF。NDF可以有效地恢复高分辨率视差，证明了其隐式、连续表示场景视差的能力。 et.al.|[2407.15380](http://arxiv.org/abs/2407.15380)|null|
|**2024-07-19**|**Contextual modulation of language comprehension in a dynamic neural model of lexical meaning**|我们提出并计算实现了一个词汇意义的动态神经模型，并对其行为预测进行了实验测试。我们使用英语词汇“have”作为测试用例来演示模型的架构和行为，重点关注其多义词的使用。在该模型中，“have”映射到由两个连续的概念维度（连通性和控制不对称性）定义的语义空间，这两个维度之前被提出用于参数化语言的概念系统。映射被建模为表示词条的神经节点和表示概念维度的神经场之间的耦合。虽然词汇知识被建模为稳定的耦合模式，但实时词汇意义检索被建模为神经激活模式在对应于语义解释或阅读的亚稳态之间的运动。模型模拟捕捉到了两个先前报道的实证观察结果：（1）词汇语义解释的语境调制，以及（2）这种调制幅度的个体差异。模拟还产生了一种新的预测，即句子阅读时间和可接受性之间的试验关系应该根据上下文进行调节。结合自定进度阅读和可接受性判断的实验复制了之前的结果，并证实了新的模型预测。总之，研究结果支持了一种关于词汇多义的新观点：一个词的许多相关含义是亚稳态的神经激活状态，这是由控制连续语义维度解释的神经群体的非线性动力学引起的。 et.al.|[2407.14701](http://arxiv.org/abs/2407.14701)|null|
|**2024-07-18**|**MeshFeat: Multi-Resolution Features for Neural Fields on Meshes**|参数特征网格编码作为神经场的编码方法受到了广泛关注，因为它们允许更小的MLP，这大大缩短了模型的推理时间。在这项工作中，我们提出了MeshFeat，这是一种针对网格量身定制的参数特征编码，为此我们采用了欧几里德空间的多分辨率特征网格的思想。我们从给定顶点拓扑提供的结构开始，使用网格简化算法直接在网格上构建多分辨率特征表示。该方法允许在网格上的神经场中使用小MLP，与之前的表示相比，我们显示出显著的加速，同时保持了纹理重建和BRDF表示的可比重建质量。鉴于其与顶点的内在耦合，该方法特别适用于变形网格上的表示，使其非常适合对象动画。 et.al.|[2407.13592](http://arxiv.org/abs/2407.13592)|null|
|**2024-07-16**|**Adaptive Environment-Aware Robotic Arm Reaching Based on a Bio-Inspired Neurodynamical Computational Framework**|仿生机器人系统具有自适应学习、可扩展控制和高效信息处理的能力。为这些系统提供实时决策对于应对环境的动态变化至关重要。我们专注于在开放区域使用带有鸟瞰摄像头的机器人六自由度操纵器进行动态目标跟踪，并部署神经动力学计算框架（NeuCF）进行视觉反馈。NeuCF是最近开发的一种基于动态神经场（DNF）和随机最优控制（SOC）理论的仿生目标跟踪模型。它已经过训练，可以在平面上对局部视觉信标进行到达动作，并且可以根据环境的变化（例如，出现了新的目标，或者删除了现有的目标）实时重新定位或生成停止信号。我们在各种目标达成场景下评估了我们的系统。在所有实验中，与基线三次多项式轨迹生成器相比，NeuCF具有较高的末端执行器位置精度，生成了平滑的轨迹，并提供了更短的路径长度。总之，开发的系统提供了一种强大的、动态感知的机器人操纵方法，可以提供实时决策。 et.al.|[2407.11377](http://arxiv.org/abs/2407.11377)|null|

<p align=right>(<a href=#updated-on-20240806>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

