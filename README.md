[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.09.25
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-09-24**|**Semantics-Controlled Gaussian Splatting for Outdoor Scene Reconstruction and Rendering in Virtual Reality**|高斯散点（GS）等3D渲染技术的进步允许在虚拟现实（VR）中进行新颖的视图合成和实时渲染。然而，GS创建的3D环境通常很难编辑。对于场景增强或合并3D资源，按类分割高斯分布是必不可少的。现有的分割方法通常仅限于某些类型的场景，例如“圆形”场景，以确定清晰的对象边界。然而，在非“循环”场景（如大型室外场景）中删除大型物体时，这种方法是无效的。我们提出了语义控制GS（SCGS），这是一种分段驱动的GS方法，能够在不受控制的自然环境中分离大型场景部分。SCGS允许对VR进行场景编辑和提取场景部分。此外，我们引入了一个具有挑战性的室外数据集，克服了“循环”设置。我们在数据集的视觉质量和3D-OVS数据集的分割质量方面都优于最先进的技术。我们进行了一项探索性用户研究，将360度视频、普通GS和VR中的SCGS与固定视点进行了比较。在我们随后的主要研究中，允许用户自由移动，评估普通GS和SCGS。我们的主要研究结果表明，参与者明显更喜欢SCGS而不是普通GS。我们总体上提出了一种创新的方法，在技术和用户体验方面都超越了最先进的水平。 et.al.|[2409.15959](http://arxiv.org/abs/2409.15959)|null|
|**2024-09-24**|**Disentangled Generation and Aggregation for Robust Radiance Fields**|近年来，基于三平面的辐射场的利用引起了人们的关注，因为它能够以高质量的表示和低计算成本有效地分离3D场景。该方法的一个关键要求是精确输入相机姿态。然而，由于三平面的局部更新特性，与之前的联合姿态NeRF优化类似的联合估计很容易导致局部最小值。为此，我们提出了解耦三平面生成模块，将全局特征上下文和平滑度引入三平面学习，从而减轻了局部更新引起的误差。然后，我们提出了解耦平面聚合来减轻相机姿态更新过程中常见的三平面特征聚合引起的纠缠。此外，我们引入了一种两阶段热启动训练策略，以减少由三平面生成器引起的隐式约束。定量和定性结果表明，我们提出的方法在具有噪声或未知相机姿态的新型视图合成中取得了最先进的性能，并实现了高效的优化收敛。项目页面：https://gaohchen.github.io/DiGARR/. et.al.|[2409.15715](http://arxiv.org/abs/2409.15715)|null|
|**2024-09-23**|**AgriNeRF: Neural Radiance Fields for Agriculture in Challenging Lighting Conditions**|神经辐射场（NeRF）在3D场景重建和新颖的视图合成方面显示出巨大的前景。在农业环境中，NeRF可以作为数字双胞胎，为农民提供有关水果检测的关键信息，用于产量估算和其他重要指标。然而，传统的NeRF对具有挑战性的照明条件（如低光、极亮的光和变化的照明）并不稳健。为了解决这些问题，这项工作利用了三种不同的传感器：RGB相机、事件相机和热像仪。我们的RGB场景重建显示，PSNR和SSIM分别提高了+2.06 dB和+8.3%。我们的交叉光谱场景重建使mAP50的下游水果检测提高了+43.0%，mAP50-95提高了+61.1%。额外传感器的集成带来了更强大和信息量更大的NeRF。我们证明，我们的多模态系统在各种树冠覆盖和一天中的不同时间产生了高质量的照片级逼真重建。这项工作的结果是开发了一种有弹性的NeRF，能够在明显退化的情况下表现良好，以及一种用于自动水果检测的学习交叉光谱表示。 et.al.|[2409.15487](http://arxiv.org/abs/2409.15487)|null|
|**2024-09-23**|**SpikeGS: Learning 3D Gaussian Fields from Continuous Spike Stream**|尖峰相机是一种专用的高速视觉传感器，与传统的帧相机相比，它具有高时间分辨率和高动态范围等优点。这些特征为相机在许多计算机视觉任务中提供了显著的优势。然而，基于尖峰相机的3D重建和新型视图合成的任务仍然不发达。尽管有从尖峰流中学习神经辐射场的现有方法，但它们要么在极其嘈杂、低质量的光照条件下缺乏鲁棒性，要么由于神经辐射场中使用的深度全连接神经网络和光线行进渲染策略，计算复杂度很高，难以恢复精细的纹理细节。相比之下，3DGS的最新进展通过将点云表示优化为高斯椭球体实现了高质量的实时渲染。在此基础上，我们介绍了SpikeGS，这是第一种仅从尖峰流中学习3D高斯场的方法。我们设计了一个基于3DGS的可微分尖峰流渲染框架，结合了噪声嵌入和尖峰神经元。通过利用3DGS的多视图一致性和基于图块的多线程并行渲染机制，我们实现了高质量的实时渲染结果。此外，我们引入了一个尖峰渲染损失函数，该函数在不同的光照条件下具有通用性。我们的方法可以从移动尖峰相机捕获的连续尖峰流中重建具有精细纹理细节的视图合成结果，同时在极其嘈杂的低光场景中表现出很高的鲁棒性。在真实和合成数据集上的实验结果表明，我们的方法在渲染质量和速度方面超越了现有的方法。我们的代码将在https://github.com/520jz/SpikeGS. et.al.|[2409.15176](http://arxiv.org/abs/2409.15176)|null|
|**2024-09-23**|**FusionRF: High-Fidelity Satellite Neural Radiance Fields from Multispectral and Panchromatic Acquisitions**|我们介绍了FusionRF，这是一种基于光学未处理卫星图像的新型神经渲染地形重建方法。虽然以前的方法依赖于外部泛色法来融合低分辨率多光谱图像和高分辨率全色图像，但FusionRF直接在没有先验知识的情况下基于光学未处理的采集进行重建。这是通过添加一个锐化内核来实现的，该内核对多光谱图像中的分辨率损失进行建模。此外，新颖的模态嵌入允许模型执行图像融合，这是新颖视图合成的瓶颈。我们在不同位置对WorldView-3卫星的多光谱和全色卫星图像进行了评估，FusionRF在未处理图像的深度重建、渲染清晰的训练和新颖的视图以及保留多光谱信息方面优于之前的最先进方法。 et.al.|[2409.15132](http://arxiv.org/abs/2409.15132)|null|
|**2024-09-23**|**AIM 2024 Sparse Neural Rendering Challenge: Methods and Results**|本文回顾了稀疏神经渲染的挑战，这是与ECCV 2024联合举办的图像处理进展（AIM）研讨会的一部分。本文重点介绍了比赛设置、提出的方法及其各自的结果。该挑战旨在从稀疏图像观测中生成不同场景的新颖相机视图合成。它由两条轨道组成，具有不同程度的稀疏性；Track 1中有3个视图（非常稀疏），Track 2中有9个视图（稀疏）。参与者被要求优化通过峰值信噪比（PSNR）度量测量的地面实况图像的客观保真度。对于这两个轨道，我们使用新引入的稀疏渲染（SpaRe）数据集和流行的DTU MVS数据集。在本次挑战中，5支队伍向Track 1提交了最终成绩，4支队伍向Track2提交了最终结果。提交的模型多种多样，突破了稀疏神经渲染的最新技术。本文详细描述了在挑战中开发的所有模型。 et.al.|[2409.15045](http://arxiv.org/abs/2409.15045)|null|
|**2024-09-23**|**AIM 2024 Sparse Neural Rendering Challenge: Dataset and Benchmark**|可微分和神经渲染的最新发展在各种2D和3D任务中取得了令人印象深刻的突破，例如新颖的视图合成、3D重建。通常，可微分渲染依赖于场景的密集视点覆盖，这样几何体就可以单独从外观观察中消除歧义。当只有少数输入视图可用时，会出现一些挑战，通常称为稀疏或少镜头神经渲染。由于这是一个约束不足的问题，大多数现有方法都引入了正则化的使用，以及各种学习和手工制作的先验。稀疏渲染文献中反复出现的一个问题是缺乏同质、最新的数据集和评估协议。虽然高分辨率数据集是密集重建文献中的标准，但稀疏渲染方法通常使用低分辨率图像进行评估。此外，不同手稿之间的数据分割不一致，测试地面真实图像通常是公开的，这可能会导致过度拟合。在这项工作中，我们提出了稀疏渲染（SpaRe）数据集和基准测试。我们引入了一个遵循DTU MVS数据集设置的新数据集。该数据集由97个基于合成高质量资产的新场景组成。每个场景最多有64个相机视图和7个照明配置，以1600x1200分辨率渲染。我们发布了82个场景的训练分割，以培养可推广的方法，并为验证和测试集提供了一个在线评估平台，其真实图像保持隐藏。我们提出了两种不同的稀疏配置（分别为3幅和9幅输入图像）。这为可重复评估提供了一个强大而方便的工具，并使研究人员能够轻松访问具有最先进绩效评分的公共排行榜。可用网址：https://sparebenchmark.github.io/ et.al.|[2409.15041](http://arxiv.org/abs/2409.15041)|null|
|**2024-09-22**|**MVPGS: Excavating Multi-view Priors for Gaussian Splatting from Sparse Input Views**|最近，神经辐射场（NeRF）的进步促进了少镜头新视图合成（NVS），这是3D视觉应用中的一个重大挑战。尽管多次尝试降低NeRF中的密集输入要求，但它仍然受到耗时的训练和渲染过程的困扰。最近，3D高斯散斑（3DGS）通过显式的基于点的表示实现了实时高质量的渲染。然而，与NeRF类似，由于缺乏约束，它往往会过度拟合训练视图。在本文中，我们提出了\textbf{MVPGS}，这是一种基于3D高斯散斑挖掘多视图先验的少镜头NVS方法。我们利用最近基于学习的多视图立体（MVS）来提高3DGS的几何初始化质量。为了减轻过拟合，我们提出了一种基于计算几何的前向扭曲方法，用于符合场景的额外外观约束。此外，我们为高斯参数引入了视图一致的几何约束，以促进适当的优化收敛，并利用单目深度正则化作为补偿。实验表明，该方法在实时渲染速度方面达到了最先进的性能。项目页面：https://zezeaaa.github.io/projects/MVPGS/ et.al.|[2409.14316](http://arxiv.org/abs/2409.14316)|null|
|**2024-09-19**|**GStex: Per-Primitive Texturing of 2D Gaussian Splatting for Decoupled Appearance and Geometry Modeling**|高斯飞溅在视图合成和场景重建方面表现出了出色的性能。该表示通过优化场景中数千到数百万个2D或3D高斯图元的位置、比例、颜色和不透明度来实现逼真的质量。然而，由于每个高斯基元都编码外观和几何体，因此这些属性是强耦合的——因此，即使场景几何体很简单（例如，对于纹理平面），高保真外观建模也需要大量的高斯基元。我们建议对每个2D高斯基元进行纹理处理，这样即使是单个高斯基元也可以用来捕捉外观细节。通过采用每基元纹理，我们的外观表示与场景几何体的拓扑结构和复杂性无关。我们证明，我们的方法GStex在纹理高斯斑点方面比之前的工作产生了更好的视觉质量。此外，我们证明，与2D高斯散点相比，当减少高斯基元的数量时，我们的解耦能够提高新颖的视图合成性能，并且GStex可用于场景外观编辑和重新纹理化。 et.al.|[2409.12954](http://arxiv.org/abs/2409.12954)|null|
|**2024-09-24**|**GaRField++: Reinforced Gaussian Radiance Fields for Large-Scale 3D Scene Reconstruction**|本文提出了一种基于3D高斯飞溅（3DGS）的大规模场景重建新框架，旨在解决现有方法面临的可扩展性和准确性挑战。为了解决可扩展性问题，我们将大型场景拆分为多个单元，并通过基于可见性的相机选择和渐进式点云扩展将每个单元的候选点云和相机视图相关联。为了提高渲染质量，与vanilla 3DGS相比，进行了三项突出的改进，即光线高斯交集策略和用于学习效率的新型高斯密度控制，基于ConvKAN网络的外观解耦模块，用于解决大规模场景中的不均匀光照条件，以及具有颜色损失、深度失真损失和正常一致性损失的精细最终损失。最后，执行无缝拼接过程以合并单个高斯辐射场，从而在不同单元之间进行新的视图合成。对Mill19、Urban3D和MatrixCity数据集的评估表明，我们的方法始终比最先进的大规模场景重建方法生成更高保真的渲染结果。我们通过在商业无人机记录的自收集视频片段上进行渲染，进一步验证了所提出方法的可推广性。 et.al.|[2409.12774](http://arxiv.org/abs/2409.12774)|null|

<p align=right>(<a href=#updated-on-20240925>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-09-24**|**Age of Gossip in Networks with Multiple Views of a Source**|我们考虑网络中的信息版本年龄（AoI），其中节点子集充当感测节点，对通常可以遵循连续分布的源进行采样。源的任何样本都构成了信息的新版本，信息的版本年龄是根据整个网络可用信息的最新版本定义的。我们推导出了节点不同子集之间的平均版本AoI的递归表达式，可用于评估包括任何单个节点在内的任何节点子集的平均版本AoI。我们推导了各种拓扑结构（包括线、环和全连接网络）在网络任何单个节点上的平均AoI的渐近行为。Yates关于网络版本年龄的现有技术结果[ISIT'21]在我们的推导中可以被解释为具有单一源视图的网络，例如通过速率为 $\lambda_{00}$的泊松过程。我们的结果表明，通过分割相同的速率$\lambda_{00}$，将源的单个视图替换为跨多个节点的分布式感知，平均版本AoI性能没有损失。特别地，我们证明，对于全连接和环形网络，平均AoI分别渐近地缩放为$O（\log（n））$和$O（\sqrt{n}）$。更有趣的是，我们表明，对于环形网络，如果感测节点的数量仅随$O（\sqrt{n}）$而不是需要$O（n）$的先前已知结果缩放，则分布式感测在平均AoI上仍然可以实现相同的$O（$sqrt{n}）$渐近性能。我们的结果表明，只要连续非感测节点的最大数量也缩放为$O（\sqrt{n}）$ ，就可以任意选择感测节点。 et.al.|[2409.16285](http://arxiv.org/abs/2409.16285)|null|
|**2024-09-24**|**AIR-Embodied: An Efficient Active 3DGS-based Interaction and Reconstruction Framework with Embodied Large Language Model**|3D重建和神经渲染的最新进展增强了高质量数字资产的创建，但现有的方法很难在不同的对象形状、纹理和遮挡之间进行推广。虽然次优视图（NBV）规划和基于学习的方法提供了解决方案，但它们往往受到预定义标准的限制，无法用人类的常识来管理遮挡。为了解决这些问题，我们提出了AIR Embodied，这是一种新的框架，将嵌入的AI代理与大规模预训练的多模态语言模型集成在一起，以改进主动3DGS重建。AIR Embodied采用了一个三阶段过程：通过多模态提示了解当前的重建状态，通过视点选择和交互动作规划任务，并采用闭环推理来确保准确执行。代理根据计划结果和实际结果之间的差异动态改进其操作。在虚拟和现实世界环境中的实验评估表明，AIR Embodied显著提高了重建效率和质量，为主动3D重建中的挑战提供了一个稳健的解决方案。 et.al.|[2409.16019](http://arxiv.org/abs/2409.16019)|null|
|**2024-09-23**|**Matérn Kernels for Tunable Implicit Surface Reconstruction**|我们建议使用Mat'ern核家族进行可调隐式曲面重建，以最近成功的定向点云三维重建核方法为基础。正如我们所展示的，从理论和实践的角度来看，Mat'ern核都有一些吸引人的特性，使其特别适合曲面重建——优于基于弧余弦核的最先进方法，同时更容易实现、计算更快、可扩展。由于是平稳的，我们证明了Mat'ern核'光谱可以以与傅里叶特征映射相同的方式进行调整，以帮助基于坐标的MLP克服光谱偏差。此外，我们从理论上分析了Mat'ern核与SIREN网络的连接，以及它与以前使用的弧余弦核的关系。最后，基于最近引入的神经核域，我们提出了数据依赖的Mat'ern核，并得出结论，特别是拉普拉斯核（作为Mat'ern家族的一部分）具有极强的竞争力，在无噪声的情况下，其性能几乎与最先进的方法相当，同时训练时间缩短了五倍以上。 et.al.|[2409.15466](http://arxiv.org/abs/2409.15466)|**[link](https://github.com/mweiherer/matern-surface-reconstruction)**|
|**2024-09-23**|**ReLoo: Reconstructing Humans Dressed in Loose Garments from Monocular Video in the Wild**|虽然前几年在从单眼视频中重建人类的3D方面取得了很大进展，但很少有最先进的方法能够处理在关节运动过程中表现出较大非刚性表面变形的宽松服装。这限制了这种方法在穿着标准裤子或T恤的人身上的应用。我们的方法ReLoo克服了这一局限性，从野生视频中的单眼重建了穿着宽松衣服的人的高质量3D模型。为了解决这个问题，我们首先建立了一个分层的神经人体表示，将穿着衣服的人分解为神经内体和外衣。在分层神经表示的基础上，我们进一步为服装层引入了一个可以自由移动的非分层虚拟骨变形模块，这使得非刚性变形的宽松服装能够准确恢复。全局优化通过多层可微体绘制联合优化人体和服装的形状、外观和变形。为了评估ReLoo，我们在多视图捕捉工作室中记录了具有动态变形服装的主题。对现有数据集和我们的新数据集的评估表明，ReLoo在室内数据集和野外视频上都明显优于现有技术。 et.al.|[2409.15269](http://arxiv.org/abs/2409.15269)|null|
|**2024-09-23**|**SpikeGS: Learning 3D Gaussian Fields from Continuous Spike Stream**|尖峰相机是一种专用的高速视觉传感器，与传统的帧相机相比，它具有高时间分辨率和高动态范围等优点。这些特征为相机在许多计算机视觉任务中提供了显著的优势。然而，基于尖峰相机的3D重建和新型视图合成的任务仍然不发达。尽管有从尖峰流中学习神经辐射场的现有方法，但它们要么在极其嘈杂、低质量的光照条件下缺乏鲁棒性，要么由于神经辐射场中使用的深度全连接神经网络和光线行进渲染策略，计算复杂度很高，难以恢复精细的纹理细节。相比之下，3DGS的最新进展通过将点云表示优化为高斯椭球体实现了高质量的实时渲染。在此基础上，我们介绍了SpikeGS，这是第一种仅从尖峰流中学习3D高斯场的方法。我们设计了一个基于3DGS的可微分尖峰流渲染框架，结合了噪声嵌入和尖峰神经元。通过利用3DGS的多视图一致性和基于图块的多线程并行渲染机制，我们实现了高质量的实时渲染结果。此外，我们引入了一个尖峰渲染损失函数，该函数在不同的光照条件下具有通用性。我们的方法可以从移动尖峰相机捕获的连续尖峰流中重建具有精细纹理细节的视图合成结果，同时在极其嘈杂的低光场景中表现出很高的鲁棒性。在真实和合成数据集上的实验结果表明，我们的方法在渲染质量和速度方面超越了现有的方法。我们的代码将在https://github.com/520jz/SpikeGS. et.al.|[2409.15176](http://arxiv.org/abs/2409.15176)|null|
|**2024-09-23**|**AIM 2024 Sparse Neural Rendering Challenge: Dataset and Benchmark**|可微分和神经渲染的最新发展在各种2D和3D任务中取得了令人印象深刻的突破，例如新颖的视图合成、3D重建。通常，可微分渲染依赖于场景的密集视点覆盖，这样几何体就可以单独从外观观察中消除歧义。当只有少数输入视图可用时，会出现一些挑战，通常称为稀疏或少镜头神经渲染。由于这是一个约束不足的问题，大多数现有方法都引入了正则化的使用，以及各种学习和手工制作的先验。稀疏渲染文献中反复出现的一个问题是缺乏同质、最新的数据集和评估协议。虽然高分辨率数据集是密集重建文献中的标准，但稀疏渲染方法通常使用低分辨率图像进行评估。此外，不同手稿之间的数据分割不一致，测试地面真实图像通常是公开的，这可能会导致过度拟合。在这项工作中，我们提出了稀疏渲染（SpaRe）数据集和基准测试。我们引入了一个遵循DTU MVS数据集设置的新数据集。该数据集由97个基于合成高质量资产的新场景组成。每个场景最多有64个相机视图和7个照明配置，以1600x1200分辨率渲染。我们发布了82个场景的训练分割，以培养可推广的方法，并为验证和测试集提供了一个在线评估平台，其真实图像保持隐藏。我们提出了两种不同的稀疏配置（分别为3幅和9幅输入图像）。这为可重复评估提供了一个强大而方便的工具，并使研究人员能够轻松访问具有最先进绩效评分的公共排行榜。可用网址：https://sparebenchmark.github.io/ et.al.|[2409.15041](http://arxiv.org/abs/2409.15041)|null|
|**2024-09-21**|**ExFMan: Rendering 3D Dynamic Humans with Hybrid Monocular Blurry Frames and Events**|近年来，随着神经渲染技术的出现，从单眼视频中重建动态人体的3D技术取得了巨大进展。该任务具有广泛的应用，包括为虚拟现实（VR）环境创建虚拟角色。然而，当单眼视频受到运动模糊的影响时，重建清晰的人类仍然具有挑战性，特别是由人类快速运动（例如跑步、跳舞）引起的运动模糊，这在野外经常发生。这导致渲染的3D人体的形状和外观明显不一致，特别是在快速运动的模糊区域，例如手和腿。在这篇论文中，我们提出了ExFMan，这是第一个神经渲染框架，它揭示了使用基于混合帧的RGB和仿生事件相机在快速运动中渲染高质量人类的可能性。“开箱即用”的见解是以互补的方式利用事件数据的高时间信息，并根据渲染的人类速度自适应地重新加权RGB帧和局部区域事件的损失影响。这显著减轻了与RGB帧中的运动模糊相关的不一致性。具体来说，我们首先在规范空间中构建3D身体的速度场，并将其渲染到图像空间中，以识别具有运动模糊的身体部位。然后，我们提出了两种新的损失，即速度感知光度损失和速度相对事件损失，以在估计速度的指导下优化两种模态的神经人。此外，我们引入了新的姿态正则化和阿尔法损失，以促进连续姿态和清晰边界。对合成和真实世界数据集的广泛实验表明，ExFMan可以重建更清晰、更高质量的人类。 et.al.|[2409.14103](http://arxiv.org/abs/2409.14103)|null|
|**2024-09-20**|**Tactile Neural De-rendering**|触觉传感已被证明是增强机器人感知的宝贵工具，特别是在视觉数据有限或不可用的情况下。然而，使用触觉数据进行姿态估计的传统方法通常依赖于传感器力学的复杂建模或接触贴片的估计，这可能很麻烦，而且具有固有的确定性。在这项工作中，我们介绍了触觉神经去渲染，这是一种利用生成模型仅基于物体的触觉特征重建物体局部3D表示的新方法。通过将对象渲染为嵌入指尖的虚拟相机所感知的对象，我们的方法提供了更直观、更灵活的触觉数据表示。这种3D重建不仅有助于精确的姿态估计，还可以量化不确定性，为机器人中基于触觉的感知提供了一个强大的框架。 et.al.|[2409.13923](http://arxiv.org/abs/2409.13923)|null|
|**2024-09-20**|**Occupancy-Based Dual Contouring**|我们介绍了一种双轮廓方法，该方法为占用功能提供了最先进的性能，同时实现了几秒钟的计算时间。我们的方法是免费学习，精心设计，以最大限度地利用GPU并行化。最近隐式神经表示的激增引起了人们对占用场的极大关注，从而产生了基于它们的各种3D重建和生成方法。然而，由于将生成的占用函数转换为网格的瓶颈，这些方法的输出被低估了。行进立方体往往会产生类似楼梯的伪影，而大多数后续作品都专注于利用带符号的距离函数作为输入，也会产生占用函数的次优结果。基于流形双轮廓（MDC），我们提出了基于占用的双轮廓（ODC），它主要修改了网格边缘点（1D点）和网格单元点（3D点）的计算，使其不使用任何距离信息。我们引入了用于计算局部曲面法线的辅助2D点以及1D点，通过二次误差函数帮助识别3D点。为了搜索1D、2D和3D点，我们开发了可在所有网格边、面和单元上并行化的快速算法。我们对几个3D神经生成模型和一个3D网格数据集的实验表明，与之前的工作相比，我们的方法达到了最佳的保真度。 et.al.|[2409.13418](http://arxiv.org/abs/2409.13418)|**[link](https://github.com/kaist-visual-ai-group/odc)**|
|**2024-09-20**|**Elite-EvGS: Learning Event-based 3D Gaussian Splatting by Distilling Event-to-Video Priors**|事件相机是仿生传感器，输出异步和稀疏的事件流，而不是固定帧。受益于其独特的优势，如高动态范围和高时间分辨率，事件相机已被应用于解决3D重建问题，这对机器人测绘非常重要。最近，神经渲染技术，如3D高斯溅射（3DGS），在3D重建中取得了成功。然而，如何开发有效的基于事件的3DGS管道仍有待探索。特别是，由于3DGS通常依赖于高质量的初始化和密集的多视图约束，因此考虑到其固有的稀疏特性，3DGS优化出现了一个潜在的问题。为此，我们提出了一种新的基于事件的3DGS框架，名为Elite EvGS。我们的核心思想是从现成的事件到视频（E2V）模型中提取先验知识，以从粗到细的优化方式从事件中有效地重建3D场景。具体来说，为了解决从事件初始化3DGS的复杂性，我们引入了一种新的预热初始化策略，该策略从E2V模型生成的帧中优化粗略的3DGS，然后结合事件来细化细节。然后，我们提出了一种渐进式事件监督策略，该策略采用窗口切片操作来逐步减少用于监督的事件数量。这巧妙地缓解了事件帧的时间随机性，有利于优化局部纹理和全局结构细节。在基准数据集上的实验表明，Elite EvGS可以重建具有更好纹理和结构细节的3D场景。同时，我们的方法在捕获的真实世界数据上产生了合理的性能，包括各种具有挑战性的条件，如快速运动和低光场景。 et.al.|[2409.13392](http://arxiv.org/abs/2409.13392)|null|

<p align=right>(<a href=#updated-on-20240925>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-09-24**|**MonoFormer: One Transformer for Both Diffusion and Autoregression**|大多数现有的多模态方法使用单独的主干进行基于自回归的离散文本生成和基于扩散的连续视觉生成，或者通过离散化视觉数据来使用自回归进行文本和视觉生成，从而使用相同的主干。在本文中，我们提出研究一个简单的想法：为自回归和扩散共享一个变压器。可行性来自两个主要方面：（i）Transformer成功应用于视觉生成的扩散，以及（ii）自回归和扩散的Transformer训练非常相似，区别仅在于扩散使用双向注意力掩码，自回归使用因果注意力掩码。实验结果表明，我们的方法在保持文本生成能力的同时，实现了与当前最先进方法相当的图像生成性能。该项目可在以下网址公开获取https://monoformer.github.io/. et.al.|[2409.16280](http://arxiv.org/abs/2409.16280)|null|
|**2024-09-24**|**Generative Factor Chaining: Coordinated Manipulation with Diffusion-based Factor Graph**|众所周知，学习规划多步、多机械手任务是困难的，因为搜索空间大，约束满足问题复杂。我们提出了生成因素链（GFC），这是一种可组合的生成规划模型。GFC将规划问题表示为时空因素图，其中节点表示场景中的对象和机器人，空间因素捕获节点之间有效关系的分布，时间因素表示技能转换的分布。每个因素都被实现为一个模块化的扩散模型，在推理过程中通过双向消息传递生成可行的长期计划。我们表明，GFC可以解决复杂的双手操作任务，并对具有新对象和约束组合的看不见的规划任务表现出很强的泛化能力。更多详细信息请访问：https://generative-fc.github.io/ et.al.|[2409.16275](http://arxiv.org/abs/2409.16275)|null|
|**2024-09-24**|**Exactly solvable stochastic spectator**|暴胀的随机形式使我们能够以非微扰的方式描述标量场动力学。扩散与Schr的对应关系{o}dinger方程使得在随机通货膨胀中详尽地构造解析解成为可能。这些精确的统计量，如分布和相关函数，与非相对论量子力学中经典正交多项式的精确可解解一一对应。通过具有称为形状不变性的潜在对称性的等谱哈密顿量，提出了一类这样的解。 et.al.|[2409.16272](http://arxiv.org/abs/2409.16272)|null|
|**2024-09-24**|**MaskBit: Embedding-free Image Generation via Bit Tokens**|用于类条件图像生成的掩蔽变换器模型已成为扩散模型的一种引人注目的替代方案。这些框架通常包括两个阶段——用于在潜在空间和图像空间之间转换的初始VQGAN模型，以及用于潜在空间内图像生成的后续Transformer模型——为图像合成提供了有前景的途径。在这项研究中，我们提出了两个主要贡献：第一，对VQGAN进行了实证和系统的检验，从而实现了现代化的VQGAN。其次，一种直接在比特令牌上运行的新型嵌入自由生成网络——一种具有丰富语义的令牌的二进制量化表示。第一个贡献提供了一个透明、可重复和高性能的VQGAN模型，增强了可访问性，并与当前最先进的方法的性能相匹配，同时揭示了以前未公开的细节。第二个贡献表明，在ImageNet 256x256基准上，使用位令牌嵌入免费图像生成可以实现1.52的最新FID，并且生成器模型仅包含305M个参数。 et.al.|[2409.16211](http://arxiv.org/abs/2409.16211)|null|
|**2024-09-24**|**MIMO: Controllable Character Video Synthesis with Spatial Decomposed Modeling**|角色视频合成旨在在逼真的场景中生成可动画角色的逼真视频。作为计算机视觉和图形领域的一个基本问题，3D作品通常需要多视图捕捉来进行个案训练，这严重限制了它们在短时间内对任意字符建模的适用性。最近的2D方法通过预训练的扩散模型打破了这一限制，但它们在姿态通用性和场景交互方面存在困难。为此，我们提出了MIMO，这是一种新的框架，它不仅可以合成具有简单用户输入提供的可控属性（即角色、运动和场景）的角色视频，还可以在统一的框架中同时实现对任意角色的高级可扩展性、对新颖3D运动的通用性和对交互式现实世界场景的适用性。其核心思想是将2D视频编码为紧凑的空间码，同时考虑到视频发生的固有3D特性。具体来说，我们使用单眼深度估计器将2D帧像素提升为3D，并根据3D深度将视频片段分解为分层中的三个空间分量（即主要人物、底层场景和浮动遮挡）。这些分量被进一步编码为规范身份码、结构化运动码和全场景码，用作合成过程的控制信号。空间分解建模的设计实现了灵活的用户控制、复杂的运动表达以及场景交互的3D感知合成。实验结果证明了该方法的有效性和鲁棒性。 et.al.|[2409.16160](http://arxiv.org/abs/2409.16160)|null|
|**2024-09-24**|**Spreading dynamics of a Fisher-KPP nonlocal diffusion model with a free boundary**|本文研究了具有自由边界的Fisher KPP非局部扩散模型的传播速度和渐近行为，这在{LLW22}中是一个悬而未决的问题。利用一个新的下解，我们得到了自由边界的精确有限扩展速度，该速度被证明是解分量 $u$的渐近扩展速度。此外，对于代数衰变核，我们推导了加速扩展率和解分量$u$的相应渐近行为。特别是，对于具有$\lambda \in（0，u^*）$的水平集$E^{\lambda}（t）$ ，我们发现了一个与双自由边界问题不同的有趣传播现象。 et.al.|[2409.16101](http://arxiv.org/abs/2409.16101)|null|
|**2024-09-24**|**Cloudy modeling suggests a diversity of ionization mechanisms for diffuse extraplanar gas**|位于高能中平面OB恒星上方的扩散气体的电离对普遍接受的观点提出了挑战，即OB恒星的辐射是星系中气体的主要电离源。我们研究了电离辐射的来源，特别是泄漏的中平面HII区域和/或原位热低质量演化恒星（HOLMES），在用多单元光谱探测器（MUSE）观察到的八个附近（17-52Mpc）边盘星系样本中的平面外扩散电离气体（eDIG）中。我们使用随后运行的Cloudy光电离代码构建了eDIG云的光电离和电离辐射通过eDIG传播的模型。我们的模型包括来自中平面OB恒星和原位演化恒星的辐射，以及它在eDIG中传播时的稀释和处理。我们使用样本星系的垂直线比率剖面将模型拟合到数据中，发现虽然原位演化恒星的电离对我们样本中的大多数星系来说微不足道，但它可能能够解释绿谷星系ESO 544-27的eDIG中增强的高电离线。我们的结果表明，虽然来自中平面HII区域的泄漏辐射是eDIG的主要电离源，但原位演化的恒星可以在低恒星形成率的星系中电离平面外气体中发挥重要作用。 et.al.|[2409.16062](http://arxiv.org/abs/2409.16062)|null|
|**2024-09-24**|**Tracing Ion Migration in Halide Perovskites with Machine Learned Force Fields**|卤化物钙钛矿光电器件会因高流动性带电缺陷的迁移而发生化学降解和电流-电压滞后。原子尺度分子动力学模拟可以捕捉到这些离子缺陷的运动，但经典力场太不灵活，无法描述它们的动态电荷态。以CsPbI3为例，我们从密度泛函理论计算中开发了机器学习力场，并研究了块状CsPbI3中带电卤化物间隙和空位缺陷的扩散。我们发现，负碘化物间隙和正碘化物空位是各自缺陷类型最稳定的电荷态，在室温下以相似的速率迁移。中性间隙更快，但中性空位慢一个数量级。相反带电的间隙和空位，因为它们可能出现在设备操作或反向偏压条件下，速度明显较慢，可以认为相对不动。 et.al.|[2409.16051](http://arxiv.org/abs/2409.16051)|null|
|**2024-09-24**|**Transient bubble rising in the presence of a surfactant at very low concentrations**|我们研究了在含有少量表面活性剂的水箱中释放气泡时动态吸附层的形成。通过比较十二烷基硫酸钠（SDS）和Triton X-100的实验，研究了吸附动力学常数的影响。这些实验使我们能够确定导致气泡稳定上升的参数条件，并验证模拟结果。简单的标度分析和模拟表明，动态吸附层的形成可以分为三个阶段，其特征是不同的时间尺度。控制这些相的机制是表面活性剂对流、吸附-解吸和扩散。吸附在界面上的表面活性剂的量在整个三相中单调增加。实验和模拟表明，当实际形成动态吸附层时，上升速度在 $k_d^{-1}$（$k_d$ 是解吸常数）量级达到最大值。即使液体中只存在微量表面活性剂，也会发生这种情况。最大表面活性剂表面浓度的非单调行为可以用气泡释放后气泡后部的逆流来解释。这项工作有助于理解流体力学和表面活性剂在气泡上升过程中的传输和动力学之间的复杂相互作用。 et.al.|[2409.16029](http://arxiv.org/abs/2409.16029)|null|
|**2024-09-24**|**PRESTO: Fast motion planning using diffusion models based on key-configuration environment representation**|我们介绍了一种学习引导的运动规划框架，该框架使用扩散模型提供初始种子轨迹以进行轨迹优化。给定一个工作空间，我们的方法通过一个关键配置表示来近似配置空间（C空间）障碍，该表示由一组稀疏的任务相关关键配置组成，并将其用作扩散模型的输入。扩散模型整合了正则化项，在训练过程中鼓励避免碰撞和平滑轨迹，轨迹优化细化了生成的种子轨迹，以进一步校正任何碰撞段。我们的实验结果表明，使用通过我们的C空间圆形扩散模型学习的高质量轨迹先验，可以在狭窄通道环境中高效生成无碰撞轨迹，优于基于先验学习和规划的基线。视频和其他材料可以在项目页面上找到：https://kiwi-sherbet.github.io/PRESTO. et.al.|[2409.16012](http://arxiv.org/abs/2409.16012)|null|

<p align=right>(<a href=#updated-on-20240925>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-09-24**|**Generative 3D Cardiac Shape Modelling for In-Silico Trials**|我们提出了一种深度学习方法，基于将形状表示为神经有符号距离场的零级集，对合成主动脉形状进行建模和生成，该方法受一系列可训练的嵌入向量的约束，并对每个形状的几何特征进行编码。通过使神经场在采样表面点上消失并强制其空间梯度具有单位范数，在从CT图像重建的主动脉根部网格数据集上训练网络。实证结果表明，我们的模型可以高保真地表示主动脉形状。此外，通过从学习到的嵌入向量中采样，我们可以生成类似于真实患者解剖结构的新形状，可用于计算机模拟试验。 et.al.|[2409.16058](http://arxiv.org/abs/2409.16058)|null|
|**2024-09-21**|**MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors**|由于缺乏几何指导和不完美的视图相关2D先验，从单眼图像中精确重建密集和语义注释的3D网格仍然是一项具有挑战性的任务。尽管我们已经见证了隐式神经场景表示的最新进展，能够简单地从多视图图像中进行精确的2D渲染，但很少有研究仅使用单眼先验来解决3D场景理解问题。在本文中，我们提出了MOSE，这是一种神经场语义重建方法，可以将推断的图像级噪声先验提升到3D，在3D和2D空间中产生精确的语义和几何。我们方法的关键动机是利用通用类不可知的分段掩码作为指导，在训练过程中促进渲染语义的局部一致性。在语义的帮助下，我们进一步将平滑正则化应用于无纹理区域，以获得更好的几何质量，从而实现几何和语义的互惠互利。在ScanNet数据集上的实验表明，我们的MOSE在3D语义分割、2D语义分割和3D表面重建任务的所有指标上都优于相关基线。 et.al.|[2409.14019](http://arxiv.org/abs/2409.14019)|null|
|**2024-09-17**|**SplatFields: Neural Gaussian Splats for Sparse 3D and 4D Reconstruction**|从多视图图像中数字化3D静态场景和4D动态事件长期以来一直是计算机视觉和图形学领域的一个挑战。最近，3D高斯散斑（3DGS）已经成为一种实用且可扩展的重建方法，由于其令人印象深刻的重建质量、实时渲染能力以及与广泛使用的可视化工具的兼容性而越来越受欢迎。然而，该方法需要大量的输入视图来实现高质量的场景重建，这引入了一个重大的实际瓶颈。在捕捉动态场景时，这一挑战尤为严峻，因为部署广泛的相机阵列的成本可能高得令人望而却步。在这项工作中，我们发现斑点特征缺乏空间自相关性是导致3DGS技术在稀疏重建环境中性能不佳的因素之一。为了解决这个问题，我们提出了一种优化策略，通过将splat特征建模为相应隐式神经场的输出，有效地正则化splat特征。这导致在各种场景中重建质量的一致提高。我们的方法有效地处理了静态和动态情况，这在不同设置和场景复杂性的广泛测试中得到了证明。 et.al.|[2409.11211](http://arxiv.org/abs/2409.11211)|null|
|**2024-09-17**|**Neural Fields for Adaptive Photoacoustic Computed Tomography**|光声计算机断层扫描（PACT）是一种具有广泛医学应用的非侵入性成像技术。传统的PACT图像重建算法受到组织中声速不均匀（SOS）引起的波前失真的影响，导致图像质量下降。考虑到这些影响可以提高图像质量，但测量SOS分布的实验成本很高。另一种方法是仅使用PA信号对初始压力图像和SOS进行联合重建。现有的关节重建方法存在局限性：计算成本高，无法直接恢复SOS，以及依赖于不准确的简化假设。隐式神经表示或神经场是计算机视觉中的一种新兴技术，用于通过基于坐标的神经网络学习物理场的有效和连续表示。在这项工作中，我们介绍了NF-APACT，这是一种高效的自监督框架，利用神经场来估计SOS，以实现准确和鲁棒的多通道解卷积。我们的方法比现有方法更快、更准确地消除了SOS像差。我们在一个新的数值体模以及实验收集的体模和体内数据上证明了我们的方法的成功。我们的代码和数字幻影可在https://github.com/Lukeli0425/NF-APACT. et.al.|[2409.10876](http://arxiv.org/abs/2409.10876)|null|
|**2024-09-09**|**Lagrangian Hashing for Compressed Neural Field Representations**|我们提出了拉格朗日散列，这是一种神经场的表示，结合了依赖于欧拉网格（即~InstantNGP）的快速训练NeRF方法的特征，以及使用配备有特征的点作为表示信息的方法（例如3D高斯散点或PointNeRF）。我们通过将基于点的表示合并到InstantNGP表示的分层哈希表的高分辨率层中来实现这一点。由于我们的点具有影响域，我们的表示可以被解释为哈希表中存储的高斯混合。我们提出的损失鼓励我们的高斯人向需要更多代表预算才能充分代表的地区移动。我们的主要发现是，我们的表示允许使用更紧凑的表示来重建信号，而不会影响质量。 et.al.|[2409.05334](http://arxiv.org/abs/2409.05334)|null|
|**2024-09-08**|**Exploring spectropolarimetric inversions using neural fields. Solar chromospheric magnetic field under the weak-field approximation**|全斯托克斯偏振数据集来源于狭缝光谱仪或窄带滤光片图，如今已被常规采集。随着二维光谱偏振仪和允许长时间高质量观测序列的观测技术的出现，数据速率正在增加。在光谱偏振反演中，显然需要通过利用推断物理量的时空相干性来超越传统的逐像素策略。我们探索了神经网络作为时间和空间（也称为神经场）上物理量的连续表示的潜力，用于光谱极化反演。我们已经实现并测试了一个神经场，以在弱场近似（WFA）下执行磁场矢量的推理（也称为物理知情神经网络的方法）。通过使用神经场来描述磁场矢量，我们可以通过假设物理量是坐标的连续函数来在空间和时间域中正则化解。我们研究了Ca II 8542 A谱线的合成和真实观测结果。我们还探讨了其他显式正则化的影响，例如使用外推磁场的信息或色球原纤维的取向。与传统的逐像素反演相比，神经场方法提高了磁场矢量重建的保真度，特别是横向分量。这种隐式正则化是一种提高观测值有效信噪比的方法。虽然它比逐像素WFA估计慢，但这种方法通过减少自由参数的数量并在解决方案中引入时空约束，显示出深度分层反演的巨大潜力。 et.al.|[2409.05156](http://arxiv.org/abs/2409.05156)|**[link](https://github.com/cdiazbas/neural_wfa)**|
|**2024-09-04**|**MDNF: Multi-Diffusion-Nets for Neural Fields on Meshes**|我们提出了一种在三角形网格上表示神经场的新框架，该框架在空间和频率域上都是多分辨率的。受神经傅里叶滤波器组（NFFB）的启发，我们的架构通过将更精细的空间分辨率级别与更高的频带相关联来分解空间和频率域，而将更粗糙的分辨率映射到较低的频率。为了实现几何感知的空间分解，我们利用了多个扩散网络组件，每个组件都与不同的空间分辨率级别相关联。随后，我们应用傅里叶特征映射来鼓励更精细的分辨率水平与更高的频率相关联。最终信号是使用正弦激活的MLP以小波激励的方式组成的，将高频信号聚集在低频信号之上。我们的架构在学习复杂神经场方面具有很高的精度，并且对目标场的不连续性、指数尺度变化和网格修改具有鲁棒性。我们通过将我们的方法应用于不同的神经领域，如合成RGB函数、UV纹理坐标和顶点法线，展示了其有效性，并说明了不同的挑战。为了验证我们的方法，我们将其性能与两种替代方案进行了比较，展示了我们的多分辨率架构的优势。 et.al.|[2409.03034](http://arxiv.org/abs/2409.03034)|null|
|**2024-09-03**|**GraspSplats: Efficient Manipulation with 3D Feature Splatting**|机器人对物体部件进行高效和零样本抓取的能力对于实际应用至关重要，并且随着视觉语言模型（VLM）的最新进展而变得普遍。为了弥合二维到三维表示的差距以支持这种能力，现有的方法依赖于神经场（NeRF），通过可微渲染或基于点的投影方法。然而，我们证明了NeRF由于其隐含性而不适合场景变化，并且基于点的方法对于没有基于渲染的优化的零件定位是不准确的。为了修正这些问题，我们提出了“把握辉煌”。使用深度监督和一种新的参考特征计算方法，GraspSplats在60秒内生成高质量的场景表示。我们进一步验证了基于高斯表示法的优势，表明GraspSplats中的显式和优化几何足以原生支持（1）实时抓取采样和（2）使用点跟踪器进行动态和铰接对象操作。通过在Franka机器人上进行的广泛实验，我们证明了在不同的任务设置下，GraspSplats的表现明显优于现有的方法。特别是，GraspSplats的性能优于基于NeRF的方法，如F3RM和LERF-TOGO，以及2D检测方法。 et.al.|[2409.02084](http://arxiv.org/abs/2409.02084)|null|
|**2024-08-23**|**S4D: Streaming 4D Real-World Reconstruction with Gaussians and 3D Control Points**|最近，使用高斯分布的动态场景重建引起了越来越多的兴趣。主流方法通常采用全局变形场来扭曲规范空间中的3D场景。然而，隐式神经场固有的低频特性往往导致复杂运动的无效表示。此外，它们的结构刚性会阻碍对不同分辨率和持续时间的场景的适应。为了克服这些挑战，我们引入了一种利用离散3D控制点的新方法。该方法对局部射线进行物理建模，并建立一个运动解耦坐标系，该坐标系有效地将传统图形与可学习的流水线相结合，以实现鲁棒且高效的局部6自由度（6-DoF）运动表示。此外，我们还开发了一个广义框架，将我们的控制点与高斯算子结合起来。从初始3D重建开始，我们的工作流程将流式4D真实世界重建分解为四个独立的子模块：3D分割、3D控制点生成、对象运动操纵和残差补偿。我们的实验表明，该方法在Neu3DV和CMU全景数据集上的表现优于现有的最先进的4D高斯散斑技术。我们的方法还显著加速了训练，在单个NVIDIA 4070 GPU上，每帧只需2秒即可优化我们的3D控制点。 et.al.|[2408.13036](http://arxiv.org/abs/2408.13036)|**[link](https://github.com/hebing-sjtu/S4D)**|
|**2024-08-22**|**Neural Fields and Noise-Induced Patterns in Neurons on Large Disordered Networks**|我们研究了随机图上受时空随机强迫的大维神经网络类的模式形成。在耦合和节点动力学的一般条件下，我们证明了该网络具有严格的平均场极限，类似于Wilson Cowan神经场方程。限制系统的状态变量是神经元活动的均值和方差。我们选择平均场方程易于处理的网络，并使用每个神经元上传入白噪声的扩散强度作为控制参数进行分叉分析。我们在皮质被建模为环的系统中找到了图灵分叉的条件，并在二维皮质模型中产生了噪声诱导螺旋波的数值证据。我们提供了数值证据，证明有限尺寸网络的解弱收敛于平均场模型的解。最后，我们证明了大偏差原理，该原理提供了一种评估有限尺寸效应引起的平均场方程偏差可能性的方法。 et.al.|[2408.12540](http://arxiv.org/abs/2408.12540)|null|

<p align=right>(<a href=#updated-on-20240925>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

