[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.06.11
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-10**|**IllumiNeRF: 3D Relighting without Inverse Rendering**|现有的可重新照明视图合成方法——使用一组未知照明下的对象图像来恢复可以在目标照明下从新视点渲染的3D表示——基于反向渲染，并试图解开解释输入图像的对象几何结构、材料和照明。此外，这通常涉及通过可微分蒙特卡罗渲染进行优化，这是脆弱的，并且计算成本很高。在这项工作中，我们提出了一种更简单的方法：我们首先使用以照明为条件的图像扩散模型重新照明每个输入图像，然后用这些重新照明的图像重建神经辐射场（NeRF），从中我们在目标照明下绘制新的视图。我们证明，这一战略具有惊人的竞争力，并在多个重新照明基准上取得了最先进的结果。请参阅我们的项目页面https://illuminerf.github.io/. et.al.|[2406.06527](http://arxiv.org/abs/2406.06527)|null|
|**2024-06-10**|**Lighting Every Darkness with 3DGS: Fast Training and Real-Time Rendering for HDR View Synthesis**|基于体积渲染的方法，如NeRF，擅长从RAW图像合成HDR视图，尤其是在夜间场景中。然而，它们的训练时间很长，并且由于密集的采样要求而无法执行实时渲染。3D高斯散射（3DGS）的出现实现了实时渲染和更快的训练。然而，由于其固有的缺点，直接使用3DGS实现基于RAW图像的视图合成是具有挑战性的：1）在夜间场景中，极低的SNR导致远景中的运动结构（SfM）估计较差；2） 球面谐波（SH）函数有限的表示能力不适合于RAW线性颜色空间；以及3）不准确的场景结构阻碍了诸如重新聚焦之类的下游任务。为了解决这些问题，我们提出了LE3D（用3DGS照亮每一个黑暗）。我们的方法提出了锥散射初始化来丰富SfM的估计，并用彩色MLP代替SH来表示RAW线性颜色空间。此外，我们引入了深度失真和远近正则化，以提高下游任务场景结构的准确性。这些设计使LE3D能够执行实时新颖的视图合成、HDR渲染、重新聚焦和色调映射更改。与以前基于体积渲染的方法相比，LE3D将训练时间减少到1%，并将2K分辨率图像的渲染速度提高了4000倍。代码和查看器可在中找到https://github.com/Srameo/LE3D . et.al.|[2406.06216](http://arxiv.org/abs/2406.06216)|**[link](https://github.com/srameo/le3d)**|
|**2024-06-09**|**Self-supervised Adversarial Training of Monocular Depth Estimation against Physical-World Attacks**|单目深度估计（MDE）在自动驾驶等应用中发挥着至关重要的作用。然而，各种攻击针对MDE模型，物理攻击对系统安全构成重大威胁。传统的对抗性训练方法需要地面实况标签，不能直接应用于缺乏地面实况深度的MDE模型。一些自监督模型强化技术（例如，对比学习）忽略了MDE的领域知识，导致性能次优。在这项工作中，我们为MDE模型引入了一种新的自监督对抗性训练方法，利用视图合成而不需要地面实况深度。我们通过在训练过程中引入L_0-norm-bounded扰动来增强对抗真实世界攻击的鲁棒性。我们根据专门为MDE设计的基于监督学习和基于对比学习的方法来评估我们的方法。我们对两个具有代表性的MDE网络的实验表明，它提高了对各种对抗性攻击的鲁棒性，对良性性能的影响最小。 et.al.|[2406.05857](http://arxiv.org/abs/2406.05857)|**[link](https://github.com/Bob-cheng/DepthModelHardening)**|
|**2024-06-09**|**RefGaussian: Disentangling Reflections from 3D Gaussian Splatting for Realistic Rendering**|三维高斯散射（3D-GS）在神经渲染、三维场景重建和新型视图合成等领域取得了显著的进展。然而，3D-GS在准确表示物理反射方面遇到了主要挑战，尤其是在真实世界场景中常见的全反射和半反射的情况下。这种限制导致反射被错误地视为具有物理存在的独立元素，从而导致不精确的重建。在此，为了应对这一挑战，我们建议RefGaussian将反射从3D-GS中分离出来，以便对反射进行逼真建模。具体来说，我们建议将场景划分为透射分量和反射分量，并使用两个球面谐波（SH）来表示这些分量。考虑到这种分解尚未完全确定，我们使用局部正则化技术来确保透射分量和反射分量的局部平滑，从而实现比3D-GS更合理的分解结果。实验结果表明，我们的方法实现了优越的新视图合成和准确的深度估计结果。此外，它能够利用场景编辑应用程序，确保高质量的结果和物理一致性。 et.al.|[2406.05852](http://arxiv.org/abs/2406.05852)|null|
|**2024-06-09**|**VCR-GauS: View Consistent Depth-Normal Regularizer for Gaussian Surface Reconstruction**|尽管3D高斯散射由于其逼真和高效的新颖视图合成而得到了广泛的研究，但从基于点的表示中提取高质量的曲面仍然是一项挑战。先前的工作通过结合现成法线估计器的几何先验来改进曲面。然而，存在两个主要限制：1）监督从3D高斯渲染的法线仅更新旋转参数，而忽略其他几何参数；2） 跨多个视图的预测法线图的不一致性可能导致严重的重建伪影。在本文中，我们提出了一种深度正则化子，它直接将法线与其他几何参数耦合，从而从法线正则化中得到几何参数的完全更新。我们进一步提出了一个置信项，以减轻多个视图中正常预测的不一致性。此外，我们还引入了一种致密化和分裂策略，以正则化3D高斯的大小和分布，从而实现更精确的表面建模。与基于高斯的基线相比，实验表明，我们的方法在更快的训练速度和100+FPS的渲染下获得了更好的重建质量，并保持了有竞争力的外观质量。我们的代码将在论文接受后开源。 et.al.|[2406.05774](http://arxiv.org/abs/2406.05774)|null|
|**2024-06-07**|**Multi-style Neural Radiance Field with AdaIN**|在这项工作中，我们提出了一种结合AdaIN和NeRF的新管道，用于风格化的小说视图合成任务。与以前的工作相比，我们做出了以下贡献：1）我们简化了管道。2） 我们扩展了模型的功能来处理多样式任务。3） 我们修改了模型架构，使其在具有强烈笔触的样式上表现良好。4） 我们在多样式模型上实现了样式插值，使我们能够控制任意两个样式之间的样式以及样式化输出和原始场景之间的样式强度，从而更好地控制样式化强度。 et.al.|[2406.04960](http://arxiv.org/abs/2406.04960)|**[link](https://github.com/vppyw/Stylized-NeRF-with-AdaIN)**|
|**2024-06-06**|**Flash3D: Feed-Forward Generalisable 3D Scene Reconstruction from a Single Image**|在本文中，我们提出了Flash3D，这是一种从单个图像进行场景重建和新颖视图合成的方法，它既非常通用又高效。为了通用性，我们从单目深度估计的“基础”模型开始，并将其扩展到全3D形状和外观重建器。为了提高效率，我们将这种扩展建立在前馈高斯散射的基础上。具体来说，我们在预测的深度预测第一层3D高斯，然后添加在空间上偏移的附加高斯层，使模型能够完成遮挡和截断后的重建。Flash3D非常高效，可以在一天内在单个GPU上进行训练，因此大多数研究人员都可以访问。在RealEstate10k上进行训练和测试时，它取得了最先进的成绩。当转移到像纽约大学这样看不见的数据集时，它的表现大大优于竞争对手。更令人印象深刻的是，当转移到KITTI时，Flash3D实现了比专门在该数据集上训练的方法更好的PSNR。在某些情况下，它甚至优于最近使用多个视图作为输入的方法。代码、模型、演示和更多结果可在https://www.robots.ox.ac.uk/~vgg/research/flash3d/。 et.al.|[2406.04343](http://arxiv.org/abs/2406.04343)|null|
|**2024-06-06**|**Coarse-To-Fine Tensor Trains for Compact Visual Representations**|学习视觉数据的紧凑、高质量和易于优化的表示的能力对于许多应用程序（如新颖的视图合成和3D重建）至关重要。最近的工作表明，在使用张量网络来设计这种紧凑和高质量的表示方面取得了实质性的成功。然而，优化基于张量的表示，特别是高度紧凑的张量列表示的能力仍然缺乏。这阻碍了从业者为视觉数据部署张量网络的全部潜力。为此，我们提出了“延长上采样张量序列（PuTT）”，这是一种以从粗到细的方式学习张量序列表示的新方法。我们的方法涉及延长或“上采样”已学习的张量序列表示，创建一个增量细化的“从粗到细”张量序列。我们沿着三个轴来评估我们的表示：（1）。压缩，（2）。去噪能力，以及（3）。图像完成能力。为了评估这些轴，我们考虑了图像拟合、3D拟合和新视图合成的任务，其中与最先进的基于张量的方法相比，我们的方法显示出改进的性能。有关完整结果，请参阅我们的项目网页：https://sebulo.github.io/PuTT_website/ et.al.|[2406.04332](http://arxiv.org/abs/2406.04332)|**[link](https://github.com/sebulo/PuTT)**|
|**2024-06-06**|**Conv-INR: Convolutional Implicit Neural Representation for Multimodal Visual Signals**|内隐神经表征（INR）最近成为一种很有前途的信号表征范式。通常，INR由多人感知器（MLP）参数化，该感知器将坐标作为输入并生成信号的相应属性。然而，基于MLP的INR面临两个关键问题：i）单独考虑每个坐标，而忽略连接；ii）遭受频谱偏移，从而不能学习高频分量。虽然目标视觉信号通常表现出强烈的局部结构和邻域依赖性，并且高频分量在这些信号中很重要，但这些问题损害了INRs的代表能力。本文提出了第一个完全基于卷积的INR模型Conv-INR。由于卷积的固有属性，Conv-INR可以同时考虑相邻坐标并有效地学习高频分量。与现有的基于MLP的INR相比，Conv INR在不需要主要功能扩展的情况下具有更好的代表能力和可训练性。我们在四项任务上进行了广泛的实验，包括图像拟合、CT/MRI重建和新的视图合成，Conv INR都显著超过了现有的基于MLP的INR，验证了其有效性。最后，我们提出了三种重新参数化方法，它们可以在不引入任何额外推理成本的情况下进一步提高vanilla Conv INR的性能。 et.al.|[2406.04249](http://arxiv.org/abs/2406.04249)|null|
|**2024-06-06**|**Encoding Semantic Priors into the Weights of Implicit Neural Representation**|隐式神经表示（INR）最近成为一种很有前途的信号表示范式，它以坐标为输入并生成相应的信号值。由于这些坐标不包含语义特征，INR没有考虑任何语义信息。然而，语义信息已被证明在许多视觉任务中至关重要，尤其是在视觉信号表示方面。本文提出了一种称为SPW的重新参数化方法，该方法将语义先验编码为INR的权重，从而使INR隐含地包含语义信息，提高其表示能力。具体来说，SPW使用语义神经网络（SNN）来提取目标视觉信号的低级和高级语义信息，并生成语义向量，将其输入到权重生成网络（WGN）中以生成INR模型的权重。最后，INR使用生成的具有语义先验的权重将坐标映射到信号值。训练后，我们只保留生成的权重，同时放弃SNN和WGN，因此SPW在推理中不会引入额外的成本。实验结果表明，SPW可以显著提高各种INR模型在各种任务上的性能，包括图像拟合、CT重建、MRI重建和新视图合成。进一步的实验表明，采用SPW的模型具有较低的权值冗余，学习到了更多新颖的表示，验证了SPW的有效性。 et.al.|[2406.04178](http://arxiv.org/abs/2406.04178)|null|

<p align=right>(<a href=#updated-on-20240611>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-09**|**MAP-ADAPT: Real-Time Quality-Adaptive Semantic 3D Maps**|创建环境的3D语义重建是许多应用程序的基础，尤其是与自主代理操作（例如，面向目标的导航或对象交互和操作）相关的应用程序。通常，3D语义重建系统以相同的细节级别捕获整个场景。然而，某些任务（例如，对象交互）需要细粒度和高分辨率的地图，特别是当要交互的对象是小尺寸或复杂的几何体时。在最近的实践中，这导致整个地图具有相同的高质量分辨率，这导致计算和存储成本增加。为了应对这一挑战，我们提出了MAP-ADAPT，这是一种使用RGBD帧进行质量自适应语义3D重建的实时方法。MAP-ADAPT是第一种自适应语义3D映射算法，与之前的工作不同，它基于场景的语义信息和几何复杂性直接生成具有不同质量区域的单个地图。利用语义SLAM管道进行姿态和语义估计，我们在合成和真实世界的数据上实现了与最先进的方法相当或优越的结果，同时显著降低了存储和计算需求。 et.al.|[2406.05849](http://arxiv.org/abs/2406.05849)|null|
|**2024-06-09**|**VCR-GauS: View Consistent Depth-Normal Regularizer for Gaussian Surface Reconstruction**|尽管3D高斯散射由于其逼真和高效的新颖视图合成而得到了广泛的研究，但从基于点的表示中提取高质量的曲面仍然是一项挑战。先前的工作通过结合现成法线估计器的几何先验来改进曲面。然而，存在两个主要限制：1）监督从3D高斯渲染的法线仅更新旋转参数，而忽略其他几何参数；2） 跨多个视图的预测法线图的不一致性可能导致严重的重建伪影。在本文中，我们提出了一种深度正则化子，它直接将法线与其他几何参数耦合，从而从法线正则化中得到几何参数的完全更新。我们进一步提出了一个置信项，以减轻多个视图中正常预测的不一致性。此外，我们还引入了一种致密化和分裂策略，以正则化3D高斯的大小和分布，从而实现更精确的表面建模。与基于高斯的基线相比，实验表明，我们的方法在更快的训练速度和100+FPS的渲染下获得了更好的重建质量，并保持了有竞争力的外观质量。我们的代码将在论文接受后开源。 et.al.|[2406.05774](http://arxiv.org/abs/2406.05774)|null|
|**2024-06-09**|**GTR: Improving Large 3D Reconstruction Models through Geometry and Texture Refinement**|我们提出了一种从多视图图像中重建三维网格的新方法。我们的方法的灵感来自大型重建模型，如LRM，该模型使用基于变压器的三平面发生器和在多视图图像上训练的神经辐射场（NeRF）模型。然而，在我们的方法中，我们引入了几个重要的修改，使我们能够显著提高3D重建质量。首先，我们检查了LRM的原始架构，发现了一些不足之处。随后，我们对LRM架构进行了相应的修改，从而改进了多视图图像表示并提高了计算效率。其次，为了改进几何重建并实现全图像分辨率的监督，我们以可微分的方式从NeRF场中提取网格，并通过网格渲染对NeRF模型进行微调。这些修改使我们能够在2D和3D评估指标上实现最先进的性能，如谷歌扫描对象（GSO）数据集的PSNR为28.67。尽管取得了这些优异的结果，但我们的前馈模型仍难以重建复杂的纹理，如资产上的文本和肖像。为了解决这个问题，我们引入了一个轻量级的每实例纹理细化过程。该过程仅在4秒内使用输入的多视图图像对网格表面上的三平面表示和NeRF颜色估计模型进行微调。这种细化将PSNR提高到29.79，并实现了对复杂纹理（如文本）的忠实重建。此外，我们的方法支持各种下游应用程序，包括文本或图像到3D的生成。 et.al.|[2406.05649](http://arxiv.org/abs/2406.05649)|null|
|**2024-06-08**|**PAPR in Motion: Seamless Point-level 3D Scene Interpolation**|我们提出了点级3D场景插值问题，该问题旨在从多个视图同时重建处于两种状态的3D场景，合成它们之间的平滑点级插值，并从新的视点渲染场景，所有这些都不需要状态之间的任何监督。主要挑战是实现国家之间的平稳过渡，这可能涉及重大和非刚性的变化。为了应对这些挑战，我们引入了“运动中的PAPR”，这是一种基于最近的接近注意力点渲染（PAPR）技术的新方法，该技术可以使点云变形以匹配明显不同的形状，并即使在非刚性变形后也能渲染视觉上连贯的场景。我们的方法是专门设计的，通过为PAPR引入各种正则化技术来保持几何结构的时间一致性。其结果是一种方法，可以有效地桥接大的场景变化，并在几何体和外观上产生视觉连贯和时间平滑的插值。对不同运动类型的评估表明，“运动中的PAPR”在动态场景方面优于领先的神经渲染器。有关更多结果和代码，请访问我们的项目网站https://niopeng.github.io/PAPR-in-Motion/ . et.al.|[2406.05533](http://arxiv.org/abs/2406.05533)|null|
|**2024-06-07**|**Proton 3D reconstruction with T-odd TMD gluon densities**|我们提出的研究旨在通过观众模型方法计算的自旋相关TMD胶子密度来探测质子的3D胶子含量。我们的形式主义结合了观众质量的基于拟合的调制函数，旨在捕捉宽运动学范围内的纵向动量效应。特别强调时间反转偶数布尔-穆德斯和时间反转奇数西弗斯函数。准确理解这些功能对于进行核子的精确3D分析至关重要，这突出了LHC和EIC社区之间合作的重要性。 et.al.|[2406.04893](http://arxiv.org/abs/2406.04893)|null|
|**2024-06-07**|**3DRealCar: An In-the-wild RGB-D Car Dataset with 360-degree Views**|3D汽车通常用于自动驾驶系统、虚拟/增强现实和游戏。然而，现有的3D汽车数据集要么是合成的，要么是低质量的，这与高质量的真实世界3D汽车数据集中存在显著差距，并限制了它们在实际场景中的应用。在本文中，我们提出了第一个大规模的3D真实汽车数据集，称为3DRealCar，提供了三个独特的特征。（1） \textbf｛High Volume｝：2500辆汽车被3D扫描仪仔细扫描，获得具有真实世界维度的汽车图像和点云；（2） \textbf｛高质量｝：每辆车平均在200个密集、高分辨率的360度RGB-D视图中拍摄，实现高保真3D重建；（3） \textbf｛High Diversity｝：该数据集包含来自100多个品牌的各种汽车，在三种不同的照明条件下收集，包括反射、标准和黑暗。此外，我们为每个实例提供详细的汽车解析地图，以促进汽车解析任务的研究。此外，我们去除了背景点云，并将汽车方向标准化为一个统一的轴，仅在没有背景和可控渲染的汽车上进行重建。我们在3DRealCar中的每个照明条件下使用最先进的方法对3D重建结果进行基准测试。大量实验表明，3DRealCar的标准照明条件部分可以用于生产大量高质量的3D汽车，改善与汽车相关的各种2D和3D任务。值得注意的是，我们的数据集揭示了一个事实，即最近的3D重建方法在反射和黑暗照明条件下重建高质量的3D汽车时面临挑战。\textcolor｛red｝｛\href{https://xiaobiaodu.github.io/3drealcar/}｛我们的数据集在这里可用。｝｝ et.al.|[2406.04875](http://arxiv.org/abs/2406.04875)|null|
|**2024-06-07**|**Normal-guided Detail-Preserving Neural Implicit Functions for High-Fidelity 3D Surface Reconstruction**|神经隐式表示已经成为3D重建的强大范例。然而，尽管它们取得了成功，但现有的方法无法捕捉精细的几何细节和薄结构，尤其是在只有感兴趣对象的稀疏RGB视图可用的情况下。我们假设，当前从RGB或RGBD图像中学习神经隐式表示的方法会产生具有缺失部分和细节的3D表面，因为它们只依赖于0阶微分特性，即3D表面点及其投影，作为监督信号。然而，这样的特性不会捕捉点周围的局部3D几何体，也会忽略点之间的相互作用。本文证明，即使在只有两个RGB（正面和背面）图像可用的情况下，训练具有一阶微分特性的神经表示，即表面法线，也能实现高精度的3D表面重建。给定感兴趣对象的多视图RGB图像，我们首先使用现成的单目深度估计器（如depth Anything模型）生成的深度图的梯度来计算图像空间中的近似表面法线。然后，使用损失函数来训练隐式曲面回归器，该函数强制回归曲面的一阶微分特性与从Depth Anything估计的特性相匹配。我们在广泛的真实和合成数据集上进行的大量实验表明，即使使用两个RGB视图，所提出的方法也能达到前所未有的重建精度。详细的消融研究还表明，基于法线的监督在性能的显著提高中发挥着关键作用，使复杂的几何细节和薄结构的3D重建成为可能，而这些细节和结构以前很难捕捉。 et.al.|[2406.04861](http://arxiv.org/abs/2406.04861)|null|
|**2024-06-06**|**Flash3D: Feed-Forward Generalisable 3D Scene Reconstruction from a Single Image**|在本文中，我们提出了Flash3D，这是一种从单个图像进行场景重建和新颖视图合成的方法，它既非常通用又高效。为了通用性，我们从单目深度估计的“基础”模型开始，并将其扩展到全3D形状和外观重建器。为了提高效率，我们将这种扩展建立在前馈高斯散射的基础上。具体来说，我们在预测的深度预测第一层3D高斯，然后添加在空间上偏移的附加高斯层，使模型能够完成遮挡和截断后的重建。Flash3D非常高效，可以在一天内在单个GPU上进行训练，因此大多数研究人员都可以访问。在RealEstate10k上进行训练和测试时，它取得了最先进的成绩。当转移到像纽约大学这样看不见的数据集时，它的表现大大优于竞争对手。更令人印象深刻的是，当转移到KITTI时，Flash3D实现了比专门在该数据集上训练的方法更好的PSNR。在某些情况下，它甚至优于最近使用多个视图作为输入的方法。代码、模型、演示和更多结果可在https://www.robots.ox.ac.uk/~vgg/research/flash3d/。 et.al.|[2406.04343](http://arxiv.org/abs/2406.04343)|null|
|**2024-06-06**|**Coarse-To-Fine Tensor Trains for Compact Visual Representations**|学习视觉数据的紧凑、高质量和易于优化的表示的能力对于许多应用程序（如新颖的视图合成和3D重建）至关重要。最近的工作表明，在使用张量网络来设计这种紧凑和高质量的表示方面取得了实质性的成功。然而，优化基于张量的表示，特别是高度紧凑的张量列表示的能力仍然缺乏。这阻碍了从业者为视觉数据部署张量网络的全部潜力。为此，我们提出了“延长上采样张量序列（PuTT）”，这是一种以从粗到细的方式学习张量序列表示的新方法。我们的方法涉及延长或“上采样”已学习的张量序列表示，创建一个增量细化的“从粗到细”张量序列。我们沿着三个轴来评估我们的表示：（1）。压缩，（2）。去噪能力，以及（3）。图像完成能力。为了评估这些轴，我们考虑了图像拟合、3D拟合和新视图合成的任务，其中与最先进的基于张量的方法相比，我们的方法显示出改进的性能。有关完整结果，请参阅我们的项目网页：https://sebulo.github.io/PuTT_website/ et.al.|[2406.04332](http://arxiv.org/abs/2406.04332)|**[link](https://github.com/sebulo/PuTT)**|
|**2024-06-06**|**Sparse Multi-baseline SAR Cross-modal 3D Reconstruction of Vehicle Targets**|由于数据稀疏性，多基线SAR三维成像面临着重大挑战。近年来，深度学习技术在提高稀疏SAR三维成像质量方面取得了显著成功。然而，以前的工作通常依赖于全孔径高分辨率雷达图像来监督深度神经网络（DNN）的训练，仅利用雷达数据中的单模态信息。因此，成像性能有限，并且获取多基线SAR的全孔径数据成本高昂，有时在现实应用中不切实际。在本文中，我们提出了一种跨模态重建网络（CMR-Net），该网络将可微分渲染和跨模态监督与光学图像相结合，将车辆目标的高度稀疏的多基线SAR 3D图像重建为视觉结构化和高分辨率的图像。我们精心设计了网络架构和训练策略，以增强网络泛化能力。值得注意的是，仅在模拟数据上训练的CMR-Net在公开的模拟数据集和实际测量数据集上都展示了高分辨率重建能力，优于基于压缩传感和其他基于学习的方法的传统稀疏重建算法。此外，使用光学图像作为监督提供了一种成本效益高的方法来构建训练数据集，降低了方法传播的难度。我们的工作展示了深度学习在多基线SAR三维成像中的广阔前景，并为基于跨模态学习理论的雷达成像研究提供了一条新的途径。 et.al.|[2406.04158](http://arxiv.org/abs/2406.04158)|null|

<p align=right>(<a href=#updated-on-20240611>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-10**|**IllumiNeRF: 3D Relighting without Inverse Rendering**|现有的可重新照明视图合成方法——使用一组未知照明下的对象图像来恢复可以在目标照明下从新视点渲染的3D表示——基于反向渲染，并试图解开解释输入图像的对象几何结构、材料和照明。此外，这通常涉及通过可微分蒙特卡罗渲染进行优化，这是脆弱的，并且计算成本很高。在这项工作中，我们提出了一种更简单的方法：我们首先使用以照明为条件的图像扩散模型重新照明每个输入图像，然后用这些重新照明的图像重建神经辐射场（NeRF），从中我们在目标照明下绘制新的视图。我们证明，这一战略具有惊人的竞争力，并在多个重新照明基准上取得了最先进的结果。请参阅我们的项目页面https://illuminerf.github.io/. et.al.|[2406.06527](http://arxiv.org/abs/2406.06527)|null|
|**2024-06-10**|**Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation**|我们介绍了LlamaGen，这是一个新的图像生成模型家族，它将大型语言模型的原始“下一个标记预测”范式应用于视觉生成领域。这是一个肯定的答案，如果缩放得当，在视觉信号上没有归纳偏差的香草自回归模型（例如Llama）是否可以实现最先进的图像生成性能。我们重新审视了图像标记器的设计空间、图像生成模型的可伸缩性特性及其训练数据质量。这项探索的结果包括：（1）图像标记器的下采样率为16，重建质量为0.94rFID，在ImageNet基准上码本使用率为97%。（2）一系列类别条件图像生成模型，参数范围从111M到3.1B，在ImageNet256x256基准上实现2.18FID，优于流行的扩散模型，如LDM、DiT。（3） 一个具有775M参数的文本条件图像生成模型，来自LAION-COCO和高美学质量图像的两阶段训练，展示了视觉质量和文本对齐的竞争性能。（4） 我们验证了LLM服务框架在优化图像生成模型推理速度方面的有效性，并实现了326%-414%的加速。我们发布所有模型和代码，以促进可视化生成和多模式基础模型的开源社区。 et.al.|[2406.06525](http://arxiv.org/abs/2406.06525)|**[link](https://github.com/foundationvision/llamagen)**|
|**2024-06-10**|**NaRCan: Natural Refined Canonical Image with Integration of Diffusion Prior for Video Editing**|我们提出了一种视频编辑框架NaRCan，它集成了混合变形场和扩散，然后生成高质量的自然规范图像来表示输入视频。我们的方法利用单应性对全局运动进行建模，并使用多层感知器（MLP）来捕捉局部残余变形，增强了模型处理复杂视频动态的能力。通过从训练的早期阶段引入扩散先验，我们的模型确保生成的图像保持高质量的自然外观，使生成的规范图像适合视频编辑中的各种下游任务，这是当前基于规范的方法无法实现的。此外，我们结合了低秩自适应（LoRA）微调，并引入了一种噪声和扩散先验更新调度技术，该技术将训练过程加速了14倍。大量的实验结果表明，我们的方法在各种视频编辑任务中优于现有方法，并产生了连贯和高质量的编辑视频序列。有关视频结果，请访问我们的项目页面https://koi953215.github.io/NaRCan_page/. et.al.|[2406.06523](http://arxiv.org/abs/2406.06523)|null|
|**2024-06-10**|**Monkey See, Monkey Do: Harnessing Self-attention in Motion Diffusion for Zero-shot Motion Transfer**|考虑到使用扩散模型进行运动合成的显著结果，一个自然的问题出现了：我们如何有效地利用这些模型进行运动编辑？现有的基于扩散的运动编辑方法忽略了嵌入预训练模型权重内的先验的深刻潜力，这使得能够操纵潜在特征空间；因此，它们主要集中在处理运动空间上。在这项工作中，我们探索了预先训练的运动扩散模型的注意力机制。我们揭示了注意力元素在捕捉和表现复杂的人类运动模式中的作用和相互作用，并仔细整合这些元素，将引导者的运动传递给跟随者，同时保持跟随者的细微特征，从而实现零样本运动传递。编辑与所选运动相关的特征使我们能够面对在先前的运动扩散方法中观察到的挑战，该方法使用一般指令（例如，文本、音乐）进行编辑，最终无法有效地传达细微的差别。我们的工作灵感来自猴子如何在保持其独特运动模式的同时密切模仿它所看到的东西；所以我们把它叫做“猴子看”、“猴子做”，并给它起名叫“莫莫”。使用我们的技术可以完成合成分布外运动、风格转换和空间编辑等任务。此外，扩散反演很少用于运动；因此，编辑工作集中在生成的运动上，限制了真实运动的可编辑性。MoMo利用运动反演，将其应用扩展到真实运动和生成运动。实验结果显示了我们的方法相对于现有技术的优势。特别是，与通过训练为特定应用量身定制的方法不同，我们的方法在推理时应用，不需要训练。我们的网页位于https://monkeyseedocg.github.io. et.al.|[2406.06508](http://arxiv.org/abs/2406.06508)|**[link](https://github.com/monkeyseedocg/momo-code)**|
|**2024-06-10**|**Rephasing spectral diffusion in time-bin spin-spin entanglement protocols**|产生高保真度的自旋-自旋纠缠是量子中继器网络在长距离分布量子信息的一项重要任务。基于固态的自旋光子界面是实现量子网络节点的有希望的候选者，但通常受到光学跃迁的光谱扩散的限制，这会导致纠缠态的相位误差。在这里，我们介绍了一种方法，通过将发射器搁置在激发态以重新聚焦未知相位，来校正纠缠态产生后准静态频率波动的相位误差。对于准静态频率波动，保真度仅由用于搁置的激发态的寿命决定，这使得它特别适用于具有相关光谱扩散的长寿命搁置态的系统。这种搁置状态可以在Kramers双光子系统中发现，例如稀土发射体和Si或SiC中的色心，它们与具有强频率依赖性Purcell增强的纳米光子腔接口。该协议可用于在不降低纠缠生成速率的情况下生成高保真纠缠自旋对。 et.al.|[2406.06497](http://arxiv.org/abs/2406.06497)|null|
|**2024-06-10**|**Probing the Heights and Depths of Y Dwarf Atmospheres: A Retrieval Analysis of the JWST Spectral Energy Distribution of WISE J035934.06 $-$540154.6**|我们对Y0棕矮星WISE J035934.06$-$540154.6进行了大气反演分析，使用了citet{Beiler_2023}中提出的低分辨率0.96-12$\mu$mJWST光谱。我们获得了主要气相吸收剂（H$_2$O、CH$_4$、CO、CO$_2$、PH$_3$和H$_2$S）的体积数混合比，其比以前使用HST光谱的工作精确3-5倍。我们还发现，JWST数据的宽波长覆盖直接导致了反演热剖面的精度提高了一个数量级。我们使用检索到的热剖面和表面重力生成了一个化学正演模型网格，该网格具有不同的金属度（C/O）$_\textrm{atm}$和由涡流扩散系数$K_\textrm｛zz｝$封装的垂直混合强度。检索到的丰度与该模型网格的比较表明，WISE 0359$-$54的深层大气显示出强烈的垂直混合迹象，$K_\textrm｛zz｝=10^9$[cm$^{2}$s$^{-1}$]。为了测试这些结果对我们的5节样条热剖面模型的敏感性，我们使用\citet｛Madhusudhan _2009｝热剖面模型进行了第二次检索。虽然两次检索的结果基本一致，但我们确实发现H$_2$S的质量和体积数混合比的检索值之间存在差异，中值的分数差异分别为$-$0.64和$-$ 0.10。此外，在1到70巴之间的压力下，5节的热剖面始终更热。尽管如此，我们的研究结果强调了詹姆斯·韦伯太空望远镜可获得的宽波长红外光谱对冷棕矮星大气层的表征能力。 et.al.|[2406.06493](http://arxiv.org/abs/2406.06493)|null|
|**2024-06-10**|**AID: Adapting Image2Video Diffusion Models for Instruction-guided Video Prediction**|文本引导视频预测（TVP）涉及根据指令从初始帧预测未来帧的运动，在虚拟现实、机器人和内容创建中具有广泛的应用。以前的TVP方法通过将稳定扩散应用于该任务而取得了重大突破。然而，主要由于视频数据集的规模有限，它们在帧一致性和时间稳定性方面存在困难。我们观察到，预训练的Image2视频扩散模型具有良好的视频动力学先验，但缺乏文本控制。因此，传输Image2Video模型以利用其视频动态先验，同时注入指令控制以生成可控视频，这既是一项有意义的任务，也是一项具有挑战性的任务。为了实现这一点，我们引入了多模式大语言模型（MLLM）来基于初始帧和文本指令预测未来的视频状态。更具体地说，我们设计了一种双查询转换器（DQFormer）架构，它将指令和帧集成到条件嵌入中，用于未来的帧预测。此外，我们开发了长短期时间适配器和空间适配器，可以以最低的训练成本将通用视频扩散模型快速转移到特定场景。实验结果表明，我们的方法在四个数据集上显著优于最先进的技术：SomethingSomething V2、Epic Kitchen-100、Bridge Data和UCF-101。值得注意的是，AID在Bridge和SSv2上分别实现了91.2%和55.5%的FVD改善，证明了其在各个领域的有效性。更多示例可在我们的网站上找到https://chenhsing.github.io/AID. et.al.|[2406.06465](http://arxiv.org/abs/2406.06465)|null|
|**2024-06-10**|**Cometh: A continuous-time discrete-state graph diffusion model**|离散状态去噪扩散模型在图生成方面，特别是在分子领域，带来了最先进的性能。最近，它们被转换为连续时间，允许在反向过程中有更大的灵活性，并在采样效率和质量之间有更好的权衡。在这里，为了利用这两种方法的优势，我们提出了Cometh，一种连续时间离散状态图扩散模型，将图数据集成到连续时间扩散模型框架中。从经验上看，我们表明，在一大组分子和非分子基准数据集上，与最先进的离散状态扩散模型相比，集成连续时间在各种指标上都有显著改进。 et.al.|[2406.06449](http://arxiv.org/abs/2406.06449)|null|
|**2024-06-10**|**QSSEP describes the fluctuations of quantum coherences in the Anderson model**|使用传递矩阵方法，我们数值研究了在零温度和线性响应下，当外部引线驱动金属相脱离平衡时，三维Anderson模型中的空间相干结构及其波动。我们发现稳态在纵向上具有非局部非高斯相关性，这是扩散非平衡稳态的特征。这些相关性与量子对称简单排除过程（QSSEP）中解析导出的相关性在数量上匹配，至少高达三阶，该过程描述了受动力学无序影响的1d中的扩散费米子。此外，这些相关性的大偏差标度和 $U（1）$ 不变性暗示了Anderson模型和自由概率理论之间的联系。我们的发现表明，在非相互作用的扩散量子系统中存在一种普遍的关联结构，该结构可能被QSSEP捕获。 et.al.|[2406.06444](http://arxiv.org/abs/2406.06444)|null|
|**2024-06-10**|**Margin-aware Preference Optimization for Aligning Diffusion Models without Reference**|基于人类偏好的现代对准技术，如RLHF和DPO，通常采用相对于参考模型的发散正则化来确保训练稳定性。然而，这往往限制了模型在对齐过程中的灵活性，尤其是当偏好数据和参考模型之间存在明显的分布差异时。在本文中，我们重点研究了最近的文本到图像扩散模型的对齐，如稳定扩散XL（SDXL），并发现由于视觉模态的非结构化性质，这种“参考不匹配”确实是对齐这些模型的一个重大问题：例如，对特定风格方面的偏好很容易导致这种差异。受这一观察结果的启发，我们为扩散模型提出了一种新的、记忆友好的偏好对齐方法，该方法不依赖于任何参考模型，即边际感知偏好优化（MaPO）。MaPO联合最大化优选图像集和不推荐图像集之间的可能性裕度以及优选图像集的可能性，同时学习一般的风格特征和偏好。为了进行评估，我们引入了两个新的成对偏好数据集，它们包括来自SDXL、Pick Style和Pick Safety的自生成图像对，模拟了参考不匹配的不同场景。我们的实验验证了当与Pick-a-Pic v2一起使用时，MaPO可以显著改善Pick Style和Pick Safety的对齐以及一般偏好对齐，超过了基本的SDXL和其他现有方法。我们的代码、模型和数据集可通过https://mapo-t2i.github.io et.al.|[2406.06424](http://arxiv.org/abs/2406.06424)|null|

<p align=right>(<a href=#updated-on-20240611>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-10**|**LOP-Field: Brain-inspired Layout-Object-Position Fields for Robotic Scene Understanding**|空间认知使动物具有非常高效的导航能力，这在很大程度上取决于对空间环境的场景级理解。最近，人们发现，大鼠大脑嗅后皮层的神经群体比场景中的物体更能强烈地适应空间布局。受局部场景中空间布局表示的启发，我们提出了实现布局对象位置（LOP）关联的LOP域，以对机器人场景理解的层次表示进行建模。在基础模型和隐式场景表示的支持下，神经场被实现为机器人的场景存储器，存储具有位置、对象和布局信息的场景的可查询表示。为了验证所建立的LOP关联，对该模型进行了测试，以使用定量指标从3D位置推断区域信息，实现了超过88%的平均准确度。还表明，与最先进的定位方法相比，所提出的使用区域信息的方法可以在文本和RGB输入的情况下实现改进的对象和视图定位结果。 et.al.|[2406.05985](http://arxiv.org/abs/2406.05985)|null|
|**2024-06-09**|**Grounding Continuous Representations in Geometry: Equivariant Neural Fields**|最近，神经场已经成为表示连续信号的强大建模范式。在条件神经领域中，一个领域由一个潜在变量表示，该变量对NeF进行了调节，否则其参数化将在整个数据集上共享。我们提出了基于交叉注意力变换器的等变神经场，其中NeFs以几何条件变量，即潜在点云为条件，从而实现从潜在到场的等变解码。我们的等变方法引入了一个可操纵性性质，通过该性质，场和势能都以几何为基础，并服从变换定律。如果场变换，势能相应地表示变换，反之亦然。至关重要的是，等变关系确保潜在的能够（1）真实地表示几何模式，允许在潜在空间中进行几何推理，（2）在空间相似的模式上进行权重共享，允许有效地学习场的数据集。与其他非等变NeF方法相比，使用分类实验和拟合整个数据集的能力验证了这些主要特性。我们通过展示独特的局部场编辑特性，进一步验证了ENF的潜力。 et.al.|[2406.05753](http://arxiv.org/abs/2406.05753)|null|
|**2024-06-06**|**ReFiNe: Recursive Field Networks for Cross-modal Multi-scene Representation**|最先进的多形状表示方法（单个模型“打包”多个对象）的常见权衡包括将建模精度与内存和存储进行权衡。我们展示了如何以比以前更高的精度和低内存使用率对表示为连续神经场的多个形状进行编码。我们方法的关键是利用对象自相似性的递归层次公式，从而产生高度压缩和高效的形状潜在空间。由于递归公式，我们的方法支持空间和全局到局部的潜在特征融合，而无需初始化和维护辅助数据结构，同时仍允许连续的字段查询，以实现光线跟踪等应用。在一组不同数据集上的实验中，我们提供了令人信服的定性结果，并展示了每个数据集使用单个网络的最先进的多场景重建和压缩结果。 et.al.|[2406.04309](http://arxiv.org/abs/2406.04309)|null|
|**2024-06-06**|**Vectorized Conditional Neural Fields: A Framework for Solving Time-dependent Parametric Partial Differential Equations**|变压器模型越来越多地用于求解偏微分方程（PDE）。已经提出了几种自适应方法，所有这些方法都存在变压器的典型问题，如二次记忆和时间复杂性。此外，用于PDE求解的所有流行体系结构都缺乏理想代理模型的几个期望性质中的至少一个，例如（i）对训练期间未看到的PDE参数的泛化，（ii）空间和时间零样本超分辨率，（iii）连续时间外推，（iv）对1D、2D和3D PDE的支持，以及（v）对更长时间展开的有效推断。为了解决这些局限性，我们提出了矢量化条件神经场（VCNeFs），它将时间相关偏微分方程的解表示为神经场。然而，与先前的方法相反，对于一组多个时空查询点，VCNeF并行计算它们的解决方案，并通过注意力机制对它们的依赖性进行建模。此外，VCNeF可以根据偏微分方程的初始条件和参数来调节神经场。一组广泛的实验表明，VCNeF与现有的基于ML的代理模型具有竞争力，并且往往优于现有的代理模型。 et.al.|[2406.03919](http://arxiv.org/abs/2406.03919)|**[link](https://github.com/jhagnberger/vcnef)**|
|**2024-06-05**|**Dynamic 3D Gaussian Fields for Urban Areas**|我们提出了一种用于大规模动态城市区域的新型视图合成（NVS）的高效神经3D场景表示。现有作品由于其有限的视觉质量和非交互式渲染速度，不太适合混合现实或闭环模拟等应用。最近，基于光栅化的方法已经以令人印象深刻的速度实现了高质量的NVS。然而，这些方法仅限于小规模、同质的数据，即它们不能处理由于天气、季节和照明而引起的严重外观和几何变化，也不能扩展到具有数千张图像的更大的动态区域。我们提出了4DGF，这是一种神经场景表示，可扩展到大规模动态城市区域，处理异构输入数据，并显著提高渲染速度。我们使用3D高斯作为有效的几何支架，同时依赖神经场作为紧凑灵活的外观模型。我们在全局范围内通过场景图集成场景动力学，同时通过变形在局部范围内建模关节运动。这种分解方法实现了适用于真实世界应用程序的灵活场景合成。在实验中，我们的PSNR超过了最先进的3 dB，渲染速度超过了200倍。 et.al.|[2406.03175](http://arxiv.org/abs/2406.03175)|null|
|**2024-06-04**|**A fast neural emulator for interstellar chemistry**|天体化学模型是解释不同环境中分子和原子物种观测结果的重要工具。然而，这些模型非常耗时，妨碍了对参数空间的彻底探索，导致了不确定性和偏差结果。使用神经网络来模拟天体化学模型的行为是规避这一问题的一种方法，它可以基于真实的天体化学模型提供快速计算。在本文中，我们提出了一个基于条件神经场的天文化学代码Nautilus的快速神经模拟器。由此产生的模型在1到10 $^7$年之间的任意时间内产生了192种物种的丰度。所有物种的不确定性都远低于0.2 dex，而计算时间比Nautilus小10$^4$ 。这将为执行更复杂的正向模型以更好地了解星际介质的物理性质开辟可能性。作为这些模型威力的一个例子，我们对Nautilus预测的电子丰度进行了特征重要性分析。我们发现，在低密度气体中，电子密度与初始硫丰度有关。将初始硫丰度从耗尽的情况增加到宇宙丰度会导致电子密度增加一个数量级。这种增强可能会对恒星形成地点的气体动力学产生潜在影响。 et.al.|[2406.02387](http://arxiv.org/abs/2406.02387)|null|
|**2024-06-05**|**AROMA: Preserving Spatial Structure for Latent PDE Modeling with Local Neural Fields**|我们提出了AROMA（带注意力的注意力降阶模型），这是一个旨在使用局部神经场增强偏微分方程（PDE）建模的框架。我们灵活的编码器-解码器架构可以从各种数据类型中获得空间物理场的平滑潜在表示，包括不规则网格输入和点云。这种多功能性消除了打补丁的需要，并允许高效处理各种几何形状。我们的潜在表示的顺序性质可以在空间上进行解释，并允许使用条件转换器来建模偏微分方程的时间动力学。通过采用基于扩散的公式，与传统的MSE训练相比，我们实现了更大的稳定性，并实现了更长的推广时间。AROMA在模拟1D和2D方程方面的卓越性能突显了我们的方法在捕捉复杂动力学行为方面的有效性。 et.al.|[2406.02176](http://arxiv.org/abs/2406.02176)|null|
|**2024-06-04**|**Activity patterns in ring networks of quadratic integrate-and-fire neurons with synaptic and gap junction coupling**|我们考虑具有非局部突触和间隙连接耦合的二次积分和激发神经元的环形网络。相应的神经场模型支持驻波和行波以及倾斜波等解决方案。我们证明了这些解中的许多都满足自洽方程，当参数变化时，自洽方程可以用来跟随它们。我们对神经场模型进行了数值分叉分析，重点研究了不同间隙结耦合强度的影响。我们的方法通常适用于各种各样的二次积分和激发神经元网络。 et.al.|[2406.01881](http://arxiv.org/abs/2406.01881)|null|
|**2024-06-03**|**Enhancing Dynamic CT Image Reconstruction with Neural Fields Through Explicit Motion Regularizers**|具有高度欠采样数据的动态逆问题的图像重建提出了一个主要挑战：不考虑过程的动力学会导致没有时间规律的不真实运动。已经提出了惩罚时间导数或引入运动模型正则化子的变分方法，以使用基于网格的离散化来关联后续帧并提高图像质量。神经场通过深度神经网络提供了所需时空量的替代参数化，这是一种轻量级、连续且偏向于平滑表示的网络。归纳偏差已被用于增强动态逆问题的时间规律性，从而仅通过最小化数据保真度项来优化神经场。在本文中，我们研究并展示了在2D+时间计算机断层扫描中引入基于显式PDE的运动正则化子，即光流方程，用于优化神经场的好处。我们还将神经场与基于网格的求解器进行了比较，并表明前者的性能优于后者。 et.al.|[2406.01299](http://arxiv.org/abs/2406.01299)|null|
|**2024-06-03**|**Pattern Formation in a Spiking Neural-Field of Renewal Neurons**|阐明神经模式形成背后的神经生理学机制仍然是计算神经科学中的一个突出挑战。在这篇论文中，我们通过考虑更新神经元网络来解决理解神经模式出现的问题，更新神经元是一类公认的尖峰细胞。在热力学极限下，网络的动力学可以精确地用一个偏微分方程和一个非局部微分方程来表示。确定了非局部系统的稳态，并进行了扰动分析，以分析表征图灵不稳定性发生的条件。考虑到突触耦合和外部驱动等神经网络参数，我们用数值方法获得了将异步状态与模式出现分开的分叉线。我们的理论发现为尖峰神经网络中图灵模式的出现提供了一个新的、有见地的视角。从长远来看，我们的形式主义将能够研究神经模式，同时保持微观细胞特性、网络耦合和图灵不稳定性的出现之间的联系。 et.al.|[2406.01167](http://arxiv.org/abs/2406.01167)|null|

<p align=right>(<a href=#updated-on-20240611>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

