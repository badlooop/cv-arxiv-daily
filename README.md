[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2026.02.15
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#video-diffusion>Video Diffusion</a></li>
    <li><a href=#3d>3D</a></li>
    <li><a href=#具生智能&自动驾驶>具生智能&自动驾驶</a></li>
  </ol>
</details>

## Video Diffusion

- **2026-02-12** **MonarchRT: Efficient Attention for Real-Time Video Generation** [2602.12271](http://arxiv.org/abs/2602.12271)
  > 使用扩散变压器的实时视频生成受到 3D 自注意力二次成本的瓶颈，特别是在少步和自回归的实时机制中，其中误差随时间复合，每个去噪步骤必须携带更多信息。在这种情况下，我们发现尽管双向、多步扩散显示出很强的结果，但先前的稀疏注意力近似方法还是失效了。具体来说，我们观察到视频注意力并不是可靠的稀疏，而是将由时空位置驱动的显着周期结构与动态、稀疏语义对应和密集混合相结合，甚至超过了 oracle top-k 注意力的表示能力。基于这一见解，我们提出了 Monarch-RT，这是一种用于视频扩散模型的结构化注意力参数化，它使用 Monarch 矩阵分解注意力。通过适当对齐的块结构和扩展的平铺 Monarch 参数化，我们在保持计算效率的同时实现了高表达力。我们通过使用自定义 Triton 内核进行微调，进一步克服了参数化的开销。我们首先验证 Monarch-RT 相对于仅为双向模型设计的现有稀疏基线的高效性。我们进一步观察到，当应用于最先进的模型 Self-Forcing 时，Monarch-RT 获得了高达 95% 的注意力稀疏度，且质量没有损失，这使得 Monarch-RT 成为实时视频生成的高性能稀疏注意力参数化的开创性工作。我们的优化实现在 Nvidia RTX 5090、H100 和 B200 GPU 上的性能分别优于 FlashAttention-2、FlashAttention-3 和 FlashAttention-4 内核，提供 1.4-11.8 倍的内核加速。这使我们第一次能够在单个 RTX 5090 上以 16 FPS 的速度实现真正的实时视频生成。

- **2026-02-12** **DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation** [2602.12160](http://arxiv.org/abs/2602.12160)
  > 基础模型的最新进展彻底改变了联合音频视频生成。然而，现有方法通常将以人为中心的任务视为孤立的目标，包括基于参考的音频视频生成（R2AV）、视频编辑（RV2AV）和音频驱动视频动画（RA2V）。此外，在单一框架内实现对多个角色身份和音色的精确、分离的控制仍然是一个开放的挑战。在本文中，我们提出了 DreamID-Omni，这是一个用于可控的以人为中心的音频视频生成的统一框架。具体来说，我们设计了一个对称条件扩散变压器，它通过对称条件注入方案集成异构调节信号。为了解决多人场景中普遍存在的身份-音色绑定失败和说话者混乱的问题，我们引入了一种双层解缠策略：信号级别的同步 RoPE 以确保严格的注意力空间绑定，语义级别的结构化字幕以建立明确的属性-主题映射。此外，我们设计了一种多任务渐进训练方案，利用弱约束的生成先验来规范强约束的任务，防止过度拟合并协调不同的目标。大量实验表明，DreamID-Omni 在视频、音频和视听一致性方面实现了全面的最先进性能，甚至超越了领先的专有商业模型。我们将发布我们的代码，以弥合学术研究和商业级应用程序之间的差距。

- **2026-02-12** **FAIL: Flow Matching Adversarial Imitation Learning for Image Generation** [2602.12155](http://arxiv.org/abs/2602.12155)
  > 流匹配模型的后训练——将输出分布与高质量目标对齐——在数学上等同于模仿学习。虽然监督微调有效地模仿了专家的演示，但它无法纠正看不见的状态中的政策漂移。偏好优化方法可以解决这个问题，但需要昂贵的偏好对或奖励建模。我们提出了流匹配对抗性模仿学习（FAIL），它通过对抗性训练来最小化政策专家分歧，而无需明确的奖励或成对比较。我们推导出两种算法：FAIL-PD 利用可微分 ODE 求解器来实现低方差路径梯度，而 FAIL-PG 则为离散或计算约束设置提供黑盒替代方案。仅通过 Nano Banana pro 的 13,000 次演示对 FLUX 进行微调，FAIL 在快速跟随和美学基准方面实现了具有竞争力的性能。此外，该框架有效地推广到离散图像和视频生成，并作为强大的正则化器来减轻基于奖励的优化中的奖励黑客行为。代码和数据可在 https://github.com/HansPolo113/FAIL 获取。

- **2026-02-12** **HLA: Hadamard Linear Attention** [2602.12128](http://arxiv.org/abs/2602.12128)
  > 注意力机制是 Transformer 成功的重要原因。它依赖于计算标记之间的成对关系。为了降低标准二次注意力的高计算成本，线性注意力被提出作为一种有效的近似。它采用在计算成对相似度之前独立应用于输入的核函数。这允许高效的计算过程，然而，这相当于一个逼近 softmax 的低次有理函数。   我们提出哈达玛线性注意力（HLA）。与之前的线性注意力工作不同，HLA 中的非线性不是单独应用于查询和键，而是类似于标准的 softmax 注意力，在计算成对相似性之后应用。将会表明，所提出的非线性相当于一个更高阶的有理函数来近似 softmax。推导了所提出方法的有效计算方案，该方案类似于标准线性注意的方案。与其他方法相比，应用所提出的算法不需要耗时的张量整形。该方法的有效性通过将其应用于用于视频生成的大型扩散变压器模型（涉及大量令牌的应用程序）来证明。

- **2026-02-12** **VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model** [2602.12063](http://arxiv.org/abs/2602.12063)
  > 本文的目标是通过迭代在线交互来提高视觉-语言-动作（VLA）模型的性能和可靠性。由于在现实世界中收集策略推出的成本很高，因此我们研究了是否可以使用学习的模拟器（具体而言，动作条件视频生成模型）来生成额外的推出数据。不幸的是，现有的世界模型缺乏政策改进所需的物理保真度：它们主要是在演示数据集上进行训练的，这些数据集缺乏对许多不同物理交互（特别是失败案例）的覆盖，并且很难在接触丰富的对象操作中准确地模拟微小但关键的物理细节。我们提出了一种简单的迭代改进算法，该算法使用现实世界的转出数据来提高世界模型的保真度，然后可以使用该算法生成补充合成数据以改进 VLA 模型。在我们对真实机器人的实验中，我们使用这种方法来提高最先进的 VLA 模型在多个下游任务上的性能。与基本策略相比，我们的绝对成功率提高了 39.2%，通过生成的综合部署进行训练，绝对成功率提高了 11.6%。视频可以在这个匿名网站上找到：https://sites.google.com/view/vla-w

- **2026-02-12** **Beyond End-to-End Video Models: An LLM-Based Multi-Agent System for Educational Video Generation** [2602.11790](http://arxiv.org/abs/2602.11790)
  > 尽管最近的端到端视频生成模型在面向视觉的内容创建方面表现出了令人印象深刻的性能，但它们在需要严格逻辑严谨性和精确知识表示的场景中仍然受到限制，例如教学和教育媒体。为了解决这个问题，我们提出了 LAVES，一种基于 LLM 的分层多智能体系统，用于根据教育问题生成高质量的教学视频。 LAVES 将教育视频生成制定为一项多目标任务，同时要求正确的逐步推理、教学上连贯的叙述、语义上忠实的视觉演示以及精确的视听对齐。为了解决先前方法的局限性（包括程序保真度低、生产成本高和可控性有限），LAVES 将生成工作流程分解为由具有明确质量门和迭代批评机制的中央编排代理协调的专门代理。具体来说，编排代理监督解决方案代理以严格解决问题，插图代理生成可执行的可视化代码，以及叙述代理以用于面向学习者的教学脚本。此外，工作代理的所有输出都受到语义批评、基于规则的约束和基于工具的编译检查。该系统不是直接合成像素，而是构建一个结构化的可执行视频脚本，该脚本使用模板驱动的组装规则确定性地编译成同步的视觉效果和旁白，从而实现完全自动化的端到端制作，无需手动编辑。在大规模部署中，LAVES 的吞吐量每天超过 100 万个视频，与当前行业标准方法相比，成本降低了 95% 以上，同时保持了较高的接受率。

- **2026-02-12** **LUVE : Latent-Cascaded Ultra-High-Resolution Video Generation with Dual Frequency Experts** [2602.11564](http://arxiv.org/abs/2602.11564)
  > 视频扩散模型的最新进展显着提高了视觉质量，但由于运动建模、语义规划和细节合成的复杂困难，超高分辨率 (UHR) 视频生成仍然是一个艰巨的挑战。为了解决这些限制，我们提出了 \textbf{LUVE}，一个基于双频 \textbf{E}xperts 构建的 \textbf{L}atent 级联 \textbf{U}HR \textbf{V}ideo 生成框架。 LUVE 采用三阶段架构，包括用于运动一致潜在合成的低分辨率运动生成、直接在潜在空间中执行分辨率上采样以减轻内存和计算开销的视频潜在上采样，以及集成低频和高频专家以共同增强语义一致性和细粒度细节生成的高分辨率内容细化。大量实验表明，我们的 LUVE 在 UHR 视频生成中实现了卓越的照片真实感和内容保真度，全面的消融研究进一步验证了每个组件的有效性。该项目位于 \href{https://unicornanrocinu.github.io/LUVE_web/}{https://github.io/LUVE/}。

- **2026-02-11** **H-WM: Robotic Task and Motion Planning Guided by Hierarchical World Model** [2602.11291](http://arxiv.org/abs/2602.11291)
  > 世界模型正在成为机器人规划和控制的核心，因为它们能够预测未来的状态转换。现有的方法通常强调视频生成或自然语言预测，这些方法很难直接反映机器人的动作，并且在长期范围内会出现复合错误。传统的任务和运动规划依赖于符号逻辑世界模型，例如规划域，这些模型是机器人可执行的并且对于长视野推理来说是鲁棒的。然而，这些方法通常独立于视觉感知进行操作，从而阻止了同步的符号和感知状态预测。我们提出了一种分层世界模型（H-WM），它在统一的双层框架内联合预测逻辑和视觉状态转换。 H-WM 将高级逻辑世界模型与低级视觉世界模型相结合，将机器人可执行的符号推理的长期鲁棒性与视觉观察的感知基础相结合。分层输出为长期任务提供稳定一致的中间指导，减少错误累积并实现跨扩展任务序列的稳健执行。为了训练 H-WM，我们引入了一个机器人数据集，该数据集将机器人运动与符号状态、动作和视觉观察对齐。视觉-语言-动作（VLA）控制策略的实验证明了该方法的有效性和通用性。

- **2026-02-11** **SurfPhase: 3D Interfacial Dynamics in Two-Phase Flows from Sparse Videos** [2602.11154](http://arxiv.org/abs/2602.11154)
  > 两相流中的界面动力学控制动量、热量和质量传递，但仍然难以通过实验测量。经典技术在移动界面附近面临固有的局限性，而现有的神经渲染方法针对具有扩散边界的单相流，无法处理尖锐、可变形的液-气界面。我们提出了 SurfPhase，一种从稀疏相机视图重建 3D 界面动力学的新颖模型。我们的方法将动态高斯面元与带符号距离函数公式相结合以实现几何一致性，并利用视频扩散模型来合成新颖的视图视频，以改进稀疏观测的重建。我们对高速池沸腾视频的新数据集进行了评估，仅通过两个摄像机视图演示了高质量的视图合成和速度估计。项目网站：https://yuegao.me/SurfPhase。

- **2026-02-11** **HairWeaver: Few-Shot Photorealistic Hair Motion Synthesis with Sim-to-Real Guided Video Diffusion** [2602.11117](http://arxiv.org/abs/2602.11117)
  > 我们推出了 HairWeaver，这是一种基于扩散的管道，可以通过逼真且富有表现力的头发动态来对单个人类图像进行动画处理。虽然现有方法成功地控制了身体姿势，但它们缺乏对头发的具体控制，因此无法捕捉复杂的头发运动，导致动画僵硬且不切实际。 HairWeaver 使用两个专用模块克服了这一限制：一个用于集成运动条件的 Motion-Context-LoRA，另一个是 Sim2Real-Domain-LoRA，用于在不同数据域中保留主体的真实外观。这些轻量级组件旨在指导视频传播主干，同时保持其核心生成功能。通过对 CG 模拟器生成的动态人体运动的专门数据集进行训练，HairWeaver 可以对头发运动进行精细控制，并最终学会生成对运动做出自然响应的高度逼真的头发。综合评估表明，我们的方法树立了新的技术水平，可以制作具有动态细节的逼真的人发动画。

- **2026-02-11** **FastFlow: Accelerating The Generative Flow Matching Models with Bandit Inference** [2602.11105](http://arxiv.org/abs/2602.11105)
  > 流匹配模型在图像和视频生成中提供最先进的保真度，但固有的顺序去噪过程使它们速度变慢。现有的加速方法（例如蒸馏、轨迹截断和一致性方法）是静态的，需要重新训练，并且通常无法跨任务泛化。我们提出了 FastFlow，一种即插即用的自适应推理框架，可加速流匹配模型的生成。 FastFlow 识别仅对去噪路径产生微小调整的去噪步骤，并在不使用用于速度预测的完整神经网络模型的情况下对其进行近似。该近似利用先前预测的有限差分速度估计来有效地推断未来状态，从而以零计算成本沿着去噪路径实现更快的进展。这使得能够跳过中间步骤的计算。我们将在需要完整模型计算之前安全跳过多少步骤的决策建模为多臂老虎机问题。老虎机学习最佳跳跃以平衡速度与性能。 FastFlow 与现有管道无缝集成，并可泛化图像生成、视频生成和编辑任务。实验表明，在保持高质量输出的同时，速度提高了 2.6 倍以上。这项工作的源代码可以在 https://github.com/Div290/FastFlow 找到。

- **2026-02-11** **Flow caching for autoregressive video generation** [2602.10825](http://arxiv.org/abs/2602.10825)
  > 自回归模型通常建立在 Transformer 架构之上，代表了通过合成连续块中的内容来生成超长视频的强大范例。然而，这种顺序生成过程是出了名的慢。虽然缓存策略已被证明对于加速传统视频扩散模型是有效的，但现有方法假设所有帧都采用统一的去噪——这种假设在自回归模型中被打破，其中不同的视频块在相同的时间步长表现出不同的相似性模式。在本文中，我们介绍了 FlowCache，这是第一个专为自回归视频生成而设计的缓存框架。我们的主要见解是每个视频块应该维护独立的缓存策略，从而可以对每个时间步需要重新计算的块进行细粒度控制。我们引入了一种分块缓存策略，该策略动态适应每个块的独特去噪特性，并辅以联合重要性冗余优化的 KV 缓存压缩机制，该机制在保持固定内存边界的同时保持生成质量。我们的方法在 MAGI-1 上实现了 2.38 倍的显着加速，在 SkyReels-V2 上实现了 6.7 倍的显着加速，而质量下降可以忽略不计（VBench：分别增加 0.87 倍和减少 0.79 倍）。这些结果表明，FlowCache 成功释放了自回归模型在实时、超长视频生成方面的潜力，为大规模高效视频合成建立了新基准。该代码可从 https://github.com/mikeallen39/FlowCache 获取。

- **2026-02-11** **Say, Dream, and Act: Learning Video World Models for Instruction-Driven Robot Manipulation** [2602.10717](http://arxiv.org/abs/2602.10717)
  > 机器人操纵需要预测环境如何响应行动而演变，但大多数现有系统缺乏这种预测能力，常常导致错误和低效率。虽然视觉语言模型（VLM）提供高级指导，但它们无法明确预测未来状态，并且现有的世界模型要么仅预测短期情况，要么产生空间不一致的框架。为了应对这些挑战，我们提出了一个快速、预测性视频条件动作框架。我们的方法首先选择并调整一个强大的视频生成模型，以确保可靠的未来预测，然后应用对抗性蒸馏来快速、几步视频生成，最后训练一个动作模型，利用生成的视频和真实观察来纠正空间错误。大量的实验表明，我们的方法产生时间上一致、空间上准确的视频预测，直接支持精确操作，在现有基线的基础上实现了实施例一致性、空间参考能力和任务完成度的显着改进。代码和型号将被发布。

- **2026-02-11** **TwiFF (Think With Future Frames): A Large-Scale Dataset for Dynamic Visual Reasoning** [2602.10675](http://arxiv.org/abs/2602.10675)
  > 视觉思维链（VCoT）已成为一种有前途的范式，通过将视觉感知集成到中间推理步骤来增强多模态推理。然而，现有的 VCoT 方法主要局限于静态场景，难以捕捉指令、预测和相机运动等任务所必需的时间动态。为了弥补这一差距，我们提出了 TwiFF-2.7M，这是第一个大规模、基于时间的 VCoT 数据集，源自价值 270 万美元的视频剪辑，专门为动态视觉问答而设计。与此同时，我们推出了 TwiFF-Bench，这是一个包含 1,078 美元样本的高质量评估基准，用于评估开放式动态设置中推理轨迹的合理性和最终答案的正确性。在此基础上，我们提出了 TwiFF 模型，这是一种统一模式，协同利用预先训练的视频生成和图像理解功能来产生时间连贯的视觉推理线索，迭代地生成未来的动作框架和文本推理。大量实验表明，TwiFF 在动态推理任务上显着优于现有的 VCoT 方法和文本思维链基线，充分验证了动态场景下视觉问答的有效性。我们的代码和数据可在 https://github.com/LiuJunhua02/TwiFF 获取。

- **2026-02-10** **ConsID-Gen: View-Consistent and Identity-Preserving Image-to-Video Generation** [2602.10113](http://arxiv.org/abs/2602.10113)
  > 图像到视频生成 (I2V) 将静态图像按照文本指令动画化为时间连贯的视频序列，但在不断变化的视点下保留细粒度的对象身份仍然是一个持续的挑战。与文本到视频模型不同，现有的 I2V 管道经常遭受外观漂移和几何失真的影响，我们将这些伪影归因于单视图 2D 观察的稀疏性和弱的跨模式对齐。这里我们从数据和模型两个角度来解决这个问题。首先，我们策划 ConsIDVid，这是一个以可扩展管道构建的大规模以对象为中心的数据集，用于高质量、时间对齐的视频，并建立 ConsIDVid-Bench，在其中我们使用对细微几何和外观偏差敏感的指标，提出了一种新颖的多视图一致性基准测试和评估框架。我们进一步提出 ConsID-Gen，一种视图辅助的 I2V 生成框架，它通过未设置的辅助视图增强第一帧，并通过双流视觉几何编码器以及文本视觉连接器融合语义和结构线索，为 Diffusion Transformer 主干产生统一条件。 ConsIDVid-Bench 的实验表明，ConsID-Gen 在多个指标上始终表现出色，其最佳整体性能超越了 Wan2.1 和 HunyuanVideo 等领先的视频生成模型，在具有挑战性的现实场景下提供卓越的身份保真度和时间一致性。我们将在 https://myangwu.github.io/ConsID-Gen 发布我们的模型和数据集。

- **2026-02-10** **DexImit: Learning Bimanual Dexterous Manipulation from Monocular Human Videos** [2602.10105](http://arxiv.org/abs/2602.10105)
  > 数据稀缺从根本上限制了双手灵巧操作的普及，因为灵巧手的现实世界数据收集成本高昂且劳动密集型。人类操作视频作为操作知识的直接载体，为扩大机器人学习提供了巨大的潜力。然而，人手和机器人灵巧手之间的巨大体现差距使得从人类视频直接进行预训练极具挑战性。为了弥补这一差距并释放大规模人类操纵视频数据的潜力，我们提出了 DexImit，这是一种自动化框架，可以将单眼人类操纵视频转换为物理上合理的机器人数据，而无需任何附加信息。 DexImit 采用四阶段生成流程：（1）从任意视角以接近公制的尺度重建手部与物体的交互； (2)进行子任务分解和双手调度； (3) 合成与所演示的交互一致的机器人轨迹； (4) 全面的数据增强，用于零次现实世界部署。基于这些设计，DexImit 可以根据来自互联网或视频生成模型的人类视频生成大规模机器人数据。 DexImit 能够处理各种操作任务，包括工具使用（例如切苹果）、长期任务（例如制作饮料）和细粒度操作（例如堆叠杯子）。

- **2026-02-10** **VideoWorld 2: Learning Transferable Knowledge from Real-world Videos** [2602.10102](http://arxiv.org/abs/2602.10102)
  > 从未标记的视频数据中学习可转移的知识并将其应用到新环境中是智能代理的基本能力。这项工作提出了 VideoWorld 2，它扩展了 VideoWorld，并首次对直接从原始现实世界视频中学习可转移知识进行了研究。 VideoWorld 2 的核心引入了动态增强的潜在动态模型 (dLDM)，它将动作动态与视觉外观分离：预训练的视频扩散模型处理视觉外观建模，使 dLDM 能够学习专注于紧凑且有意义的任务相关动态的潜在代码。然后对这些潜在代码进行自回归建模，以学习任务策略并支持长期推理。我们在具有挑战性的现实世界手工制作任务中评估了 VideoWorld 2，其中先前的视频生成和潜在动态模型难以可靠运行。值得注意的是，VideoWorld 2 将任务成功率提高了 70%，并生成连贯的长执行视频。在机器人技术中，我们证明 VideoWorld 2 可以从 Open-X 数据集中获取有效的操作知识，这大大提高了 CALVIN 上的任务性能。这项研究揭示了直接从原始视频中学习可转移的世界知识的潜力，所有代码、数据和模型都将开源以供进一步研究。

- **2026-02-10** **Causality in Video Diffusers is Separable from Denoising** [2602.10095](http://arxiv.org/abs/2602.10095)
  > 因果关系——指的是组件之间的时间性、单向因果关系——是许多复杂生成过程的基础，包括视频、语言和机器人轨迹。当前的因果扩散模型将时间推理与迭代去噪结合起来，在所有层、每个去噪步骤以及整个上下文中应用因果注意力。在本文中，我们证明这些模型中的因果推理与多步骤去噪过程是可分离的。通过对自回归视频扩散器的系统探测，我们发现了两个关键规律：（1）早期层在去噪步骤中产生高度相似的特征，表明沿扩散轨迹的冗余计算； （2）更深的层表现出稀疏的跨帧注意力，并且主要执行帧内渲染。受这些发现的启发，我们引入了可分离因果扩散（SCD），这是一种新架构，它通过因果变换编码器将每帧一次的时间推理与通过轻量级扩散解码器的多步逐帧渲染明确解耦。对合成基准和真实基准的训练前和训练后任务进行的大量实验表明，SCD 显着提高了吞吐量和每帧延迟，同时匹配或超越了强因果扩散基准的生成质量。

- **2026-02-10** **Monocular Normal Estimation via Shading Sequence Estimation** [2602.09929](http://arxiv.org/abs/2602.09929)
  > 单目法线估计旨在从任意光照下物体的单个 RGB 图像估计法线图。现有方法依赖深度模型来直接预测法线贴图。然而，它们经常遭受 3D 未对准的影响：虽然估计的法线贴图可能看起来具有正确的外观，但重建的表面通常无法与几何细节对齐。我们认为这种错位源于当前的范式：模型难以区分和重建法线贴图中表示的不同几何形状，因为底层几何形状的差异仅通过相对微妙的颜色变化反映出来。为了解决这个问题，我们提出了一种新的范式，将法线估计重新表述为着色序列估计，其中着色序列对各种几何信息更加敏感。在此范例的基础上，我们提出了 RoSE，一种利用图像到视频生成模型来预测着色序列的方法。然后通过解决简单的普通最小二乘问题将预测的着色序列转换为法线贴图。为了增强鲁棒性并更好地处理复杂对象，RoSE 在具有不同形状、材料和光照条件的合成数据集 MultiShade 上进行训练。实验表明，RoSE 在基于对象的单目法线估计的真实世界基准数据集上实现了最先进的性能。

- **2026-02-10** **AdaTSQ: Pushing the Pareto Frontier of Diffusion Transformers via Temporal-Sensitivity Quantization** [2602.09883](http://arxiv.org/abs/2602.09883)
  > 扩散变压器 (DiT) 已成为高保真图像和视频生成的最先进的支柱。然而，它们巨大的计算成本和内存占用阻碍了在边缘设备上的部署。虽然训练后量化 (PTQ) 已被证明对大型语言模型 (LLM) 有效，但由于忽略了扩散过程中固有的独特时间动态，直接将现有方法应用于 DiT 会产生次优结果。在本文中，我们提出了 AdaTSQ，这是一种新颖的 PTQ 框架，它通过利用 DiT 的时间敏感性来推动效率和质量的帕累托前沿。首先，我们提出了帕累托感知时间步动态位宽分配策略。我们将量化策略搜索建模为受限寻路问题。我们利用由端到端重建误差引导的波束搜索算法来跨不同时间步动态分配分层位宽。其次，我们提出了费舍尔引导的时间校准机制。它利用时态 Fisher 信息对来自高度敏感时间步长的校准数据进行优先级排序，与基于 Hessian 的权重优化无缝集成。对四种先进 DiT（例如 Flux-Dev、Flux-Schnell、Z-Image 和 Wan2.1）的大量实验表明，AdaTSQ 的性能显着优于 SVDQuant 和 ViDiT-Q 等最先进的方法。我们的代码将发布在https://github.com/Qiushao-E/AdaTSQ。

- **2026-02-10** **Free-GVC: Towards Training-Free Extreme Generative Video Compression with Temporal Coherence** [2602.09868](http://arxiv.org/abs/2602.09868)
  > 基于视频生成领域的最新进展，生成视频压缩已成为实现视觉上令人愉悦的重建的新范例。然而，现有方法对时间相关性的利用有限，导致在超低比特率下出现明显的闪烁和时间相干性下降。在本文中，我们提出了 Free-GVC，这是一种免训练的生成视频压缩框架，它将视频编码重新表述为由视频扩散先验引导的潜在轨迹压缩。我们的方法在图片组（GOP）级别上运行，将视频片段编码到紧凑的潜在空间中，并沿着扩散轨迹逐步压缩它们。为了确保跨 GOP 的感知一致重建，我们引入了自适应质量控制模块，该模块动态构建在线速率感知代理模型来预测每个 GOP 的最佳扩散步骤。此外，GOP 间对齐模块可建立帧重叠并在相邻组之间执行潜在融合，从而减轻闪烁并增强时间一致性。实验表明，与最新的神经编解码器 DCVC-RT 相比，Free-GVC 在 DISTS 中实现了平均 93.29% 的 BD-Rate 降低，并且用户研究进一步证实了其在超低比特率下的卓越感知质量和时间一致性。

- **2026-02-10** **Tele-Omni: a Unified Multimodal Framework for Video Generation and Editing** [2602.09609](http://arxiv.org/abs/2602.09609)
  > 基于扩散的视频生成的最新进展极大地提高了视觉保真度和时间连贯性。然而，大多数现有方法仍然是特定于任务的，并且主要依赖于文本指令，限制了它们在统一框架内处理多模式输入、上下文参考以及不同视频生成和编辑场景的能力。此外，许多视频编辑方法依赖于针对单独操作精心设计的管道，这阻碍了可扩展性和可组合性。在本文中，我们提出了 Tele-Omni，这是一种用于视频生成和编辑的统一多模式框架，它遵循单一模型中的多模式指令，包括文本、图像和参考视频。 Tele-Omni 利用预训练的多模态大语言模型来解析异构指令并推断结构化生成或编辑意图，而基于扩散的生成器则根据这些结构化信号执行高质量视频合成。为了实现跨异构视频任务的联合训练，我们引入了任务感知数据处理管道，它将多模态输入统一为结构化指令格式，同时保留特定于任务的约束。 Tele-Omni 支持各种以视频为中心的任务，包括文本到视频生成、图像到视频生成、首尾帧视频生成、上下文视频生成和上下文视频编辑。通过将指令解析与视频合成解耦并将其与任务感知数据设计相结合，Tele-Omni 实现了灵活的多模式控制，同时保持了强大的时间连贯性和视觉一致性。实验结果表明，Tele-Omni 在多项任务中实现了具有竞争力的性能。

- **2026-02-10** **Hand2World: Autoregressive Egocentric Interaction Generation via Free-Space Hand Gestures** [2602.09600](http://arxiv.org/abs/2602.09600)
  > 以自我为中心的交互式世界模型对于增强现实和嵌入式人工智能至关重要，其中视觉生成必须以低延迟、几何一致性和长期稳定性响应用户输入。我们研究自由空间手势下单个场景图像的以自我为中心的交互生成，旨在合成逼真的视频，其中手进入场景，与物体交互，并在头部运动下诱导可信的世界动态。这种设置带来了根本性的挑战，包括自由空间手势和大量接触训练数据之间的分布变化、单目视图中手部运动和相机运动之间的模糊性，以及任意长度视频生成的需要。我们提出了 Hand2World，这是一个统一的自回归框架，它通过基于投影 3D 手部网格的遮挡不变手调节来解决这些挑战，允许从场景上下文中推断可见性和遮挡，而不是在控制信号中进行编码。为了稳定以自我为中心的视点变化，我们通过每像素 Plücker 射线嵌入注入显式相机几何形状，将相机运动与手部运动分开并防止背景漂移。我们进一步开发了一个全自动的单目注释管道，并将双向扩散模型提炼成因果生成器，从而实现任意长度的合成。对三个以自我为中心的交互基准进行的实验表明，感知质量和 3D 一致性得到了显着改善，同时支持相机控制和长视距交互生成。

- **2026-02-10** **AUHead: Realistic Emotional Talking Head Generation via Action Units Control** [2602.09534](http://arxiv.org/abs/2602.09534)
  > 逼真的头部说话视频生成对于虚拟化身、电影制作和交互系统至关重要。由于缺乏细粒度的情绪控制，当前的方法难以处理微妙的情绪表达。为了解决这个问题，我们引入了一种新颖的两阶段方法（AUHead）来从音频中分离出细粒度的情感控制，即动作单元（AU），并实现可控生成。在第一阶段，我们通过时空AU标记化和“情感然后AU”的思想链机制来探索大型音频语言模型（ALM）的AU生成能力。它的目的是将 AU 与原始语音分开，有效捕捉微妙的情感线索。在第二阶段，我们提出了一种由 AU 驱动的可控扩散模型，该模型可以合成以 AU 序列为条件的逼真的头部说话视频。具体来说，我们首先将 AU 序列映射到结构化 2D 面部表示中以增强空间保真度，然后在交叉注意模块内对 AU 视觉交互进行建模。为了实现灵活的 AU 质量权衡控制，我们在推理过程中引入了 AU 解纠缠指导策略，进一步细化生成视频的情感表达和身份一致性。基准数据集的结果表明，我们的方法在情感真实性、准确的口型同步和视觉连贯性方面实现了竞争性能，显着超越了现有技术。我们的实现可在 https://github.com/laura990501/AUHead_ICLR 获取

- **2026-02-09** **WorldCompass: Reinforcement Learning for Long-Horizon World Models** [2602.09022](http://arxiv.org/abs/2602.09022)
  > 这项工作提出了 WorldCompass，这是一种新颖的强化学习 (RL) 后训练框架，适用于长视野、基于交互式视频的世界模型，使他们能够根据交互信号更准确、一致地探索世界。为了有效地“引导”世界模型的探索，我们引入了针对自回归视频生成范式量身定制的三项核心创新：1）剪辑级推出策略：我们在单个目标剪辑上生成并评估多个样本，这显着提高了推出效率并提供细粒度的奖励信号。 2）补充奖励函数：我们设计了针对交互跟踪准确性和视觉质量的奖励函数，提供直接监督并有效抑制奖励黑客行为。 3）高效的强化学习算法：我们采用负感知微调策略结合各种效率优化来高效且有效地增强模型容量。对SoTA开源世界模型WorldPlay的评估表明，WorldCompass显着提高了各种场景下的交互准确性和视觉保真度。

- **2026-02-09** **WorldArena: A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models** [2602.08971](http://arxiv.org/abs/2602.08971)
  > 虽然世界模型已成为体现智能的基石，使智能体能够通过行动条件预测来推理环境动态，但它们的评估仍然支离破碎。目前对具体世界模型的评估主要集中在感知保真度（例如视频生成质量），而忽视了这些模型在下游决策任务中的功能效用。在这项工作中，我们介绍了 WorldArena，这是一个统一的基准，旨在跨感知和功能维度系统地评估具体世界模型。 WorldArena 通过三个维度评估模型：视频感知质量，通过 6 个子维度的 16 个指标进行衡量；体现任务功能，将世界模型评估为数据引擎、政策评估者和与主观人类评估相结合的行动规划者。此外，我们提出了 EWMScore，这是一种将多维性能集成到单个可解释指数中的整体指标。通过对 14 个代表性模型的广泛实验，我们揭示了显着的感知功能差距，表明高视觉质量并不一定转化为强大的具体任务能力。 WorldArena 基准测试和公共排行榜在 https://worldarena.ai 上发布，提供了一个框架，用于跟踪具体人工智能中真正功能性世界模型的进展。

- **2026-02-09** **MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE** [2602.08961](http://arxiv.org/abs/2602.08961)
  > 我们引入了 MotionCrafter，这是一种基于视频扩散的框架，可以联合重建 4D 几何结构并估计单目视频中的密集运动。我们方法的核心是共享坐标系中密集 3D 点图和 3D 场景流的新颖联合表示，以及有效学习这种表示的新颖 4D VAE。与之前强制 3D 值和潜在变量与 RGB VAE 潜在变量严格对齐的工作不同（尽管它们的分布根本不同），我们表明这种对齐是不必要的，并且会导致性能不佳。相反，我们引入了一种新的数据归一化和 VAE 训练策略，可以更好地传输扩散先验并大大提高重建质量。跨多个数据集的大量实验表明，MotionCrafter 在几何重建和密集场景流估计方面均实现了最先进的性能，在几何和运动重建方面分别实现了 38.64% 和 25.0% 的改进，并且全部无需任何后期优化。项目页面：https://ruijiezhu94.github.io/MotionCrafter_Page

- **2026-02-09** **VideoVeritas: AI-Generated Video Detection via Perception Pretext Reinforcement Learning** [2602.08828](http://arxiv.org/abs/2602.08828)
  > 视频生成能力的不断增强带来了不断升级的安全风险，因此可靠的检测变得越来越重要。在本文中，我们介绍了VideoVeritas，一个集成了细粒度感知和基于事实的推理的框架。我们观察到，虽然当前的多模态大语言模型（MLLM）表现出强大的推理能力，但它们的粒度感知能力仍然有限。为了缓解这个问题，我们引入了联合偏好对齐和感知借口强化学习（PPRL）。具体来说，我们没有直接针对检测任务进行优化，而是在强化学习阶段采用通用时空基础和自监督对象计数，通过简单的感知借口任务来增强检测性能。为了促进稳健的评估，我们进一步引入了 MintVid，这是一个轻量但高质量的数据集，包含来自 9 个最先进的生成器的 3K 视频，以及现实世界中收集的内容存在事实错误的子集。实验结果表明，现有方法往往偏向于肤浅推理或机械分析，而 VideoVeritas 在不同基准测试中实现了更平衡的性能。

- **2026-02-09** **Omni-Video 2: Scaling MLLM-Conditioned Diffusion for Unified Video Generation and Editing** [2602.08820](http://arxiv.org/abs/2602.08820)
  > 我们推出了 Omni-Video 2，这是一种可扩展且计算高效的模型，它将预训练的多模态大语言模型 (MLLM) 与视频扩散模型连接起来，以实现统一的视频生成和编辑。我们的关键想法是利用 MLLM 的理解和推理能力来生成明确的目标标题来解释用户指令。通过这种方式，理解模型中丰富的上下文表示可以直接用于指导生成过程，从而提高复杂和组合编辑的性能。此外，还开发了一个轻量级适配器，将多模态条件标记注入到预训练的文本到视频扩散模型中，从而以参数有效的方式最大程度地重用其强大的生成先验。受益于这些设计，我们在精心策划的高质量训练数据上将 Omni-Video 2 扩展到 14B 视频扩散模型，支持高质量的文本到视频生成和各种视频编辑任务，例如对象删除、添加、背景更改、复杂运动编辑、\emph{等}。我们在细粒度视频编辑的 FiVE 基准和文本到视频生成的 VBench 基准上评估 Omni-Video 2 的性能。结果证明了其在视频编辑中遵循复杂构图指令的卓越能力，同时在视频生成任务中也实现了具有竞争力或卓越的质量。

- **2026-02-09** **ALIVE: Animate Your World with Lifelike Audio-Video Generation** [2602.08682](http://arxiv.org/abs/2602.08682)
  > 视频生成正在快速发展为统一的音视频生成。在本文中，我们提出了 ALIVE，一种生成模型，它将预训练的文本到视频 (T2V) 模型应用于 Sora 风格的音频视频生成和动画。特别是，与 T2V 基础模型相比，该模型解锁了文本到视频和音频 (T2VA) 以及参考到视频和音频（动画）功能。为了支持视听同步和参考动画，我们通过联合音视频分支增强了流行的 MMDiT 架构，其中包括用于时间对齐跨模态融合的 TA-CrossAttn 和用于精确视听对齐的 UniTemp-RoPE。同时，精心设计了由音视频字幕、质量控制等组成的综合数据管道，以收集高质量的微调数据。此外，我们引入了一个新的基准来执行全面的模型测试和比较。经过百万级高质量数据的持续预训练和微调，ALIVE表现出了出色的性能，持续优于开源模型，并匹配或超越最先进的商业解决方案。通过详细的配方和基准，我们希望 ALIVE 能够帮助社区更有效地开发音视频生成模型。官方页面：https://github.com/FoundationVision/Alive。

- **2026-02-09** **T2VTree: User-Centered Visual Analytics for Agent-Assisted Thought-to-Video Authoring** [2602.08368](http://arxiv.org/abs/2602.08368)
  > 生成模型大大扩展了视频生成功能，但实际的思想到视频创作仍然是一个多阶段、多模式和决策密集型的过程。然而，现有工具要么隐藏重复重新运行背后的中间决策，要么暴露操作员级别的工作流程，这使得探索跟踪难以管理、比较和重用。我们提出了 T2VTree，一种以用户为中心的可视化分析方法，用于代理辅助的思想到视频创作。 T2VTree 将创作过程表示为树可视化。树中的每个节点都将可编辑的规范（意图、引用的输入、工作流选择、提示和参数）与生成的多模式输出绑定在一起，从而使细化、分支和来源检查可直接操作。为了减轻决定下一步做什么的负担，一组协作代理将步骤级意图转换为可执行计划，该计划在执行前保持可见且用户可编辑。我们进一步实现了一个可视化分析系统，该系统将分支创作与就地预览和拼接集成在一起以进行聚合组装，从而无需离开创作上下文即可实现端到端的多场景创建。我们通过两个多场景案例研究和比较用户研究来演示 T2VTreeVA，展示 T2VTree 可视化和可编辑代理规划如何支持真实创作工作流程中的可靠细化、本地化比较和实际重用。 T2VTree 位于：https://github.com/tezuka0210/T2VTree。

- **2026-02-09** **PISCO: Precise Video Instance Insertion with Sparse Control** [2602.08277](http://arxiv.org/abs/2602.08277)
  > 人工智能视频生成的格局正在经历关键转变：超越依赖于详尽的即时工程和“樱桃采摘”的一般生成，转向细粒度、可控生成和高保真后处理。在专业的人工智能辅助电影制作中，进行精准、有针对性的修改至关重要。此过渡的基石是视频实例插入，这需要将特定实例插入到现有素材中，同时保持场景完整性。与传统的视频编辑不同，此任务需要几个要求：精确的时空放置、物理上一致的场景交互以及忠实保留原始动态 - 所有这些都在用户最小的努力下实现。在本文中，我们提出了 PISCO，一种视频扩散模型，用于具有任意稀疏关键帧控制的精确视频实例插入。 PISCO 允许用户在任意时间戳指定单个关键帧、开始和结束关键帧或稀疏关键帧，并自动传播对象外观、运动和交互。为了解决预训练视频扩散模型中稀疏条件引起的严重分布变化，我们引入了用于鲁棒条件的可变信息指导和用于稳定时间生成的分布保持时间掩蔽，以及用于现实场景适应的几何感知条件。我们进一步构建了 PISCO-Bench，这是一个具有经过验证的实例注释和配对的干净背景视频的基准，并使用基于参考和无参考的感知指标来评估性能。实验表明，PISCO 在稀疏控制下始终优于强大的修复和视频编辑基线，并且随着提供额外的控制信号，表现出清晰、单调的性能改进。项目页面： yangbogaobarry.github.io/PISCO。


<p align=right>(<a href=#updated-on-20260215>back to top</a>)</p>

## 3D

- **2026-02-12** **Kagome edge states under lattice termination, spin-orbit coupling, and magnetic order** [2602.12223](http://arxiv.org/abs/2602.12223)
  > 我们使用紧束缚方法研究二维 kagome 晶格的边缘态特性，重点关注晶格终止、自旋轨道耦合和磁序的作用。在原始极限下，我们表明局部边缘态的存在对边界几何高度敏感，某些终端完全抑制边缘模式。 Kane-Mele 自旋轨道耦合打开了一个体能隙并稳定了拓扑保护的螺旋边缘态，从而产生了对终止细节不敏感的稳健的 $\mathbb{Z}_2$ 绝缘相。相比之下，塞曼场和拉什巴自旋轨道耦合的综合效应驱动系统进入陈绝缘相，陈数与手性边缘模式的数量一致。我们进一步证明，非共面磁性纹理通过有限标量自旋手性产生多个陈相，并通过凯恩-梅勒耦合强烈调整拓扑间隙。我们的结果为戈薇晶格中边缘态的可调性提供了重要的见解，这对于设计具有新颖电子特性和拓扑相的材料至关重要。

- **2026-02-12** **3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting** [2602.12159](http://arxiv.org/abs/2602.12159)
  > 对象导航是体现智能的核心能力，使代理能够在未知环境中定位目标对象。视觉语言模型 (VLM) 的最新进展促进了零样本目标导航 (ZSON)。然而，现有的方法通常依赖于场景抽象，将环境转换为语义图或文本表示，导致高层决策受到低层感知准确性的限制。在这项工作中，我们提出了 3DGSNav，这是一种新颖的 ZSON 框架，它嵌入 3D 高斯分布 (3DGS) 作为 VLM 的持久存储器，以增强空间推理。通过主动感知，3DGSNav 逐步构建环境的 3DGS 表示，从而实现前沿感知第一人称视图的轨迹引导自由视点渲染。此外，我们设计了结构化的视觉提示，并将其与思想链（CoT）提示相结合，以进一步改进 VLM 推理。在导航过程中，实时目标检测器会过滤潜在目标，而 VLM 驱动的主动视点切换则执行目标重新验证，确保高效可靠的识别。对四足机器人的多个基准测试和真实世界实验的广泛评估表明，我们的方法相对于最先进的方法实现了稳健且具有竞争力的性能。项目页面：https://aczheng-cai.github.io/3dgsnav.github.io/

- **2026-02-12** **TexSpot: 3D Texture Enhancement with Spatially-uniform Point Latent Representation** [2602.12157](http://arxiv.org/abs/2602.12157)
  > 由于当前主流多视图扩散管道固有的视图不一致，高质量 3D 纹理生成仍然是一个基本挑战。现有的表示要么依赖于 UV 贴图（在展开过程中会出现失真），要么依赖于基于点的方法（将纹理保真度与几何密度紧密结合在一起，从而限制了高分辨率纹理的生成）。为了解决这些限制，我们引入了 TexSpot，一种基于扩散的纹理增强框架。其核心是 Texlet，这是一种新颖的 3D 纹理表示，它将基于点的 3D 纹理的几何表现力与基于 UV 的表示的紧凑性融为一体。每个 Texlet 潜在向量通过 2D 编码器对局部纹理块进行编码，并使用 3D 编码器进一步聚合以合并全局形状上下文。级联 3D 到 2D 解码器可重建高质量纹理块，从而实现 Texlet 空间学习。利用这种表示，我们训练了一个以 Texlet 为条件的扩散变换器，以细化和增强多视图扩散方法产生的纹理。大量实验表明，与现有最先进的 3D 纹理生成和增强方法相比，TexSpot 显着提高了视觉保真度、几何一致性和鲁棒性。项目页面：https://anonymous.4open.science/w/TexSpot-page-2D91。

- **2026-02-12** **Resurrecting Kaluza-Klein Dark Matter with Low-Temperature Reheating** [2602.12154](http://arxiv.org/abs/2602.12154)
  > 在通用额外维度 (UED) 场景中，最轻的卡鲁扎-克莱因 (KK) 粒子由于额外维度致密化产生的残余离散对称性（KK 宇称）而自然稳定。这种稳定性不需要特殊的对称性，并且使卡鲁扎-克莱因暗物质成为一个有充分动机的候选者，只要它能够重现观察到的遗迹丰度。具有高度预测性的最小 UED (mUED) 框架受到标准宇宙学假设下遗迹密度和对撞机搜索的综合要求的强烈限制。在非标准宇宙学历史的存在下，我们重新审视了 mUED 的暗物质现象学，其特点是由长期暴胀衰变驱动的低再加热温度。通过求解暗物质、辐射和暴胀子能量密度的耦合玻尔兹曼方程，我们发现再加热过程中的熵注入可以将遗迹丰度稀释几个数量级，从而重新打开先前排除的参数空间的大区域。我们进一步证明，恢复的参数空间与当前的对撞机、直接检测和间接检测约束一致，同时仍然可以通过即将进行的实验进行测试。

- **2026-02-12** **Neutral Prompts, Non-Neutral People: Quantifying Gender and Skin-Tone Bias in Gemini Flash 2.5 Image and GPT Image 1.5** [2602.12133](http://arxiv.org/abs/2602.12133)
  > 本研究量化了两种广泛部署的商业图像生成器（Gemini Flash 2.5 Image (NanoBanana) 和 GPT Image 1.5）中的性别和肤色偏差，以测试中性提示产生人口统计中性输出的假设。我们使用四个语义中性的提示生成了 3,200 张逼真的图像。该分析采用了严格的流程，结合了混合颜色归一化、面部标志掩蔽以及使用 Monk (MST)、PERLA 和 Fitzpatrick 量表进行感知均匀肤色量化。中性的提示产生了高度两极分化的默认值。两种模型都表现出强烈的“默认白色”偏差（> 96% 的输出）。然而，他们在性别上存在巨大分歧：双子座偏爱女性呈现对象，而 GPT 则偏爱肤色较浅的男性呈现对象。这项研究使用照明感知比色方法对最先进的模型进行了大规模的比较审核，将美学渲染与合成图像中的底层色素沉着区分开来。该研究表明，中性提示充当诊断探针，而不是中性指令。它为审核算法视觉文化提供了一个强大的框架，并挑战了社会语言学的假设，即无标记语言导致包容性表征。

- **2026-02-12** **Iskra: A System for Inverse Geometry Processing** [2602.12105](http://arxiv.org/abs/2602.12105)
  > 我们提出了一个通过解决几何处理问题来区分的系统。我们的系统区分了广泛的几何算法，利用几何处理中常见的现有快速特定问题方案，包括局部全局和 ADMM 求解器。它与机器学习框架兼容，为新型逆几何处理应用程序打开了大门。我们将网格处理的分散-聚集方法与基于张量的工作流程结合起来，并依靠应用于用户指定的命令性代码的伴随方法来在幕后生成高效的向后传递。我们通过区分平均曲率流、光谱共形参数化、测地距离计算和尽可能刚性的变形来展示我们的方法，并检查这些应用程序的可用性和性能。我们的系统允许从业者通过现有的几何处理算法进行区分，而无需重新制定它们，从而与非针对几何处理的可微分优化工具相比，实现工作量低，运行时间快，并且内存需求更低。

- **2026-02-12** **Unconditional full vector magnetometry using spin selectivity in Nitrogen Vacancy centers in diamond** [2602.12090](http://arxiv.org/abs/2602.12090)
  > 十多年来，基于金刚石氮空位 (NV) 中心的量子传感器一直是传感界的中心话题。金刚石自旋系统在室温下的非凡特性使其成为开发商业量子传感器的最著名的量子平台之一。特别是，NV中心电子自旋的敏感性使得基于金刚石的磁传感器因​​其在医疗、工业或导航解决方案中的潜在应用而受到特别关注。然而，这些传感器在通用矢量磁力测量中的使用受到了限制，因为需要事先了解被测量领域的知识才能充分利用它们的优势。在这项工作中，我们展示了一种仅基于金刚石和微波天线组合的空间排列来执行无条件矢量磁力测量的方法，无需外部磁场信息。虽然以前基于 NV 的矢量磁力测量方法需要部分磁场知识（例如校准的偏置场），但我们利用椭圆偏振微波场选择金刚石中自旋的特定方向的可能性。我们证明，我们的方法可以估计外部磁场的大小和方向，而无需进一步的假设或约束。

- **2026-02-12** **Efficient parallel finite-element methods for planetary gravitation: DtN and multipole expansions** [2602.12075](http://arxiv.org/abs/2602.12075)
  > 控制行星引力场的泊松方程建立在无界域 $\mathbb{R}^3$ 上，而有限元计算需要有界网格。我们实现并比较了有限元方法中处理无限外部的三种策略：（i）朴素域截断； (ii) 截断边界上的狄利克雷到诺伊曼 (DtN) 地图； (iii) 截断边界上的多极展开。虽然所有这些方法在地球物理文献中都是已知的，但我们讨论了它们在现代开源有限元代码中的并行实现，特别关注广泛使用的 MFEM 包。我们考虑计算静态密度结构的引力势和计算位移场引起的势的线性扰动——这是将自引力耦合到行星动力学的必要步骤。与一些早期的研究相比，我们发现域截断方法可以以可接受的成本提供准确的解决方案，并在外部域内对网格进行适当的粗化。尽管如此，DtN 和多极方法在大规模并行地球物理模拟中以较低的成本提供了卓越的精度，尽管它们需要与球谐展开相关的非本地通信。特别是，DtN 方法允许基于 MPI 通信器的高效并行实现，该通信器仅限于包含部分网格外边界的处理器。提供了一系列进一步的说明性计算，以显示 DtN 和多极方法在现实地球物理建模中的潜力。

- **2026-02-12** **Anomaly Reparametrization of the Ligon--Schaaf Regularization in the Kepler problem** [2602.12034](http://arxiv.org/abs/2602.12034)
  > 我们重新审视开普勒问题的 Ligon-Schaaf 正则化，并确定其变换中出现的旋转的几何原点。我们表明，这种旋转是由开普勒运动的偏心异常决定的，提供了对角度的透明动力学解释，使开普勒流在 $T^{*}S^{3}$ 上均匀。基于这一见解，我们通过相应的双曲和抛物线异常将结构扩展到正能量和零能量，获得了跨所有能级的开普勒流的统一几何描述。

- **2026-02-12** **Existence of the $DD^*\bar{K}^*$ and $BB^*K^*$ three-body molecular states** [2602.12010](http://arxiv.org/abs/2602.12010)
  > 我们研究了单玻色子交换（OBE）模型中由 $DD^*\bar{K}^*$ 组成的三体分子态的存在性。一个主要挑战是，虽然赝标量-介子耦合是明确确定的，但标量-和矢量-介子交换的耦合呈现出显着的模型依赖性。为了确保预测的可靠性并减少模型依赖性，我们重新校准了 OBE 模型的耦合常数。我们将 $Z_c(3900)$ 的极位置，或等效的标量 $σ$-交换耦合常数，视为唯一的未知参数。向量 $ρ$- 和 $ω$- 交换的耦合常数由已建立的状态 $X(3872)$ 和 $T_{cc}(3875)$ 的极位置确定。我们证明这些参数集也成功地描述了 $T_{cs0}(2870)$ 而无需进一步调整。对于三体系统，我们的结果表明，当 $Z_c(3900)$ 是位于 $D\bar{D}^*$ 阈值的大约 $-10~\text{MeV}$ 范围内的虚拟状态时，存在 $I\left(J^P\right)=1 / 2\left(0^{-}\right)$ 三体分子束缚态。此外，我们使用复标度方法将分析扩展到复能量平面以搜索分子共振，尽管在所考虑的通道中没有发现共振的证据。我们还将这种形式主义应用于底层模拟 $BB^*K^*$ 系统。在这个区域中，三体束缚态存在的条件更加宽松，因为位于阈值以下 $-25~\text{MeV}$ 内的 $Z_c(3900)$ 虚拟态就足够了，尽管三体分子共振仍然不存在。我们建议未来的实验精确测量 $Z_c(3900)$ 的极位置或在 $DD\bar{K}ππ$ 和 $DD\bar{K}$ 通道中搜索三体束缚态，因为这些努力将相互阐明相关态的性质。

- **2026-02-11** **SurfPhase: 3D Interfacial Dynamics in Two-Phase Flows from Sparse Videos** [2602.11154](http://arxiv.org/abs/2602.11154)
  > 两相流中的界面动力学控制动量、热量和质量传递，但仍然难以通过实验测量。经典技术在移动界面附近面临固有的局限性，而现有的神经渲染方法针对具有扩散边界的单相流，无法处理尖锐、可变形的液-气界面。我们提出了 SurfPhase，一种从稀疏相机视图重建 3D 界面动力学的新颖模型。我们的方法将动态高斯面元与带符号距离函数公式相结合以实现几何一致性，并利用视频扩散模型来合成新颖的视图视频，以改进稀疏观测的重建。我们对高速池沸腾视频的新数据集进行了评估，仅通过两个摄像机视图演示了高质量的视图合成和速度估计。项目网站：https://yuegao.me/SurfPhase。

- **2026-02-11** **FastFlow: Accelerating The Generative Flow Matching Models with Bandit Inference** [2602.11105](http://arxiv.org/abs/2602.11105)
  > 流匹配模型在图像和视频生成中提供最先进的保真度，但固有的顺序去噪过程使它们速度变慢。现有的加速方法（例如蒸馏、轨迹截断和一致性方法）是静态的，需要重新训练，并且通常无法跨任务泛化。我们提出了 FastFlow，一种即插即用的自适应推理框架，可加速流匹配模型的生成。 FastFlow 识别仅对去噪路径产生微小调整的去噪步骤，并在不使用用于速度预测的完整神经网络模型的情况下对其进行近似。该近似利用先前预测的有限差分速度估计来有效地推断未来状态，从而以零计算成本沿着去噪路径实现更快的进展。这使得能够跳过中间步骤的计算。我们将在需要完整模型计算之前安全跳过多少步骤的决策建模为多臂老虎机问题。老虎机学习最佳跳跃以平衡速度与性能。 FastFlow 与现有管道无缝集成，并可泛化图像生成、视频生成和编辑任务。实验表明，在保持高质量输出的同时，速度提高了 2.6 倍以上。这项工作的源代码可以在 https://github.com/Div290/FastFlow 找到。

- **2026-02-11** **SQ-CBF: Signed Distance Functions for Numerically Stable Superquadric-Based Safety Filtering** [2602.11049](http://arxiv.org/abs/2602.11049)
  > 确保机器人在杂乱和动态环境中安全运行仍然是一项基本挑战。虽然控制屏障函数为实时安全过滤提供了有效的框架，但其性能很大程度上取决于底层的几何表示，而该几何表示通常被简化，导致行为过于保守或碰撞覆盖范围不足。超级二次曲面提供了一种使用一些基元对复杂形状进行建模的富有表现力的方法，并且越来越多地用于机器人安全。为了将此表示集成到碰撞避免中，大多数现有方法直接使用其隐式函数作为障碍候选。然而，我们在这种实践中发现了一个关键但被忽视的问题：隐式 SQ 函数的梯度可能会变得严重病态，可能导致优化不可行并破坏可靠的实时安全过滤。为了解决这个问题，我们制定了一个基于 SQ 的安全过滤框架，该框架使用符号距离函数作为障碍候选。由于分析 SDF 不适用于一般 SQ，因此我们使用高效的 Gilbert-Johnson-Keerthi 算法计算距离，并通过随机平滑获得梯度。广泛的模拟和现实世界实验证明了在杂乱和非结构化场景中一致的无碰撞操纵，显示出对具有挑战性的几何形状、传感噪声和动态干扰的鲁棒性，同时提高了远程操作任务中的任务效率。这些结果突出了一条通往安全过滤器的道路，该过滤器在现实环境的几何复杂性下仍然保持精确和可靠。

- **2026-02-11** **Normalized Surveillance in the Datafied Car: How Autonomous Vehicle Users Rationalize Privacy Trade-offs** [2602.11026](http://arxiv.org/abs/2602.11026)
  > 自动驾驶车辆 (AV) 的特点是通过车内摄像头、激光雷达和 GPS 等传感器进行普遍的数据化和监控。本研究利用建构主义扎根理论对 16 次自动驾驶汽车驾驶员进行的半结构化访谈进行分析，探讨用户如何在日常数据化中理解车辆监控。调查结果显示，驾驶员很少表现出与自动驾驶汽车相关的隐私问题，而是通过与现有数字平台进行比较来规范监控。我们通过将视音频监控置于平台环境的“监控生态”中来对这种冷漠进行理论化，认为数据化汽车的功能是“漏水之家”的移动延伸——通过不断传输行为数据的互联技术使私人空间变得可渗透。   该研究通过展示接受全面智能手机和智能家居监控的用户如何将 AV 数据化视为标准化数据提取的另一个节点，为监视信念、数据化和平台治理方面的学术做出贡献。我们强调数据访问的地理限制（目前限制对加利福尼亚州的驾驶员日志访问）如何造成不对称性，从而阻碍知情的隐私审议，体现了“第三级数字鸿沟”。最后，我们研究了机器学习对数据密集型方法的依赖如何产生超越单个制造商选择的结构性监视压力。我们提出治理干预措施，使社会学习民主化，包括通用数据访问权、具有约束力的透明度要求和数据最小化标准，以防止汽车数据化中的逐底竞争。

- **2026-02-11** **When Fusion Helps and When It Breaks: View-Aligned Robustness in Same-Source Financial Imaging** [2602.11020](http://arxiv.org/abs/2602.11020)
  > 我们研究同源多视图学习和利用金融图像表示进行次日方向预测的对抗鲁棒性。在上海黄金交易所（SGE）现货黄金数据（2005-2025）上，我们从每个滚动窗口构建了两个窗口对齐视图：OHLCV 渲染的价格/成交量图表和技术指标矩阵。为了确保评估的可靠性，我们采用带有禁运的防泄漏时间块分割并使用马修斯相关系数（MCC）。我们发现结果在很大程度上取决于标签噪声制度：我们应用事后最小移动过滤器，丢弃第二天实现的绝对回报低于 tau 的样本，以定义具有减少的接近零标签模糊度的评估子集。这会导致非单调的数据噪声权衡，可以揭示预测信号，但最终会随着样本量的缩小而增加方差；该过滤器用于离线基准构建，而不是推理时间决策规则。在稳定的子集中，融合是依赖于机制的：通过通道堆叠的早期融合可能表现出负转移，而使用双编码器和融合头的后期融合提供了主要的清洁性能增益；跨视图一致性正则化具有次要的、依赖于主干网的影响。我们进一步在两种威胁场景下使用 FGSM 和 PGD 评估测试时的 L-无穷扰动：扰乱一个视图的视图受限攻击和扰乱两者的联合攻击。我们观察到在极小的预算和强烈的观点不对称的情况下存在严重的脆弱性。后期融合持续提高了视图受限攻击下的鲁棒性，但联合攻击​​仍然具有挑战性，并且仍然可能导致严重的最坏情况退化。

- **2026-02-11** **Variational Optimality of Föllmer Processes in Generative Diffusions** [2602.10989](http://arxiv.org/abs/2602.10989)
  > 我们使用随机插值框架构建并分析生成扩散，在有限时间范围内将点质量传输到规定的目标分布。漂移表示为条件期望，可以根据独立样本进行估计，而无需模拟随机过程。我们表明，可以在不改变时间边缘分布的情况下调整扩散系数 \emph{a~posteriori}。在所有这些调整中，我们证明，最小化估计误差对路径空间 Kullback-Leibler 散度的影响会选择封闭形式的 Föllmer 过程，即一种扩散，其路径测量最小化相对于仅由插值计划确定的参考过程的相对熵。这产生了福尔默过程的新变分特征，通过薛定谔桥和随机控制补充了经典公式。我们进一步确定，在这种最优扩散系数下，路径空间 Kullback-Leibler 散度变得独立于插值时间表，使得不同的时间表在这种变分意义上统计上等效。

- **2026-02-11** **The State's Politics of "Fake Data"** [2602.10944](http://arxiv.org/abs/2602.10944)
  > 数据有力量。因此，大多数关于数据的讨论都假设记录应该反映一些理想化的基本事实。偏差被视为失败。借鉴中国街头官僚机构和美国人口普查局对国家数据制作的两项民族志研究，我们展示了看似“虚假”的国家数据如何执行机构工作。我们绘制了行动者在表述准确性和组织要求之间进行谈判的四个时刻：创造、纠正、共谋和增强。官僚们通常会优先考虑数据的用途而不是数据所代表的内容，从而编造出符合公务员自身利益并使得行政管理受到限制的虚构故事。我们认为状态数据的“虚假性”是关系性的（依赖于上下文）、过程性的（通过工作流程出现）和表演性的（通过标签和实践产生）。我们敦促从业者将目标适用性放在数据评估和情境治理的中心。社会技术系统不应追求不可能的表征准确性，而应使有用小说的政治可见、可争议且可问责。

- **2026-02-11** **Hybrid Methods for Friedrichs Systems with Application to Scalar and Vector Diffusion-Advection Problems** [2602.10890](http://arxiv.org/abs/2602.10890)
  > 在这项工作中，我们研究 Friedrichs 系统的任意阶混合离散化。 Friedrich 系统提供的框架超出了偏微分方程双曲或椭圆的标准分类，因此特别适合包含扩散项和平流项的问题。这项工作中提出的数值方案系列取决于单元和面处具有未知数的混合空间。它们支持一般网格，具有局部保守性，并且与传统的不连续伽辽金离散化相比，一旦应用静态凝聚，就会产生更小的代数系统。我们进行了完整的稳定性和收敛性分析，这似乎是此类分析中的首次。该方法的性能在标量和矢量三维扩散平流反应问题上得到了说明。

- **2026-02-11** **Diagnosing Structural Failures in LLM-Based Evidence Extraction for Meta-Analysis** [2602.10881](http://arxiv.org/abs/2602.10881)
  > 系统评价和荟萃分析依赖于将叙述性文章转化为结构化的、基于数字的研究记录。尽管大型语言模型（LLM）取得了快速进展，但仍不清楚它们是否能够满足该过程的结构要求，这取决于跨文档保留角色、方法和效果大小归因，而不是识别孤立的实体。我们提出了一个结构性诊断框架，将基于 LLM 的证据提取评估为一系列模式约束查询，其关系和数字复杂性不断增加，从而能够精确识别原子级提取之外的故障点。使用跨越五个科学领域的手动管理语料库，以及统一的查询套件和评估协议，我们在每个文档和长上下文、多文档输入机制下评估两个最先进的法学硕士。在跨领域和模型中，单属性查询的性能仍然中等，但一旦任务需要变量、角色、统计方法和效果大小之间的稳定绑定，性能就会急剧下降。完整的元分析关联元组的提取可靠性接近于零，而长上下文输入进一步加剧了这些失败。下游聚合甚至会放大较小的上游错误，从而导致语料库级别的统计数据不可靠。我们的分析表明，这些限制并非源于实体识别错误，而是源于系统结构故障，包括角色反转、交叉分析绑定漂移、密集结果部分中的实例压缩以及数字错误归因，这表明当前的法学硕士缺乏自动荟萃分析所需的结构保真度、关系绑定和数字基础。代码和数据可在 GitHub (https://github.com/zhiyintan/LLM-Meta-Analysis) 上公开获取。

- **2026-02-11** **Less is More: The Dilution Effect in Multi-Link Wireless Sensing** [2602.10823](http://arxiv.org/abs/2602.10823)
  > 无线传感方法有望将智能基础设施转变为保护隐私的运动探测器，但商业应用仍然有限。一个常见的假设可以解释这一差距：更密集的传感器部署会产生更好的精度。我们在住宅环境中使用 9 节点 ESP32-C3 网格（72 个传感链路）进行了为期 12 天的自然研究，测试了这一假设。我们的结果表明，单个放置良好的链接优于完整的 72 链接网格（AUC 0.541 与 0.489，Cohen 的 $d$=0.86）。即使是随机链接选择也与优化选择相匹配 ($p$=0.35)。好处来自避免多链路融合，而不是来自选择正确的链路。我们将此归因于“稀释效应”：菲涅耳区错过活动区域的链接会产生噪音，从而压倒信息链接的信号。在我们的部署中，战略链接放置比分类器选择重要 2.7$\times$ 。我们发布了 312 小时的标记 CSI 数据、固件和分析代码，以便在不同环境中进行验证。

- **2026-02-10** **Topologically Protected Surface Altermagnetism on Antiferromagnets** [2602.10108](http://arxiv.org/abs/2602.10108)
  > 交变磁性 (AM) 及其相关的自旋输运现象通常与块体材料中的自旋分裂电子​​能带结构有关。然而，晶体表面相对于整体的对称性降低，这可能会在传统反铁磁体 (AFM) 的表面引发 AM，这是一种无法使用整体特性检测到的局部效应。在这项工作中，我们定义了表面增材制造所需的对称条件，并展示了如何对其进行拓扑保护，使其具有强大的效果。我们为表面增材制造的一个简单的和两个拓扑示例提供了一个最小模型。我们证明，即使全能带结构完全自旋简并，通过自旋和角度分辨光电子能谱可获取的自旋谱密度也可以在表面表现出类似 $d$ 波的交变磁特征。我们的拓扑模型描述了狄拉克半金属 CuMnAs，它提供了我们理论的现有实现。我们的研究结果表明，晶体表面是一个平台，可以实现强大的、拓扑和对称驱动的非常规磁性，超越磁性材料的整体分类。

- **2026-02-10** **Causality in Video Diffusers is Separable from Denoising** [2602.10095](http://arxiv.org/abs/2602.10095)
  > 因果关系——指的是组件之间的时间性、单向因果关系——是许多复杂生成过程的基础，包括视频、语言和机器人轨迹。当前的因果扩散模型将时间推理与迭代去噪结合起来，在所有层、每个去噪步骤以及整个上下文中应用因果注意力。在本文中，我们证明这些模型中的因果推理与多步骤去噪过程是可分离的。通过对自回归视频扩散器的系统探测，我们发现了两个关键规律：（1）早期层在去噪步骤中产生高度相似的特征，表明沿扩散轨迹的冗余计算； （2）更深的层表现出稀疏的跨帧注意力，并且主要执行帧内渲染。受这些发现的启发，我们引入了可分离因果扩散（SCD），这是一种新架构，它通过因果变换编码器将每帧一次的时间推理与通过轻量级扩散解码器的多步逐帧渲染明确解耦。对合成基准和真实基准的训练前和训练后任务进行的大量实验表明，SCD 显着提高了吞吐量和每帧延迟，同时匹配或超越了强因果扩散基准的生成质量。

- **2026-02-10** **Cosmological signature and light Dark Matter in Dirac $L_μ-L_τ$ model** [2602.09962](http://arxiv.org/abs/2602.09962)
  > 我们重新审视狄拉克框架中标准模型 (SM) $viz.$ 规范 ${L_μ-L_τ}$ 模型的无异常扩展，其中局部 $U(1)_{L_μ-L_τ}$ 对称性破缺并产生新的规范玻色子 $Z'$ 和相应的规范耦合 $g_{μτ}$。添加了三个额外的重矢量状费米子、三个轻右手中微子和两个重单线态标量，以完成狄拉克中微子的模型框架。另一个单线态矢量状费米子被添加了新的规范电荷，它作为可行的 DM 候选者，并且通过共振效应获得了正确的遗迹丰度。在满足 $M_{Z'}$ 和规范耦合 $g_{μτ}$ 的当前界限后，考虑参数空间。结合暗物质研究来自附加光自由度的暗辐射的影响。在施加所有相关的理论和实验约束后，发现允许的参数空间受到高度限制，但仍可用于正在进行的和近期的实验，从而使场景具有很强的预测性。此外，在整个研究中，相关观测值之间出现了明显的相关性，使得该模型可以在当前和未来的实验搜索中进行测试。

- **2026-02-10** **SARS: A Novel Face and Body Shape and Appearance Aware 3D Reconstruction System extends Morphable Models** [2602.09918](http://arxiv.org/abs/2602.09918)
  > 可变形模型 (3DMM) 是一种可变形模型，它以 2D 图像作为输入，重新创建 3D 对象（尤其是人脸和身体）的结构和物理外观。 3DMM 将身份和表情混合形状与基本面部网格相结合，创建详细的 3D 模型。 3D Morphable 模型的可变性可以通过调整不同的参数来控制。它们是高级图像描述符，例如形状、纹理、照明和相机参数。先前 3D 人体重建的研究仅集中于全局面部结构或几何形状，忽略了面部语义特征，例如年龄、性别以及表征面部边界、曲线、凹陷和皱纹的面部标志。为了适应这些高级面部特征的变化，这项工作引入了一种形状和外观感知的 3D 重建系统（我们将其命名为 SARS），这是一个 C 模块化管道，可以从单个图像中提取身体和面部信息，以正确重建人体全身的 3D 模型。

- **2026-02-10** **TriPilot-FF: Coordinated Whole-Body Teleoperation with Force Feedback** [2602.09888](http://arxiv.org/abs/2602.09888)
  > 移动机械手拓宽了机器人操纵的操作范围。然而，此类机器人的全身远程操作仍然是一个问题：操作员必须协调轮式底座和两个手臂，同时推理障碍物和接触。现有的界面主要以手动为中心（例如 VR 控制器和操纵杆），而对于连续基础控制而言，脚踏操作通道尚未得到充分探索。我们推出了 TriPilot-FF，这是一种用于定制双手移动机械手的开源全身远程操作系统，该系统引入了带有激光雷达驱动踏板触觉的脚踏踏板，并结合了上身双手领导者-跟随者远程操作。 TriPilot-FF 仅使用低成本底座安装的激光雷达，根据指令方向上接近障碍物的信号呈现电阻踏板提示，从而在没有明确的防撞控制器的情况下将操作员命令塑造为防碰撞行为。该系统还支持手臂侧力反射以实现接触感知，并提供双手可操作性的实时力和视觉引导，以提示移动底座重新定位，从而提高覆盖范围。我们展示了 TriPilot-FF 能够在长时间范围内和需要精确的移动基地移动和协调的任务中有效地“副驾驶”人类操作员。最后，我们将远程操作反馈信号合并到 Transformers 的 Action Chunking (ACT) 策略中，并在附加信息可用时展示了改进的性能。我们发布了踏板设备设计、完整的软件堆栈，并在双手轮式平台上进行了广泛的实际评估。 TriPilot-FF的项目页面为http://bit.ly/46H3ZJT。

- **2026-02-10** **Code2World: A GUI World Model via Renderable Code Generation** [2602.09856](http://arxiv.org/abs/2602.09856)
  > 自主 GUI 代理通过感知界面并执行操作与环境进行交互。作为一个虚拟沙箱，GUI World 模型通过启用动作条件预测，使代理具有类似人类的远见。然而，现有的基于文本和像素的方法很难同时实现高视觉保真度和细粒度的结构可控性。为此，我们提出了 Code2World，一种视觉语言编码器，可通过可渲染代码生成来模拟下一个视觉状态。具体来说，为了解决数据稀缺问题，我们通过将 GUI 轨迹转换为高保真 HTML 并通过视觉反馈修订机制完善合成代码来构建 AndroidCode，从而生成超过 80K 高质量屏幕操作对的语料库。为了使现有的 VLM 适应代码预测，我们首先执行 SFT 作为格式布局遵循的冷启动，然后进一步应用渲染感知强化学习，通过强制视觉语义保真度和动作一致性，使用渲染结果作为奖励信号。大量实验表明，Code2World-8B 实现了性能最佳的下一个 UI 预测，可与竞争性的 GPT-5 和 Gemini-3-Pro-Image 相媲美。值得注意的是，Code2World 以灵活的方式显着提高了下游导航的成功率，使 Gemini-2.5-Flash 在 AndroidWorld 导航上提高了 9.5%。该代码可从 https://github.com/AMAP-ML/Code2World 获取。

- **2026-02-10** **Covo-Audio Technical Report** [2602.09823](http://arxiv.org/abs/2602.09823)
  > 在这项工作中，我们提出了 Covo-Audio，这是一种 7B 参数的端到端 LALM，它可以在单个统一架构中直接处理连续音频输入并生成音频输出。通过大规模策划的预训练和有针对性的后训练，Covo-Audio 在各种任务（包括语音文本建模、口语对话、语音理解、音频理解和全双工语音交互）中实现了同类规模模型中最先进或有竞争力的性能。广泛的评估表明，预训练的基础模型在多个基准上表现出强大的语音文本理解和语义推理能力，优于同等规模的代表性开源模型。此外，面向对话的 Covo-Audio-Chat 表现出强大的口语会话能力，包括理解、上下文推理、遵循指令以及生成上下文适当和同理心的响应，验证了其在现实世界会话助理场景中的适用性。 Covo-Audio-Chat-FD作为全双工模型的演进，在语音对话能力和全双工交互行为上都取得了显着的优越性能，展示了其实际鲁棒性。为了降低为自然对话系统部署端到端 LALM 的高昂成本，我们提出了一种智能-说话者解耦策略，将对话智能与语音渲染分开，从而以最少的文本到语音 (TTS) 数据实现灵活的语音定制，同时保留对话性能。总体而言，我们的结果凸显了 7B 规模模型将复杂的音频智能与高级语义推理相集成的强大潜力，并提出了一条通往功能更强大、用途更广泛的 LALM 的可扩展路径。

- **2026-02-10** **CompSplat: Compression-aware 3D Gaussian Splatting for Real-world Video** [2602.09816](http://arxiv.org/abs/2602.09816)
  > 来自现实世界视频的高质量新颖视图合成 (NVS) 对于文化遗产保护、数字孪生和沉浸式媒体等应用至关重要。然而，现实世界的视频通常包含具有不规则相机轨迹和未知姿势的长序列，导致重建过程中出现姿势漂移、特征错位和几何失真。此外，有损压缩会引入不一致性，从而逐渐降低几何形状和渲染质量，从而加剧了这些问题。虽然最近的研究已经解决了长序列 NVS 或无姿势重建问题，但压缩感知方法仍然关注特定的工件或有限的场景，从而导致长视频中的各种压缩模式没有得到充分探索。在本文中，我们提出了 CompSplat，这是一种压缩感知训练框架，它显式地模拟帧压缩特性，以减轻帧间不一致和累积的几何误差。 CompSplat 结合了压缩感知帧权重和自适应修剪策略，以增强鲁棒性和几何一致性，特别是在重度压缩下。对具有挑战性的基准（包括 Tanks and Temples、Free 和 Hike）进行的大量实验表明，CompSplat 实现了最先进的渲染质量和姿势精度，在严格的压缩条件下显着超越了最新的最先进的 NVS 方法。

- **2026-02-10** **SciFlow-Bench: Evaluating Structure-Aware Scientific Diagram Generation via Inverse Parsing** [2602.09809](http://arxiv.org/abs/2602.09809)
  > 科学图表传达了明确的结构信息，但现代文本到图像模型通常会产生视觉上合理但结构上不正确的结果。现有的基准要么依赖于以图像为中心的或对结构不敏感的主观指标，要么评估中间符号表示而不是最终渲染的图像，从而导致基于像素的图表生成尚未得到充分探索。我们引入了 SciFlow-Bench，这是一种结构优先的基准，用于直接从像素级输出评估科学图表的生成。 SciFlow-Bench 以真正的科学 PDF 为基础，将每个源框架图与规范的地面实况图配对，并在闭环、往返协议下将模型评估为黑盒图像生成器，该协议将生成的图表图像反向解析回结构化图以进行比较。该设计通过结构可恢复性而不是仅通过视觉相似性来强制进行评估，并通过协调规划、感知和结构推理的分层多智能体系统来实现。实验表明，保持结构正确性仍然是一个基本挑战，特别是对于具有复杂拓扑的图，这强调了结构感知评估的必要性。

- **2026-02-10** **An Unsupervised Normalizing Flow-Based Neyman-Pearson Detector for Covert Communications in the Presence of Disco Reconfigurable Intelligent Surfaces** [2602.09763](http://arxiv.org/abs/2602.09763)
  > 隐蔽通信，也称为低检测概率 (LPD) 通信，通过隐藏周围环境中的传输，提供比加密和物理层安全 (PLS) 更高级别的隐私保护。在这里，我们调查了典狱长 Willie 部署的迪斯科可重构智能表面 (DRIS) 的情况下的秘密通信，这同时降低了他的检测错误概率并降低了 Alice 和 Bob 之间的通信性能，而无需依赖信道状态信息 (CSI) 或额外的干扰能力。然而，DRIS 的引入使得 Willie 构建 Neyman-Pearson (NP) 检测器变得困难，因为在 Alice-Bob 传输假设下，检验统计量的概率密度函数 (PDF) 在分析上是困难的。此外，考虑到威利和爱丽丝/鲍勃之间的对抗关系，假设威利可以访问带标签的训练数据集是不现实的。为了应对这些挑战，我们提出了一种基于无监督屏蔽自回归流（MAF）的 NP 检测框架，该框架利用了隐蔽通信中固有的先验知识。我们进一步将误报率（FAR）和漏检率（MDR）定义为 Willie 的监控性能指标，并将信号干扰加噪声比（SJNR）定义为 Alice-Bob 传输的通信性能指标。此外，我们推导了 SJNR 的理论表达式，并揭示了存在 DRIS 时隐蔽通信的独特属性。仿真验证了该理论，并表明所提出的基于 MAF 的无监督 NP 检测器的性能与其有监督对应物相当。

- **2026-02-09** **Dexterous Manipulation Policies from RGB Human Videos via 4D Hand-Object Trajectory Reconstruction** [2602.09013](http://arxiv.org/abs/2602.09013)
  > 由于高维动作空间和获取大规模训练数据的困难，多指机器人手的操纵和抓取具有挑战性。现有方法很大程度上依赖于人类通过可穿戴设备或专用传感设备进行远程操作来捕获手部物体交互，这限制了可扩展性。在这项工作中，我们提出了 VIDEOMANIP，这是一种无需设备的框架，可以直接从 RGB 人类视频中学习灵巧的操作。利用计算机视觉的最新进展，VIDEOMANIP 通过估计人类手部姿势、物体网格，从单目视频中重建明确的 4D 机器人物体轨迹，并将重建的人类运动重新定位到机器人手以进行操作学习。为了使重建的机器人数据适合灵巧操作训练，我们引入了以交互为中心的抓取建模的手部物体接触优化，以及从单个视频生成不同训练轨迹的演示综合策略，无需额外的机器人演示即可实现可推广的策略学习。在模拟中，学习抓取模型使用 Inspire Hand 在 20 个不同物体上实现了 70.25% 的成功率。在现实世界中，使用 LEAP Hand 从 RGB 视频训练的操纵策略在七项任务中平均成功率为 62.86%，比基于重定向的方法高出 15.87%。项目视频可在 videomanip.github.io 上获取。

- **2026-02-09** **Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense** [2602.09012](http://arxiv.org/abs/2602.09012)
  > 支持 GUI 的代理的快速发展已经使传统的验证码变得过时。虽然 OpenCaptchaWorld 等之前的基准测试为评估多模式代理建立了基准，但 Gemini3-Pro-High 和 GPT-5.2-Xhigh 等推理型模型的最新进展有效地打破了这一安全屏障，在“Bingo”等复杂逻辑谜题上实现了高达 90% 的通过率。作为回应，我们推出了下一代验证码，这是一个可扩展的防御框架，旨在保护下一代网络免受高级代理的攻击。与静态数据集不同，我们的基准测试建立在强大的数据生成管道之上，允许大规模且易于扩展的评估，特别是对于后端支持的类型，我们的系统能够有效生成无限制的验证码实例。我们利用交互感知、记忆、决策和行动中持续存在的人类代理“认知差距”。通过设计需要自适应直觉而不是细粒度规划的动态任务，我们重新建立了生物用户和人工代理之间的牢固区别，为代理时代提供了可扩展且多样化的防御机制。

- **2026-02-09** **GEBench: Benchmarking Image Generation Models as GUI Environments** [2602.09007](http://arxiv.org/abs/2602.09007)
  > 图像生成模型的最新进展使得能够根据用户指令预测未来的图形用户界面（GUI）状态。然而，现有的基准主要关注一般领域的视觉保真度，而对特定于 GUI 的上下文中的状态转换和时间一致性的评估尚未得到充分探索。为了解决这一差距，我们引入了 GEBench，这是一个用于评估 GUI 生成中的动态交互和时间一致性的综合基准。 GEBench 包含 700 个精心策划的样本，涵盖五个任务类别，涵盖现实世界和虚构场景中的单步交互和多步轨迹，以及接地点定位。为了支持系统评估，我们提出了 GE-Score，这是一种新颖的五维指标，用于评估目标实现、交互逻辑、内容一致性、UI 合理性和视觉质量。对当前模型的广泛评估表明，虽然它们在单步转换上表现良好，但在较长交互序列上维持时间连贯性和空间基础方面存在很大困难。我们的研究结果表明图标解释、文本渲染和定位精度是关键瓶颈。这项工作为系统评估奠定了基础，并为构建高保真生成 GUI 环境的未来研究提出了有希望的方向。代码位于：https://github.com/stepfun-ai/GEBench。

- **2026-02-09** **Reverse Online Guessing Attacks on PAKE Protocols** [2602.08993](http://arxiv.org/abs/2602.08993)
  > 尽管尚未广泛部署，但密码验证密钥交换 (PAKE) 协议已成为最近多项标准化工作的主题，部分原因是它们能够抵抗各种猜测攻击，而且还因为它们不需要公钥基础设施 (PKI)，因此天然能够抵抗 PKI 故障。本文的目标是重新评估 PAKE 模型，指出由于缺乏 PKI（或者更一般地说，缺乏除密码之外的服务器身份验证机制），使得此类协议容易受到反向在线猜测攻击，在这种攻击中，对手试图通过冒充服务器来验证密码猜测。虽然它们的逻辑与传统猜测类似，即攻击者冒充客户端，但反向猜测会带来独特的风险，因为检测的负担转移到客户端，从而使针对传统猜测的现有防御变得毫无意义。我们的结果表明，当对手不加区别地攻击客户端时，例如网络钓鱼或密码喷射攻击，或者对于具有自动登录过程或通用密码的应用程序（例如 WPA3-SAE），反向猜测特别有效。我们的分析表明，默认情况下，利益相关者应该使用比用户密码更严格的措施对服务器进行身份验证，并且当其他身份验证机制不可用时，仅密码操作模式应该是防止灾难性安全故障的最后手段。

- **2026-02-09** **Zero Trust for Multi-RAT IoT: Trust Boundary Management in Heterogeneous Wireless Network Environments** [2602.08989](http://arxiv.org/abs/2602.08989)
  > 多无线电接入技术、物联网设备的激增，特别是通过 LoRaWAN、5G/4G 蜂窝、Meshtastic 网格、DJI OcuSync、MAVLink 遥测链路、Wi-Fi 和卫星等专有协议运行的无人机，为零信任架构的采用带来了根本性且迄今为止未经审查的挑战。无线接入技术之间的每次转换都构成信任边界交叉：设备退出一个网络信任域并进入另一个网络信任域，从而可能使身份验证状态、设备证明和上下文信任信号失效。当前的 ZTA 框架假设相对稳定的网络环境，并且没有解决移动物联网部署中频繁、动态 RAT 切换的信任影响。

- **2026-02-09** **Cyclic universe from uniform rate inflation on the brane with a timelike extra dimension** [2602.08974](http://arxiv.org/abs/2602.08974)
  > 我们研究了一种非奇异宇宙学场景，其中均匀率膨胀是在各向异性的什塔诺夫-萨尼膜世界上实现的。该模型自然地解决了初始奇异性，导致无限数量的平滑非奇异反弹，同时适应由标量场以恒定速率滚动驱动的加速膨胀阶段。类时额外维度的存在会引起对有效弗里德曼动力学的高能修正，从而允许各向异性剪切在反弹附近被动态抑制，并使背景演化稳定。我们通过分析得出完整的背景动力学，并证明均匀速率膨胀可以一致地嵌入各向异性膜世界框架中。使用 $δN$ 形式来分析原始标量和张量扰动，确保只有在暴胀期间离开视界的物理相关模式才会对可观测量做出贡献。值得注意的是，我们发现在我们考虑的两种不同场景中，可以通过不同水平的各向异性来实现观测一致性，而不会影响反弹的平滑性或稳定性。我们的结果建立了各向异性膜世界上的统一率暴胀，作为标准暴胀宇宙学的稳健且观测上可行的替代方案，提供了一个令人信服的框架，在该框架中非奇异早期宇宙动力学和精确宇宙学可以一致地统一。

- **2026-02-09** **Convergence Analysis for the Recovery of the Friction Threshold in a Scalar Tresca Model** [2602.08967](http://arxiv.org/abs/2602.08967)
  > 我们考虑在足够平滑的域 $Ω$ 上的标量值椭圆偏微分方程，并服从 $\partial Ω$ 子集 $Γ$ 上的正则化 Tresca 摩擦型边界条件。摩擦阈值是该边界条件中出现的正函数，假设未知，并用作反问题中要恢复的系数。假设（i）摩擦阈值位于具有已知基函数的有限维空间中，（ii）偏微分方程的右侧已知，并且（iii）在一些小的开子集 $ω\subset Ω$ 上的偏微分方程的解可用，我们开发了一种用于恢复摩擦阈值的迭代计算方法。该算法实现简单并且基于分段线性有限元。我们表明，所提出的算法以二阶收敛到函数 $a_h$，此外，$a_h$ 在有限元网格大小 $h$ 中以二阶收敛到真实（未知）摩擦阈值。我们通过模拟来强调我们的理论结果，以数字方式确认我们的速率。

- **2026-02-09** **Analysis of Converged 3D Gaussian Splatting Solutions: Density Effects and Prediction Limit** [2602.08909](http://arxiv.org/abs/2602.08909)
  > 我们研究了标准多视图优化的 3D 高斯分布 (3DGS) 解决方案中出现的结构。我们将这些渲染最佳参考（ROR）称为并分析它们的统计特性，揭示稳定的模式：跨不同场景的混合结构尺度和双峰辐射度。为了了解决定这些参数的因素，我们通过训练预测器来应用可学习性探针，以在没有渲染监督的情况下从点云重建 ROR。我们的分析揭示了基本的密度分层。密集区域表现出适合免渲染预测的几何相关参数，而稀疏区域则表现出跨架构的系统故障。我们通过方差分解将其形式化，证明可见性异质性在稀疏区域中的几何参数和外观参数之间创建了协方差主导的耦合。这揭示了 ROR 的双重特征：点云就足够的几何基元，以及多视图约束必不可少的视图合成基元。我们提供密度感知策略，以提高训练的稳健性，并讨论自适应平衡前馈预测和基于渲染的细化的系统的架构影响。

- **2026-02-09** **VedicTHG: Symbolic Vedic Computation for Low-Resource Talking-Head Generation in Educational Avatars** [2602.08775](http://arxiv.org/abs/2602.08775)
  > 教育技术中越来越多地采用头像头像来传递具有社交存在感和提高参与度的内容。然而，许多最近的头部说话生成（THG）方法依赖于以 GPU 为中心的神经渲染、大型训练集或高容量扩散模型，这限制了在离线或资源受限的学习环境中的部署。描述了一种确定性和面向 CPU 的 THG 框架，称为符号吠陀计算，它将语音转换为时间对齐的音素流，将音素映射到紧凑的视位库存，并通过受吠陀经 Urdhva Tiryakbhyam 启发的符号协同发音产生平滑的视位轨迹。轻量级 2D 渲染器执行感兴趣区域 (ROI) 变形和稳定的嘴部合成，以支持商用 CPU 上的实时合成。实验报告了仅 CPU 执行下的同步准确性、时间稳定性和身份一致性，以及针对代表性 CPU 可行基线的基准测试。结果表明，可以实现可接受的口型同步质量，同时大幅减少计算负载和延迟，支持低端硬件上的实用教育化身。 GitHub：https://vineetkumarrakesh.github.io/vedicthg

- **2026-02-09** **A single frequency approach to nonequilibrium modeling of the chromosphere** [2602.08763](http://arxiv.org/abs/2602.08763)
  > 太阳色球层是辐射在能量转移中发挥关键作用并与等离子体发生强烈相互作用的区域。在这一层中，强谱线（例如莱曼线）对辐射能量交换有显着贡献。由于电离/弛豫时间尺度较长，色球层中与 LTE 的偏离变得显着。因此，准确建模这一层需要解决莱曼跃迁的非 LTE 辐射传输问题。我们提出了 MURaM 代码的更新版本，以便能够更准确地模拟色球氢水平总体和温度演化。在之前的扩展中，代码中已经实现了非 LTE 状态方程、氢的碰撞跃迁和非莱曼线的辐射跃迁。在此基础上，我们现在合并了莱曼线的辐射传输来计算辐射率系数和相关的辐射损失。这些用于求解种群和温度演化方程，使系统自洽。为了降低计算成本，在辐射传输问题的数值求解中对每条线应用了单频近似。扩展模型与 Lightweaver 框架的参考解决方案表现出良好的一致性，准确捕获了与色球层莱曼线相关的辐射过程。这一扩展使色球层深处的模拟氢水平群体更接近详细的辐射平衡，而色球层上部的氢水平群体仍然明显不平衡，这与真实太阳大气中的预期条件一致。该扩展使 MURaM 代码能够准确捕获色球动态。


<p align=right>(<a href=#updated-on-20260215>back to top</a>)</p>

## 具生智能&自动驾驶

- **2026-02-12** **Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment** [2602.12281](http://arxiv.org/abs/2602.12281)
  > 通用机器人的长期愿景取决于它们理解自然语言指令并采取行动的能力。视觉-语言-动作（VLA）模型在实现这一目标方面取得了显着进展，但它们生成的动作仍然可能与给定的指令不一致。在本文中，我们研究了测试时验证作为缩小“意图-动作差距”的一种手段。我们首先描述了具体指令遵循的测试时缩放定律，并证明联合缩放改写指令和生成动作的数量大大增加了测试时样本的多样性，通常比独立缩放每个维度更有效地恢复正确的动作。为了利用这些缩放定律，我们提出了 CoVer，一种用于视觉-语言-动作对齐的对比验证器，并表明我们的架构可以通过额外的计算来优雅地缩放然后，我们为 VLA 引入“启动时计算”和分层验证推理管道。在部署时，我们的框架会根据视觉语言模型 (VLM) 预先计算一组不同的改写指令，为每条指令重复生成候选动作，然后使用验证器来选择最佳的高级提示和低级动作块。与对相同数据进行扩展策略预训练相比，我们的验证方法在分布和数据方面获得了 22% 的增益。在 SIMPLER 基准上分布不均 13%，在实际实验中进一步提高 45% 在 PolaRiS 基准上，CoVer 的任务进度提高了 14%，成功率提高了 9%。

- **2026-02-12** **The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics** [2602.12218](http://arxiv.org/abs/2602.12218)
  > 确定神经模型是否将物理定律内化为世界模型，而不是利用统计捷径，仍然具有挑战性，特别是在分布外（OOD）变化的情况下。标准评估通常通过下游适应（例如微调或高容量探测）来测试潜在能力，但此类干预可能会改变正在测量的表示，从而混淆自监督学习（SSL）期间学到的内容。我们提出了一种非侵入性评估协议 PhyIP。在线性表示假设的推动下，我们测试物理量是否可以从冻结表示中线性解码。在流体动力学和轨道力学中，我们发现当 SSL 实现低误差时，潜在结构变得可线性访问。 PhyIP 在 OOD 测试中恢复内能和牛顿平方反比缩放（例如 $ρ> 0.90$）。相反，基于适应的评估可以破坏这种结构（$ρ\approx 0.05$ ）。这些发现表明，基于适应的评估可以掩盖潜在结构，并且低容量探针可以对物理世界模型提供更准确的评估。

- **2026-02-12** **LDA-1B: Scaling Latent Dynamics Action Model via Universal Embodied Data Ingestion** [2602.12215](http://arxiv.org/abs/2602.12215)
  > 最近的机器人基础模型在很大程度上依赖于大规模行为克隆，它模仿专家的行为，但丢弃了嵌入异构数据中的可转移的动力学知识。虽然统一世界模型 (UWM) 公式有潜力利用如此多样化的数据，但由于粗略的数据使用和分散的数据集，现有的实例很难扩展到基础级别。我们引入了 LDA-1B，这是一种机器人基础模型，通过联合学习动态、策略和视觉预测，为不同质量的数据分配不同的角色，通过通用的具体数据摄取进行扩展。为了大规模支持这种制度，我们组装并标准化了 EI-30k，这是一个具体的交互数据集，以统一的格式包含超过 30,000 小时的人类和机器人轨迹。通过在结构化 DINO 潜在空间中进行预测，可以实现对此类异构数据的可扩展动态学习，从而避免冗余的像素空间外观建模。作为对这种表示的补充，LDA-1B 采用多模态扩散变压器来处理异步视觉和动作流，从而实现 1B 参数规模的稳定训练。模拟和现实世界的实验表明，在接触丰富、灵巧和长视野任务上，LDA-1B 的性能分别比先前方法（例如 $π_{0.5}$ ）高出 21\%、48\% 和 23\%。值得注意的是，LDA-1B 能够实现数据高效的微调，通过利用 30% 的通常有害和丢弃的低质量轨迹，获得 10% 的增益。

- **2026-02-12** **Oxygen left behind: Atmospheric Enrichment due to Fractionation in Sub-Neptunes using BOREAS** [2602.12201](http://arxiv.org/abs/2602.12201)
  > 系外行星大气的演化受到大气逃逸的强烈影响，特别是对于近距离行星而言。大气损失过程中的分馏可以优先除去较轻的元素（例如氢），同时保留较重的元素（例如氧）。在这项研究中，我们研究了流体动力逃逸和化学分馏如何以及在什么条件下共同塑造系外行星大气的质量和成分，特别是混合 H2 + H2O 大气。我们开发了 BOREAS，这是一种自洽质量损失模型，将一维帕克风公式与质量相关分馏方案相结合，我们将其应用于一系列行星质量、半径、平衡温度和入射 XUV 通量，使我们能够及时跟踪不同快照下的氢和氧逃逸率。我们发现氧气在大部分参数空间上被有效保留。在高入射 XUV 通量下会发生显着的氧损失，而在中等通量下，氧损失主要局限于低重力行星。在保留氧气的情况下，辐射太弱而无法促使氢气大量逸出，从而限制了大气富集。相比之下，我们的模型预测海王星以下的大气层在大约 10 年内会经历大量富集。当氢气逸出有效且伴有部分氧气夹带时为 200 Myr。值得注意的是，我们的结果表明，半径谷附近的亚海王星可以演化成富含水的行星，这与 GJ 9827 d 一致。在某些条件下，当今富含水的大气可能起源于贫水的包层，这凸显了在演化模型中包括化学分馏的必要性。 BOREAS 是公开可用的。

- **2026-02-12** **Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision** [2602.12164](http://arxiv.org/abs/2602.12164)
  > 大型语言模型（LLM）已经展示了卓越的推理能力，并且共同进化的范式在代码和数学等领域显示出了有希望的结果。然而，在科学推理任务中，由于解决方案评估不可靠和验证策略的多样性有限，这些模型仍然脆弱。在这项工作中，我们提出了 Sci-CoE，这是一个两阶段的科学协同进化框架，使模型能够通过从稀疏监督到无监督学习的过渡，作为求解器和验证器进行自我进化。在第一阶段，模型使用一小组带注释的数据为验证者建立基本的正确性判断锚。第二阶段，我们引入了共同考虑共识、可靠性和多样性的几何奖励机制，驱动未标记数据的大规模自我迭代。在多个通用科学基准上的实验表明，Sci-CoE增强了复杂推理能力，并表现出强大的可扩展性，有利于构建更强大、更多样化的评估系统。代码可在 https://github.com/InternScience/Sci-CoE 获取。

- **2026-02-12** **GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning** [2602.12099](http://arxiv.org/abs/2602.12099)
  > 由于场景理解受限和未来预测能力较弱，直接根据当前观察预测多步骤动作块的视觉-语言-动作（VLA）模型面临着固有的局限性。相比之下，在网络规模视频语料库上预先训练的视频世界模型表现出强大的时空推理和准确的未来预测，使它们成为增强 VLA 学习的天然基础。因此，我们提出 \textit{GigaBrain-0.5M*}，这是一种通过基于世界模型的强化学习训练的 VLA 模型。基于 \textit{GigaBrain-0.5} 构建，该文件经过超过 10,000 小时的机器人操作数据预训练，其中间版本目前在国际 RoboChallenge 基准测试中排名第一。 \textit{GigaBrain-0.5M*} 通过 \textit{RAMP} （通过世界模型条件策略进行强化学习）进一步集成基于世界模型的强化学习，以实现强大的跨任务适应。实证结果表明，\textit{RAMP} 比 RECAP 基线实现了显着的性能提升，在具有挑战性的任务上实现了约 30\% 的改进，包括 \texttt{洗衣折叠}、\texttt{盒子包装} 和 \texttt{浓缩咖啡准备}。至关重要的是，\textit{GigaBrain-0.5M $^*$ } 表现出可靠的长视野执行，始终如一地完成复杂的操作任务，不会失败，这已通过我们的\href{https://gigabrain05m.github.io}{项目页面}上的实际部署视频进行了验证。

- **2026-02-12** **VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model** [2602.12063](http://arxiv.org/abs/2602.12063)
  > 本文的目标是通过迭代在线交互来提高视觉-语言-动作（VLA）模型的性能和可靠性。由于在现实世界中收集策略推出的成本很高，因此我们研究了是否可以使用学习的模拟器（具体而言，动作条件视频生成模型）来生成额外的推出数据。不幸的是，现有的世界模型缺乏政策改进所需的物理保真度：它们主要是在演示数据集上进行训练的，这些数据集缺乏对许多不同物理交互（特别是失败案例）的覆盖，并且很难在接触丰富的对象操作中准确地模拟微小但关键的物理细节。我们提出了一种简单的迭代改进算法，该算法使用现实世界的转出数据来提高世界模型的保真度，然后可以使用该算法生成补充合成数据以改进 VLA 模型。在我们对真实机器人的实验中，我们使用这种方法来提高最先进的 VLA 模型在多个下游任务上的性能。与基本策略相比，我们的绝对成功率提高了 39.2%，通过生成的综合部署进行训练，绝对成功率提高了 11.6%。视频可以在这个匿名网站上找到：https://sites.google.com/view/vla-w

- **2026-02-12** **HoloBrain-0 Technical Report** [2602.12062](http://arxiv.org/abs/2602.12062)
  > 在这项工作中，我们介绍了 HoloBrain-0，这是一个全面的视觉-语言-动作 (VLA) 框架，它弥补了基础模型研究和可靠的现实世界机器人部署之间的差距。我们系统的核心是一种新颖的 VLA 架构，它明确地结合了机器人实施例先验，包括多视图相机参数和运动学描述 (URDF)，以增强 3D 空间推理并支持不同的实施例。我们通过可扩展的“训练前然后训练后”范例验证了这一设计，在 RoboTwin 2.0、LIBERO 和 GenieSim 等模拟基准上取得了最先进的结果，并且在具有挑战性的长视野现实世界操作任务中取得了出色的结果。值得注意的是，我们高效的 0.2B 参数变体可与更大的基线相媲美，从而实现低延迟的设备部署。为了进一步加速研究和实际采用，我们完全开源整个 HoloBrain 生态系统，其中包括：(1) 强大的预训练 VLA 基础；(2) 用于多个模拟套件和实际任务的后训练检查点；(3) RoboOrchard，用于数据管理、模型训练和部署的全栈 VLA 基础设施，与标准化数据收集协议一起，该版本为社区提供了一条完整的、可重复的高性能机器人操作路径。

- **2026-02-12** **When would Vision-Proprioception Policies Fail in Robotic Manipulation?** [2602.12032](http://arxiv.org/abs/2602.12032)
  > 本体感觉信息对于提供实时机器人状态的精确伺服控制至关重要。人们高度期望它与视觉的合作能够提高复杂任务中操纵策略的性能。然而，最近的研究报告了对视觉本体感觉政策的普遍化的不一致的观察。在这项工作中，我们通过进行时间控制实验来研究这一点。我们发现，在机器人运动转换的任务子阶段（需要目标定位）中，视觉本体感觉策略的视觉模态发挥的作用有限。进一步的分析表明，该策略自然倾向于简洁的本体感受信号，这些信号在训练时可以更快地减少损失，从而在运动转换阶段主导优化并抑制视觉模态的学习。为了缓解这个问题，我们提出了带有相位引导的梯度调整（GAP）算法，该算法自适应地调节本体感觉的优化，从而实现视觉本体感觉策略内的动态协作。具体来说，我们利用本体感觉来捕获机器人状态并估计属于运动转换阶段的轨迹中每个时间步的概率。在策略学习过程中，我们应用细粒度的调整，根据估计的概率降低本体感觉梯度的大小，从而形成稳健且可推广的视觉本体感觉策略。综合实验表明，GAP 适用于模拟和现实环境、单臂和双臂设置，并且与传统模型和视觉-语言-动作模型兼容。我们相信这项工作可以为机器人操纵中视觉本体感觉策略的发展提供有价值的见解。

- **2026-02-12** **Accelerating Robotic Reinforcement Learning with Agent Guidance** [2602.11978](http://arxiv.org/abs/2602.11978)
  > 强化学习 (RL) 为自主机器人提供了一个强大的范例，让其通过反复试验掌握通用操作技能。然而，其实际应用却因严重的样本效率低下而受到抑制。最近的人在环（HIL）方法通过使用人工修正来加速训练，但这种方法面临可扩展性障碍。对人类监督员的依赖强制实行 1:1 的监督比例，这限制了车队的扩张，操作员在长时间的工作中会感到疲劳，并且由于人员熟练程度不一致而带来很大的差异。我们提出了代理引导策略搜索（AGPS），这是一个通过用多模式代理取代人类监督员来自动化训练流程的框架。我们的主要见解是，代理可以被视为语义世界模型，在结构物理探索之前注入内在价值。通过使用可执行工具，代理通过修正路径点和空间约束提供精确的指导，以进行探索修剪。我们在两项任务上验证了我们的方法，从精确插入到可变形对象操作。结果表明，AGPS 在样本效率方面优于 HIL 方法。这实现了监督管道的自动化，开启了免劳动力且可扩展的机器人学习之路。项目网站：https://agps-rl.github.io/agps。

- **2026-02-11** **Reentrance in a Hamiltonian flocking model** [2602.11104](http://arxiv.org/abs/2602.11104)
  > 自运动和排斥粒子的聚集，即所谓的运动诱导相分离（MIPS），是主动物理学最清晰的特征之一。通常，增加自迁移率的幅度会增加聚集程度，然而，对于足够高的自迁移率，会重新进入均质相。在这里，我们报告说，这种重入自然出现在哈密顿（保守）模型中，该模型已知可概括（活跃）鸟群的特性，并表现出让人想起 MIPS 的聚类行为。我们在数值上证明了均质相的重入，并将潜在机制确定为自旋速度耦合驱动的振幅与迁移率限制的动力学挫败之间的竞争。具体来说，我们揭示了强自旋速度耦合抑制了横向扩散，从而导致系统进入停止状态，从而关闭了相分离的窗口。总的来说，我们的工作在平衡和非平衡材料的重入物理学之间提供了哈密顿保守的桥梁。

- **2026-02-11** **RISE: Self-Improving Robot Policy with Compositional World Model** [2602.11075](http://arxiv.org/abs/2602.11075)
  > 尽管模型容量和数据采集不断扩展，但视觉-语言-动作 (VLA) 模型在接触丰富的动态操作任务中仍然很脆弱，在这些任务中，微小的执行偏差可能会导致失败。虽然强化学习 (RL) 提供了实现稳健性的原则性途径，但物理世界中的策略 RL 受到安全风险、硬件成本和环境重置的限制。为了弥补这一差距，我们推出了 RISE，这是一个通过想象力进行机器人强化学习的可扩展框架。其核心是组合世界模型，（i）通过可控动态模型预测多视角未来，（ii）通过进步价值模型评估想象的结果，为政策改进提供信息优势。这种组合设计允许通过最适合但独特的架构和目标来定制状态和价值。这些组件被集成到一个闭环自我改进管道中，该管道不断生成想象中的部署、估计优势并更新想象空间中的策略，而无需昂贵的物理交互。在三个具有挑战性的现实世界任务中，RISE 比现有技术取得了显着改进，动态砖块分类的绝对性能提高了 35% 以上，背包包装的绝对性能提高了 45%，盒子关闭的性能提高了 35%。

- **2026-02-11** **ContactGaussian-WM: Learning Physics-Grounded World Model from Videos** [2602.11021](http://arxiv.org/abs/2602.11021)
  > 开发理解复杂物理交互的世界模型对于推进机器人规划和仿真至关重要。然而，现有方法通常很难在数据稀缺和复杂的接触丰富的动态运动条件下准确地对环境进行建模。为了应对这些挑战，我们提出了 ContactGaussian-WM，这是一种基于物理的可微刚体世界模型，能够直接从稀疏和接触丰富的视频序列中学习复杂的物理定律。我们的框架由两个核心组件组成：（1）视觉外观和碰撞的统一高斯表示（2）端到端可微学习框架，通过封闭式物理引擎进行区分，从稀疏的视觉观察中推断物理属性。广泛的模拟和现实世界评估表明，ContactGaussian-WM 在学习复杂场景方面优于最先进的方法，展现出强大的泛化能力。此外，我们展示了我们的框架在下游应用中的实际效用，包括数据合成和实时 MPC。

- **2026-02-11** **Interpretable Vision Transformers in Monocular Depth Estimation via SVDA** [2602.11005](http://arxiv.org/abs/2602.11005)
  > 单目深度估计是计算机视觉在机器人、AR 和自动驾驶领域的应用的核心问题，但驱动现代 Transformer 架构的自注意力机制仍然不透明。我们将 SVD-Inspired Attention (SVDA) 引入到密集预测变换器 (DPT) 中，为密集预测任务提供了第一个频谱结构的注意力公式。 SVDA 通过将可学习的对角矩阵嵌入到标准化的查询键交互中，将方向对齐与频谱调制解耦，从而实现本质上可解释的注意力图，而不是事后近似。 KITTI 和 NYU-v2 上的实验表明，SVDA 保留或略微提高了预测准确性，同时仅增加了少量计算开销。更重要的是，SVDA 解锁了六个光谱指标，可量化熵、秩、稀疏性、对齐、选择性和鲁棒性。这些揭示了训练过程中注意力如何组织的一致的跨数据集和深度模式，这些见解在标准 Transformer 中仍然无法获得。通过将注意力的作用从不透明机制转移到可量化描述符，SVDA 重新定义了单目深度估计的可解释性，并为透明密集预测模型开辟了一条原则性途径。

- **2026-02-11** **Sample Efficient Generative Molecular Optimization with Joint Self-Improvement** [2602.10984](http://arxiv.org/abs/2602.10984)
  > 生成分子优化旨在设计性能超越现有化合物的分子。然而，此类候选者很少见，评估成本也很高，因此样本效率至关重要。此外，为预测分子评估而引入的替代模型会受到分布变化的影响，因为优化导致候选者越来越脱离分布。为了应对这些挑战，我们引入了联合自我改进，它受益于（i）联合生成预测模型和（ii）自我改进抽样方案。前者将生成器与代理对齐，减轻分布偏移，而后者使用预测模型对联合模型的生成部分进行偏置，以在推理时有效地生成优化的分子。离线和在线分子优化基准的实验表明，在有限的评估预算下，联合自我改进优于最先进的方法。

- **2026-02-11** **Scaling World Model for Hierarchical Manipulation Policies** [2602.10983](http://arxiv.org/abs/2602.10983)
  > 视觉-语言-动作（VLA）模型对于通用机器人操作很有希望，但在分布外（OOD）设置中仍然很脆弱，尤其是在真实机器人数据有限的情况下。为了解决泛化瓶颈，我们引入了分层视觉-语言-动作框架 \our{}，该框架利用大规模预训练世界模型的泛化来实现稳健且可泛化的视觉子目标任务分解 VISTA。我们的分层框架 \our{} 由作为高级规划器的世界模型和作为低级执行器的 VLA 组成。高层世界模型首先将操作任务划分为具有目标图像的子任务序列，低层策略遵循文本和视觉指导来生成动作序列。与原始文本目标规范相比，这些合成的目标图像为低级策略提供了视觉和物理基础的细节，使得在未见过的物体和新场景中进行泛化成为可能。我们在大规模分布外场景中验证了视觉目标合成和分层 VLA 策略，并且在世界模型生成的指导下，相同结构的 VLA 在新颖场景中的性能可以从 14% 提高到 69%。结果表明，我们的方法明显优于以前的基线，特别是在分布外的情况下。项目页面：\href{https://vista-wm.github.io/}{https://vista-wm.github.io}

- **2026-02-11** **RADAR: Benchmarking Vision-Language-Action Generalization via Real-World Dynamics, Spatial-Physical Intelligence, and Autonomous Evaluation** [2602.10980](http://arxiv.org/abs/2602.10980)
  > VLA模型在具身智能方面取得了显着的进步；然而，他们的评估仍然主要局限于模拟或高度受限的现实环境。这种不匹配造成了巨大的现实差距，强大的基准性能往往掩盖了不同物理环境中较差的泛化能力。我们发现当前基准测试实践中的三个系统性缺陷阻碍了公平和可靠的模型比较。 (1) 现有基准无法对现实世界的动态进行建模，忽略了动态对象配置、机器人初始状态、照明变化和传感器噪声等关键因素。 （2）当前协议忽视了空间物理智能，减少了对不探究几何推理的死记硬背操作任务的评估。 (3) 该领域缺乏可扩展的完全自主评估，而是依赖于忽略 3D 空间结构的简单 2D 指标，或者依赖于成本高昂、存在偏见且不可扩展的人机交互系统。为了解决这些限制，我们引入了 RADAR（真实世界自主动力学和推理），这是一个旨在系统地评估现实条件下 VLA 泛化能力的基准。 RADAR 集成了三个核心组件：(1) 一套原则性的物理动力学； (2) 明确测试空间推理和物理理解的专门任务； (3) 基于 3D 指标的完全自主的评估流程，无需人工监督。我们应用 RADAR 来审核多个最先进的 VLA 模型，并发现其表面能力之下的严重脆弱性。在适度的物理动力学条件下，性能急剧下降，在传感器噪声下，3D IoU 的预期从 0.261 下降到 0.068。此外，模型表现出有限的空间推理能力。这些发现使 RADAR 成为对 VLA 模型进行可靠且可推广的现实世界评估的必要基础。

- **2026-02-11** **ResWorld: Temporal Residual World Model for End-to-End Autonomous Driving** [2602.10884](http://arxiv.org/abs/2602.10884)
  > 世界模型对驾驶场景的全面理解能力，显着提高了端到端自动驾驶框架的规划精度。然而，静态区域的冗余建模以及缺乏与轨迹的深度交互阻碍了世界模型发挥其全部有效性。在本文中，我们提出了时间残差世界模型（TR-World），它专注于动态对象建模。通过计算场景表示的时间残差，可以在不依赖检测和跟踪的情况下提取动态对象的信息。 TR-World仅将时间残差作为输入，从而更准确地预测动态对象的未来空间分布。通过将预测与当前BEV特征中包含的静态物体信息相结合，可以获得准确的未来BEV特征。此外，我们提出了未来引导轨迹细化（FGTR）模块，该模块在先前轨迹（根据当前场景表示预测）和未来 BEV 特征之间进行交互。该模块不仅可以利用未来的路况来细化轨迹，还可以对未来的 BEV 特征提供稀疏时空监督，​​以防止世界模型崩溃。在 nuScenes 和 NAVSIM 数据集上进行的综合实验表明，我们的方法（即 ResWorld）实现了最先进的规划性能。代码可在 https://github.com/mengtan00/ResWorld.git 获取。

- **2026-02-11** **Viewpoint Recommendation for Point Cloud Labeling through Interaction Cost Modeling** [2602.10871](http://arxiv.org/abs/2602.10871)
  > 3D 点云的语义分割对于许多应用都很重要，例如自动驾驶。为了训练语义分割模型，标记的点云分割数据集是必不可少的。同时，点云标记对于注释者来说非常耗时，这通常涉及调整相机视点并通过套索选择点。为了减少点云标记的时间成本，我们提出了一种观点推荐方法来减少注释者的标记时间成本。我们采用费茨定律来模拟点云中套索选择的时间成本。使用建模的时间成本，向注释者推荐最小化套索选择时间成本的观点。我们构建了一个用于 3D 点云语义分割的数据标记系统，该系统集成了我们的视点推荐方法。该系统使用户能够导航到推荐的观点以进行有效的注释。通过消融研究，我们观察到我们的方法有效降低了数据标记时间成本。我们还将我们的方法与之前在不同数据集上的观点选择方法进行定性比较。

- **2026-02-11** **The Effect of Design Thinking on Creative & Innovation Processes: An Empirical Study Across Different Design Experience Levels** [2602.10827](http://arxiv.org/abs/2602.10827)
  > 本研究采用线性回归和结构方程模型来探索思维技能、设计思维、创意自我效能（CSE）和集体创意效能（CCE）如何驱动设计创意和创新，并分析模型在不同经验水平上的结构稳定性。路径分析结果表明，四种设计思维技能：问题驱动设计（beta = 0.198，p < 0.01）、信息驱动设计（beta = 0.241，p < 0.001）、解决方案驱动设计（beta = 0.227，p < 0.001）和知识驱动设计（beta = 0.263，p < 0.001）都对设计产生显着和积极的影响思考。此外，设计思维对设计创造力和创新具有显着的正向预测作用（beta = 0.286，p < 0.001）。中介分析确认了三个重要的中介路径：CSE 中介路径（beta = 0.128，p < 0.001）、CCE 中介路径（beta = 0.073，p < 0.01）和“CSE 到 CCE”链中介路径（beta = 0.025，p < 0.01）。多组比较结果揭示了完全等效模型下学生组和专业组之间的显着差异。放宽特定约束后，基线模型的嵌套模型、部分测量不变性、结构权重不变性、结构协方差不变性均无显着差异。这些发现阐明了设计创意与创新的多维路径，为优化差异化教学模型和专业实践指南提供了坚实的实证基础。

- **2026-02-10** **ST4VLA: Spatially Guided Training for Vision-Language-Action Models** [2602.10109](http://arxiv.org/abs/2602.10109)
  > 大型视觉语言模型（VLM）擅长多模态理解，但在扩展到具体任务时却表现不佳，在具体任务中指令必须转换为低级运动动作。我们引入了 ST4VLA，这是一种双系统视觉-语言-动作框架，它利用空间引导训练将动作学习与 VLM 中的空间先验保持一致。 ST4VLA 包括两个阶段：(i) 空间基础预训练，通过来自网络规模和机器人特定数据的可扩展点、框和轨迹预测，为 VLM 配备可转移的先验；(ii) 空间引导动作后训练，鼓励模型产生更丰富的空间先验，以通过空间提示指导动作生成。这种设计在政策学习期间保留了空间基础，并促进空间和行动目标的一致优化。根据经验，ST4VLA 比普通 VLA 取得了实质性改进，Google Robot 上的性能从 66.1 -> 84.6 增加，WidowX Robot 上的性能从 54.7 -> 73.2 增加，在 SimplerEnv 上建立了新的最先进结果。它还展示了对看不见的物体和释义指令的更强的泛化能力，以及对现实世界环境中的长视野扰动的鲁棒性。这些结果凸显了可扩展的空间引导训练是稳健、可推广的机器人学习的一个有前途的方向。源代码、数据和模型发布于 https://internrobotics.github.io/internvla-m1.github.io/

- **2026-02-10** **EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration** [2602.10106](http://arxiv.org/abs/2602.10106)
  > 人类演示自然地提供了丰富的环境多样性和规模，使其成为机器人远程操作的有吸引力的替代方案。虽然这种范例具有先进的机器人手臂操纵，但其解决更具挑战性、需要数据的人形机器人操纵问题的潜力在很大程度上仍未得到探索。我们提出了 EgoHumanoid，这是第一个使用丰富的以自我为中心的人类演示和有限的机器人数据来共同训练视觉-语言-动作策略的框架，使类人机器人能够在不同的现实世界环境中执行局部操作。为了弥合人类和机器人之间的体现差距，包括物理形态和观点的差异，我们引入了从硬件设计到数据处理的系统对准管道。开发了一种用于可扩展人类数据收集的便携式系统，并且我们建立了实用的收集协议以提高可转移性。我们的人与人之间的对齐流程的核心是两个关键组件。视图对齐减少了由相机高度和透视变化引起的视域差异。动作对齐将人体运动映射到一个统一的、运动学上可行的动作空间中，用于人形控制。广泛的现实世界实验表明，合并无机器人的自我中心数据显着优于仅机器人的基线 51%，特别是在看不见的环境中。我们的分析进一步揭示了哪些行为可以有效转移以及扩展人类数据的潜力。

- **2026-02-10** **Olaf-World: Orienting Latent Actions for Video World Modeling** [2602.10104](http://arxiv.org/abs/2602.10104)
  > 动作可控世界模型的扩展受到动作标签稀缺的限制。虽然潜在动作学习有望从未标记的视频中提取控制界面，但学习到的潜在动作通常无法跨上下文迁移：它们纠缠了特定于场景的线索并且缺乏共享的坐标系。发生这种情况是因为标准目标仅在每个剪辑内运行，没有提供跨上下文对齐动作语义的机制。我们的主要见解是，虽然动作是不可观察的，但它们的语义效果是可观察的并且可以作为共享参考。我们引入了 Seq $Δ$ -REPA，这是一种序列级控制效果对齐目标，它将集成的潜在动作锚定到来自冻结的自监督视频编码器的时间特征差异。在此基础上，我们提出了 Olaf-World，这是一个从大规模被动视频中预训练动作条件视频世界模型的管道。大量的实验表明，我们的方法学习了一个更加结构化的潜在动作空间，与最先进的基线相比，可以实现更强的零样本动作转移和更高效的数据适应新的控制界面。

- **2026-02-10** **VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model** [2602.10098](http://arxiv.org/abs/2602.10098)
  > 在互联网规模的视频上预训练视觉-语言-动作（VLA）策略很有吸引力，但当前的潜在动作目标经常学到错误的东西：它们仍然锚定于像素变化而不是与动作相关的状态转换，这使得它们容易受到外观偏差、令人讨厌的运动和信息泄漏的影响。我们引入了 VLA-JEPA，这是一种 JEPA 风格的预训练框架，它通过设计避开了这些陷阱。关键思想是 \emph{无泄漏状态预测}：目标编码器从未来帧生成潜在表示，而学生路径只能看到当前的观察结果 - 未来信息仅用作监督目标，从不用作输入。通过在潜在空间而不是像素空间中进行预测，VLA-JEPA 学习了对相机运动和不相关背景变化具有鲁棒性的动态抽象。这产生了一个简单的两阶段配方——JEPA 预训练，然后是动作头微调——没有先前潜在动作管道的多阶段复杂性。对 LIBERO、LIBERO-Plus、SimplerEnv 和现实世界操作任务的实验表明，VLA-JEPA 在泛化性和鲁棒性方面比现有方法取得了一致的进步。

- **2026-02-10** **UniVTAC: A Unified Simulation Platform for Visuo-Tactile Manipulation Data Generation, Learning, and Benchmarking** [2602.10093](http://arxiv.org/abs/2602.10093)
  > 通过视觉-语言-动作（VLA）政策，机器人操作取得了快速进展。然而，视觉触觉感知对于富含接触的操作至关重要，因为仅使用视觉很难稳健地完成诸如插入之类的任务。与此同时，在物理世界中获取大规模且可靠的触觉数据仍然成本高昂且具有挑战性，而且缺乏统一的评估平台进一步限制了政策学习和系统分析。为了应对这些挑战，我们提出了 UniVTAC，这是一种基于模拟的视觉触觉数据合成平台，支持三种常用的视觉触觉传感器，并能够生成可扩展且可控的信息接触交互。基于该平台，我们推出了 UniVTAC 编码器，这是一种视觉触觉编码器，使用设计的监控信号在大规模模拟合成数据上进行训练，为下游操作任务提供以触觉为中心的视觉触觉表示。此外，我们还提出了 UniVTAC 基准，它由八个代表性的视觉触觉操作任务组成，用于评估触觉驱动的策略。实验结果表明，集成 UniVTAC 编码器在 UniVTAC 基准上将平均成功率提高了 17.1%，而现实世界的机器人实验进一步证明任务成功率提高了 25%。我们的网页位于 https://univtac.github.io/。

- **2026-02-10** **Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning** [2602.10090](http://arxiv.org/abs/2602.10090)
  > 大语言模型 (LLM) 的最新进展使自主代理能够执行需要与工具和环境进行多轮交互的复杂任务。然而，由于缺乏多样化和可靠的环境，扩展此类代理训练受到限制。在本文中，我们提出了代理世界模型（AWM），一个完全合成的环境生成管道。使用此管道，我们可以扩展到涵盖日常场景的 1,000 个环境，其中代理可以与丰富的工具集（平均每个环境 35 个工具）进行交互并获得高质量的观察结果。值得注意的是，这些环境是代码驱动的，并由数据库支持，提供比法学硕士模拟的环境更可靠、更一致的状态转换。此外，与从现实环境中收集轨迹相比，它们可以实现更有效的代理交互。为了证明该资源的有效性，我们对多轮工具使用代理进行大规模强化学习。得益于完全可执行的环境和可访问的数据库状态，我们还可以设计可靠的奖励函数。对三个基准的实验表明，仅在合成环境中进行训练，而不是在特定于基准的环境中进行训练，可以产生强大的分布外泛化能力。该代码可在 https://github.com/Snowflake-Labs/agent-world-model 获取。

- **2026-02-10** **Optimistic World Models: Efficient Exploration in Model-Based Deep Reinforcement Learning** [2602.10044](http://arxiv.org/abs/2602.10044)
  > 高效探索仍然是强化学习（RL）的核心挑战，特别是在稀疏奖励环境中。我们引入了乐观世界模型 (OWM)，这是一种用于乐观探索的有原则且可扩展的框架，它将经典的奖励偏差最大似然估计 (RBMLE) 从自适应控制引入深度强化学习。与上置信界 (UCB) 式的探索方法相比，OWM 通过乐观动态损失的增强，将乐观主义直接融入到模型学习中，这种损失使想象的转变偏向于更高回报的结果。这种完全基于梯度的损失既不需要不确定性估计，也不需要约束优化。我们的方法是与现有的世界模型框架即插即用，保持可扩展性，同时只需要对标准训练程序进行最少的修改。我们在两个最先进的世界模型架构中实例化了 OWM，从而产生了 Optimistic DreamerV3 和 Optimistic STORM，与基准模型相比，它们在样本效率和累积回报方面表现出了显着的改进。

- **2026-02-10** **RoboInter: A Holistic Intermediate Representation Suite Towards Robotic Manipulation** [2602.09973](http://arxiv.org/abs/2602.09973)
  > 大型视觉语言模型 (VLM) 的进步激发了人们对用于机器人操作的视觉语言动作 (VLA) 系统日益增长的兴趣。然而，现有的操作数据集的管理成本仍然很高，高度特定于实施例，并且覆盖范围和多样性不足，从而阻碍了 VLA 模型的泛化。最近的方法试图通过先计划后执行的范例来减轻这些限制，其中首先生成高级计划（例如子任务、跟踪），然后将其转换为低级操作，但它们严重依赖于额外的中间监督，而现有数据集中基本上不存在这种监督。为了弥补这一差距，我们引入了 RoboInter Manipulation Suite，这是一个统一的资源，包括数据、基准测试和操作中间表示模型。它由 RoboInter-Tool 和 RoboInter-Data 组成，RoboInter-Tool 是一个轻量级 GUI，可对不同表示进行半自动注释；RoboInter-Data 是一个大型数据集，包含 571 个不同场景的 23 万多个片段，可在 10 多个类别的中间表示上提供密集的每帧注释，在规模和注释质量方面大大超过了之前的工作。在此基础上，RoboInter-VQA 引入了 9 个空间和 20 个时间的体现 VQA 类别，以系统地基准测试和增强 VLM 的体现推理能力。同时，RoboInter-VLA 提供了一个集成的计划然后执行框架，支持模块化和端到端的 VLA 变体，通过中间监督将高层规划与低层执行联系起来。总的来说，RoboInter 为通过细粒度和多样化的中间表示推进稳健和通用的机器人学习奠定了实践基础。

- **2026-02-10** **Hydra-Nav: Object Navigation via Adaptive Dual-Process Reasoning** [2602.09972](http://arxiv.org/abs/2602.09972)
  > 虽然大型视觉语言模型（VLM）显示出物体目标导航的希望，但当前的方法仍然面临成功率低和看不见的物体定位效率低的问题——失败主要归因于时空推理能力弱。与此同时，最近尝试将推理注入基于 VLM 的代理中，提高了成功率，但会产生大量的计算开销。为了解决现有方法的低效和低效问题，我们引入了 Hydra-Nav，这是一种统一的 VLM 架构，可以在用于分析勘探历史和制定高级计划的深思熟虑的慢系统和用于高效执行的反应快速系统之间自适应地切换。我们通过三阶段课程来训练 Hydra-Nav：（i）空间动作对齐以加强轨迹规划，（ii）记忆推理整合以增强长视野探索中的时空推理，以及（iii）迭代拒绝微调以在关键决策点实现选择性推理。大量实验表明，Hydra-Nav 在 HM3D、MP3D 和 OVON 基准测试中实现了最先进的性能，分别比第二好的方法高出 11.1%、17.4% 和 21.2%。此外，我们还引入了 SOT（按操作时间加权的成功），这是一种新指标，用于衡量具有不同推理强度的 VLM 的搜索效率。结果表明，自适应推理比固定频率基线显着提高了搜索效率。

- **2026-02-10** **Instruct2Act: From Human Instruction to Actions Sequencing and Execution via Robot Action Network for Robotic Manipulation** [2602.09940](http://arxiv.org/abs/2602.09940)
  > 由于计算和传感的限制，机器人常常难以在现实世界中遵循自由形式的人类指令。我们通过轻量级、完全在设备上的管道来解决这一差距，该管道将自然语言命令转换为可靠的操作。我们的方法有两个阶段：（i）动作指令模块（Instruct2Act），一个紧凑的 BiLSTM，具有多头注意力自动编码器，可将指令解析为有序的原子动作序列（例如，到达、抓取、移动、放置）； (ii) 机器人动作网络 (RAN)，它使用动态自适应轨迹径向网络 (DATRN) 和基于视觉的环境分析器 (YOLOv8) 来为每个子动作生成精确的控制轨迹。整个系统运行在一个没有云服务的普通系统上。在我们的自定义专有数据集上，Instruct2Act 实现了 91.5% 的子动作预测准确率，同时保持了较小的占用空间。对四项任务（拾取放置、拾取倾倒、擦拭和拾取-给予）进行的真实机器人评估总体成功率为 90%；子动作推理在 3.8 秒内完成，根据任务复杂性，端到端执行在 30-60 秒内完成。这些结果表明，细粒度的指令到动作解析与基于 DATRN 的轨迹生成和视觉引导接地相结合，为资源受限的单摄像头设置中的确定性实时操作提供了一条实用路径。

- **2026-02-09** **TwinRL-VLA: Digital Twin-Driven Reinforcement Learning for Real-World Robotic Manipulation** [2602.09023](http://arxiv.org/abs/2602.09023)
  > 尽管泛化能力很强，但视觉-语言-动作（VLA）模型仍然受到专家演示成本高昂和现实世界交互不足的限制。虽然在线强化学习 (RL) 在改进通用基础模型方面表现出了良好的前景，但在现实环境中将 RL 应用于 VLA 操作仍然受到探索效率低和探索空间有限的阻碍。通过系统的现实世界实验，我们观察到在线强化学习的有效探索空间与监督微调（SFT）的数据分布密切相关。受这一观察的启发，我们提出了 TwinRL，这是一种数字孪生现实世界协作 RL 框架，旨在扩展和指导 VLA 模型的探索。首先，从智能手机捕获的场景中有效地重建高保真数字孪生，从而实现真实环境和模拟环境之间的真实双向传输。在SFT预热阶段，我们引入了使用数字孪生的探索空间扩展策略，以拓宽数据轨迹分布的支持。基于这种增强的初始化，我们提出了一种模拟到真实的引导探索策略，以进一步加速在线强化学习。具体来说，TwinRL 在部署之前在数字孪生中执行高效且并行的在线强化学习，有效地弥合了离线和在线训练阶段之间的差距。随后，我们利用高效的数字孪生采样来识别容易发生故障但信息丰富的配置，这些配置用于指导在真实机器人上进行有针对性的人机交互。在我们的实验中，TwinRL 在现实世界演示覆盖的分布内区域和分布外区域均取得了 100% 的成功，比之前的现实世界 RL 方法至少提高了 30% 的速度，并且四项任务平均只需要大约 20 分钟。

- **2026-02-09** **WorldCompass: Reinforcement Learning for Long-Horizon World Models** [2602.09022](http://arxiv.org/abs/2602.09022)
  > 这项工作提出了 WorldCompass，这是一种新颖的强化学习 (RL) 后训练框架，适用于长视野、基于交互式视频的世界模型，使他们能够根据交互信号更准确、一致地探索世界。为了有效地“引导”世界模型的探索，我们引入了针对自回归视频生成范式量身定制的三项核心创新：1）剪辑级推出策略：我们在单个目标剪辑上生成并评估多个样本，这显着提高了推出效率并提供细粒度的奖励信号。 2）补充奖励函数：我们设计了针对交互跟踪准确性和视觉质量的奖励函数，提供直接监督并有效抑制奖励黑客行为。 3）高效的强化学习算法：我们采用负感知微调策略结合各种效率优化来高效且有效地增强模型容量。对SoTA开源世界模型WorldPlay的评估表明，WorldCompass显着提高了各种场景下的交互准确性和视觉保真度。

- **2026-02-09** **Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving** [2602.09018](http://arxiv.org/abs/2602.09018)
  > 自动驾驶中的分布外 (OOD) 鲁棒性通常会简化为一个数字，从而隐藏了违反策略的内容。我们沿着五个轴分解环境：场景（农村/城市）、季节、天气、时间（白天/夜晚）和代理组合；并测量受控 $k$ 因子扰动下的性能 ($k \in \{0,1,2,3\}$)。使用 VISTA 中的闭环控制，我们对 FC、CNN 和 ViT 策略进行基准测试，在冻结的基础模型 (FM) 特征上训练紧凑的 ViT 头，并在规模、多样性和时间上下文中改变 ID 支持。 (1) ViT 策略明显比同等规模的 CNN/FC 更具有 OOD 鲁棒性，并且 FM 功能以延迟成本取得了最先进的成功。 (2) 朴素时间输入（多帧）无法击败最佳单帧基线。 （3）单因素下降最大的是农村$\rightarrow$城市和白天$\rightarrow$夜间（各$\sim 31\%$）；演员交换$\sim 10\%$，中雨$\sim 7\%$；季节变化可能会很剧烈，并且将时间翻转与其他变化结合起来会进一步降低性能。 (4) FM特色保单在三项同时变化下保持在$85\%$之上；非 FM 单帧策略受到较大的第一轮打击，所有非 FM 模型均通过三个变化跌至 50\%$ 以下。 (5) 相互作用是非累加性的：一些配对会部分抵消，而季节组合尤其有害。 (6) 冬季/雪地训练对于单因素变化最为稳健，而乡村+夏季基线则提供最佳的整体 OOD 性能。 (7) 缩放轨迹/视图可提高鲁棒性（从 5 美元到 14 美元轨迹，$+11.8 点），但有针对性地暴露在恶劣条件下可以替代缩放。 （8）使用多个ID环境扩大了覆盖范围并加强了弱案例（城市OOD $60.6\% \rightarrow 70.1\%$ ），ID下降幅度较小；单 ID 可以保持峰值性能，但范围很窄。这些结果为 OOD 稳健的驾驶策略提供了可行的设计规则。

- **2026-02-09** **Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models** [2602.09017](http://arxiv.org/abs/2602.09017)
  > 机器人学习中的流行范例试图在运行时通过语言提示来概括环境、实施例和任务。一个基本的张力限制了这种方法：语言往往过于抽象，无法指导鲁棒操作所需的具体物理理解。在这项工作中，我们引入了接触锚定策略（CAP），它用空间中的物理接触点代替语言调节。同时，我们将 CAP 构建为模块化实用模型库，而不是单一的通才政策。这种分解使我们能够实现从真实到模拟的迭代周期：我们构建了 EgoGym，一个轻量级模拟基准，以快速识别故障模式并在实际部署之前完善我们的模型和数据集。我们表明，通过对接触进行调节并通过模拟进行迭代，CAP 在仅使用 23 小时的演示数据的情况下，可以在三种基本操作技能上推广到新颖的环境和开箱即用的实施例，并且在零样本评估中比大型、最先进的 VLA 性能高出 56%。所有模型检查点、代码库、硬件、模拟和数据集都将开源。项目页面：https://cap-policy.github.io/

- **2026-02-09** **WorldArena: A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models** [2602.08971](http://arxiv.org/abs/2602.08971)
  > 虽然世界模型已成为体现智能的基石，使智能体能够通过行动条件预测来推理环境动态，但它们的评估仍然支离破碎。目前对具体世界模型的评估主要集中在感知保真度（例如视频生成质量），而忽视了这些模型在下游决策任务中的功能效用。在这项工作中，我们介绍了 WorldArena，这是一个统一的基准，旨在跨感知和功能维度系统地评估具体世界模型。 WorldArena 通过三个维度评估模型：视频感知质量，通过 6 个子维度的 16 个指标进行衡量；体现任务功能，将世界模型评估为数据引擎、政策评估者和与主观人类评估相结合的行动规划者。此外，我们提出了 EWMScore，这是一种将多维性能集成到单个可解释指数中的整体指标。通过对 14 个代表性模型的广泛实验，我们揭示了显着的感知功能差距，表明高视觉质量并不一定转化为强大的具体任务能力。 WorldArena 基准测试和公共排行榜在 https://worldarena.ai 上发布，提供了一个框架，用于跟踪具体人工智能中真正功能性世界模型的进展。

- **2026-02-09** **stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation** [2602.08968](http://arxiv.org/abs/2602.08968)
  > 世界模型已经成为学习环境动态的紧凑、预测性表示的强大范例，使智能体能够超越直接经验进行推理、计划和概括。尽管最近人们对世界模型很感兴趣，但大多数可用的实现仍然是特定于出版物的，这严重限制了它们的可重用性，增加了错误的风险，并降低了评估标准化。为了缓解这些问题，我们引入了稳定世界模型（SWM），这是一个模块化、经过测试和记录的世界模型研究生态系统，可提供高效的数据收集工具、标准化环境、规划算法和基线实施。此外，SWM 中的每个环境都可以实现可控的变化因素，包括视觉和物理属性，以支持鲁棒性和持续学习研究。最后，我们通过使用 SWM 研究 DINO-WM 中的零样本鲁棒性来展示 SWM 的实用性。

- **2026-02-09** **Modeling 3D Pedestrian-Vehicle Interactions for Vehicle-Conditioned Pose Forecasting** [2602.08962](http://arxiv.org/abs/2602.08962)
  > 准确预测行人运动对于复杂城市环境中安全可靠的自动驾驶至关重要。在这项工作中，我们提出了一个 3D 车辆调节行人姿势预测框架，该框架明确地结合了周围车辆信息。为了支持这一点，我们使用对齐的 3D 车辆边界框增强了 Waymo-3DSkelMo 数据集，从而实现了多智能体行人-车辆交互的真实建模。我们引入了一种采样方案，根据行人和车辆数量对场景进行分类，从而促进不同交互复杂性的训练。我们提出的网络采用专用车辆编码器和行人车辆交互交叉注意模块来适应 TBIFormer 架构，以融合行人和车辆特征，从而允许根据历史行人运动和周围车辆进行预测。大量实验证明了预测准确性的显着提高，并验证了行人-车辆交互建模的不同方法，凸显了车辆感知 3D 姿态预测对于自动驾驶的重要性。代码可见：https://github.com/GuangxunZhu/VehCondPose3D

- **2026-02-09** **Any-to-All MRI Synthesis: A Unified Foundation Model for Nasopharyngeal Carcinoma and Its Downstream Applications** [2602.08822](http://arxiv.org/abs/2602.08822)
  > 磁共振成像 (MRI) 对于鼻咽癌 (NPC) 放疗 (RT) 至关重要，但患者不适、扫描时间长和成本高等实际限制往往会导致临床实践中的治疗方式不完整，从而影响放疗计划的准确性。传统的MRI合成方法具有模态特异性、解剖适应性有限、缺乏临床可解释性，无法满足鼻咽癌的RT需求。在这里，我们开发了一个统一的基础模型，集成了对比视觉表示学习和视觉语言对齐（VLA），以实现任意到所有的 MRI 合成。该模型使用对比编码器进行模态不变表示，并使用基于 CLIP 的文本通知解码器进行语义一致的合成，通过一个统一的基础模型支持任意到所有 MRI 合成。它使用来自 13 个机构的 40,825 张图像进行训练，在 26 个内部/外部验证站点（15,748 张图像）中实现了一致的高性能（平均 SSIM 0.90，PSNR 27），具有卓越的合成保真度以及对噪声和域偏移的鲁棒性。同时，其统一表示增强了下游 RT 相关任务（例如分割）。这项工作通过利用基础模型连接技术综合和临床实用，推进了鼻咽癌护理的数字医学解决方案。

- **2026-02-09** **Multi-Staged Framework for Safety Analysis of Offloaded Services in Distributed Intelligent Transportation Systems** [2602.08821](http://arxiv.org/abs/2602.08821)
  > 面向服务的架构 (SOA) 与分布式智能交通系统 (ITS) 功能卸载的集成为联网自动驾驶车辆 (CAV) 提供了扩展其本地可用服务的机会。将 CAV 处理链中的功能子集卸载到远程设备的一个主要目标是降低 CAV 的整体计算复杂性。然而，使用远程服务的扩展需要仔细的安全分析，因为远程创建的数据更容易被破坏，例如，通过远程设备上的攻击者或通过拦截无线传输。为了解决这个问题，我们首先分析分布式环境的 SOA 概念。由此，我们推导出一个安全框架，用于验证远程服务和本地接收的数据的可靠性。由于自动驾驶任务可以卸载多个不同的服务，因此我们提出了一个具体的多阶段框架，用于依赖于本地和远程服务的服务组合进行安全分析。出于效率原因，我们直接将多阶段安全分析框架包含在我们在早期工作中提出的面向服务的功能卸载框架（SOFOF）中。该评估比较了扩展框架的性能，考虑到计算复杂性，节能是功能卸载的主要动机，以及从损坏的远程服务中检测数据的能力。

- **2026-02-09** **A Generic Service-Oriented Function Offloading Framework for Connected Automated Vehicles** [2602.08799](http://arxiv.org/abs/2602.08799)
  > 功能卸载是一种很有前途的解决方案，可以通过以分布式服务的形式在本地和远程计算设备之间分配计算任务来解决联网自动驾驶车辆（CAV）或其他自主机器人的计算能力和可用能量的限制。本文提出了一种通用功能卸载框架，可用于卸载任意一组计算任务，重点关注自动驾驶。为了提供灵活性，功能卸载框架被设计为合并不同的卸载决策算法和服务质量（QoS）要求，可以根据不同的场景或 CAV 的目标进行调整。着眼于适用性，我们提出了一种有效的基于位置的方法，其中任务是在本地还是远程处理的决定取决于 CAV 的位置。我们将所提出的框架应用于面向服务的轨迹规划用例，其中我们将 CAV 的轨迹规划任务卸载到多访问边缘计算（MEC）服务器。评估是在模拟和实际应用中进行的。它展示了功能卸载框架在保证轨迹规划的 QoS 的同时提高 CAV 的计算效率的潜力。此外，模拟结果还显示了该框架对涉及多个 CAV 同时卸载请求的不同场景的适应性。


<p align=right>(<a href=#updated-on-20260215>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

