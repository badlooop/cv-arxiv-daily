[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.08.30
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-08-29**|**3D-MuPPET: 3D Multi-Pigeon Pose Estimation and Tracking**|动物姿势跟踪的无标记方法最近得到了发展，但在3D中跟踪大型动物群体的框架和基准仍然缺乏。为了克服文献中的这一空白，我们提出了3D MuPPET，这是一个使用多个视图以交互式速度估计和跟踪多达10只鸽子的3D姿势的框架。我们训练姿势估计器来推断多只鸽子的2D关键点和边界框，然后将关键点三角化为3D。对于对应匹配，我们首先将2D检测与第一帧中的全局身份动态匹配，然后使用2D跟踪器来维护后续帧中跨视图的对应关系。对于均方根误差（RMSE）和正确关键点百分比（PCK），我们实现了与现有技术的3D姿态估计器相当的精度。我们还展示了一个新颖的用例，其中我们的模型用单个鸽子的数据训练，在包含多只鸽子的数据上提供了可比较的结果。这可以简化向新物种的领域转移，因为注释单个动物数据比注释多动物数据劳动密集度低。此外，我们对3D MuPPET的推理速度进行了基准测试，在2D中高达10fps，在3D中高达1.5fps，并进行了定量跟踪评估，这产生了令人鼓舞的结果。最后，我们展示了3D MuPPET在自然环境中也能工作，而无需对附加注释进行模型微调。据我们所知，我们是第一个提出适用于室内和室外环境的2D/3D姿势和轨迹跟踪框架的公司。 et.al.|[2308.15316](http://arxiv.org/abs/2308.15316)|null|
|**2023-08-29**|**Pose-Free Neural Radiance Fields via Implicit Pose Regularization**|无姿态神经辐射场（NeRF）旨在用未经处理的多视图图像训练NeRF，近年来取得了令人印象深刻的成功。大多数现有工作共享一个管道，首先用渲染图像训练粗略的姿态估计器，然后联合优化估计的姿态和神经辐射场。然而，由于姿态估计器仅用渲染图像进行训练，由于真实图像和渲染图像之间的域间隙，姿态估计通常对真实图像有偏差或不准确，导致真实图像的姿态估计鲁棒性差，并且在联合优化中存在进一步的局部最小值。我们设计了IR NeRF，这是一种创新的无姿态NeRF，它引入了隐式姿态正则化来改进未聚焦真实图像的姿态估计器，并提高了真实图像姿态估计的鲁棒性。通过特定场景的2D图像的集合，IR NeRF构建了一个场景码本，该场景码本存储场景特征，并隐式地捕捉特定场景的姿势分布作为先验。因此，根据只有当2D真实图像的估计姿势位于姿势分布内时才可以从场景码本很好地重建2D真实图像这一原理，可以利用场景先验来提高姿势估计的鲁棒性。大量实验表明，IR NeRF实现了卓越的新视图合成，并在多个合成和真实数据集上始终优于最先进的视图合成。 et.al.|[2308.15049](http://arxiv.org/abs/2308.15049)|null|
|**2023-08-28**|**CLNeRF: Continual Learning Meets NeRF**|新颖的视图合成旨在呈现给定一组校准图像的看不见的视图。在实际应用中，场景的覆盖范围、外观或几何结构可能会随着时间的推移而变化，不断捕捉新的图像。有效地整合这种持续的变化是一个公开的挑战。标准NeRF基准测试仅涉及场景覆盖范围的扩展。为了研究其他实际的场景变化，我们提出了一个新的数据集，即跨时间世界（WAT），由外观和几何结构随时间变化的场景组成。我们还提出了一种简单而有效的方法CLNeRF，它将连续学习（CL）引入到神经辐射场（NeRF）中。CLNeRF结合了生成回放和即时神经图形原件（NGP）架构，以有效防止灾难性遗忘，并在新数据到达时有效更新模型。我们还向NGP添加了可训练的外观和几何嵌入，允许单个紧凑模型处理复杂的场景变化。在不需要存储历史图像的情况下，在变化场景的多次扫描上顺序训练的CLNeRF与在一次所有扫描上训练的上界模型性能相当。与其他CL基线相比，CLNeRF在标准基准和WAT上的表现要好得多。源代码和WAT数据集可在https://github.com/IntelLabs/CLNeRF.视频演示可在以下网址获得：https://youtu.be/nLRt6OoDGq0?si=8yD6k-8MMBJInQP et.al.|[2308.14816](http://arxiv.org/abs/2308.14816)|**[link](https://github.com/intellabs/clnerf)**|
|**2023-08-28**|**Flexible Techniques for Differentiable Rendering with 3D Gaussians**|快速、可靠的形状重建是许多计算机视觉应用中的重要组成部分。Neural Radiance Fields证明，真实感的新视图合成是触手可及的，但受到真实场景和对象快速重建性能要求的限制。最近的一些方法建立在替代形状表示的基础上，特别是3D高斯。我们开发了这些渲染器的扩展，例如集成可微分光流、导出防水网格和渲染每光线法线。此外，我们还展示了最近的两种方法是如何相互操作的。这些重建快速、稳健，并且可以在GPU或CPU上轻松执行。有关代码和可视化示例，请参见https://leonidk.github.io/fmb-plus et.al.|[2308.14737](http://arxiv.org/abs/2308.14737)|null|
|**2023-08-27**|**Depth self-supervision for single image novel view synthesis**|在本文中，我们解决了在给定单个帧作为输入的情况下从任意视点生成新图像的问题。虽然在这种设置中操作的现有方法旨在预测目标视图深度图以指导合成，但在没有明确监督此类任务的情况下，我们共同优化了新视图合成和深度估计的框架，以最大限度地释放两者之间的协同作用。具体地，以自监督的方式训练共享深度解码器，以预测在源视图和目标视图中一致的深度图。我们的结果证明了我们的方法在解决这两项任务的挑战方面的有效性，这两项工作允许生成更高质量的图像，并为目标视点提供更准确的深度。 et.al.|[2308.14108](http://arxiv.org/abs/2308.14108)|**[link](https://github.com/johnminelli/twowaysynth)**|
|**2023-08-27**|**Sparse3D: Distilling Multiview-Consistent Diffusion for Object Reconstruction from Sparse Views**|从极其稀疏的视图重建3D对象是一个长期存在且具有挑战性的问题。虽然最近的技术使用图像扩散模型来在新视点生成看似合理的图像，或者使用分数蒸馏采样（SDS）将预先训练的扩散先验提取到3D表示中，但这些方法通常难以同时实现新视点合成（NVS）和几何体的高质量、一致和详细的结果。在这项工作中，我们提出了Sparse3D，这是一种为稀疏视图输入量身定制的新型3D重建方法。我们的方法从多视点一致扩散模型中提取鲁棒先验，以细化神经辐射场。具体来说，我们使用了一个控制器，该控制器利用输入视图中的核线特征，引导预先训练的扩散模型，如稳定扩散，以生成与输入保持3D一致性的新视图图像。通过利用强大的图像扩散模型中的2D先验，我们的集成模型即使在面对开放世界对象时也能始终如一地提供高质量的结果。为了解决传统SDS引入的模糊性，我们引入了类别分数蒸馏采样（C-SDS）来增强细节。我们在CO3DV2上进行了实验，这是一个真实世界对象的多视图数据集。定量和定性评估都表明，我们的方法在NVS和几何重建方面优于以往最先进的工作。 et.al.|[2308.14078](http://arxiv.org/abs/2308.14078)|null|
|**2023-08-25**|**ReST: A Reconfigurable Spatial-Temporal Graph Model for Multi-Camera Multi-Object Tracking**|多摄像机多目标跟踪（MC-MOT）利用来自多个视图的信息来更好地处理遮挡和拥挤场景的问题。最近，使用基于图的方法来解决跟踪问题变得非常流行。然而，当前许多基于图的方法不能有效地利用关于空间和时间一致性的信息。相反，它们依赖于单摄像头跟踪器作为输入，这很容易出现碎片和ID切换错误。在本文中，我们提出了一种新的可重构图模型，该模型首先在空间上关联摄像机上所有检测到的对象，然后将其重新配置为用于时间关联的时间图。这种两阶段关联方法使我们能够提取强大的空间和时间感知特征，并解决碎片化轨迹的问题。此外，我们的模型是为在线跟踪而设计的，适用于现实世界中的应用。实验结果表明，所提出的图模型能够提取更多的判别特征用于对象跟踪，并且我们的模型在几个公共数据集上达到了最先进的性能。 et.al.|[2308.13229](http://arxiv.org/abs/2308.13229)|**[link](https://github.com/chengche6230/rest)**|
|**2023-08-24**|**NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes**|最近的隐式神经表示在新的视图合成中显示出了很好的结果。然而，现有的方法需要从许多视图进行昂贵的每场景优化，因此限制了它们在真实世界的无边界城市环境中的应用，在这些环境中，从极少数视图观察到感兴趣的对象或背景。为了缓解这一挑战，我们引入了一种名为NeO360的新方法，用于户外场景稀疏视图合成的神经场。NeO 360是一种可推广的方法，它从单个或几个摆出姿势的RGB图像重建360｛\deg｝场景。我们方法的本质是捕捉复杂的真实世界户外3D场景的分布，并使用可以从任何世界点查询的混合图像条件三平面表示。我们的表示结合了基于体素和鸟瞰图（BEV）的最佳表示，比每种表示都更有效、更具表现力。NeO 360的表示使我们能够从大量无界3D场景中学习，同时在推理过程中从一张图像中提供对新视图和新场景的可推广性。我们在所提出的具有挑战性的360｛\deg｝无界数据集NeRDS 360上演示了我们的方法，并表明NeO 360在新视图合成方面优于最先进的可推广方法，同时还提供编辑和合成功能。项目页面：https://zubair-irshad.github.io/projects/neo360.html et.al.|[2308.12967](http://arxiv.org/abs/2308.12967)|**[link](https://github.com/zubair-irshad/NeO-360)**|
|**2023-08-24**|**Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis**|静息状态功能性MRI（rs-fMRI）越来越多地用于多部位研究，以帮助神经系统疾病分析。现有研究通常存在由站点效应（如扫描仪/协议的差异）引起的显著跨站点/领域数据异质性。已经提出了许多方法来减少源域和目标域之间的fMRI异质性，这在很大程度上依赖于源数据的可用性。但是，由于多站点研究中的隐私问题和/或数据存储负担，获取源数据具有挑战性。为此，我们设计了一个用于fMRI分析的无源协作域自适应（SCDA）框架，其中只有预训练的源模型和未标记的目标数据是可访问的。具体而言，开发了一种用于目标fMRI分析的多视角特征富集方法（MFE），该方法由多个协作分支组成，用于从多个视图动态捕获未标记目标数据的fMRI特征。每个分支都有一个数据馈送模块、一个时空特征编码器和一个类预测器。设计了相互一致性约束，以鼓励从这些分支生成的相同输入的潜在特征的成对一致性，用于鲁棒表示学习。为了在没有源数据的情况下促进有效的跨领域知识转移，我们使用预训练的源模型的参数初始化MFE。我们还介绍了一种无监督预训练策略，使用来自三个大型辅助数据库的3806个未标记的fMRI，旨在获得通用特征编码器。在三个公共数据集和一个私人数据集上的实验结果证明了我们的方法在交叉扫描和交叉研究预测任务中的有效性。在大规模rs fMRI数据上预训练的模型已经向公众发布。 et.al.|[2308.12495](http://arxiv.org/abs/2308.12495)|**[link](https://github.com/yqfang9199/scda)**|
|**2023-08-23**|**ARF-Plus: Controlling Perceptual Factors in Artistic Radiance Fields for 3D Scene Stylization**|辐射场风格转移是一个新兴的领域，由于神经辐射场在三维重建和视图合成中的出色表现，作为三维场景风格化的一种手段，它最近受到了欢迎。我们强调了在辐射场风格转移方面的研究空白，即缺乏足够的感知可控性，这是由2D图像风格转移中的现有概念所驱动的。在本文中，我们提出了ARF Plus，一个对感知因素提供可管理控制的3D神经风格转移框架，以系统地探索3D场景风格化中的感知可控性。提出了四种不同类型的控制——颜色保持控制、（风格模式）比例控制、空间（选择性风格化区域）控制和深度增强控制——并将其集成到该框架中。来自真实世界数据集的定量和定性结果表明，在对3D场景进行风格化时，我们的ARF Plus框架中的四种类型的控件成功地实现了相应的感知控件。这些技术适用于单个样式输入以及场景中多个样式的同时应用。这开启了一个无限可能性的领域，允许对风格化效果进行定制修改，并灵活融合不同风格的优势，最终能够在3D场景中创造新颖而引人注目的风格效果。 et.al.|[2308.12452](http://arxiv.org/abs/2308.12452)|null|
|**2023-08-24**|**A Visualization System for Hexahedral Mesh Quality Study**|在本文中，我们介绍了一种新的三维十六进制网格视觉分析系统，该系统通过聚合字形强调质量较差的区域，突出重叠元素，并以三种形式提供详细的边界误差检查。通过支持多视图的多级分析，我们的系统有效地评估了各种网格模型，并比较了六面体网格的网格生成和优化算法的性能。 et.al.|[2308.12158](http://arxiv.org/abs/2308.12158)|null|
|**2023-08-22**|**Enhancing NeRF akin to Enhancing LLMs: Generalizable NeRF Transformer with Mixture-of-View-Experts**|跨场景可推广的NeRF模型可以直接合成看不见场景的新视图，已成为NeRF领域的一个新焦点。现有的几种尝试依赖于越来越端到端的“神经化”架构，即用变压器等高性能神经网络取代场景表示和/或渲染模块，并将新颖的视图合成转化为前馈推理管道。虽然这些前馈“神经化”架构仍然不能很好地开箱即用地适应不同的场景，但我们建议将它们与来自大型语言模型（LLM）的强大的专家混合（MoE）思想联系起来，该思想通过在更大的整体模型容量和灵活的每实例专业化之间进行平衡，展示了卓越的泛化能力。从最近一种名为GNT的可推广NeRF架构开始，我们首先证明了MoE可以巧妙地插入以增强模型。我们进一步定制了共享的永久专家和几何体感知的一致性损失，以分别增强跨场景一致性和空间平滑性，这对于可推广的视图合成至关重要。我们提出的模型被称为GNT with Mixture-of-View-Experts（GNT-MOVE），在转移到看不见的场景时，实验显示了最先进的结果，表明在零样本和少拍摄设置中都有更好的跨场景泛化。我们的代码可在https://github.com/VITA-Group/GNT-MOVE. et.al.|[2308.11793](http://arxiv.org/abs/2308.11793)|**[link](https://github.com/vita-group/gnt-move)**|
|**2023-08-22**|**IT3D: Improved Text-to-3D Generation with Explicit View Synthesis**|从强大的大型文本到图像扩散模型（LDM）中提取知识，推动了文本到3D技术的最新进展。尽管如此，现有的文本到3D方法经常会遇到诸如过度饱和、细节不足和不切实际的输出等挑战。这项研究提出了一种新的策略，利用显式合成的多视图图像来解决这些问题。我们的方法涉及利用LDM授权的图像到图像管道，以基于粗略3D模型的渲染生成高质量的图像。尽管生成的图像在很大程度上缓解了上述问题，但由于大扩散模型固有的生成性质，诸如视图不一致和显著的内容差异等挑战仍然存在，这给有效利用这些图像带来了巨大的困难。为了克服这一障碍，我们主张将鉴别器与新的扩散GAN双重训练策略相结合，以指导3D模型的训练。对于合并的鉴别器，合成的多视图图像被视为真实数据，而优化的3D模型的渲染则充当假数据。我们进行了一系列全面的实验，证明了我们的方法相对于基线方法的有效性。 et.al.|[2308.11473](http://arxiv.org/abs/2308.11473)|**[link](https://github.com/buaacyw/it3d-text-to-3d)**|
|**2023-08-22**|**ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes**|我们展示了ScanNet++，这是一个大规模的数据集，将室内场景的高质量和商品级几何图形和颜色的捕捉结合在一起。每个场景都是用亚毫米分辨率的高端激光扫描仪拍摄的，还有来自单反相机的3300万像素图像和来自iPhone的RGB-D流。场景重建进一步用开放的语义词汇表进行注释，明确注释标签模糊场景以进行全面的语义理解。ScanNet++为新视图合成提供了一个新的现实世界基准，既有高质量的RGB捕获，也有重要的商品级图像，此外还有一个全面封装多样和模糊语义标记场景的3D语义场景理解新基准。目前，ScanNet++包含460个场景、28万张单反图像和370多万个iPhone RGBD帧。 et.al.|[2308.11417](http://arxiv.org/abs/2308.11417)|null|
|**2023-08-22**|**Enhancing Interpretable Object Abstraction via Clustering-based Slot Initialization**|使用槽的以对象为中心的表示显示了从合成场景中的低级感知特征向高效、灵活和可解释的抽象的发展。当前的方法随机化时隙的初始状态，然后进行迭代细化。正如我们在本文中所展示的，随机时隙初始化显著影响最终时隙预测的准确性。此外，当前的方法需要来自数据的先验知识的预定数量的时隙，这限制了在现实世界中的适用性。在我们的工作中，我们使用以感知输入特征为条件的聚类算法来初始化槽表示。这需要体系结构中的一个附加层来初始化给定已识别集群的插槽。我们设计了该层的置换不变和置换等变版本，以实现聚类后的可交换槽表示。此外，我们使用均值偏移聚类来自动识别给定场景的槽数。我们评估了我们在各种数据集的对象发现和新视图合成任务上的方法。结果表明，我们的方法始终优于先前的工作，尤其是在复杂场景下。 et.al.|[2308.11369](http://arxiv.org/abs/2308.11369)|null|
|**2023-08-22**|**Novel-view Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views**|在沉浸式通信中，手与物体的交互理解和几乎没有解决的新颖视角合成是非常需要的，而由于手的高度变形和手与物体之间的严重遮挡，这是具有挑战性的。在本文中，我们提出了一种用于稀疏视图中手-物体交互的神经渲染和姿态估计系统，该系统还可以实现3D手-物体的交互编辑。我们分享了最近场景理解工作的灵感，该工作表明，预先建立的特定场景模型可以显著改善和解锁视觉任务，尤其是在输入稀疏的情况下，并将其扩展到动态手-物交互场景中，并提出分两个阶段解决问题。我们首先在离线阶段使用神经表示分别学习手和物体的形状和外观先验知识。在在线阶段，我们设计了一个基于渲染的联合模型拟合框架，以了解手与对象的动态交互与预先构建的手与对象模型以及交互先验，从而克服了手与对象之间的渗透和分离问题，并实现了新的视图合成。为了在一个序列中的手-物体交互过程中获得稳定的接触，我们提出了一个稳定的接触损失，以使接触区域一致。实验表明，我们的方法优于最先进的方法。项目网页中提供了代码和数据集https://iscas3dv.github.io/HO-NeRF. et.al.|[2308.11198](http://arxiv.org/abs/2308.11198)|null|
|**2023-08-22**|**Efficient View Synthesis with Neural Radiance Distribution Field**|最近对神经辐射场（NeRF）的研究表明，在高质量视图合成方面取得了重大进展。NeRF的一个主要限制是由于需要多个网络转发来渲染单个像素，因此其渲染效率较低。现有的改进NeRF的方法要么减少所需样本的数量，要么优化实现以加速网络转发。尽管做出了这些努力，但由于辐射场的固有表示，多次采样的问题仍然存在。相反，神经光场（NeLF）通过每像素仅查询一个单个网络转发来降低NeRF的计算成本。为了实现与NeRF接近的视觉质量，现有的NeLF方法需要更大的网络容量，这限制了它们在实践中的渲染效率。在这项工作中，我们提出了一种称为神经辐射分布场（NeRDF）的新表示，该表示以实时有效的视图合成为目标。具体来说，我们使用类似于NeRF的小型网络，同时通过像NeLF中那样的每像素单个网络转发来保持渲染速度。关键是用频率基对每条射线的辐射分布进行建模，并使用网络预测频率权重。然后通过对辐射分布进行体积渲染来计算像素值。实验表明，与现有方法相比，我们提出的方法在速度、质量和网络大小之间提供了更好的权衡：在类似网络大小的情况下，我们比NeRF实现了~254倍的加速，性能仅略有下降。我们的项目页面位于yushung-wu.github.io/NeRDF。 et.al.|[2308.11130](http://arxiv.org/abs/2308.11130)|null|
|**2023-08-23**|**Information Theory-Guided Heuristic Progressive Multi-View Coding**|多视图表示学习旨在从共享上下文的多个视图中获取综合信息。最近的工作以成对的方式将对比学习直观地应用于不同的视图，这仍然是可扩展的：在学习视图共享表示时，视图特定的噪声没有被过滤；假负对，其中负项实际上与正项在同一类中，而真负对被同等对待；均匀地测量术语之间的相似性可能会干扰优化。重要的是，很少有作品研究广义自监督多视角学习的理论框架，尤其是两种以上的视角。为此，我们从信息论的角度重新思考了现有的多视角学习范式，并提出了一个新的广义多视角学习的信息理论框架。在此基础上，我们构建了一种具有三层渐进结构的多视图编码方法，即信息论引导的分层渐进多视图编码（IPMC）。在分布层中，IPMC将视图之间的分布对齐，以减少视图特定的噪声。在设置层中，IPMC构建自调整对比池，并通过视图过滤器进行自适应修改。最后，在实例层，我们采用设计的统一损失来学习表示，并减少梯度干扰。从理论和经验上，我们证明了IPMC优于最先进的方法。 et.al.|[2308.10522](http://arxiv.org/abs/2308.10522)|null|
|**2023-08-19**|**ControlCom: Controllable Image Composition using Diffusion Model**|图像合成的目标是从一对前景图像和背景图像合成逼真的合成图像。最近，考虑到生成合成方法在图像生成中的巨大潜力，在大型预训练扩散模型的基础上建立了生成合成方法来生成合成图像。然而，它们在前景属性上缺乏可控制性，前景身份保存较差。为了应对这些挑战，我们提出了一种可控的图像合成方法，该方法将四个任务统一在一个扩散模型中：图像混合、图像协调、视图合成和生成合成。同时，我们设计了一个自我监督的训练框架，并结合了一个量身定制的训练数据准备管道。此外，我们提出了一个局部增强模块来增强扩散模型中的前景细节，提高了合成图像的前景保真度。在公共基准和真实世界的数据上对所提出的方法进行了评估，这表明我们的方法可以生成比现有方法更忠实和可控的合成图像。代码和型号将在https://github.com/bcmi/ControlCom-Image-Composition. et.al.|[2308.10040](http://arxiv.org/abs/2308.10040)|**[link](https://github.com/bcmi/controlcom-image-composition)**|
|**2023-08-18**|**Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis**|我们提出了一种同时处理动态场景新视图合成和所有密集场景元素的六自由度（6-DOF）跟踪任务的方法。我们遵循合成分析框架，灵感来自最近的工作，该工作将场景建模为3D高斯集合，这些高斯集合经过优化，可以通过可微分渲染重建输入图像。为了对动态场景建模，我们允许高斯随时间移动和旋转，同时强制它们具有持久的颜色、不透明度和大小。通过用局部刚度约束正则化高斯的运动和旋转，我们表明我们的动态3D高斯在一段时间内正确地对物理空间的同一区域建模，包括该空间的旋转。密集的6自由度跟踪和动态重建从持久的动态视图合成中自然出现，而不需要任何对应关系或流作为输入。我们展示了我们的表示所支持的大量下游应用程序，包括第一人称视图合成、动态合成场景合成和4D视频编辑。 et.al.|[2308.09713](http://arxiv.org/abs/2308.09713)|null|

<p align=right>(<a href=#updated-on-20230830>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-08-28**|**R3D3: Dense 3D Reconstruction of Dynamic Scenes from Multiple Cameras**|密集的三维重建和自我运动估计是自动驾驶和机器人技术的关键挑战。与当今部署的复杂、多模态系统相比，多摄像头系统提供了一种更简单、低成本的替代方案。然而，基于相机的复杂动态场景的3D重建已被证明是极其困难的，因为现有的解决方案往往会产生不完整或不连贯的结果。我们提出了R3D3，一种用于密集3D重建和自我运动估计的多摄像机系统。我们的方法在利用来自多个相机的时空信息的几何估计和单目深度细化之间迭代。我们集成了多相机特征相关性和密集束调整算子，以产生稳健的几何深度和姿态估计。为了改进几何深度不可靠的重建，例如对于移动对象或低纹理区域，我们通过深度细化网络引入了可学习的场景先验。我们展示了这种设计能够对具有挑战性的动态户外环境进行密集、一致的3D重建。因此，我们在DDAD和NuScenes基准上实现了最先进的密集深度预测。 et.al.|[2308.14713](http://arxiv.org/abs/2308.14713)|null|
|**2023-08-27**|**Sparse3D: Distilling Multiview-Consistent Diffusion for Object Reconstruction from Sparse Views**|从极其稀疏的视图重建3D对象是一个长期存在且具有挑战性的问题。虽然最近的技术使用图像扩散模型来在新视点生成看似合理的图像，或者使用分数蒸馏采样（SDS）将预先训练的扩散先验提取到3D表示中，但这些方法通常难以同时实现新视点合成（NVS）和几何体的高质量、一致和详细的结果。在这项工作中，我们提出了Sparse3D，这是一种为稀疏视图输入量身定制的新型3D重建方法。我们的方法从多视点一致扩散模型中提取鲁棒先验，以细化神经辐射场。具体来说，我们使用了一个控制器，该控制器利用输入视图中的核线特征，引导预先训练的扩散模型，如稳定扩散，以生成与输入保持3D一致性的新视图图像。通过利用强大的图像扩散模型中的2D先验，我们的集成模型即使在面对开放世界对象时也能始终如一地提供高质量的结果。为了解决传统SDS引入的模糊性，我们引入了类别分数蒸馏采样（C-SDS）来增强细节。我们在CO3DV2上进行了实验，这是一个真实世界对象的多视图数据集。定量和定性评估都表明，我们的方法在NVS和几何重建方面优于以往最先进的工作。 et.al.|[2308.14078](http://arxiv.org/abs/2308.14078)|null|
|**2023-08-27**|**Multi-plane denoising diffusion-based dimensionality expansion for 2D-to-3D reconstruction of microstructures with harmonized sampling**|获得可靠的微观结构数据集是借助集成计算材料工程（ICME）方法进行材料系统设计的关键一步。然而，由于高实验成本或技术限制，获得三维（3D）微观结构数据集通常具有挑战性，而获得二维（2D）显微照片相对更容易。为了解决这个问题，本研究提出了一种使用基于扩散的生成模型（DGM）进行微观结构二维到三维重建的新框架，称为Micro3Diff。具体而言，这种方法仅需要预先训练的DGM来生成2D样本，并且维度扩展（2D到3D）仅在生成过程（即反向扩散过程）中发生。所提出的框架结合了一个称为多平面去噪扩散的新概念，该概念将来自不同平面的噪声样本（即潜在变量）转换为数据结构，同时保持3D空间中的空间连通性。此外，还开发了一个协调的采样过程，以解决在维度扩展过程中DGM的反向马尔可夫链的可能偏差。结合起来，我们证明了Micro3Diff在重建具有连接切片的3D样本方面的可行性，这些切片在形态学上与原始2D图像保持等效。为了验证Micro3Diff的性能，重建了各种类型的微观结构（合成和实验观察），并对生成的样品的质量进行了定性和定量评估。成功的重建结果激发了Micro3Diff在即将到来的ICME应用中的潜在应用，同时在理解和操纵DGM的潜在空间方面取得了突破。 et.al.|[2308.14035](http://arxiv.org/abs/2308.14035)|null|
|**2023-08-26**|**HoloPOCUS: Portable Mixed-Reality 3D Ultrasound Tracking, Reconstruction and Overlay**|超声（US）成像为手术指导和诊断成像提供了一种安全、易用的解决方案。传统2D US用于介入引导的有效使用需要丰富的经验来将图像平面投影到患者身上，并且诊断中的图像解释存在高的用户内和用户间可变性。3D US重建允许更一致的诊断和解释，但现有的解决方案在设备和实时导航的适用性方面受到限制。为了解决这些问题，我们提出了HoloPOCUS——一种混合现实的US系统（MR-US），它在护理点环境中将丰富的US信息覆盖在用户的视觉上。HoloPOCUS扩展了现有的MR-US方法，不仅将US平面放置在用户的视野中，还包括3D重建和投影，可以帮助使用传统探针进行程序指导。我们验证了一个跟踪管道，该管道与现有的MR-US工作相比具有更高的准确性。此外，通过幻影任务进行的用户研究表明，当使用我们提出的方法时，导航持续时间显著改善。 et.al.|[2308.13823](http://arxiv.org/abs/2308.13823)|null|
|**2023-08-25**|**Textureless Deformable Surface Reconstruction with Invisible Markers**|重建和跟踪很少或没有纹理的可变形表面一直是一个挑战。从根本上说，这些挑战源于无纹理表面缺乏建立跨图像对应的特征。在这项工作中，我们提出了一种新型的标记，以主动丰富物体的表面特征，从而简化三维表面重建和对应跟踪。我们的标记是由荧光染料制成的，只有在紫外线下才能看到，在正常的照明条件下是看不见的。利用这些标记，我们设计了一个多摄像头系统，以时间复用的方式捕捉紫外线和可见光下的表面变形。在紫外线下，物体上的标记会出现，以丰富其表面纹理，从而实现高质量的3D形状重建和跟踪。在可见光下，标记变得不可见，使我们能够捕捉到物体原始的未受影响的外观。我们在各种具有挑战性的场景中进行实验，包括手势、面部表情、挥舞布料和手物交互。在所有这些情况下，我们证明了我们的系统能够产生稳健、高质量的3D重建和跟踪。 et.al.|[2308.13678](http://arxiv.org/abs/2308.13678)|null|
|**2023-08-23**|**ARF-Plus: Controlling Perceptual Factors in Artistic Radiance Fields for 3D Scene Stylization**|辐射场风格转移是一个新兴的领域，由于神经辐射场在三维重建和视图合成中的出色表现，作为三维场景风格化的一种手段，它最近受到了欢迎。我们强调了在辐射场风格转移方面的研究空白，即缺乏足够的感知可控性，这是由2D图像风格转移中的现有概念所驱动的。在本文中，我们提出了ARF Plus，一个对感知因素提供可管理控制的3D神经风格转移框架，以系统地探索3D场景风格化中的感知可控性。提出了四种不同类型的控制——颜色保持控制、（风格模式）比例控制、空间（选择性风格化区域）控制和深度增强控制——并将其集成到该框架中。来自真实世界数据集的定量和定性结果表明，在对3D场景进行风格化时，我们的ARF Plus框架中的四种类型的控件成功地实现了相应的感知控件。这些技术适用于单个样式输入以及场景中多个样式的同时应用。这开启了一个无限可能性的领域，允许对风格化效果进行定制修改，并灵活融合不同风格的优势，最终能够在3D场景中创造新颖而引人注目的风格效果。 et.al.|[2308.12452](http://arxiv.org/abs/2308.12452)|null|
|**2023-08-21**|**Coordinate Quantized Neural Implicit Representations for Multi-view Reconstruction**|近年来，在从多视图图像中学习用于三维重建的神经隐式表示方面取得了巨大进展。作为补充坐标的额外输入，使用正弦函数作为位置编码在利用基于坐标的神经网络揭示高频细节方面发挥着关键作用。然而，高频位置编码使优化不稳定，这导致了有噪声的重建和空空间中的伪影。为了在一般意义上解决这个问题，我们引入了学习具有量化坐标的神经隐式表示，这减少了优化过程中该领域的不确定性和模糊性。代替连续坐标，我们使用量化坐标之间的最近插值将连续坐标离散为离散坐标，这些量化坐标是通过以极高分辨率离散场而获得的。我们使用离散坐标及其位置编码来通过体积渲染学习隐式函数。这显著减少了采样空间中的变化，并对来自不同视图的光线的交点触发了更多的多视图一致性约束，从而能够以更有效的方式推断隐式函数。我们的量化坐标不会带来任何计算负担，并且可以无缝地使用最新的方法。我们根据广泛使用的基准进行的评估表明，我们优于最先进的基准。我们的代码可在https://github.com/MachinePerceptionLab/CQ-NIR. et.al.|[2308.11025](http://arxiv.org/abs/2308.11025)|**[link](https://github.com/machineperceptionlab/cq-nir)**|
|**2023-08-19**|**Root Pose Decomposition Towards Generic Non-rigid 3D Reconstruction with Monocular Videos**|这项工作专注于基于单目RGB视频序列的非刚性物体的3D重建。具体来说，我们的目标是为通用对象类别和随意捕捉的场景构建高保真度模型。为此，我们不假设对象的已知根姿势，也不使用特定类别的模板或密集姿势先验。我们的根姿势分解（RPD）方法的关键思想是保持每帧根姿势变换，同时通过局部变换建立密集场来校正根姿势。局部变换的优化是通过对规范空间的点配准来执行的。我们还将RPD应用于具有对象遮挡和个体差异的多对象场景。因此，RPD允许对包含具有大变形、复杂运动模式、遮挡和不同个体的尺度多样性的对象的复杂场景进行非刚性3D重建。这样的管道可能会扩展到野外的各种物体。我们的实验表明，RPD在具有挑战性的DAVIS、OVIS和AMA数据集上超越了最先进的方法。 et.al.|[2308.10089](http://arxiv.org/abs/2308.10089)|null|
|**2023-08-19**|**TSAR-MVS: Textureless-aware Segmentation and Correlative Refinement Guided Multi-View Stereo**|由于图像之间缺乏可靠的像素对应关系，无纹理区域的重建长期以来一直是MVS中具有挑战性的问题。在本文中，我们提出了无纹理感知分割和相关细化引导的多视图立体（TSAR-MVS），这是一种通过滤波、细化和分割有效解决三维重建中无纹理区域带来的挑战的新方法。首先，我们实现了联合假设滤波，这是一种将置信度估计器与视差不连续检测器相结合的技术，以消除不正确的深度估计。其次，为了以置信深度扩展像素，我们引入了一种迭代相关细化策略，该策略利用RANSAC生成超像素，然后是中值滤波器，以扩大准确确定的像素的影响。最后，我们提出了一种无纹理感知分割方法，该方法利用边缘检测和线检测来准确识别要使用3D平面拟合的大的无纹理区域。在大量数据集上的实验表明，我们的方法显著优于大多数非学习方法，并且在保留精细细节的同时，对无纹理区域表现出鲁棒性。 et.al.|[2308.09990](http://arxiv.org/abs/2308.09990)|null|
|**2023-08-19**|**A Theory of Topological Derivatives for Inverse Rendering of Geometry**|我们介绍了一个可微曲面演化的理论框架，该框架允许通过使用拓扑导数对图像泛函进行变分优化来实现离散拓扑变化。虽然先前的几何体反向渲染方法依赖于拓扑变化的轮廓梯度，但这种信号是稀疏的。相反，我们的理论推导了拓扑导数，这些导数将消失空穴和相位的引入与图像强度的变化联系起来。因此，我们能够以空穴或相成核的形式实现可微分的形状扰动。我们通过优化2D中的闭合曲线和3D中的曲面来验证所提出的理论，以深入了解当前方法的局限性，并实现改进的应用，如图像矢量化、从文本提示生成矢量图形、形状模糊图的单图像重建和多视图3D重建。 et.al.|[2308.09865](http://arxiv.org/abs/2308.09865)|null|
|**2023-08-18**|**On the three-dimensional relation between the coronal dimming, erupting filament and CME. Case study of the 28 October 2021 X1.0 event**|我们研究了太阳轨道飞行器、STEREO-A、SDO和SOHO从多个角度观测到的2021年10月28日X1.0耀斑/CME事件中，变暗区域的时空演化与细丝喷发和CME传播的主导方向之间的关系。我们提出了一种通过跟踪其面积演变来估计主调光方向的方法，并通过计算每个像素的球体表面积来强调其精确估计。为了确定早期通量绳的传播方向，我们通过分级圆柱壳建模（GCS）和细丝的连接点对CME进行了三维重建。调光最初呈放射状扩展，后来向东南移动。喷发细丝在太阳表面上重建的高度演化的正交投影位于主要变暗增长的扇区中，而GCS重建的内部的正交投影与总变暗区域对齐。灯丝在约180 Mm的高度达到约250 km/s的最大速度。其运动方向从径向强烈倾斜（向东64 $^\circ$，向南32$^\icrc$）。CME和细丝腿之间在3D方向上的50$^\circ$ 差异与重建确定的CME半宽度密切对应，这表明重建的细丝与CME体的相关腿之间存在潜在关系。我们的发现强调，变暗增长的主导传播反映了太阳大气中喷发磁结构（细丝）的方向，尽管细丝的演化与全球CME膨胀的方向没有直接关系。整体变暗形态与CME重建的内部非常相似，验证了使用变暗观测来深入了解CME方向。 et.al.|[2308.09815](http://arxiv.org/abs/2308.09815)|null|
|**2023-08-18**|**A deep learning approach for the 3D reconstruction of dust density and temperature in star-forming regions**|目的：我们介绍了一种新的深度学习方法，用于从单个恒星形成云核心（<0.2pc）的多波长尘埃发射观测中重建三维尘埃密度和温度分布。方法：我们通过使用POLARIS辐射传输代码处理云工厂模拟的云芯来构建训练数据集，以产生12至1300 $\mu$m之间23个波长的合成尘埃发射观测值。我们通过沿着单个视线重建云结构来简化任务，并为此目的训练条件可逆神经网络（cNN）。cNN属于归一化流方法组，能够预测目标灰尘特性的完全后验分布。我们测试了不同的cNN设置，从包括所有23个波长的场景到仅在7个波长进行观测的更现实的有限情况。我们在综合测试数据上评估了这些模型的预测性能。结果：我们报道了23个波长的cNN模型的良好重建性能，在$\log（n_{dust}/m^{-3}）$中实现了约1.8%的中值绝对相对误差，在$\log（T_{dust}/K）$中获得了约1%的中值绝对绝对相对误差。我们确定了在密度范围的低端高估和在密度和温度的高端低估的趋势，这可能与训练数据中的偏差有关。将覆盖范围限制为仅七个波长的组合，我们仍然发现令人满意的性能，在$\log（n_{dust}/m^{-3}）$和$\lod（T_{dust}/K）$ 中的平均绝对相对误差约为3.3%和2.5%。结论：这项概念验证研究表明，在现实的观测约束下，基于cNN的灰尘密度和温度三维重建方法非常有前景，甚至是可行的。 et.al.|[2308.09657](http://arxiv.org/abs/2308.09657)|null|
|**2023-08-18**|**O^2-Recon: Completing 3D Reconstruction of Occluded Objects in the Scene with a Pre-trained 2D Diffusion Model**|遮挡是RGB-D视频三维重建中的一个常见问题，通常会阻碍对象的完整重建，并带来持续的问题。在本文中，我们提出了一种新的框架，通过基于2D扩散的绘画模型来重建物体隐藏部分的完整表面。具体来说，我们利用预先训练的扩散模型来填充2D图像的隐藏区域。然后，我们在绘制的图像中使用这些来优化用于3D重建的每个实例的神经隐式表面表示。由于制作这一过程所需的彩绘面具很棘手，我们采用了一种“人在环”的策略，只需要很少的人参与就可以制作出高质量的面具。此外，物体的某些部分可能被完全隐藏，因为视频通常是从有限的视角拍摄的。为了确保恢复这些不可见区域，我们开发了一种级联网络架构，用于预测有符号距离场，利用位置编码的不同频带并保持整体平滑。除了常用的渲染损失、Eikonal损失和轮廓损失外，我们还采用了基于CLIP的语义一致性损失来从看不见的相机角度引导曲面。在ScanNet场景上的实验表明，我们提出的框架在场景级RGB-D视频的对象级重建中实现了最先进的准确性和完整性。 et.al.|[2308.09591](http://arxiv.org/abs/2308.09591)|null|
|**2023-08-18**|**DMCVR: Morphology-Guided Diffusion Model for 3D Cardiac Volume Reconstruction**|通过电影磁共振成像（cMRI）进行精确的3D心脏重建对于改善心血管疾病诊断和了解心脏运动至关重要。然而，目前在临床环境中使用的基于心脏MRI的重建技术是2D的，通过平面的分辨率有限，导致重建的心脏体积质量低。为了从稀疏的2D图像堆栈中更好地重建3D心脏体积，我们提出了一种用于3D心脏体积重建的形态学引导扩散模型DMCVR，该模型综合了高分辨率2D图像和相应的3D重建体积。我们的方法优于以前的方法，因为它将心脏形态限制在生成模型上，消除了潜在代码耗时的迭代优化过程，并提高了生成质量。所学习的潜在空间为重建3D心脏形状提供了具有高度可解释价值的每个2D cMRI切片的全局语义、局部心脏形态和细节。我们的实验表明，DMCVR在二维生成和三维重建性能等方面都非常有效。有了DMCVR，我们可以制作高分辨率的3D心脏MRI重建，超越了目前的技术。我们提出的框架在提高心脏病诊断和治疗计划的准确性方面具有巨大潜力。代码可访问https://github.com/hexiaoxiao-cs/DMCVR. et.al.|[2308.09223](http://arxiv.org/abs/2308.09223)|**[link](https://github.com/hexiaoxiao-cs/dmcvr)**|
|**2023-08-17**|**A Fusion of Variational Distribution Priors and Saliency Map Replay for Continual 3D Reconstruction**|单图像三维重建是一项研究挑战，重点是从单视图图像中预测三维物体形状。这项任务需要大量的数据采集来预测形状的可见部分和遮挡部分。此外，基于学习的方法面临着为所有可能的类创建综合训练数据集的困难。为此，我们提出了一种基于连续学习的3D重建方法，其中我们的目标是使用变分先验设计一个模型，即使在对新类进行训练后，该模型仍然可以合理地重建以前看到的类。变分先验表示抽象形状和战斗遗忘，而显著性映射则以较少的内存使用来保留对象属性。由于存储大量训练数据的资源限制，这一点至关重要。此外，我们引入了基于显著性地图的体验回放，以捕捉全局和不同的对象特征。与已建立的方法相比，全面的实验在定量和定性方面都显示出有竞争力的结果。 et.al.|[2308.08812](http://arxiv.org/abs/2308.08812)|null|
|**2023-08-17**|**Long-Range Grouping Transformer for Multi-View 3D Reconstruction**|如今，变压器网络在许多计算机视觉任务中表现出了优越的性能。在遵循这种范式的多视图3D重建算法中，当面对大量视图输入时，自注意处理必须处理复杂的图像标记，包括大量信息。信息内容的诅咒导致了模型学习的极端困难。为了缓解这个问题，最近的方法压缩了表示每个视图的令牌编号，或者放弃了来自不同视图的令牌之间的注意力操作。显然，它们会对性能产生负面影响。因此，我们提出了基于分治原则的长程分组注意力（LGA）。来自所有视图的令牌都被分组以进行单独的注意力操作。每组中的标记都是从所有视图中采样的，并且可以为驻留的视图提供宏表示。不同群体之间的多样性保证了特征学习的丰富性。可以建立一种有效且高效的编码器，该编码器使用LGA连接视图间特征，并使用标准自注意层提取视图内特征。此外，还设计了一种新颖的渐进上采样解码器，用于相对高分辨率的体素生成。在此基础上，我们构建了一个强大的基于变压器的网络，称为LRGT。在ShapeNet上的实验结果验证了我们的方法在多视图重建中达到了SOTA的精度。代码将在https://github.com/LiyingCV/Long-Range-Grouping-Transformer. et.al.|[2308.08724](http://arxiv.org/abs/2308.08724)|**[link](https://github.com/liyingcv/long-range-grouping-transformer)**|
|**2023-08-16**|**DeDoDe: Detect, Don't Describe -- Describe, Don't Detect for Local Feature Matching**|关键点检测是3D重建中的关键步骤，通过该步骤可以在场景的每个视图中检测到（最多）K个点的集合。至关重要的是，检测到的点需要在视图之间保持一致，即对应于场景中的同一3D点。关键点检测的主要挑战之一是学习目标的制定。以前基于学习的方法通常将描述符与关键点联合学习，并将关键点检测视为对相互最近邻居的二元分类任务。然而，基于描述符最近邻居的关键点检测是一项代理任务，不能保证产生3D一致的关键点。此外，这将关键点与特定描述符联系在一起，使下游使用变得复杂。在这项工作中，我们直接从3D一致性中学习关键点。为此，我们训练检测器来检测大规模SfM中的轨道。由于这些点通常过于稀疏，我们导出了一个半监督的双视图检测目标，以将该集扩展到所需的检测数量。为了训练描述符，我们使用单独的网络在关键点上最大化相互最近邻目标。结果表明，我们的方法DeDoDe在多个几何基准上实现了显著的增益。代码提供于https://github.com/Parskatt/DeDoDe。 et.al.|[2308.08479](http://arxiv.org/abs/2308.08479)|**[link](https://github.com/parskatt/dedode)**|
|**2023-08-17**|**Deep Learning Framework for Spleen Volume Estimation from 2D Cross-sectional Views**|异常脾脏肿大（脾肿大）被认为是一系列疾病的临床指标，包括肝脏疾病、癌症和血液疾病。虽然从超声图像中测量的脾脏长度是脾脏大小的常用替代品，但脾脏体积仍然是评估脾肿大和相关临床状况严重程度的金标准。计算机断层扫描是测量脾脏体积的主要成像方式，但在脾肿大发病率高的地区（如全球南部），它不太容易获得。我们的目标是通过二维横截面分割实现脾脏体积的自动测量，这可以从超声成像中获得。在这项研究中，我们描述了一种基于变分自动编码器的框架，用于从单视图或双视图2D脾脏分割中测量脾脏体积。我们在此框架内提出并评估了三种体积估计方法。我们还展示了如何产生体积估计的95%置信区间，使我们的方法在临床上更有用。我们的最佳模型在单视图和双视图分割中分别实现了86.62%和92.58%的平均相对体积准确率，超过了使用手动测量的线性回归临床标准方法和基于比较深度学习的2D-3D重建方法的性能。所提出的脾脏体积估计框架可以集成到目前使用2D超声图像来测量脾脏长度的标准临床工作流程中。据我们所知，这是第一项从2D脾脏分割中直接实现3D脾脏体积估计的工作。 et.al.|[2308.08038](http://arxiv.org/abs/2308.08038)|null|
|**2023-08-17**|**ObjectSDF++: Improved Object-Compositional Neural Implicit Surfaces**|近年来，神经隐式表面重建已成为多视图三维重建的一种流行范式。与传统的多视图立体方法不同，基于神经隐式表面的方法利用神经网络将3D场景表示为符号距离函数（SDF）。然而，它们往往忽略场景中单个对象的重建，这限制了它们的性能和实际应用。为了解决这个问题，以前的工作ObjectSDF引入了一个很好的对象组合神经隐式曲面框架，该框架利用2D实例掩码来监督单个对象的SDF。在本文中，我们提出了一个名为ObjectSDF++的新框架来克服ObjectSDF的局限性。首先，与ObjectSDF相比，ObjectSDF的性能主要受其转换的语义场的限制，我们模型的核心组件是一个感知遮挡的对象不透明度渲染公式，该公式直接对要使用实例掩码进行监督的对象不透明进行体绘制。其次，我们设计了一个新的正则化项来区分对象，它可以有效地缓解ObjectSDF由于缺乏防止碰撞的约束而可能在不可见区域中导致意外重建的问题。我们的大量实验表明，我们的新框架不仅产生了优越的对象重建结果，而且显著提高了场景重建的质量。可以在\url中找到代码和更多资源{https://qianyiwu.github.io/objectsdf++} et.al.|[2308.07868](http://arxiv.org/abs/2308.07868)|**[link](https://github.com/qianyiwu/objectsdf_plus)**|
|**2023-08-15**|**CCD-3DR: Consistent Conditioning in Diffusion for Single-Image 3D Reconstruction**|在本文中，我们提出了一种新的形状重建方法，该方法利用扩散模型为单个RGB图像中捕获的对象生成3D稀疏点云。最近的方法通常利用基于全局嵌入或局部投影的特征作为指导扩散模型的条件。然而，这种策略无法将去噪的点云与给定的图像一致地对齐，导致条件不稳定和性能较差。在本文中，我们提出了CCD-3DR，它利用了一种新的中心扩散概率模型来进行一致的局部特征调节。我们将扩散模型中的噪声和采样点云约束到一个子空间中，在该子空间中，点云中心在正向扩散过程和反向过程中保持不变。稳定的点云中心进一步充当锚，以将每个点与其对应的基于局部投影的特征对准。在合成基准ShapeNet-R2N2上进行的大量实验表明，CCD-3DR的性能大大优于所有竞争对手，提高了40%以上。我们还提供了真实世界数据集Pix3D的结果，以彻底展示CCD-3DR在真实世界应用中的潜力。代码将很快发布 et.al.|[2308.07837](http://arxiv.org/abs/2308.07837)|null|

<p align=right>(<a href=#updated-on-20230830>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-08-29**|**ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer**|语篇风格转换是在保留意义的同时转换语篇风格特征的任务。目标“风格”可以用多种方式定义，从单一属性（如形式）到作者（如莎士比亚）。以前的无监督风格转移方法通常只依赖于固定风格集的大量标记数据，或者需要大型语言模型。相反，我们引入了一种新的基于扩散的通用风格转移框架，该框架可以在推理时灵活地适应任意目标风格。我们的参数高效方法ParaGuide利用转述条件扩散模型以及来自现成分类器和强大的现有风格嵌入器的基于梯度的指导来转换文本风格，同时保留语义信息。我们在安然电子邮件语料库上验证了该方法，包括人工评估和自动评估，发现它在形式、情感甚至作者风格转移方面都优于强基线。 et.al.|[2308.15459](http://arxiv.org/abs/2308.15459)|null|
|**2023-08-29**|**Vortex core radius in baroclinic turbulence: Implications for scaling predictions**|基于经验观察，对于非常低的底部阻力系数，涡核半径偏离罗斯比变形半径，我们重新审视了斜压湍流热传输的涡旋气体标度理论。我们推导了涡核半径的比例预测。对于线性底部阻力，涡流芯半径的这种比例依赖性不影响涡流扩散率和混合长度的涡流气体预测，其与Gallet和Ferrari中的预测保持一致（Proc.Nat.Acad.Sci.USA，1172020）。相反，对于二次阻力，当二次阻力系数逐渐变低时，核心半径的比例依赖性为涡流扩散率和混合长度引入了新的比例定律。我们通过对具有非常低的二次阻力系数的双层模型的数值模拟来验证修改后的比例预测。 et.al.|[2308.15398](http://arxiv.org/abs/2308.15398)|null|
|**2023-08-29**|**Rayleigh-Bénard instability in a horizontal porous layer with anomalous diffusion**|重新考虑了流体饱和水平多孔层中质量扩散引起的Rayleigh-B’nard不稳定性的分析。基于分子位置随时间线性增长的方差的标准扩散理论被推广到异常扩散，其中方差被建模为时间的幂律函数。采用基于随时间变化的质量扩散系数的异常扩散模型，结合动量传递的达西定律，以及浮力流的Boussinesq近似。对一种基本状态进行了线性稳定性分析，其中溶质具有潜在的不稳定浓度分布，在垂直方向上线性变化，并且流体处于静止状态。结果表明，任何偏离标准扩散过程的微小偏离都会对不稳定的开始条件产生显著影响。这种情况显示出对异常扩散指数的强烈敏感性。研究表明，对于每一个正质量扩散瑞利数，次扩散都会产生不稳定性，而无论瑞利数有多大，超扩散都会带来稳定。最后讨论了基于亚扩散Galilei变分导数模型的线性稳定性分析。 et.al.|[2308.15359](http://arxiv.org/abs/2308.15359)|null|
|**2023-08-29**|**Elucidating the Exposure Bias in Diffusion Models**|扩散模型已经证明了令人印象深刻的生成能力，但其“暴露偏差”问题，即训练和采样之间的输入不匹配，缺乏深入的探索。在本文中，我们首先对采样分布进行分析建模，然后将每个采样步骤的预测误差归因于暴露偏差问题的根本原因，从而系统地研究了扩散模型中的暴露偏差问题。此外，我们讨论了这个问题的潜在解决方案，并提出了一个直观的衡量标准。在阐明暴露偏差的同时，我们提出了一种简单但有效的无训练方法，称为Epsilon标度，以减轻暴露偏差。我们表明，通过缩小网络输出（Epsilon），Epsilon Scaling显式地将采样轨迹移动到更接近训练阶段学习的向量场，从而减轻训练和采样之间的输入失配。在各种扩散框架（ADM、DDPM/DDM、LDM）、无条件和条件设置以及确定性与随机抽样上的实验验证了我们方法的有效性。 et.al.|[2308.15321](http://arxiv.org/abs/2308.15321)|null|
|**2023-08-29**|**Turing instabilities are not enough to ensure pattern formation**|对称性破坏不稳定性在理解自然界中观察到的模式多样性背后的机制方面发挥着重要作用，例如在图灵的反应-扩散理论中，该理论将细胞信号传导和运输与生长和形态的发展联系起来。广泛的文献集中于这些系统中均匀平衡的线性稳定性分析，最终导致运输驱动的不稳定性的一组条件，这些条件通常被认为是启动自组织的。我们证明了选择一个简单的、规范的、只有温和的多稳态非线性的传输模型可以满足图灵不稳定性条件，同时也可以鲁棒地只表现出瞬态模式。因此，图灵样的不稳定性不足以存在模式态。鉴于生物系统（包括基因调控网络和空间分布的生态系统）通常表现出高度的多稳定性和非线性，这就提出了如何分析自我组织的潜在机制的重要问题。 et.al.|[2308.15311](http://arxiv.org/abs/2308.15311)|null|
|**2023-08-29**|**Diffusion-based kernel density estimation improves the assessment of carbon isotope modelling**|比较不同大小的数据集是模型评估和校准的主要任务之一。这是由于与模拟模型结果相比，现场数据通常是稀疏的。我们通过应用一种新的基于扩散的核密度估计器（diffKDE）来解决这一任务，该估计器近似数据集的概率密度函数，几乎与可用数据量无关。我们通过Wasserstein距离对测量和模拟的海洋颗粒有机碳-13同位素的密度估计进行了定性和定量比较。为了参考，我们还展示了基于同等大小的数据集的相应比较，并减少了模拟和现场数据。基于所有可用数据的比较揭示了模拟与现场数据的更好拟合，并在掩蔽分析中显示了误导性的模型特性。diffKDE和传统的高斯KDE之间的比较表明，在diffKDE下，数据特征的分辨率更好。我们能够在KDE在模型校准中的应用中显示出有希望的优势，特别是在diffKDE的应用中。 et.al.|[2308.15282](http://arxiv.org/abs/2308.15282)|null|
|**2023-08-29**|**Summary of IceCube Tau Neutrino Searches and Flavor Composition Measurements of the Diffuse Astrophysical Neutrino Flux**|我们使用南极冰立方中微子观测站的数据，对漫射天体物理中微子通量的风味成分测量进行了总结。IceCube通过两种不同的方法确定了候选天体物理学τ中微子。一种方法使用了专门的粒子识别算法来分类和重建“双级联”事件拓扑，这是τ中微子-带电电流相互作用的特征。第一种方法应用于高能启动事件（HESE）样本，这是一组能量超过60~TeV的全天空、全口味中微子事件，涵盖了冰立方12年的生存时间。我们表明，与之前的冰立方分析相比，在HESE样本上添加更多年份的数据和更新的冰特性，对天体物理中微子通量的风味成分产生了更严格的限制，特别是当它与贯穿轨道和级联的高统计数样本相结合时。第二种方法使用了一种敏感的基于机器学习的选择技术，在9.7年的IceCube数据中找到了七个候选事件。这种方法排除了迄今为止统计意义最高的零天体物理学τ中微子假说。 et.al.|[2308.15213](http://arxiv.org/abs/2308.15213)|null|
|**2023-08-29**|**Propagation of Chaos for Mean Field Interacting Particle System with Multiplicative Noise**|本文得到了相对熵中具有乘性噪声的平均场相互作用粒子系统的混沌的定量传播，其中扩散是无分布的，漂移中的相互作用是有界的或Lipschitz连续的，并且相互作用粒子的初始分布与极限方程的初始分布是奇异的。当扩散和漂移中的相互作用是Lipschitz连续时，证明了 $L^\eta$（$\eta\in（0,1）$）-Waserstein距离中混沌的定量传播，这似乎是文献中关于$L^\eta$（$\eta\in（0,1）$）-Vaserstein距离中混沌定量传播的第一个结果。此外，还导出了耗散条件下混沌在相对熵中的长时间定量传播以及$L^2$ （-Waserstein距离）。 et.al.|[2308.15181](http://arxiv.org/abs/2308.15181)|null|
|**2023-08-29**|**Non-equilibrium cluster-cluster aggregation in the presence of anchoring sites**|假设在细胞膜中或在细胞膜处扩散的颗粒的非平衡簇簇聚集在不同的生物环境中导致有限大小的结构域，如脂质筏、细胞粘附复合物或神经元中的突触后结构域。在这种情况下，颗粒的解吸平衡了到膜的连续通量，对可能的聚集体尺寸施加了限制，并产生了稳定的尺寸分布。在这里，我们在二维中研究了非平衡簇-簇聚集的情况，其中扩散粒子和/或簇在空间中固定在特定的锚定位点，这应该与突触特别相关，但也可能存在于其他生物或物理系统中。使用锚定簇周围浓度场的有效平均场描述，我们导出了它们的平均大小作为参数（如锚定位点密度）的函数的表达式。我们进一步提出并求解了适当的速率方程，使我们能够预测扩散和固定团簇的尺寸分布。我们用基于粒子的模拟证实了我们的结果，并讨论了对生物和物理系统的潜在影响。 et.al.|[2308.15162](http://arxiv.org/abs/2308.15162)|null|
|**2023-08-29**|**Unravelling H $_2$ chemisorption and physisorption on metal decorated graphene using quantum Monte Carlo**|分子氢是氢能应用的核心，有可能显著减少二氧化碳排放能源过程的使用。然而，氢气储存是其大规模使用的主要瓶颈，因为目前的储存方法是能源密集型的。在不同的储存方法中，在环境压力和温度下物理吸附分子氢是一种很有前途的替代方法，特别是由于可调谐的轻质纳米材料和高通量筛选方法。尽管如此，理解氢在定义明确的纳米材料中的吸附仍然具有实验挑战性，尽管预测氢吸附的工作激增，但参考信息很少。在这项工作中，我们重点研究了Li、Na、Ca和K修饰的石墨烯片作为氢吸附的基底，并使用量子扩散蒙特卡罗（DMC）计算了迄今为止最准确的吸附能。基于我们之前在密度泛函理论（DFT）层面的见解，我们发现，根据DMC，分子氢的弱共价化学吸附，即Kubas结合，在Ca修饰的石墨烯上是可行的，这与DFT一致。这一发现与之前DMC对4H$_2$/Ca$^+$ 气体团簇的预测形成了对比，其中不利于化学吸附。然而，我们发现，根据广泛使用的DFT方法，氢在金属修饰石墨烯上的吸附能与DMC并不完全一致，并且差异也不系统。本文报道的参考吸附能可用于寻找更好的工作马方法，用于氢吸附的大规模建模。此外，这项工作的意义影响了寻找合适的储氢材料和高通量方法的策略。 et.al.|[2308.15160](http://arxiv.org/abs/2308.15160)|null|
|**2023-08-29**|**Evidence for a large off-centered galactic outflow and its connection to the extraplanar diffuse ionized gas in IC 1553**|目标。我们分析了IC1553星系恒星形成边缘的MUSE光学积分场谱，以研究其平面外扩散电离气体（eDIG）及其盘晕界面的形成过程。方法。我们从积分场光谱中提取了光发射线的特性，并生成了常用的发射线诊断图，以分析电离条件和eDIG的分布。此外，我们进行了引力势拟合，以研究疑似星系外流的运动学。后果我们发现，在投影中，eDIG标度高度的最大值约为1.0kpc，并随着距离星系中心的径向距离大致线性下降。eDIG的电离状态与纯光电离场景不一致，而是需要冲击电离的显著贡献。除了气体运动学之外，这也有力地表明了银河系规模外流的存在，其起源距离银河系中心至少1.4 kpc。eDIG中推断出的大约225 km s-1的冲击速度与我们潜在建模中估计的逃逸速度相当。目前恒星形成星团的不对称分布在eDIG中产生了一系列不同的电离条件。因此，垂直发射线轮廓沿着星系的主轴在数量和质量上都有所不同。该分析表明，在eDIG的研究中，至关重要的是使用考虑空间和运动学分布的观测，例如使用积分场单元进行的观测，以形成相关物理特性的准确图像。 et.al.|[2308.15134](http://arxiv.org/abs/2308.15134)|null|
|**2023-08-29**|**Close-in ice lines and the super-stellar C/O ratio in discs around very low-mass stars**|与太阳型恒星周围的圆盘相比，晚M矮星周围圆盘的C/O比升高的原因尚不清楚。在这里，我们试图使用粘度驱动的圆盘演化模型，再现观察到的圆盘C/O比随恒星质量变化的差异，并研究这些圆盘中生长在水冰线内的行星的相应大气成分。我们使用耦合的圆盘演化和行星形成代码进行了模拟，其中包括卵石漂移和蒸发。我们对圆盘中平面的尘埃成分使用了化学分配模型。在水冰线内，由于富含水冰的卵石向内漂移和蒸发，圆盘的C/O比最初降低到亚恒星，然后由于富含碳的蒸汽向内扩散，再次增加到超恒星值。我们表明，与太阳型恒星相比，这种过程对质量非常低的恒星更有效，因为冰线更近，圆盘粘性时间尺度更短。在高粘度盘中，由于富碳气体的快速向内平流，从亚恒星到超恒星的转变发生得更快。我们的研究结果表明，早期（当圆盘C/O仍然是亚恒星时）吸积大气层的行星将具有较低的大气C/O比，而晚期（圆盘C/O已经成为超恒星时）的行星可以获得较高的C/O比。我们的模型预测与观测结果一致，假设所有恒星都具有相同的金属丰度和化学成分，并且内盘的垂直混合时间尺度比径向平流时间尺度短得多。这进一步加强了在未来的研究中考虑恒星丰度和圆盘演化的理由，这些研究旨在将行星（大气）成分与圆盘成分联系起来。 et.al.|[2308.15128](http://arxiv.org/abs/2308.15128)|null|
|**2023-08-29**|**Diffusion rate in non-generic directions in the wind-tree model**|我们展示了[0,1）是具有合理参数的风树模型的扩散率。我们还将提供一个标准来描述作为表示的悬架获得的并环的李雅普诺夫谱的形状。作为一个应用，我们展示了一个无限族的风树台球，其李雅普诺谱的内部尽可能大：这是全平方（0,1）^2。据作者所知，这是第一个完整的描述，其中李亚普诺夫谱的内部在二维中是明确已知的，即使对于一般的Fuchsian群也是如此。 et.al.|[2308.15121](http://arxiv.org/abs/2308.15121)|null|
|**2023-08-29**|**DiffusionVMR: Diffusion Model for Video Moment Retrieval**|视频时刻检索是一项基本的视觉语言任务，旨在基于语言查询从未修剪的视频中检索目标时刻。现有的方法通常提前手动或通过生成网络生成大量建议作为检索的支持集，这不仅不灵活，而且耗时。受扩散模型在目标检测方面的成功启发，本工作旨在将视频时刻检索重新定义为去噪生成过程，以摆脱不灵活和耗时的建议生成。为此，我们提出了一种新的无建议框架，即DiffusionVMR，它直接从噪声中采样随机跨度作为候选，并将去噪学习引入地面目标矩。在训练过程中，高斯噪声被添加到真实时刻，并且模型被训练以学习如何逆转这个过程。在推理中，一组时间跨度是从初始噪声到最终输出逐渐细化的。值得注意的是，DiffusionVMR的训练和推理是解耦的，并且在推理中可以使用任意数量的随机跨度，而不与训练阶段一致。在三个广泛使用的基准（即QVHighlight、Charades STA和TACoS）上进行的大量实验通过将所提出的DiffusionVMR与最先进的方法进行比较，证明了其有效性。 et.al.|[2308.15109](http://arxiv.org/abs/2308.15109)|null|
|**2023-08-29**|**Quasiprojectile breakup and isospin equilibration at Fermi energies: an indication of longer projectile-target contact times?**|研究了在32和52MeV/核子下 $^{58,64}$Ni+$^{58，64}$ Ni的半周碰撞和周碰撞中的准抛射体破裂通道。INDRA-FAZIA装置在GANIL的第一次实验活动中获得了数据。利用由两个破碎碎片重建的准弹的中子质子比，利用同位旋输运比技术，强调了在两个不对称反应中，弹与目标之间的同位旋扩散效应。我们发现有证据表明，对于相同的反应中心性，相对于更密集的二元输出，在破裂通道中实现了初始同位旋不平衡的更高程度的弛豫，这可能表明对特定动力学特征的间接选择。我们提出了一种基于与所研究的两个出口通道相关的不同平均射弹-目标接触时间的解释，其中破裂通道的相互作用更长。时间信息是从与GEMINI++耦合的研究系统的AMD模拟中提取的：模型计算支持本文提出的假设。 et.al.|[2308.15077](http://arxiv.org/abs/2308.15077)|null|
|**2023-08-29**|**DiffBIR: Towards Blind Image Restoration with Generative Diffusion Prior**|我们提出了DiffBIR，它利用预训练的文本到图像的扩散模型来解决盲图像恢复问题。我们的框架采用了两阶段流水线。在第一阶段，我们在各种退化中预训练恢复模块，以提高现实世界场景中的泛化能力。第二阶段利用潜在扩散模型的生成能力，实现逼真的图像恢复。具体来说，我们引入了一个内射调制子网络——LAControlNet来进行微调，而预先训练的稳定扩散是为了保持其生成能力。最后，我们介绍了一个可控模块，该模块允许用户在推理过程中通过在去噪过程中引入潜像引导来平衡质量和保真度。在合成和真实世界的数据集上，大量的实验已经证明了它在盲图像超分辨率和盲人脸恢复任务方面优于最先进的方法。代码可在https://github.com/XPixelGroup/DiffBIR. et.al.|[2308.15070](http://arxiv.org/abs/2308.15070)|null|
|**2023-08-29**|**Finite-dimensional leading order dynamics for the fast diffusion equation near extinction**|利用Dirichlet边界条件在有界域上分析了快速扩散方程，已知其解在有限时间内消失。我们构造了不变流形，它为任何规定的收敛速度提供了在消失解附近的有限维近似。 et.al.|[2308.15032](http://arxiv.org/abs/2308.15032)|null|
|**2023-08-29**|**C2G2: Controllable Co-speech Gesture Generation with Latent Diffusion Model**|协同语音手势生成对于自动数字化身动画至关重要。然而，现有的方法存在诸如不稳定的训练和时间不一致的问题，特别是在生成高保真度和全面的手势方面。此外，这些方法缺乏对说话者身份的有效控制和对生成的手势的时间编辑。以捕捉时间潜在信息和应用实际控制为重点，我们提出了一个可控制的协同语音手势生成框架C2G2。具体来说，我们提出了一种由潜在扩散模型驱动的两阶段时间依赖性增强策略。我们进一步介绍了C2G2的两个关键功能，即用于生成与说话者相关的真实长度骨架的特定于说话者的解码器和用于灵活手势生成/编辑的重新绘制策略。在基准手势数据集上进行的大量实验验证了我们提出的C2G2与几个最先进的基线相比的有效性。项目演示页面的链接可以在https://c2g2-gesture.github.io/c2_gesture et.al.|[2308.15016](http://arxiv.org/abs/2308.15016)|null|
|**2023-08-29**|**Robust topology optimisation of lattice structures with spatially correlated uncertainties**|结构的材料和其他特性的不确定性通常在空间上是相关的。我们介绍了一种在晶格结构的鲁棒拓扑优化中表示和处理空间相关随机场的有效技术。稳健优化考虑结构响应的统计数据，以获得其性能对随机场的具体实现不太敏感的设计。我们通过利用随机场和随机偏微分方程（SPDE）之间建立的联系来表示格上的高斯随机场。已知具有Mat’ern协方差的随机场的精度矩阵，即协方差矩阵的逆，等于具有二阶椭圆算子的可能分数PDE的有限元刚度矩阵。我们考虑了PDE在晶格上的离散化，以获得一个随机场，该随机场通过设计考虑了其几何结构和连通性。这样获得的随机场可以被解释为一种物理学，该物理学是由椭圆SPDE对制造过程中发生的物理过程（如热和质量扩散）进行建模的假设预先告知的。尽管所提出的方法是通用的，但我们证明了它在杆件杨氏模量不确定的销接桁架晶格中的应用。我们将结构合规性的期望值和标准差的加权和视为成本函数。为了计算期望值和标准偏差及其相对于构件横截面的梯度，我们使用一阶泰勒级数近似。成本函数及其梯度仅使用稀疏矩阵运算来计算。我们使用几个具有各向同性、各向异性和非平稳随机场的晶格示例以及多达8万个随机变量和优化变量来证明所提出方法的有效性。 et.al.|[2308.14958](http://arxiv.org/abs/2308.14958)|null|
|**2023-08-28**|**The Effects of Non-Equilibrium Velocity Distributions on Alfvén Ion-Cyclotron Waves in the Solar Wind**|在这项工作中，我们研究了太阳风质子速度分布函数（VDF）中发现的复杂结构，而不是通常假设的双组分双麦克斯韦结构，如何影响平行传播微稳定性的开始和演化。我们使用任意线性等离子体解算器（ALPS），一种数值色散解算器，来找到为从Wind航天器对太阳风的观测中提取的质子VDF计算的Alfv’en模式的真实频率和增长/阻尼率。我们将这种波动行为与通过将相同的程序应用于Wind质子VDF的核心和束流双麦克斯韦拟合而获得的波动行为进行了比较。我们发现，从提取的数据和双麦克斯韦拟合中获得的等离子体波存在几个显著差异，包括生长/阻尼率对VDF形状的强烈依赖性。通过将准线性扩散算子应用于这些VDF，我们精确定位了速度空间中的共振相互作用区域，其中VDF结构的差异显著影响波的增长和阻尼率。Alfv’en模式行为对VDF结构的敏感依赖性的证明可以解释为什么线性理论预测的太阳风质子背景VDF的双麦克斯韦模型的Alfv‘en离子回旋不稳定性阈值并不能完全约束航天器对太阳风质子VDF的观测，如wind航天器的观测。 et.al.|[2308.14944](http://arxiv.org/abs/2308.14944)|null|

<p align=right>(<a href=#updated-on-20230830>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-08-29**|**Canonical Factors for Hybrid Neural Fields**|因子特征量提供了一种简单的方法来构建更紧凑、高效和可积分的神经场，但也引入了对真实世界数据不一定有益的偏差。在这项工作中，我们（1）描述了这些架构对轴对准信号的不希望有的偏差——它们可能导致高达2 PSNR的辐射场重建差异——以及（2）探索了学习一组规范化变换如何通过消除这些偏差来改进表示。我们在二维模型问题中证明，同时学习这些变换和场景外观是成功的，效率大大提高。我们使用图像、符号距离和辐射场重建任务验证了最终的架构，我们称之为TILTED，在这些任务中，我们观察到了质量、稳健性、紧凑性和运行时间方面的改进。结果表明，TILTED可以实现比基线大2倍的能力，同时突出神经场评估程序的弱点。 et.al.|[2308.15461](http://arxiv.org/abs/2308.15461)|null|
|**2023-08-28**|**NSF: Neural Surface Fields for Human Modeling from Monocular Depth**|从单眼相机获得个性化的3D可动画化化身在游戏、虚拟试穿、动画和VR/XR等领域有几个现实世界的应用。然而，从这种稀疏的数据中建模动态和细粒度的服装变形是非常具有挑战性的。现有的从深度数据建模3D人类的方法在计算效率、网格一致性以及分辨率和拓扑结构的灵活性方面具有局限性。例如，使用隐式函数重建形状和每帧提取显式网格在计算上是昂贵的，并且不能确保跨帧的连贯网格。此外，在具有离散表面的预先设计的人类模板上预测每个顶点的变形在分辨率和拓扑结构上缺乏灵活性。为了克服这些局限性，我们提出了一种新的方法“关键特征：神经表面场”，用于从单目深度对穿着3D衣服的人类进行建模。NSF仅在基面上定义了一个神经场，该神经场对连续和灵活的位移场进行建模。NSF可以适应不同分辨率和拓扑结构的基面，而无需在推理时进行重新训练。与现有方法相比，我们的方法在保持网格一致性的同时消除了昂贵的每帧表面提取，并且能够在不重新训练的情况下重建任意分辨率的网格。为了促进这方面的研究，我们在项目页面上发布了我们的代码：https://yuxuan-xue.com/nsf. et.al.|[2308.14847](http://arxiv.org/abs/2308.14847)|null|
|**2023-08-28**|**A Transformer-Conditioned Neural Fields Pipeline with Polar Coordinate Representation for Astronomical Radio Interferometric Data Reconstruction**|在射电天文学中，能见度数据是对射电望远镜波信号的测量，被转换成图像，用于观测遥远的天体。然而，由于信号稀疏性和其他因素，这些结果图像通常包含真实源和伪影。获得更干净图像的一种方法是在成像之前将样本重建成致密的形式。不幸的是，现有的可见性重建方法可能会错过频率数据的一些分量，因此模糊的对象边缘和持久的伪影仍然存在于图像中。此外，由于数据偏斜，在不规则可见性样本上的计算开销很高。为了解决这些问题，我们提出了PolarRec，这是一种干涉能见度数据的重建方法，它由具有极坐标表示的变压器条件神经场管道组成。这种表示与望远镜在地球自转时观察天体区域的方式相匹配。我们进一步提出了径向频率损失函数，使用极坐标系中的径向坐标与频率信息进行关联，以帮助重建完整的可见性。我们还根据极坐标系中的角坐标对可见性采样点进行分组，并使用分组作为随后使用Transformer编码器进行编码的粒度。因此，我们的方法可以有效地捕捉可见性数据的固有特征。我们的实验表明，PolarRec通过忠实地重建可见性域中的所有频率分量，显著提高了成像结果，同时显著降低了计算成本。 et.al.|[2308.14610](http://arxiv.org/abs/2308.14610)|null|
|**2023-08-24**|**NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes**|最近的隐式神经表示在新的视图合成中显示出了很好的结果。然而，现有的方法需要从许多视图进行昂贵的每场景优化，因此限制了它们在真实世界的无边界城市环境中的应用，在这些环境中，从极少数视图观察到感兴趣的对象或背景。为了缓解这一挑战，我们引入了一种名为NeO360的新方法，用于户外场景稀疏视图合成的神经场。NeO 360是一种可推广的方法，它从单个或几个摆出姿势的RGB图像重建360｛\deg｝场景。我们方法的本质是捕捉复杂的真实世界户外3D场景的分布，并使用可以从任何世界点查询的混合图像条件三平面表示。我们的表示结合了基于体素和鸟瞰图（BEV）的最佳表示，比每种表示都更有效、更具表现力。NeO 360的表示使我们能够从大量无界3D场景中学习，同时在推理过程中从一张图像中提供对新视图和新场景的可推广性。我们在所提出的具有挑战性的360｛\deg｝无界数据集NeRDS 360上演示了我们的方法，并表明NeO 360在新视图合成方面优于最先进的可推广方法，同时还提供编辑和合成功能。项目页面：https://zubair-irshad.github.io/projects/neo360.html et.al.|[2308.12967](http://arxiv.org/abs/2308.12967)|**[link](https://github.com/zubair-irshad/NeO-360)**|
|**2023-08-23**|**Semantic-Aware Implicit Template Learning via Part Deformation Consistency**|学习隐式模板作为神经场最近在无监督形状对应方面表现出了令人印象深刻的性能。尽管取得了成功，但我们观察到，目前仅依赖几何信息的方法往往会在具有高结构可变性的通用物体形状中学习次优变形。在本文中，我们强调了零件变形一致性的重要性，并提出了一个语义感知的隐式模板学习框架，以实现语义上合理的变形。通过利用自监督特征提取器的语义先验，我们建议使用新的语义感知变形代码进行局部条件调节，并对零件变形、全局变形和全局缩放进行变形一致性正则化。我们的大量实验证明了所提出的方法在各种任务中优于基线：关键点转移、零件标签转移和纹理转移。更有趣的是，我们的框架在更具挑战性的环境下显示出更大的性能提升。我们还提供了定性分析来验证语义感知变形的有效性。代码可在https://github.com/mlvlab/PDC. et.al.|[2308.11916](http://arxiv.org/abs/2308.11916)|null|
|**2023-08-22**|**Approaching human 3D shape perception with neurally mappable models**|人类毫不费力地推断出物体的三维形状。这种能力的基础是什么计算？尽管已经提出了各种计算模型，但它们都没有捕捉到人类在不同视点之间匹配物体形状的能力。在这里，我们询问是否以及如何缩小这一差距。我们从一类相对新颖的计算模型3D神经场开始，它通过深度神经网络（DNN）中的合成封装了经典分析的基本原理。首先，我们发现3D光场网络（3D-LFN）支持与人类完全一致的3D匹配判断，用于类别内比较、强调标准DNN模型的3D失败情况的对抗性定义比较，以及用于无类别结构的算法生成形状的对抗性定义比较。然后，我们通过一系列计算实验研究了3D-LFN实现人类对齐性能的能力来源。在训练过程中暴露于物体的多个视角和多视角学习目标是模型-人对齐背后的主要因素；当使用多视图目标进行训练时，即使是传统的DNN架构也更接近人类行为。最后，我们发现，虽然用多视图学习目标训练的模型能够部分推广到新的对象类别，但它们不能达到人类的一致性。这项工作为理解可神经映射的计算架构中的人形推断提供了基础，并突出了未来工作的重要问题。 et.al.|[2308.11300](http://arxiv.org/abs/2308.11300)|null|
|**2023-08-21**|**Canonical Cortical Field Theories**|我们根据场论，使用放置在皮层表面2D晶格上的神经单元来表征神经元活动的动力学。分析神经元单元的电活动，目的是推导出一个具有简单功能形式的神经场模型，该模型仍然能够预测或重现经验发现。使用神经质量对每个神经单元进行建模，并在连续极限中导出伴随的场论。场论包括耦合的（真实的）克莱因-戈登场，其中模型的预测属于实验结果的范围。这些预测包括从皮层测量的电活动频谱，该频谱是使用能量对神经场本征函数的平分得出的。此外，神经场模型在一组参数内对用于建模每个神经元质量的动力学系统是不变的。具体而言，拓扑等效的动力学系统在连接到晶格中时产生相同的神经场模型；这表明所导出的场可以被解读为典型的皮层场论。我们专门研究了为传入信息的编码（或表示）提供结构的非分散场。进一步阐述随后的神经场理论，包括分散力的影响，对于理解皮层对信息的处理可能具有重要意义。 et.al.|[2308.10645](http://arxiv.org/abs/2308.10645)|null|
|**2023-08-14**|**S3IM: Stochastic Structural SIMilarity and Its Unreasonable Effectiveness for Neural Fields**|最近，神经辐射场（NeRF）通过学习仅使用姿态RGB图像的隐式表示，在渲染给定场景的新视图图像方面取得了巨大成功。NeRF和相关的神经场方法（例如，神经表面表示）通常优化逐点损失并进行逐点预测，其中一个数据点对应于一个像素。不幸的是，这一研究未能使用对远处像素的集体监督，尽管已知图像或场景中的像素可以提供丰富的结构信息。据我们所知，我们是第一个通过一种新的随机结构相似性（S3IM）损失为NeRF和相关神经场方法设计非局部多重训练范式的人，该损失将多个数据点作为一个整体处理，而不是独立处理多个输入。我们的大量实验证明了S3IM在几乎免费改进NeRF和神经表面表示方面的不合理有效性。质量度量的改进对于那些相对困难的任务可能特别显著：例如，TensoRF和DVGO在八个新的视图合成任务中的测试MSE损失意外下降了90%以上；在八个表面重建任务中，NeuS的198%F分数增益和64%的倒角$L_。此外，即使在稀疏输入、损坏图像和动态场景的情况下，S3IM也始终是稳健的。 et.al.|[2308.07032](http://arxiv.org/abs/2308.07032)|**[link](https://github.com/madaoer/s3im_nerf)**|
|**2023-08-11**|**Zero-shot Text-driven Physically Interpretable Face Editing**|本文提出了一种基于任意文本提示的人脸编辑新方法，该方法具有物理可解释性。与以前基于GAN反转的人脸编辑方法（操纵GAN的潜在空间）或基于扩散的方法（将图像操纵建模为反向扩散过程）不同，我们将人脸编辑过程视为在人脸图像上施加矢量流场，表示每个图像像素的空间坐标和颜色的偏移。在上述提出的范式下，我们用两种方式表示矢量流场：1）用光栅化张量显式表示流矢量，2）通过利用隐式神经表示的最新进展，将流矢量隐式参数化为连续、平滑和分辨率不可知的神经场。在预先训练的对比语言图像预训练（CLIP）模型的指导下，通过最大化编辑后的图像和文本提示之间的相关性，迭代优化流向量。我们还提出了一种基于学习的一次性人脸编辑框架，该框架快速且适用于任何文本提示输入。我们的方法还可以灵活地扩展到实时视频人脸编辑。与最先进的文本驱动的人脸编辑方法相比，我们的方法可以生成具有高身份一致性和图像质量的物理可解释的人脸编辑结果。我们的代码将公开。 et.al.|[2308.05976](http://arxiv.org/abs/2308.05976)|null|
|**2023-08-07**|**Explicifying Neural Implicit Fields for Efficient Dynamic Human Avatar Modeling via a Neural Explicit Surface**|本文提出了一种通过神经显式表面（NES）来解释隐式神经场来有效地建模动态人类的技术。在根据稀疏观测对动态3D内容进行建模以及有效地表示复杂的几何形状和外观方面，隐式神经场比传统的显式表示具有优势。然而，由于在体积渲染过程中需要密集采样，在3D空间中定义的隐式神经场的渲染成本很高。此外，当对稀疏3D空间进行建模时，可以进一步优化它们的存储效率。为了克服这些问题，本文提出利用神经显式曲面（NES）来显式表示隐式神经场，以提高记忆和计算效率。为了实现这一点，本文利用隐式和显式方法的优势，在NES的隐式神经场和显式渲染接口之间创建了一个完全可微分的转换。这种转换能够使用隐式方法有效地训练混合表示，并通过将显式渲染接口与新提出的基于光栅化的神经渲染器集成来实现高效渲染，该神经渲染器对于与显式表面的初始光线交互只产生一次纹理颜色查询，从而提高推理效率。NES在2D空间中描述了具有姿态相关神经隐式表面变形场的动态人体几何结构及其动态神经纹理，这是传统3D方法的一种更具记忆效率的替代方法，减少了冗余和计算负载。综合实验表明，NES的性能与以前的3D方法类似，大大提高了渲染速度，降低了内存成本。 et.al.|[2308.05112](http://arxiv.org/abs/2308.05112)|null|
|**2023-08-15**|**Neural Field Movement Primitives for Joint Modelling of Scenes and Motions**|本文提出了一种新的从演示中学习（LfD）方法，该方法使用神经场来高效准确地学习新技能。它通过利用共享嵌入以生成的方式学习场景和运动表示来实现这一点。我们的方法将每个专家演示平滑地映射到场景运动嵌入，并学习对它们进行建模，而不需要手工制作的任务参数或大型数据集。它通过强制场景和运动生成相对于嵌入空间的变化是平滑的来实现数据效率。在推理时，我们的方法可以使用测试时间优化来检索场景运动嵌入，并为新场景生成精确的运动轨迹。所提出的方法是通用的，可以使用图像、3D形状和任何其他可以使用神经场建模的场景表示。此外，它还可以生成末端效应器位置和基于关节角度的轨迹。我们的方法是在需要精确运动轨迹生成的任务上进行评估的，其中基本任务参数化是基于对象位置和几何场景变化的。实验结果表明，该方法优于基线方法，可推广到新的场景中。此外，在真实世界的实验中，我们表明我们的方法可以成功地对多值轨迹进行建模，它对推理时引入的干扰对象是鲁棒的，并且它可以生成6D运动。 et.al.|[2308.05040](http://arxiv.org/abs/2308.05040)|null|
|**2023-08-10**|**InstantAvatar: Efficient 3D Head Reconstruction via Surface Rendering**|通过可微分表面或体积渲染来优化神经场以表示单个场景，从而获得了全头部重建的最新进展。虽然这些技术达到了前所未有的精度，但由于需要昂贵的优化过程，它们需要几分钟甚至几个小时。在这项工作中，我们介绍了InstantAvatar，一种在商品硬件上几秒钟内从几张图像（减少到一张）中恢复全头头像的方法。为了加快重建过程，我们首次提出了一种将体素网格神经场表示与曲面渲染器相结合的系统。值得注意的是，这两种技术的天真组合会导致不稳定的优化，无法收敛到有效的解决方案。为了克服这一限制，我们提出了一种新的统计模型，该模型使用基于体素网格的架构来学习3D头部符号距离函数上的先验分布。该现有模型的使用，与其他设计选择相结合，形成了一个系统，该系统以与现有技术相当的精度实现3D头部重建，速度提高了100倍。 et.al.|[2308.04868](http://arxiv.org/abs/2308.04868)|null|
|**2023-08-07**|**DNFOMP: Dynamic Neural Field Optimal Motion Planner for Navigation of Autonomous Robots in Cluttered Environment**|动态变化环境中的运动规划是自动驾驶中最复杂的挑战之一。除了驾驶舒适性和速度限制外，安全性也是一项至关重要的要求。虽然经典的基于采样、基于网格和基于优化的规划方法可以生成平滑而短的路径，但它们通常不考虑环境的动力学。一些技术确实考虑了这一点，但它们依赖于在旅途中更新环境，而不是明确考虑动态，这不适合自动驾驶。为了解决这一问题，我们提出了一种基于神经场最优运动规划器（NFOMP）的新方法，该方法在归一化曲率和尖端数量方面优于最先进的方法。我们的方法将先前已知的移动障碍物嵌入到神经场碰撞模型中，以考虑环境的动力学。我们还通过在轨迹损失函数中添加拉格朗日乘子，引入了轨迹的时间剖面和非线性速度约束。我们使用BeamNG.tech驾驶模拟器，将我们的方法应用于解决城市环境中的最优运动规划问题。一辆自动驾驶汽车在三个城市场景中驾驶生成的轨迹，同时与障碍车共享道路。我们的评估表明，乘客能立即体验到的最大加速度为-7.5 m/s ^2，89.6%的驾驶时间用于加速度低于3.5 m/s ^2的正常驾驶。驾驶风格的特点是，轻轨交通风格和适度驾驶风格分别占驾驶时间的46.0%和31.4%。 et.al.|[2308.03539](http://arxiv.org/abs/2308.03539)|null|
|**2023-08-04**|**DTF-Net: Category-Level Pose Estimation and Shape Reconstruction via Deformable Template Field**|从RGB深度图像对估计开放世界场景中物体的6D姿态和重建物体的3D形状是具有挑战性的。许多现有的方法依赖于学习与特定模板相对应的几何特征，而忽略同一类别中对象之间的形状变化和姿态差异。因此，在复杂环境中处理看不见的对象实例时，这些方法表现不佳。相比之下，其他方法旨在通过利用归一化的几何结构先验来实现类别级别的估计和重建，但基于静态先验的重建难以应对大量的类内变化。为了解决这些问题，我们提出了DTF-Net，这是一种基于对象类别的隐式神经场的姿态估计和形状重建的新框架。在DTF-Net中，我们设计了一个可变形模板域来表示一般类别的形状潜在特征和类别内的几何变形特征。该字段建立连续的形状对应，将类别模板变形为任意观察到的实例，以完成形状重建。我们引入了一个姿态回归模块，该模块共享来自场的变形特征和模板代码，以估计场景中每个对象的精确6D姿态。我们集成了一个多模态表示提取模块来提取对象特征和语义掩码，从而实现端到端推理。此外，在训练过程中，我们实现了形状不变的训练策略和视点采样方法，以进一步增强模型提取物体姿态特征的能力。在REAL275和CAMERA25数据集上进行的大量实验证明了DTF-Net在合成场景和真实场景中的优越性。此外，我们还证明了DTF-Net可以有效地支持真实机械臂的抓取任务。 et.al.|[2308.02239](http://arxiv.org/abs/2308.02239)|null|
|**2023-08-03**|**NeuroSwarm: Multi-Agent Neural 3D Scene Reconstruction and Segmentation with UAV for Optimal Navigation of Quadruped Robot**|四足机器人具有独特的能力，可以调整自己的身体和步幅高度，在杂乱的环境中导航。尽管如此，这些机器人要想在现实世界中充分发挥其潜力，就需要了解其环境和障碍物的几何形状。我们提出了一种新的多智能体机器人系统，该系统融合了尖端技术。所提出的解决方案具有3D神经重建算法，该算法能够在静态和半静态环境中对四足机器人进行导航。环境的先前区域也根据四足机器人通过它们的能力进行分割。此外，我们还开发了一种自适应神经场最优运动规划器（ANFOMP），该规划器同时考虑了二维空间中的碰撞概率和障碍物高度。我们的新导航和映射方法使四足机器人能够调整自己的高度和行为，在拱门下导航，并穿过较小尺寸的障碍物。多智能体映射操作已被证明是高度准确的，障碍物重建精度为82%。此外，四足机器人可以利用3D障碍物信息和ANFOMP系统进行导航，从而使路径长度减少33.3%，导航时间减少70%。 et.al.|[2308.01725](http://arxiv.org/abs/2308.01725)|**[link](https://github.com/iana-zhura/neuroswarm)**|
|**2023-07-31**|**DiVA-360: The Dynamic Visuo-Audio Dataset for Immersive Neural Fields**|神经领域的进步使得能够高保真地捕捉静态和动态场景的形状和外观。然而，由于算法挑战和缺乏大规模的真实世界数据集，它们的能力落后于像素或网格等表示所提供的能力。我们用DiVA-360解决了数据集的局限性，DiVA-36是一个真实世界的360动态视觉音频数据集，具有关于表级场景的同步多模式视觉、音频和文本信息。它包含46个动态场景、30个静态场景和95个静态对象，跨越11个类别，使用一个新的硬件系统捕获，该系统使用53个120 FPS的RGB相机和6个麦克风，总共获得8.6M图像帧和1360 s的动态数据。我们提供了所有场景的详细文本描述、前景背景分割遮罩、静态对象的特定类别3D姿势对齐，以及用于比较的指标。我们的数据、硬件和软件以及代码可在https://diva360.github.io/. et.al.|[2307.16897](http://arxiv.org/abs/2307.16897)|null|
|**2023-07-28**|**Implicit neural representation for change detection**|由于空间支持和采集系统噪声不匹配，检测在同一地理区域的两个不同时间采集的一对3D机载激光雷达点云中发生的变化是一项具有挑战性的任务。最近检测点云变化的尝试都是基于监督方法，这需要在现实世界应用程序中不可用的大量标记数据。为了解决这些问题，我们提出了一种无监督的方法，该方法包括两个组成部分：用于连续形状重建的神经场（NF）和用于对变化进行分类的高斯混合模型。NF提供了一种网格不可知的表示，以编码具有无与伦比的空间支持的双时间点云，可以对其进行正则化，以增加高频细节并减少噪声。在任意空间尺度上比较每个时间戳的重建，从而显著提高检测能力。我们将我们的方法应用于城市扩展的模拟激光雷达点云的基准数据集。该数据集提供了具有不同分辨率、输入模式和噪声水平的不同挑战性场景，允许将我们的方法与当前最先进的方法进行多场景比较。我们在这个数据集上以10%的交集优势超过了并集度量。此外，我们将我们的方法应用于真实世界的场景，以识别考古遗址的非法挖掘（抢劫），并确认它们与现场专家的发现相匹配。 et.al.|[2307.15428](http://arxiv.org/abs/2307.15428)|null|
|**2023-07-24**|**Unsupervised reconstruction of accelerated cardiac cine MRI using Neural Fields**|心脏电影MRI是心脏功能评估的黄金标准，但固有的缓慢采集过程产生了加速欠采样采集的重建方法的必要性。已经提出了几种利用时空冗余的正则化方法来重建欠采样的心脏电影MRI。最近，还提出了基于监督深度学习的方法，以进一步加速采集和重建。然而，这些技术通常依赖于大型数据集进行训练，而这些数据集并不总是可用的。在这项工作中，我们提出了一种基于隐式神经场表示的无监督方法，用于心脏电影MRI（称为NF-cMRI）。所提出的方法在体内欠采样金角径向多线圈采集中进行了评估，欠采样因子为26x和52x，实现了良好的图像质量，并且与最先进的重建技术相比，实现了相当的空间和改进的时间描述。 et.al.|[2307.14363](http://arxiv.org/abs/2307.14363)|null|
|**2023-07-25**|**INFINITY: Neural Field Modeling for Reynolds-Averaged Navier-Stokes Equations**|对于数值设计来说，开发高效准确的替代模型至关重要。它们使我们能够近似复杂的物理现象，从而减少直接数值模拟的计算负担。我们提出了INFINITY，这是一种利用隐式神经表征（INRs）来应对这一挑战的深度学习模型。我们的框架将几何信息和物理场编码为紧凑表示，并学习它们之间的映射来推断物理场。我们使用翼型设计优化问题作为示例任务，并在具有挑战性的AirfRANS数据集上评估我们的方法，该数据集与现实世界的工业用例非常相似。实验结果表明，我们的框架通过准确推断整个体积和表面的物理场，实现了最先进的性能。此外，我们还证明了它在设计探索和形状优化等环境中的适用性：我们的模型可以在遵守方程的同时正确预测阻力和升力系数。 et.al.|[2307.13538](http://arxiv.org/abs/2307.13538)|null|
|**2023-08-24**|**Strivec: Sparse Tri-Vector Radiance Fields**|我们提出了Strivec，这是一种新的神经表示，它将3D场景建模为具有稀疏分布和紧凑因子分解的局部张量特征网格的辐射场。在最近的工作TensoRF之后，我们的方法利用张量分解来对张量网格进行建模。与使用全局张量并专注于向量矩阵分解的TensoRF不同，我们建议使用局部张量云，并应用经典的CANDECOMP/PARAFAC（CP）分解将每个张量分解为三个向量，这些向量表示沿空间轴的局部特征分布，并对局部神经场进行紧凑编码。我们还应用多尺度张量网格来发现几何和外观的共性，并在多个局部尺度上利用三向量分解来利用空间相干性。通过聚集来自所有尺度上的多个局部张量的神经特征来回归最终的辐射场特性。我们的三向量张量稀疏地分布在实际场景表面周围，这是通过利用3D场景的稀疏性进行快速粗略重建发现的。我们证明，我们的模型可以实现更好的渲染质量，同时使用比以前的方法（包括TensoRF和Instant NGP）更少的参数。 et.al.|[2307.13226](http://arxiv.org/abs/2307.13226)|**[link](https://github.com/zerg-overmind/strivec)**|

<p align=right>(<a href=#updated-on-20230830>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

