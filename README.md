[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.05.16
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-05-10**|**I3DGS: Improve 3D Gaussian Splatting from Multiple Dimensions**|3D Gaussian Splatting是一种新的三维视图合成方法，与传统的神经渲染技术相比，它可以获得隐含的神经学习渲染结果，但保持更高清晰度的快速渲染速度。但是，对于实际应用来说，在三维高斯散射上仍然很难达到足够快的效率。为了解决这个问题，我们提出了I3DS，一种综合模型性能改进的评估解决方案和实验测试。从原始三维高斯飞溅的多个重要层面或维度，我们进行了2000多种不同的实验，以测试所选择的不同项目和组件如何影响三维高斯飞溅模型的训练效率。在本文中，我们将分享关于如何提高训练、绩效以及模型的不同项目所造成的影响的丰富而有意义的经验和方法。提出了一种特殊但正常的95进制整数压缩和94进制浮点压缩ASCII编解码机制。将记录许多真实有效的实验和测试结果或现象。经过一系列合理的微调，I3DS可以获得比之前更好的性能提升。项目代码以开源形式提供。 et.al.|[2405.06408](http://arxiv.org/abs/2405.06408)|null|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|本文介绍了一种基于高斯散射的密集视觉同步定位与映射（VSLAM）的新框架。近年来，基于高斯飞溅的SLAM取得了很好的结果，但它依赖于RGB-D输入，跟踪能力较弱。为了解决这些局限性，我们首次将高级稀疏视觉里程计与密集高斯散射场景表示独特地集成在一起，从而消除了对基于高斯散射的SLAM系统典型的深度图的依赖，并增强了跟踪鲁棒性。在这里，稀疏视觉里程计在RGB流中跟踪相机姿势，而高斯散射处理地图重建。这些组件通过多视图立体（MVS）深度估计网络互连。我们提出了一种深度平滑损失来减少估计深度图的负面影响。此外，稀疏视觉里程计和密集高斯图之间的尺度一致性通过稀疏密集调整环（SDAR）得以保持。我们已经在各种合成和真实世界的数据集上评估了我们的系统。我们的姿态估计精度超过了现有方法，并达到了最先进的性能。此外，在新的视图合成保真度方面，它优于以前的单目方法，与利用RGB-D输入的神经SLAM系统的结果相匹配。 et.al.|[2405.06241](http://arxiv.org/abs/2405.06241)|null|
|**2024-05-09**|**FastScene: Text-Driven Fast 3D Indoor Scene Generation via Panoramic Gaussian Splatting**|文本驱动的3D室内场景生成具有广泛的应用，从游戏和智能家居到AR/VR应用。快速高保真的场景生成对于确保用户友好的体验至关重要。然而，现有方法的特点是生成过程漫长，或者需要复杂的手动指定运动参数，这给用户带来了不便。此外，这些方法通常依赖于窄场视点迭代生成，从而影响全局一致性和整体场景质量。为了解决这些问题，我们提出了FastScene，这是一个用于快速、更高质量的3D场景生成的框架，同时保持场景一致性。具体来说，在给定文本提示的情况下，我们生成全景图并估计其深度，因为全景图包含了关于整个场景的信息，并表现出明确的几何约束。为了获得高质量的新颖视图，我们引入了粗略视图合成（CVS）和渐进新颖视图修复（PNVI）策略，以确保场景一致性和视图质量。随后，我们利用多视图投影（MVP）形成透视图，并应用3D高斯散射（3DGS）进行场景重建。综合实验表明，FastScene在生成速度和质量上都优于其他方法，具有更好的场景一致性。值得注意的是，FastScene仅在文本提示的引导下，就可以在15分钟内生成3D场景，这比最先进的方法快至少一个小时，使其成为用户友好的场景生成典范。 et.al.|[2405.05768](http://arxiv.org/abs/2405.05768)|null|
|**2024-05-09**|**RPBG: Towards Robust Neural Point-based Graphics in the Wild**|基于点的表示最近在新颖的视图合成中流行起来，因为它们具有直观的几何表示、简单的操作和更快的收敛等独特优势。然而，根据我们的观察，这些基于点的神经重渲染方法预计只能在理想条件下表现良好，并且会遇到噪声、斑点点和无边界场景，这些问题很难处理，但在实际应用中很常见。为此，我们重新审视了一种有影响力的方法，称为基于神经点的图形（NPBG），作为我们的基线，并提出了稳健的基于点图形（RPBG）。我们深入分析了阻碍NPBG在通用数据集上实现令人满意的渲染的因素，并相应地改革了管道，使其对野外不同的数据集更具鲁棒性。受图像恢复实践的启发，我们极大地增强了神经渲染器，以实现基于注意力的点可见性校正和不完全光栅化的修复，只需可接受的开销。我们还寻求一种简单而轻量级的环境建模替代方案和一种迭代方法来缓解较差的几何形状问题。通过对具有不同拍摄条件和相机轨迹的广泛数据集进行彻底评估，RPBG稳定地以很大的优势优于基线，并表现出其相对于最先进的基于NeRF的变体的强大鲁棒性。代码可在https://github.com/QT-Zhu/RPBG. et.al.|[2405.05663](http://arxiv.org/abs/2405.05663)|null|
|**2024-05-08**|**GDGS: Gradient Domain Gaussian Splatting for Sparse Representation of Radiance Fields**|3D高斯飞溅方法越来越流行。然而，它们直接作用于信号，导致信号的密集表示。即使使用一些技术，如修剪或蒸馏，结果仍然很密集。在本文中，我们建议对原始信号的梯度进行建模。梯度比原始信号稀疏得多。因此，梯度使用更少的高斯飞溅，从而在训练和渲染过程中获得更高效的存储，从而获得更高的计算性能。由于稀疏性，在视图合成过程中，只需要少量像素，从而获得高得多的计算性能（快 $100\sim 1000\times$ ）。并且可以通过求解具有线性计算复杂性的泊松方程来从梯度中恢复2D图像。进行了几个实验来验证梯度的稀疏性和所提出方法的计算性能。该方法可以应用于各种应用，如人体建模和室内环境建模。 et.al.|[2405.05446](http://arxiv.org/abs/2405.05446)|null|
|**2024-05-07**|**Novel View Synthesis with Neural Radiance Fields for Industrial Robot Applications**|神经辐射场（NeRF）已成为一个快速发展的研究领域，有可能彻底改变典型的摄影测量工作流程，例如用于3D场景重建的工作流程。作为输入，NeRF需要具有相应相机姿态和内部方向的多视图图像。在典型的NeRF工作流程中，相机姿态和内部方向是通过运动结构（SfM）预先估计的。但是，生成的新视图的质量很难预测，这取决于不同的参数，如可用图像的数量和分布，以及相关相机姿态和内部方向的准确性。此外，SfM是一个耗时的预处理步骤，其质量在很大程度上取决于图像内容。此外，SfM的未定义的缩放因子阻碍了需要度量信息的后续步骤。在本文中，我们评估了NeRF在工业机器人应用中的潜力。我们提出了一种SfM预处理的替代方案：我们使用连接到工业机器人末端执行器的校准相机捕捉输入图像，并基于机器人运动学确定具有公制尺度的精确相机姿态。然后，我们通过将新观点与基本事实进行比较，并基于集成方法计算内部质量度量，来研究这些观点的质量。出于评估目的，我们获取了多个数据集，这些数据集对典型的工业应用的重建提出了挑战，如反射物体、较差的纹理和精细的结构。我们表明，基于机器人的姿态确定在非要求的情况下达到了与SfM相似的精度，同时在更具挑战性的场景中具有明显的优势。最后，我们给出了在缺乏基本事实的情况下应用集成方法来估计合成新视图的质量的第一个结果。 et.al.|[2405.04345](http://arxiv.org/abs/2405.04345)|null|
|**2024-05-06**|**A Construct-Optimize Approach to Sparse View Synthesis without Camera Pose**|从稀疏的输入图像集进行新的视图合成是一个具有挑战性的问题，具有很大的实际意义，尤其是当相机姿态不存在或不准确时。由于姿态和深度之间的耦合以及单目深度估计的不精确性，在神经辐射场算法中直接优化相机姿态和使用估计的深度通常不会产生好的结果。在本文中，我们利用最近的3D高斯飞溅方法，开发了一种新的无相机姿态稀疏视图合成的构造和优化方法。具体来说，我们通过使用单目深度并将像素投影回3D世界来逐步构建解决方案。在构建过程中，我们通过检测训练视图和相应渲染图像之间的2D对应关系来优化解决方案。我们开发了一个统一的可微分管道，用于相机配准和调整相机姿势和深度，然后进行反向投影。我们还引入了高斯飞溅中预期表面的新概念，这对我们的优化至关重要。这些步骤实现了粗略的解决方案，然后可以使用标准优化方法对其进行低通滤波和细化。我们展示了坦克、寺庙和静态远足数据集的结果，只有三个宽间距的视图，显示出比竞争方法（包括具有近似相机姿态信息的方法）明显更好的质量。此外，即使使用一半的数据集，我们的结果也会随着更多的视图而改进，并优于以前的InstantNGP和Gaussian Splatting算法。 et.al.|[2405.03659](http://arxiv.org/abs/2405.03659)|null|
|**2024-05-06**|**Gaussian Splatting: 3D Reconstruction and Novel View Synthesis, a Review**|基于图像的3D重建是一项具有挑战性的任务，涉及从一组输入图像推断对象或场景的3D形状。基于学习的方法因其直接估计3D形状的能力而受到关注。这篇综述论文的重点是最先进的3D重建技术，包括生成新颖的、看不见的视图。概述了高斯飞溅方法的最新发展，包括输入类型、模型结构、输出表示和训练策略。还讨论了尚未解决的挑战和未来的方向。鉴于该领域的快速进展以及增强3D重建方法的众多机会，对算法进行全面检查似乎至关重要。因此，本研究对高斯散射的最新进展进行了全面的概述。 et.al.|[2405.03417](http://arxiv.org/abs/2405.03417)|null|
|**2024-05-04**|**LidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes**|逼真度模拟在自动驾驶等应用中发挥着至关重要的作用，神经辐射场（NeRF）的进步可以通过自动创建数字3D资产实现更好的可扩展性。然而，由于在较高速度下相机运动基本共线和采样稀疏，街道场景的重建质量受到影响。另一方面，应用程序通常要求从偏离输入的摄影机视图进行渲染，以准确模拟车道变更等行为。在本文中，我们提出了一些见解，可以更好地利用激光雷达数据来提高街景的NeRF质量。首先，我们的框架从激光雷达中学习几何场景表示，该表示与基于隐式网格的表示融合用于辐射解码，从而提供由显式点云提供的更强的几何信息。其次，我们提出了一种鲁棒的遮挡感知深度监督方案，该方案允许通过累积来利用密集的激光雷达点。第三，我们从激光雷达点生成增强训练视图，以便进一步改进。我们的见解转化为在真实驾驶场景下大大改进的新颖视图合成。 et.al.|[2405.00900](http://arxiv.org/abs/2405.00900)|null|
|**2024-05-09**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|我们提出了实时高斯SLAM（RTG-SLAM），这是一个使用RGBD相机的实时三维重建系统，用于使用高斯飞溅的大规模环境。该系统具有紧凑的高斯表示和高效的动态高斯优化方案。我们强制每个高斯要么不透明，要么几乎透明，不透明的适合表面和主色，透明的适合残余色。通过以不同于彩色渲染的方式渲染深度，我们让单个不透明高斯很好地拟合局部表面区域，而不需要多个重叠的高斯，从而大大降低了内存和计算成本。对于动态高斯优化，我们明确地为每帧三种类型的像素添加高斯：新观察到的、具有大颜色误差的和具有大深度误差的。我们还将所有高斯分为稳定高斯和不稳定高斯，其中稳定高斯有望很好地拟合先前观察到的RGBD图像，否则不稳定。我们只优化不稳定的高斯，只渲染不稳定高斯占用的像素。这样，要优化的高斯数和要渲染的像素都大大减少，并且可以实时进行优化。我们展示了各种大型场景的实时重建。与最先进的基于NeRF的RGBD SLAM相比，我们的系统实现了相当高质量的重建，但速度约为其两倍，内存成本约为其一半，并在新视图合成的真实性和相机跟踪精度方面表现出卓越的性能。 et.al.|[2404.19706](http://arxiv.org/abs/2404.19706)|null|

<p align=right>(<a href=#updated-on-20240516>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-05-15**|**Classifying geospatial objects from multiview aerial imagery using semantic meshes**|航空图像越来越多地用于地球科学和自然资源管理，作为劳动密集型地面调查的补充。航空系统可以收集重叠的图像，这些图像从不同的角度提供每个位置的多个视图。然而，大多数预测方法（例如，用于树种分类）使用单个合成的自上而下的“正交镶嵌”图像作为输入，该图像几乎不包含关于对象的垂直方面的信息，并且可能包括处理伪像。我们提出了一种替代方法，直接在原始图像上生成预测，并使用语义网格将这些预测准确映射到地理空间坐标中。这种方法 $\unicode｛x2013｝$作为一个用户友好的开源工具包$\unicode{x2013｝$ 发布，使分析人员能够使用最高质量的数据进行预测，捕捉物体侧面的信息，并利用每个位置的多个视点来增加稳健性。我们在美国西部四个森林点的新基准数据集上证明了这种方法的价值，该数据集包括无人机图像、摄影测量结果、预测的树木位置和人工调查得出的物种分类数据。我们表明，在具有挑战性的跨站点树种分类任务中，相对于正交镶嵌基线，我们提出的多视角方法将分类精度从53%提高到75%。 et.al.|[2405.09544](http://arxiv.org/abs/2405.09544)|null|
|**2024-05-14**|**Dynamic NeRF: A Review**|神经辐射场（NeRF）是一种新的实现高分辨率三维重建和表示的隐式方法。在NeRF的首次研究提出后，NeRF获得了强大的发展动力，并在三维建模、表示和重建领域蓬勃发展。然而，基于NeRF的第一个和随后的大多数研究项目都是静态的，在实际应用中很薄弱。因此，越来越多的研究者对在实际应用或情况下更可行、更有用的动态NeRF的研究产生了兴趣和关注。与静态NeRF相比，动态NeRF的实现更加困难和复杂。但动态在未来更有潜力，甚至是可编辑NeRF的基础。在这篇综述中，我们对Dynamci-NeRF的发展和重要实施原则进行了详细而丰富的阐述。动态NeRF的主要原理和发展分析是从2021年到2023年，包括大多数动态NeRF项目。此外，我们还用丰富多彩、新颖新颖的特殊设计图形和表格，对各种动态的不同特点进行了详细的比较和分析。此外，我们还分析和讨论了实现动态NeRF的关键方法。参考文献的数量很大。陈述和比较是多方面的。通过阅读这篇综述，可以很容易地理解和获得Dynamic NeRF的整个发展历史和大多数主要设计方法或原理。 et.al.|[2405.08609](http://arxiv.org/abs/2405.08609)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|在臭名昭著的《星球大战》系列全息技术的指导下，我提出了一个使用激光雷达增强3D重建创建实时全息覆盖的应用程序。先前的尝试涉及SLAM或NeRF，它们要么需要高度校准的场景，要么产生高昂的计算成本，要么无法渲染动态场景。我提出了3种高保真度重建工具，可以在便携式设备上运行，例如iPhone 14 Pro，它可以实现精确的面部重建。我的系统实现了交互式和沉浸式全息体验，可用于广泛的应用，包括增强现实、远程呈现和娱乐。 et.al.|[2405.07178](http://arxiv.org/abs/2405.07178)|null|
|**2024-05-12**|**CoViews: Adaptive Augmentation Using Cooperative Views for Enhanced Contrastive Learning**|数据扩充在生成有效对比学习所需的高质量正负对方面发挥着关键作用。然而，常见的做法涉及重复使用单个增强策略来生成多个视图，由于视图之间缺乏合作，可能导致训练对效率低下。此外，为了找到最佳的扩充集，许多现有方法需要广泛的监督评估，忽略了模型的演变性质，在整个训练过程中可能需要不同的扩充。其他方法训练可微增广生成器，从而限制了文献中不可微变换函数的使用。在本文中，我们通过提出一个框架来解决这些挑战，该框架用于以最小的计算开销学习用于对比学习的高效自适应数据增强策略。我们的方法在培训期间不断生成新的数据增强策略，并在没有任何监督的情况下产生有效的积极/消极因素。在这个框架内，我们提出了两种方法：\ac｛IndepViews｝，它生成在所有视图中使用的增强策略；\ac{CoViews}，它为每个视图生成依赖的增强策略。这使我们能够学习应用于每个视图的转换之间的依赖关系，并确保应用于不同视图的增强策略相互补充，从而产生更有意义和有区别的表示。通过在多个数据集和对比学习框架上的广泛实验，我们证明了我们的方法始终优于基线解决方案，并且使用依赖于视图的增强策略的训练优于使用跨视图共享的独立策略的训练，展示了其在增强对比学习性能方面的有效性。 et.al.|[2405.07116](http://arxiv.org/abs/2405.07116)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|对精确相机姿态的依赖是神经辐射场（NeRF）模型在3D重建和SLAM任务中广泛部署的一个重要障碍。现有方法引入单目深度先验来联合优化相机姿态和NeRF，未能充分利用深度先验，并忽略了其固有噪声的影响。在本文中，我们提出了截断深度NeRF（TD NeRF），这是一种新的方法，通过联合优化辐射场和相机姿态的可学习参数，可以从未知的相机姿态中训练NeRF。我们的方法通过三个关键进展明确利用了单目深度先验：1）我们提出了一种新的基于截断正态分布的基于深度的射线采样策略，提高了姿态估计的收敛速度和精度；2） 为了规避局部极小值并细化深度几何，我们引入了一种从粗到细的训练策略，该策略逐步提高了深度精度；3） 我们提出了一种更鲁棒的帧间点约束，该约束增强了训练过程中对深度噪声的鲁棒性。在三个数据集上的实验结果表明，TD NeRF在相机姿态和NeRF的联合优化方面取得了卓越的性能，超过了以往的工作，并生成了更准确的深度几何。我们方法的实现已在发布https://github.com/nubot-nudt/TD-NeRF. et.al.|[2405.07027](http://arxiv.org/abs/2405.07027)|null|
|**2024-05-10**|**OneTo3D: One Image to Re-editable Dynamic 3D Model and Video Generation**|单图像到可编辑动态三维模型和视频生成是单图像到三维表示或图像三维重建研究领域的新方向和变化。与原始的神经辐射场相比，高斯散射在隐式三维重建中显示了其优势。随着技术和原理的快速发展，人们试图使用稳定扩散模型来生成带有文本指令的目标模型。然而，使用普通的隐式机器学习方法很难获得精确的运动和动作控制，而且很难生成内容长、语义连续的3D视频。为了解决这个问题，我们提出了OneTo3D，这是一种使用单个图像生成可编辑3D模型并生成目标语义连续时间不受限制的3D视频的方法和理论。我们使用普通的基本高斯飞溅模型从单个图像生成3D模型，这需要较少的视频内存和计算机计算能力。随后，我们设计了一种对象电枢的自动生成和自适应绑定机制。结合我们提出的可重新编辑的运动和动作分析与控制算法，我们可以在建立3D模型、精确的运动和行动控制以及用输入的文本指令生成稳定的语义连续时间无限制的3D视频方面取得比SOTA项目更好的性能。在这里我们将分析详细的实施方法和理论分析。将介绍相关比较和结论。项目代码是开源的。 et.al.|[2405.06547](http://arxiv.org/abs/2405.06547)|**[link](https://github.com/lin-jinwei/OneTo3D)**|
|**2024-05-10**|**Comparative Analysis of Advanced Feature Matching Algorithms in Challenging High Spatial Resolution Optical Satellite Stereo Scenarios**|特征匹配决定了高空间分辨率（HSR）光学卫星立体定向的精度，从而影响了3D重建和变化检测等几个重要应用。然而，偏离轨道的HSR光学卫星立体像的匹配经常遇到具有挑战性的条件，包括宽基线观测、显著的辐射差异、多时相变化、不同的空间分辨率、不一致的光谱分辨率和不同的传感器。在这项研究中，我们评估了各种先进的HSR光学卫星立体特征匹配算法。利用来自六个具有挑战性场景的五颗卫星的专门构建的数据集，即HSROSS数据集，我们对四种算法进行了比较分析：传统的SIFT和基于深度学习的方法，包括SuperPoint+SuperGlue、SuperPoint+LightGlue和LoFTR。我们的研究结果突出了SuperPoint+LightGlue在平衡稳健性、准确性、分布性和效率方面的整体卓越性能，展示了其在复杂高铁光学卫星场景中的潜力。 et.al.|[2405.06246](http://arxiv.org/abs/2405.06246)|null|
|**2024-05-09**|**Minimal Perspective Autocalibration**|我们从多个角度引入了一个新的最小问题族进行重构。我们的主要关注点是一种新的自动校准方法，这是计算机视觉中一个长期存在的问题。解决这个问题的传统方法，如基于Kruppa方程或模约束的方法，明确地依赖于多个基本矩阵或投影重建的知识。相反，我们考虑了一种新的公式，该公式涉及图像点的约束、3D点的未知深度和部分指定的校准矩阵 $K$。对于$2$和$3$视图，我们给出了通过放松其中一些约束而获得的最小自动校准问题的综合分类法。这些问题根据视图的数量和$K$ 的任何假定先验知识被组织成类。在每个类中，我们用最少的——或者相对较少的——解决方案来确定问题。从这一大堆问题中，我们设计了三个实用的解决方案。使用合成数据和真实数据进行的实验以及我们的求解器与COLMAP的接口证明，与最先进的校准方法相比，我们实现了卓越的精度。代码位于https://github.com/andreadalcin/MinimalPerspectiveAutocalibration et.al.|[2405.05605](http://arxiv.org/abs/2405.05605)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|神经辐射场（NeRF）已成为3D场景表示的一种强大范例，提供了一组稀疏和非结构化传感器数据的高保真渲染和重建。在自主机器人的背景下，对环境的感知和理解至关重要，NeRF在提高性能方面有着巨大的前景。在本文中，我们对利用NeRF增强自主机器人能力的最新技术进行了全面的调查和分析。我们特别关注自主机器人的感知、定位和导航以及决策模块，并深入研究对自主操作至关重要的任务，包括3D重建、分割、姿态估计、同步定位和映射（SLAM）、导航和规划以及交互。我们的调查仔细地对现有的基于NeRF的方法进行了基准测试，深入了解了它们的优势和局限性。此外，我们还探索了这一领域未来研究和开发的有希望的途径。值得注意的是，我们讨论了3D高斯飞溅（3DGS）、大型语言模型（LLM）和生成人工智能等先进技术的集成，以提高重建效率、场景理解和决策能力。这项调查为寻求利用NeRF为自主机器人赋能的研究人员提供了路线图，为能够在复杂环境中无缝导航和交互的创新解决方案铺平了道路。 et.al.|[2405.05526](http://arxiv.org/abs/2405.05526)|null|
|**2024-05-06**|**MVDiff: Scalable and Flexible Multi-View Diffusion for 3D Object Reconstruction from Single-View**|为3D重建任务生成一致的多个视图仍然是对现有图像到3D扩散模型的挑战。通常，将3D表示合并到扩散模型中会降低模型的速度以及可推广性和质量。本文提出了一个通用框架，从单个图像或利用场景表示变换器和视图条件扩散模型生成一致的多视图图像。在模型中，我们引入了极线几何约束和多视图注意力，以增强三维一致性。从一个图像输入中，我们的模型能够生成超过评估指标基线方法的3D网格，包括PSNR、SSIM和LPIPS。 et.al.|[2405.03894](http://arxiv.org/abs/2405.03894)|null|

<p align=right>(<a href=#updated-on-20240516>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-05-15**|**MMFusion: Multi-modality Diffusion Model for Lymph Node Metastasis Diagnosis in Esophageal Cancer**|癌症是世界上最常见的癌症类型之一，在癌症相关死亡率中排名第六。癌症进展的精确计算机辅助诊断可以帮助医生有效地定制个性化治疗计划。目前，基于CT的癌症诊断方法因其检查患者病情的综合能力而备受关注。然而，基于多模态的方法可能会引入信息冗余，导致表现不佳。此外，多模态表征之间高效有效的相互作用还有待进一步探索，缺乏对多模态特征中预后相关性的深入探索。在这项工作中，我们介绍了一种基于多模式异质图的条件特征引导扩散模型，用于基于CT图像、临床测量和放射组学数据的淋巴结转移诊断。为了探索多模态特征之间的复杂关系，我们构建了一个异构图。在此之后，应用条件特征引导的扩散方法来消除信息冗余。此外，我们提出了一种掩蔽关系表示学习策略，旨在揭示原发性肿瘤和淋巴结图像表示的潜在预后相关性和优先级。各种实验结果验证了我们提出的方法的有效性。代码位于https://github.com/wuchengyu123/MMFusion. et.al.|[2405.09539](http://arxiv.org/abs/2405.09539)|null|
|**2024-05-15**|**A velocity-based moving mesh Discontinuous Galerkin method for the advection-diffusion equation**|在对流主导的流动中，空间离散化的鲁棒性是一个关键特性。虽然内部惩罚伽辽金（IPG）方法已经被证明在大网格Peclet数的情况下是有效的，但任意拉格朗日-欧拉（ALE）方法能够通过移动网格来减少对流优势。本文介绍并分析了求解线性平流-扩散方程的基于速度的移动网格间断伽辽金方法。通过引入平滑的参数化速度 $\tilde｛V｝$，将流分离为平均流（也称为移动网格速度）和剩余的平流场$V-\tilde{V｝$，我们基于网格速度的平滑性进行了收敛分析。此外，平流速度的降低提高了显式时间步长的稳定性，并且非守恒ALE公式的使用改变了矫顽力条件。最后，通过将现有的鲁棒误差准则适用于这种移动网格的情况，我们导出了鲁棒\textit｛a posteriori｝误差准则，该准则描述了平均流的潜在小偏差，并包括向$V=\tilde｛V｝$ 过渡的信息。 et.al.|[2405.09408](http://arxiv.org/abs/2405.09408)|null|
|**2024-05-15**|**Probing particle acceleration in Abell 2256: from to 16 MHz to gamma rays**|合并的星系团通常拥有壮观的散射无线电同步辐射源。这些源可以用团簇内介质中的冲击和湍流加速的相对论电子的非热池来解释。该池的起源以及宇宙射线在星团中传输和加速机制的细节仍然是悬而未决的问题。由于散射无线电发射的光谱指数往往非常陡峭，因此最好在低频率下进行研究。然而，由于与电离层有关的射频干扰和校准问题变得严重，地面望远镜可用的最低频率窗口（10-30兆赫）在很大程度上仍未得到探索。在这里，我们介绍了从16到168MHz的LOFAR观测，目标是著名的星团Abell 2256。在有史以来最深的十米波长的图像中，我们检测并解析了无线电晕、无线电冲击和各种陡峭的频谱源。我们测量了无线电晕和无线电冲击光谱的标准单幂律行为，发现了整个无线电晕的显著光谱指数和曲率波动，表明发射体积不均匀。与大尺度扩散源的直幂律谱相反，各种AGN相关源往往表现出向高频的极端陡峭和向低频的平坦。我们还发现了一种新的化石等离子体源，其频谱在23至144 MHz之间， $\alpha=-1.9\pm 0.1$ 。最后，通过比较无线电和伽马射线的观测结果，我们排除了Abell 2256中无线电晕起源的纯强子模型，除非星团中的磁场强度异常高，这是能量论证无法支持的，并且与其他星团磁场的知识不一致。 et.al.|[2405.09384](http://arxiv.org/abs/2405.09384)|null|
|**2024-05-15**|**Diffusion-based Contrastive Learning for Sequential Recommendation**|对比学习已被有效地应用于缓解数据稀疏性问题和提高推荐性能。大多数现有方法使用随机扩增来生成原始序列的扩增视图。然后，学习目标旨在最小化同一用户的不同视图的表示之间的距离。然而，这些随机增强策略（例如，掩码或替换）忽略了同一用户的不同增强视图的语义一致性，导致具有相似表示的序列在语义上不一致。此外，大多数扩充方法都无法利用上下文信息，这对理解序列语义至关重要。为了解决这些局限性，我们引入了一种基于扩散的对比学习方法来进行顺序推荐。具体来说，在给定用户序列的情况下，我们首先选择一些位置，然后利用上下文信息，通过引导扩散模型来引导替代项目的生成。通过重复这种方法，我们可以为同一用户获得语义一致的增强视图，用于提高对比学习的有效性。为了保持扩散模型和推荐模型的表示空间之间的内聚性，我们使用共享项目嵌入以端到端的方式训练整个框架。在五个基准数据集上进行的大量实验证明了我们提出的方法的优越性。 et.al.|[2405.09369](http://arxiv.org/abs/2405.09369)|null|
|**2024-05-15**|**DeCoDEx: Confounder Detector Guidance for Improved Diffusion-based Counterfactual Explanations**|深度学习分类器倾向于锁定数据集中存在的主要混杂因素，而不是与目标类别相关的因果标记，导致泛化能力差和预测有偏差。尽管通过反事实图像生成的可解释性已经成功地暴露了这个问题，但在存在主要和不同伪影的情况下允许准确解释的偏差缓解策略仍然没有解决。在这项工作中，我们提出了DeCoDEx框架，并展示了如何在推理过程中利用外部预训练的二进制伪影检测器来引导基于扩散的反事实图像生成器实现准确的可解释性。在CheXpert数据集上使用合成伪影和真实视觉伪影（支持设备）的实验表明，所提出的方法成功地合成了反事实图像，这些图像改变了与胸腔积液相关的因果病理标记，同时保留或忽略了视觉伪影。使用DeCoDEx生成的图像增强ERM和Group DRO分类器大大改善了每个类别分布不均的代表性不足的组的结果。该代码公开于https://github.com/NimaFathi/DeCoDEx. et.al.|[2405.09288](http://arxiv.org/abs/2405.09288)|null|
|**2024-05-15**|**Searches for Galactic Neutrinos with the IceCube Neutrino observatory**|到目前为止，星系带电宇宙射线的来源尚不清楚，因为它们的到达方向在星系磁场中是随机的。加速强子的物体预计会产生高能中微子。此外，根据星系宇宙射线在传播过程中与物质的相互作用，可以预测出弥漫的星系中微子通量。位于地理南极的冰立方中微子观测站用光学模块测量一立方公里的冰，以探测中微子相互作用中产生的粒子的切伦科夫光。IceCube在其完整的探测器配置中运行了十多年，在寻找中微子源方面处于独特的地位。这篇文章讨论了对中微子扩散通量的搜索，以及对来自银河系平面中候选点源和扩展源的中微子的搜索。 et.al.|[2405.09267](http://arxiv.org/abs/2405.09267)|null|
|**2024-05-15**|**Dance Any Beat: Blending Beats with Visuals in Dance Video Generation**|从音乐中生成舞蹈的任务至关重要，但由于需要精确的联合注释，目前主要产生联合序列的方法导致输出缺乏直观性，并使数据收集复杂化。我们介绍了一种Dance Any Beat Diffusion模型，即DabFusion，该模型使用音乐作为条件输入，利用条件图像到视频的生成原理，从静止图像直接创建舞蹈视频。这种方法开创了在图像到视频合成中使用音乐作为条件因子的先河。我们的方法分为两个阶段：训练自动编码器来预测参考帧和驱动帧之间的潜在光流，消除联合注释的需要，以及训练基于U-Net的扩散模型来产生由CLAP编码的音乐节奏引导的这些潜在光流。尽管能够制作高质量的舞蹈视频，但基线模型在节奏对齐方面很吃力。我们通过添加节拍信息来增强模型，提高同步性。我们介绍了一种用于定量评估的2D运动音乐对齐分数（2D-MM Align）。在AIST++数据集上进行评估后，我们的增强模型在2D-MM Align评分和已建立的指标方面显示出显著的改进。视频结果可以在我们的项目页面上找到：https://DabFusion.github.io. et.al.|[2405.09266](http://arxiv.org/abs/2405.09266)|null|
|**2024-05-15**|**Exact analysis of the two-dimensional asymmetric simple exclusion process with attachment and detachment of particles**|非对称简单排斥过程（ASEP）是一个范式驱动的扩散系统，描述了晶格中具有核心相互作用的粒子的非对称扩散。尽管ASEP是一个精确可解的模型，但大多数精确结果仅限于一维系统。最近，人们提出了多维ASEP中的精确稳态[1]。这项研究的重点是粒子数量守恒的情况。在本文中，我们考虑了具有粒子附着和分离的二维ASEP（ASEP-LK），其中粒子数守恒是违反的。利用参考文献[1]中的结果，我们构造了ASEP-LK的精确稳态，并通过物理量的精确计算揭示了其性质。 et.al.|[2405.09261](http://arxiv.org/abs/2405.09261)|null|
|**2024-05-15**|**Propagation of chaos for moderately interacting particle systems related to singular kinetic Mckean-Vlasov SDEs**|我们研究了一类中等相互作用粒子系统中混沌的传播，以近似α稳定过程驱动的奇异动力学McKean Vlasov SDE。扩散部分包括布朗（α=2）和纯跳跃（1<\alpha<2）扰动，在非光滑各向异性Besov空间中考虑相互作用核。使用Duhamel公式、sharp密度估计（最近发表在Hao、Rockner和Zhang 2023）和适当的鞅泛函不等式，我们获得了粒子系统的经验测度对McKean-Vlasov分布的收敛速度的直接估计。这些估计进一步导致了弱意义和强意义上的混沌结果的定量传播。 et.al.|[2405.09195](http://arxiv.org/abs/2405.09195)|null|
|**2024-05-15**|**QMedShield: A Novel Quantum Chaos-based Image Encryption Scheme for Secure Medical Image Storage in the Cloud**|在数字技术时代，医学图像在医疗保健行业发挥着至关重要的作用，帮助外科医生做出准确的决策并缩短诊断时间。然而，在第三方云服务中存储大量这些图像会引发隐私和安全问题。有很多经典的安全机制来保护它们。尽管如此，量子计算的出现需要开发用于医疗保健的基于量子的加密模型。因此，本文介绍了一种新的基于量子混沌的医学图像加密方案。该模型包括位平面加扰、量子逻辑图、扩散阶段的量子运算和混合混沌图、DNA编码以及混淆阶段的计算，以将普通医学图像转换为密码医学图像。所提出的方案已经使用多种统计指标进行了评估，并针对更多的攻击进行了验证，例如使用三个不同的医学数据集进行的差分攻击。因此，所引入的加密模型已被证明比其他现有的图像加密方案具有抗攻击性和鲁棒性，确保了医学图像在云环境中的安全存储。 et.al.|[2405.09191](http://arxiv.org/abs/2405.09191)|null|

<p align=right>(<a href=#updated-on-20240516>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-05-08**|**${M^2D}$NeRF: Multi-Modal Decomposition NeRF with 3D Feature Fields**|神经场（NeRF）已经成为表示连续3D场景的一种很有前途的方法。然而，NeRF中缺乏语义编码对场景分解提出了重大挑战。为了应对这一挑战，我们提出了一个单一的模型，即多模式分解NeRF（${M^2D}$ NeRF），它能够进行基于文本和基于视觉补丁的编辑。具体来说，我们使用多模态特征提取将来自预训练的视觉和语言模型的教师特征集成到3D语义特征体积中，从而促进一致的3D编辑。为了增强三维特征体积中视觉特征和语言特征之间的一致性，我们引入了多模态相似性约束。我们还引入了一种基于补丁的联合对比损失，这有助于鼓励对象区域在3D特征空间中合并，从而产生更精确的边界。与先前的基于NeRF的方法相比，在各种真实世界场景上的实验显示出在3D场景分解任务中的优越性能。 et.al.|[2405.05010](http://arxiv.org/abs/2405.05010)|null|
|**2024-05-09**|**Radar Fields: Frequency-Space Neural Scene Representations for FMCW Radar**|神经场作为再现和新一代各种户外场景的场景表示，包括自动驾驶汽车和机器人必须处理的场景，已经得到了广泛的研究。虽然存在RGB和激光雷达数据的成功方法，但雷达作为传感模式的神经重建方法在很大程度上尚未被探索。雷达传感器在毫米波长下工作，对雾和雨中的散射具有鲁棒性，因此为主动和被动光学传感技术提供了一种互补的方式。此外，现有的雷达传感器具有很高的成本效益，并广泛应用于户外作业的机器人和车辆中。我们介绍了雷达场——一种为有源雷达成像器设计的神经场景重建方法。我们的方法将一个明确的、基于物理的传感器模型与一个隐含的神经几何和反射模型相结合，直接合成原始雷达测量值并提取场景占用率。所提出的方法不依赖于体绘制。相反，我们在傅立叶频率空间中学习场，并用原始雷达数据进行监督。我们在不同的室外场景中验证了该方法的有效性，包括车辆和基础设施密集的城市场景，以及在毫米波长传感特别有利的恶劣天气场景中。 et.al.|[2405.04662](http://arxiv.org/abs/2405.04662)|null|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|现有的基于神经场的SLAM方法通常使用单个单片场作为其场景表示。这阻碍了循环闭合约束的有效结合，并限制了可扩展性。为了解决这些缺点，我们提出了一种神经映射框架，该框架将轻量级神经场锚定到稀疏视觉SLAM系统的姿态图上。我们的方法显示了整合大规模闭环的能力，同时限制了必要的重新融合。此外，我们通过在优化过程中考虑多个环路闭合来验证我们的方法的可扩展性，并证明我们的方法在质量和运行时间方面优于现有的最先进的方法。我们的代码可在https://kth-rpl.github.io/neural_graph_mapping/. et.al.|[2405.03633](http://arxiv.org/abs/2405.03633)|null|
|**2024-05-03**|**Simulation-based Inference of Developmental EEG Maturation with the Spectral Graph Model**|宏观神经活动的光谱内容在整个发育过程中不断演变，但这种成熟与潜在的大脑网络形成和动力学之间的关系尚不清楚。为了深入了解这一过程的机制，我们通过频谱图模型（SGM）的贝叶斯模型反演来评估发育脑电频谱变化，SGM是一种全脑空间频谱活动的简约模型，源于由结构连接体耦合的线性化神经场模型。基于模拟的推理用于从跨越发育期的脑电图频谱中估计年龄变化的SGM参数后验分布。我们发现，这种模型拟合方法通过关键神经参数的神经生物学一致进展准确地捕捉了脑电图频谱的发育成熟：长程耦合、轴突传导速度和兴奋性：抑制性平衡。这些结果表明，在正常发育过程中观察到的大脑活动的光谱成熟得到了功能适应的支持，特别是局部神经动力学的年龄依赖性调节及其在宏观结构网络中的长期耦合。 et.al.|[2405.02524](http://arxiv.org/abs/2405.02524)|null|
|**2024-04-30**|**Lightplane: Highly-Scalable Components for Neural 3D Fields**|当代3D研究，特别是在重建和生成方面，严重依赖2D图像进行输入或监督。然而，这些2D-3D映射的当前设计是内存密集型的，对现有方法构成了显著的瓶颈，并阻碍了新的应用。作为回应，我们为3D神经场提出了一对高度可扩展的组件：Lightplane Render和Splatter，这显著减少了2D-3D映射中的内存使用。这些创新能够以较小的内存和计算成本处理更多、更高分辨率的图像。我们展示了它们在各种应用中的实用性，从有利于图像级损失的单场景优化到实现用于大幅缩放3D重建和生成的多功能管道。代码：\url{https://github.com/facebookresearch/lightplane}. et.al.|[2404.19760](http://arxiv.org/abs/2404.19760)|**[link](https://github.com/facebookresearch/lightplane)**|
|**2024-05-03**|**Object Registration in Neural Fields**|神经场以一种对机器人应用具有巨大前景的方式提供3D几何结构和外观的连续场景表示。解锁机器人中神经领域独特用例的一个功能是对象6-DoF注册。在本文中，我们对最近的Reg-NF神经场配准方法及其在机器人环境中的用例进行了扩展分析。我们展示了使用场景和对象神经场模型确定场景中已知对象的6-DoF姿态的场景。我们展示了如何使用它来更好地表示未完全建模的场景中的对象，并通过将对象神经场模型替换到场景中来生成新的场景。 et.al.|[2404.18381](http://arxiv.org/abs/2404.18381)|null|
|**2024-04-26**|**ArtNeRF: A Stylized Neural Field for 3D-Aware Cartoonized Face Synthesis**|生成视觉模型和神经辐射领域的最新进展极大地促进了3D感知图像合成和风格化任务。然而，以前基于NeRF的工作仅限于单场景风格化，训练模型生成具有任意风格的3D感知卡通人脸仍然没有解决。为了解决这个问题，我们提出了ArtNeRF，这是一种从3D感知GAN中派生出来的新颖的人脸风格化框架。在这个框架中，我们利用表达生成器来合成风格化的人脸，并利用三分支鉴别器模块来提高生成人脸的视觉质量和风格一致性。具体而言，利用基于对比学习的风格编码器来提取风格图像的鲁棒低维嵌入，使生成器能够获得各种风格的知识。为了平滑跨领域迁移学习的训练过程，我们提出了一个自适应风格混合模块，该模块有助于注入风格信息，并允许用户自由调整风格化水平。我们进一步引入了一个神经渲染模块，以实现更高分辨率图像的高效实时渲染。大量实验表明，ArtNeRF在生成具有任意风格的高质量3D感知卡通人脸方面是通用的。 et.al.|[2404.13711](http://arxiv.org/abs/2404.13711)|**[link](https://github.com/silence-tang/artnerf)**|
|**2024-04-19**|**BANF: Band-limited Neural Fields for Levels of Detail Reconstruction**|主要由于其隐含性质，神经场缺乏直接的滤波机制，因为离散信号处理的傅立叶分析不直接适用于这些表示。神经场的有效滤波对于实现下游应用程序中的细节处理水平至关重要，并支持在规则网格上对场进行采样的操作（例如，行进立方体）。试图在频域中分解神经场的现有方法要么采用启发式方法，要么需要对神经场架构进行广泛修改。我们展示了通过一个简单的修改，可以获得低通滤波的神经场，进而展示了如何利用这一点来获得整个信号的频率分解。我们通过研究细节水平重建来证明我们的技术的有效性，并展示了如何有效地计算粗糙的表示。 et.al.|[2404.13024](http://arxiv.org/abs/2404.13024)|null|
|**2024-04-15**|**Efficient and accurate neural field reconstruction using resistive memory**|人类通过将稀疏的观测整合到大规模互连的突触和神经元中来构建空间感知，提供了卓越的并行性和效率。在人工智能中复制这一能力在医学成像、AR/VR和嵌入式人工智能中有着广泛的应用，在这些领域，输入数据往往是稀疏的，计算资源有限。然而，传统的数字计算机信号重构方法面临着软硬件两方面的挑战。在软件方面，传统显式信号表示中的存储效率低下会带来困难。硬件障碍包括冯·诺依曼瓶颈，它限制了CPU和存储器之间的数据传输，以及CMOS电路在支持并行处理方面的局限性。我们提出了一种软硬件协同优化的系统方法，用于从稀疏输入重建信号。在软件方面，我们使用神经场通过神经网络隐式地表示信号，并使用低秩分解和结构化修剪对其进行进一步压缩。在硬件方面，我们设计了一个基于电阻存储器的内存计算（CIM）平台，该平台具有高斯编码器（GE）和MLP处理引擎（PE）。GE利用电阻存储器的内在随机性进行有效的输入编码，而PE通过硬件感知量化（HAQ）电路实现精确的权重映射。我们在基于40nm 256Kb电阻存储器的内存内计算宏上展示了该系统的功效，在不影响3D CT稀疏重建、新视图合成和动态场景新视图合成等任务的重建质量的情况下，实现了巨大的能效和并行性改进。这项工作推进了人工智能驱动的信号恢复技术，为未来高效、稳健的医疗人工智能和3D视觉应用铺平了道路。 et.al.|[2404.09613](http://arxiv.org/abs/2404.09613)|null|
|**2024-04-10**|**Ray-driven Spectral CT Reconstruction Based on Neural Base-Material Fields**|在谱CT重建中，基底材料分解涉及求解大规模非线性积分方程组，这在数学上是高度不适定的。本文提出了一种模型，该模型使用神经场表示来参数化对象的衰减系数，从而避免了线积分离散化过程中像素驱动的投影系数矩阵的复杂计算。介绍了一种基于光线驱动神经场的线积分轻量级离散化方法，提高了离散化过程中积分逼近的精度。将基底材料表示为连续的向量值隐函数，以建立基底材料的神经场参数化模型。然后使用深度学习的自动微分框架来求解神经基底材料场的隐式连续函数。该方法不受重建图像空间分辨率的限制，并且网络具有紧凑和规则的特性。实验验证表明，我们的方法在处理光谱CT重建方面表现得非常好。此外，它还满足了生成高分辨率重建图像的要求。 et.al.|[2404.06991](http://arxiv.org/abs/2404.06991)|null|

<p align=right>(<a href=#updated-on-20240516>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

