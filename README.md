[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2026.01.15
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#video-diffusion>Video Diffusion</a></li>
    <li><a href=#3d>3D</a></li>
    <li><a href=#具生智能&自动驾驶>具生智能&自动驾驶</a></li>
  </ol>
</details>

## Video Diffusion

- **2026-01-14** **Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering** [2601.09697](http://arxiv.org/abs/2601.09697)
  > 基于扩散模型的现代视频生成模型可以生成非常逼真的剪辑，但它们的计算效率较低，通常需要几分钟的 GPU 时间来处理几秒钟的视频。这种低效率对在需要实时交互的应用程序（例如嵌入式 AI 和 VR/AR）中部署生成视频构成了关键障碍。本文探索了一种静态场景相机条件视频生成的新策略：使用基于扩散的生成模型生成一组稀疏关键帧，然后通过 3D 重建和渲染合成完整视频。通过将关键帧提升为 3D 表示并渲染中间视图，我们的方法可以在数百个帧之间分摊生成成本，同时强制几何一致性。我们进一步引入了一个模型，可以预测给定相机轨迹的最佳关键帧数量，从而允许系统自适应地分配计算。我们的最终方法 SRENDER 使用非常稀疏的关键帧来表示简单的轨迹，使用更密集的关键帧来表示复杂的相机运动。这使得视频生成速度比基于扩散的基线快 40 倍以上，生成 20 秒的视频，同时保持高视觉保真度和时间稳定性，为高效、可控的视频合成提供了一条实用途径。

- **2026-01-14** **MAD: Motion Appearance Decoupling for efficient Driving World Models** [2601.09452](http://arxiv.org/abs/2601.09452)
  > 最近的视频扩散模型生成逼真、时间连贯的视频，但它们不足以作为自动驾驶的可靠世界模型，其中结构化运动和物理一致的交互至关重要。将这些通用视频模型适应驱动领域已显示出希望，但通常需要大量特定领域的数据和昂贵的微调。我们提出了一种有效的适应框架，可以将通用视频扩散模型转换为具有最少监督的可控驾驶世界模型。关键思想是将运动学习与外观合成分离。首先，该模型适用于以简化形式预测结构化运动：骨架代理和场景元素的视频，重点学习物理和社会的合理性。然后，重复使用相同的主干来合成以这些运动序列为条件的逼真的 RGB 视频，有效地用纹理和照明“修饰”运动。这个两阶段过程反映了推理渲染范例：首先推断动态，然后渲染外观。我们的实验表明，这种解耦方法非常高效：采用 SVD，我们可以用不到 6% 的计算量来匹配之前的 SOTA 模型。扩展到 LTX，我们的 MAD-LTX 模型优于所有开源竞争对手，并支持一整套文本、自我和对象控制。项目页面：https://vita-epfl.github.io/MAD-World-Model/

- **2026-01-14** **PhyRPR: Training-Free Physics-Constrained Video Generation** [2601.09255](http://arxiv.org/abs/2601.09255)
  > 最近基于扩散的视频生成模型可以合成视觉上合理的视频，但它们往往难以满足物理限制。一个关键原因是大多数现有方法仍然是单阶段的：它们将高级物理理解与低级视觉合成纠缠在一起，使得很难生成需要显式物理推理的内容。为了解决这个限制，我们提出了一种免训练的三阶段管道，\textit{PhyRPR}:\textit{Phy\uline{R}eason}--\textit{Phy\uline{P}lan}--\textit{Phy\uline{R}efine}，它将物理理解与视觉合成分离。具体来说，\textit{PhyReason} 使用大型多模态模型进行物理状态推理，并使用图像生成器进行关键帧合成； \textit{PhyPlan} 确定性地合成一个可控的粗运动支架； \textit{PhyRefine} 通过潜在融合策略将该支架注入扩散采样中，以细化外观，同时保留计划的动态。这种分阶段设计可以在生成过程中实现明确的物理控制。在物理限制下的大量实验表明，我们的方法不断提高物理合理性和运动可控性。

- **2026-01-13** **Motion Attribution for Video Generation** [2601.08828](http://arxiv.org/abs/2601.08828)
  > 尽管视频生成模型取得了快速进展，但人们对数据在影响运动中的作用却知之甚少。我们提出了 Motive（视频生成的 MOTIon 归因），这是一种以运动为中心、基于梯度的数据归因框架，可扩展到现代、大型、高质量的视频数据集和模型。我们用它来研究哪些微调剪辑可以改善或降低时间动态。 Motive 通过运动加权损失掩模将时间动态与静态外观隔离，从而产生高效且可扩展的运动特定影响计算。在文本到视频模型上，Motive 可以识别强烈影响运动的剪辑，并指导数据管理，从而提高时间一致性和物理合理性。利用Motive选择的高影响力数据，我们的方法提高了VBench上的运动平滑度和动态程度，与预训练的基础模型相比，实现了74.1%的人类偏好获胜率。据我们所知，这是第一个在视频生成模型中归因于运动而不是视觉外观并使用它来管理微调数据的框架。

- **2026-01-14** **MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head** [2601.07832](http://arxiv.org/abs/2601.07832)
  > 虽然 Transformer 架构在许多领域占据主导地位，但其二次自注意力复杂性阻碍了其在大规模应用中的使用。线性注意力提供了一种有效的替代方案，但其直接应用通常会降低性能，现有的修复通常会通过额外的模块（例如深度可分离卷积）重新引入计算开销，从而违背了最初的目的。在这项工作中，我们确定了这些方法中的一个关键失败模式：全局上下文崩溃，其中模型失去了表征多样性。为了解决这个问题，我们提出了多头线性注意力（MHLA），它通过沿着令牌维度计算分割头内的注意力来保留这种多样性。我们证明 MHLA 保持了线性复杂度，同时恢复了 Softmax Attention 的大部分表达能力，并验证了其在多个领域的有效性，在相同时间复杂度下，在 ImageNet 分类上实现了 3.6\% 的改进，在 NLP 上实现了 6.3\% 的增益，在图像生成上实现了 12.6\% 的改进，在视频生成上实现了 41\% 的增强。

- **2026-01-12** **Video Generation Models in Robotics -- Applications, Research Challenges, Future Directions** [2601.07823](http://arxiv.org/abs/2601.07823)
  > 视频生成模型已经成为物理世界的高保真模型，能够合成高质量视频，捕捉代理与其环境之间的细粒度交互，这些交互取决于多模式用户输入。它们令人印象深刻的功能解决了基于物理的模拟器面临的许多长期挑战，推动了许多问题领域的广泛采用，例如机器人技术。例如，视频模型可以实现逼真、物理一致的变形体模拟，而无需做出令人望而却步的简化假设，这是基于物理的模拟的主要瓶颈。此外，视频模型可以作为基础世界模型，以细粒度和富有表现力的方式捕捉世界的动态。因此，它们在描述复杂的物理交互时克服了纯语言抽象的有限表达能力。在本次调查中，我们回顾了视频模型及其在机器人技术中作为具体世界模型的应用，包括模仿学习中具有成本效益的数据生成和动作预测、强化学习中的动态和奖励建模、视觉规划和政策评估。此外，我们强调了阻碍视频模型在机器人技术中可靠集成的重要挑战，其中包括指令遵循不佳、违反物理等幻觉以及不安全的内容生成，以及重要的数据管理、培训和推理成本等基本限制。我们提出了解决这些开放研究挑战的潜在未来方向，以激励研究并最终促进更广泛的应用，特别是在安全关键的环境中。

- **2026-01-12** **StdGEN++: A Comprehensive System for Semantic-Decomposed 3D Character Generation** [2601.07660](http://arxiv.org/abs/2601.07660)
  > 我们推出了 StdGEN++，这是一种新颖且全面的系统，用于从不同的输入生成高保真、语义分解的 3D 角色。现有的 3D 生成方法通常会生成整体网格，缺乏游戏和动画工业管道所需的结构灵活性。为了解决这一差距，StdGEN++ 建立在双分支语义感知大型重建模型（双分支 S-LRM）的基础上，该模型以前馈方式联合重建几何、颜色和每个组件的语义。为了实现生产级保真度，我们引入了一种与混合隐式字段兼容的新颖的语义表面提取形式。该机制通过从粗到细的提议方案来加速，从而显着减少内存占用并实现高分辨率网格生成。此外，我们提出了一种基于视频扩散的纹理分解模块，将外观分解为可编辑层（例如，分离的虹膜和皮肤），解决面部区域的语义混淆。实验表明，StdGEN++ 实现了最先进的性能，在几何精度和语义解缠方面显着优于现有方法。至关重要的是，由此产生的结构独立性解锁了先进的下游功能，包括无损编辑、符合物理的动画和视线跟踪，使其成为自动化角色资产生产的强大解决方案。

- **2026-01-12** **Forecast the Principal, Stabilize the Residual: Subspace-Aware Feature Caching for Efficient Diffusion Transformers** [2601.07396](http://arxiv.org/abs/2601.07396)
  > 扩散变压器 (DiT) 模型在图像和视频生成方面取得了前所未有的质量，但其迭代采样过程在计算上仍然令人望而却步。为了加速推理，通过跨时间步重用中间表示出现了特征缓存方法。然而，现有的缓存方法统一处理所有特征组件。我们揭示了 DiT 特征空间包含不同的主子空间和残差子空间，具有不同的时间行为：主子空间平稳且可预测地演化，而残差子空间表现出不稳定的低能量振荡，难以准确预测。基于这一见解，我们提出了 SVD-Cache，这是一种子空间感知的缓存框架，它通过奇异值分解（SVD）分解扩散特征，将指数移动平均（EMA）预测应用于主要的低秩分量，并直接重用残差子空间。大量的实验表明，SVD-Cache 在不同的模型和方法中实现了近乎无损的效果，包括在 FLUX 和 HunyuanVideo 上实现了 5.55 $\times$ 的加速，以及与蒸馏、量化和稀疏注意力等模型加速技术的兼容性。我们的代码位于补充材料中，并将在 Github 上发布。

- **2026-01-12** **Focal Guidance: Unlocking Controllability from Semantic-Weak Layers in Video Diffusion Models** [2601.07287](http://arxiv.org/abs/2601.07287)
  > 图像到视频（I2V）生成的任务旨在根据参考图像和文本提示合成视频。这需要扩散模型在去噪过程中协调高频视觉约束和低频文本指导。然而，虽然现有的 I2V 模型优先考虑视觉一致性，但如何有效地结合这种双重指导以确保严格遵守文本提示仍有待探索。在这项工作中，我们观察到，在基于扩散变压器 (DiT) 的 I2V 模型中，某些中间层表现出弱语义响应（称为语义弱层），如文本视觉相似性可测量的下降所示。我们将此归因于一种称为“条件隔离”的现象，即对视觉特征的注意力部分脱离文本指导，并过度依赖学习的视觉先验。为了解决这个问题，我们提出了焦点引导（FG），它增强了语义弱层的可控性。 FG 包括两种机制：（1）细粒度语义引导（FSG）利用 CLIP 来识别参考框架中的关键区域，并将它们用作锚点来指导语义弱层。 （2）注意力缓存将注意力图从语义响应层转移到语义弱层，注入显式语义信号并减轻它们对模型学习的视觉先验的过度依赖，从而增强对文本指令的遵守。为了进一步验证我们的方法并解决这方面缺乏评估的问题，我们引入了一个用于评估 I2V 模型中指令遵循的基准。在此基准测试中，Focal Guidance 证明了其有效性和普适性，将 Wan2.1-I2V 的总分提升至 0.7250 (+3.97\%)，并将基于 MMDiT 的 HunyuanVideo-I2V 提升至 0.5571 (+7.44\%)。

- **2026-01-10** **Object-WIPER : Training-Free Object and Associated Effect Removal in Videos** [2601.06391](http://arxiv.org/abs/2601.06391)
  > 在本文中，我们介绍了 Object-WIPER，这是一个免训练框架，用于从视频中删除动态对象及其相关的视觉效果，并用语义一致和时间连贯的内容修复它们。我们的方法利用预先训练的文本到视频扩散转换器（DiT）。给定输入视频、用户提供的对象掩码以及描述目标对象及其效果的查询标记，我们通过视觉文本交叉注意和视觉自注意来定位相关的视觉标记。这会产生一个中间效果掩码，我们将其与用户掩码融合以获得要替换的最终前景标记掩码。我们首先通过 DiT 反转视频以获得结构化噪声，然后用高斯噪声重新初始化屏蔽标记，同时保留背景标记。在去噪过程中，我们复制反转过程中保存的背景标记的值，以保持场景保真度。为了解决缺乏适当评估的问题，我们引入了一种新的对象删除指标，该指标奖励连续帧中前景标记之间的时间一致性、每帧内前景和背景标记之间的一致性以及输入和输出前景标记之间的相异性。 DAVIS 和新策划的现实世界关联效应基准 (WIPER-Bench) 上的实验表明，Object-WIPER 在指标方面超越了基于训练和无训练的基线，无需任何再训练即可实现干净的去除和时间稳定的重建。我们的新基准、源代码和预训练模型将公开。

- **2026-01-09** **Perception Test 2025: Challenge Summary and a Unified VQA Extension** [2601.06287](http://arxiv.org/abs/2601.06287)
  > 第三次感知测试挑战赛是与 IEEE/CVF 国际计算机视觉会议 (ICCV) 2025 同期举办的全天研讨会。其主要目标是对最先进的视频模型进行基准测试并衡量多模态感知的进展。今年，研讨会还有 2 个客座曲目：KiVA（图像理解挑战）和 Physic-IQ（视频生成挑战）。在本报告中，我们总结了主要感知测试挑战的结果，详细介绍了现有任务以及基准测试的新增内容。在本次迭代中，我们强调任务统一，因为这对当前的 SOTA 多模态模型提出了更具挑战性的测试。该挑战包括五个综合轨道：统一视频 QA、统一对象和点跟踪、统一动作和声音本地化、接地视频 QA 和长达一小时的视频 QA，以及仍可供提交的分析和可解释性轨道。值得注意的是，统一视频 QA 轨道引入了一个新颖的子集，它将传统的感知任务（例如点跟踪和时间动作定位）重新表述为视频语言模型可以本地解决的多项选择视频 QA 问题。统一的对象和点跟踪合并了原始的对象跟踪和点跟踪任务，而统一的动作和声音定位合并了原始的时间动作定位和时间声音定位轨道。因此，我们要求竞争对手使用统一的方法，而不是使用特定于任务的模型来设计管道。通过提出这样一个统一的挑战，Perception Test 2025 强调了现有模型在通过统一接口处理不同感知任务时面临的重大困难。

- **2026-01-09** **VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction** [2601.05966](http://arxiv.org/abs/2601.05966)
  > 视频生成领域的最新进展主要由扩散和流匹配模型主导，这些模型可以产生高质量的结果，但计算量仍然很大且难以扩展。在这项工作中，我们介绍了 VideoAR，这是第一个用于视频生成的大规模视觉自回归 (VAR) 框架，它将多尺度下一帧预测与自回归建模相结合。 VideoAR 通过将帧内 VAR 建模与因果下一帧预测相集成，消除了空间和时间依赖性，并由可有效编码时空动态的 3D 多尺度分词器支持。为了提高长期一致性，我们提出了多尺度时间 RoPE、跨帧纠错和随机帧掩模，它们共同减轻了错误传播并稳定了时间相干性。我们的多阶段预训练管道逐步调整空间和时间学习，以提高分辨率和持续时间。根据经验，VideoAR 在自回归模型中取得了最先进的结果，将 UCF-101 上的 FVD 从 99.5 提高到 88.6，同时将推理步骤减少了 10 倍以上，并达到了 81.74 的 VBench 分数，与基于扩散的模型相比要高出一个数量级。这些结果表明，VideoAR 缩小了自回归和扩散范式之间的性能差距，为未来的视频生成研究提供了可扩展、高效且时间一致的基础。

- **2026-01-09** **Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals** [2601.05848](http://arxiv.org/abs/2601.05848)
  > 视频生成领域的最新进展使得能够模拟机器人和规划的潜在未来的“世界模型”的开发成为可能。然而，为这些模型指定精确的目标仍然是一个挑战；文本指令通常过于抽象，无法捕捉物理细微差别，而目标图像通常无法为动态任务指定。为了解决这个问题，我们引入了 Goal Force，这是一种新颖的框架，允许用户通过明确的力向量和中间动力学来定义目标，反映了人类如何概念化物理任务。我们在合成因果原语（例如弹性碰撞和倒下的多米诺骨牌）的精选数据集上训练视频生成模型，教导它通过时间和空间传播力。尽管接受了简单物理数据的训练，但我们的模型对复杂的现实世界场景（包括工具操作和多对象因果链）表现出出色的零样本泛化能力。我们的结果表明，通过将视频生成基于基本的物理交互，模型可以作为隐式神经物理模拟器出现，从而无需依赖外部引擎即可实现精确的物理感知规划。我们在项目页面发布了所有数据集、代码、模型权重和交互式视频演示。

- **2026-01-09** **TAGRPO: Boosting GRPO on Image-to-Video Generation with Direct Trajectory Alignment** [2601.05729](http://arxiv.org/abs/2601.05729)
  > 最近的研究证明了将组相对策略优化（GRPO）集成到流匹配模型中的有效性，特别是对于文本到图像和文本到视频的生成。然而，我们发现直接将这些技术应用于图像到视频（I2V）模型通常无法产生一致的奖励改进。为了解决这个限制，我们提出了 TAGRPO，这是一个受对比学习启发的强大的 I2V 模型训练后框架。我们的方法基于这样的观察：从相同的初始噪声生成的推出视频为优化提供了卓越的指导。利用这一见解，我们提出了一种应用于中间潜伏的新型 GRPO 损失，鼓励与高奖励轨迹直接对齐，同时最大化与低奖励对应轨迹的距离。此外，我们引入了用于展示视频的内存库，以增强多样性并减少计算开销。尽管很简单，但 TAGRPO 在 I2V 生成方面比 DanceGRPO 实现了显着改进。

- **2026-01-09** **Rotate Your Character: Revisiting Video Diffusion Models for High-Quality 3D Character Generation** [2601.05722](http://arxiv.org/abs/2601.05722)
  > 从单个图像生成高质量的 3D 角色仍然是数字内容创建中的一项重大挑战，特别是由于复杂的身体姿势和自遮挡。在本文中，我们介绍了 RCM（旋转角色模型），这是一种高级图像到视频扩散框架，专为高质量小说视图合成 (NVS) 和 3D 角色生成而定制。与现有的基于扩散的方法相比，RCM 具有几个关键优势：(1) 将具有任何复杂姿势的角色转换为规范姿势，从而在整个观看轨道上实现一致的新颖视图合成；(2) 生成 1024x1024 分辨率的高分辨率轨道视频；(3) 给定不同的初始相机姿势，可控制观察位置；(4) 多视图调节支持最多 4 个输入图像，适应不同的用户场景。大量实验表明，RCM 在新颖的视图合成和 3D 生成质量方面均优于最先进的方法。

- **2026-01-09** **GaussianSwap: Animatable Video Face Swapping with 3D Gaussian Splatting** [2601.05511](http://arxiv.org/abs/2601.05511)
  > 我们引入了 GaussianSwap，一种新颖的视频人脸交换框架，它从目标视频构建基于 3D 高斯 Splatting 的人脸头像，同时将身份从源图像转移到头像。传统的视频交换框架仅限于生成基于像素的格式的面部表示。由此产生的交换面仅作为一组非结构化像素存在，没有任何动画或交互操作的能力。我们的工作引入了从传统的基于像素的视频生成到创建具有交换面孔的高保真头像的范式转变。该框架首先对目标视频进行预处理，以提取 FLAME 参数、相机姿势和分割蒙版，然后将 3D 高斯分布跨帧绑定到 FLAME 模型，从而实现动态面部控制。为了确保身份保留，我们提出了一种由三种最先进的人脸识别模型构建的复合身份嵌入，用于头像微调。最后，我们将换脸头像渲染在背景帧上，得到换脸视频。实验结果表明，GaussianSwap 实现了卓越的身份保留、视觉清晰度和时间一致性，同时实现了以前无法实现的交互式应用程序。


<p align=right>(<a href=#updated-on-20260115>back to top</a>)</p>

## 3D

- **2026-01-14** **Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering** [2601.09697](http://arxiv.org/abs/2601.09697)
  > 基于扩散模型的现代视频生成模型可以生成非常逼真的剪辑，但它们的计算效率较低，通常需要几分钟的 GPU 时间来处理几秒钟的视频。这种低效率对在需要实时交互的应用程序（例如嵌入式 AI 和 VR/AR）中部署生成视频构成了关键障碍。本文探索了一种静态场景相机条件视频生成的新策略：使用基于扩散的生成模型生成一组稀疏关键帧，然后通过 3D 重建和渲染合成完整视频。通过将关键帧提升为 3D 表示并渲染中间视图，我们的方法可以在数百个帧之间分摊生成成本，同时强制几何一致性。我们进一步引入了一个模型，可以预测给定相机轨迹的最佳关键帧数量，从而允许系统自适应地分配计算。我们的最终方法 SRENDER 使用非常稀疏的关键帧来表示简单的轨迹，使用更密集的关键帧来表示复杂的相机运动。这使得视频生成速度比基于扩散的基线快 40 倍以上，生成 20 秒的视频，同时保持高视觉保真度和时间稳定性，为高效、可控的视频合成提供了一条实用途径。

- **2026-01-14** **Two continuous extensions of the Neural Approximated Virtual Element Method** [2601.09595](http://arxiv.org/abs/2601.09595)
  > 我们提出了神经近似虚拟元素方法 (NAVEM) 的两种基于全局连续神经的变体，称为 B-NAVEM 和 P-NAVEM。两种方法都使用预先训练的完全连接的神经网络构建局部基函数，同时确保相邻网格元素之间的精确连续性。 B-NAVEM 利用物理信息神经网络来近似解决定义虚拟单元基函数的局部拉普拉斯问题，而 P-NAVEM 通过定制的损失函数直接强制多项式可再现性，而不需要单元内部的和谐性。数值实验从训练和测试阶段的计算成本、内存使用和准确性方面评估这些方法。

- **2026-01-14** **OpenVoxel: Training-Free Grouping and Captioning Voxels for Open-Vocabulary 3D Scene Understanding** [2601.09575](http://arxiv.org/abs/2601.09575)
  > 我们提出了 OpenVoxel，这是一种免训练算法，用于对开放词汇 3D 场景理解任务的稀疏体素进行分组和描述。考虑到从 3D 场景的多视图图像获得的稀疏体素光栅化 (SVR) 模型，我们的 OpenVoxel 能够生成描述场景中不同对象的有意义的组。此外，通过利用强大的视觉语言模型 (VLM) 和多模态大语言模型 (MLLM)，我们的 OpenVoxel 通过为每个组添加字幕，成功构建了信息丰富的场景图，从而实现了进一步的 3D 场景理解任务，例如开放词汇分割 (OVS) 或引用表达分割 (RES)。与以前的方法不同，我们的方法无需训练，并且不会引入来自 CLIP/BERT 文本编码器的嵌入。相反，我们直接使用 MLLM 进行文本到文本搜索。通过大量的实验，我们的方法表现出了比最近的研究更优越的性能，特别是在复杂的引用表达分割（RES）任务中。代码将被公开。

- **2026-01-14** **SlidesGen-Bench: Evaluating Slides Generation via Computational and Quantitative Metrics** [2601.09487](http://arxiv.org/abs/2601.09487)
  > 大型语言模型 (LLM) 的快速发展催生了自动幻灯片生成的多种范式，从代码驱动的布局到以图像为中心的合成。然而，评估这些异构系​​统仍然具有挑战性，因为现有协议通常难以提供跨架构的可比分数或依赖于未经校准的判断。在本文中，我们介绍了 SlidesGen-Bench，这是一个旨在通过三个核心原则（通用性、量化和可靠性）评估幻灯片生成的基准。首先，为了建立统一的评估框架，我们将分析立足于视觉领域，将终端输出视为渲染，以保持与底层生成方法无关。其次，我们提出了一种计算方法，可以跨三个不同的维度（内容、美学和可编辑性）定量评估幻灯片，提供可重复的指标，而先前的工作依赖于主观或依赖于参考的代理。最后，为了确保与人类偏好的高度相关性，我们构建了 Slides-Align1.5k 数据集，这是一个人类偏好一致的数据集，涵盖来自七种场景的九种主流生成系统的幻灯片。我们的实验表明，与现有的评估流程相比，SlidesGen-Bench 与人类判断的一致性更高。我们的代码和数据可在 https://github.com/YunqiaoYang/SlidesGen-Bench 获取。

- **2026-01-14** **MAD: Motion Appearance Decoupling for efficient Driving World Models** [2601.09452](http://arxiv.org/abs/2601.09452)
  > 最近的视频扩散模型生成逼真、时间连贯的视频，但它们不足以作为自动驾驶的可靠世界模型，其中结构化运动和物理一致的交互至关重要。将这些通用视频模型适应驱动领域已显示出希望，但通常需要大量特定领域的数据和昂贵的微调。我们提出了一种有效的适应框架，可以将通用视频扩散模型转换为具有最少监督的可控驾驶世界模型。关键思想是将运动学习与外观合成分离。首先，该模型适用于以简化形式预测结构化运动：骨架代理和场景元素的视频，重点学习物理和社会的合理性。然后，重复使用相同的主干来合成以这些运动序列为条件的逼真的 RGB 视频，有效地用纹理和照明“修饰”运动。这个两阶段过程反映了推理渲染范例：首先推断动态，然后渲染外观。我们的实验表明，这种解耦方法非常高效：采用 SVD，我们可以用不到 6% 的计算量来匹配之前的 SOTA 模型。扩展到 LTX，我们的 MAD-LTX 模型优于所有开源竞争对手，并支持一整套文本、自我和对象控制。项目页面：https://vita-epfl.github.io/MAD-World-Model/

- **2026-01-14** **Variable Basis Mapping for Real-Time Volumetric Visualization** [2601.09417](http://arxiv.org/abs/2601.09417)
  > 大规模体数据的实时可视化仍然具有挑战性，因为直接体渲染和基于体素的方法的计算成本过高。我们提出了可变基映射 (VBM)，这是一个通过小波域分析将体积场转换为 3D 高斯分布 (3DGS) 表示的框架。首先，我们预先计算一个紧凑的小波到高斯转换库，它为跨多个尺度的规范小波原子提供最佳高斯代理。其次，我们执行分析高斯构造，使用封闭形式的数学原理规则将离散小波系数直接映射到 3DGS 参数。最后，轻量级图像空间微调阶段进一步细化表示以提高渲染保真度。对不同数据集的实验表明，VBM 显着加速了收敛速度并提高了渲染质量，从而实现了实时体积可视化。

- **2026-01-14** **AI-NativeBench: An Open-Source White-Box Agentic Benchmark Suite for AI-Native Systems** [2601.09393](http://arxiv.org/abs/2601.09393)
  > 从云原生架构到人工智能原生架构的转变从根本上重塑了软件工程，用概率代理服务取代了确定性微服务。然而，这种转变使得传统的黑盒评估范例变得不够：现有的基准测试衡量原始模型的能力，但对系统级执行动态仍然视而不见。为了弥补这一差距，我们推出了 AI-NativeBench，这是第一个以应用程序为中心的白盒 AI-Native 基准套件，基于模型上下文协议 (MCP) 和代理到代理 (A2A) 标准。通过将代理跨度视为分布式跟踪中的一等公民，我们的方法可以对超出简单功能的工程特征进行精细分析。利用跨 21 个系统变体的基准测试，我们发现了传统指标中看不见的关键工程现实：参数悖论，其中轻量级模型在协议遵守方面常常超越旗舰，普遍的推理主导地位使协议开销成为次要，以及昂贵的故障模式，其中自我修复机制矛盾地充当了不可行的工作流程的成本乘数。这项工作提供了第一个系统证据来指导从测量模型能力到设计可靠的 AI-Native 系统的转变。为了促进可重复性和进一步研究，我们开源了基准和数据集。

- **2026-01-14** **GaussianFluent: Gaussian Simulation for Dynamic Scenes with Mixed Materials** [2601.09265](http://arxiv.org/abs/2601.09265)
  > 3D 高斯泼溅 (3DGS) 已成为高保真和实时渲染的重要 3D 表示形式。先前的工作将物理模拟与高斯耦合，但主要针对柔软的可变形材料，脆性断裂在很大程度上尚未得到解决。这源于两个关键障碍：GS 表示中缺乏具有连贯纹理的体积内部，以及缺乏高斯的断裂感知模拟方法。为了解决这些挑战，我们引入了 GaussianFluent，一个用于动态对象状态的真实模拟和渲染的统一框架。首先，它通过在生成模型的指导下致密内部高斯来合成照片级真实感的内部空间。其次，它集成了优化的连续损伤材料点法 (CD-MPM)，能够以非常高的速度进行脆性断裂模拟。我们的方法可以处理复杂的场景，包括混合材料物体和多级断裂扩展，实现了以前方法无法实现的结果。实验清楚地证明了 GaussianFluent 具有照片级真实感、实时渲染和内部结构一致的能力，凸显了其在 VR 和机器人等下游应用中的潜力。

- **2026-01-14** **A $^2$ TG: Adaptive Anisotropic Textured Gaussians for Efficient 3D Scene Representation** [2601.09243](http://arxiv.org/abs/2601.09243)
  > 高斯泼溅已成为高质量、实时 3D 场景渲染的强大表现形式。虽然最近的工作使用可学习的纹理扩展高斯以丰富视觉外观，但现有的方法为每个图元分配固定的方形纹理，导致内存使用效率低下，并且对场景变化的适应性有限。在本文中，我们介绍了自适应各向异性纹理高斯（A $^2$ TG），这是一种通过为每个图元配备各向异性纹理来概括纹理高斯的新颖表示形式。我们的方法采用梯度引导的自适应规则来共同确定纹理分辨率和纵横比，从而实现与高斯图的各向异性性质相一致的非均匀、细节感知的分配。这种设计显着提高了纹理效率，减少了内存消耗，同时增强了图像质量。对多个基准数据集的实验表明，TG 始终优于固定纹理高斯泼溅方法，以显着降低的内存需求实现了可比的渲染保真度。

- **2026-01-14** **Affostruction: 3D Affordance Grounding with Generative Reconstruction** [2601.09211](http://arxiv.org/abs/2601.09211)
  > 本文解决了物体 RGBD 图像的可供性基础问题，其目的是定位与描述物体上的动作的文本查询相对应的表面区域。虽然现有方法仅预测可见表面上的可供性区域，但我们提出了 Affostruction，这是一种生成框架，可以根据部分观察重建完整的几何形状，并在包括未观察到的区域在内的完整形状上提供可供性。我们做出了三个核心贡献：通过稀疏体素融合进行生成多视图重建，推断出不可见的几何形状，同时保持恒定的标记复杂性；基于流的可供性基础，捕获可供性分布中固有的模糊性；可供性驱动的主动视图选择，利用预测可供性进行智能视点采样。 Affostruction 在可供性基础上达到 19.1 aIoU（提高 40.4%），在 3D 重建方面达到 32.67 IoU（提高 67.7%），从而能够对完整形状进行准确的可供性预测。

- **2026-01-13** **RAVEN: Erasing Invisible Watermarks via Novel View Synthesis** [2601.08832](http://arxiv.org/abs/2601.08832)
  > 隐形水印已成为验证人工智能生成的图像内容的关键机制，各大平台都大规模部署水印方案。然而，评估这些方案针对复杂的删除攻击的脆弱性对于评估其可靠性和指导稳健的设计仍然至关重要。在这项工作中，我们通过将水印去除重新表述为视图合成问题，揭示了不可见水印的基本漏洞。我们的主要见解是，生成相同语义内容的感知一致的替代视图，类似于从不同的角度重新观察场景，自然地删除嵌入的水印，同时保持视觉保真度。这揭示了一个关键的差距：对像素空间和频域攻击具有鲁棒性的水印仍然容易受到语义保留视点转换的影响。我们引入了一种基于零样本扩散的框架，该框架在潜在空间中应用受控几何变换，并通过视图引导的对应注意进行增强，以在重建过程中保持结构一致性。我们的方法在没有检测器访问或水印知识的情况下在冻结的预训练模型上运行，在 15 种水印方法中实现了最先进的水印抑制，优于 14 种基线攻击，同时在多个数据集上保持卓越的感知质量。

- **2026-01-13** **Adaptive Requesting in Decentralized Edge Networks via Non-Stationary Bandits** [2601.08760](http://arxiv.org/abs/2601.08760)
  > 我们研究了一个去中心化协作请求问题，旨在优化由多个客户端、接入节点（AN）和服务器组成的边缘网络中时间敏感客户端的信息新鲜度。客户端通过充当网关的 AN 请求内容，而无需观察 AN 状态或其他客户端的操作。我们将奖励定义为客户选择 AN 所导致的信息减少的年龄，并将问题表述为非平稳多臂老虎机。在这种去中心化且部分可观察的环境中，所产生的奖励过程依赖于历史并且在客户之间耦合，并且预期奖励表现出突然和逐渐的变化，使得基于强盗的经典方法无效。为了应对这些挑战，我们提出了带有自适应重置的老化强盗算法，该算法将自适应窗口与定期监控相结合，以跟踪不断变化的奖励分布。我们建立了理论性能保证，表明所提出的算法实现了接近最优的性能，并通过模拟验证了理论结果。

- **2026-01-13** **Convergence analysis and adaptive computation of a Banach-space mixed finite element method for generalized bioconvective flows** [2601.08759](http://arxiv.org/abs/2601.08759)
  > 我们开发并分析了一种用于稳态广义生物对流的自适应完全混合有限元方法，其中具有浓度依赖性粘度的纳维-斯托克斯方程与游动微生物的守恒定律相结合。该公式引入了辅助变量，包括无痕速度梯度、对称伪应力张量、浓度梯度和半平流微生物通量，这也允许对 Robin 型边界条件进行一致处理。变分问题在 Banach 空间框架内提出，并重新表述为定点算子。解的存在性遵循 Schauder 定理，而唯一性是在适当的数据假设下获得的。离散问题是使用 Raviart--Thomas 有限元空间以及宏单元结构网格上的分段多项式近似来构造的，并通过 Brouwer 定理建立了离散解的存在性。先验误差分析产生最佳收敛率。我们进一步推导了基于残差的后验误差估计器，并使用全局 inf-sup 条件、亥姆霍兹分解和合适的投影算子证明了其可靠性，同时通过定位技术和气泡函数确保了效率。二维和三维数值实验证实了理论结果，证明了自适应细化对于奇异解和包含夹杂物的复杂几何形状的有效性，并说明了该方法对于由爱因斯坦-巴彻勒型粘度定律控制的羽流形成的生物对流基准的鲁棒性。

- **2026-01-13** **End-to-End Video Character Replacement without Structural Guidance** [2601.08587](http://arxiv.org/abs/2601.08587)
  > 由于缺乏配对视频数据，用用户提供的身份进行可控视频角色替换仍然是一个具有挑战性的问题。先前的工作主要依赖于基于重建的范例，该范例需要每帧分割掩模和明确的结构指导（例如骨架、深度）。然而，这种依赖严重限制了它们在涉及遮挡、角色与对象交互、不寻常姿势或具有挑战性的照明的复杂场景中的通用性，通常会导致视觉伪影和时间不一致。在本文中，我们提出了 MoCha，这是一种开创性的框架，它仅需要单个任意帧掩码即可绕过这些限制。为了有效适应多模态输入条件并增强面部身份，我们引入了条件感知 RoPE 并采用基于 RL 的后训练阶段。此外，为了克服合格配对训练数据的稀缺性，我们提出了一个全面的数据构建管道。具体来说，我们设计了三个专用数据集：使用虚幻引擎 5 (UE5) 构建的高保真渲染数据集、由当前肖像动画技术合成的表达驱动数据集以及从现有视频蒙版对派生的增强数据集。大量的实验表明，我们的方法大大优于现有的最先进的方法。我们将发布代码以方便进一步的研究。请参阅我们的项目页面了解更多详细信息：orange-3dv-team.github.io/MoCha

- **2026-01-13** **Kinetic Blockade and Filamentary Pair Density Waves in Strain-Engineered Graphene** [2601.08586](http://arxiv.org/abs/2601.08586)
  > 我们使用自洽的 Bogoliubov-de Gennes 方法研究应变工程石墨烯的超导性。挑战平带中的高态密度普遍增强配对的范式，我们确定了一种“动力学封锁”机制：应变诱导的亚晶格极化分离电子态，使这些奇点变得惰性。相反，超导性在几何节点处以坚固的细丝形式出现，形成一对密度波。该状态具有符号反转的顺序参数，可通过杂质引起的零能量模式检测到。我们的研究结果揭示了丝状超导性的独特几何起源，为狄拉克材料中应变调谐量子相提供了新的视角。

- **2026-01-13** **FRET between NV centers in diamond and chlorophyll molecules: a novel resource for multimodal sensing and imaging in plant cells** [2601.08580](http://arxiv.org/abs/2601.08580)
  > 这项工作证明了位于单晶金刚石表面下方 7 nm 和 9 nm 的浅氮空位 (NV) 中心群与天然存在的荧光团（即从拟南芥中提取的叶绿素 a 和 b 分子的混合物）之间的有效福斯特共振能量转移 (FRET)。 NV 中心的宽荧光带在光谱上与叶绿素分子的吸收重叠，从而实现 FRET。因此，在金刚石表面沉积叶绿素层可将 NV 荧光寿命从约 14 ns 缩短至 4 ns 以下，表明能量转移有效。激光诱导的叶绿素光漂白可恢复未淬灭的 NV 寿命。相比之下，位于金刚石内部更深处 40 nm 和 72 nm 处的 NV 中心未受影响，这证实了观察到的淬火源自短程 FRET 机制。 NV 系综在观察 FRET 时保留了光学检测到的磁共振对比度，证明了其自旋特性的保留。这些原理验证实验确立了将基于 FRET 的距离测量与使用光学可读自旋的磁传感相结合的可行性。

- **2026-01-13** **Chirality tomography: measuring local helicity from trajectory linking** [2601.08569](http://arxiv.org/abs/2601.08569)
  > 我们提出了通过手性断层扫描获得的完全发展的湍流的第一个三维螺旋度图，这是一种基于拉格朗日体素的方法，可以从粒子轨迹重建螺旋度密度。我们的方法建立在螺旋度和轨迹链接之间凭经验建立的关系的基础上，将符号交叉 $K$ 的局部计数转换为无量纲螺旋度的体积图 $H(\mathbf{x})$。我们证明，通过平均符号交叉数来量化的粒子轨迹的纠缠，不仅在全球范围内，而且在局部空间和时间范围内，为螺旋性提供了可靠的代理。我们的方法可以揭示螺旋性的局部空间异质性，并将其与大规模流动组织联系起来，从而能够重建空间分辨的手性结构。该方法应用于冯卡门实验和泰勒-格林直接数值模拟，揭示了等螺旋度表面和相干手性特征，而$K$的时间序列准确地跟踪了域平均螺旋度的演化。 $K$ 和 $H$ 之间的比例在不同的体素几何形状和不同的粒子惯性值中保持稳健，但在层流或时间调制流中不保持不变。这项研究表明，手性断层扫描提供了湍流中实用的螺旋度诊断，同时在轨迹级拓扑和湍流的基本动力学不变量之间建立了直接的桥梁。

- **2026-01-13** **In the Search for Good Neck Cuts** [2601.08566](http://arxiv.org/abs/2601.08566)
  > 我们研究在表面上寻找颈状特征的问题。此类切割的应用包括机器人技术、网格分割和算法应用。我们为表面瓶颈提供了一个新的定义——非正式地，它是相对于它所分隔的区域大小的最短周期。受等周不等式的启发，我们正式定义了此类最佳切割，研究了它们的属性，并提出了受这些想法启发的几种算法，这些算法在实践中效果出奇地好。有关我们算法的示例，请参阅 https://neckcut.space。

- **2026-01-13** **MASH: Evading Black-Box AI-Generated Text Detectors via Style Humanization** [2601.08564](http://arxiv.org/abs/2601.08564)
  > 人工智能生成文本（AIGT）的滥用日益增加，推动了 AIGT 检测方法的快速发展。然而，这些探测器的可靠性对于对抗性规避仍然很脆弱。现有的攻击策略通常依赖于白盒假设或需要过高的计算和交互成本，导致它们在实际的黑盒场景下无效。在本文中，我们提出了风格人性化的多阶段对齐（MASH），这是一种基于风格迁移规避黑盒检测器的新颖框架。 MASH 依次采用风格注入监督微调、直接偏好优化和推理时间细化来塑造 AI 生成文本的分布，使其与人类编写的文本相似。跨 6 个数据集和 5 个检测器的实验证明了 MASH 的性能优于 11 个基线规避者。具体来说，MASH 的平均攻击成功率 (ASR) 达到 92%，平均超出最强基线 24%，同时保持卓越的语言质量。

- **2026-01-13** **A Structure Preserving Finite Volume Scheme for the Navier-Stokes-Korteweg Equations** [2601.08498](http://arxiv.org/abs/2601.08498)
  > 我们提出了局部 NavierStokes-Korteweg 和 Euler-Korteweg 系统的半离散有限体积方案。我们的方案适用于一维和二维空间中的等距笛卡尔网格。与其他工作相比，例如采用方程的双曲近似或导致扩展系统的辅助变量方法，我们的方案直接在原始系统上运行。我们证明它保持质量和动量守恒并且能量稳定。数值实验补充了我们的理论发现，表明如果采用显式或隐式时间离散化，该方案是一阶收敛的。

- **2026-01-13** **Drone Surveillance via Coordinated Beam Sweeping in MIMO-ISAC Networks** [2601.08483](http://arxiv.org/abs/2601.08483)
  > 本文介绍了一种与第五代（5G）同步信号块（SSB）小区搜索程序相协调的无人机监视方案，以同时检测体积监视网格内的低空无人机。在此，我们考虑一种多静态配置，其中多个接入点 (AP) 协作照亮音量，同时独立传输 SSB 广播信号。这两项任务都是通过光束扫描来执行的。在所提出的方案中，协调 AP 在 5G SSB 突发的同时向体积监视区域内的体素网格发送传感光束。为了防止通信和传感信号之间的干扰，我们提出了一种预编码器设计，可保证传感波束和 SSB 的正交性，以最大化传感信号与干扰加噪声比 (SINR)，同时确保用户指定的 SINR，并最大限度地减少直接链路的影响。结果表明，所提出的预编码器优于非协调预编码器，并且受无人机高度变化的影响最小。

- **2026-01-12** **Are LLM Decisions Faithful to Verbal Confidence?** [2601.07767](http://arxiv.org/abs/2601.07767)
  > 大型语言模型（LLM）可以对其自身的不确定性产生令人惊讶的复杂估计。然而，目前尚不清楚这种表达的信心在多大程度上与模型的推理、知识或决策相关。为了测试这一点，我们引入了 $\textbf{RiskEval}$ ：一个旨在评估模型是否根据不同的错误惩罚调整其弃权策略的框架。我们对几个前沿模型的评估揭示了一种严重的分离：模型在表达其口头信心时既没有成本意识，也没有在决定在高罚条件下参与或弃权时做出战略响应。即使极端惩罚使频繁弃权成为数学上的最佳策略，模型也几乎从不弃权，从而导致效用崩溃。这表明，经过校准的口头置信度分数可能不足以创建值得信赖和可解释的人工智能系统，因为当前模型缺乏将不确定性信号转化为最佳和风险敏感决策的战略机构。

- **2026-01-12** **On the Compact Discontinuous Galerkin method for polytopal meshes** [2601.07757](http://arxiv.org/abs/2601.07757)
  > 紧致间断伽辽金法由 Peraire 和 Persson 在 (SIAM J. Sci. Comput., 30, 1806--1824, 2008) 中提出。在这项工作中，我们提出了该方法的 $hp$ 版本的稳定性和收敛性分析，该方法应用于多面体网格上的椭圆问题。此外，我们引入了快速实用的算法，允许在统一框架内实现 CDG、LDG 和 BR2 方法。我们的数值实验表明，CDG 方法可生成紧凑的刚度矩阵模板，与 LDG 和 BR2 方法相比，组装和求解时间更快。我们通过数值研究矫顽力如何取决于各种网格类型的方法参数，特别关注每个网格元素的面数。最后，我们证明了在使用可变多项式次数时为数值通量选择正确方向的重要性。

- **2026-01-12** **FMAC: a Fair Fiducial Marker Accuracy Comparison Software** [2601.07723](http://arxiv.org/abs/2601.07723)
  > 本文提出了一种使用基准标记对姿态估计的准确性进行公平比较的方法。这些比较依赖于大量高保真合成图像，能够深入探索 6 个自由度。空间的低差异采样允许通过绘制 36 对组合来检查每个自由度与位姿误差之间的相关性。图像使用基于物理的光线追踪代码进行渲染，该代码是专门开发用于直接使用任何相机的标准校准系数的。该软件可再现图像扭曲、散焦和衍射模糊。此外，子像素采样应用于锐利边缘，以增强渲染图像的保真度。在介绍了渲染算法及其实验验证后，本文提出了一种评估位姿精度的方法。该方法应用于众所周知的标记，揭示它们在姿势估计方面的优点和缺点。该代码是开源的，可在 GitHub 上获取。

- **2026-01-12** **Tachyonic gravitational dark matter production after inflation** [2601.07670](http://arxiv.org/abs/2601.07670)
  > 我们提出了一种新颖的引力机制，用于由膨胀后曲率引起的速子不稳定性驱动的暗物质的非热产生。与通常研究的与重力的非最小耦合不同，我们的框架考虑了与时空曲率不变量二次耦合的真实观众标量场。我们证明，暴涨结束时时空曲率的快速重组可以动态地使暗物质场呈现快光状态，从而引发自发对称性破缺和爆炸性粒子产生的短暂阶段。作为一个具体的、理论上受控的例子，我们关注高斯-博内拓扑不变量。通过将分析估计与完全非线性的 $3+1$ 经典晶格模拟相结合，我们跟踪系统的非平衡演化并计算由此产生的暗物质丰度。我们发现这种纯粹的引力机制可以在广泛的质量和暴胀尺度上稳健地再现观察到的暗物质遗迹密度，还提供了一个简单的拟合函数，使得我们的结果能够独立于晶格应用。

- **2026-01-12** **StdGEN++: A Comprehensive System for Semantic-Decomposed 3D Character Generation** [2601.07660](http://arxiv.org/abs/2601.07660)
  > 我们推出了 StdGEN++，这是一种新颖且全面的系统，用于从不同的输入生成高保真、语义分解的 3D 角色。现有的 3D 生成方法通常会生成整体网格，缺乏游戏和动画工业管道所需的结构灵活性。为了解决这一差距，StdGEN++ 建立在双分支语义感知大型重建模型（双分支 S-LRM）的基础上，该模型以前馈方式联合重建几何、颜色和每个组件的语义。为了实现生产级保真度，我们引入了一种与混合隐式字段兼容的新颖的语义表面提取形式。该机制通过从粗到细的提议方案来加速，从而显着减少内存占用并实现高分辨率网格生成。此外，我们提出了一种基于视频扩散的纹理分解模块，将外观分解为可编辑层（例如，分离的虹膜和皮肤），解决面部区域的语义混淆。实验表明，StdGEN++ 实现了最先进的性能，在几何精度和语义解缠方面显着优于现有方法。至关重要的是，由此产生的结构独立性解锁了先进的下游功能，包括无损编辑、符合物理的动画和视线跟踪，使其成为自动化角色资产生产的强大解决方案。

- **2026-01-12** **Performance Benchmarks for 2-View and 3-View Fiber-Projection Fine-Grained Particle Detectors** [2601.07633](http://arxiv.org/abs/2601.07633)
  > 细粒度闪烁体探测器对于核物理和粒子物理中的精确测量至关重要，其中相互作用顶点和次级粒子方向的精确重建使得信号与背景事件分离。众所周知的设计选择是光纤读出几何结构：传统的 2 视图系统使用正交的 X 和 Y 光纤，而下一代 3 视图设计添加了第三个 Z 光纤层，可提供明确的 3D 体素识别。 2 视图方法遭受组合重影的影响，即光纤投影模糊性产生的错误 3D 候选，降低了高多样性事件中的重建性能。本文提出了全面的模拟基准，量化了 2 视图和 3 视图几何图形之间关键指标的性能差异。我们发现，3 视图几何体根据事件拓扑将重影命中减少了 30--90%，在复杂的拓扑中提供了强大的顶点分辨率，并为簇射方向重建保持了卓越的角度分辨率。这些基准为未来探测器的设计优化提供信息，并为中微子物理、稀有 kaon/pion 衰变和对撞机量热等广泛实验的重建算法开发提供定量指导。

- **2026-01-12** **Machine learning nonequilibrium phase transitions in charge-density wave insulators** [2601.07583](http://arxiv.org/abs/2601.07583)
  > 非平衡电子力在电压驱动的相变中发挥着核心作用，但众所周知，在动态模拟中评估其成本非常昂贵。在这里，我们开发了一个与非平衡电子耦合的绝热晶格动力学的机器学习框架，并演示了荷斯坦模型中门控诱导绝缘体从电荷密度波态到金属的转变。尽管可以通过非平衡格林函数 (NEGF) 计算获得精确的电子力，但其高昂的计算成本使得长时间的动态模拟成本过高。通过利用电子响应的局部性，我们训练神经网络直接从晶格配置预测瞬时局部电子力，从而绕过时间演化过程中重复的 NEGF 计算。当与布朗动力学相结合时，产生的机器学习力场定量地再现了从完整的 NEGF 模拟中获得的畴壁运动和非平衡相变动力学，同时实现了计算效率的数量级增益。我们的结果将直接力学习确立为一种有效且准确的方法，用于模拟驱动量子材料中的非平衡晶格动力学。

- **2026-01-12** **GPU accelerated surface-based gaze mapping for XR experiences** [2601.07571](http://arxiv.org/abs/2601.07571)
  > 扩展现实是一个快速增长的领域，越来越需要分析和理解用户行为。特别是，在沉浸式体验中理解人类视觉注意力对于许多应用来说至关重要。视觉注意力的可视化和分析通常是通过根据眼动追踪数据构建注视密度图来完成的。这种视觉注意力映射对于 3 自由度 (3DoF) 体验（\textit{即}，涉及 360 个图像或视频）来说可以很好地掌握，但对于 6DoF 数据来说就更不好了，因为用户可以在 3D 空间中自由移动。在这种情况下，视觉注意力信息必须映射到 3D 对象本身。存在一些用于构造这种基于表面的 6DoF 注意力图的解决方案，但是它们具有几个缺点：处理时间、对网格分辨率和/或纹理映射的强烈依赖、和/或用于进一步处理的不切实际的数据表示。在此背景下，我们提出了一种新颖的基于 GPU 的算法，该算法可以在交互时生成并实时渲染的同时解决上述问题。在具有挑战性的场景上进行的实验证明了我们方法的准确性和鲁棒性。为了促进这一领域的研究，源代码被公开发布并集成到 PLUME 中，以便于在 XR 实验中使用。

- **2026-01-12** **ViewMorpher3D: A 3D-aware Diffusion Framework for Multi-Camera Novel View Synthesis in Autonomous Driving** [2601.07540](http://arxiv.org/abs/2601.07540)
  > 自动驾驶系统严重依赖多视图图像来确保准确的感知和稳健的决策。为了有效地开发和评估感知堆栈和规划算法，逼真的闭环模拟器是必不可少的。虽然高斯溅射等 3D 重建技术为模拟器构建提供了有希望的途径，但渲染的新颖视图通常会出现伪影，特别是在外推视角或可用观察稀疏时。   我们推出 ViewMorpher3D，这是一种基于图像扩散模型的多视图图像增强框架，旨在提升驾驶场景中的真实感和多视图一致性。与单视图方法不同，ViewMorpher3D 联合处理一组以相机姿势、3D 几何先验以及时间相邻或空间重叠参考视图为条件的渲染视图。这使得模型能够推断缺失的细节、抑制渲染伪影并强制执行跨视图一致性。   我们的框架可容纳不同数量的摄像机和灵活的参考/目标视图配置，使其能够适应不同的传感器设置。对现实世界驾驶数据集的实验表明，图像质量指标得到了显着改善，有效减少了伪影，同时保持了几何保真度。

- **2026-01-12** **R3-RECON: Radiance-Field-Free Active Reconstruction via Renderability** [2601.07484](http://arxiv.org/abs/2601.07484)
  > 在主动重建中，实体代理必须决定接下来要查看哪里，以有效获取支持高质量新颖视图渲染的视图。最近关于神经渲染主动视图规划的工作主要通过辐射场反向传播或估计 3D 高斯基元的信息熵来导出次最佳视图 (NBV) 标准。虽然有效，但这些策略将视图选择与繁重的、特定于表示的机制紧密结合在一起，并且无法考虑轻量级在线部署所需的计算和资源限制。在本文中，我们从以可渲染性为中心的角度重新审视主动重建。我们提出 $\mathbb{R}^{3}$-RECON，一个无辐射场的主动重建框架，它从轻量级体素图在 SE(3) 上引入隐式的、姿势条件可渲染性场。我们的公式将每个体素的在线观察统计数据聚合成一个统一的标量可渲染性分数，该分数更新成本低廉，并且可以在毫秒内以封闭形式在任意候选视点进行查询，而不需要梯度或辐射场训练。该可渲染性场与图像空间重建误差密切相关，自然地指导 NBV 选择。我们进一步引入了一个全景扩展，可以估计全向（360$^\circ$）视图效用，以加速候选评估。在标准室内复制数据集中，$\mathbb{R}^{3}$ -RECON 比最近具有匹配视图和时间预算的活动 GS 基线实现了更均匀的新颖视图质量和更高的 3D 高斯泼溅 (3DGS) 重建精度。

- **2026-01-11** **An efficient hyper reduced-order model for segregated solvers for geometrical parametrization problems** [2601.07082](http://arxiv.org/abs/2601.07082)
  > 我们提出了一种高效的超降阶模型（HROM），专为几何参数化问题中的隔离有限体积求解器而设计。该方法遵循先离散后投影的策略：首先使用有限体积或有限元离散化组装全阶算子，然后使用通过 DEIM 等超简化技术选择的一小组空间采样点投影到低维空间。这种方法消除了在线计算成本对完整网格尺寸的依赖。该方法在三个基准问题上进行评估：线性输运方程、非线性伯格斯方程和不可压缩纳维-斯托克斯方程。结果表明，超简化模型与全阶解紧密匹配，同时大幅减少了计算时间。由于在在线阶段仅评估网格单元的稀疏子集，因此该方法自然可并行化并可扩展到非常大的网格。这些发现表明，超还原可以与分离求解器和几何参数化有效结合，以实现快速、准确的 CFD 模拟。

- **2026-01-11** **Adaptive Robust Control for Uncertain Systems with Ellipsoid-Set Learning** [2601.07079](http://arxiv.org/abs/2601.07079)
  > 尽管不确定系统的随机控制方法取得了巨大的成功，但此类方法处理非高斯不确定性的能力有限。这项工作提出了一种针对线性不确定系统的自适应鲁棒控制，其过程噪声、观测噪声和系统状态由椭球集而不是高斯分布来描述。我们设计了一种椭球集学习方法来估计状态集的边界，并将学习集纳入控制律推导中，以减少鲁棒控制中的保守性。此外，我们考虑状态空间矩阵中的参数不确定性。特别是，我们为不确定参数分配有限的候选，并为每个候选构建一系列候选条件鲁棒控制问题。我们通过聚合候选条件控制律得出最终控制律。通过这种方式，我们将控制方案分离为并行的鲁棒控制，将学习和控制解耦，否则会使控制无法实现。我们在线性二次调节和跟踪控制的情况下在数值模拟中证明了所提出的控制的有效性。

- **2026-01-11** **Match Made with Matrix Completion: Efficient Learning under Matching Interference** [2601.06982](http://arxiv.org/abs/2601.06982)
  > 匹配市场越来越需要了解需求和供给之间的匹配质量，以便有效设计匹配政策。在实践中，由于参与者的多样性不断增加，匹配奖励是高维的。我们利用这两个市场中匹配奖励的自然低秩矩阵结构，并建议利用矩阵完成来加速有限离线数据的奖励学习。在这种情况下，矩阵补全的一个独特属性是，奖励矩阵的条目是在匹配干扰的情况下观察的——即，由于匹配或预算限制，条目不是独立观察的，而是相互依赖的。这种匹配依赖性带来了独特的技术挑战，例如矩阵补全文献中现有分析工具的次优性或不适用，因为它们通常依赖于样本独立性。在本文中，我们首先证明标准核范数正则化在匹配干扰下理论上仍然有效。我们在这种情况下提供了近乎最优的弗罗贝尼乌斯范数保证，并结合了新的分析技术。接下来，为了指导某些匹配决策，我们基于核范数估计器开发了一种新颖的“双重增强”估计器，具有近乎最优的入口保证。我们的双重增强程序可以适用于更广泛的采样方案，即使具有依赖性，这可能是独立的兴趣。此外，我们将我们的方法扩展到具有匹配约束（例如最佳匹配和稳定匹配）的在线学习设置，并在矩阵维度中提出改进的遗憾界限。最后，我们使用劳动力市场的合成数据和真实数据证明了我们的方法的实用价值。

- **2026-01-11** **Symphonym: Universal Phonetic Embeddings for Cross-Script Toponym Matching via Teacher-Student Distillation** [2601.06932](http://arxiv.org/abs/2601.06932)
  > 将不同语言和书写系统的地名联系起来是数字人文和地理信息检索中的一个基本挑战。现有的方法依赖于特定于语言的语音算法或音译规则，当名称跨越脚本边界时，这些算法或音译规则就会失败——没有任何字符串度量可以确定以西里尔语或阿拉伯语呈现的“莫斯科”指的是同一个城市。   我提出了 Symphony，这是一种神经嵌入系统，可将 20 个书写系统中的地名映射到统一的 128 维语音空间中。经过发音语音特征训练的教师网络（通过 Epitran 和 PanPhon）生成目标嵌入，而学生网络则学习从原始字符中近似这些嵌入。推理时，只需要轻量级的Student（170万个参数），无需运行时语音转换即可部署。   培训采用三阶段课程，涉及来自 GeoNames、Wikidata 和 Getty 地名同义词库的 5700 万个地名。第一阶段训练老师 467K 语音基础三连音。第 2 阶段将 2300 万个样本中的学生输出与教师输出进行对齐，实现 96.6% 的余弦相似度。第 3 阶段对 330 万个硬否定三元组进行微调 - 否定与锚共享前缀和脚本，但指的是不同的地方 - 以加强区分。   MEHDIE 希伯来语-阿拉伯语基准的评估达到 89.2% Recall@1，优于 Levenshtein (81.5%) 和 Jaro-Winkler (78.5%)。系统针对跨脚本匹配进行了优化；相同脚本的变体可以通过互补的字符串方法来处理。 Symphony 将在世界历史地名词典的 6700 万个地名中实现模糊语音协调和搜索。代码和模型是公开的。

- **2026-01-11** **RenderFlow: Single-Step Neural Rendering via Flow Matching** [2601.06928](http://arxiv.org/abs/2601.06928)
  > 传统的基于物理的渲染 (PBR) 管道通过计算密集型光传输模拟生成逼真的图像。尽管最近的深度学习方法利用扩散模型先验和几何缓冲区（G-缓冲区）来产生视觉上引人注目的结果，而无需明确的场景几何或光模拟，但它们仍然受到两个主要限制。首先，扩散过程的迭代性质引入了相当大的延迟。其次，这些生成模型固有的随机性损害了物理准确性和时间一致性。为了应对这些挑战，我们提出了一种新颖的、端到端的、确定性的、单步神经渲染框架 RenderFlow，它建立在流匹配范例的基础上。为了进一步增强渲染质量和泛化能力，我们提出了一种高效且有效的稀疏关键帧指导模块。我们的方法显着加速了渲染过程，并且通过选择性地合并稀疏渲染的关键帧作为指导，增强了输出的物理合理性和整体视觉质量。由此产生的管道实现了近乎实时的性能和逼真的渲染质量，有效地缩小了现代生成模型的效率与传统基于物理的渲染的精度之间的差距。此外，我们通过引入一个轻量级的、基于适配器的模块来展示我们框架的多功能性，该模块有效地将预训练的前向模型重新用于内在分解的逆渲染任务。

- **2026-01-11** **Efficient Subdivision of Bézier Curves/Surfaces via Blossoms** [2601.06841](http://arxiv.org/abs/2601.06841)
  > 我们考虑使用花朵进行贝塞尔曲线/曲面细分的问题。根据计算控制点的需要，我们提出了用于花朵评估的封闭式公式。这种方法提供了直接有效的方法来获得贝塞尔曲线以及张量积和三角形贝塞尔曲面的细分。它大大简化了细分控制点的计算，这在需要动态细化或调整曲线/曲面的应用中至关重要。例如，在 CAD/CAM 系统、建筑设计或动画中，快速准确地确定新控制点的能力对于操纵和渲染复杂形状至关重要。更高效的细分可以促进复杂的操作，例如查找曲面之间的交点或平滑地混合多个曲面。

- **2026-01-11** **PRISM: Color-Stratified Point Cloud Sampling** [2601.06839](http://arxiv.org/abs/2601.06839)
  > 我们提出了 PRISM，一种用于 RGB-LiDAR 点云的新型颜色引导分层采样方法。我们的方法的动机是观察到独特的场景特征通常表现出色彩多样性，而重复的冗余特征在颜色上是均匀的。传统的下采样方法（随机采样、体素网格、法线空间采样）会强制执行空间均匀性，同时忽略此光度内容。相反，PRISM 分配与色度多样性成正比的采样密度。通过将 RGB 颜色空间视为分层域并为每个颜色仓施加最大容量 k，该方法保留了具有高颜色变化的纹理丰富区域，同时显着减少了视觉上均匀的表面。这将采样空间从空间覆盖转移到视觉复杂性，以生成更稀疏的点云，保留 3D 重建任务的基本特征。

- **2026-01-11** **The optimal error analysis of nonuniform L1 method for the variable-exponent subdiffusion model** [2601.06773](http://arxiv.org/abs/2601.06773)
  > 这项工作研究了非均匀时间网格下变指数次扩散模型的完全离散方案的最优误差估计。我们应用摄动方法将原始模型重新表示为其等效形式，并应用L1格式和插值求积规则分别对重新表示的模型中的Caputo导数项和卷积项进行离散化。然后，我们证明了非均匀网格下的时间收敛率 $O(N^{-\min\{2-α(0), rα(0)\}})$，这改进了 [Zheng, CSIAM T. Appl.数学。 2025] $r\geq \frac{2-α(0)}{α(0)}$ 。给出的数值结果证实了理论结果。

- **2026-01-10** **Detecting the Onset and Progression of Spinodal Decomposition using Transient Grating Spectroscopy** [2601.06659](http://arxiv.org/abs/2601.06659)
  > 旋节线分解会降低耐腐蚀性并使材料脆化。在灾难性材料降解之前快速、最终、非破坏性地检测旋节线分解开始的能力将代表材料测试的重大进步。我们证明，可以使用原位和异位瞬态光栅光谱 (TGS) 通过模量硬化来检测二元 Fe-Cr 合金中的旋节线分解。关键的机理见解是弹性模量作为 Cr 含量函数的非线性，使得旋节线分解的 Fe-Cr 合金比初始铬成分一定范围的等效固溶体更硬。我们使用差示扫描量热法 (DSC) 确认了 36 at.% 铬合金中存在旋节线分解，与已知的旋节线分解能量学相关，并通过原子模拟表明，36 at.% 铬合金中的旋节线分解后预期弹性模量硬化。这项研究的结果表明，TGS 可以作为一种实用工具，对易受此类降解影响的关键材料进行无损评估。

- **2026-01-10** **Stereo Audio Rendering for Personal Sound Zones Using a Binaural Spatially Adaptive Neural Network (BSANN)** [2601.06621](http://arxiv.org/abs/2601.06621)
  > 提出了一种用于个人声音区域（PSZ）的双耳渲染框架，以使多个头部跟踪听众能够接收完全独立的立体声音频节目。目前的 PSZ 系统通常依赖于单声道渲染，因此无法单独控制左耳和右耳，这限制了空间成像的质量和准确性。所提出的方法采用双耳空间自适应神经网络（BSANN）来生成耳朵优化的扬声器滤波器，从而在多个听众的每只耳朵处重建所需的声场。该框架集成了消声测量的扬声器频率响应、分析建模的换能器方向性和刚性球头相关传递函数 (HRTF)，以提高声学准确性和空间渲染保真度。显式主动串扰消除 (XTC) 级进一步改善了三维空间感知。实验表明，测量的客观性能指标显着提高，包括区域间隔离 (IZI)、程序间隔离 (IPI) 和串扰消除 (XTC)，对数频率加权值分别为 10.23/10.03 dB (IZI)、11.11/9.16 dB (IPI) 和 10.55/11.13 dB (XTC)。 100-20,000 赫兹。耳控控制、精确声学建模和集成有源 XTC 的结合使用产生了统一的渲染方法，可提供更好的隔离性能、增强的对房间不对称性的鲁棒性以及在真实声学环境中更忠实的空间再现。

- **2026-01-09** **Manifold limit for the training of shallow graph convolutional neural networks** [2601.06025](http://arxiv.org/abs/2601.06025)
  > 我们研究了在流形假设下在采样点云的邻近图上训练浅图卷积神经网络（GCNN）的离散到连续一致性。图卷积是通过图拉普拉斯算子在频谱上定义的，其低频频谱近似于底层平滑流形的 Laplace-Beltrami 算子的频谱，而可能无限宽度的浅层 GCNN 是参数空间上的测量空间上的线性函数。从函数分析的角度来看，图信号被视为流形上函数的空间离散化，这导致了训练数据在图分辨率上保持一致的自然概念。为了实现收敛结果，连续参数空间被选择为单位球的弱紧积，并对输出权重和偏差施加 Sobolev 正则，但不对卷积参数施加 Sobolev 正则。相应的离散参数空间继承了相应的谱衰减，并且还受到适合拉普拉斯图的信息谱窗口的频率截止的限制。在这些假设下，我们证明了正则化经验风险最小化泛函的 $Г$ 收敛性及其全局最小化函数的相应收敛性，即参数度量的弱收敛性和函数在紧集上的一致收敛性。这为此类网络的训练提供了网格和样本独立性的形式化。

- **2026-01-09** **Skyrme-Hartree-Fock-Bogoliubov mass models on a 3D mesh: V. The N2LO extension of the Skyrme EDF** [2601.05968](http://arxiv.org/abs/2601.05968)
  > 我们推出 BSkG5，它是布鲁塞尔 Skyrme 网格 (BSkG) 系列的最新产品，也是第一个基于次次次前导阶 (N2LO) Skyrme 能量密度泛函 (EDF) 的大型核结构模型。通过使用包含多达四个梯度的中心项扩展传统的 Skyrme EDF ansatz，我们能够将核基态特性的出色全局描述与纯中子物质的刚性状态方程结合起来，该状态方程与中子星的所有天文观测一致。更准确地说，新模型与早期 BSkG 模型的精度相匹配，但少了两个参数：2457 个原子质量的均方根偏差为 0.649 MeV，810 个电荷半径的均方根偏差为 0.0267 fm，45 个锕系元素核的初级裂变势垒的均方根偏差为 0.43 MeV。我们证明，即使对于要求苛刻的多体计算，N2LO EDF 的复杂性也并非不可克服。

- **2026-01-09** **Superdiffusive central limit theorem for a class of driven diffusive systems at the critical dimension** [2601.05945](http://arxiv.org/abs/2601.05945)
  > 我们研究一类驱动扩散系统的大规模行为，该系统由随机偏微分方程（具有一般非线性的随机伯格斯方程 (SBE)）在临界尺寸和无限体积下建模。我们的主要结果表明，在对数超扩散时空缩放下，它由[G. Cannizzaro, Q. Moulard, & F. Toninelli, arxiv.org/abs/2501.00344, 2025] 的二次 SBE，但具有适当的重正化系数，从而严格证明并部分纠正了 [H. Cannizzaro, Q. Moulard, & F. Toninelli, arxiv.org/abs/2501.00344, 2025] van Beijeren、R. Kutner 和 H. Spohn，物理学家。 Rev. Lett.，1986] 基于 Spohn 的非线性脉动流体动力学理论。此外，我们的结果是第一个非平衡系统的普遍性结果，也是[M. Hairer, J. Quastel，数学论坛，Pi，卷。 6, 2018, e3]，达到临界尺寸并超越弱耦合。我们工作中的主要挑战是非线性的温和增长条件，这使得微观方程的适定性变得不平凡。其他关键的新颖之处包括对生成器非二次部分的精细估计的推导，以及与二次 SBE 解相关的求解器的新近似。

- **2026-01-09** **Coupled Level-Set Lattice Boltzmann Method on Adaptive Cartesian Grids** [2601.05936](http://arxiv.org/abs/2601.05936)
  > 提出了一种基于自适应笛卡尔网格的新型耦合水平集格子玻尔兹曼方法，用于模拟液-气多相流。该方法解决了精确建模以尖锐界面和大密度比为特征的多相系统的固有挑战。通过对通过界面处的边界条件耦合的每个流体相采用单独的求解算法，该方法更加准确和高效。该研究强调了使用格子玻尔兹曼方法与水平集技术一起有效跟踪界面同时促进自适应网格细化的优势。对各种测试案例（例如不混溶分层流和上升气泡）的应用证明了该方法能够捕获复杂的界面动力学并根据文献数据验证其准确性。

- **2026-01-09** **Universal and Asymptotically Optimal Data and Task Allocation in Distributed Computing** [2601.05873](http://arxiv.org/abs/2601.05873)
  > 我们研究分布式计算中通信和计算成本的联合最小化，其中主节点协调 $N$ 个工作节点来评估 $n$ 个文件库上的函数。假设该函数被分解为任意子函数集 $\mathbf{X}$，每个子函数依赖于 $d$ 输入文件，将我们的分布式计算问题呈现为 $d$ 均匀超图边缘分区问题，其中由顶点（文件）之间的 $d$ 依赖关系定义的边缘集（子函数集）必须跨 $N$ 不相交组（工人）进行分区。目的是设计一个文件和子函数分配，对应于 $\mathbf{X}$ 的分区，最小化通信成本 $π_{\mathbf{X}}$（表示每个服务器的不同文件的最大数量），同时最小化与最大工作子函数负载相对应的计算成本 $δ_{\mathbf{X}}$。对于广泛的参数，我们提出了一种确定性分配解决方案，即 \emph{Interweaved-Cliques (IC) design}，其受信息论启发的交织团结构对于一大类分解 $\mathbf{X}$ 同时实现了顺序最优的通信和计算成本。这种最优性源自我们的可实现性和逆界，这揭示了在 $\mathbf{X}$ 密度的合理假设下，通信成本的最佳缩放采用 $n/N^{1/d}$ 的形式，表明我们的设计实现了按 $N^{1/d}$ 缩放的阶次最优 \textit{partitioning Gain}，同时还实现了阶次最优计算成本。有趣的是，这种顺序最优性是以确定性方式实现的，而且非常重要的是，它是从 $\mathbf{X}$ 盲目实现的，因此无需重新整理文件即可计算多个所需的函数。

- **2026-01-09** **LayerGS: Decomposition and Inpainting of Layered 3D Human Avatars via 2D Gaussian Splatting** [2601.05853](http://arxiv.org/abs/2601.05853)
  > 我们提出了一种新颖的框架，用于将任意姿势的人类分解为可动画的多层 3D 人类化身，将身体和服装分开。传统的单层重建方法将服装锁定为一种身份，而先前的多层方法则难以应对遮挡区域。我们通过将每一层编码为一组 2D 高斯函数来克服这两个限制，以实现精确的几何形状和真实感渲染，并通过分数蒸馏采样 (SDS) 使用预训练的 2D 扩散模型修复隐藏区域。我们的三阶段训练策略首先通过单层重建来重建粗糙的规范服装，然后通过多层训练来共同恢复内层身体和外层服装细节。在两个 3D 人体基准数据集（4D-Dress、T human2.0）上进行的实验表明，我们的方法比之前最先进的技术实现了更好的渲染质量以及层分解和重组，从而能够在新颖的视点和姿势下进行逼真的虚拟试穿，并推进用于沉浸式应用程序的高保真 3D 人体资产的实际创建。我们的代码位于 https://github.com/RockyXu66/LayerGS

- **2026-01-09** **GeoSurDepth: Spatial Geometry-Consistent Self-Supervised Depth Estimation for Surround-View Cameras** [2601.05839](http://arxiv.org/abs/2601.05839)
  > 准确的环视深度估计为激光传感器提供了一种有竞争力的替代方案，对于自动驾驶中的 3D 场景理解至关重要。虽然先前的研究提出了各种主要侧重于在光度水平上强制执行交叉视图约束的方法，但很少有人明确利用单目和环视设置中固有的丰富几何结构。在这项工作中，我们提出了 GeoSurDepth，一个利用几何一致性作为环视深度估计的主要线索的框架。具体来说，我们利用基础模型作为伪几何先验和特征表示增强工具来指导网络保持空间 3D 空间中的表面法线一致性，并规范 2D 中对象和纹理一致的深度估计。此外，我们引入了一种新颖的视图合成管道，其中通过空间扭曲重建密集深度来实现 2D-3D 提升，鼓励跨时间、空间和时空上下文的额外光度监督，并补偿单视图图像重建的局限性。最后，新提出的自适应联合运动学习策略使网络能够自适应地强调信息丰富的空间几何线索，以改进运动推理。对 DDAD 和 nuScenes 的大量实验表明，GeoSurDepth 实现了最先进的性能，验证了我们方法的有效性。我们的框架强调了利用几何相干性和一致性来实现稳健的自监督多视图深度估计的重要性。

- **2026-01-09** **Stability and convergence analysis of unconditionally original energy dissipative implicit-explicit Runge--Kutta methods for the phase field crystal models without Lipschitz assumptions** [2601.05780](http://arxiv.org/abs/2601.05780)
  > 相场晶体（PFC）方法是模拟原子长度尺度和扩散时间尺度晶体微结构演化的有效技术。由于高阶导数（六阶）和强非线性项（局部 Lipschitz），开发高阶稳定方案并建立相应的误差估计特别具有挑战性。在本研究中，我们首先建立了高阶隐式-显式（IMEX）龙格-库塔方法的通用框架，该框架保留了非线性项上全局 Lipschitz 截断的辅助模型的原始能量耗散。通过使用Sobolev嵌入定理和柯西交错定理，我们证明了辅助模型的解与不具有全局Lipschitz性质的原始模型的解相同，只要初始值的自由能是明确定义的。此外，我们严格证明了 L-无穷范数下解的一致有界性和无条件全局时间稳定性。这允许一个简单的框架来导出最佳的任意高阶 L-无穷大误差估计，而不依赖于 Lipschitz 假设。特别是，与现有文献相比，误差估计的论点以更加简化和优雅的方式提出，而不对时间步长或网格大小施加任何限制。事实上，所报告的框架建立在原始模型的截断辅助问题的基础上，可以直接扩展到广泛的梯度流，包括 Allen-Cahn 方程、非局部 PFC 模型和外延薄膜生长方程，提供无条件能量耗散，而无需强制 Lipschitz 连续性。最后，我们提出数值示例来验证我们的分析结果并证明捕获长期动态的有效性。

- **2026-01-09** **More Power to the Particles: Analytic Geometry for Partial Optimal Transport-based Fluid simulation** [2601.05765](http://arxiv.org/abs/2601.05765)
  > 我们提出了一种基于部分最优传输（例如加卢埃-梅里戈方案或功率粒子方法）的自由表面流体模拟和变形力学所需的几何结构的解析构造。此类方法以前依赖于利用经典的凸细胞裁剪算法对细胞进行离散化。然而，这会导致大量的计算成本和评估量的粗略近似。相比之下，我们的算法有效地计算广义拉盖尔细胞，即拉盖尔细胞和球体之间的交集。这使得可以更精确地计算小面的体积和面积，并大大减少获得几何形状所需的操作数量。此外，我们还提供了一个仅基于计算的体积结构的专用渲染框架。

- **2026-01-09** **FeatureSLAM: Feature-enriched 3D gaussian splatting SLAM in real time** [2601.05738](http://arxiv.org/abs/2601.05738)
  > 我们提出了一种实时跟踪 SLAM 系统，该系统使用 3D 高斯分布 (3DGS) 将高效的相机跟踪与照片级真实感特征丰富的映射结合起来。我们的主要贡献是将密集特征光栅化集成到小说视图合成中，并与视觉基础模型保持一致。这产生了强大的语义，超越了基本的 RGB-D 输入，有助于跟踪和映射的准确性。与之前的语义 SLAM 方法（嵌入预定义的类标签）不同，FeatureSLAM 通过自由视点、开放集分割实现全新的下游任务。在标准基准测试中，我们的方法实现了实时跟踪，与最先进的系统相当，同时提高了跟踪稳定性和地图保真度，而无需过多的计算。从数量上讲，与最近的固定集 SLAM 基线相比，我们获得了 9% 的位姿误差降低和 8% 的映射精度提高。我们的结果证实，实时特征嵌入的 SLAM 不仅对于启用新的下游应用程序有价值。它还提高了底层跟踪和映射子系统的性能，提供与离线 3DGS 模型相当的语义和语言屏蔽结果，以及最先进的跟踪、深度和 RGB 渲染。


<p align=right>(<a href=#updated-on-20260115>back to top</a>)</p>

## 具生智能&自动驾驶

- **2026-01-14** **Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning** [2601.09708](http://arxiv.org/abs/2601.09708)
  > 视觉-语言-动作（VLA）任务需要对复杂的视觉场景进行推理并在动态环境中执行自适应动作。虽然最近关于推理 VLA 的研究表明，显式思维链 (CoT) 可以提高泛化能力，但由于推理轨迹过长，推理延迟较高。我们提出了 Fast-ThinkAct，这是一种高效的推理框架，可以通过可语言的潜在推理实现紧凑而高性能的规划。 Fast-ThinkAct 通过从教师那里提炼，在偏好引导的目标驱动下，学习如何利用潜在 CoT 进行有效推理，以调整操作轨迹，从而传输语言和视觉规划能力以实现具体控制。这使得推理增强型策略学习能够有效地将紧凑推理与行动执行联系起来。跨各种具体操作和推理基准的大量实验表明，Fast-ThinkAct 实现了强大的性能，与最先进的推理 VLA 相比，推理延迟降低了 89.3%，同时保持有效的长期规划、小样本适应和故障恢复。

- **2026-01-14** **CLARE: Continual Learning for Vision-Language-Action Models via Autonomous Adapter Routing and Expansion** [2601.09512](http://arxiv.org/abs/2601.09512)
  > 为了教导机器人执行复杂的操作任务，现在的常见做法是根据特定任务的数据微调预先训练的视觉语言动作模型（VLA）。然而，由于这个配方更新了现有的表示，它不适合在现实世界中长期运行，机器人必须不断适应新的任务和环境，同时保留它们已经获得的知识。现有的机器人持续学习方法通​​常需要存储以前的数据（样本），难以应对长任务序列，或者依赖任务标识符进行部署。为了解决这些限制，我们提出了 CLARE，这是一种通用的、参数有效的框架，用于使用 VLA 进行无样本持续学习。 CLARE 将轻量级模块化适配器引入到选定的前馈层中，并仅在学习新任务时根据逐层特征相似性的指导，在必要时自动扩展模型。在部署过程中，基于自动编码器的路由机制会动态激活最相关的适配器，而无需任务标签。通过对 LIBERO 基准的大量实验，我们表明 CLARE 在新任务上实现了高性能，而不会灾难性地忘记早期任务，甚至显着优于基于示例的方法。代码和数据可在 https://tum-lsy.github.io/clare 获取。

- **2026-01-14** **MAD: Motion Appearance Decoupling for efficient Driving World Models** [2601.09452](http://arxiv.org/abs/2601.09452)
  > 最近的视频扩散模型生成逼真、时间连贯的视频，但它们不足以作为自动驾驶的可靠世界模型，其中结构化运动和物理一致的交互至关重要。将这些通用视频模型适应驱动领域已显示出希望，但通常需要大量特定领域的数据和昂贵的微调。我们提出了一种有效的适应框架，可以将通用视频扩散模型转换为具有最少监督的可控驾驶世界模型。关键思想是将运动学习与外观合成分离。首先，该模型适用于以简化形式预测结构化运动：骨架代理和场景元素的视频，重点学习物理和社会的合理性。然后，重复使用相同的主干来合成以这些运动序列为条件的逼真的 RGB 视频，有效地用纹理和照明“修饰”运动。这个两阶段过程反映了推理渲染范例：首先推断动态，然后渲染外观。我们的实验表明，这种解耦方法非常高效：采用 SVD，我们可以用不到 6% 的计算量来匹配之前的 SOTA 模型。扩展到 LTX，我们的 MAD-LTX 模型优于所有开源竞争对手，并支持一整套文本、自我和对象控制。项目页面：https://vita-epfl.github.io/MAD-World-Model/

- **2026-01-14** **Data Scaling for Navigation in Unknown Environments** [2601.09444](http://arxiv.org/abs/2601.09444)
  > 将模仿学习的导航策略推广到训练中未见过的环境仍然是一个重大挑战。我们通过首次大规模研究数据数量和数据多样性如何影响端到端、无地图视觉导航中的现实世界泛化来解决这个问题。我们使用在 35 个国家/地区 161 个地点收集的精心策划的 4,565 小时众包数据集，训练点目标导航策略，并评估其在四个国家/地区运行的人行道机器人的闭环控制性能，覆盖 125 公里的自动驾驶。   我们的结果表明，大规模训练数据可以在未知环境中实现零样本导航，接近通过特定环境演示训练的策略的性能。至关重要的是，我们发现数据多样性比数据数量重要得多。将训练集中的地理位置数量加倍可将导航错误减少约 15%，而从现有位置添加数据所带来的性能优势会因数据很少而饱和。我们还观察到，对于嘈杂的众包数据，基于简单回归的模型优于生成式和基于序列的架构。我们在项目页面上发布了我们的政策、评估设置和示例视频。

- **2026-01-14** **ReflexDiffusion: Reflection-Enhanced Trajectory Planning for High-lateral-acceleration Scenarios in Autonomous Driving** [2601.09377](http://arxiv.org/abs/2601.09377)
  > 在长尾场景中为自动驾驶车辆生成安全可靠的轨迹仍然是一项重大挑战，特别是对于急转弯等高横向加速度机动，这代表了关键的安全情况。由于数据不平衡，现有的轨迹规划器在这些场景中表现出系统性故障。这导致在高风险情况下对车辆动力学、道路几何形状和环境约束的建模不充分，从而导致当车辆在接近其物理极限时运行时轨迹预测不理想或不安全。在本文中，我们介绍了 ReflexDiffusion，这是一种新颖的推理阶段框架，可通过反射调整增强基于扩散的轨迹规划器。我们的方法在迭代去噪过程中引入了基于梯度的调整机制：在每次标准轨迹更新后，我们计算条件和无条件噪声预测之间的梯度，以明确放大关键条件信号，包括道路曲率和横向车辆动力学。这种放大强制严格遵守物理约束，特别是提高高横向加速操作期间的稳定性，其中精确的车路交互至关重要。在 nuPlan Test14-hard 基准测试中进行评估，与最先进的 (SOTA) 方法相比，ReflexDiffusion 在高横向加速场景下的驾驶得分提高了 14.1%。这表明推理时间轨迹优化可以通过动态强化接近处理极限的安全关键约束来有效地补偿训练数据稀疏性。该框架的架构无关的设计可以直接部署到现有的基于扩散的规划器，为提高自动驾驶汽车在具有挑战性的驾驶条件下的安全性提供了实用的解决方案。

- **2026-01-14** **Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving** [2601.09353](http://arxiv.org/abs/2601.09353)
  > 无车道交通环境使车辆能够更好地利用道路的横向容量，而不受车道保持的限制，从而提高交通流量。因此，我们的自动驾驶环境独特且更具挑战性。在这项工作中，我们考虑了一种用于无车道交通中单智能体自动驾驶的蒙特卡罗树搜索（MCTS）规划方法，其中我们制定的相关马尔可夫决策过程受到与强化学习框架相关的现有方法的影响。此外，MCTS 还配备了一个预先训练的神经网络 (NN)，用于指导选择阶段。该过程结合了神经网络的预测能力，可在计算约束下实现更明智的树搜索过程。在我们的实验评估中，我们考虑了解决安全性（通过碰撞率）和功效（通过测量的速度）的指标。然后，我们研究：（a）在无车道环境中各向同性状态信息对车辆的影响，导致轻推行为——车辆的策略由于存在更快的尾随行为而做出反应，（b）神经网络引导的 MCTS 变体的性能加速，以及（c）计算资源和解决方案质量之间的权衡。

- **2026-01-14** **The Quasar Feedback Survey: Revealing the importance of sensitive radio imaging for AGN identification deeper into the radio-quiet regime** [2601.09218](http://arxiv.org/abs/2601.09218)
  > 我们提出了新的亚弧秒 ( $\sim$0.3-1 arcsec; $\sim$1--3\,kpc) VLA 成像，在 1.4\,GHz 和 6\,GHz 下进行了 29 个光学选择，[O~{\sc iii}] 发光 ($L_{\rm [O III]}$ > 10$^{42.1}$\,erg\,s$^{-1}$)， $z<0.2$ 类星体取自扩展类星体反馈勘测（QFeedS；其中 $L_\mathrm{1.4\,GHz} = 10^{22.6}$--10$^{26.3}$\,W\,Hz$^{-1}$）。这 29 个新对象占据 QFeedS 样本中无线电功率分布的低端 ($L_\mathrm{1.4\,GHz}$=$10^{22.63}$--10$^{23.45}$\,W\,Hz$^{-1}$)，名义上是“无线电安静”。尽管如此，我们还是发现了活动星系核驱动的同步加速器活动的广泛证据。近 $\sim 31\,$per\,cent 在 $\sim$0.1--20\,kpc 尺度上表现出解析的射电结构，与紧凑型喷流或风驱动的流出一致，而 $\sim 90\,$per\,cent 显示陡峭的光谱（$α\lesssim -1$），表明光学薄同步加速器发射。结合形态、光谱指数和亮度-温度诊断，至少 $\sim38\,$per\,cent 的样本显示出清晰的活动星系核特征，而这些特征无法仅用恒星形成来解释。这些构成了扩展 QFeedS（现在有 71 个类星体，跨越无线电功率约 4$ dex）的第一个结果，并表明紧凑、低功率喷流和 AGN 冲击在无线电静默区域深处很常见。通过将这些高分辨率射电观测与多波长观测联系起来，将能够彻底了解来自类星体的反馈过程，深入到“无线电安静”状态。

- **2026-01-14** **Data-Driven Exploration and Insights into Temperature-Dependent Phonons in Inorganic Materials** [2601.09123](http://arxiv.org/abs/2601.09123)
  > 声子是原子晶格的量子化振动，是理解晶体固体中的热传输、结构稳定性和相行为的基础。尽管计算材料科学取得了进步，但大型材料数据库中振动特性的大多数预测都依赖于谐波近似，而忽略了关键的温度依赖性非谐波效应。在这里，我们提出了一个可扩展的计算框架，该框架结合了机器学习原子间势、非谐晶格动力学和高通量计算，以研究数千种材料中与温度相关的声子。通过使用高质量声子数据微调通用 M3GNet 原子间势，我们将声子预测精度提高了四倍，同时保持了计算效率。将这个改进的模型集成到随机自洽谐波近似的高通量实现中，我们计算了 4,669 种无机化合物的温度相关声子。我们的分析确定了控制非谐声子重整化的系统元素和结构趋势，在碱金属、钙钛矿衍生框架和相关系统中表现尤为强烈。在此数据集上训练的机器学习模型可识别驱动强不和谐性的关键原子尺度特征，包括弱键合、大原子半径和特定的配位图案。第一性原理验证证实，非简谐效应可以使某些材料的晶格热导率显着改变两到四倍。这项工作建立了一种强大而高效的数据驱动方法来预测有限温度声子行为，为设计和发现具有定制热和振动特性的材料提供了新途径。

- **2026-01-14** **The AI Hippocampus: How Far are We From Human Memory?** [2601.09113](http://arxiv.org/abs/2601.09113)
  > 记忆在增强现代大型语言模型和多模态法学硕士的推理、适应性和上下文保真度方面发挥着基础作用。随着这些模型从静态预测器过渡到能够持续学习和个性化推理的交互式系统，记忆机制的结合已成为其架构和功能演变的中心主题。这项调查对法学硕士和 MLLM 中的记忆进行了全面、结构化的综合，将文献组织成一个包含内隐、外显和代理记忆范式的有凝聚力的分类法。具体来说，该调查描绘了三个主要的记忆框架。内隐记忆是指嵌入预先训练的 Transformer 内部参数中的知识，包括记忆、联想检索和上下文推理的能力。最近的工作探索了解释、操纵和重新配置这种潜在记忆的方法。显式记忆涉及外部存储和检索组件，旨在通过动态、可查询的知识表示（例如文本语料库、密集向量和基于图形的结构）来增强模型输出，从而实现与信息源的可扩展和可更新的交互。代理记忆在自主代理中引入了持久的、临时扩展的记忆结构，促进多代理系统中的长期规划、自我一致性和协作行为，与具体化和交互式人工智能相关。除了文本之外，该调查还研究了多模式环境中的记忆整合，其中视觉、语言、音频和行动模式的一致性至关重要。讨论了关键的架构进步、基准测试任务和开放挑战，包括与内存容量、对齐、事实一致性和跨系统互操作性相关的问题。

- **2026-01-14** **Towards Open Environments and Instructions: General Vision-Language Navigation via Fast-Slow Interactive Reasoning** [2601.09111](http://arxiv.org/abs/2601.09111)
  > 视觉语言导航旨在使智能体能够根据语言指令导航到目标位置。传统的 VLN 通常遵循闭集假设，即训练和测试数据共享相同风格的输入图像和指令。然而，现实世界是开放的，充满了各种看不见的环境，给近集方法带来了巨大的困难。为此，我们专注于通用场景适应（GSA-VLN）任务，旨在通过引入多样化的环境和不一致的指令来学习广义导航能力。对于该任务，当面对未见的环境和指令时，挑战主要在于如何使智能体在导航过程中动态产生广义策略。最近的研究表明，通过快速和慢速认知系统，人类可以制定稳定的政策，从而加强他们对开放世界的适应。受这个想法的启发，我们提出了slow4fast-VLN，建立了动态​​交互的快慢推理框架。快速推理模块是一个端到端的策略网络，通过实时输入输出动作。它将执行记录累积在历史存储库中以构建内存。慢速推理模块分析快速推理模块生成的记忆。通过深度反思，提炼经验，增强决策的泛化能力。这些经验被结构化存储并用于不断优化快速推理模块。与将快慢推理视为独立机制的传统方法不同，我们的框架支持快慢交互。通过利用缓慢推理的经验。这种交互使得系统在面对未见过的场景时能够不断适应并有效地执行导航任务。

- **2026-01-13** **Reasoning Matters for 3D Visual Grounding** [2601.08811](http://arxiv.org/abs/2601.08811)
  > 具有强大推理能力的大型语言模型（LLM）的最新发展推动了数学、编码和科学发现等各个领域的研究。与此同时，由于最近 3D 视觉基础模型的推理能力有限，3D 视觉基础作为 3D 理解的一项基本任务仍然具有挑战性。当前的大多数方法都结合了文本编码器和视觉特征编码器来生成跨模态融合特征并预测引用对象。这些模型通常需要对大量 3D 注释数据进行监督训练。另一方面，最近的研究也集中在扩展合成数据以训练更强的 3D 视觉基础 LLM，然而，性能增益仍然有限，并且与数据收集成本不成比例。在这项工作中，我们提出了一种 3D 视觉基础数据管道，它能够自动合成 3D 视觉基础数据以及相应的推理过程。此外，我们利用生成的数据进行 LLM 微调，并引入 Reason3DVG-8B，这是一种强大的 3D 视觉基础 LLM，其性能优于之前基于 LLM 的方法 3D-GRAND，仅使用 1.6% 的训练数据，证明了我们数据的有效性以及推理在 3D 视觉基础中的重要性。

- **2026-01-13** **VLingNav: Embodied Navigation with Adaptive Reasoning and Visual-Assisted Linguistic Memory** [2601.08665](http://arxiv.org/abs/2601.08665)
  > VLA 模型通过统一感知和规划，同时继承了大型 VLM 强大的泛化能力，在实体导航方面展现出了巨大的潜力。然而，大多数现有的 VLA 模型依赖于直接从观察到行动的反应性映射，缺乏复杂、长视野导航任务所需的显式推理能力和持久记忆。为了应对这些挑战，我们提出了 VLingNav，一种基于语言驱动认知的实体导航 VLA 模型。首先，受人类认知双过程理论的启发，我们引入了一种自适应思维链机制，仅在必要时动态触发显式推理，使智能体能够在快速、直观的执行和缓慢、深思熟虑的计划之间流畅地切换。其次，为了处理长视野空间依赖性，我们开发了一个视觉辅助语言记忆模块，该模块构建了持久的、跨模式的语义记忆，使智能体能够回忆过去的观察结果，以防止重复探索并推断动态环境的运动趋势。对于训练方案，我们构建了 Nav-AdaCoT-2.9M，这是迄今为止最大的带有推理注释的具体化导航数据集，并通过自适应 CoT 注释进行了丰富，从而产生了能够调整思考时间和思考内容的推理范式。此外，我们还引入了在线专家指导的强化学习阶段，使模型能够超越纯粹的模仿学习，并获得更强大的、自我探索的导航行为。大量实验表明，VLingNav 在各种具体导航基准测试中实现了最先进的性能。值得注意的是，VLingNav以零镜头的方式转移到现实世界的机器人平台，执行各种导航任务，并展示了强大的跨域和跨任务泛化能力。

- **2026-01-13** **SoC: Semantic Orthogonal Calibration for Test-Time Prompt Tuning** [2601.08617](http://arxiv.org/abs/2601.08617)
  > 随着医疗保健或自动驾驶等关键决策系统越来越多地采用视觉语言模型 (VLM)，对其不确定性估计的校准变得至关重要。然而，在 VLM 测试时提示调整（TPT）文献中，这个维度在很大程度上没有得到充分探索，这些文献主要关注于提高其判别性能。最近最先进的主张在文本对上强制执行完全正交性提示嵌入以增强可分离性，从而增强校准。然而，正如我们在这项工作中理论上所表明的那样，完全正交约束的固有梯度将强烈推开语义相关的类，最终使模型过于自信。根据我们的发现，我们提出了语义正交校准（SoC），这是一种基于 Huber 的正则化器，可以在保持语义接近性的同时强制平滑原型分离，从而与之前基于正交性的方法相比改进校准。通过全面的实证验证，我们证明 SoC 不断提高校准性能，同时保持有竞争力的判别能力。

- **2026-01-13** **Coverage-Guided Road Selection and Prioritization for Efficient Testing in Autonomous Driving Systems** [2601.08609](http://arxiv.org/abs/2601.08609)
  > 自动驾驶辅助系统 (ADAS) 依靠广泛的测试来确保安全性和可靠性，但道路场景数据集通常包含冗余案例，这些案例会减慢测试过程，而不会改善故障检测。为了解决这个问题，我们提出了一种新颖的测试优先级框架，可以减少冗余，同时保留几何和行为多样性。根据ADAS驾驶行为的几何和动态特征对道路场景进行聚类，从中选择代表性案例来保证覆盖。最终根据几何复杂性、驾驶难度和历史故障对道路进行优先级排序，确保首先执行最关键和最具挑战性的测试。我们使用两个 ADAS 模型在 OPENCAT 数据集和 Udacity 自动驾驶汽车模拟器上评估我们的框架。平均而言，我们的方法实现了测试套件大小减少 89%，同时保留平均 79% 的失败道路场景。与随机基线相比，优先级策略将早期故障检测提高了 95 倍。

- **2026-01-13** **Real2Sim based on Active Perception with automatically VLM-generated Behavior Trees** [2601.08454](http://arxiv.org/abs/2601.08454)
  > 构建真实环境的精确仿真模型需要可靠地估计质量、几何形状、摩擦力和接触表面等物理参数。传统的真实到仿真 (Real2Sim) 管道依赖于手动测量或固定的预编程探索例程，这限制了它们对不同任务和用户意图的适应性。本文提出了一个 Real2Sim 框架，该框架可以自动生成和执行特定于任务的物理交互的行为树，以仅获取给定模拟目标所需的参数，而不依赖于预定义的任务模板或专家设计的探索例程。给定高级用户请求、不完整的模拟描述和场景的 RGB 观察，视觉语言模型执行多模态推理来识别相关对象，推断所需的物理参数，并生成由基本机器人动作组成的结构化行为树。由此产生的行为在扭矩控制的 Franka Emika Panda 上执行，从而实现了参数估计的合规、接触丰富的交互。获得的测量结果用于自动构建物理感知模拟。真实机械手的实验结果证明了对多个场景（包括遮挡物体和不完整的先验模型）中物体质量、表面高度和摩擦相关量的估计。所提出的方法实现了可解释、意图驱动和自主的 Real2Sim 管道，将高级推理与基于物理的机器人交互联系起来。

- **2026-01-13** **Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving?** [2601.08434](http://arxiv.org/abs/2601.08434)
  > 大型多模态模型 (LMM) 的出现提供了一种很有前途的技术，可以解决自动驾驶中模块化设计的局限性，这种局限性在需要持续的环境理解和逻辑推理的开放世界场景中经常会出现问题。此外，具身人工智能通过闭环交互促进策略优化，实现持续学习能力，从而将自动驾驶推向具身智能（El）驾驶。然而，如果仅依靠 LMM 来增强 EI 驱动而不进行联合决策，这种能力将受到限制。本文介绍了一种新颖的语义和策略双驱动混合决策框架来应对这一挑战，确保持续学习和联合决策。该框架融合了用于语义理解和认知表示的 LMM 以及用于实时策略优化的深度强化学习 (DRL)。我们首先介绍 EI 驱动和 LMM 的基本原理。此外，我们还研究了该框架带来的新机会，包括潜在好处和代表性用例。通过实验进行案例研究，以验证我们的框架在完成换道规划任务方面的性能优越性。最后，确定了赋能EI驾驶的几个未来研究方向，以指导后续工作。

- **2026-01-13** **Creativity in AI as Emergence from Domain-Limited Generative Models** [2601.08388](http://arxiv.org/abs/2601.08388)
  > 人工智能的创造力通常通过评估框架来解决，旨在衡量生成输出的新颖性、多样性或有用性。虽然这些方法为现代生成模型的行为提供了有价值的见解，但它们在很大程度上将创造力视为一种需要评估的属性，而不是一种需要明确建模的现象。与此同时，大规模生成系统，特别是多模式架构的最新进展，已经展示了日益复杂的模式重组形式，引发了关于机器创造力的本质和局限性的问题。本文提出了人工智能创造力的生成视角，将其视为嵌入有限信息环境中的有限领域生成模型的新兴属性。我们没有引入新的评估标准，而是关注创造性行为产生的结构和背景条件。我们将创造力概念分解为四个相互作用的组件——基于模式的生成、诱导世界模型、情境基础和任意性，并研究这些组件在多模式生成系统中的表现方式。通过将创造力植根于生成动力学和特定领域表征之间的相互作用，这项工作旨在提供一个技术框架，用于研究创造力作为人工智能系统中的新兴现象，而不是作为事后评估标签。

- **2026-01-13** **Large earthquakes follow highly unequal ones** [2601.08356](http://arxiv.org/abs/2601.08356)
  > 长期以来，人们推测构造板块处于自组织临界状态，古腾堡-里希特（幂）定律就是这一点的体现。最近的研究表明，对于接近临界点的系统，它们对外部驱动的响应的不平等可能表明接近临界点。在这项工作中，我们通过数值模拟和地震数据分析表明，大地震事件往往会遵循高度不平等的事件。我们已将该框架应用于各个构造活跃地区，例如北美、日本南部、东南亚部分地区和印度尼西亚。

- **2026-01-13** **Semantic Misalignment in Vision-Language Models under Perceptual Degradation** [2601.08355](http://arxiv.org/abs/2601.08355)
  > 视觉语言模型 (VLM) 越来越多地部署在自动驾驶和嵌入式人工智能系统中，其中可靠的感知对于安全的语义推理和决策至关重要。虽然最近的 VLM 在多模式基准上表现出强大的性能，但它们对现实感知退化的鲁棒性仍然知之甚少。在这项工作中，我们使用 Cityscapes 数据集上的语义分割作为代表性感知模块，系统地研究了在上游视觉感知受控退化的情况下 VLM 中的语义错位。我们引入了感知真实的损坏，仅导致传统分段指标适度下降，但观察到下游 VLM 行为的严重失败，包括幻觉对象提及、安全关键实体的遗漏以及不一致的安全判断。为了量化这些影响，我们提出了一组语言级错位指标，用于捕获幻觉、关键遗漏和安全误解，并分析它们与跨多个对比和生成 VLM 的分段质量的关系。我们的结果揭示了像素级鲁棒性和多模态语义可靠性之间的明显脱节，凸显了当前基于 VLM 的系统的关键局限性，并激发了对明确考虑安全关键应用中感知不确定性的评估框架的需求。

- **2026-01-13** **ActiveVLA: Injecting Active Perception into Vision-Language-Action Models for Precise 3D Robotic Manipulation** [2601.08325](http://arxiv.org/abs/2601.08325)
  > 机器人操纵的最新进展利用了预先训练的视觉语言模型 (VLM)，并探索将 3D 空间信号集成到这些模型中以进行有效的动作预测，从而产生了有前途的视觉语言动作 (VLA) 范式。然而，大多数现有方法都忽视了主动感知的重要性：它们通常依赖于静态的腕式摄像机来提供以末端执行器为中心的视角。因此，这些模型无法在任务执行过程中自适应地选择最佳视点或分辨率，这极大地限制了它们在长视野任务和细粒度操作场景中的性能。为了解决这些限制，我们提出了 ActiveVLA，这是一种新颖的视觉-语言-动作框架，赋予机器人主动感知能力，以实现高精度、细粒度的操作。 ActiveVLA采用从粗到细的范式，将过程分为两个阶段：（1）关键区域定位。 ActiveVLA 将 3D 输入投影到多视图 2D 投影上，识别关键 3D 区域，并支持动态空间感知。 (2)主动感知优化。 ActiveVLA 利用局部关键区域，使用主动视图选择策略来选择最佳视点。这些观点旨在最大化非模态相关性和多样性，同时最小化遮挡。此外，ActiveVLA 应用 3D 放大来提高关键区域的分辨率。这些步骤共同实现了更细粒度的主动感知，以实现精确的操作。大量实验表明，ActiveVLA 可实现精确的 3D 操作，并在三个模拟基准测试中优于最先进的基线。此外，ActiveVLA可以无缝转移到现实场景，使机器人能够在复杂环境中学习高精度任务。

- **2026-01-12** **Video Generation Models in Robotics -- Applications, Research Challenges, Future Directions** [2601.07823](http://arxiv.org/abs/2601.07823)
  > 视频生成模型已经成为物理世界的高保真模型，能够合成高质量视频，捕捉代理与其环境之间的细粒度交互，这些交互取决于多模式用户输入。它们令人印象深刻的功能解决了基于物理的模拟器面临的许多长期挑战，推动了许多问题领域的广泛采用，例如机器人技术。例如，视频模型可以实现逼真、物理一致的变形体模拟，而无需做出令人望而却步的简化假设，这是基于物理的模拟的主要瓶颈。此外，视频模型可以作为基础世界模型，以细粒度和富有表现力的方式捕捉世界的动态。因此，它们在描述复杂的物理交互时克服了纯语言抽象的有限表达能力。在本次调查中，我们回顾了视频模型及其在机器人技术中作为具体世界模型的应用，包括模仿学习中具有成本效益的数据生成和动作预测、强化学习中的动态和奖励建模、视觉规划和政策评估。此外，我们强调了阻碍视频模型在机器人技术中可靠集成的重要挑战，其中包括指令遵循不佳、违反物理等幻觉以及不安全的内容生成，以及重要的数据管理、培训和推理成本等基本限制。我们提出了解决这些开放研究挑战的潜在未来方向，以激励研究并最终促进更广泛的应用，特别是在安全关键的环境中。

- **2026-01-12** **Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation** [2601.07821](http://arxiv.org/abs/2601.07821)
  > 基于深度强化学习的后训练算法可以突破机器人模型针对特定目标的限制，例如通用性、准确性和鲁棒性。然而，在现实世界的探索过程中，需要干预的故障（IR 故障）（例如，机器人溅水或打碎易碎玻璃）不可避免地会发生，这阻碍了这种范例的实际部署。为了解决这个问题，我们引入了故障感知离线到在线强化学习（FARL），这是一种新的范式，可以最大限度地减少现实世界强化学习期间的故障。我们创建了 FailureBench，这是一个包含需要人工干预的常见故障场景的基准，并提出了一种算法，该算法集成了基于世界模型的安全批评家和离线训练的恢复策略，以防止在线探索期间出现故障。广泛的模拟和真实实验证明了 FARL 在显着减少 IR 故障方面的有效性，同时提高了在线强化学习训练后的性能和泛化能力。 FARL 将 IR 故障减少了 73.1%，同时在现实世界的 RL 训练后将性能平均提高了 11.3%。视频和代码可在 https://failure-aware-rl.github.io 上获取。

- **2026-01-12** **Leveraging 3D Representation Alignment and RGB Pretrained Priors for LiDAR Scene Generation** [2601.07692](http://arxiv.org/abs/2601.07692)
  > LiDAR 场景合成是解决自动驾驶等机器人任务 3D 数据稀缺问题的新兴解决方案。最近的方法采用扩散或流动匹配模型来生成逼真的场景，但与具有数百万个样本的 RGB 数据集相比，3D 数据仍然有限。我们引入了 R3DPA，这是第一个用于解锁 LiDAR 点云图像预训练先验的 LiDAR 场景生成方法，并利用自监督 3D 表示来获得最先进的结果。具体来说，我们 (i) 将生成模型的中间特征与自监督 3D 特征对齐，这大大提高了生成质量； (ii) 将知识从大规模图像预训练生成模型转移到 LiDAR 生成，从而缓解 LiDAR 数据集有限的问题； (iii) 在推理时启用点云控制，以仅使用无条件模型进行对象修复和场景混合。在 KITTI-360 基准测试中，R3DPA 实现了最先进的性能。代码和预训练模型可在 https://github.com/valeoai/R3DPA 获取。

- **2026-01-12** **ViewMorpher3D: A 3D-aware Diffusion Framework for Multi-Camera Novel View Synthesis in Autonomous Driving** [2601.07540](http://arxiv.org/abs/2601.07540)
  > 自动驾驶系统严重依赖多视图图像来确保准确的感知和稳健的决策。为了有效地开发和评估感知堆栈和规划算法，逼真的闭环模拟器是必不可少的。虽然高斯溅射等 3D 重建技术为模拟器构建提供了有希望的途径，但渲染的新颖视图通常会出现伪影，特别是在外推视角或可用观察稀疏时。   我们推出 ViewMorpher3D，这是一种基于图像扩散模型的多视图图像增强框架，旨在提升驾驶场景中的真实感和多视图一致性。与单视图方法不同，ViewMorpher3D 联合处理一组以相机姿势、3D 几何先验以及时间相邻或空间重叠参考视图为条件的渲染视图。这使得模型能够推断缺失的细节、抑制渲染伪影并强制执行跨视图一致性。   我们的框架可容纳不同数量的摄像机和灵活的参考/目标视图配置，使其能够适应不同的传感器设置。对现实世界驾驶数据集的实验表明，图像质量指标得到了显着改善，有效减少了伪影，同时保持了几何保真度。

- **2026-01-12** **Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions** [2601.07516](http://arxiv.org/abs/2601.07516)
  > 视觉语言模型越来越多地用作多模式会话代理（MCA）来执行不同的会话任务。最近，强化学习 (RL) 已被广泛探索，用于使 MCA 适应各种人机交互场景。尽管在泛化性能方面显示出巨大的增强，但通过 RL 微调 MCA 在处理极大的文本标记空间方面仍然面临挑战。为了解决这个问题，我们学习了一个紧凑的潜在动作空间来进行强化学习微调。具体来说，我们采用从观察中学习的机制来构建潜在动作空间的密码本，其中利用未来的观察来估计当前的潜在动作，这些动作可以进一步用于重建未来的观察。然而，图像-文本配对数据的稀缺阻碍了学习具有足够覆盖范围的码本。因此，我们利用成对的图像文本数据和纯文本数据来构建潜在动作空间，使用跨模式投影仪将文本嵌入转换为图像文本嵌入。我们在成对的图像文本数据上初始化跨模态投影仪，并在大量纯文本数据上进一步训练它，并使用新颖的循环一致性损失来增强其鲁棒性。我们证明，我们基于潜在动作的方法在各种 RL 算法的两个对话任务上优于竞争基线。

- **2026-01-12** **Task Prototype-Based Knowledge Retrieval for Multi-Task Learning from Partially Annotated Data** [2601.07474](http://arxiv.org/abs/2601.07474)
  > 多任务学习 (MTL) 在自动驾驶和机器人等现实应用中至关重要，可以同时处理不同的任务。然而，由于标签成本的原因，获取所有任务的完整注释数据是不切实际的。现有的部分标记 MTL 方法通常依赖于未标记任务的预测，这使得难以建立可靠的任务关联，并可能导致负迁移和次优性能。为了解决这些问题，我们提出了一个基于原型的知识检索框架，该框架实现了稳健的 MTL，而不是依赖于未标记任务的预测。我们的框架由两个关键组件组成：（1）嵌入任务特定特征并量化任务关联的任务原型，以及（2）知识检索转换器，根据这些关联自适应地细化特征表示。为了实现这一目标，我们引入了关联知识生成（AKG）损失，以确保任务原型一致地捕获特定于任务的特征。大量的实验证明了我们框架的有效性，突出了其强大的多任务学习的潜力，即使只注释了任务的子集。

- **2026-01-12** **Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning** [2601.07463](http://arxiv.org/abs/2601.07463)
  > 离线多智能体强化学习（MARL）旨在使用预先收集的数据集解决多智能体系统中的协作决策问题。现有的离线 MARL 方法主要限制数据集分布内的训练，导致策略过于保守，难以在数据支持之外进行泛化。虽然基于模型的方法通过使用学习世界模型生成的合成数据扩展原始数据集提供了一种有前途的解决方案，但多智能体系统的高维性、非平稳性和复杂性使得准确估计离线 MARL 中的转换和奖励函数变得具有挑战性。考虑到直接建模联合动力学的困难，我们提出了一种局部到全局（LOGO）世界模型，这是一种利用局部预测（更容易估计）来推断全局状态动态的新颖框架，从而提高预测准确性，同时隐式捕获智能体依赖关系。使用经过训练的世界模型，我们生成合成数据来扩充原始数据集，扩展有效的状态-动作空间。为了确保可靠的策略学习，我们进一步引入了一种不确定性感知采样机制，该机制通过预测不确定性对合成数据进行自适应加权，减少近似误差传播到策略。与传统的基于集成的方法相比，我们的方法仅需要一个额外的编码器来进行不确定性估计，从而在保持准确性的同时显着减少计算开销。针对 8 个基线的 8 个场景的广泛实验表明，我们的方法超越了标准离线 MARL 基准的最先进基线，为可推广的离线多智能体学习建立了一个新的基于模型的基线。

- **2026-01-12** **Software-Hardware Co-optimization for Modular E2E AV Paradigm: A Unified Framework of Optimization Approaches, Simulation Environment and Evaluation Metrics** [2601.07393](http://arxiv.org/abs/2601.07393)
  > 模块化端到端（ME2E）自动驾驶范例将模块化可解释性与全局优化能力相结合，并表现出强大的性能。然而，现有的研究主要集中在准确性的提高，而推理延迟和能耗等关键的系统级因素往往被忽视，导致模型设计日益复杂，阻碍了实际部署。先前在模型压缩和加速方面的努力通常是单独优化软件或硬件方面。纯软件优化无法从根本上消除中间张量访问和算子调度开销，而纯硬件优化则受到模型结构和精度的限制。因此，此类优化在现实世界中带来的好处通常是有限的。为了应对这些挑战，本文提出了一种可重用的ME2E自动驾驶推理软硬件协同优化和闭环评估框架。该框架在统一的系统级目标下将软件级模型优化与硬件级计算优化联合集成。此外，引入多维度评估指标，综合考虑安全性、舒适性、效率、延迟和能耗来评估系统性能，从而能够定量比较不同优化策略。跨多个 ME2E 自动驾驶堆栈的实验表明，所提出的框架保留了基线水平的驾驶性能，同时显着降低了推理延迟和能耗，实现了整体系统级的实质性改进。这些结果表明，所提出的框架为 ME2E 自动驾驶系统的高效部署提供了实用且可操作的指导。

- **2026-01-12** **Motion Focus Recognition in Fast-Moving Egocentric Video** [2601.07154](http://arxiv.org/abs/2601.07154)
  > 从视觉-语言-动作（VLA）系统到机器人技术，现有的以自我为中心的数据集主要关注动作识别任务，而很大程度上忽视了运动分析在运动和其他快速运动场景中的固有作用。为了弥补这一差距，我们提出了一种实时运动焦点识别方法，可以从任何以自我为中心的视频中估计主体的运动意图。我们的方法利用相机姿态估计的基础模型，并引入系统级优化来实现高效且可扩展的推理。在收集的以自我为中心的动作数据集上进行评估，我们的方法通过滑动批量推理策略实现了实时性能和可管理的内存消耗。这项工作使得以运动为中心的分析对于边缘部署变得实用，并为现有的以自我为中心的体育和快速运动活动研究提供了补充视角。

- **2026-01-12** **SC-MII: Infrastructure LiDAR-based 3D Object Detection on Edge Devices for Split Computing with Multiple Intermediate Outputs Integration** [2601.07119](http://arxiv.org/abs/2601.07119)
  > 使用基于 LiDAR 的点云数据和深度神经网络进行 3D 物体检测对于自动驾驶技术至关重要。然而，由于高计算需求和能耗，在边缘设备上部署最先进的模型面临着挑战。此外，单个激光雷达设置存在盲点。本文提出了 SC-MII，即边缘设备上基于多基础设施 LiDAR 的 3D 物体检测，用于具有多个中间输出集成的分割计算。在 SC-MII 中，边缘设备通过初始 DNN 层处理本地点云，并将中间输出发送到边缘服务器。服务器集成这些功能并完成推理，减少延迟和设备负载，同时提高隐私性。在真实数据集上的实验结果显示，速度提高了 2.19 倍，边缘设备处理时间减少 71.6%，准确率最多下降 1.09%。

- **2026-01-11** **Efficient Visual Question Answering Pipeline for Autonomous Driving via Scene Region Compression** [2601.07092](http://arxiv.org/abs/2601.07092)
  > 自动驾驶越来越依赖视觉问答 (VQA)，使车辆能够通过分析视觉输入和文本查询来了解复杂的环境。目前，该领域 VQA 的首要关注点是对快速延迟和实时处理的严格要求，因为延迟直接影响这一安全关键型应用程序中的实际安全性。然而，当前最先进的 VQA 模型，特别是大型视觉语言模型 (VLM)，通常优先考虑性能而不是计算效率。这些模型通常会为每一帧处理密集的补丁标记，从而导致过高的计算成本 (FLOP) 和显着的推理延迟，尤其是对于长视频序列。这种关注限制了它们在实时自动驾驶场景中的实际部署。为了解决这个问题，我们提出了一种用于自动驾驶 VQA 任务的高效 VLM 框架，SRC-Pipeline。它学习将早期帧令牌压缩为少量高级令牌，同时保留最近帧的完整补丁令牌。自动驾驶视频问答任务的实验表明，我们的方法在保持可比性能的同时实现了 66% 的 FLOP 减少，使 VLM 能够在实时、安全关键的自动驾驶环境中更有效地运行。

- **2026-01-11** **PALM: Progress-Aware Policy Learning via Affordance Reasoning for Long-Horizon Robotic Manipulation** [2601.07060](http://arxiv.org/abs/2601.07060)
  > 视觉-语言-动作（VLA）模型的最新进展在机器人操作方面显示出了希望，但它们仍然在长期、多步骤任务方面遇到困难。现有方法缺乏内部推理机制，无法识别与任务相关的交互线索或跟踪子任务内的进度，从而导致严重的执行错误，例如重复操作、错过步骤和过早终止。为了应对这些挑战，我们引入了 PALM，这是一个 VLA 框架，围绕以交互为中心的可供性推理和子任务进度线索构建策略学习。 PALM 提炼出互补的可供性表示，捕获对象相关性、接触几何、空间放置和运动动力学，并作为视觉运动控制的任务相关锚点。为了进一步稳定长期执行，PALM 可以预测子任务内的连续进度，从而实现无缝子任务转换。在广泛的模拟和现实世界实验中，PALM 始终优于基线，在 LIBERO-LONG 上实现了 91.8% 的成功率，在 CALVIN ABC->D 上平均长度提高了 12.5%，在三个长视野泛化设置中比现实世界基线提高了 2 倍。

- **2026-01-11** **PANDA-film: an automated system for electrodeposition of polymer thin films and their wetting analysis** [2601.07043](http://arxiv.org/abs/2601.07043)
  > 聚合物薄膜广泛用作功能性和保护性涂层。然而，由于必须考虑大量因素以及大多数合成和表征方法的手动性质，确定产生所需功能的组成和加工条件是一个繁琐的过程。自动驾驶实验室 (SDL) 或准备和测试材料样品的机器人系统旨在通过有效探索复杂参数空间来克服这一瓶颈。在本文中，我们报告了聚合物分析与发现阵列 (PANDA) 薄膜的开发和测试，这是一种模块化 SDL，用于电化学合成聚合物薄膜，然后确定其水接触角作为表面能的量度。该系统设计为高度模块化，并基于低成本龙门平台，以方便采用。除了验证流体处理和电化学任务之外，我们还引入了两种新颖的模块化功能，使 PANDA-film 能够持续研究薄膜的润湿特性：(1) 电磁加盖/脱盖系统，以减轻流体蒸发，以及 (2) 自上而下的光学方法，用于根据反射率确定水接触角。这些功能通过使用聚合物网络电沉积 (EPoN) 沉积和表征聚甲基丙烯酸烯丙酯 (PAMA) 薄膜来验证。包括复制 PANDA-film 硬件和软件的全面详细信息。

- **2026-01-11** **Conditional Normalizing Flows for Forward and Backward Joint State and Parameter Estimation** [2601.07013](http://arxiv.org/abs/2601.07013)
  > 用于状态估计的传统滤波算法（例如经典卡尔曼滤波、无迹卡尔曼滤波和粒子滤波器）在应用于不确定性遵循任意非高斯分布和潜在多模态分布的非线性系统时表现出性能下降。本研究回顾了最近通过基于条件归一化流的非线性过滤进行状态估计的方法，其中条件嵌入是由标准 MLP 架构、变压器或选择性状态空间模型（如 Mamba-SSM）生成的。此外，我们还测试了最佳传输启发的动力学损失项在减轻由大量变换组成的流中过度参数化方面的有效性。我们研究了这些方法在与自动驾驶和患者群体动态相关的应用中的性能，特别关注它们如何处理时间反演和链式预测。最后，我们评估了各种调节策略在现实世界的 COVID-19 联合 SIR 系统预测和参数估计中的应用性能。

- **2026-01-11** **On-the-Fly VLA Adaptation via Test-Time Reinforcement Learning** [2601.06748](http://arxiv.org/abs/2601.06748)
  > 视觉-语言-动作模型最近已成为通用机器人学习的强大范例，使代理能够将视觉观察和自然语言指令映射到可执行的机器人动作。尽管很受欢迎，但它们主要通过监督微调或训练时强化学习进行训练，需要明确的微调阶段、人工干预或受控数据收集。因此，现有方法仍然不适合具有挑战性的模拟或物理世界部署，其中机器人必须自主、灵活地响应不断变化的环境。为了解决这一限制，我们引入了 VLA 测试时强化学习 (TT-VLA)，这是一个能够在推理过程中进行动态策略调整的框架。 TT-VLA 制定了密集的奖励机制，利用逐步的任务进度信号来细化测试期间的行动策略，同时保留 SFT/RL 训练的先验，使其成为当前 VLA 模型的有效补充。实证结果表明，我们的方法增强了模拟和现实环境中动态的、以前未见过的场景中的整体适应性、稳定性和任务成功率。我们相信 TT-VLA 为实现自我改进、部署就绪的 VLA 迈出了原则性的一步。

- **2026-01-10** **Object-Centric World Models Meet Monte Carlo Tree Search** [2601.06604](http://arxiv.org/abs/2601.06604)
  > 在本文中，我们介绍了 ObjectZero，这是一种新颖的强化学习 (RL) 算法，它利用对象级表示的强大功能来更有效地对动态环境进行建模。与将世界作为单个无差别输入进行处理的传统方法不同，我们的方法采用图神经网络（GNN）来捕获多个对象之间复杂的交互。这些可以被操纵并相互交互的对象是我们的模型理解环境的基础。我们在充满各种交互式对象的复杂环境中训练该算法，展示了其有效学习和预测对象动态的能力。我们的结果强调，基于以对象为中心的表示操作的结构化世界模型可以成功集成到使用蒙特卡罗树搜索作为规划模块的基于模型的强化学习算法中。

- **2026-01-10** **SparseOccVLA: Bridging Occupancy and Vision-Language Models via Sparse Queries for Unified 4D Scene Understanding and Planning** [2601.06474](http://arxiv.org/abs/2601.06474)
  > 在自动驾驶中，视觉语言模型（VLM）擅长高级推理，而语义占用则提供细粒度的细节。尽管各个领域取得了重大进展，但仍然没有一种方法可以有效地整合这两种范式。传统的 VLM 面临着令牌爆炸和有限的时空推理的问题，而语义占用提供了统一、明确的空间表示，但过于密集，无法与 VLM 有效集成。为了应对这些挑战并弥合 VLM 和占用率之间的差距，我们提出了 SparseOccVLA，这是一种新颖的视觉-语言-动作模型，它统一了由稀疏占用查询支持的场景理解、占用预测和轨迹规划。从轻量级稀疏占用编码器开始，SparseOccVLA 生成紧凑但信息丰富的稀疏占用查询，充当视觉和语言之间的单一桥梁。这些查询与语言空间对齐，并由法学硕士进行推理，以实现统一的场景理解和未来的占用预测。此外，我们引入了 LLM 引导的锚扩散规划器，具有解耦锚评分和去噪，以及跨模型轨迹条件融合。 SparseOccVLA 在 CIDEr 上相对于 OmniDrive-nuScenes 上最先进的技术提高了 7%，在 Occ3D-nuScenes 上的 mIoU 分数提高了 0.5，并在 nuScenes 基准上设置了最先进的开环规划指标，展示了其强大的整体能力。

- **2026-01-10** **CulinaryCut-VLAP: A Vision-Language-Action-Physics Framework for Food Cutting via a Force-Aware Material Point Method** [2601.06451](http://arxiv.org/abs/2601.06451)
  > 食品切割是视觉和机器人操作交叉领域的一种高度实用但尚未充分开发的应用。这项任务仍然具有挑战性，因为刀和可变形材料之间的相互作用是高度非线性的，通常会带来大变形、频繁接触和拓扑变化，这反过来又阻碍了稳定和安全的大规模数据收集。   为了应对这些挑战，我们提出了一个统一的框架，将视觉语言动作（VLA）数据集与基于材料点方法（MPM）构建的物理真实切割模拟器结合起来。我们的模拟器采用 MLS-MPM 作为其计算核心，即使在拓扑变化的切割下，也能减少数值耗散和能量漂移，同时保留旋转和剪切响应。在切割过程中，力和应力分布是根据颗粒和网格之间的脉冲交换来估计的，从而能够稳定跟踪瞬态接触力和能量传递。   我们还提供了一个基准数据集，集成了不同的切割轨迹、多视图视觉观察和细粒度的语言指令，以及力-扭矩和工具-姿势标签，以提供物理一致的训练信号。   这些组件实现了学习-评估循环，尊重切割的核心物理原理，并为在可变形物体操作中推进 VLA 模型奠定了安全、可重复和可扩展的基础。

- **2026-01-10** **WHU-PCPR: A cross-platform heterogeneous point cloud dataset for place recognition in complex urban scenes** [2601.06442](http://arxiv.org/abs/2601.06442)
  > 基于点云的位置识别（PCPR）在自动驾驶、机器人定位和导航以及地图更新等应用中展现出巨大的潜力。在实际应用中，用于位置识别的点云通常是从不同平台和不同场景的激光雷达获取的。然而，现有的PCPR数据集缺乏场景、平台和传感器的多样性，限制了相关研究的有效发展。为了解决这一差距，我们建立了 WHU-PCPR，这是一个专为地点识别而设计的跨平台异构点云数据集。该数据集通过其独特的特征与现有数据集区分开来：1）跨平台异构点云：从测量级车载移动激光扫描（MLS）系统和低成本便携式头盔式激光扫描（PLS）系统收集，每个系统都配备了不同的机械和固态LiDAR传感器。 2）复杂的定位场景：涵盖城市和校园道路场景的实时和长期变化。 3）大范围空间覆盖：60个月内轨迹长82.3公里，无重复路线约30公里。基于WHU-PCPR，我们对几种具有代表性的PCPR方法进行了广泛的评估和深入分析，并对关键挑战和未来的研究方向进行了简洁的讨论。数据集和基准代码可在 https://github.com/zouxianghong/WHU-PCPR 获取。

- **2026-01-09** **A Critical Examination of Active Learning Workflows in Materials Science** [2601.05946](http://arxiv.org/abs/2601.05946)
  > 主动学习 (AL) 在材料科学中发挥着至关重要的作用，可实现诸如构建用于原子模拟的机器学习原子间势以及自动驾驶实验室的运行等应用。尽管应用广泛，但 AL 工作流程的可靠性和有效性取决于隐含的设计假设，而这些假设很少被系统地检验。在这里，我们严格评估材料科学中部署的 AL 工作流程，并研究关键设计选择（例如替代模型、采样策略、不确定性量化和评估指标）与其性能的关系。通过识别常见陷阱并讨论实际的缓解策略，我们为从业者提供材料科学中 AL 工作流程的高效设计、评估和解释的指导。

- **2026-01-09** **Reverse segregation and self-organization in inclined chute flows of bidisperse granular mixtures** [2601.05940](http://arxiv.org/abs/2601.05940)
  > 在细粒和粗粒球形颗粒的双分散混合物的稳定倾斜溜槽流的通常分离情况下，粗颗粒向自由表面上升，在流动堆顶部形成富含粗粒的区域。相反，超过大约 4 的阈值粗细直径比时，粗颗粒的重量超过了偏析驱动力，导致单个粗颗粒下沉在堆内并产生反向偏析状态。然而，当粒径比超过 4 {\textit{并且}} 粗颗粒质量分数相当大时，对桩结构集体演化的理解仍然缺乏。为了探索这种广泛的双分散极限，我们进行了离散元法模拟，考虑了高达 8 的平均粒径比和 0.1 至 0.9 的粗颗粒质量分数。稳态流动剖面揭示了一些取决于直径比和质量分数的有趣行为。这些包括先前确定的从普通偏析到反向偏析的转变，以及新发现的自组织成沿剪切梯度方向堆叠的交替的粗粒和细粒层的趋势，层厚度由粗粒直径决定。更全面地了解这种规模的分离可以为商业规模的增强混合或分层技术铺平道路。

- **2026-01-09** **Can We Predict Before Executing Machine Learning Agents?** [2601.05930](http://arxiv.org/abs/2601.05930)
  > 自主机器学习代理彻底改变了科学发现，但它们仍然受到生成-执行-反馈范式的限制。以前的方法存在严重的执行瓶颈，因为假设评估严格依赖于昂贵的物理执行。为了绕过这些物理限制，我们从世界模型中汲取灵感，将执行先验内在化，用即时预测推理代替昂贵的运行时检查。在这项工作中，我们形式化了以数据为中心的解决方案偏好的任务，并构建了一个包含 18,438 个成对比较的综合语料库。我们证明，法学硕士在提供经过验证的数据分析报告时表现出显着的预测能力，实现了 61.5% 的准确度和强大的置信度校准。最后，我们在 FOREAGENT 中实例化该框架，该代理采用 Predict-then-Verify 循环，实现了 6 倍的收敛加速，同时超出基于执行的基线 +6%。我们的代码和数据集很快将在 https://github.com/zjunlp/predict-before-execute 上公开。

- **2026-01-09** **When legs and bodies synchronize: Two-level collective dynamics in dense crowds** [2601.05867](http://arxiv.org/abs/2601.05867)
  > 超密集的人群中，人与人之间不可避免地发生身体接触，造成了重大的安全隐患。然而，推动他们集体行为的潜在动力仍然知之甚少。现有的密集人群模型大多是二维的和基于接触的，忽略了控制个体平衡运动的生物力学机制。在这项研究中，我们引入了一个最小的两级行人模型，该模型将上半身和腿部动力学耦合起来，使我们能够捕获个体尺度上平衡和不平衡状态之间的转变。尽管以前的模型未能实现这一目标，但这种耦合产生了凭经验观察到的集体行为，例如自组织波浪和人群内的大规模旋转运动。该模型将基本的个体生物力学概念和宏观流动动力学联系起来，为建模和理解超密集人群中的集体运动提供了一个新的框架。

- **2026-01-09** **Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals** [2601.05848](http://arxiv.org/abs/2601.05848)
  > 视频生成领域的最新进展使得能够模拟机器人和规划的潜在未来的“世界模型”的开发成为可能。然而，为这些模型指定精确的目标仍然是一个挑战；文本指令通常过于抽象，无法捕捉物理细微差别，而目标图像通常无法为动态任务指定。为了解决这个问题，我们引入了 Goal Force，这是一种新颖的框架，允许用户通过明确的力向量和中间动力学来定义目标，反映了人类如何概念化物理任务。我们在合成因果原语（例如弹性碰撞和倒下的多米诺骨牌）的精选数据集上训练视频生成模型，教导它通过时间和空间传播力。尽管接受了简单物理数据的训练，但我们的模型对复杂的现实世界场景（包括工具操作和多对象因果链）表现出出色的零样本泛化能力。我们的结果表明，通过将视频生成基于基本的物理交互，模型可以作为隐式神经物理模拟器出现，从而无需依赖外部引擎即可实现精确的物理感知规划。我们在项目页面发布了所有数据集、代码、模型权重和交互式视频演示。

- **2026-01-09** **GeoSurDepth: Spatial Geometry-Consistent Self-Supervised Depth Estimation for Surround-View Cameras** [2601.05839](http://arxiv.org/abs/2601.05839)
  > 准确的环视深度估计为激光传感器提供了一种有竞争力的替代方案，对于自动驾驶中的 3D 场景理解至关重要。虽然先前的研究提出了各种主要侧重于在光度水平上强制执行交叉视图约束的方法，但很少有人明确利用单目和环视设置中固有的丰富几何结构。在这项工作中，我们提出了 GeoSurDepth，一个利用几何一致性作为环视深度估计的主要线索的框架。具体来说，我们利用基础模型作为伪几何先验和特征表示增强工具来指导网络保持空间 3D 空间中的表面法线一致性，并规范 2D 中对象和纹理一致的深度估计。此外，我们引入了一种新颖的视图合成管道，其中通过空间扭曲重建密集深度来实现 2D-3D 提升，鼓励跨时间、空间和时空上下文的额外光度监督，并补偿单视图图像重建的局限性。最后，新提出的自适应联合运动学习策略使网络能够自适应地强调信息丰富的空间几何线索，以改进运动推理。对 DDAD 和 nuScenes 的大量实验表明，GeoSurDepth 实现了最先进的性能，验证了我们方法的有效性。我们的框架强调了利用几何相干性和一致性来实现稳健的自监督多视图深度估计的重要性。

- **2026-01-09** **Modular Autonomy with Conversational Interaction: An LLM-driven Framework for Decision Making in Autonomous Driving** [2601.05806](http://arxiv.org/abs/2601.05806)
  > 大型语言模型 (LLM) 的最新进展为自动驾驶系统 (ADS) 创建自然语言界面提供了新的机会，超越了严格的输入。本文解决了将人类语言的复杂性映射到模块化 ADS 软件的结构化动作空间的挑战。我们提出了一个框架，将基于 LLM 的交互层与 Autoware（一种广泛使用的开源软件）集成。该系统使乘客能够发出高级命令，从查询状态信息到修改驾驶行为。我们的方法基于三个关键组成部分：交互类别的分类、用于命令翻译的以应用程序为中心的领域特定语言（DSL）以及安全保护验证层。两阶段的法学硕士架构通过根据最终的执行状态提供反馈来确保高度透明度。评估确认了系统的计时效率和翻译稳健性。模拟成功验证了所有五个交互类别的命令执行。这项工作为模块化和安全意识自治堆栈中的可扩展、DSL 辅助交互奠定了基础。

- **2026-01-09** **From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation** [2601.05787](http://arxiv.org/abs/2601.05787)
  > 视觉语言模型越来越多地部署为操作桌面和浏览器的计算机使用代理（CUA）。性能最佳的 CUA 是基于框架的系统，可分解规划和执行，而端到端的屏幕截图到操作策略更易于部署，但在 OSWorld-Verified 等基准测试中落后。像 OSWorld 这样的 GUI 数据集存在两个瓶颈：它们仅公开数百个交互式、可验证的任务和环境，并且必须通过与这些环境交互来收集专家轨迹，从而使得此类数据难以扩展。因此，我们询问可验证奖励（RLVR）的强化学习如何最好地利用一小部分现有的专家轨迹来训练端到端策略。天真地将这些离策略轨迹混合到在策略 RLVR 中是很脆弱的：即使在格式转换之后，专家轨迹也会表现出结构不匹配和学习者的分布变化。我们提出了 BEPA（双层专家策略同化），它通过基本策略 (LEVEL-1) 下的自滚动可达轨迹和 RLVR (LEVEL-2) 中使用的按任务动态更新的缓存，将静态专家跟踪转换为策略一致的指导。在 OSWorld-Verified 上，BEPA 将 UITARS1.5-7B 的成功率从 22.87% 提高到 32.13%，并将保留的分裂率从 5.74% 提高到 10.30%，在 MMBench-GUI 和 Online-Mind2Web 上保持一致的增长。我们的代码和数据可在以下位置获取：https://github.com/LEON-gittech/Verl_GUI.git

- **2026-01-09** **Drivora: A Unified and Extensible Infrastructure for Search-based Autonomous Driving Testing** [2601.05685](http://arxiv.org/abs/2601.05685)
  > 基于搜索的测试对于评估自动驾驶系统 (ADS) 的安全性和可靠性至关重要。然而，现有的方法通常建立在异构框架（例如，不同的场景空间、模拟器和 ADS）上，这需要付出相当大的努力来重用和适应不同的设置。为了应对这些挑战，我们推出了 Drivora，这是一个统一且可扩展​​的基础架构，用于基于广泛使用的 CARLA 模拟器构建的基于搜索的 ADS 测试。 Drivora 引入了统一的场景定义 OpenScenario，它使用低级可操作参数指定场景，以确保与现有方法的兼容性，同时支持新测试设计的可扩展性（例如，多自动驾驶车辆测试）。除此之外，Drivora 将测试引擎、场景执行和 ADS 集成解耦。测试引擎利用进化计算探索新场景，并支持核心组件的灵活定制。场景执行可以使用并行执行机制运行任意场景，最大限度地提高大规模批量模拟的硬件利用率。对于 ADS 集成，Drivora 通过统一接口提供对 12 个 ADS 的访问，从而简化了配置并简化了新 ADS 的合并。我们的工具可在 https://github.com/MingfeiCheng/Drivora 上公开获取。

- **2026-01-09** **EvoQRE: Modeling Bounded Rationality in Safety-Critical Traffic Simulation via Evolutionary Quantal Response Equilibrium** [2601.05653](http://arxiv.org/abs/2601.05653)
  > 自动驾驶汽车现有的交通模拟框架通常依赖于模仿学习或博弈论方法来解决纳什或粗略相关均衡，隐含地假设完全理性的代理。然而，人类驾驶员表现出有限理性，在认知和感知约束下做出近似最优的决策。我们提出了 EvoQRE，这是一个原则框架，用于将安全关键型交通交互建模为通过量子响应均衡 (QRE) 和进化博弈动力学解决的一般和马尔可夫博弈。 EvoQRE 将预先训练的生成世界模型与熵正则化复制动力学相结合，在保持平衡结构的同时捕获随机人类行为。我们提供了严格的理论结果，证明所提出的动力学在两时间尺度随机近似下收敛于 Logit-QRE，在弱单调性假设下显式收敛率为 O(log k / k^{1/3})。我们使用基于混合物和基于能量的策略表示进一步将 QRE 扩展到连续行动空间。 Waymo 开放运动数据集和 nuPlan 基准测试表明，EvoQRE 实现了最先进的现实性、改进的安全指标，并通过可解释的合理性参数可控地生成各种安全关键场景。


<p align=right>(<a href=#updated-on-20260115>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

