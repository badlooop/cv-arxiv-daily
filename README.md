[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.07.24
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-07-22**|**BoostMVSNeRFs: Boosting MVS-based NeRFs to Generalizable View Synthesis in Large-scale Scenes**|虽然神经辐射场（NeRFs）表现出了卓越的质量，但其漫长的训练时间仍然是一个限制。可推广和基于MVS的NeRF虽然能够缩短训练时间，但往往会在质量上进行权衡。本文提出了一种称为BoostMVSNeRFs的新方法，以提高基于MVS的NeRF在大规模场景中的渲染质量。我们首先确定了基于MVS的NeRF方法的局限性，例如受限的视口覆盖和由于有限的输入视图引起的伪影。然后，我们通过提出一种在体绘制过程中选择和组合多个成本体积的新方法来解决这些局限性。我们的方法不需要训练，可以以前馈方式适应任何基于MVS的NeRF方法，以提高渲染质量。此外，我们的方法也是端到端可训练的，允许对特定场景进行微调。我们通过在大规模数据集上的实验证明了我们的方法的有效性，在大规模场景和无界户外场景中显示出显著的渲染质量改进。BoostMVSNeRFs的源代码发布于https://su-terry.github.io/BoostMVSNeRFs/. et.al.|[2407.15848](http://arxiv.org/abs/2407.15848)|null|
|**2024-07-22**|**6DGS: 6D Pose Estimation from a Single Image and a 3D Gaussian Splatting Model**|我们提出了6DGS来估计给定表示场景的3D高斯散斑（3DGS）模型的目标RGB图像的相机姿态。6DGS避免了典型的合成分析方法（如iNeRF）的迭代过程，该方法还需要初始化相机姿态才能收敛。相反，我们的方法通过反转3DGS渲染过程来估计6DoF姿态。从物体表面开始，我们定义了一个辐射Ellicell，它均匀地生成从每个椭球体出发的光线，这些椭球体对3DGS模型进行了参数化。每个Ellicell光线都与每个椭球体的渲染参数相关联，这些参数又用于获得目标图像像素和投射光线之间的最佳绑定。然后对这些像素光线绑定进行排序，以选择得分最高的光线束，它们的交点提供了相机中心，进而提供了相机旋转。所提出的解决方案消除了初始化时“先验”姿态的必要性，并以封闭形式解决了6DoF姿态估计问题，而不需要迭代。此外，与现有的用于姿态估计的新视图合成（NVS）基线相比，6DGS可以在真实场景中将整体平均旋转精度提高12%，平移精度提高22%，尽管不需要任何初始化姿态。同时，我们的方法近乎实时运行，在消费类硬件上达到15fps。 et.al.|[2407.15484](http://arxiv.org/abs/2407.15484)|null|
|**2024-07-19**|**SparseCraft: Few-Shot Neural Reconstruction through Stereopsis Guided Geometric Linearization**|我们提出了一种从少数彩色图像中恢复3D形状和视图相关外观的新方法，实现了高效的3D重建和新颖的视图合成。我们的方法以符号距离函数（SDF）和辐射场的形式学习隐式神经表示。该模型通过支持光线行进的体积渲染逐步训练，并使用无需学习的多视图立体（MVS）线索进行正则化。我们贡献的关键是一种新的隐式神经形状函数学习策略，该策略鼓励我们的SDF场在水平集附近尽可能线性，从而使训练对监督和正则化信号发出的噪声具有鲁棒性。在不使用任何预训练先验的情况下，我们的方法SparseCraft在新的视图合成和标准基准中从稀疏视图重建方面都达到了最先进的性能，同时只需要不到10分钟的训练时间。 et.al.|[2407.14257](http://arxiv.org/abs/2407.14257)|null|
|**2024-07-19**|**Mono-ViFI: A Unified Learning Framework for Self-supervised Single- and Multi-frame Monocular Depth Estimation**|自监督单目深度估计引起了人们的极大兴趣，因为它可以将训练从对深度注释的依赖中解放出来。在单目视频训练的情况下，最近的方法只在现有的摄像机视图之间进行视图合成，导致引导不足。为了解决这个问题，我们试图通过基于流的视频帧插值（VFI）来合成更多的虚拟相机视图，称为时间增强。对于多帧推理，为了避开基于显式几何的方法（如ManyDepth）遇到的动态对象问题，我们回到了特征融合范式，并设计了一个VFI辅助的多帧融合模块，使用基于流的VFI模型获得的运动和遮挡信息来对齐和聚合多帧特征。最后，我们构建了一个统一的自监督学习框架，名为Mono ViFI，以双向连接单帧和多帧深度。在这个框架中，通过图像仿射变换进行空间数据增强以实现数据多样性，同时进行正则化的三重深度一致性损失。单帧和多帧模型可以共享权重，使我们的框架紧凑且内存高效。大量实验表明，我们的方法可以为当前的先进架构带来重大改进。源代码可在https://github.com/LiuJF1226/Mono-ViFI. et.al.|[2407.14126](http://arxiv.org/abs/2407.14126)|**[link](https://github.com/liujf1226/mono-vifi)**|
|**2024-07-18**|**Shape of Motion: 4D Reconstruction from a Single Video**|由于单眼动态重建任务的高度不适定性，它是一个具有挑战性和长期存在的视觉问题。现有的方法存在局限性，因为它们要么依赖于模板，要么仅在准静态场景中有效，要么无法明确地对3D运动进行建模。在这项工作中，我们介绍了一种能够从随意捕获的单眼视频中重建具有显式、全序列长3D运动的通用动态场景的方法。我们通过两个关键的见解来解决这个问题的欠约束性质：首先，我们通过用一组紧凑的SE3运动基表示场景运动来利用3D运动的低维结构。每个点的运动都表示为这些基的线性组合，有助于将场景软分解为多个刚性移动的组。其次，我们利用了一套全面的数据驱动先验，包括单眼深度图和长距离2D轨迹，并设计了一种方法来有效地整合这些嘈杂的监控信号，从而得到动态场景的全局一致表示。实验表明，我们的方法在长距离3D/2D运动估计和动态场景上的新颖视图合成方面都取得了最先进的性能。项目页面：https://shape-of-motion.github.io/ et.al.|[2407.13764](http://arxiv.org/abs/2407.13764)|null|
|**2024-07-18**|**Streetscapes: Large-scale Consistent Street View Generation Using Autoregressive Video Diffusion**|我们提出了一种通过动态合成的城市尺度场景生成街景长序列视图的方法。我们这一代人受到语言输入（如城市名称、天气）以及承载所需轨迹的底层地图/布局的制约。与最近的视频生成或3D视图合成模型相比，我们的方法可以扩展到更远的摄像机轨迹，跨越几个街区，同时保持视觉质量和一致性。为了实现这一目标，我们基于最近在视频扩散方面的工作，在一个可以轻松扩展到长序列的自回归框架内使用。特别是，我们引入了一种新的时间插补方法，可以防止我们的自回归方法偏离现实城市图像的分布。我们使用来自谷歌街景的令人信服的数据源来训练我们的街景系统，这些数据源包括图像，以及上下文地图数据，这些数据允许用户根据任何所需的城市布局生成城市景观，并具有可控的摄像器姿态。请在我们的项目页面上查看更多结果https://boyangdeng.com/streetscapes. et.al.|[2407.13759](http://arxiv.org/abs/2407.13759)|null|
|**2024-07-18**|**KFD-NeRF: Rethinking Dynamic NeRF with Kalman Filter**|我们介绍了KFD NeRF，这是一种新型的动态神经辐射场，与基于卡尔曼滤波的高效高质量运动重建框架相结合。我们的关键思想是将动态辐射场建模为一个动态系统，其时变状态基于两个知识来源进行估计：观测和预测。我们介绍了一种新的插件卡尔曼滤波器引导的变形场，该变形场能够根据场景观测和预测进行精确的变形估计。我们使用浅层多层感知器（MLP）进行观测，并将运动建模为局部线性，以使用运动方程计算预测。为了进一步提高观测MLP的性能，我们在规范空间中引入正则化，以提高网络学习不同帧扭曲的能力。此外，我们采用了一种高效的三平面表示来编码规范空间，该表示已被实验证明可以快速、高质量地收敛。这使我们能够使用较浅的观测MLP，在我们的实现中仅由两层组成。我们对合成数据和真实数据进行了实验，并与过去的动态NeRF方法进行了比较。我们的KFD NeRF在相当的计算时间内表现出类似甚至更优的渲染性能，并通过彻底的训练实现了最先进的视图合成性能。 et.al.|[2407.13185](http://arxiv.org/abs/2407.13185)|null|
|**2024-07-17**|**Generalizable Human Gaussians for Sparse View Synthesis**|神经渲染的最新进展带来了开创性的方法，如NeRF和高斯散斑，这些方法彻底改变了AR/VR、游戏和内容创建等各个领域的视图渲染。虽然这些方法擅长在训练数据中插值，但从非常稀疏的视图推广到新场景和对象的挑战仍然存在。具体来说，由于人体几何形状的固有复杂性，从稀疏视图对3D人体进行建模存在巨大的障碍，导致几何和纹理的重建不准确。为了应对这一挑战，本文利用高斯散布的最新进展，介绍了一种学习可推广的人类高斯分布的新方法，该方法允许以前馈方式从有限的稀疏视图集中对新的人类对象进行逼真和精确的视图渲染。我们方法的一个关键创新是将3D高斯参数的学习重新表述为在人类模板的2D UV空间上定义的回归过程，这允许利用强几何先验和2D卷积的优点。此外，还提出了一种多脚手架来有效地表示偏移细节。我们的方法在数据集内泛化和跨数据集泛化设置上都优于最近的方法。 et.al.|[2407.12777](http://arxiv.org/abs/2407.12777)|null|
|**2024-07-17**|**Efficient Depth-Guided Urban View Synthesis**|隐式场景表示的最新进展实现了高保真街景新视图合成。然而，现有的方法严重依赖密集的训练图像和大量的计算资源，为每个场景优化神经辐射场。为了减轻这一缺点，我们引入了一种名为高效深度引导城市景观合成（EDUS）的新方法，用于快速前馈推理和高效的每场景微调。与基于特征匹配推断几何的先前可推广方法不同，EDUS利用噪声预测的几何先验作为指导，从稀疏输入图像中实现可推广的城市景观合成。几何先验允许我们直接在3D空间中应用我们的可推广模型，在各种稀疏级别上获得鲁棒性。通过在KITTI-360和Waymo数据集上的综合实验，我们展示了对新颖街道场景的有前景的泛化能力。此外，我们的结果表明，当与快速测试时间优化相结合时，EDUS在稀疏视图设置中实现了最先进的性能。 et.al.|[2407.12395](http://arxiv.org/abs/2407.12395)|null|
|**2024-07-17**|**Splatfacto-W: A Nerfstudio Implementation of Gaussian Splatting for Unconstrained Photo Collections**|由于光度变化和瞬态遮挡使精确的场景重建复杂化，从无约束的野生图像集合中进行新的视图合成仍然是一项重要但具有挑战性的任务。以前的方法通过在神经辐射场（NeRF）中集成每幅图像的外观特征嵌入来解决这些问题。尽管3D高斯散斑（3DGS）提供了更快的训练和实时渲染，但由于架构的显著不同，将其应用于无约束的图像集合并非易事。在本文中，我们介绍了Splatfacto-W，这是一种将每高斯神经颜色特征和每图像外观嵌入集成到光栅化过程中的方法，以及基于球面谐波的背景模型，用于表示不同的光度外观并更好地描绘背景。我们的主要贡献包括潜在外观建模、高效的瞬态对象处理和精确的背景建模。Splatfacto-W提供高质量、实时的新颖视图合成，在野外场景中提高了场景一致性。与3DGS相比，我们的方法将峰值信噪比（PSNR）平均提高了5.3 dB，与基于NeRF的方法相比，训练速度提高了150倍，并实现了与3DGS相似的渲染速度。集成到Nerfstudio中的其他视频结果和代码可在以下网址获得https://kevinxu02.github.io/splatfactow/. et.al.|[2407.12306](http://arxiv.org/abs/2407.12306)|null|

<p align=right>(<a href=#updated-on-20240724>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-07-22**|**Enhancement of 3D Gaussian Splatting using Raw Mesh for Photorealistic Recreation of Architectures**|建筑场景的真实感重建和渲染在电影、游戏和交通等行业有着广泛的应用。它在城市规划、建筑设计和城市推广方面也发挥着重要作用，特别是在保护历史文化遗产方面。由于其优于NeRF的性能，3D高斯散斑已成为3D重建的主流技术。它唯一的输入是一组图像，但它在很大程度上依赖于SfM过程计算的几何参数。与此同时，现有大量的原始3D模型可以为某些建筑物的结构感知提供信息，但无法应用。在这篇论文中，我们提出了一种直接的方法，利用这些原始的3D模型来引导3D高斯人捕捉建筑物的基本形状，并在非系统地捕捉照片时提高纹理和细节的视觉质量。这一探索为提高3D重建技术在建筑设计领域的有效性开辟了新的可能性。 et.al.|[2407.15435](http://arxiv.org/abs/2407.15435)|null|
|**2024-07-21**|**3D Reconstruction of the Human Colon from Capsule Endoscope Video**|随着受胃肠系统疾病影响的人数不断增加，对预防性筛查的更高要求是不可避免的。这将大大增加胃肠病学家的工作量。为了帮助减少工作量，计算机视觉工具可能会有所帮助。在这篇论文中，我们研究了使用无线胶囊内窥镜视频中的图像序列构建人体结肠整个切片的3D模型的可能性，为胃肠病学家提供了增强的观看体验。由于胶囊内窥镜图像包含失真和伪影，这对许多3D重建算法来说是不理想的，因此这个问题具有挑战性。然而，最近基于虚拟图形的人体胃肠系统模型的发展，可以启用或禁用失真和伪影，从而可以“剖析”这个问题。图形模型还提供了一个地面真实值，可以计算3D重建方法引入的几何失真。在这篇论文中，大多数失真和伪影被排除在外，以确定通过现有方法重建人体胃肠系统的整个部分是否可行。我们证明了使用同步定位和映射可以进行3D重建。此外，为了从密度变化很大的点云重建胃肠壁表面，泊松表面重建是一个不错的选择。研究结果很有希望，鼓励对这个问题进行进一步的研究。 et.al.|[2407.15228](http://arxiv.org/abs/2407.15228)|null|
|**2024-07-21**|**HoloDreamer: Holistic 3D Panoramic World Generation from Text Descriptions**|3D场景生成在各个领域都有很高的需求，包括虚拟现实、游戏和电影行业。由于文本到图像扩散模型具有强大的生成能力，可以提供可靠的先验信息，因此仅使用文本提示创建3D场景变得可行，从而显著推进了文本驱动的3D场景生成研究。为了从2D扩散模型中获得多视图监控，主流方法通常采用扩散模型生成初始局部图像，然后使用扩散模型迭代地绘制局部图像以逐渐生成场景。然而，这些基于外画的方法容易产生全局不一致的场景生成结果，没有高度的完整性，限制了它们更广泛的应用。为了解决这些问题，我们引入了HoloDreamer，这是一个框架，它首先生成高清全景作为完整3D场景的整体初始化，然后利用3D高斯散斑（3D-GS）快速重建3D场景，从而促进创建视图一致和完全封闭的3D场景。具体来说，我们提出了风格化的等矩形全景生成，这是一种结合了多个扩散模型的管道，可以从复杂的文本提示中生成风格化和详细的等矩形的全景。随后，引入了增强两阶段全景重建，对3D-GS进行两阶段优化，以输入缺失区域并增强场景的完整性。综合实验表明，在生成全封闭场景时，我们的方法在整体视觉一致性和和谐性以及重建质量和渲染鲁棒性方面优于先前的工作。 et.al.|[2407.15187](http://arxiv.org/abs/2407.15187)|null|
|**2024-07-21**|**VoxDepth: Rectification of Depth Images on Edge Devices**|自动飞行无人机和工业机器人等自主移动机器人在很大程度上依赖于深度图像来执行3D重建和视觉SLAM等任务。然而，这些深度图像中不准确的存在会极大地阻碍这些应用的有效性，导致次优结果。商用相机产生的深度图像经常出现噪声，表现为闪烁的像素和错误的补丁。基于ML的校正这些图像的方法不适合计算资源非常有限的边缘设备。非机器学习方法要快得多，但精度有限，特别是对于纠正因遮挡和相机移动而导致的错误。我们提出了一种名为VoxDepth的方案，该方案快速、准确，在边缘设备上运行良好。它依赖于一系列新技术：3D点云构建和融合，并使用它来创建一个可以修复错误深度图像的模板。VoxDepth在合成数据集和真实数据集上都显示出卓越的结果。与现实世界深度数据集上的最先进方法相比，我们的质量提高了31%，同时保持了27 FPS（每秒帧数）的竞争帧率。 et.al.|[2407.15067](http://arxiv.org/abs/2407.15067)|null|
|**2024-07-19**|**SparseCraft: Few-Shot Neural Reconstruction through Stereopsis Guided Geometric Linearization**|我们提出了一种从少数彩色图像中恢复3D形状和视图相关外观的新方法，实现了高效的3D重建和新颖的视图合成。我们的方法以符号距离函数（SDF）和辐射场的形式学习隐式神经表示。该模型通过支持光线行进的体积渲染逐步训练，并使用无需学习的多视图立体（MVS）线索进行正则化。我们贡献的关键是一种新的隐式神经形状函数学习策略，该策略鼓励我们的SDF场在水平集附近尽可能线性，从而使训练对监督和正则化信号发出的噪声具有鲁棒性。在不使用任何预训练先验的情况下，我们的方法SparseCraft在新的视图合成和标准基准中从稀疏视图重建方面都达到了最先进的性能，同时只需要不到10分钟的训练时间。 et.al.|[2407.14257](http://arxiv.org/abs/2407.14257)|null|
|**2024-07-19**|**I Know About "Up"! Enhancing Spatial Reasoning in Visual Language Models Through 3D Reconstruction**|视觉语言模型（VLMs）对于各种任务，特别是视觉推理任务至关重要，因为它们具有强大的多模态信息集成、视觉推理能力和上下文感知能力。然而，现有的视觉空间推理能力往往不足，即使在区分左右等基本任务上也很困难。为了解决这个问题，我们提出了我们的模型，旨在增强VLMS的视觉空间推理能力。ZeroVLM采用Zero1-to-3，这是一种3D重建模型，用于获得输入图像的不同视图，并结合了提示机制，以进一步改善视觉空间推理。在四个视觉空间推理数据集上的实验结果表明，我们的{}实现了高达19.48%的准确率提高，这表明了ZeroVLM的3D重建和提示机制的有效性。 et.al.|[2407.14133](http://arxiv.org/abs/2407.14133)|null|
|**2024-07-19**|**FAVis: Visual Analytics of Factor Analysis for Psychological Research**|心理学研究通常涉及通过对问卷收集的数据进行因子分析来理解心理结构，问卷可能包括数百个问题。如果没有用于解释因子模型的交互系统，研究人员经常会受到主观性的影响，这可能会导致误解或忽视关键信息。本文介绍了FAVis，这是一种新型的交互式可视化工具，旨在帮助研究人员解释和评估因子分析结果。FAVis通过支持多种视图来可视化因素载荷和相关性，使用户能够从不同角度分析信息，从而增强了对变量和因素之间关系的理解。FAVis的主要功能是使用户能够为因子负载设置最佳阈值，以平衡清晰度和信息保留。FAVis还允许用户为变量分配标签，通过将它们与相关的心理结构联系起来，增强对因素的理解。我们的用户研究证明了FAVis在各种任务中的实用性。 et.al.|[2407.14072](http://arxiv.org/abs/2407.14072)|null|
|**2024-07-19**|**DirectL: Efficient Radiance Fields Rendering for 3D Light Field Displays**|尽管经过几十年的发展，自动立体显示器尚未得到广泛应用，主要是因为非专业人士在3D内容创作方面面临着艰巨的挑战。辐射场作为一种创新的3D表示的出现，显著地彻底改变了3D重建和生成的领域。这项技术大大简化了普通用户的3D内容创建，扩大了光场显示器（LFD）的适用范围。然而，这两个领域的结合在很大程度上仍未得到探索。为基于视差的光场显示器创建最佳内容的标准范式要求渲染至少45个略微偏移的视图，最好是每帧高分辨率，这是实时渲染的一个重大障碍。我们介绍了DirectL，这是一种用于3D显示器上辐射场的新型渲染范式。我们深入分析了空间光线到屏幕子像素的交织映射，精确地确定了进入人眼的光线，并提出了子像素的重新利用，以显著减少渲染所需的像素数。针对两个主要的辐射场——神经辐射场（NeRFs）和3D高斯散斑（3DGS），我们提出了相应的优化渲染管道，直接渲染光场图像，而不是多视图图像。在各种显示器和用户研究中进行的广泛实验表明，与标准范式相比，DirectL在不牺牲视觉质量的情况下将渲染速度提高了40倍。仅对其渲染过程进行修改，即可无缝集成到后续的辐射场任务中。最后，我们将DirectL集成到各种应用中，展示了令人惊叹的视觉体验以及LFD和Radiance Fields之间的协同作用，这为商业化应用带来了巨大的潜力。\href{direct-l.github.io}{\textbf{项目主页} et.al.|[2407.14053](http://arxiv.org/abs/2407.14053)|null|
|**2024-07-18**|**MaRINeR: Enhancing Novel Views by Matching Rendered Images with Nearby References**|从3D重建中渲染逼真的图像是许多计算机视觉和机器人管道的重要任务，特别是对于混合现实应用以及在模拟环境中训练自主代理。然而，新颖视图的质量在很大程度上取决于源重建，由于噪声或缺少几何和外观，源重建往往是不完美的。受最近基于参考的超分辨率网络成功的启发，我们提出了MaRINeR，这是一种利用附近映射图像的信息来改善目标视点渲染的细化方法。我们首先基于深度特征在目标视点的场景几何的原始渲染图像和附近的参考之间建立匹配，然后进行分层细节传递。我们从显式和隐式场景表示的定量指标和定性示例中展示了改进的渲染。我们进一步将我们的方法应用于伪地面真实性验证、合成数据增强和细节恢复等下游任务，用于简化3D重建的渲染。 et.al.|[2407.13745](http://arxiv.org/abs/2407.13745)|null|
|**2024-07-18**|**EaDeblur-GS: Event assisted 3D Deblur Reconstruction with Gaussian Splatting**|随着神经辐射场（NeRF）和3D高斯散斑（3DGS）的发展，3D去模糊重建技术最近取得了重大进展。尽管这些技术可以从模糊的图像输入中恢复相对清晰的3D重建，但在处理严重模糊和复杂的相机运动方面仍然存在局限性。为了解决这些问题，我们提出了高斯散斑事件辅助3D去模糊重建（EaDeblur GS），它集成了事件相机数据，以增强3DGS对运动模糊的鲁棒性。通过采用自适应偏差估计器（ADE）网络来估计高斯中心偏差，并使用新的损失函数，EaDeblur GS实时实现了清晰的3D重建，其性能可与最先进的方法相媲美。 et.al.|[2407.13520](http://arxiv.org/abs/2407.13520)|null|

<p align=right>(<a href=#updated-on-20240724>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-07-22**|**Artist: Aesthetically Controllable Text-Driven Stylization without Training**|扩散模型在去噪过程中纠缠了内容和样式生成，当直接应用于样式化任务时，会导致不希望的内容修改。现有的方法难以有效地控制扩散模型，以满足风格化的审美水平要求。在本文中，我们介绍了\textbf{Artist}，这是一种无需训练的方法，可以从美学上控制文本驱动风格化预训练扩散模型的内容和风格生成。我们的关键见解是将内容和风格的去噪分解为单独的扩散过程，同时在它们之间共享信息。我们提出了简单而有效的内容和风格控制方法，抑制了风格无关的内容生成，从而产生了和谐的风格化结果。大量实验表明，我们的方法擅长实现美学层面的风格化要求，保留内容图像中的复杂细节，并与风格提示很好地对齐。此外，我们从多个角度展示了风格化强度的高度可控性。代码将发布，项目主页：https://DiffusionArtist.github.io et.al.|[2407.15842](http://arxiv.org/abs/2407.15842)|null|
|**2024-07-22**|**Stretching Each Dollar: Diffusion Training from Scratch on a Micro-Budget**|随着生成式人工智能中的缩放定律推动性能，它们也同时将这些模型的开发集中在具有大量计算资源的参与者身上。我们专注于文本到图像（T2I）生成模型，旨在通过演示大规模T2I扩散变换器模型的低成本训练来解决这一瓶颈。由于变换器的计算成本随着每张图像中补丁数量的增加而增加，我们建议在训练过程中随机屏蔽多达75%的图像补丁。我们提出了一种延迟掩蔽策略，在掩蔽之前使用补丁混合器对所有补丁进行预处理，从而显著降低了掩蔽的性能下降，使其在降低计算成本方面优于模型降尺度。我们还整合了变压器架构的最新改进，例如使用专家层的混合，以提高性能，并进一步确定在微观预算培训中使用合成图像的关键优势。最后，仅使用3700万张公开可用的真实和合成图像，我们仅以1890美元的经济成本训练了11.6亿参数稀疏变换器，并在COCO数据集上实现了12.7 FID的零样本生成。值得注意的是，我们的模型实现了有竞争力的FID和高质量的世代，同时比稳定的扩散模型低118美元，比目前最先进的28400美元的方法低14美元。我们的目标是发布我们的端到端培训管道，以进一步使微观预算上的大规模扩散模型的培训民主化。 et.al.|[2407.15811](http://arxiv.org/abs/2407.15811)|null|
|**2024-07-22**|**Diffusion Model Based Resource Allocation Strategy in Ultra-Reliable Wireless Networked Control Systems**|扩散模型在生成式人工智能中得到了广泛的应用，利用其捕获复杂数据分布的能力。然而，它们在无线网络资源分配领域的潜力在很大程度上仍未得到探索。本文介绍了一种新的基于扩散模型的无线网络控制系统（WNCS）资源分配策略，其目标是通过优化控制系统中的采样周期以及通信系统有限块长状态下的块长和分组错误概率来最小化总功耗。首先，基于最优性条件的推导，将问题简化为仅对块长度的优化。然后，优化理论解决方案收集信道增益和相应最佳块长度的数据集。最后，去噪扩散概率模型（DDPM）使用收集到的数据集来训练资源分配算法，该算法根据信道状态信息（CSI）生成最优块长度值。通过广泛的模拟，所提出的方法被证明优于之前提出的基于深度强化学习（DRL）的方法，在总功耗方面接近最优性能。此外，观察到在减少关键约束违规方面提高了18倍，进一步强调了解决方案的准确性。 et.al.|[2407.15784](http://arxiv.org/abs/2407.15784)|null|
|**2024-07-22**|**A Hamilton-Jacobi approach to road-field reaction-diffusion models**|我们考虑了Berestycki、Roquejoffre和Rossi提出的道路场反应扩散模型。通过执行“薄前沿极限”，我们能够在道路上推导出具有适当有效哈密顿量的哈密顿-雅可比方程，该方程控制着道路场模型的前沿位置。我们的主要动机是应用强（通量限制）粘度解理论，以确定前沿位置的控制公式解释。鉴于道路-田地模型的生态意义，这是很自然的，因为它将入侵问题视为寻找最佳路径之一，以平衡田地的正增长率和道路上的快速扩散。我们的主要贡献是对两个道路圆锥域上的行为进行了近乎完整的描述。当每条道路上的扩散率相同时，我们表明，锥体中每个方向的传播速度可以通过与一条道路半空间问题相关的速度来计算。当扩散率不同时，我们发现沿着较快道路的速度不变，而沿着较慢道路的速度可以提高。在此过程中，我们通过我们的方法为单向半空间问题的已知结果提供了新的证明。 et.al.|[2407.15760](http://arxiv.org/abs/2407.15760)|null|
|**2024-07-22**|**Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond**|近年来，语义分割中的分布外检测（OoD）研究主要集中在道路场景上，这是一个语义多样性受限的领域。在这项工作中，我们挑战了这一约束，并将这一任务的领域扩展到一般的自然图像。为此，我们介绍：1。ADE OoD基准，基于ADE20k数据集，包括来自具有高度语义多样性的不同领域的图像，以及2。一种使用扩散分数匹配进行OoD检测（DOoD）并且对增加的语义多样性具有鲁棒性的新方法。ADE OoD以室内和室外图像为特征，定义了150个分布中的语义类别，并包含各种OoD对象。对于DOoD，我们在分布嵌入的语义上训练了一个具有MLP架构的扩散模型，并基于分数匹配解释在推理时计算像素级的OoD分数。在常见的道路场景OoD基准测试中，DOoD的性能与最新技术相当或更好，无需使用异常值进行训练或对数据域做出假设。在ADE-OoD上，DOoD的表现优于之前的方法，但仍有很大的改进空间。 et.al.|[2407.15739](http://arxiv.org/abs/2407.15739)|**[link](https://github.com/lmb-freiburg/diffusion-for-ood)**|
|**2024-07-22**|**Inverse problems for coupled nonlocal nonlinear systems arising in mathematical biology**|本文提出并研究了非局域非线性耦合偏微分方程系统中确定未知参数的几个逆问题，包括势、非线性相互作用函数和时间分数阶。在这些耦合系统中，我们强制解决方案的非负性，与生物学和生态学中的现实情景保持一致。我们的逆问题研究有几个突出特征：由于平均效应导致的测量/观测数据的急剧减少、多个方程之间的非线性耦合以及分数型导数引起的非局域性。这些因素对我们的逆问题提出了重大挑战，而以前的文献从未探讨过此类逆问题。为了应对这些挑战，我们制定了新的有效方案。我们的方法涉及正确控制不同源项的注入，以获得多组平均通量数据。这使我们能够获得独特的可识别性结果，并准确确定未知参数。最后，我们建立了我们的研究与生物学实际应用之间的联系，进一步强调了我们的工作在现实世界中的相关性。 et.al.|[2407.15713](http://arxiv.org/abs/2407.15713)|null|
|**2024-07-22**|**Estimating Probability Densities with Transformer and Denoising Diffusion**|Transformers通常是构建基础模型的首选架构，这些模型会吸收大量的训练数据。但是，当在回归问题上训练时，这些模型并不能估计概率密度分布，但获得完整的概率输出对许多科学领域至关重要，在这些领域，答案的概率分布可以是非高斯和多模态的。在这项工作中，我们证明，即使对于高维输入，使用变压器顶部的去噪扩散头训练概率模型也能提供合理的概率密度估计。变压器+去噪扩散组合模型允许在任意输入组合上调节输出概率密度，因此它是所有可能输入/输出组合的高度灵活的密度函数仿真器。我们通过在银河系内天文观测和恒星测量标签的大型数据集上训练Transformer+去噪扩散模型来说明我们的模型，并将其应用于各种推理任务，以表明该模型可以以合理的分布准确地推断标签。 et.al.|[2407.15703](http://arxiv.org/abs/2407.15703)|null|
|**2024-07-22**|**Voltage mapping in subcellular nanodomains using electro-diffusion modeling**|亚细胞微结构域（如神经元突触、小突起或树突棘）中的电压分布调节离子通道的打开和关闭、能量产生，从而调节细胞稳态和兴奋性。然而，由于实验衍射极限、大信号波动和快速电压指示器的分辨率仍然有限，在体内如此小的范围内电压如何变化仍然具有挑战性。在这里，我们使用基于泊松-能斯特-普朗克方程的离子电扩散运动计算方法研究纳米隔室中的电压分布，其中通道之间产生向内和向外的通量。我们报告了一个推广能斯特定律的电流-电压（I-V）对数关系，揭示了局部膜曲率如何调节电压。我们进一步发现，渗透细胞电解质的流入电流会导致数十至数百纳米深的扰动，具体取决于局部通道组织。最后，我们发现树突棘的颈部阻力可以被位于头部边界的转运蛋白完全分流，促进离子流动。总之，我们提出电压在亚细胞水平上是由通道组织、膜曲率和狭窄通道调节的。 et.al.|[2407.15697](http://arxiv.org/abs/2407.15697)|null|
|**2024-07-22**|**Particle Based Inference for Continuous-Discrete State Space Models**|本文开发了一种方法，允许在我们所说的连续离散状态空间模型（CD SSM）上应用基于粒子的推理方法的完整机制。这些模型对应于一个潜在的连续时间扩散过程，在离散时间点用噪声观察到。由于隐藏信号的连续时间特性，标准的费曼-卡克公式及其伴随的基于粒子的近似必须克服几个挑战，主要是由于以下考虑：（i）信号的有限时间跃迁密度通常是难以处理的；（ii）采样信号的祖先被确定为w.p.~1，因此不能重新采样；（iii）给定采样信号的扩散率参数产生狄拉克分布。我们通过引入一个基于精心设计的提案及其转换的框架来克服上述所有问题。也就是说，我们得到了Feynman-Kac模型的新表达式，该表达式适应了连续时间信号的影响并克服了诱导退化。所构建的公式将使CD SSM能够使用全系列基于粒子的算法：用于在线或离线的滤波/平滑和参数推理。我们的框架与滤波步骤中的指导性建议兼容，这些建议对于在存在信息观测或更高维度的情况下实现高效的算法性能至关重要，并且适用于非常通用的CD SSM类别，包括信号被建模为次椭圆扩散的情况。我们的方法可以立即整合到基于粒子的算法的可用软件包中。 et.al.|[2407.15666](http://arxiv.org/abs/2407.15666)|null|
|**2024-07-22**|**DriveDiTFit: Fine-tuning Diffusion Transformers for Autonomous Driving**|在自动驾驶中，深度模型在各种视觉感知任务中表现出了卓越的性能，需要高质量和巨大多样性的训练数据集。预计此类数据集将涵盖各种恶劣天气、照明条件和各种移动物体的驾驶场景。然而，手动收集这些数据带来了巨大的挑战和昂贵的成本。随着大型生成模型的快速发展，我们提出了DriveDiTFit，这是一种通过微调预训练扩散变换器（DiTs）有效生成自动驾驶数据的新方法。具体而言，DriveDiTFit利用间隙驱动调制技术，根据预训练的源数据和目标驱动数据之间的差异，仔细选择并有效微调DiT中的一些参数。此外，DriveDiTFit开发了一个有效的天气和光照条件嵌入模块，以确保生成的数据的多样性，该数据由最近的语义相似性初始化方法初始化。DriveDiTFit通过渐进式调整方案来细化早期扩散过程中的细节生成过程，并在训练损失中扩大与小对象对应的权重，从而确保在生成的数据中高质量地生成小运动对象。在驾驶数据集上进行的大量实验证实，我们的方法可以有效地生成各种真实的驾驶数据。源代码可在https://github.com/TtuHamg/DriveDiTFit. et.al.|[2407.15661](http://arxiv.org/abs/2407.15661)|**[link](https://github.com/ttuhamg/driveditfit)**|

<p align=right>(<a href=#updated-on-20240724>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-07-22**|**Iterative approach to reconstructing neural disparity fields from light-field data**|本研究提出了一种神经视差场（NDF），该场基于神经场建立了场景视差的隐式连续表示，并采用迭代方法解决了从光场数据重建NDF的逆问题。NDF能够无缝和精确地表征三维场景中的视差变化，并可以以任何任意分辨率对视差进行离散化，克服了传统视差图容易出现采样误差和插值不准确的局限性。所提出的NDF网络架构利用哈希编码结合多层感知器来捕获纹理级别的详细差异，从而增强其表示复杂场景几何信息的能力。通过利用光场数据中固有的空间角度一致性，开发了一种可微分正向模型，用于从光场数据生成中心视图图像。基于正向模型，建立了一种使用可微传播算子的NDF重建逆问题的优化方案。此外，在优化方案中，采用迭代求解方法重建NDF，该方法不需要训练数据集，适用于各种采集方法捕获的光场数据。实验结果表明，使用所提出的方法可以从光场数据中重建高质量的NDF。NDF可以有效地恢复高分辨率视差，证明了其隐式、连续表示场景视差的能力。 et.al.|[2407.15380](http://arxiv.org/abs/2407.15380)|null|
|**2024-07-19**|**Contextual modulation of language comprehension in a dynamic neural model of lexical meaning**|我们提出并计算实现了一个词汇意义的动态神经模型，并对其行为预测进行了实验测试。我们使用英语词汇“have”作为测试用例来演示模型的架构和行为，重点关注其多义词的使用。在该模型中，“have”映射到由两个连续的概念维度（连通性和控制不对称性）定义的语义空间，这两个维度之前被提出用于参数化语言的概念系统。映射被建模为表示词条的神经节点和表示概念维度的神经场之间的耦合。虽然词汇知识被建模为稳定的耦合模式，但实时词汇意义检索被建模为神经激活模式在对应于语义解释或阅读的亚稳态之间的运动。模型模拟捕捉到了两个先前报道的实证观察结果：（1）词汇语义解释的语境调制，以及（2）这种调制幅度的个体差异。模拟还产生了一种新的预测，即句子阅读时间和可接受性之间的试验关系应该根据上下文进行调节。结合自定进度阅读和可接受性判断的实验复制了之前的结果，并证实了新的模型预测。总之，研究结果支持了一种关于词汇多义的新观点：一个词的许多相关含义是亚稳态的神经激活状态，这是由控制连续语义维度解释的神经群体的非线性动力学引起的。 et.al.|[2407.14701](http://arxiv.org/abs/2407.14701)|null|
|**2024-07-18**|**MeshFeat: Multi-Resolution Features for Neural Fields on Meshes**|参数特征网格编码作为神经场的编码方法受到了广泛关注，因为它们允许更小的MLP，这大大缩短了模型的推理时间。在这项工作中，我们提出了MeshFeat，这是一种针对网格量身定制的参数特征编码，为此我们采用了欧几里德空间的多分辨率特征网格的思想。我们从给定顶点拓扑提供的结构开始，使用网格简化算法直接在网格上构建多分辨率特征表示。该方法允许在网格上的神经场中使用小MLP，与之前的表示相比，我们显示出显著的加速，同时保持了纹理重建和BRDF表示的可比重建质量。鉴于其与顶点的内在耦合，该方法特别适用于变形网格上的表示，使其非常适合对象动画。 et.al.|[2407.13592](http://arxiv.org/abs/2407.13592)|null|
|**2024-07-16**|**Adaptive Environment-Aware Robotic Arm Reaching Based on a Bio-Inspired Neurodynamical Computational Framework**|仿生机器人系统具有自适应学习、可扩展控制和高效信息处理的能力。为这些系统提供实时决策对于应对环境的动态变化至关重要。我们专注于在开放区域使用带有鸟瞰摄像头的机器人六自由度操纵器进行动态目标跟踪，并部署神经动力学计算框架（NeuCF）进行视觉反馈。NeuCF是最近开发的一种基于动态神经场（DNF）和随机最优控制（SOC）理论的仿生目标跟踪模型。它已经过训练，可以在平面上对局部视觉信标进行到达动作，并且可以根据环境的变化（例如，出现了新的目标，或者删除了现有的目标）实时重新定位或生成停止信号。我们在各种目标达成场景下评估了我们的系统。在所有实验中，与基线三次多项式轨迹生成器相比，NeuCF具有较高的末端执行器位置精度，生成了平滑的轨迹，并提供了更短的路径长度。总之，开发的系统提供了一种强大的、动态感知的机器人操纵方法，可以提供实时决策。 et.al.|[2407.11377](http://arxiv.org/abs/2407.11377)|null|
|**2024-07-12**|**Physics-Informed Learning of Characteristic Trajectories for Smoke Reconstruction**|我们通过稀疏视图RGB视频深入研究了烟雾和障碍物的物理信息神经重建，解决了复杂动力学观测有限带来的挑战。现有的基于物理信息的神经网络通常强调短期物理约束，对长期守恒的适当保护探索较少。我们引入了神经特征轨迹场，这是一种利用欧拉神经场隐式建模拉格朗日流体轨迹的新表示方法。这种无拓扑、可自动微分的表示便于在任意帧之间进行高效的流图计算，以及通过自动微分进行高效的速度提取。因此，它实现了涵盖长期保护和短期物理先验的端到端监督。在此基础上，我们提出了基于物理的轨迹学习和集成到基于NeRF的场景重建中。我们通过自我监督的场景分解和无缝集成的边界约束来实现高级障碍物处理。我们的结果展示了克服遮挡不确定性、密度-颜色模糊性和静态-动态纠缠等挑战的能力。代码和示例测试位于\url{https://github.com/19reborn/PICT_smoke}. et.al.|[2407.09679](http://arxiv.org/abs/2407.09679)|null|
|**2024-07-10**|**Neural Localizer Fields for Continuous 3D Human Pose and Shape Estimation**|随着可用训练数据的爆炸性增长，单图像3D人体建模领先于向以数据为中心的范式过渡。成功利用数据规模的关键是设计灵活的模型，这些模型可以从不同研究人员或供应商生产的各种异构数据源进行监督。为此，我们提出了一种简单而强大的范式，用于无缝统一不同的人体姿势和形状相关的任务和数据集。我们的公式侧重于在训练和测试时查询人体体积的任意点并在3D中获得其估计位置的能力。我们通过学习身体点定位器函数的连续神经场来实现这一点，每个函数都是基于不同参数化的3D热图卷积点定位器（检测器）。为了生成参数输出，我们提出了一种高效的后处理步骤，用于将SMPL族身体模型拟合到非参数关节和顶点预测中。通过这种方法，我们可以自然地利用不同注释的数据源，包括网格、2D/3D骨架和密集姿势，而无需在它们之间进行转换，从而训练出大规模的3D人体网格和骨架估计模型，这些模型在3DPW、EMDB和SSP-3D等几个公共基准上的表现远远优于最先进的水平。 et.al.|[2407.07532](http://arxiv.org/abs/2407.07532)|null|
|**2024-07-03**|**Cerebral cortex inspired representation of neural field network**|进化及其智能元素在探索中带来了刺激和挑战。然而，物种如何拥有记忆、检索记忆并保持连续性是根本问题。大多数现象只能由研究人员假设，通过实验验证它们是一个很大的挑战。将大脑视为理想的智能机器并对其进行建模，为计算算法开辟了新的维度。本文提出了一个假设，即类似于大脑皮层的记忆创造。大脑皮层的区域隐含着特定功能的特异性，构成了一维的矢量形式的神经场。整个皮层的神经场相互连接形成了一个网络。这些网络与生存本能、情绪和奖励相关联，构成了对暴露环境的记忆，或者说学习。具有多维控制点的图形工具NURBS被隐式地用于将这些网络表示为一组三次方程。通过数据学习是智能系统的主要模块，本文试图将数据转换为低维模式，而不是实时智能系统的现有绝对形式。 et.al.|[2407.04741](http://arxiv.org/abs/2407.04741)|null|
|**2024-07-01**|**Fast and Efficient: Mask Neural Fields for 3D Scene Segmentation**|理解3D场景是计算机视觉研究中的一个关键挑战，其应用跨越多个领域。最近在将2D视觉语言基础模型提取到神经领域（如NeRF和3DGS）方面取得的进展，使3D场景能够从2D多视图图像中进行开放式词汇分割，而不需要精确的3D注释。然而，虽然有效，但高维CLIP特征的每像素蒸馏会引入模糊性，并需要复杂的正则化策略，从而在训练过程中增加效率。本文介绍了MaskField，它能够在弱监督下利用神经场实现快速高效的3D开放式分词。与以前的方法不同，MaskField提取掩模而不是密集的高维CLIP特征。MaskFields使用神经场作为二进制掩模生成器，并使用SAM生成的掩模对其进行监督，并通过粗略的CLIP特征进行分类。MaskField通过在训练过程中自然引入SAM分割的对象形状而无需额外的正则化来克服模糊的对象边界。通过在训练过程中避免直接处理高维CLIP特征，MaskField与3DGS等显式场景表示特别兼容。我们广泛的实验表明，MaskField不仅超越了现有的最先进的方法，而且实现了非常快的收敛速度，仅需5分钟的训练就超越了以前的方法。我们希望MaskField能够激发对如何训练神经场以从2D模型中理解3D场景的进一步探索。 et.al.|[2407.01220](http://arxiv.org/abs/2407.01220)|null|
|**2024-07-15**|**3D Feature Distillation with Object-Centric Priors**|将自然语言与物理世界联系起来是一个无处不在的话题，在计算机视觉和机器人技术中有着广泛的应用。最近，CLIP等二维视觉语言模型因其在二维图像中具有令人印象深刻的开放词汇基础能力而得到了广泛推广。最近的工作旨在通过特征提取将2D CLIP特征提升到3D，但要么学习特定于场景的神经场，因此缺乏泛化能力，要么专注于需要访问多个摄像头视图的室内房间扫描数据，这在机器人操作场景中是不可行的。此外，相关方法通常在像素级融合特征，并假设所有相机视图都具有相同的信息量。在这项工作中，我们表明这种方法在接地精度和分割清晰度方面都会导致次优的3D特征。为了缓解这一问题，我们提出了一种多视图特征融合策略，该策略采用以对象为中心的先验来消除基于语义信息的无信息视图，并通过实例分割掩码在对象级别融合特征。为了提取我们以对象为中心的3D特征，我们生成了一个大规模的合成多视图数据集，其中包含杂乱的桌面场景，从3300多个独特的对象实例中生成了15k个场景，我们将其公之于众。我们表明，我们的方法在从单视图RGB-D重建3D CLIP特征的同时，提高了接地容量和空间一致性，从而偏离了测试时多个相机视图的假设。最后，我们证明了我们的方法可以推广到新的桌面领域，并可以在不进行微调的情况下重新用于3D实例分割，并证明了它在混乱中的语言引导机器人抓取中的实用性 et.al.|[2406.18742](http://arxiv.org/abs/2406.18742)|null|
|**2024-06-25**|**Masked Generative Extractor for Synergistic Representation and 3D Generation of Point Clouds**|在二维图像生成建模和表示学习领域，掩模生成编码器（MAGE）已经证明了生成建模与表示学习之间的协同潜力。受此启发，我们提出Point MAGE将这一概念扩展到点云数据。具体来说，该框架首先利用矢量量化变分自编码器（VQVAE）重建3D形状的神经场表示，从而学习点补丁的离散语义特征。随后，通过将掩蔽模型与可变掩蔽比相结合，我们实现了生成和表示学习的同步训练。此外，我们的框架与现有的点云自监督学习（SSL）模型无缝集成，从而提高了它们的性能。我们广泛评估了Point MAGE的表示学习和生成能力。在形状分类任务中，Point MAGE在ModelNet40数据集上的准确率达到94.2%，在ScanObjectNN数据集上达到92.9%（+1.3%）。此外，它在少数镜头学习和零件分割任务中取得了最新的性能。实验结果还证实，Point MAGE可以在无条件和有条件的设置下生成详细和高质量的3D形状。 et.al.|[2406.17342](http://arxiv.org/abs/2406.17342)|null|

<p align=right>(<a href=#updated-on-20240724>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

