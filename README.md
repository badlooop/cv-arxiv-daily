[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.11.18
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-11-15**|**Efficient Density Control for 3D Gaussian Splatting**|3D高斯散斑（3DGS）在新颖的视图合成方面表现出色，在高级渲染质量和实时性能之间取得了平衡。然而，在训练过的场景中，大量低不透明度的高斯分布显著增加了渲染成本。这个问题是由于致密化过程中分割和克隆操作中的缺陷引起的，这些缺陷导致了广泛的高斯重叠和随后的不透明度降低。为了提高高斯利用率，我们改进了3DGS的自适应密度控制。首先，我们引入了一种更有效的长轴分割操作来代替原始的克隆和分割，这减轻了高斯重叠并提高了致密化效率。其次，我们提出了一种简单的自适应修剪技术来减少低不透明度高斯分布的数量。最后，通过动态降低分割阈值和应用重要性加权，进一步提高了高斯利用率。我们在各种具有挑战性的现实世界数据集上评估了我们提出的方法。实验结果表明，我们的高效密度控制（EDC）可以提高渲染速度和质量。 et.al.|[2411.10133](http://arxiv.org/abs/2411.10133)|null|
|**2024-11-14**|**DyGASR: Dynamic Generalized Exponential Splatting with Surface Alignment for Accelerated 3D Mesh Reconstruction**|3D高斯散斑（3DGS）的最新进展带来了高质量的新颖视图合成和加速渲染，显著提高了辐射场重建的质量。然而，从大量微小的3D高斯点中提取网格仍然是一个巨大的挑战，因为高斯分布的体积很大，并且由于其固有的低通特性而难以表示尖锐的信号。为了解决这个问题，我们提出了DyGASR，它利用广义指数函数而不是传统的3D高斯函数来减少粒子数量，并动态优化捕获信号的表示。此外，我们观察到，在不进行修改的情况下，使用广义指数散布（GES）重建网格经常会导致失败，因为广义指数分布质心可能无法与场景表面精确对齐。为了克服这一点，我们采用Sugar的方法并引入了广义表面正则化（GSR），该方法将每个点云的最小缩放向量减少到零，并确保垂直于表面的法线对齐，从而便于后续的泊松表面网格重建。此外，我们提出了一种动态分辨率调整策略，该策略利用余弦调度在训练阶段从低到高逐渐提高图像分辨率，从而避免了恒定的全分辨率，这大大提高了重建速度。我们的方法超越了现有的基于3DGS的网格重建方法，对各种场景数据集的广泛评估证明了这一点，速度提高了25%，内存使用减少了30%。 et.al.|[2411.09156](http://arxiv.org/abs/2411.09156)|null|
|**2024-11-14**|**Mono2Stereo: Monocular Knowledge Transfer for Enhanced Stereo Matching**|由于现有合成数据集的域间隙和真实数据集中GT标签的稀疏性，立体匹配网络的泛化和性能受到限制。相比之下，单目深度估计已经取得了重大进展，受益于大规模深度数据集和自我监督策略。为了弥合单目深度估计和立体匹配之间的性能差距，我们提出利用单目知识转移来增强立体匹配，即Mono2Stereo。我们引入了两阶段训练过程的知识转移，包括合成数据预训练和现实世界数据微调。在预训练阶段，我们设计了一个数据生成管道，从单眼图像中合成立体训练数据。该流水线利用单眼深度进行扭曲和新颖的视图合成，并采用我们提出的边缘感知（EA）修复模块来填充生成图像中缺失的内容。在微调阶段，我们引入了稀疏到密集知识蒸馏（S2DKD）策略，鼓励预测的分布与密集的单眼深度对齐。该策略缓解了稀疏现实标签中的边缘模糊问题，并提高了整体一致性。实验结果表明，我们的预训练模型具有较强的零样本泛化能力。此外，使用我们的预训练模型和S2DKD策略进行特定领域的微调，可以显著提高领域性能。代码将很快提供。 et.al.|[2411.09151](http://arxiv.org/abs/2411.09151)|null|
|**2024-11-13**|**4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization**|动态场景的新颖视图合成在各种应用中变得越来越重要，包括增强现实和虚拟现实。我们提出了一种新的4D高斯散斑（4DGS）算法，用于随机记录的单眼视频中的动态场景。为了克服这些真实世界视频的现有工作的过拟合问题，我们引入了一种不确定性感知正则化，该正则化可以识别具有很少观测值的不确定区域，并基于扩散模型和深度平滑度在这些区域上选择性地施加额外的先验。该方法提高了新颖视图合成的性能和训练图像重建的质量。我们还发现了快速移动动态区域中4DGS的初始化问题，其中运动结构（SfM）算法无法提供可靠的3D地标。为了在这些区域中初始化高斯基元，我们提出了一种使用估计的深度图和场景流的动态区域致密化方法。我们的实验表明，所提出的方法提高了从手持单目相机捕获的视频中重建4DGS的性能，并且在少镜头静态场景重建中也显示出有前景的结果。 et.al.|[2411.08879](http://arxiv.org/abs/2411.08879)|null|
|**2024-11-13**|**BillBoard Splatting (BBSplat): Learnable Textured Primitives for Novel View Synthesis**|我们提出了一种基于纹理几何图元的3D场景表示新方法——广告牌飞溅（BBSplat）。BBSplat将场景表示为一组可优化的纹理平面图元，具有可学习的RGB纹理和阿尔法贴图来控制其形状。BBSplat基元可用于任何高斯Splatting管道中，作为高斯分布的插入式替换。当BBSplat达到1200 FPS以上时，当使用较少的基元时，我们的方法对3D和2D高斯的定性和定量改进最为明显。我们新颖的正则化项鼓励纹理具有更稀疏的结构，从而实现了高效的压缩，减少了模型的存储空间。我们的实验表明，BBSplat在真实室内和室外场景的标准数据集（如坦克和寺庙、DTU和Mip-NeRF-360）上的效率很高。与最新技术相比，我们展示了PSNR、SSIM和LPIPS指标的改进，特别是在使用较少基元的情况下，另一方面，在相同的渲染质量下，推理速度提高了2倍。 et.al.|[2411.08508](http://arxiv.org/abs/2411.08508)|null|
|**2024-11-13**|**DG-SLAM: Robust Dynamic Gaussian Splatting SLAM with Hybrid Pose Optimization**|在动态场景中实现鲁棒和精确的姿态估计是视觉同步定位和映射（SLAM）领域的一个重大研究挑战。最近将高斯散斑集成到SLAM系统中的进展已被证明在使用显式3D高斯模型创建高质量渲染方面是有效的，显著提高了环境重建的保真度。然而，这些方法依赖于静态环境假设，并且由于对几何和光度的不一致观测，在动态环境中面临挑战。为了解决这个问题，我们提出了DG-SLAM，这是第一个基于3D高斯的鲁棒动态视觉SLAM系统，它提供了精确的相机姿态估计和高保真重建。具体而言，我们提出了有效的策略，包括运动掩模生成、自适应高斯点管理和混合相机跟踪算法，以提高姿态估计的准确性和鲁棒性。大量实验表明，DG-SLAM在动态场景中的相机姿态估计、地图重建和新颖的视图合成方面具有最先进的性能，在保持实时渲染能力的同时优于现有方法。 et.al.|[2411.08373](http://arxiv.org/abs/2411.08373)|null|
|**2024-11-12**|**Novel View Synthesis with Pixel-Space Diffusion Models**|从单个输入图像合成新视图是一项具有挑战性的任务。传统上，这项任务是通过估计场景深度、扭曲和修复来完成的，机器学习模型支持部分管道。最近，生成模型越来越多地用于新颖视图合成（NVS），通常涵盖整个端到端系统。在这项工作中，我们采用了一种现代扩散模型架构，用于像素空间中的端到端NVS，其性能大大优于先前最先进的（SOTA）技术。我们探索了将几何信息编码到网络中的不同方法。我们的实验表明，虽然这些方法可以提高性能，但与使用改进的生成模型相比，它们的影响很小。此外，我们引入了一种新的NVS训练方案，该方案利用了单视图数据集，利用了它们与多视图数据集相比的相对丰富性。这提高了对具有域外内容的场景的泛化能力。 et.al.|[2411.07765](http://arxiv.org/abs/2411.07765)|null|
|**2024-11-14**|**Projecting Gaussian Ellipsoids While Avoiding Affine Projection Approximation**|最近，3D高斯散斑以其实时渲染速度和最先进的渲染质量主导了新颖的视图合成。然而，在渲染过程中，使用投影变换的仿射近似的雅可比矩阵会导致不可避免的误差，从而导致最终渲染图像中的模糊、伪影和缺乏场景一致性。为了解决这个问题，我们引入了一种基于椭球体的投影方法来计算高斯椭球体在图像平面上的投影，这是3D高斯散斑的基本方法。由于我们提出的基于椭球体的投影方法无法处理内部有相机原点或相机空间中位于 $z=0$ 平面以下的高斯椭球体，我们设计了一种预滤波策略。在多个广泛采用的基准数据集上的实验表明，我们的基于椭球体的投影方法可以提高3D高斯散斑及其扩展的渲染质量。 et.al.|[2411.07579](http://arxiv.org/abs/2411.07579)|null|
|**2024-11-11**|**A Hierarchical Compression Technique for 3D Gaussian Splatting Compression**|3D高斯散斑（GS）在新颖的视图合成中表现出优异的渲染质量和生成速度。然而，大量的数据量给存储和传输带来了挑战，使3D GS压缩成为一项必不可少的技术。当前的3D GS压缩研究主要集中在开发更紧凑的场景表示，例如将显式的3D GS数据转换为隐式形式。相比之下，GS数据本身的压缩几乎并没有得到探索。为了解决这一差距，我们提出了一种分层GS压缩（HGSC）技术。最初，我们根据从全局和局部重要性中得出的重要性得分来修剪不重要的高斯分布，有效地减少了冗余，同时保持了视觉质量。八叉树结构用于压缩3D位置。基于3D GS八叉树，我们采用KD树将3D GS划分为多个块，实现了一种分层属性压缩策略。我们应用最远点采样来选择每个块内的锚基元，并将其他锚基元作为具有不同细节级别（LoD）的非锚基元。锚基元用作跨不同LoD预测非锚基元的参考点，以减少空间冗余。对于锚基元，我们使用区域自适应分层变换来实现各种属性的近无损压缩。对于非锚基元，每个基元都是基于k个最近的锚基元进行预测的。为了进一步最小化预测误差，将重建的LoD和锚基元组合在一起，形成新的锚基元，以预测下一个LoD。与小型场景数据集上最先进的压缩方法相比，我们的方法显著实现了卓越的压缩质量，数据大小大幅减少了4.5倍以上。 et.al.|[2411.06976](http://arxiv.org/abs/2411.06976)|null|
|**2024-11-10**|**Adaptive and Temporally Consistent Gaussian Surfels for Multi-view Dynamic Reconstruction**|3D高斯散点最近在动态场景的新颖视图合成和静态场景的几何重建方面取得了显著成功。在这些进步的基础上，通过全局优化整个序列，开发了用于动态表面重建的早期方法。然而，重建具有显著拓扑变化、出现或消失的物体以及快速运动的动态场景仍然是一个巨大的挑战，特别是对于长序列。为了解决这些问题，我们提出了AT-GS，这是一种通过每帧增量优化从多视图视频中重建高质量动态曲面的新方法。为了避免跨帧的局部最小值，我们引入了一种统一的自适应梯度感知致密化策略，该策略整合了传统克隆和分裂技术的优势。此外，我们通过确保连续帧中曲率图的一致性来减少动态曲面中的时间抖动。我们的方法在动态表面重建中实现了卓越的精度和时间相干性，即使在复杂和具有挑战性的场景中也能提供高保真的时空新颖视图合成。对不同多视图视频数据集的广泛实验证明了我们的方法的有效性，显示出比基线方法明显的优势。项目页面：\url{https://fraunhoferhhi.github.io/AT-GS} et.al.|[2411.06602](http://arxiv.org/abs/2411.06602)|null|

<p align=right>(<a href=#updated-on-20241118>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-11-15**|**Uncertainty-Weighted Mutual Distillation for Multi-View Fusion**|多视图学习在有效利用从不同角度和位置捕获的图像方面经常面临挑战。在解决观点之间的不一致和不确定性时，这一挑战尤为明显。本文提出了一种新的多视图不确定性加权互蒸馏（MV-UWMD）方法。我们的方法通过在所有可能的视图组合（包括单视图、部分多视图和完全多视图预测）中执行分层相互蒸馏来增强预测一致性。这通过相互蒸馏引入了一种基于不确定性的加权机制，允许有效利用来自每个视图的独特信息，同时减轻不确定预测的影响。我们扩展了CNN-Transformer混合架构，以促进跨多个视图组合的稳健特征学习和集成。我们使用从各种非固定视角捕获的大型非结构化数据集进行了广泛的实验。结果表明，与现有的多视图学习方法相比，MV-UWMD提高了预测的准确性和一致性。 et.al.|[2411.10077](http://arxiv.org/abs/2411.10077)|null|
|**2024-11-14**|**CropCraft: Inverse Procedural Modeling for 3D Reconstruction of Crop Plants**|从图像中自动构建植物的3D数字双胞胎的能力在农业、环境科学、机器人技术和其他领域有着无数的应用。然而，由于严重的遮挡和复杂的几何形状，目前的3D重建方法无法恢复植物的完整形状。在这项工作中，我们提出了一种基于逆过程建模优化植物形态参数模型的农作物三维重建新方法。我们的方法首先通过拟合神经辐射场来估计深度图，然后采用贝叶斯优化来估计植物形态参数，从而得到一致的深度渲染。由此产生的3D模型是完整的，在生物学上是合理的。我们在农田真实图像的数据集上验证了我们的方法，并证明了重建可用于各种监测和模拟应用。 et.al.|[2411.09693](http://arxiv.org/abs/2411.09693)|null|
|**2024-11-13**|**Biomass phenotyping of oilseed rape through UAV multi-view oblique imaging with 3DGS and SAM model**|油菜生物量估算对于优化作物生产力和育种策略至关重要。虽然基于无人机的成像具有先进的高通量表型，但目前的方法通常依赖于正射影像图像，在复杂的野外环境中，正射影像难以处理重叠的叶子和不完整的结构信息。本研究将3D高斯散点（3DGS）与分段任意模型（SAM）相结合，用于油菜的精确3D重建和生物量估算。使用来自36个角度的无人机多视角斜向图像进行3D重建，SAM模块增强了点云分割。然后将分割的点云转换为点云体积，使用线性回归将其与地面测量的生物量进行拟合。结果表明，3DGS（7k和30k迭代）提供了高精度，峰值信噪比（PSNR）分别为27.43和29.53，训练时间分别为7和49分钟。该性能超越了运动结构（SfM）和mipmap神经辐射场（Mip-NeRF），展现出卓越的效率。SAM模块实现了高分割精度，平均交集超过并集（mIoU）为0.961，F1得分为0.980。此外，对生物质提取模型的比较发现，点云体积模型是最准确的，其决定系数（R2）为0.976，均方根误差（RMSE）为2.92 g/株，平均绝对百分比误差（MAPE）为6.81%，优于地块作物体积和单个作物体积模型。这项研究强调了将3DGS与多视图无人机成像相结合以改善生物量表型的潜力。 et.al.|[2411.08453](http://arxiv.org/abs/2411.08453)|null|
|**2024-11-12**|**Constraints on local primordial non-Gaussianity with 3d Velocity Reconstruction from the Kinetic Sunyaev-Zeldovich Effect**|宇宙速度场是总物质分布的无偏探测器，但在中等和高红移下直接测量具有挑战性。大尺度速度场通过动力学Sunyaev-Zeldovich（kSZ）效应在宇宙微波背景（CMB）中留下信号。我们通过将二次估计器应用于CMB温度图和星系的三维位置，从kSZ效应对大尺度速度场进行了首次三维重建。我们通过结合阿塔卡马宇宙学望远镜（与普朗克望远镜结合）第五次数据发布的CMB数据和斯隆数字巡天的光谱星系样本来实现这一目标。然后，我们测量了星系速度交叉功率谱，并在信噪比为7.2 $\sigma$时检测到kSZ信号的存在。仅使用这个星系速度互相关，我们约束了局部原始非高斯性的振幅，发现$f_{\rm NL}=-90 ^{+210}_{-350}$。这一探路者测量为联合星系CMB-kSZ约束奠定了基础，通过样本方差抵消显著增强了从星系调查中获得的$f_{\rm NL}$ 信息。 et.al.|[2411.08240](http://arxiv.org/abs/2411.08240)|null|
|**2024-11-12**|**SP-VIO: Robust and Efficient Filter-Based Visual Inertial Odometry with State Transformation Model and Pose-Only Visual Description**|基于滤波器的视觉惯性里程计（VIO）具有计算效率高、内存需求小的优点，在小型化和有效载荷受限的嵌入式系统中具有良好的应用前景。然而，基于滤波器的方法存在精度不足的问题。为此，我们通过重建状态和测量模型，并考虑进一步的视觉剥夺条件，提出了状态转换和仅姿态VIO（SP-VIO）。详细地说，我们首先提出了一种基于双状态变换扩展卡尔曼滤波器（DST-EKF）的系统模型，该模型已被证明比基于扩展卡尔曼滤波器和状态变换扩展Kalman滤波器的模型具有更好的可观测性和一致性。其次，为了减少由不准确的3D重建引起的线性化误差的影响，我们采用仅位姿（PO）理论将测量模型与3D特征解耦。此外，为了应对视觉剥夺的情况，我们提出了一种双态变换Rauch Tung-Striebel（DST-RTS）回溯方法来优化视觉中断期间的运动轨迹。在公共（EuRoC、Tum VI、KITTI）和个人数据集上的实验表明，SP-VIO比最先进的（SOTA）VIO算法具有更好的准确性和效率，并且在视觉剥夺条件下具有更好的鲁棒性。 et.al.|[2411.07551](http://arxiv.org/abs/2411.07551)|null|
|**2024-11-12**|**Extreme Rotation Estimation in the Wild**|我们提出了一种技术和基准数据集，用于估计在极端环境中捕获的一对互联网图像之间的相对3D方向，其中图像具有有限或不重叠的视场。之前针对极端旋转估计的工作假设了受约束的3D环境，并通过从全景图中裁剪区域来模拟透视图像。然而，在野外拍摄的真实图像非常多样化，在外观和相机内部都表现出变化。在这项工作中，我们提出了一种基于Transformer的方法来估计极端现实环境中的相对旋转，并贡献了由场景级互联网照片集组装而成的ExtremeLandmarkPairs数据集。我们的评估表明，我们的方法成功地估计了各种极端视图互联网图像对中的相对旋转，优于各种基线，包括专用旋转估计技术和当代3D重建方法。 et.al.|[2411.07096](http://arxiv.org/abs/2411.07096)|null|
|**2024-11-11**|**AV-PedAware: Self-Supervised Audio-Visual Fusion for Dynamic Pedestrian Awareness**|在这项研究中，我们介绍了AV PedAware，这是一种自我监督的视听融合系统，旨在提高机器人应用中的动态行人感知能力。行人意识是许多机器人应用中的关键要求。然而，依赖相机和LIDAR覆盖多个视图的传统方法可能很昂贵，并且容易受到光照、遮挡和天气条件变化等问题的影响。我们提出的解决方案使用低成本的音频和视觉融合来复制人类对3D行人检测的感知。这项研究首次尝试利用视听融合来监测脚步声，以预测附近行人的运动。该系统通过基于激光雷达生成标签的自我监督学习进行训练，使其成为基于激光雷达的行人感知的经济高效的替代方案。AV PedAware以极低的成本实现了与基于激光雷达的系统相当的结果。通过利用注意力机制，它可以处理动态照明和遮挡，克服了传统激光雷达和基于相机的系统的局限性。为了评估我们的方法的有效性，我们收集了一个新的多模式行人检测数据集，并进行了实验，证明该系统即使在极端的视觉条件下，也能仅使用音频和视觉数据提供可靠的3D检测结果。我们将把收集到的数据集和源代码在线提供给社区，以鼓励机器人感知系统领域的进一步发展。 et.al.|[2411.06789](http://arxiv.org/abs/2411.06789)|null|
|**2024-11-10**|**Real-time Deformation-aware Control for Autonomous Robotic Subretinal Injection under iOCT Guidance**|机器人平台提供可重复和精确的工具定位，显著增强视网膜显微手术。这种系统与术中光学相干断层扫描（iOCT）的集成实现了图像引导的机器人干预，允许自主执行高级治疗可能性，例如将治疗剂注射到视网膜下腔。然而，在自主iOCT引导的机器人视网膜下注射中，由于工具-组织相互作用导致的组织变形是一个主要挑战，会影响正确的针头定位，从而影响手术的结果。本文提出了一种在iOCT引导下自主视网膜下注射的新方法，该方法考虑了插入过程中的组织变形。这是通过从密集采样的iOCT B扫描（我们称之为B5扫描）中实时分割和3D重建手术场景来实现的，以监测仪器相对于ILM和RPE之间相对位置处定义的虚拟目标层的定位。我们在离体猪眼睛上的实验表明，与之前的自主插入方法相比，插入深度的动态调整和针头定位的整体精度得到了提高。与之前方法生成视网膜下泡的成功率为35%相比，我们提出的方法在所有实验中都可靠、稳健地创建了视网膜下泡。 et.al.|[2411.06557](http://arxiv.org/abs/2411.06557)|null|
|**2024-11-10**|**A novel algorithm for optimizing bundle adjustment in image sequence alignment**|捆绑调整（BA）模型通常使用非线性最小二乘法进行优化，Levenberg-Marquardt（L-M）算法是典型的选择。然而，尽管L-M算法很有效，但当应用于条件较差的数据集时，它对初始条件的敏感性往往会导致收敛速度较慢，从而激发了对替代优化策略的探索。本文介绍了一种在低温电子断层成像图像序列比对背景下优化BA模型的新算法，该算法利用最优控制理论直接优化一般非线性函数。所提出的最优控制算法（OCA）表现出优异的收敛速度，并有效地缓解了L-M算法中经常观察到的振荡行为。对合成数据集和真实世界数据集进行了广泛的实验，以评估算法的性能。结果表明，与L-M算法相比，OCA实现了更快的收敛。此外，基于二分法的更新过程显著提高了OCA的性能，特别是在初始化不佳的数据集中。这些发现表明，OCA可以大大提高低温电子断层扫描中3D重建的效率。 et.al.|[2411.06343](http://arxiv.org/abs/2411.06343)|null|
|**2024-11-08**|**Benchmarking 3D multi-coil NC-PDNet MRI reconstruction**|深度学习在从欠采样数据中重建MRI方面显示出巨大的前景，但目前还缺乏对其在非笛卡尔欠采样的3D并行成像采集中的性能进行验证的研究。此外，伪影和由此产生的图像质量取决于欠采样模式。为了解决这一未知领域的问题，我们将非笛卡尔原始双网络（NC PDNet）扩展到3D多线圈设置，这是一种最先进的展开神经网络。我们评估了通道特定训练配置与通道无关训练配置的影响，并检查了线圈压缩的效果。最后，我们使用公开的卡尔加里坎皮纳斯数据集，对四种不同的非笛卡尔欠采样模式进行基准测试，加速因子为6。我们的结果表明，在具有不同输入通道数的压缩数据上训练的NC PDNet在1mm各向同性32通道全脑3D重建中实现了42.98 dB的平均PSNR。推理时间为4.95秒，GPU内存使用率为5.49 GB，我们的方法在临床研究应用中具有巨大的潜力。 et.al.|[2411.05883](http://arxiv.org/abs/2411.05883)|null|

<p align=right>(<a href=#updated-on-20241118>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-11-15**|**M-VAR: Decoupled Scale-wise Autoregressive Modeling for High-Quality Image Generation**|最近在计算机视觉领域有一项名为VAR的工作，提出了一种新的自回归图像生成范式。与香草下一个令牌预测不同，VAR在结构上将图像生成重新表述为从粗到细的下一个尺度预测。在本文中，我们证明了这种尺度自回归框架可以有效地解耦为\textit{尺度内建模}和\textit{inter-scale建模}，\textit}捕获每个尺度内的局部空间依赖性，\textit{尺度间建模}从粗尺度到细尺度逐步建模跨尺度关系。这种解耦结构允许以更高效的计算方式重建VAR。具体来说，对于生成高保真图像至关重要的尺度内建模，我们保留了原始的双向自关注设计，以确保全面建模；对于跨尺度建模，它在语义上连接了不同的尺度，但计算量很大，我们应用了像Mamba这样的线性复杂度机制来大大减少计算开销。我们将这个新框架称为M-VAR。大量实验表明，我们的方法在图像质量和生成速度方面都优于现有模型。例如，我们的1.5B模型具有更少的参数和更快的推理速度，其性能优于最大的VAR-d30-2B。此外，我们最大的模型M-VAR-d32在ImageNet 256×256上令人印象深刻地记录了1.78 FID，分别比现有技术的自回归模型LlamaGen/VAR高0.4/0.19，比流行的扩散模型LDM/DiT高1.82/0.49。代码位于\url{https://github.com/OliverRensu/MVAR}. et.al.|[2411.10433](http://arxiv.org/abs/2411.10433)|null|
|**2024-11-15**|**Mitigating Parameter Degeneracy using Joint Conditional Diffusion Model for WECC Composite Load Model in Power Systems**|近年来，动态系统的数据驱动建模受到了广泛关注。其逆公式，参数估计，旨在从观测中推断出固有的模型参数。然而，参数退化，即不同的参数组合产生相同的可观测输出，对准确和唯一地识别模型参数构成了关键障碍。在电力系统WECC复合负荷模型（CLM）的背景下，公用事业从业者观察到，为一个故障事件精心选择的CLM参数在另一个故障中可能无法令人满意。在这里，我们创新了一种基于联合条件扩散模型的逆问题求解器（JCDI），该求解器将联合条件架构与多事件观测的同时输入相结合，以提高参数的泛化能力。对WECC CLM的仿真研究表明，所提出的JCDI有效地降低了退化参数的不确定性，因此与单事件学习方案相比，参数估计误差降低了42.1%。这使得该模型能够在预测不同故障事件（包括电子负载跳闸和电机失速）下的功率轨迹方面实现高精度，优于标准的深度强化学习和监督学习方法。我们预计这项工作将有助于缓解系统动力学中的参数退化，为各种科学领域提供一个通用的参数估计框架。 et.al.|[2411.10431](http://arxiv.org/abs/2411.10431)|null|
|**2024-11-15**|**Lower bounds on the top Lyapunov exponent for linear PDEs driven by the 2D stochastic Navier-Stokes equations**|我们考虑了与平流扩散相关的顶部李雅普诺夫指数和二维环面上的线性化Navier-Stokes方程。速度场由具有幂律相关结构的非简并白噪声驱动的随机Navier-Stokes方程给出。我们证明了顶部李雅普诺夫指数从下到下由扩散参数的负幂函数所限定。这部分回答了Doering和Miles的猜想，并提供了Batchelor尺度上扩散率的第一个下限。该证明依赖于通过其谱中值动力学对与线性方程相关的投影过程进行稳健分析。我们引入了一个概率论证，表明投影过程的高频状态在随机扰动下是不稳定的，从而导致李雅普诺夫漂移条件和定量扩散率估计。 et.al.|[2411.10419](http://arxiv.org/abs/2411.10419)|null|
|**2024-11-15**|**Repurposing Stable Diffusion Attention for Training-Free Unsupervised Interactive Segmentation**|基于交互式点提示的图像分割的最新进展可以显著减少获取高质量语义标签的人工工作量。最先进的无监督方法使用自监督预训练模型来获得伪标签，这些伪标签用于训练基于提示的分割模型。在这篇论文中，我们提出了一种新的无监督和无训练的方法，该方法完全基于稳定扩散的自我注意。我们将自我注意张量解释为马尔可夫转移算子，这使我们能够迭代地构建马尔可夫链。对沿马尔可夫链达到相对概率阈值所需的迭代次数进行逐像素计数，得到马尔可夫迭代图，我们简称之为马尔可夫图。与原始注意力图相比，我们发现我们提出的马尔可夫图在语义相似的区域内具有更少的噪声、更清晰的语义边界和更均匀的值。我们将马尔可夫图整合到一个简单而有效的截断最近邻框架中，以获得基于交互式点提示的分割。尽管无需训练，但我们的实验表明，我们的方法在点击次数（NoC）方面取得了优异的结果，甚至在大多数数据集中都优于最先进的基于训练的无监督方法。 et.al.|[2411.10411](http://arxiv.org/abs/2411.10411)|null|
|**2024-11-15**|**Towards High-Fidelity 3D Portrait Generation with Rich Details by Cross-View Prior-Aware Diffusion**|最近基于扩散的单图像3D肖像生成方法通常采用2D扩散模型来提供多视图知识，然后将其提取为3D表示。然而，这些方法通常很难产生高保真度的3D模型，经常产生过于模糊的纹理。我们将此问题归因于在扩散过程中对交叉视图一致性的考虑不足，导致不同视图之间存在显著差异，最终导致3D表示模糊。在本文中，我们通过综合利用条件反射和扩散过程中的多视图先验来解决这个问题，以生成一致、细节丰富的肖像。从条件化的角度来看，我们提出了一种混合先验扩散模型，该模型显式和隐式地将多视图先验作为条件，以提高生成的多视图肖像的状态一致性。从扩散的角度来看，考虑到扩散噪声分布对详细纹理生成的显著影响，我们提出了一种集成在优化过程中的多视图噪声重采样策略，该策略利用跨视图先验来增强表示一致性。大量实验表明，我们的方法可以从单张图像中生成具有精确几何形状和丰富细节的3D肖像。项目页面位于\url{https://haoran-wei.github.io/Portrait-Diffusion}. et.al.|[2411.10369](http://arxiv.org/abs/2411.10369)|null|
|**2024-11-15**|**Anisotropic Field Theory of Wave Transmission Statistics in Disordered Media**|我们提出了一种场论来表征相干波在无序介质中传播的传输本征值的平均分布。与Dorokhov-Mello-Pereyra Kumar（DMPK）理论不同，我们的方法不依赖于各向同性假设，该假设假设散射通道上的场强均匀。因此，它准确地预测了扩散和准弹道状态下的传输特征值分布。此外，它被证明比DMPK理论更通用，允许在对形式进行最小调整的情况下结合吸收或部分通道控制等物理效应。尽管这些效应在复杂介质的实验中很常见，但到目前为止还没有从头计算理论来解决它们。我们的预测与根据微观波动方程计算的传输特征值分布进行了数值验证。 et.al.|[2411.10360](http://arxiv.org/abs/2411.10360)|null|
|**2024-11-15**|**Transmission eigenvalue distribution in disordered media from anisotropic field theory**|详细发展了通过无序介质传输本征值分布的场论。该理论的中心方程是2×2矩阵辐射的自洽输运方程。该方程不仅确定了扩散区的透射本征值分布，还确定了准弹道区的透射特征值分布，在准弹道区，辐射率预计在材料体中具有显著的各向异性。我们证明，在这种情况下，矩阵输运方程可以解析求解。我们还表明，除了有限宽度波导外，我们的方程还能够预测通过无限板的传输本征值分布。 et.al.|[2411.10355](http://arxiv.org/abs/2411.10355)|null|
|**2024-11-15**|**Probabilistic Prior Driven Attention Mechanism Based on Diffusion Model for Imaging Through Atmospheric Turbulence**|大气湍流引入了严重的空间和几何失真，挑战了传统的图像恢复方法。我们提出了概率先验湍流去除网络（PPTRN），该网络将基于概率扩散的先验建模与变压器驱动的特征提取相结合，以解决这个问题。PPTRN采用两阶段方法：首先，在清晰图像上联合训练潜在编码器和Transformer，以建立鲁棒的特征表示。然后，去噪扩散概率模型（DDPM）对潜在向量上的先验分布进行建模，指导Transformer捕获恢复所必需的各种特征变化。PPTRN的一个关键创新是概率先验驱动交叉注意机制，该机制将DDPM生成的先验与特征嵌入相结合，以减少伪影并增强空间一致性。大量实验证实，PPTRN显著提高了湍流退化图像的恢复质量，在清晰度和结构保真度方面树立了新的基准。 et.al.|[2411.10321](http://arxiv.org/abs/2411.10321)|null|
|**2024-11-15**|**Modification Takes Courage: Seamless Image Stitching via Reference-Driven Inpainting**|当前的图像拼接方法在不均匀色调和大视差等具有挑战性的场景中经常会产生明显的接缝。为了解决这个问题，我们提出了参考驱动的内涂缝合器（RDISPitcher），它将图像融合和矩形调整重新表述为基于参考的修复模型，与以前的方法相比，它包含了更大的修改融合区域和更强的修改强度。此外，我们引入了一种自监督模型训练方法，通过微调文本到图像（T2I）扩散模型，可以在不需要标记数据的情况下实现RDISPitcher。认识到评估拼接图像质量的困难，我们提出了基于多模态大语言模型（MLLM）的度量，为评估拼接图像的质量提供了新的视角。与最先进的（SOTA）方法相比，广泛的实验表明，我们的方法显著提高了拼接图像中的内容连贯性和无缝过渡。特别是在零样本实验中，我们的方法表现出较强的泛化能力。代码：https://github.com/yayoyo66/RDIStitcher et.al.|[2411.10309](http://arxiv.org/abs/2411.10309)|**[link](https://github.com/yayoyo66/rdistitcher)**|
|**2024-11-15**|**The Unreasonable Effectiveness of Guidance for Diffusion Models**|制导是一种纠错技术，用于提高扩散模型生成的图像的感知质量。通常，校正是通过线性外推实现的，使用性能低于主模型的辅助扩散模型。使用2D玩具示例，我们表明，当辅助模型表现出与主模型相似但更强的误差时，这是非常有益的。我们在更高的维度上验证了这一发现，我们表明，当辅助模型仅通过更强的权重正则化与主模型不同时，可以实现与最先进的制导方法竞争的生成性能。作为一项独立贡献，我们研究了增加长距离空间依赖性是否可以提高视觉保真度。其结果是一种新的引导方法，我们称之为滑动窗口引导（SWG），通过约束其感受野来引导主模型本身。有趣的是，SWG比最先进的指导方法更符合人类偏好，同时不需要培训、架构修改或课堂条件。代码将被发布。 et.al.|[2411.10257](http://arxiv.org/abs/2411.10257)|null|

<p align=right>(<a href=#updated-on-20241118>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-11-14**|**The Hydrodynamic Limit of Hawkes Processes on Adaptive Stochastic Networks**|我们确定了自适应网络上相互作用的霍克斯过程网络的大尺寸限制。节点变量的翻转被认为具有由传入边缘和节点的平均场给出的强度。边缘变量的翻转是传入节点变量的函数。边变量可以是对称的，也可以是不对称的。该模型受到社会学、神经科学和流行病学应用的启发。一般来说，极限概率律可以表示为具有强度函数的自洽泊松过程的不动点，该强度函数（i）是延迟的，（ii）取决于其自身的概率律。在边缘翻转仅由突触前神经元的状态决定的特定情况下（如神经科学中），证明了可以获得突触增强和神经增强双重进化的自主神经场型方程。 et.al.|[2411.09260](http://arxiv.org/abs/2411.09260)|null|
|**2024-11-09**|**Epi-NAF: Enhancing Neural Attenuation Fields for Limited-Angle CT with Epipolar Consistency Conditions**|神经场方法最初在逆渲染领域取得了成功，最近已扩展到CT重建，标志着传统技术的范式转变。虽然这些方法在稀疏视图CT重建中提供了最先进的结果，但它们在有限的角度设置中很难实现，在有限的视角范围内捕获输入投影。我们提出了一种基于X射线投影图像中相应极线之间一致性条件的新损失项，旨在规范神经衰减场优化。通过强制执行这些一致性条件，我们的方法Epi NAF将监督从有限角度范围内的输入视图传播到整个锥束CT范围内的预测投影。与基线方法相比，这种损失导致重建的定性和定量改进。 et.al.|[2411.06181](http://arxiv.org/abs/2411.06181)|null|
|**2024-11-07**|**LoFi: Scalable Local Image Reconstruction with Implicit Neural Representation**|神经场或隐式神经表示（INR）因其对图像和3D体积的有效连续表示而在机器学习和信号处理中引起了广泛关注。在这项工作中，我们以INR为基础，引入了一种基于坐标的局部处理框架来解决成像逆问题，称为LoFi（局部场）。与传统的图像重建方法不同，LoFi通过多层感知器（MLP）分别处理每个坐标处的局部信息，在该特定坐标处恢复对象。与INR类似，LoFi可以在任何连续坐标下恢复图像，从而实现多分辨率的图像重建。LoFi在图像重建方面的性能与标准CNN相当或更好，几乎与图像分辨率无关，对分布外数据和内存使用具有出色的泛化能力。值得注意的是，对1024美元×1024美元的图像进行训练只需要3GB的内存，比标准CNN通常需要的内存少20多倍。此外，LoFi的局部设计使其能够在小于10个样本的极小数据集上进行训练，而不会过拟合或需要正则化或提前停止。最后，我们使用LoFi作为即插即用框架中的去噪先验，用于解决一般的逆问题，以受益于其连续的图像表示和强大的泛化能力。尽管在低分辨率图像上进行了训练，但LoFi可以用作低维先验，以解决任何分辨率的逆问题。我们通过各种成像方式验证了我们的框架，从低剂量计算机断层扫描到无线电干涉成像。 et.al.|[2411.04995](http://arxiv.org/abs/2411.04995)|null|
|**2024-11-04**|**Physically Based Neural Bidirectional Reflectance Distribution Function**|我们介绍了基于物理的神经双向反射分布函数（PBNBRDF），这是一种基于神经场的材料外观的新颖连续表示。我们的模型准确地重建了真实世界的材料，同时独特地增强了现实BRDF的物理特性，特别是通过重新参数化的亥姆霍兹互易性和通过高效分析积分的能量无源性。我们进行了系统分析，证明了遵守这些物理定律对重建材料的视觉质量的好处。此外，我们通过引入色度强制监督RGB通道的规范来提高神经BRDF的颜色精度。通过在多个测量的真实BRDF数据库上进行定性和定量实验，我们表明，遵守这些物理约束可以使神经场更忠实、更稳定地表示原始数据，并实现更高的渲染质量。 et.al.|[2411.02347](http://arxiv.org/abs/2411.02347)|null|
|**2024-11-01**|**Intensity Field Decomposition for Tissue-Guided Neural Tomography**|锥束计算机断层扫描（CBCT）通常需要数百次X射线投影，这引起了人们对辐射暴露的担忧。虽然稀疏视图重建通过使用更少的投影来减少曝光，但它很难达到令人满意的图像质量。为了应对这一挑战，本文介绍了一种新的稀疏视图CBCT重建方法，该方法为神经场赋予了人体组织正则化的能力。我们的方法被称为组织引导神经断层扫描（TNT），其动机是CBCT中骨骼和软组织之间明显的强度差异。直观地说，分离这些成分可能有助于神经场的学习过程。更确切地说，TNT包括一个异构的四重网络和相应的训练策略。该网络将强度场表示为软组织和硬组织成分及其各自纹理的组合。我们在估计的组织投影的指导下训练网络，从而能够有效地学习网络头所需的模式。大量实验表明，所提出的方法显著改善了稀疏视图CBCT重建，投影数量从10到60不等。与最先进的基于神经渲染的方法相比，我们的方法以更少的投影和更快的收敛实现了相当的重建质量。 et.al.|[2411.00900](http://arxiv.org/abs/2411.00900)|null|
|**2024-10-26**|**Neural Fields in Robotics: A Survey**|神经场已经成为计算机视觉和机器人技术中3D场景表示的一种变革性方法，能够从姿势的2D数据中准确推断几何、3D语义和动力学。利用可微分渲染，神经场包括连续隐式和显式神经表示，实现了高保真3D重建、多模态传感器数据的集成和新视点的生成。这项调查探讨了它们在机器人技术中的应用，强调了它们在增强感知、规划和控制方面的潜力。它们的紧凑性、内存效率和可微性，以及与基础模型和生成模型的无缝集成，使其成为实时应用的理想选择，提高了机器人的适应性和决策能力。本文基于200多篇论文，对机器人中的神经场进行了全面的回顾，对各个领域的应用进行了分类，并评估了它们的优势和局限性。首先，我们介绍了四个关键的神经场框架：占用网络、有符号距离场、神经辐射场和高斯散斑。其次，我们详细介绍了神经场在五个主要机器人领域的应用：姿态估计、操纵、导航、物理和自动驾驶，重点介绍了关键工作，并讨论了要点和公开挑战。最后，我们概述了神经场在机器人技术中的局限性，并为未来的研究提出了有前景的方向。项目页面：https://robonerf.github.io et.al.|[2410.20220](http://arxiv.org/abs/2410.20220)|**[link](https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics)**|
|**2024-10-24**|**3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation**|多视图图像扩散模型显著推进了开放域3D对象生成。然而，大多数现有模型依赖于缺乏固有3D偏差的2D网络架构，导致几何一致性受损。为了应对这一挑战，我们引入了3D Adapter，这是一个插件模块，旨在将3D几何感知注入预训练的图像扩散模型中。我们方法的核心是3D反馈增强的思想：对于采样循环中的每个去噪步骤，3D Adapter将中间的多视图特征解码为连贯的3D表示，然后对渲染的RGBD视图进行重新编码，通过特征添加来增强预训练的基础模型。我们研究了3D Adapter的两种变体：一种是基于高斯飞溅的快速前馈版本，另一种是利用神经场和网格的通用无训练版本。我们广泛的实验表明，3D Adapter不仅大大提高了文本到多视图模型（如Instant3D和Zero123++）的几何质量，而且还使用纯文本到图像的稳定扩散实现了高质量的3D生成。此外，我们通过在文本到3D、图像到3D、文本到纹理和文本到化身任务中呈现高质量的结果，展示了3D适配器的广泛应用潜力。 et.al.|[2410.18974](http://arxiv.org/abs/2410.18974)|**[link](https://github.com/Lakonik/MVEdit)**|
|**2024-10-22**|**Cortical Dynamics of Neural-Connectivity Fields**|皮质组织的宏观研究揭示了振荡活动的普遍性，这反映了神经相互作用的微调。本研究通过将广义振荡动力学纳入先前关于保守或半保守神经场动力学的工作中，扩展了神经场理论。先前的研究在很大程度上假设了神经单元之间的各向同性连接；然而，这项研究表明，广泛的各向异性和波动连接仍然可以维持振荡。使用拉格朗日场方法，我们研究了不同类型的连接、它们的动力学以及与神经场的潜在相互作用。基于这一理论基础，我们推导出了一个框架，该框架通过连接场的概念将Hebbian和非Hebbian学习（即可塑性）纳入神经场的研究中。 et.al.|[2410.16852](http://arxiv.org/abs/2410.16852)|null|
|**2024-10-15**|**Deep vectorised operators for pulsatile hemodynamics estimation in coronary arteries from a steady-state prior**|心血管血流动力学场为冠状动脉疾病提供了有价值的医学决策标志。计算流体动力学（CFD）是体内准确、无创评估这些量的金标准。在这项工作中，我们提出了一种基于机器学习的时间高效替代模型，用于基于稳态先验估计脉动血流动力学。我们引入了深度矢量化算子，这是一种用于在无限维函数空间上进行离散化独立学习的建模框架。基础神经结构是一个以血流动力学边界条件为条件的神经场。重要的是，我们展示了如何将逐点动作的要求放宽到置换等变，从而产生一系列可以通过消息传递和自我关注层进行参数化的模型。我们在从冠状动脉计算机断层扫描血管造影（CCTA）中提取的74条狭窄冠状动脉的数据集上评估了我们的方法，并将患者特异性脉动CFD模拟作为基本事实。我们证明，我们的模型能够准确估计脉动速度和压力，同时不受源域重新采样的影响（离散化独立性）。这表明，深度矢量化算子是冠状动脉及其他动脉心血管血流动力学估计的强大建模工具。 et.al.|[2410.11920](http://arxiv.org/abs/2410.11920)|null|
|**2024-10-07**|**Fast Training of Sinusoidal Neural Fields via Scaling Initialization**|神经场是一种新兴的范式，它将数据表示为由神经网络参数化的连续函数。尽管有许多优点，但神经场通常具有较高的训练成本，这阻碍了更广泛的采用。在本文中，我们关注一个流行的神经场家族，称为正弦神经场（SNF），并研究如何初始化它以最大限度地提高训练速度。我们发现，基于信号传播原理设计的SNF标准初始化方案是次优的。特别是，我们证明，通过简单地将每个权重（最后一层除外）乘以一个常数，我们可以将SNF训练加速10 $\times$。这种方法被称为$\textit{weight scaling}$ ，在各种数据域上持续提供显著的加速，使SNF的训练速度比最近提出的架构更快。为了理解为什么权重缩放效果良好，我们进行了广泛的理论和实证分析，结果表明，权重缩放不仅有效地解决了频谱偏差，而且具有良好的优化轨迹。 et.al.|[2410.04779](http://arxiv.org/abs/2410.04779)|null|

<p align=right>(<a href=#updated-on-20241118>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

