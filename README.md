[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2026.02.09
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#video-diffusion>Video Diffusion</a></li>
    <li><a href=#3d>3D</a></li>
    <li><a href=#具生智能&自动驾驶>具生智能&自动驾驶</a></li>
  </ol>
</details>

## Video Diffusion

- **2026-02-06** **CineScene: Implicit 3D as Effective Scene Representation for Cinematic Video Generation** [2602.06959](http://arxiv.org/abs/2602.06959)
  > 电影视频制作需要控制场景主体构图和摄像机移动，但由于需要构建物理布景，实景拍摄仍然成本高昂。为了解决这个问题，我们引入了具有解耦场景上下文的电影视频生成任务：给定静态环境的多个图像，目标是合成具有动态主题的高质量视频，同时保持底层场景的一致性并遵循用户指定的摄像机轨迹。我们提出了 CineScene，一个利用隐式 3D 感知场景表示来生成电影视频的框架。我们的关键创新是一种新颖的上下文调节机制，它以隐式方式注入 3D 感知功能：通过 VGGT 将场景图像编码为视觉表示，CineScene 通过额外的上下文串联将空间先验注入到预训练的文本到视频生成模型中，从而实现具有一致场景和动态主题的摄像机控制视频合成。为了进一步增强模型的鲁棒性，我们在训练期间对输入场景图像引入了一种简单而有效的随机洗牌策略。为了解决训练数据的缺乏，我们使用虚幻引擎 5 构建了一个场景解耦数据集，其中包含有和没有动态主体的场景配对视频、代表底层静态场景的全景图像及其摄像机轨迹。实验表明，CineScene 在场景一致的电影视频生成方面实现了最先进的性能，可处理大型摄像机运动并展示跨不同环境的泛化能力。

- **2026-02-06** **RFDM: Residual Flow Diffusion Model for Efficient Causal Video Editing** [2602.06871](http://arxiv.org/abs/2602.06871)
  > 教学视频编辑仅使用文本提示对输入视频进行编辑，从而实现直观的自然语言控制。尽管进展迅速，大多数方法仍然需要固定长度的输入和大量的计算。与此同时，自回归视频生成可以实现高效的可变长度合成，但在视频编辑方面仍有待探索。我们引入了一种因果高效的视频编辑模型，可以逐帧编辑可变长度的视频。为了提高效率，我们从 2D 图像到图像 (I2I) 扩散模型开始，并通过根据模型在 t-1 时的预测来调节时间步 t 的编辑，使其适应视频到视频 (V2V) 编辑。为了利用视频的时间冗余，我们提出了一种新的 I2I 扩散前向过程公式，鼓励模型预测目标输出和先前预测之间的残差。我们称之为残余流扩散模型（RFDM），它将去噪过程集中在连续帧之间的变化上。此外，我们提出了一个新的基准，可以更好地对编辑任务的最先进方法进行排名。 RFDM 在配对视频数据上进行全局/局部风格转移和对象移除训练，超越了基于 I2I 的方法，并与完全时空 (3D) V2V 模型竞争，同时匹配图像模型的计算并独立于输入视频长度进行缩放。更多内容可参见：https://smsd75.github.io/RFDM_page/

- **2026-02-06** **DiTS: Multimodal Diffusion Transformers Are Time Series Forecasters** [2602.06597](http://arxiv.org/abs/2602.06597)
  > 虽然时间序列的生成建模有助于更强大和灵活的概率预测，但现有的生成时间序列模型并不能很好地解决时间序列数据的多维属性。扩散变压器 (DiT) 的流行架构依赖于简单的条件控制和单流变压器主干，往往在协变量感知预测中未充分利用跨变量依赖关系。受到将文本指导集成到视频生成中的多模态扩散变压器的启发，我们提出了时间序列扩散变压器（DiTS），这是一种通用架构，将内源变量和外源变量构建为不同的模态。为了更好地捕获变量间和变量内的依赖关系，我们设计了一个针对时间序列数据定制的双流 Transformer 模块，包括用于沿时间维度进行自回归建模的时间注意力模块和用于跨变量建模的变量注意力模块。与将 2D 标记网格扁平化为 1D 序列的常见图像方法不同，我们的设计利用了多元依赖关系中固有的低秩属性，从而降低了计算成本。实验表明，无论未来是否存在外生变量观测值，DiTS 都能在各个基准上实现最先进的性能，与传统的确定性深度预测模型相比，展现出独特的生成预测优势。

- **2026-02-06** **World-VLA-Loop: Closed-Loop Learning of Video World Model and VLA Policy** [2602.06508](http://arxiv.org/abs/2602.06508)
  > 机器人世界模型的最新进展利用视频扩散变压器来预测基于历史状态和动作的未来观察。虽然这些模型可以模拟真实的视觉结果，但它们通常表现出较差的动作跟踪精度，从而阻碍了它们在下游机器人学习中的实用性。在这项工作中，我们引入了 World-VLA-Loop，这是一个用于联合完善世界模型和愿景-语言-行动（VLA）政策的闭环框架。我们提出了一种状态感知视频世界模型，通过联合预测未来的观察结果和奖励信号，充当高保真交互式模拟器。为了提高可靠性，我们引入了 SANS 数据集，该数据集包含接近成功的轨迹，以改善世界模型中的行动与结果的一致性。该框架完全在虚拟环境中实现了 VLA 策略的强化学习 (RL) 后训练闭环。至关重要的是，我们的方法促进了一个共同进化的循环：VLA 策略生成的失败部署会被迭代反馈以细化世界模型的精度，从而增强后续的 RL 优化。对模拟和现实世界任务的评估表明，我们的框架以最少的物理交互显着提高了 VLA 性能，在通用机器人的世界建模和策略学习之间建立了互惠互利的关系。项目页面：https://showlab.github.io/World-VLA-Loop/。

- **2026-02-05** **Driving with DINO: Vision Foundation Features as a Unified Bridge for Sim-to-Real Generation in Autonomous Driving** [2602.06159](http://arxiv.org/abs/2602.06159)
  > 在可控视频扩散出现的推动下，现有的自动驾驶视频生成 Sim2Real 方法通常依赖于显式中间表示来弥合域差距。然而，这些模式面临着根本的一致性-现实主义困境。低级信号（例如边缘、模糊图像）可确保精确控制，但会通过“烘焙”合成伪影而损害真实感，而高级先验信号（例如深度、语义、高清地图）有利于照片级真实感，但缺乏一致指导所需的结构细节。在这项工作中，我们提出了 Driving with DINO (DwD)，这是一种新颖的框架，利用视觉基础模块 (VFM) 功能作为模拟和现实世界之间的统一桥梁。我们首先确定这些特征编码一系列信息，从高级语义到细粒度结构。为了有效地利用这一点，我们采用主子空间投影来丢弃负责“纹理烘焙”的高频元素，同时引入随机通道尾部下降来减轻刚性降维中固有的结构损失，从而协调现实性与控制一致性。此外，为了充分利用 DINOv3 的高分辨率功能来提高控制精度，我们引入了一个可学习的空间对齐模块，该模块可将这些高分辨率特征适应扩散主干。最后，我们提出了一种因果时间聚合器，在集成逐帧 DINO 特征时，采用因果卷积来显式保留历史运动上下文，从而有效减轻运动模糊并保证时间稳定性。项目页面：https://albertchen98.github.io/DwD-project/

- **2026-02-05** **Context Forcing: Consistent Autoregressive Video Generation with Long Context** [2602.06028](http://arxiv.org/abs/2602.06028)
  > 最近的实时长视频生成方法通常采用流式调整策略，试图使用短上下文（无记忆）教师来训练长上下文学生。在这些框架中，学生执行长时间的展示，但接受教师的监督，仅限于 5 秒的短暂窗口。这种结构上的差异造成了严重的 \textbf{学生-教师不匹配}：教师无法访问长期历史记录，使其无法指导学生了解全局时间依赖性，从而有效地限制了学生的上下文长度。为了解决这个问题，我们提出了 \textbf{Context Forcing}，这是一种通过长上下文教师训练长上下文学生的新颖框架。通过确保教师了解完整的生成历史，我们消除了监督不匹配，从而能够对具有长期一致性的模型进行稳健的训练。为了使这种计算在极端持续时间（例如 2 分钟）下可行，我们引入了一个上下文管理系统，它将线性增长的上下文转换为 \textbf{Slow-Fast Memory} 架构，从而显着减少视觉冗余。大量结果表明，我们的方法可以实现超过 20 秒的有效上下文长度，比 LongLive 和 Infinite-RoPE 等最先进的方法长 2 到 10 倍。通过利用这种扩展的上下文，上下文强制在长时间内保持卓越的一致性，超越了各种长视频评估指标的最先进基线。

- **2026-02-05** **RISE-Video: Can Video Generators Decode Implicit World Rules?** [2602.05986](http://arxiv.org/abs/2602.05986)
  > 虽然生成视频模型已经实现了卓越的视觉保真度，但它们内化和推理隐含世界规则的能力仍然是一个关键但尚未充分探索的前沿领域。为了弥补这一差距，我们推出了 RISE-Video，这是一种面向文本图像到视频 (TI2V) 合成的开创性推理导向基准，它将评估焦点从表面美学转移到深层认知推理。 RISE-Video 包含 467 个经过精心人工注释的样本，涵盖八个严格的类别，为探索不同维度的模型智能提供了一个结构化的测试平台，从常识和空间动态到专业学科领域。我们的框架引入了一个多维评估协议，由四个指标组成：\textit{推理对齐}、\textit{时间一致性}、\textit{物理理性}和\textit{视觉质量}。为了进一步支持可扩展的评估，我们提出了一个利用大型多模态模型（LMM）来模拟以人为中心的评估的自动化管道。对 11 个最先进的 TI2V 模型进行的广泛实验揭示了在隐式约束下模拟复杂场景时普遍存在的缺陷，为未来世界模拟生成模型的发展提供了重要的见解。

- **2026-02-05** **LSA: Localized Semantic Alignment for Enhancing Temporal Consistency in Traffic Video Generation** [2602.05966](http://arxiv.org/abs/2602.05966)
  > 可控视频生成已成为自动驾驶的多功能工具，可实现交通场景的真实合成。然而，现有方法依赖于推理时的控制信号来引导生成模型实现动态对象的时间一致生成，限制了它们作为可扩展和可概括的数据引擎的实用性。在这项工作中，我们提出了局部语义对齐（LSA），这是一个简单而有效的框架，用于微调预训练的视频生成模型。 LSA 通过对齐真实视频和生成的视频剪辑之间的语义特征来增强时间一致性。具体来说，我们比较了现成特征提取模型的输出，即地面实况和围绕动态对象生成的视频剪辑，从而导致语义特征一致性损失。我们通过将此损失与标准扩散损失相结合来微调基本模型。该模型针对单个时期进行了微调，我们的新颖损失优于常见视频生成评估指标的基线。为了进一步测试生成视频的时间一致性，我们采用了对象检测任务中的两个附加指标，即 mAP 和 mIoU。 nuScenes 和 KITTI 数据集上的大量实验表明，我们的方法在增强视频生成的时间一致性方面的有效性，而无需在推理过程中使用外部控制信号和任何计算开销。

- **2026-02-05** **Pathwise Test-Time Correction for Autoregressive Long Video Generation** [2602.05871](http://arxiv.org/abs/2602.05871)
  > 蒸馏自回归扩散模型有利于实时短视频合成，但在长序列生成过程中会遭受严重的错误积累。虽然现有的测试时间优化（TTO）方法被证明对图像或短片有效，但我们发现，由于不稳定的奖励景观和蒸馏参数的超敏性，它们无法减轻扩展序列中的漂移。为了克服这些限制，我们引入了测试时校正（TTC），这是一种免训练的替代方案。具体来说，TTC 利用初始帧作为稳定的参考锚点来校准沿采样轨迹的中间随机状态。大量实验表明，我们的方法与各种精炼模型无缝集成，以可忽略不计的开销延长了生成长度，同时在 30 秒基准上与基于资源密集型训练的方法的质量相匹配。

- **2026-02-05** **Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation** [2602.05827](http://arxiv.org/abs/2602.05827)
  > 为什么视觉语言导航必须与详细而冗长的语言指令绑定？虽然这些细节简化了决策，但它们从根本上与现实世界中的导航目标相矛盾。理想情况下，代理应该拥有在未知环境中仅在简单和高级意图的指导下导航的自主权。实现这一雄心壮志带来了一项艰巨的挑战：超视距导航（BVN），智能体必须在没有密集和分步指导的情况下定位遥远的、看不见的目标。现有的基于大语言模型（LLM）的方法虽然擅长遵循密集的指令，但由于依赖短视域监督而经常出现短视行为。然而，简单地扩大监督范围会破坏法学硕士培训的稳定性。在这项工作中，我们发现视频生成模型本质上受益于长视野监督，以与语言指令保持一致，使它们独特地适合 BVN 任务。利用这一见解，我们建议首次将视频生成模型引入该领域。然而，生成长达数十秒的视频的延迟令人望而却步，使得实际部署变得不切实际。为了弥补这一差距，我们提出了 SparseVideoNav，通过生成的跨越 20 秒视野的稀疏未来来实现亚秒轨迹推断。与未优化的对应方案相比，这可实现 27 倍的显着加速。广泛的现实世界零样本实验表明，SparseVideoNav 在 BVN 任务上的成功率是最先进的 LLM 基线的 2.5 倍，并且标志着在具有挑战性的夜间场景中首次实现这种能力。

- **2026-02-05** **ShapeGaussian: High-Fidelity 4D Human Reconstruction in Monocular Videos via Vision Priors** [2602.05572](http://arxiv.org/abs/2602.05572)
  > 我们介绍了 ShapeGaussian，这是一种高保真、无模板的方法，用于根据休闲单眼视频进行 4D 人体重建。缺乏强大视觉先验的通用重建方法（例如 4DGS）很难在没有多视图线索的情况下捕获高变形的人体运动。虽然基于模板的方法（主要依赖 SMPL，例如 HUGS）可以产生逼真的结果，但它们很容易受到人体姿势估计错误的影响，通常会导致不切实际的伪影。相比之下，ShapeGaussian 有效地集成了无模板视觉先验，以实现高保真和鲁棒的场景重建。我们的方法遵循两步流程：首先，我们使用预训练模型学习粗略的可变形几何形状，该模型估计数据驱动的先验，为重建提供基础。然后，我们使用神经变形模型来细化该几何形状，以捕获细粒度的动态细节。通过利用 2D 视觉先验，我们减轻了基于模板的方法中错误姿态估计造成的伪影，并采用多个参考帧以无模板的方式解决 2D 关键点的不可见问题。大量实验表明，ShapeGaussian 在重建精度方面超越了基于模板的方法，在休闲单眼视频中的不同人体运动中实现了卓越的视觉质量和鲁棒性。

- **2026-02-05** **DisCa: Accelerating Video Diffusion Transformers with Distillation-Compatible Learnable Feature Caching** [2602.05449](http://arxiv.org/abs/2602.05449)
  > 虽然扩散模型在视频生成领域取得了巨大成功，但这种进步伴随着计算负担的迅速增加。在现有的加速方法中，特征缓存因其免训练的特性和可观的加速性能而受到欢迎，但随着进一步压缩，它不可避免地面临语义和细节的下降。另一种广泛采用的方法是训练感知的逐步蒸馏，尽管在图像生成方面取得了成功，但在视频生成方面也面临着几个步骤的严重退化。此外，当简单地将免训练特征缓存应用于逐步蒸馏模型时，由于采样步骤稀疏，质量损失变得更加严重。本文首次新颖地引入了一种与蒸馏兼容的可学习特征缓存机制。我们采用轻量级可学习神经预测器来代替传统的免训练启发式扩散模型，从而能够更准确地捕获高维特征演化过程。此外，我们探索了大规模视频模型上高度压缩蒸馏的挑战，并提出了一种保守的受限平均流方法来实现更稳定和无损的蒸馏。通过采取这些举措，我们将加速边界进一步推至 11.8 美元\次$，同时保持发电质量。大量的实验证明了我们方法的有效性。该代码位于补充材料中，并将公开发布。

- **2026-02-05** **FlashBlock: Attention Caching for Efficient Long-Context Block Diffusion** [2602.05305](http://arxiv.org/abs/2602.05305)
  > 生成长格式内容，例如一分钟长的视频和扩展文本，对于现代生成模型越来越重要。块扩散通过 KV 缓存和块级因果推理提高推理效率，并已广泛应用于扩散语言模型和视频生成中。然而，在长上下文环境中，块扩散仍然会因在不断增长的 KV 缓存上重复计算注意力而产生大量开销。我们发现了块扩散的一个未被充分探索的属性：块内注意力的跨步骤冗余。我们的分析表明，当前区块外部代币的注意力输出在扩散步骤中基本保持稳定，而区块内部注意力则变化很大。基于这一观察，我们提出了FlashBlock，一种缓存的块外部注意力机制，它重用稳定的注意力输出，在不修改扩散过程的情况下减少注意力计算和KV缓存访问。此外，FlashBlock 与稀疏注意力正交，可以作为补充的残差重用策略组合起来，从而在激进的稀疏化下显着提高模型的准确性。扩散语言模型和视频生成的实验表明，令牌吞吐量提高了 1.44 $\times$，注意力时间减少了 1.6$\times$ ，而对生成质量的影响可以忽略不计。项目页面：https://caesarhhh.github.io/FlashBlock/。

- **2026-02-05** **GT-SVJ: Generative-Transformer-Based Self-Supervised Video Judge For Efficient Video Reward Modeling** [2602.05202](http://arxiv.org/abs/2602.05202)
  > 将视频生成模型与人类偏好保持一致仍然具有挑战性：当前的方法依赖视觉语言模型（VLM）进行奖励建模，但这些模型难以捕捉微妙的时间动态。我们提出了一种根本不同的方法：重新利用视频生成模型作为奖励模型，视频生成模型本质上是为了建模时间结构而设计的。我们提出了基于生成变压器的自监督视频法官（\modelname），这是一种新颖的评估模型，可将最先进的视频生成模型转换为强大的时间感知奖励模型。我们的主要见解是，生成模型可以重新表述为基于能量的模型（EBM），将低能量分配给高质量视频，将高能量分配给降级视频，从而使它们能够在通过对比目标进行训练时以极高的精度区分视频质量。为了防止模型利用真实视频和生成视频之间的表面差异，我们通过受控的潜在空间扰动设计了具有挑战性的合成负视频：时间切片、特征交换和帧洗牌，模拟真实但微妙的视觉退化。这迫使模型学习有意义的时空特征，而不是琐碎的伪影。 \modelname 仅使用 30K 人工注释即可在 GenAI-Bench 和 MonteBench 上实现最先进的性能：比现有的基于 VLM 的方法少 6\times $到 $65\times$ 。

- **2026-02-04** **Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention** [2602.04789](http://arxiv.org/abs/2602.04789)
  > 先进的自回归 (AR) 视频生成模型提高了视觉保真度和交互性，但注意力的二次复杂度仍然是高效部署的主要瓶颈。虽然现有的稀疏注意力解决方案在双向模型上显示出了希望，但我们发现，将这些解决方案应用于 AR 模型会导致性能显着下降，原因有两个：单独考虑块生成以及对过去信息上下文的利用不足。受这些观察的启发，我们提出了 \textsc{Light Forcing}，即为 AR 视频生成模型量身定制的 \textit{first} 稀疏注意力解决方案。它采用了 \textit{Chunk-Aware Growth} 机制来定量估计每个块的贡献，这决定了它们的稀疏性分配。这种渐进式稀疏性增加策略使当前块能够在生成过程中继承早期块中的先验知识。此外，我们引入了 \textit{Hierarchical Sparse Attention} 以从粗到细的方式捕获信息丰富的历史和本地上下文。这种两级掩码选择策略（即帧级和块级）可以自适应地处理不同的注意力模式。大量实验表明，我们的方法在质量（例如 VBench 上的 84.5）和效率（例如 $1.2{\sim}1.3\times$ 端到端加速）方面优于现有的稀疏注意力。结合 FP8 量化和 LightVAE，\textsc{Light Forcing} 在 RTX~5090 GPU 上进一步实现了 $2.3\times$ 加速和 19.7\,FPS。代码将在 \href{https://github.com/hengtao-lv/LightForcing}{https://github.com/hengtao-lv/LightForcing} 发布。

- **2026-02-04** **Adaptive 1D Video Diffusion Autoencoder** [2602.04220](http://arxiv.org/abs/2602.04220)
  > 最近的视频生成模型很大程度上依赖于视频自动编码器，将像素空间视频压缩为潜在表示。然而，现有的视频自动编码器面临三个主要限制：(1) 固定速率压缩会浪费简单视频上的标记，(2) 不灵活的 CNN 架构会阻碍可变长度潜在模型的建模，(3) 确定性解码器很难从压缩的潜在模型中恢复适当的细节。为了解决这些问题，我们提出了一维扩散视频自动编码器（One-DVA），这是一种基于变压器的框架，用于自适应一维编码和基于扩散的解码。编码器采用基于查询的视觉变换器来提取时空特征并产生潜在表示，而可变长度丢失机制动态调整潜在长度。解码器是一个像素空间扩散变换器，它以潜在特征作为输入条件来重建视频。通过两阶段训练策略，One-DVA 在相同压缩比的重建指标上实现了与 3D-CNN VAE 相当的性能。更重要的是，它支持自适应压缩，从而可以获得更高的压缩比。为了更好地支持下游潜在生成，我们进一步规范生成建模的 One-DVA 潜在分布，并微调其解码器以减轻生成过程造成的伪影。

- **2026-02-04** **VTok: A Unified Video Tokenizer with Decoupled Spatial-Temporal Latents** [2602.04202](http://arxiv.org/abs/2602.04202)
  > 这项工作提出了 VTok，一个统一的视频标记化框架，可用于生成和理解任务。与通过简单的帧采样策略对视频进行标记的领先视觉语言系统不同，我们建议通过保留单个关键帧的空间特征，同时将每个后续帧编码为单个残差标记来解耦视频的空间和时间表示，从而实现紧凑而富有表现力的视频标记化。我们的实验表明，VTok 有效地降低了视频表示的复杂性，从帧计数和每帧令牌计数的乘积到它们的总和，而剩余令牌充分捕获相对于关键帧的视点和运动变化。广泛的评估证明了 VTok 的功效和效率：与使用朴素标记化的基线相比，它在一系列视频理解和文本到视频生成基准测试中实现了显着更高的性能，并且每个视频的标记序列更短（例如，我们的 TV-Align 基准测试的准确度提高了 3.4%，VBench 得分提高了 1.9%）。值得注意的是，由于其更一致的时间编码，VTok 在文本到视频生成过程中产生了更连贯的运动和更强的指导。我们希望 VTok 能够作为未来视频理解和生成研究的标准化视频标记化范式。

- **2026-02-03** **WIND: Weather Inverse Diffusion for Zero-Shot Atmospheric Modeling** [2602.03924](http://arxiv.org/abs/2602.03924)
  > 深度学习彻底改变了天气和气候建模，但目前的情况仍然支离破碎：高度专业化的模型通常针对不同的任务进行单独训练。为了统一这一格局，我们引入了 WIND，这是一个单一的预训练基础模型，能够替换大量任务中的专用基线。至关重要的是，与之前的大气基础模型相比，我们无需任何特定于任务的微调即可实现这一目标。为了学习稳健的、与任务无关的大气先验，我们使用自监督视频重建目标对 WIND 进行预训练，利用无条件视频扩散模型从噪声状态迭代重建大气动态。在推理时，我们将不同的特定领域问题严格定义为逆问题，并通过后验采样来解决它们。这种统一的方法使我们能够解决高度相关的天气和气候问题，包括概率预测、空间和时间降尺度、稀疏重建以及纯粹使用我们预先训练的模型执行守恒定律。我们进一步证明了该模型在全球变暖情景下生成物理上一致的极端天气事件反事实故事情节的能力。通过将生成视频建模与逆向问题解决相结合，WIND 为基于 AI 的大气建模提供了计算高效的范式转变。

- **2026-02-03** **Phaedra: Learning High-Fidelity Discrete Tokenization for the Physical Science** [2602.03915](http://arxiv.org/abs/2602.03915)
  > 令牌是离散表示，允许现代深度学习通过将高维数据转换为可以有效学习、生成和推广到新任务的序列来扩展。这些已成为图像和视频生成以及最近的物理模拟的基础。由于现有的标记器是为图像的真实视觉感知的明确要求而设计的，因此有必要询问这些方法是否最适合科学图像，因为科学图像表现出很大的动态范围，并且需要标记嵌入来保留物理和光谱属性。在这项工作中，我们研究了一系列图像标记器的准确性，这些指标旨在测量物理和光谱空间中偏微分方程属性的保真度。基于对这些难以捕捉精细细节和精确幅度的观察，我们提出了 Phaedra，其灵感来自于经典的形状增益量化和适当的正交分解。我们证明了 Phaedra 持续改进了一系列偏微分方程数据集的重建。此外，我们的结果显示了对三个日益复杂的任务的强大的分布外泛化能力，即不同条件下的已知偏微分方程、未知偏微分方程以及真实世界的地球观测和天气数据。

- **2026-02-03** **3D-Aware Implicit Motion Control for View-Adaptive Human Video Generation** [2602.03796](http://arxiv.org/abs/2602.03796)
  > 视频生成中现有的人体运动控制方法通常依赖 2D 姿势或显式 3D 参数模型（例如 SMPL）作为控制信号。然而，2D 将运动严格绑定到驾驶视点，从而妨碍了新颖的视图合成。显式 3D 模型虽然在结构上信息丰富，但存在固有的不准确性（例如，深度模糊性和不准确的动态），当用作强约束时，会覆盖大型视频生成器强大的内在 3D 感知能力。在这项工作中，我们从 3D 感知的角度重新审视运动控制，提倡一种隐式的、与视图无关的运动表示，它自然地与生成器的空间先验对齐，而不是依赖于外部重建的约束。我们引入了 3DiMo，它联合训练运动编码器和预先训练的视频生成器，将驱动帧提取为紧凑的、与视图无关的运动标记，并通过交叉注意力进行语义注入。为了培养 3D 意识，我们通过丰富视图的监督（即单视图、多视图和移动摄像机视频）进行训练，强制不同视点之间的运动一致性。此外，我们使用辅助几何监督，仅利用 SMPL 进行早期初始化，并退火至零，使模型能够从外部 3D 指导过渡到从数据和生成器先验中学习真正的 3D 空间运动理解。实验证实，3DiMo 通过灵活的文本驱动摄像头控制忠实地再现了驾驶动作，在运动保真度和视觉质量方面都显着超越了现有方法。

- **2026-02-03** **BridgeV2W: Bridging Video Generation Models to Embodied World Models via Embodiment Masks** [2602.03793](http://arxiv.org/abs/2602.03793)
  > 具身世界模型已成为机器人技术中一个有前途的范例，其中大多数利用大规模互联网视频或预训练的视频生成模型来丰富视觉和运动先验。然而，它们仍然面临关键挑战：坐标空间动作和像素空间视频之间的不对准、对相机视点的敏感性以及跨实施例的非统一架构。为此，我们提出了 BridgeV2W，它将坐标空间动作转换为根据 URDF 和相机参数渲染的像素对齐的实施例掩模。然后，这些掩模通过 ControlNet 风格的路径注入到预训练的视频生成模型中，该路径将动作控制信号与预测视频对齐，添加特定于视图的调节以适应相机视点，并在各个实施例中生成统一的世界模型架构。为了减轻对静态背景的过度拟合，BridgeV2W 进一步引入了基于流的运动损失，专注于学习动态和任务相关区域。在单臂 (DROID) 和双臂 (AgiBot-G1) 数据集上进行的实验涵盖了具有未见过的视点和场景的多样化且具有挑战性的条件，结果表明，与之前最先进的方法相比，BridgeV2W 提高了视频生成质量。我们进一步展示了 BridgeV2W 在下游现实世界任务中的潜力，包括政策评估和目标条件规划。更多结果可以在我们的项目网站 https://BridgeV2W.github.io 上找到。

- **2026-02-03** **How do people watch AI-generated videos of physical scenes?** [2602.03374](http://arxiv.org/abs/2602.03374)
  > 人工智能生成的真实视频在媒体平台上日益盛行，事实与虚构之间的界限日益模糊，削弱了公众的信任。了解人们如何观看人工智能生成的视频，为改进人工智能检测和指导视频生成的进步提供了以人为本的视角。然而，现有研究尚未调查人类对人工智能生成的物理场景视频的注视行为。在这里，我们收集并分析了 40 名参与者在视频理解和 AI 检测任务中的眼球运动，这些任务涉及现实世界和 AI 生成的视频的混合。我们发现，鉴于人工智能生成的视频具有高度真实性，注视行为较少受视频的实际真实性驱动，而更多地受观看者对其真实性的感知所驱动。我们的结果表明，仅仅意识到潜在的人工智能生成可能会将媒体消费从被动观看转变为主动寻找异常现象。

- **2026-02-03** **InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation** [2602.03242](http://arxiv.org/abs/2602.03242)
  > 自动驾驶依赖于经过高质量、大规模多视图驾驶视频训练的稳健模型。虽然世界模型为生成逼真的驾驶视频提供了一种经济高效的解决方案，但它们很难保持实例级的时间一致性和空间几何保真度。为了应对这些挑战，我们提出了 InstaDrive，这是一种新颖的框架，它通过两个关键的进步来增强驾驶视频的真实感：(1) Instance Flow Guider，它跨帧提取和传播实例特征以强制时间一致性，随着时间的推移保留实例身份。 (2) 空间几何对齐器，它改进了空间推理，确保精确的实例定位，并显式地建模遮挡层次结构。通过整合这些实例感知机制，InstaDrive 实现了最先进的视频生成质量，并增强了 nuScenes 数据集上的下游自动驾驶任务。此外，我们利用 CARLA 的自动驾驶仪以程序和随机方式模拟跨不同地图和区域的罕见但安全关键的驾驶场景，从而为自动驾驶系统提供严格的安全评估。我们的项目页面是https://shanpoyang654.github.io/InstaDrive/page.html。

- **2026-02-03** **ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask** [2602.03213](http://arxiv.org/abs/2602.03213)
  > 自动驾驶依赖于在大规模、高质量多视图驾驶视频上训练的强大模型。尽管世界模型为生成真实驾驶数据提供了一种经济高效的解决方案，但它们经常遭受身份漂移的困扰，即由于缺乏实例级时间约束，同一对象在不同帧之间改变其外观或类别。我们引入了 ConsisDrive，这是一种身份保护的驾驶世界模型，旨在在实例级别强制执行时间一致性。我们的框架包含两个关键组成部分：（1）实例掩码注意力，它在注意力块中应用实例身份掩码和轨迹掩码，以确保视觉标记仅与跨空间和时间维度的相应实例特征交互，从而保持对象身份一致性； (2) 实例掩蔽损失，通过概率实例掩蔽自适应地强调前景区域，减少背景噪声，同时保持整体场景保真度。通过集成这些机制，ConsisDrive 实现了最先进的驾驶视频生成质量，并在 nuScenes 数据集上展示了下游自动驾驶任务的显着改进。我们的项目页面是https://shanpoyang654.github.io/ConsisDrive/page.html。

- **2026-02-03** **Quant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantization** [2602.02958](http://arxiv.org/abs/2602.02958)
  > 尽管自回归视频传播取得了快速进展，但一个新兴的系统算法瓶颈限制了可部署性和生成能力：KV 缓存。在自回归视频生成模型中，KV 缓存随着生成历史而增长，并迅速占据 GPU 内存，通常超过 30 GB，从而阻碍了在广泛可用的硬件上的部署。更关键的是，有限的 KV 缓存预算限制了有效的工作内存，直接降低了身份、布局和运动的长期一致性。为了应对这一挑战，我们提出了 Quant VideoGen (QVG)，这是一种用于自回归视频扩散模型的免训练 KV 缓存量化框架。 QVG 通过语义感知平滑来利用视频时空冗余，产生低幅度、量化友好的残差。它还引入了渐进残差量化，这是一种从粗到细的多级方案，可减少量化误差，同时实现平滑的质量内存权衡。在 LongCat Video、HY WorldPlay 和 Self Forcing 基准测试中，QVG 在质量和内存效率之间建立了新的帕累托前沿，将 KV 缓存内存减少多达 7.0 倍，端到端延迟开销低于 4%，同时在生成质量方面始终优于现有基准。


<p align=right>(<a href=#updated-on-20260209>back to top</a>)</p>

## 3D

- **2026-02-06** **Reciprocal Latent Fields for Precomputed Sound Propagation** [2602.06937](http://arxiv.org/abs/2602.06937)
  > 真实的声音传播对于沉浸在虚拟场景中至关重要，但物理上精确的基于波的模拟在计算上仍然无法满足实时应用的要求。波编码方法通过预先计算给定场景的脉冲响应并将其压缩为一组标量声学参数来解决这一限制，这些参数在具有许多源-接收器对的大型环境中可能达到难以管理的大小。我们引入了倒数潜在场（RLF），这是一种用于编码和预测这些声学参数的内存高效框架。 RLF 框架采用可训练潜在嵌入的体积网格，通过对称函数进行解码，确保声学互易性。我们研究了各种解码器，并表明利用黎曼度量学习可以更好地再现复杂场景中的声学现象。实验验证表明，RLF 保持复制质量，同时将内存占用量减少几个数量级。此外，类似 MUSHRA 的主观听力测试表明，通过 RLF 渲染的声音在感知上与地面真实模拟无法区分。

- **2026-02-06** **Continuous-time reinforcement learning: ellipticity enables model-free value function approximation** [2602.06930](http://arxiv.org/abs/2602.06930)
  > 我们研究离策略强化学习，通过离散时间观察和动作来控制连续时间马尔可夫扩散过程。我们考虑具有函数逼近的无模型算法，直接从数据中学习价值和优势函数，而无需对动力学进行不切实际的结构假设。   利用扩散的椭圆性，我们为贝尔曼算子建立了一类新的希尔伯特空间正定性和有界性性质。基于这些特性，我们提出了 Sobolev-prox 拟合 $q$ 学习算法，该算法通过迭代求解最小二乘回归问题来学习价值函数和优势函数。我们推导了估计误差的预言不等式，该误差由以下因素控制：(i) 函数类的最佳近似误差，(ii) 其局部复杂性，(iii) 指数衰减优化误差，以及 (iv) 数值离散误差。这些结果将椭圆度确定为一个关键的结构属性，它使马尔可夫扩散的函数逼近强化学习并不比监督学习更困难。

- **2026-02-06** **A Cycle-Consistent Graph Surrogate for Full-Cycle Left Ventricular Myocardial Biomechanics** [2602.06884](http://arxiv.org/abs/2602.06884)
  > 基于图像的针对患者的左心室 (LV) 力学模拟对于了解心脏功能和支持临床干预计划很有价值，但传统的有限元分析 (FEA) 计算量较大。当前基于图的替代物不具有全周期预测能力，并且基于物理的神经网络通常难以收敛于复杂的心脏几何形状。我们提出了 CardioGraphFENet (CGFENet)，这是一种基于图的统一替代方法，用于快速全周期估计左心室心肌生物力学，并由大型 FEA 模拟数据集监督。所提出的模型集成了（i）一个全局-局部图编码器，用于捕获具有弱形式启发的全局耦合的网格特征，（ii）一个基于目标体积时间信号的门控循环单元时间编码器，以模拟循环相干动力学，以及（iii）一个用于在单个框架内加载和逆卸载的循环一致双向公式。这些策略可实现传统 FEA 基本事实的高保真度，并生成生理上合理的压力体积环，与集总参数模型结合使用时与 FEA 结果相匹配。特别是，循环一致性策略可以显着减少 FEA 监督，而精度损失却很小。

- **2026-02-06** **$hp$ -a posteriori error estimates for hybrid high-order methods applied to biharmonic problems** [2602.06872](http://arxiv.org/abs/2602.06872)
  > 我们推导出基于残差的 $hp$ - 单纯网格上的混合高阶 (HHO) 方法的后验误差估计器，应用于二维和三维多拓扑 Lipschitz 域上提出的双调和问题。后验误差估计器取决于将误差分解为合格和不合格分量。为了限制不合格误差，我们使用通过 Alfeld 分裂构造的单位 $C^1$ 分区，并结合顶点星上的局部亥姆霍兹分解。对于一致性误差，我们设计了两个基于残差的估计器，每个估计器都与特定的插值运算符相关联。在第一种设置中，一致性误差的上限仅涉及稳定项和数据振荡。在第二个设置中，边界还包含体残差、法线通量跳跃和切向跳跃。数值实验证实了理论结果并证明了所提出的估计器的效率。

- **2026-02-06** **DynFOA: Generating First-Order Ambisonics with Conditional Diffusion for Dynamic and Acoustically Complex 360-Degree Videos** [2602.06846](http://arxiv.org/abs/2602.06846)
  > 空间音频对于创建引人入胜的沉浸式 360 度视频体验至关重要。然而，从复杂声学场景中的 360 度视频生成逼真的空间音频（例如一阶立体混响 (FOA)）仍然具有挑战性。现有方法常常忽视 360 度场景的动态性质和声学复杂性，无法充分考虑动态声源，并且忽略受场景几何形状和材质影响的复杂环境效应，例如遮挡、反射和混响。我们提出了 DynFOA，一个基于动态声学感知和条件扩散的框架，用于从 360 度视频生成高保真 FOA。 DynFOA 首先通过视频编码器执行视觉处理，视频编码器检测并定位多个动态声源，估计其深度和语义，并使用 3D 高斯泼溅重建场景几何形状和材质。这种重建技术根据重建的 3D 场景的几何形状和材质以及听众的视点准确地模拟遮挡、反射和混响。然后，音频编码器捕获空间运动和时间 4D 声源轨迹，以微调基于扩散的 FOA 生成器。经过微调的 FOA 发生器可实时调整空间线索，确保在听者头部旋转和复杂环境变化期间保持一致的方向保真度。广泛的评估表明，DynFOA 在空间精度、声学保真度和分布匹配等指标上始终优于现有方法，同时还改善了用户体验。因此，DynFOA 提供了一种强大且可扩展的方法来为 VR 和沉浸式媒体应用渲染逼真的动态空间音频。

- **2026-02-06** **GaussianPOP: Principled Simplification Framework for Compact 3D Gaussian Splatting via Error Quantification** [2602.06830](http://arxiv.org/abs/2602.06830)
  > 现有的 3D 高斯分布简化方法通常使用重要性分数（例如混合权重或灵敏度）来识别冗余高斯。然而，这些分数并不是由视觉误差指标驱动的，通常会导致紧凑性和渲染保真度之间的权衡不理想。我们提出了 GaussianPOP，一个基于分析高斯误差量化的原则简化框架。我们的主要贡献是一种新颖的误差标准，直接从 3DGS 渲染方程导出，它精确测量每个高斯对渲染图像的贡献。通过引入高效的算法，我们的框架可以在单次前向传递中实现实际的误差计算。该框架既准确又灵活，支持训练中剪枝以及通过迭代误差重新量化来进行训练后简化，以提高稳定性。实验结果表明，我们的方法在这两种应用场景中始终优于现有的最先进的修剪方法，在模型紧凑性和高渲染质量之间实现了卓越的权衡。

- **2026-02-06** **On the Design of an Optimal Multi-Tone Jammer Against the Wiener Interpolation Filter** [2602.06816](http://arxiv.org/abs/2602.06816)
  > 在民用和军用通信领域，抗干扰技术对于确保存在恶意干扰时的信息完整性至关重要。传统的时域方法依赖于计算维纳插值滤波器来估计和抑制接收样本中的干扰波形。人们普遍认为，这种方法对于保护宽带系统免受窄带干扰是有效的。在这项工作中，这种范式通过 $K$ 音调干扰波形的设计受到质疑，假设使用 $L$ 抽头维纳插值滤波器，该波形本质上很难估计。该设计依赖于最大化与干扰波形估计相关的分析贝叶斯均方误差的优化程序。此外，还提供了分析证明，表明由$L/2+1$ 音调组成的多音干扰波形足以使基于维纳滤波器的抗干扰模块完全失效。分析结果通过蒙特卡罗模拟进行验证，假设接收信号的相关函数具有完善的知识和实际估计。

- **2026-02-06** **Real time, cross platform visualizations with zero dependencies for the N-body package REBOUND** [2602.06735](http://arxiv.org/abs/2602.06735)
  > 可视化已成为科学过程中不可或缺的一部分。存在一个充满活力的可视化工具生态系统，可以满足各种不同的需求。数值模拟的实时可视化为科学家提供有关模拟状态的即时反馈，并且也可以成为有价值的教育和推广工具。开发支持不同操作系统、CPU/GPU 架构和编程语言的可视化工具可能是一项挑战。使用一个或多个图形或 UI 库作为抽象层并隐藏底层复杂性是很常见的。尽管外部库极大地简化了初始编程工作，但我们认为依赖它们会带来新的依赖关系和问题，例如新开发人员和用户的进入门槛更高，以及长期支持的不确定性。在本文中，我们提出了一种新的实时可视化方法，我们已为 N 体包 REBOUND 实现了该方法。我们建议使用网络浏览器来处理 GPU 加速渲染。这使我们能够在所有主要操作系统上提供 3D 交互式可视化。我们的新方法的独特之处在于我们无需任何外部库即可实现这一目标。我们利用 WebAssembly 来重用现有的 OpenGL 可视化代码。使用 HTTP 通信和自定义内置 Web 服务器，我们能够提供本地和远程实时可视化。除了基于浏览器的实时可视化之外，我们的方法还提供其他附加操作模式，包括完全在浏览器中运行的模拟、jupyter 笔记本中的可视化以及使用 OpenGL 的传统独立可视化。我们专注于 REBOUND 中的实现，但所讨论的概念和想法可以应用于需要科学和非科学实时可视化的许多其他领域。

- **2026-02-06** **Accelerating TTL noise post-processing via combined coefficients and alternative TDI configuration** [2602.06731](http://arxiv.org/abs/2602.06731)
  > 航天器和测试质量体的角度抖动引起的倾斜长度（TTL）噪声会影响LISA、太极和天琴等天基引力波探测器的灵敏度。这种角度抖动可以使用差分波前传感技术进行测量，从而能够建模并从数据中减去 TTL 噪声。然而，由于探测器星座的多个自由度，线性 TTL 模型至少需要 24 个参数，而保真度更高的二次模型涉及多达 60 个系数，导致参数估计的计算成本很高。为了加速参数确定，我们提出了通过原始角耦合系数的线性变换获得的修改参数集，这有效地减少了TTL噪声分量之间的相关性。此外，我们使用替代的第二代时滞干涉测量配置 PD4L，而不是基准迈克尔逊配置来执行参数拟合。这两项改进将线性模型的拟合过程的收敛速度提高了约 10 倍，将二次模型的收敛速度提高了约 18 倍。因此，所提出的方法可以显着提高天基引力波探测器中 TTL 噪声校准的效率。

- **2026-02-06** **Git for Sketches: An Intelligent Tracking System for Capturing Design Evolution** [2602.06047](http://arxiv.org/abs/2602.06047)
  > 在产品概念化过程中，捕捉非线性历史和认知意图至关重要。传统的草图工具常常会失去这种背景。我们推出 DIMES（设计理念管理和演化捕获系统），这是一个基于 Web 的环境，具有 sGIT (SketchGit)、自定义可视化版本控制架构和生成式 AI。 sGIT 包括 AEGIS，这是一个使用混合深度学习和机器学习模型对六种笔画类型进行分类的模块。该系统将 Git 原语映射到设计操作，从而实现隐式分支和多模式提交（笔画数据 + 语音意图）。在一项比较研究中，使用 DIMES 的专家证明概念探索的广度增加了 160%。生成式人工智能模块生成叙述性摘要，增强知识转移；与手动摘要相比，新手实现了更高的复制保真度（基于神经透明度的余弦相似度：0.97 与 0.73）。 AI 生成的效果图也获得了更高的用户接受度（购买可能性：4.2 vs 3.1）。这项工作表明，智能版本控制将创造性行动和认知文档联系起来，为设计教育提供了新的范式。

- **2026-02-05** **VisRefiner: Learning from Visual Differences for Screenshot-to-Code Generation** [2602.05998](http://arxiv.org/abs/2602.05998)
  > 屏幕截图到代码生成旨在将用户界面屏幕截图转换为忠实再现目标布局和风格的可执行前端代码。现有的多模式大语言模型直接从屏幕截图执行此映射，但在不观察生成代码的视觉结果的情况下进行训练。相比之下，人类开发人员迭代地渲染他们的实现，将其与设计进行比较，并了解视觉差异与代码更改的关系。受此过程的启发，我们提出了 VisRefiner，这是一个训练框架，使模型能够从渲染预测和参考设计之间的视觉差异中学习。我们构建了差异对齐监督，将视觉差异与相应的代码编辑相关联，从而使模型能够理解实现更改如何引起外观变化。在此基础上，我们引入了用于自我改进的强化学习阶段，其中模型通过观察渲染的输出和目标设计、识别它们的视觉差异并相应地更新代码来改进其生成的代码。实验表明，VisRefiner 大幅提高了单步生成质量和布局保真度，同时赋予模型强大的自求精能力。这些结果证明了从视觉差异中学习对于推进屏幕截图到代码生成的有效性。

- **2026-02-05** **Tracing AGN Feedback Power with Cool/Warm Outflow Densities: Predictions and Observational Implications** [2602.05954](http://arxiv.org/abs/2602.05954)
  > 人们认为，活动星系核（AGN）中吸积盘或尘埃环面大小的风会驱动能量守恒的流出，从而塑造星系的演化。这种流出的关键特征，即热（ $T \gtrsim 10^9 \，\rm K$）、冲击风分量的存在，很难直接检测到。 AGN 流出的观测通常探测一个单独的流出阶段：冷/热气体，$T \lesssim 10^5 \, \rm K$。在这里，我们表明冷流出气体的密度与活动星系核的光度成正比，作为对难以捉摸的热风的间接诊断。我们使用移动网格代码 AREPO 进行流体动力学模拟，以速度 $\approx 10^4 \, \rm km \, s^{-1}$ 的小规模 AGN 风与包含理想的块状星际介质 (ISM) 的星系盘之间的相互作用为目标。通过针对快速冷却、快速移动的气体的新细化方案，我们的模拟在冷却、流出阶段达到了 $\lesssim 0.1 \, \rm pc$ 的分辨率。我们从模拟中产生的活动星系核驱动的流出中提取了一组冷云，发现它们的密度随着活动星系核风力和活动星系核光度的增加而系统性地增加。此外，这些云团的质量分布和内部特性似乎对ISM的初始特性不敏感，并且主要由辐射、湍流混合层的动力学形成。随着动能风力和活动星系核光度的增加，冷流出密度的增加对于流出速率的观测估计及其与活动星系核光度的比例关系具有深远的影响。根据可用的流出量和密度示踪剂，观测得出的流出率可能会被高估几个数量级。

- **2026-02-05** **AgenticTagger: Structured Item Representation for Recommendation with LLM Agents** [2602.05945](http://arxiv.org/abs/2602.05945)
  > 高质量的表征是有效推荐的核心要求。在这项工作中，我们研究了基于 LLM 的描述符生成问题，即对下游应用程序限制最小的类似关键词的自然语言项目表示生成框架。我们提出了 AgenticTagger，这是一个查询 LLM 以使用文本描述符序列表示项目的框架。然而，开放式生成对生成空间几乎没有控制，导致基数高、性能低的描述符，这给下游建模带来了挑战。为此，AgenticTagger 具有两个核心阶段：(1) 词汇构建阶段，其中识别一组分层、低基数和高质量的描述符；(2) 词汇分配阶段，法学硕士将词汇内描述符分配给项目。为了有效且高效地在感兴趣的项目语料库中基础词汇，我们设计了一种多代理反射机制，其中架构师法学硕士在来自注释器法学硕士的并行反馈的指导下迭代地细化词汇，该注释器法学硕士根据项目数据验证词汇。对公共和私人数据的实验表明，AgenticTagger 在不同的推荐场景中带来了一致的改进，包括生成式和基于术语的检索、排名以及面向可控性、基于评论的推荐。

- **2026-02-05** **Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation** [2602.05827](http://arxiv.org/abs/2602.05827)
  > 为什么视觉语言导航必须与详细而冗长的语言指令绑定？虽然这些细节简化了决策，但它们从根本上与现实世界中的导航目标相矛盾。理想情况下，代理应该拥有在未知环境中仅在简单和高级意图的指导下导航的自主权。实现这一雄心壮志带来了一项艰巨的挑战：超视距导航（BVN），智能体必须在没有密集和分步指导的情况下定位遥远的、看不见的目标。现有的基于大语言模型（LLM）的方法虽然擅长遵循密集的指令，但由于依赖短视域监督而经常出现短视行为。然而，简单地扩大监督范围会破坏法学硕士培训的稳定性。在这项工作中，我们发现视频生成模型本质上受益于长视野监督，以与语言指令保持一致，使它们独特地适合 BVN 任务。利用这一见解，我们建议首次将视频生成模型引入该领域。然而，生成长达数十秒的视频的延迟令人望而却步，使得实际部署变得不切实际。为了弥补这一差距，我们提出了 SparseVideoNav，通过生成的跨越 20 秒视野的稀疏未来来实现亚秒轨迹推断。与未优化的对应方案相比，这可实现 27 倍的显着加速。广泛的现实世界零样本实验表明，SparseVideoNav 在 BVN 任务上的成功率是最先进的 LLM 基线的 2.5 倍，并且标志着在具有挑战性的夜间场景中首次实现这种能力。

- **2026-02-05** **NVS-HO: A Benchmark for Novel View Synthesis of Handheld Objects** [2602.05822](http://arxiv.org/abs/2602.05822)
  > 我们提出 NVS-HO，这是第一个基准测试，旨在仅使用 RGB 输入在现实环境中对手持物体进行新颖的视图合成。每个对象都记录在两个互补的 RGB 序列中：(1) 手持序列，其中对象在静态摄像机前操纵；(2) 板序列，其中对象固定在 ChArUco 板上，通过标记检测提供准确的摄像机姿势。 NVS-HO 的目标是学习一个 NVS 模型，该模型从 (1) 中捕获对象的完整外观，而 (2) 提供用于评估的地面实况图像。为了建立基线，我们将经典的 SfM 管道和最先进的预训练前馈神经网络 (VGGT) 视为姿态估计器，并基于 NeRF 和高斯 Splatting 训练 NVS 模型。我们的实验揭示了当前方法在不受限制的手持条件下的显着性能差距，凸显了对更强大方法的需求。因此，NVS-HO 提供了一个具有挑战性的现实世界基准，以推动手持物体基于 RGB 的新颖视图合成的进步。

- **2026-02-05** **A penalized φ-FEM scheme for the Poisson Dirichlet problem** [2602.05698](http://arxiv.org/abs/2602.05698)
  > 在这项工作中，我们分析了具有狄利克雷边界条件的泊松方程的 φ-FEM 格式的惩罚变体。 φ-FEM 是最近引入的基于几何水平集描述的未拟合有限元方法，它避免了对边界拟合网格的需要。与原始的 φ-FEM 公式不同，这里提出的方法通过惩罚项强制执行边界条件。这种方法的优点是，仅在变分公式中与边界相邻的单元上需要水平集函数。该方案使用幽灵惩罚技术来稳定。我们得出先验误差估计，显示在适当的规律性假设下，H1 半范数的最佳收敛性和 L2 范数的准最佳收敛性。数值实验旨在验证理论结果，并将所提出的方法与原始 φ-FEM 和标准拟合有限元方法进行比较。

- **2026-02-05** **Smoothed aggregation algebraic multigrid for problems with heterogeneous and anisotropic materials** [2602.05686](http://arxiv.org/abs/2602.05686)
  > 本文介绍了一种用于平滑聚合代数多重网格方法的材料感知连接强度测量，旨在提高具有异质和各向异性材料属性的标量偏微分方程的鲁棒性。经典的连接强度测量通常仅依赖于矩阵条目或几何距离，这通常无法捕获跨材料界面的弱耦合或与各向异性方向对齐，最终导致收敛不良。所提出的方法直接将材料张量信息合并到粗化过程中，从而能够可靠地检测弱连接并确保粗略级别保留潜在问题的真实结构。因此，可以正确地表示平滑误差分量，并一致地处理急剧的系数跳跃或方向各向异性。广泛的学术测试和实际应用（包括热激活电池和太阳能电池）表明，所提出的方法在材料对比、各向异性和网格变化方面保持了鲁棒性。代数多重网格方法的可扩展性和并行性能突出了其对大规模、高性能计算环境的适用性。

- **2026-02-05** **cfdmfFTFoam: A front-tracking solver for multiphase flows on general unstructured grids in OpenFOAM** [2602.05627](http://arxiv.org/abs/2602.05627)
  > 考虑到精度和计算成本之间的权衡，前沿跟踪方法 (FTM) 是多相流数值求解的一种有前途的方法。由于编码和算法的复杂性，现有的 FTM 开源开放访问软件很少，并且仅限于结构化笛卡尔网格或无连接的前网格混合 FTM。为了在一般非结构化网格上提供纯 FTM 求解器，Ftc3D FTM 代码已集成到 OpenFOAM CFD 软件中，通过实施必要的前端网格到欧拉网格通信和前端节点平流算法，适用于非结构化网格以及串行和并行运行。新的FTM软件包名为cfdmfFTFOam，进一步配备了多种FTM子算法，包括前体积校正、重新网格化、表面张力计算、指示函数构建等。新求解器的评估和验证是针对多个标准多相流基准进行的。预计cfdmfFTFOam将有助于FTM领域未来的研究和算法改进。

- **2026-02-05** **Unified Sensor Simulation for Autonomous Driving** [2602.05617](http://arxiv.org/abs/2602.05617)
  > 在这项工作中，我们介绍了 \textbf{XSIM}，一种用于自动驾驶的传感器模拟框架。 XSIM 通过专为自动驾驶应用定制的通用卷帘快门模型扩展了 3DGUT splatting。我们的框架为外观和几何传感器建模提供了统一且灵活的公式，从而能够在动态环境中渲染复杂的传感器变形。我们将球形相机（例如 LiDAR）确定为现有 3DGUT 泼溅的关键边缘情况，因为方位角边界处的循环投影和时间不连续性导致不正确的粒子投影。为了解决这个问题，我们提出了一种相位建模机制，该机制明确地考虑了无迹变换在方位角边界投影的高斯的时间和形状不连续性。此外，我们引入了扩展的 3D 高斯表示，它结合了两个不同的不透明度参数来解决几何和颜色分布之间的不匹配问题。因此，我们的框架提供了增强的场景表示，具有改进的几何一致性和逼真的外观。我们在多个自动驾驶数据集上广泛评估我们的框架，包括 Waymo Open Dataset、Argoverse 2 和 PandaSet。我们的框架始终优于近期的强大基线，并在所有数据集上实现了最先进的性能。源代码可在 \href{https://github.com/whesense/XSIM}{https://github.com/whesense/XSIM} 公开获取。

- **2026-02-05** **A term-by-term variational multiscale method with dynamic subscales for incompressible turbulent aerodynamics** [2602.05563](http://arxiv.org/abs/2602.05563)
  > 变分多尺度 (VMS) 方法提供了一个强大的框架，用于处理未解析的流动尺度，而无需求助于特定问题的湍流模型。在这里，我们提出并评估了一种动态的逐项 VMS 稳定公式，用于模拟从层流到湍流状态的不可压缩流动。该方法嵌入增量压力校正分步框架中，并采用最小的稳定项集，产生统一的离散化，(i) 允许等阶速度-压力插值，(ii) 在复杂的三维设置中提供对对流主导动力学的鲁棒控制。正交投影是一个关键要素，可确保非残差、逐项结构通过适合湍流模拟的动态子尺度引起耗散。该方法在大规模外部空气动力学配置上进行了验证，包括 Re $= 7.68\times 10^{5}$ 的多个倾斜角度的艾哈迈德主体，使用范围从 3 到 4000 万个元素的非结构化四面体网格。在 $U_\infty=56~\mathrm{m/s}$ (201.6~km/h) 的实际 Formula~1 配置上进一步证明了适用性，对应于 Re $ \approx 10^{6}$ 。结果表明，所提出的稳定压力分离公式在规模上保持稳健，并捕获了关键的分离流特征和连贯尾流组织。逐点速度和压力谱提供了后验一致性指标，表现出与解析频带中的惯性子范围参考斜率兼容的有限频率范围，并支持统一稳定有限元框架内解析不足状态下的耗散控制。

- **2026-02-04** **VISTA-Bench: Do Vision-Language Models Really Understand Visualized Text as Well as Pure Text?** [2602.04802](http://arxiv.org/abs/2602.04802)
  > 视觉语言模型（VLM）在跨文本和视觉输入的跨模式理解方面取得了令人印象深刻的性能，但现有的基准主要集中在纯文本查询上。在现实场景中，语言也经常以嵌入图像中的可视化文本的形式出现，这就提出了一个问题：当前的 VLM 是否能够同等地处理此类输入请求。我们介绍 VISTA-Bench，这是一个从多模态感知、推理到单模态理解领域的系统基准。它通过在受控渲染条件下对比纯文本和可视化文本问题来评估可视化文本理解。对 20 多个代表性 VLM 的广泛评估揭示了明显的模态差距：当等效语义内容呈现为可视化文本时，在纯文本查询上表现良好的模型通常会大幅退化。这种差距因感知难度的增加而进一步放大，凸显了尽管语义不变但对渲染变化的敏感性。总体而言，VISTA-Bench 提供了一个原则性的评估框架来诊断这一限制，并指导在标记化文本和像素上实现更统一的语言表示。源数据集可在 https://github.com/QingAnLiu/VISTA-Bench 获取。

- **2026-02-04** **Evolutionary Mapping of Neural Networks to Spatial Accelerators** [2602.04717](http://arxiv.org/abs/2602.04717)
  > 空间加速器由计算内存集成单元阵列组成，为部署低延迟和低能耗的推理工作负载提供了一个有吸引力的平台。然而，充分利用其架构优势通常需要仔细、专家驱动的计算图到分布式处理元素的映射。在这项工作中，我们通过将映射挑战视为黑盒优化问题来自动化此过程。我们推出了第一个用于神经形态加速器的进化型硬件在环映射框架，使没有深厚硬件知识的用户能够更有效地部署工作负载。我们在 Intel Loihi 2 上评估我们的方法，这是一款具有代表性的空间加速器，在 2D 网格中每个芯片有 152 个内核。与两个稀疏多层感知器网络上的默认启发式方法相比，我们的方法可将总延迟降低高达 35%。此外，我们展示了我们的多芯片系统方法的可扩展性，并观察到能源效率高达 40% 的提高，而无需明确优化。

- **2026-02-04** **AGILE: Hand-Object Interaction Reconstruction from Video via Agentic Generation** [2602.04672](http://arxiv.org/abs/2602.04672)
  > 从单眼视频中重建动态手部物体交互对于灵巧的操作数据收集以及为机器人和 VR 创建逼真的数字孪生至关重要。然而，当前的方法面临两个令人望而却步的障碍：（1）对神经渲染的依赖通常会在严重遮挡下产生支离破碎的、无法模拟的几何形状，（2）对脆弱的运动结构（SfM）初始化的依赖会导致野外镜头频繁失败。为了克服这些限制，我们引入了 AGILE，这是一个强大的框架，它将交互学习的范式从重构转变为代理生成。首先，我们采用代理管道，其中视觉语言模型 (VLM) 引导生成模型合成具有高保真纹理的完整、无懈可击的对象网格，且与视频遮挡无关。其次，我们完全绕过脆弱的 SfM，提出了一种强大的锚定和跟踪策略。我们使用基础模型在单个交互开始帧初始化对象姿势，并利用我们生成的资产和视频观察之间的强烈视觉相似性来临时传播它。最后，接触感知优化集成了语义、几何和交互稳定性约束，以增强物理合理性。对 HO3D、DexYCB 和野外​​视频进行的大量实验表明，AGILE 在全局几何精度方面优于基线，同时在现有技术经常崩溃的挑战性序列上表现出卓越的鲁棒性。通过优先考虑物理有效性，我们的方法可以生成模拟就绪的资产，并通过机器人应用程序的真实到模拟重定向进行验证。

- **2026-02-04** **Domain decomposition methods and preconditioning strategies using generalized locally Toepltiz tools: proposals, analysis, and numerical validation** [2602.04603](http://arxiv.org/abs/2602.04603)
  > 在当前的工作中，我们通过研究这些经典 Schwarz 预处理矩阵序列的谱特性，在域分解技术的框架内提出加法和乘法 Schwarz 方法的谱分析，重点是它们的收敛行为和传输算子的影响。特别是，在概括介绍了各种选项之后，我们重点关注 Schwarz 方法的受限变体，旨在提高并行效率，同时保留其收敛特征。为了严格描述和分析收敛行为，我们采用广义局部托普利茨（GLT）序列理论，该理论为研究 Schwarz 迭代产生的离散算子的渐近谱分布提供了一个强大的框架。通过将每个算子序列与适当的 GLT 符号相关联，我们为加法和乘法 Schwarz 方法导出收敛因子的 GLT 符号的显式表达式。基于 GLT 的谱方法提供了对谱如何随着网格细化和重叠大小（在代数情况下）而演变的统一和系统的理解。我们的分析不仅加深了对经典 Schwarz 方法的理论理解，而且为使用符号谱工具检查未来受限或混合 Schwarz 变体奠定了基础。这些结果使得能够预测 GLT 序列的块 Jacobi/Gauss-Seidel 和块加法/乘法 Schwarz 预处理器的显着效率，并通过大量数值实验进一步说明。

- **2026-02-04** **Nix and Fix: Targeting 1000x Compression of 3D Gaussian Splatting with Diffusion Models** [2602.04549](http://arxiv.org/abs/2602.04549)
  > 3D 高斯喷射 (3DGS) 彻底改变了新颖的视图渲染。 3DGS 不像隐式表示那样从密集空间点进行推断，而是使用稀疏高斯分布。这可以实现实时性能，但会增加空间需求，阻碍沉浸式通信等应用。 3DGS 压缩作为一个旨在缓解这一问题的领域而应运而生。虽然已经取得了令人印象深刻的进展，但在低速率下，压缩会引入伪影，从而显着降低视觉质量。我们介绍 NiFi，这是一种通过基于伪影的、基于扩散的一步蒸馏进行恢复来实现极端 3DGS 压缩的方法。我们证明，我们的方法以极低的速率（低至 0.1 MB）实现了最先进的感知质量，并且在可比较的感知性能下，速率比 3DGS 提高了 1000 倍。该代码将在接受后开源。

- **2026-02-04** **A scalability benchmark study of model order reduction techniques for very large, strongly coupled vibroacoustic problems** [2602.04513](http://arxiv.org/abs/2602.04513)
  > 模型降阶 (MOR) 可以显着降低振动声学模拟的计算成本。虽然大多数 MOR 研究侧重于单域系统（例如结构动力学或计算流体力学），但这项工作比较了大型多域问题的 MOR 技术，以确定在超大规模下保持高效和准确的方法。特别是，用于计算从输入力到重流体域中的结构加速度或压力的传递函数的振动声学流体-结构耦合系统的谐波响应模拟引起了高度关注。为了实现这一目标，我们对多材料系统中最常见的基于模态方法和 Krylov 子空间方法的 MOR 技术进行了比较。为了评估这些技术对于不同系统尺寸的可行性和准确性，开发了一个可扩展的充水有机玻璃圆柱体基准模型，其网格尺寸为 10,000 至 1,000,000 自由度 (DOF)。通过对实验数据进行验证来保证模型的质量。提供几何形状、模型数据和实验结果，以便它们可以用作进一步研究的基准。对于大于 100,000 DOF 的系统，由于内存限制，所研究的模态方法变得不切实际，即使在功能强大的工作站上也是如此。在测试的技术中，Krylov 子空间两级正交 Arnoldi 简化与系统矩阵的对称化和调节相结合，提供了目标传递函数最准确、最有效的近似 - 特别是对于高达 1,000,000 DOF 的大型模型。与完整模型相比，这种方法实现了高达 600 倍的加速。

- **2026-02-04** **Unified MPI Parallelization of Wave Function Methods: iCIPT2 as a Showcase** [2602.04470](http://arxiv.org/abs/2602.04470)
  > 量子化学方法与高性能计算的集成对于处理精度适中的大型系统甚至高精度的小型系统是必不可少的。继续在 MetaWave 平台内统一实现非相对论和相对论波函数方法 (J. Phys. Chem. A. 2025, 129, 5170)，我们在这里提出了方法的统一 MPI 并行化，通过 Ghost 过程将方法的计算步骤抽象为动态调度的循环，然后对每个节点的局部结果进行全局缩减。算法抽象允许在不同方法的各个步骤中使用单个 MPI 模板。服用 iCIPT2 [J.化学。理论计算。 2021, 17, 949] 作为展示，在 16 个节点（1024 个核心）上，扰动计算和整体计算的并行效率分别达到 94% 和 89%。进一步结合矩阵对角化中矩阵向量乘积的改进算法和基于轨道构型的半随机估计器进行摄动校正，使得大活动空间计算成为可能，从而获得环丁二烯自聚、苯基态能和臭氧势能剖面的基准。它还表明 iCIPT2 的误差遵循关于配置状态函数数量的幂律。

- **2026-02-04** **Fine-Grained Activation Steering: Steering Less, Achieving More** [2602.04428](http://arxiv.org/abs/2602.04428)
  > 激活引导已成为修改大型语言模型 (LLM) 行为的经济有效的范例。现有的方法通常在块级别进行干预，引导选定的注意力头、前馈网络或残余流的捆绑激活。然而，我们发现块级激活本质上是异构的，纠缠着有益的、不相关的和有害的特征，从而使块级控制变得粗糙、低效和侵入性。为了研究根本原因，我们将块激活分解为细粒度原子单元（AU）级激活，其中每个AU级激活对应于块激活的单个维度，每个AU表示块权重矩阵的一个切片。因此，控制 AU 级别的激活相当于控制其关联的 AU。我们的理论和实证分析表明，异质性的出现是因为不同的 AU 或维度控制着 LLM 输出中不同的令牌分布。因此，区块级转向不可避免地将有益和有害的代币方向一起移动，从而降低了效率。将干预限制在有益的 AU 上可以产生更精确、更有效的指导。基于这一见解，我们提出了 AUSteer，这是一种简单而有效的方法，可以在 AU 级别的更细粒度上运行。 AUSteer 首先通过计算对比样本的激活动量来识别全局的判别性 AU。然后，它会根据不同的输入和选定的 AU 激活分配自适应转向强度。对多个法学硕士和任务的综合实验表明，AUSteer 始终超越先进的基线，同时引导的激活数量大大减少，这表明更少的引导可以实现更多的目标。

- **2026-02-04** **On the pure traction problem of linear elasticity: a regularized formulation and its robust approximation** [2602.04359](http://arxiv.org/abs/2602.04359)
  > 纯弹性牵引问题在工程应用中经常出现，其复杂性源于其解决方案仅在（无穷小）刚体运动范围内是唯一的。当采用有限元来近似这个问题时，通常通过在离散模型上应用仔细选择的边界条件或对变形施加全局约束来挑选出一个解决方案。然而，这些策略都不是既简单又计算高效。在这项工作中，我们提出了一种解决纯牵引问题的新方法，克服了现有的限制。我们的方法建立在问题的正则化形式上，其解被证明是唯一的，收敛于最小范数的原始解，并且可以以简单的方式用有限元来近似，而无需额外的自由度。此外，我们还分析了解域的近似导致离散问题的载荷不平衡，从而导致问题不适定的情况。在这种情况下，我们提出了一种正则化预测-校正有限元公式，用于处理载荷的不兼容性，提供一个当网格尺寸和正则化参数趋于零时收敛到原始诺依曼问题的解决方案。数值例子说明了所提出的方法对于出现纯牵引边界条件的力学代表性问题的有效性。

- **2026-02-04** **Can Vision Replace Text in Working Memory? Evidence from Spatial n-Back in Vision-Language Models** [2602.04355](http://arxiv.org/abs/2602.04355)
  > 工作记忆是智能行为的核心组成部分，为维护和更新任务相关信息提供动态工作空间。最近的工作使用 n-back 任务来探测大型语言模型中的类似工作记忆的行为，但尚不清楚当信息以视觉语言模型中的视觉代码而不是文本代码携带时，相同的探测是否会引发类似的计算。我们在受控空间 n-back 任务上评估 Qwen2.5 和 Qwen2.5-VL，该任务呈现为匹配的文本渲染或图像渲染网格。在各种条件下，模型在文本上表现出比视觉上更高的准确度和d'。为了在流程层面解释这些差异，我们使用试验性对数概率证据，发现名义 2/3-back 通常无法反映指示的滞后，而是与新近度锁定比较一致。我们进一步表明，网格大小改变了刺激流中的最近重复结构，从而改变了干扰和错误模式。这些结果激发了对多模式工作记忆的计算敏感的解释。

- **2026-02-03** **EventNeuS: 3D Mesh Reconstruction from a Single Event Camera** [2602.03847](http://arxiv.org/abs/2602.03847)
  > 在许多场景中，事件摄像机为 RGB 摄像机提供了相当好的替代方案。虽然最近有基于事件的新颖视图合成的工作，但密集 3D 网格重建仍然很少被探索，并且现有的基于事件的技术在 3D 重建精度方面受到严重限制。为了解决这个限制，我们提出了 EventNeuS，这是一种自监督神经模型，用于从单目颜色事件流中学习 3D 表示。我们的方法首次将 3D 符号距离函数和密度场学习与基于事件的监督相结合。此外，我们将球谐编码引入到我们的模型中，以增强对视图相关效果的处理。 EventNeuS 的性能显着优于现有方法，与之前的最佳方法相比，倒角距离平均降低了 34%，平均绝对误差平均降低了 31%。

- **2026-02-03** **AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations** [2602.03828](http://arxiv.org/abs/2602.03828)
  > 高质量的科学插图对于有效传达复杂的科学和技术概念至关重要，但其手工创作仍然是学术界和工业界公认的瓶颈。我们推出了FigureBench，这是第一个从长篇科学文本生成科学插图的大型基准。它包含 3,300 个高质量的科学文本-图形对，涵盖科学论文、调查、博客和教科书中的各种文本到插图任务。此外，我们提出了 AutoFigure，这是第一个基于长篇科学文本自动生成高质量科学插图的代理框架。具体来说，在渲染最终结果之前，AutoFigure 会进行广泛的思考、重组和验证，以生成结构合理且美观的布局，输出既结构完整又美观的科学插图。利用FigureBench 的高质量数据，我们进行了大量实验，以根据各种基线方法测试 AutoFigure 的性能。结果表明，AutoFigure 始终超越所有基线方法，生成可供出版的科学插图。代码、数据集和huggingface空间发布于https://github.com/ResearAI/AutoFigure。

- **2026-02-03** **3D-Aware Implicit Motion Control for View-Adaptive Human Video Generation** [2602.03796](http://arxiv.org/abs/2602.03796)
  > 视频生成中现有的人体运动控制方法通常依赖 2D 姿势或显式 3D 参数模型（例如 SMPL）作为控制信号。然而，2D 将运动严格绑定到驾驶视点，从而妨碍了新颖的视图合成。显式 3D 模型虽然在结构上信息丰富，但存在固有的不准确性（例如，深度模糊性和不准确的动态），当用作强约束时，会覆盖大型视频生成器强大的内在 3D 感知能力。在这项工作中，我们从 3D 感知的角度重新审视运动控制，提倡一种隐式的、与视图无关的运动表示，它自然地与生成器的空间先验对齐，而不是依赖于外部重建的约束。我们引入了 3DiMo，它联合训练运动编码器和预先训练的视频生成器，将驱动帧提取为紧凑的、与视图无关的运动标记，并通过交叉注意力进行语义注入。为了培养 3D 意识，我们通过丰富视图的监督（即单视图、多视图和移动摄像机视频）进行训练，强制不同视点之间的运动一致性。此外，我们使用辅助几何监督，仅利用 SMPL 进行早期初始化，并退火至零，使模型能够从外部 3D 指导过渡到从数据和生成器先验中学习真正的 3D 空间运动理解。实验证实，3DiMo 通过灵活的文本驱动摄像头控制忠实地再现了驾驶动作，在运动保真度和视觉质量方面都显着超越了现有方法。

- **2026-02-03** **BridgeV2W: Bridging Video Generation Models to Embodied World Models via Embodiment Masks** [2602.03793](http://arxiv.org/abs/2602.03793)
  > 具身世界模型已成为机器人技术中一个有前途的范例，其中大多数利用大规模互联网视频或预训练的视频生成模型来丰富视觉和运动先验。然而，它们仍然面临关键挑战：坐标空间动作和像素空间视频之间的不对准、对相机视点的敏感性以及跨实施例的非统一架构。为此，我们提出了 BridgeV2W，它将坐标空间动作转换为根据 URDF 和相机参数渲染的像素对齐的实施例掩模。然后，这些掩模通过 ControlNet 风格的路径注入到预训练的视频生成模型中，该路径将动作控制信号与预测视频对齐，添加特定于视图的调节以适应相机视点，并在各个实施例中生成统一的世界模型架构。为了减轻对静态背景的过度拟合，BridgeV2W 进一步引入了基于流的运动损失，专注于学习动态和任务相关区域。在单臂 (DROID) 和双臂 (AgiBot-G1) 数据集上进行的实验涵盖了具有未见过的视点和场景的多样化且具有挑战性的条件，结果表明，与之前最先进的方法相比，BridgeV2W 提高了视频生成质量。我们进一步展示了 BridgeV2W 在下游现实世界任务中的潜力，包括政策评估和目标条件规划。更多结果可以在我们的项目网站 https://BridgeV2W.github.io 上找到。

- **2026-02-03** **A High-order piecewise field-aligned triangular finite element method for electromagnetic gyrokinetic particle simulations of tokamak plasmas with open field lines** [2602.03759](http://arxiv.org/abs/2602.03759)
  > 开发并实现了一种高阶分段场对齐三角形有限元方法，用于具有开场线的托卡马克等离子体的全局电磁回旋粒子内模拟。该方法将局部场对齐的有限元基函数与柱坐标中的非结构化 $C^{1}$ 三角网格相结合，从而能够在大幅减少计算量的情况下进行全体积模拟，同时避免与全局场对齐坐标相关的网格畸变以及转向等离子体分界线处的相关奇点。该公式与 $δf$ 和 full-$f$ 模型兼容，并采用混合变量表示以及广义回拉方案来控制电磁模拟中的数值抵消。该方法在 TRIMEG-C1 代码中实现，并使用 TCV-X21 配置的线性和非线性电磁仿真进行演示。结果表明，该方法准确地捕获了电磁离子温度梯度和动力学气球模式物理的关键特征，包括模拟中的分界线区域，从而为现实托卡马克几何结构中的全体积电磁回旋运动模拟提供了一个强大的框架。

- **2026-02-03** **Transformation front kinetics in deformable ferromagnets** [2602.03745](http://arxiv.org/abs/2602.03745)
  > 诸如磁性形状记忆合金之类的材料在材料的磁化强度和机械变形之间具有内在的耦合。这些材料还经历结构相变，相边界分隔不同的相，并且相边界的动力学受磁场和机械应力控制。还有许多其他材料揭示了类似的现象，例如磁性钙钛矿。为了在连续尺度上模拟可变形磁性材料中相界的传播，需要三个要素：一组具有耦合磁和机械自由度的体行为控制方程、相界速度对控制因素的依赖性以及可靠的计算方法。相界速度的表达式通常在连续介质热力学设置内获得，其中导出由于相界传播而产生的熵，这给出了相界动力学的热力学驱动力。对于可变形铁磁体，所有三个要素（体积行为、界面动力学和计算方法）都已得到探索，但仍存在许多限制。本文重点讨论一般磁力机械环境中转变前沿热力学驱动力的推导，采用磁力学转变前沿的切割有限元方法，无需修改有限元网格即可极其有效地处理传播界面，并将所取得的进展应用于磁性形状记忆合金磁力学的定性建模。

- **2026-02-03** **Constraining cosmological simulations with peculiar velocities: a forward-modeling approach** [2602.03699](http://arxiv.org/abs/2602.03699)
  > 数值模拟是破译引力动力学的关键工具。然而，它们无法在空间上重现我们观察到的宇宙，从而将观察与模拟之间的比较限制在统计水平。对于在单一环境中观察到的稀有、微弱或经过深入研究的附近物体来说，这是一个很大的问题。在随机模拟中恢复这种环境的计算成本是令人望而却步的。   我们提出了 Hamlet-PM，这种方法能够限制宇宙学模拟的初始条件，从而产生可以直接与本地宇宙的观测结果进行比较的演化数值宇宙：约束模拟。   我们的方法根据后期奇特速度的稀疏和噪声测量来实现早期密度场的场级正向建模。动力学与粒子网格重力解算器集成，从而探测轻度非线性状态。该代码适用于 Cosmicflows-4 编译，奇特速度高达 z < 0.05 (160 Mpc/h)。使用高精度 N 体代码重新模拟受约束的 IC。   提出了一系列一百个仅暗物质的宇宙学约束模拟，在 500^3 [Mpc/h]3 盒子中分辨率为 512^3 粒子。特别关注十二个突出的附近星系团，它们的模拟对应物在质量和分离标准上相匹配。我们提供了受每个簇动态环境约束的质量估计。   初始条件的场级正向建模产生高度受限的宇宙学模拟。目前，该方法在质量上已经超过了特速社区中使用的管道，尽管系统偏差仍需要解决。此外，由于贝叶斯方法固有的灵活性，改进模型很容易。

- **2026-02-03** **ELIQ: A Label-Free Framework for Quality Assessment of Evolving AI-Generated Images** [2602.03558](http://arxiv.org/abs/2602.03558)
  > 生成文本到图像的模型正在以前所未有的速度发展，不断改变感知质量上限，并使以前收集的标签对新一代来说变得不可靠。为了解决这个问题，我们提出了 ELIQ，一种用于对不断变化的人工智能生成图像进行质量评估的无标签框架。具体来说，ELIQ 专注于视觉质量和提示图像对齐，自动构建正对和特定方面的负对，以涵盖传统的失真和 AIGC 特定的失真模式，从而无需人工注释即可实现可转移的监督。在这些对的基础上，ELIQ 通过指令调整将预先训练的多模态模型调整为质量感知批评者，并使用轻量级门控融合和质量查询转换器来预测二维质量。跨多个基准的实验表明，ELIQ 始终优于现有的无标签方法，无需修改即可从人工智能生成内容 (AIGC) 推广到用户生成内容 (UGC) 场景，并为不断发展的生成模型下的可扩展和无标签质量评估铺平了道路。该代码将在发布后发布。

- **2026-02-03** **Constrained Dynamic Gaussian Splatting** [2602.03538](http://arxiv.org/abs/2602.03538)
  > 虽然动态高斯分布可以实现高保真 4D 重建，但其部署受到一个根本困境的严重阻碍：无约束的致密化导致内存消耗过多，与边缘设备不兼容，而启发式剪枝无法在预设高斯预算下实现最佳渲染质量。在这项工作中，我们提出了约束动态高斯分布（CDGS），这是一种新颖的框架，它将动态场景重建制定为预算约束的优化问题，以在训练期间强制执行严格的、用户定义的高斯预算。我们的主要见解是引入可微分预算控制器作为核心优化驱动器。在多模式统一重要性评分的指导下，该控制器融合了几何、运动和感知线索，以实现精确的容量调节。为了最大化该固定预算的效用，我们进一步解耦静态和动态元素的优化，采用自适应分配机制，根据运动复杂性动态分配容量。此外，我们实施了三阶段培训策略来无缝整合这些约束，确保精确遵守目标计数。结合双模式混合压缩方案，CDGS 不仅严格遵守硬件限制（误差 < 2%}），而且还推动了率失真性能的 Pareto 前沿。大量实验表明，CDGS 在不同的容量限制下可提供最佳渲染质量，与最先进的方法相比，压缩率提高了 3 倍以上。

- **2026-02-03** **MatGPTQ: Accurate and Efficient Post-Training Matryoshka Quantization** [2602.03537](http://arxiv.org/abs/2602.03537)
  > Matryoshka 量化 (MatQuant) 是一种最新的量化方法，表明通过在推理时对最高有效位 (MSB) 进行切片，可以跨多个精度提供单个整数量化模型。这使得单个检查点能够覆盖广泛的内存和延迟预算，但使量化变得更具挑战性。特别是，最初的 MatQuant 依赖于昂贵的量化感知训练 (QAT) 变体，而不是快速一次性训练后量化 (PTQ)，并且缺乏开源和内核支持。我们通过引入训练后俄罗斯套娃量化 (MatGPTQ) 来解决所有这些限制，这是一种新的 PTQ 管道，可基于小型校准集生成针对多个目标精度一次性联合优化的单父模型。 MatGPTQ 将 Matryoshka 量化作为具有位切片和交叉位误差补偿的多精度目标，从而产生一种在单次传递中生成多位宽度、“可切片”模型的算法。我们还针对异构每层位结合了新的预算感知搜索，并提供了实现切片和混合精度执行的高效内核。在标准 LLM 和基准测试中，MatGPTQ 保留了高位精度，同时大幅提高了低位宽度设置下的性能。总体而言，我们为俄罗斯套娃式训练后量化建立了新的技术水平，并使单检查点、多精度部署开放且实用。代码可在 https://github.com/IST-DASLab/MatGPTQ 获取。


<p align=right>(<a href=#updated-on-20260209>back to top</a>)</p>

## 具生智能&自动驾驶

- **2026-02-06** **DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos** [2602.06949](http://arxiv.org/abs/2602.06949)
  > 能够模拟不同环境中行动的结果将彻底改变多面手智能体的大规模开发。然而，由于有限的数据覆盖范围和稀缺的动作标签，对这些世界动态进行建模，特别是对于灵巧的机器人任务，提出了重大挑战。作为实现这一目标的努力，我们引入了 DreamDojo，这是一个基础世界模型，可以从 44,000 小时以自我为中心的人类视频中学习多样化的交互和灵巧的控制。我们的数据混合代表了迄今为止用于世界模型预训练的最大视频数据集，涵盖具有不同对象和技能的广泛日常场景。为了解决动作标签的稀缺问题，我们引入连续的潜在动作作为统一的代理动作，增强未标记视频的交互知识转移。经过小规模目标机器人数据的后期训练，DreamDojo 表现出了对物理的深刻理解和精确的动作可控性。我们还设计了一个蒸馏管道，将 DreamDojo 的实时速度加速到 10.81 FPS，并进一步提高上下文一致性。我们的工作实现了基于生成世界模型的多种重要应用，包括实时远程操作、政策评估和基于模型的规划。对多个具有挑战性的分布外（OOD）基准的系统评估验证了我们的方法对于模拟开放世界、接触丰富的任务的重要性，为通用机器人世界模型铺平了道路。

- **2026-02-06** **From Kepler to Newton: Inductive Biases Guide Learned World Models in Transformers** [2602.06923](http://arxiv.org/abs/2602.06923)
  > 通用人工智能架构能否超越预测来发现支配宇宙的物理定律？真正的智能依赖于“世界模型”——因果抽象，使智能体不仅能够预测未来状态，而且能够理解潜在的治理动态。虽然以前的“人工智能物理学家”方法已经成功地恢复了这些定律，但它们通常依赖于强大的、特定领域的先验，可以有效地“烘焙”物理。相反，瓦法等人。最近表明，通用变形金刚无法获取这些世界模型，无法在未捕获基本物理定律的情况下实现高预测精度。我们通过系统地引入三个最小归纳偏差来弥补这一差距。我们证明，确保空间平滑性（通过将预测表述为连续回归）和稳定性（通过在嘈杂的环境中进行训练以减轻误差积累）使通用 Transformer 能够超越先前的失败并学习连贯的开普勒世界模型，成功地将椭圆拟合到行星轨迹。然而，真正的物理洞察力需要第三个偏差：时间局部性。通过将注意力窗口限制在最近的过去——施加未来状态仅依赖于局部状态而不是复杂历史的简单假设——我们迫使模型放弃曲线拟合并发现牛顿力表示。我们的结果表明，简单的架构选择决定了人工智能是否成为曲线拟合者或物理学家，标志着自动化科学发现的关键一步。

- **2026-02-06** **Temperature Scaling Attack Disrupting Model Confidence in Federated Learning** [2602.06638](http://arxiv.org/abs/2602.06638)
  > 预测置信度是关键任务系统中的基本控制信号，直接控制风险感知逻辑，例如升级、弃权和保守回退。虽然之前的联合学习攻击主要针对准确性或植入后门，但我们将置信度校准视为一个独特的攻击目标。我们提出了温度缩放攻击（TSA），这是一种训练时攻击，可以在保持准确性的同时降低校准性能。通过在本地训练期间注入具有学习率-温度耦合的温度缩放，恶意更新可以保持类似良性的优化行为，从而逃避基于准确性的监控和基于相似性的检测。我们提供了非独立同分布设置下的收敛分析，表明这种耦合保留了标准收敛边界，同时系统地扭曲了置信度。在三个基准测试中，TSA 大幅改变了校准（例如，CIFAR-100 上的误差增加了 145%），精度变化小于 2，并且在强大的聚合和事后校准防御下仍然有效。案例研究进一步表明，即使准确性不变，信心操纵也可能导致错过的危急案例（医疗保健）或误报（自动驾驶）增加高达 7.2 倍。总的来说，我们的结果将校准完整性确立为联邦学习中的关键攻击面。

- **2026-02-06** **Force Generative Imitation Learning: Bridging Position Trajectory and Force Commands through Control Technique** [2602.06620](http://arxiv.org/abs/2602.06620)
  > 在接触丰富的任务中，虽然位置轨迹通常很容易获得，但适当的力命令通常是未知的。尽管可以想象使用预训练的基础模型（例如视觉-语言-动作（VLA）模型）生成力命令，但力控制高度依赖于机器人的特定硬件，这使得此类模型的应用具有挑战性。为了弥补这一差距，我们提出了一种力生成模型，可以根据给定的位置轨迹估计力命令。然而，在处理看不见的位置轨迹时，该模型很难生成准确的力命令。为了解决这个问题，我们引入了反馈控制机制。我们的实验表明，当力生成模型具有记忆时，反馈控制不会收敛。因此，我们采用无记忆模型，实现稳定的反馈控制。这种方法允许系统有效地生成力命令，即使对于看不见的位置轨迹也是如此，从而提高了现实世界机器人书写任务的泛化能力。

- **2026-02-06** **Think Proprioceptively: Embodied Visual Reasoning for VLA Manipulation** [2602.06575](http://arxiv.org/abs/2602.06575)
  > 视觉-语言-动作（VLA）模型通常仅将本体感觉作为后期调节信号注入，这会阻止机器人状态塑造指令理解并影响整个策略中关注的视觉标记。我们引入了 ThinkProprio，它将本体感觉转换为 VLM 嵌入空间中的一系列文本标记，并将它们与输入处的任务指令融合。这种早期融合让体现状态参与后续的视觉推理和标记选择，使计算偏向于行动关键证据，同时抑制冗余的视觉标记。在对本体感觉编码、状态入口点和动作头调节的系统消融中，我们发现文本标记化比学习投影更有效，并且保留大约 15% 的视觉标记可以与使用完整标记集的性能相匹配。在 CALVIN、LIBERO 和现实世界的操作中，ThinkProprio 匹配或改进了强大的基线，同时将端到端推理延迟减少了 50% 以上。

- **2026-02-06** **LIBERO-X: Robustness Litmus for Vision-Language-Action Models** [2602.06556](http://arxiv.org/abs/2602.06556)
  > 可靠的基准测试对于推进视觉-语言-动作（VLA）模型至关重要，因为它揭示了它们的泛化性、鲁棒性以及感知与语言驱动的操作任务的一致性。然而，由于评估协议不足，无法充分捕捉现实世界的分布变化，现有基准通常提供有限或误导性的评估。这项工作从评估和数据的角度系统地重新思考了 VLA 基准测试，引入了 LIBERO-X，该基准测试具有以下特点：1）具有渐进难度级别的分层评估协议，针对三个核心功能：空间泛化、对象识别和任务指令理解。这种设计能够在环境和任务复杂性不断增加的情况下对性能下降进行细粒度分析； 2）通过人工远程操作收集的高多样性训练数据集，其中每个场景支持多个细粒度的操作目标，以弥合训练评估分布差距。对代表性 VLA 模型的实验表明，在累积扰动下，性能会显着下降，暴露出场景理解和指令基础方面持续存在的局限性。通过将分层评估与不同的训练数据相结合，LIBERO-X 为评估和推进 VLA 开发提供了更可靠的基础。

- **2026-02-06** **DriveWorld-VLA: Unified Latent-Space World Modeling with Vision-Language-Action for Autonomous Driving** [2602.06521](http://arxiv.org/abs/2602.06521)
  > 端到端（E2E）自动驾驶最近吸引了越来越多的兴趣，将视觉-语言-行动（VLA）与世界模型相结合，以增强决策能力和前瞻性想象力。然而，由于潜在状态共享不足，现有方法无法在单一架构中有效地统一未来场景演化和动作规划，从而限制了视觉想象力对动作决策的影响。为了解决这一限制，我们提出了 DriveWorld-VLA，这是一种新颖的框架，通过在表示级别紧密集成 VLA 和世界模型，在潜在空间内统一世界建模和规划，这使得 VLA 规划器能够直接从整体场景演化建模中受益，并减少对密集注释监督的依赖。此外，DriveWorld-VLA 将世界模型的潜在状态作为 VLA 规划器的核心决策状态，帮助规划器评估候选动作如何影响未来的场景演化。通过完全在潜在空间中进行世界建模，DriveWorld-VLA 支持特征级别的可控、动作条件想象，从而避免昂贵的像素级部署。广泛的开环和闭环评估证明了 DriveWorld-VLA 的有效性，它实现了最先进的性能，NAVSIMv1 上的 PDMS 为 91.3，NAVSIMv2 上的 EPDMS 为 86.8，nuScenes 上的 3 秒平均碰撞率为 0.16。代码和模型将在https://github.com/liulin815/DriveWorld-VLA.git发布。

- **2026-02-06** **Beyond the Majority: Long-tail Imitation Learning for Robotic Manipulation** [2602.06512](http://arxiv.org/abs/2602.06512)
  > 虽然通才机器人策略对于通过模仿学习多种操作技能具有重大前景，但它们的表现往往受到训练演示的长尾分布的阻碍。在此类数据上学习的策略严重偏向于少数数据丰富的头部任务，而在面对大量数据稀缺的尾部任务时，经常表现出较差的泛化性。在这项工作中，我们对政策学习中固有的普遍存在的长尾挑战进行了全面分析。我们的分析首先证明传统的长尾学习策略（例如重新采样）对于提高策略在尾部任务上的性能是无效的。然后，我们揭示了这种失败的根本机制，揭示了尾部任务的数据稀缺直接损害了策略的空间推理能力。为了克服这个问题，我们引入了接近阶段增强（APA），这是一种简单而有效的方案，可以将知识从数据丰富的头部任务转移到数据稀缺的尾部任务，而无需外部演示。模拟和现实操作任务中的大量实验证明了 APA 的有效性。我们的代码和演示可在以下位置公开获取：https://mldxy.github.io/Project-VLA-long-tail/。

- **2026-02-06** **World-VLA-Loop: Closed-Loop Learning of Video World Model and VLA Policy** [2602.06508](http://arxiv.org/abs/2602.06508)
  > 机器人世界模型的最新进展利用视频扩散变压器来预测基于历史状态和动作的未来观察。虽然这些模型可以模拟真实的视觉结果，但它们通常表现出较差的动作跟踪精度，从而阻碍了它们在下游机器人学习中的实用性。在这项工作中，我们引入了 World-VLA-Loop，这是一个用于联合完善世界模型和愿景-语言-行动（VLA）政策的闭环框架。我们提出了一种状态感知视频世界模型，通过联合预测未来的观察结果和奖励信号，充当高保真交互式模拟器。为了提高可靠性，我们引入了 SANS 数据集，该数据集包含接近成功的轨迹，以改善世界模型中的行动与结果的一致性。该框架完全在虚拟环境中实现了 VLA 策略的强化学习 (RL) 后训练闭环。至关重要的是，我们的方法促进了一个共同进化的循环：VLA 策略生成的失败部署会被迭代反馈以细化世界模型的精度，从而增强后续的 RL 优化。对模拟和现实世界任务的评估表明，我们的框架以最少的物理交互显着提高了 VLA 性能，在通用机器人的世界建模和策略学习之间建立了互惠互利的关系。项目页面：https://showlab.github.io/World-VLA-Loop/。

- **2026-02-06** **Rebenchmarking Unsupervised Monocular 3D Occupancy Prediction** [2602.06488](http://arxiv.org/abs/2602.06488)
  > 从单个图像推断 3D 结构，特别是在遮挡区域中，仍然是以视觉为中心的自动驾驶中一个基本但尚未解决的挑战。现有的无监督方法通常训练神经辐射场并在评估过程中将网络输出视为占用概率，而忽略了训练和评估协议之间的不一致。此外，二维地面实况的普遍使用未能揭示由于几何约束不足而导致的遮挡区域固有的模糊性。为了解决这些问题，本文提出了一个重新制定的无监督单目 3D 占用预测基准。我们首先解释体绘制过程中涉及的变量，并确定占用概率的物理上最一致的表示。在这些分析的基础上，我们通过将新识别的表示与体素方面的 3D 占用地面实况对齐来改进现有的评估协议，从而使无监督方法能够以与监督方法一致的方式进行评估。此外，为了在遮挡区域施加明确的约束，我们引入了一种遮挡感知偏振机制，该机制结合了多视图视觉线索，以增强这些区域中占用空间和自由空间之间的区分。大量的实验表明，我们的方法不仅显着优于现有的无监督方法，而且与有监督方法的性能相匹配。我们的源代码和评估协议将在发布后提供。

- **2026-02-05** **Thinking with Geometry: Active Geometry Integration for Spatial Reasoning** [2602.06037](http://arxiv.org/abs/2602.06037)
  > 多模态大型语言模型 (MLLM) 空间推理的最新进展越来越多地利用 3D 编码器的几何先验。然而，大多数现有的集成策略仍然是被动的：几何图形被暴露为全局流并以不加区别的方式融合，这通常会导致语义-几何错位和冗余信号。我们提出了 GeoThinker，一个将范式从被动融合转变为主动感知的框架。 GeoThinker 不是特征混合，而是使模型能够根据其内部推理需求选择性地检索几何证据。 GeoThinker 通过在精心选择的 VLM 层上应用空间接地融合来实现这一目标，其中语义视觉先验通过帧严格交叉注意选择性地查询和集成任务相关几何图形，并通过重要性门控进一步校准，将每帧注意力偏向任务相关结构。综合评估结果表明，GeoThinker 在空间智能方面树立了新的最先进水平，在 VSI-Bench 上取得了 72.6 的最高分数。此外，GeoThinker 展示了强大的泛化能力，并显着改善了复杂下游场景（包括具体参考和自动驾驶）的空间感知。我们的结果表明，主动整合空间结构的能力对于下一代空间智能至关重要。代码可以在 https://github.com/Li-Hao-yuan/GeoThinker 找到。

- **2026-02-05** **Curiosity is Knowledge: Self-Consistent Learning and No-Regret Optimization with Active Inference** [2602.06029](http://arxiv.org/abs/2602.06029)
  > 主动推理 (AIF) 通过最小化预期自由能 (EFE)、通过好奇心系数平衡认知价值（信息增益）和实用价值（任务绩效）来统一探索和利用。然而，目前尚不清楚这种平衡何时会产生连贯的学习和有效的决策：好奇心不足会导致短视的利用并阻止不确定性的解决，而过度的好奇心会导致不必要的探索和遗憾。我们为 EFE 最小化智能体建立了第一个理论保证，表明单一要求——足够的好奇心——同时确保自洽学习（贝叶斯后验一致性）和无遗憾优化（有界累积遗憾）。我们的分析描述了这一机制如何依赖于初始不确定性、可识别性和目标一致性，从而在一个理论框架内将 AIF 与经典贝叶斯实验设计和贝叶斯优化联系起来。我们进一步将这些理论转化为实用的设计指南，用于调整混合学习优化问题中的认知-实用权衡，并通过现实世界的实验进行验证。

- **2026-02-05** **Visuo-Tactile World Models** [2602.06001](http://arxiv.org/abs/2602.06001)
  > 我们引入了多任务视觉触觉世界模型（VT-WM），它通过触摸推理捕获接触的物理原理。通过用触觉感知补充视觉，VT-WM 可以更好地理解接触丰富的任务中的机器人与物体的交互，避免纯视觉模型在遮挡或模糊接触状态下的常见故障模式，例如物体消失、传送或以违反基本物理的方式移动。经过一系列接触丰富的操作任务的训练，VT-WM 提高了想象中的物理保真度，在保持物体持久性方面的性能提高了 33%，在自回归推出中对运动定律的遵从性提高了 29%。此外，实验表明，接触动力学的基础也可以转化为规划。在零样本真实机器人实验中，VT-WM 的成功率提高了 35%，在多步骤、接触丰富的任务中收益最大。最后，VT-WM 展示了显着的下游多功能性，有效地将其学到的接触动力学适应新任务，并仅通过有限的一组演示就取得了可靠的规划成功。

- **2026-02-05** **LSA: Localized Semantic Alignment for Enhancing Temporal Consistency in Traffic Video Generation** [2602.05966](http://arxiv.org/abs/2602.05966)
  > 可控视频生成已成为自动驾驶的多功能工具，可实现交通场景的真实合成。然而，现有方法依赖于推理时的控制信号来引导生成模型实现动态对象的时间一致生成，限制了它们作为可扩展和可概括的数据引擎的实用性。在这项工作中，我们提出了局部语义对齐（LSA），这是一个简单而有效的框架，用于微调预训练的视频生成模型。 LSA 通过对齐真实视频和生成的视频剪辑之间的语义特征来增强时间一致性。具体来说，我们比较了现成特征提取模型的输出，即地面实况和围绕动态对象生成的视频剪辑，从而导致语义特征一致性损失。我们通过将此损失与标准扩散损失相结合来微调基本模型。该模型针对单个时期进行了微调，我们的新颖损失优于常见视频生成评估指标的基线。为了进一步测试生成视频的时间一致性，我们采用了对象检测任务中的两个附加指标，即 mAP 和 mIoU。 nuScenes 和 KITTI 数据集上的大量实验表明，我们的方法在增强视频生成的时间一致性方面的有效性，而无需在推理过程中使用外部控制信号和任何计算开销。

- **2026-02-05** **Verification of the Implicit World Model in a Generative Model via Adversarial Sequences** [2602.05903](http://arxiv.org/abs/2602.05903)
  > 生成序列模型通常根据自然语言或形式语言的样本序列进行训练。基于样本的训练是否能够（或者在多大程度上）能够捕获这些语言的真实结构（通常称为“世界模型”）是一个关键问题。理论结果表明，我们最多只能期望健全性，即生成有效的序列，但不一定是所有序列。然而，拥有能够验证给定序列模型是否合理的实用工具仍然很重要。在本研究中，我们关注国际象棋，因为它是一个提供足够复杂性同时具有简单的基于规则的世界模型的领域。我们提出对抗性序列生成来验证序列模型的健全性。我们的对手生成有效的序列，以迫使序列模型生成无效的下一步行动预测。除了对稳健性的伪造之外，该方法还适用于对训练期间的故障模式和不同选择的影响进行更细粒度的分析。为了证明这一点，我们提出了多种对抗序列生成方法，并在大量国际象棋模型上评估该方法。我们使用多种训练方法在随机和高质量的国际象棋游戏上训练模型。我们发现没有一个模型是健全的，但一些训练技术和数据集选择能够显着提高健全性。我们还研究了董事会状态探测在我们的训练和攻击方法中的潜在应用。我们的研究结果表明，在大多数模型中，提取的董事会状态在下一个代币预测中没有因果作用。

- **2026-02-05** **Reinforcement World Model Learning for LLM-based Agents** [2602.05842](http://arxiv.org/abs/2602.05842)
  > 大型语言模型（LLM）在以语言为中心的任务中取得了强劲的性能。然而，在代理环境中，法学硕士常常难以预测行动后果并适应环境动态，这凸显了基于法学硕士的代理对世界建模能力的需求。我们提出了强化世界模型学习（RWML），这是一种自我监督方法，可以使用模拟到真实的差距奖励来学习文本状态上基于 LLM 的代理的动作条件世界模型。我们的方法将模型产生的模拟下一个状态与从环境中观察到的实现的下一个状态对齐，从而鼓励预先训练的嵌入空间中内部世界模拟和实际环境动态之间的一致性。与下一个状态令牌预测相比，下一个状态令牌预测优先考虑令牌级别的保真度（即，再现准确的措辞）而不是语义等价，并可能导致模型崩溃，我们的方法提供了更强大的训练信号，并且从经验上看，与 LLM 作为法官相比，更不易受到奖励黑客的影响。我们在 ALFWorld 和 $τ^2$ Bench 上评估我们的方法，并观察到相对于基本模型的显着收益，尽管完全是自我监督的。当与任务成功奖励相结合时，我们的方法在 ALFWorld 和 $τ^2$ Bench 上分别比直接任务成功奖励 RL 好 6.9 和 5.7 个点，同时与专家数据训练的性能相匹配。

- **2026-02-05** **UI-Mem: Self-Evolving Experience Memory for Online Reinforcement Learning in Mobile GUI Agents** [2602.05832](http://arxiv.org/abs/2602.05832)
  > 在线强化学习 (RL) 为通过直接环境交互增强 GUI 代理提供了一种有前途的范例。然而，由于缺乏经验转移，长期任务中信用分配效率低下以及跨任务重复错误严重阻碍了其有效性。为了应对这些挑战，我们提出了 UI-Mem，这是一种新颖的框架，可以通过分层体验记忆增强 GUI 在线强化学习。与传统的重播缓冲区不同，我们的记忆积累了结构化知识，包括高级工作流程、子任务技能和失败模式。这些体验存储为参数化模板，可实现跨任务和跨应用程序传输。为了有效地将记忆指导整合到在线强化学习中，我们引入了分层组采样，它在每个推出组内的轨迹上注入不同级别的指导，以保持结果多样性，推动无指导政策内化指导行为。此外，自我进化循环不断抽象出新的策略和错误，以保持记忆与代理不断发展的策略保持一致。在线 GUI 基准测试表明，UI-Mem 显着优于传统的 RL 基线和静态重用策略，对未见过的应用程序具有很强的泛化能力。项目页面：https://ui-mem.github.io

- **2026-02-05** **Allocentric Perceiver: Disentangling Allocentric Reasoning from Egocentric Visual Priors via Frame Instantiation** [2602.05789](http://arxiv.org/abs/2602.05789)
  > 随着对视觉语言导航/动作等空间基础任务的需求不断增长，视觉语言模型（VLM）中的异中心感知能力越来越受到关注。然而，VLM 在需要显式视角转换的异中心空间查询上仍然很脆弱，其中答案取决于以目标为中心的框架中的推理，而不是观察到的摄像机视图。因此，我们引入了 Allocentric Perceiver，这是一种免训练策略，可以使用现成的几何专家从一个或多张图像中恢复度量 3D 状态，然后实例化与指令语义意图一致的查询条件的异中心参考系。通过确定性地将重建的几何图形转换为目标框架，并通过结构化的、基于几何图形的表示来提示主干 VLM，Allocentric Perceriver 将心理旋转从隐式推理转移到显式计算。我们在空间推理基准上评估了多个骨干系列的 Allocentric Perciver，在异中心任务上观察到一致且实质性的收益 ( $\sim$ 10%)，同时保持强大的自我中心性能，并超越了空间感知微调模型和最先进的开源和专有模型。

- **2026-02-05** **RL-VLA $^3$ : Reinforcement Learning VLA Accelerating via Full Asynchronism** [2602.05765](http://arxiv.org/abs/2602.05765)
  > 近年来，视觉-语言-动作（VLA）模型已成为通向通用体现智能的重要途径，但其训练效率已成为关键瓶颈。尽管现有的基于强化学习（RL）的训练框架（如RLinf）可以增强模型泛化能力，但它们仍然依赖于同步执行，导致环境交互、策略生成（推出）和模型更新阶段（参与者）期间严重的资源利用不足和吞吐量限制。为了克服这一挑战，本文首次提出并实现了一个完全异步的策略训练框架，涵盖从环境交互、推出生成到参与者策略更新的整个流程。我们的框架系统地从大型模型强化学习中的异步优化思想中汲取灵感，设计了多级解耦架构。这包括环境交互和轨迹收集的异步并行化、策略生成的流式执行以及训练更新的解耦调度。我们在不同的 VLA 模型和环境中验证了我们的方法的有效性。在 LIBERO 基准测试中，与现有同步策略相比，该框架的吞吐量提高了高达 59.25%。当深度优化分离策略时，通量可提升高达126.67\%。我们通过消融研究验证了每个异步组件的有效性。跨 8 到 256 个 GPU 的扩展定律验证证明了我们的方法在大多数条件下具有出色的可扩展性。

- **2026-02-05** **ROMAN: Reward-Orchestrated Multi-Head Attention Network for Autonomous Driving System Testing** [2602.05629](http://arxiv.org/abs/2602.05629)
  > 自动驾驶系统（ADS）充当自动驾驶汽车的大脑，负责其安全性和效率。安全部署需要在不同的现实场景中进行彻底的测试，并遵守速度限制、信号服从和通行权规则等交通法规。闯红灯、超速等违法行为构成严重的安全隐患。然而，当前的测试方法面临着重大挑战：生成复杂且高风险的违法场景的能力有限，并且无法考虑涉及多辆车和危急情况的复杂交互。为了应对这些挑战，我们提出了 ROMAN，一种用于 ADS 测试的新颖场景生成方法，它将多头注意力网络与交通法加权机制相结合。 ROMAN 旨在生成高风险违规场景，以实现更彻底、更有针对性的 ADS 评估。多头注意力机制模拟车辆、交通信号和其他因素之间的相互作用。交通法规权重机制实现了一个工作流程，利用基于法学硕士的风险权重模块，根据严重性和发生率两个维度来评估违规行为。我们通过在 CARLA 仿真平台上测试百度 Apollo ADS 并进行大量实验来衡量其性能来评估 ROMAN。实验结果表明，ROMAN 超越了最先进的工具 ABLE 和 LawBreaker，平均违规计数比 ABLE 高 7.91%，比 LawBreaker 高 55.96%，同时还保持了更大的场景多样性。此外，只有 ROMAN 成功地为输入交通法规的每个条款生成了违规场景，使其能够比现有方法识别更多的高风险违规行为。

- **2026-02-04** **Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning** [2602.04821](http://arxiv.org/abs/2602.04821)
  > 城市交通管理要求系统能够同时预测未来状况、检测异常情况并采取安全的纠正措施，同时提供可靠性保证。我们提出了 STREAM-RL，一个引入了三个新颖算法贡献的统一框架：（1）PU-GAT+，一种不确定性引导的自适应共形预测器，它使用预测不确定性通过置信单调注意力动态重新加权图注意力，实现无分布的覆盖保证； (2) CRFN-BY，一种保形残差流网络，通过任意依赖下的 Benjamini-Yekutieli FDR 控制对流进行归一化，对不确定性归一化残差进行建模； (3) LyCon-WRL+，一种不确定性引导的安全世界模型 RL 代理，具有 Lyapunov 稳定性证书、经过认证的 Lipschitz 界限和不确定性传播的想象力推出。据我们所知，这是第一个通过异常检测将校准不确定性传播到具有端到端理论保证的安全政策学习的框架。对多个真实交通轨迹数据的实验表明，STREAM-RL 实现了 91.4\% 的覆盖效率，在验证依赖性的情况下将 FDR 控制在 4.1\%，与标准 PPO 的 69\% 相比，安全率提高到 95.2\%，同时获得更高的奖励，端到端推理延迟为 23ms。

- **2026-02-04** **Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty** [2602.04763](http://arxiv.org/abs/2602.04763)
  > 多智能体系统越来越多地配备异构多模态传感器，从而实现更丰富的感知，但引入了特定于模态和依赖于智能体的不确定性。现有的多智能体协作框架通常在智能体级别进行推理，假设同构感知，并隐式处理不确定性，从而限制了传感器损坏情况下的鲁棒性。我们提出了不确定性下的主动非对称多智能体多模态学习（A2MAML），这是一种用于不确定性感知、模态级协作的原则方法。 A2MAML 将每个特定于模态的特征建模为具有不确定性预测的随机估计，主动选择可靠的代理模态对，并通过贝叶斯逆方差加权聚合信息。该公式实现了细粒度、模态级融合，支持非对称模态可用性，并提供了抑制损坏或噪声模态的原则机制。针对协作事故检测的互联自动驾驶场景的大量实验表明，A2MAML 始终优于单代理和协作基线，事故检测率提高了 18.7%。

- **2026-02-04** **DRMOT: A Dataset and Framework for RGBD Referring Multi-Object Tracking** [2602.04692](http://arxiv.org/abs/2602.04692)
  > 参考多目标跟踪（RMOT）旨在根据语言描述跟踪特定目标，对于机器人和自动驾驶等交互式人工智能系统至关重要。然而，现有的 RMOT 模型仅依赖于 2D RGB 数据，由于缺乏明确的 3D 空间信息，因此很难准确检测和关联以复杂空间语义为特征的目标（例如“最靠近相机的人”），并在严重遮挡下保持可靠的身份。在这项工作中，我们提出了一项新颖的任务：RGBD 参考多对象跟踪 (DRMOT)，它明确要求模型融合 RGB、深度 (D) 和语言 (L) 模态以实现 3D 感知跟踪。为了推进 DRMOT 任务的研究，我们构建了一个定制的 RGBD 参考多目标跟踪数据集，名为 DRSet，旨在评估模型的空间语义基础和跟踪能力。具体来说，DRSet 包含来自 187 个场景的 RGB 图像和深度图，以及 240 种语言描述，其中 56 种描述包含与深度相关的信息。此外，我们提出了 DRTrack，一种 MLLM 引导的深度参考跟踪框架。 DRTrack 通过联合 RGB-D-L 输入执行深度感知目标接地，并通过合并深度提示来强制执行稳健的轨迹关联。对 DRSet 数据集的大量实验证明了我们框架的有效性。

- **2026-02-04** **Relational Scene Graphs for Object Grounding of Natural Language Commands** [2602.04635](http://arxiv.org/abs/2602.04635)
  > 机器人在人类环境中得到更广泛的应用，增加了对自然人机交互的需求。然而，理解自然语言命令需要机器人推断预期任务以及如何将其分解为可执行动作，并将这些动作基于机器人对环境的了解，包括相关对象、代理和位置。这一挑战可以通过将大型语言模型 (LLM) 的能力与理解自然语言的能力与 3D 场景图 (3DSG) 相结合来解决，以将推断的动作基于环境的语义表示。然而，许多 3DSG 缺乏对象之间明确的空间关系，尽管人类经常依赖这些关系来描述环境。本文研究了将开放或封闭词汇空间关系纳入 3DSG 是否可以提高法学硕士解释自然语言命令的能力。为了解决这个问题，我们提出了一种基于 LLM 的管道，用于根据开放词汇语言命令来确定目标对象，并提出一种基于视觉语言模型 (VLM) 的管道，用于将开放词汇空间边缘从映射时捕获的图像添加到 3DSG。最后，在一项研究中对两名法学硕士进行了评估，评估他们在目标物体接地下游任务中的表现。我们的研究表明，明确的空间关系提高了法学硕士对地面物体的能力。此外，通过机器人捕获的图像证明使用 VLM 生成开放词汇关系是可行的，但它们相对于封闭词汇关系的优势有限。

- **2026-02-04** **Act, Sense, Act: Learning Non-Markovian Active Perception Strategies from Large-Scale Egocentric Human Data** [2602.04600](http://arxiv.org/abs/2602.04600)
  > 在无约束环境下实现泛化操控需要机器人主动解决信息不确定性，即主动感知的能力。然而，现有方法通常局限于有限类型的传感行为，限制了它们对复杂环境的适用性。在这项工作中，我们将主动感知形式化为由信息增益和决策分支驱动的非马尔可夫过程，提供了视觉主动感知范式的结构化分类。基于这个观点，我们引入了 CoMe-VLA，这是一种认知和记忆感知的视觉语言动作（VLA）框架，它利用大规模人类自我中心数据来学习多功能的探索和操作先验。我们的框架集成了用于自主子任务转换的认知辅助头和双轨记忆系统，通过融合本体感受和视觉时间上下文来保持一致的自我和环境意识。通过在统一的自我中心动作空间中调整人类和机器人的手眼协调行为，我们分三个阶段逐步训练模型。在基于轮子的人形机器人上进行的大量实验表明，我们提出的方法在跨越多个主动感知场景的各种长视野任务中具有强大的鲁棒性和适应性。

- **2026-02-04** **Dual Mind World Model Inspired Network Digital Twin for Access Scheduling** [2602.04566](http://arxiv.org/abs/2602.04566)
  > 工业物联网和实时网络物理基础设施等新兴网络系统需要能够适应动态流量、截止日期和干扰约束的智能调度策略。在这项工作中，我们提出了一种新颖的数字孪生调度框架，其灵感来自双重思维世界模型（DMWM）架构，用于学习知情和想象力驱动的网络控制。与传统的基于规则或纯粹数据驱动的策略不同，所提出的 DMWM 将短期预测规划与基于符号模型的部署相结合，使调度程序能够预测未来的网络状态并相应地调整传输决策。我们在可配置的模拟测试台中实现该框架，并根据不同流量条件下的传统启发式和强化学习基线对其性能进行基准测试。我们的结果表明，DMWM 在突发、干扰有限和截止时间敏感的环境中实现了卓越的性能，同时保持了可解释性和样本效率。所提出的设计弥合了网络级推理和低开销学习之间的差距，标志着朝着可扩展和自适应的基于 NDT 的网络优化迈出了一步。

- **2026-02-04** **EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models** [2602.04515](http://arxiv.org/abs/2602.04515)
  > 在现实环境中部署人形机器人具有根本性的挑战性，因为它需要在部分信息观察和动态变化的环境下紧密集成感知、运动和操纵。以及在不同类型的子任务之间稳健地转换。为了应对这些挑战，我们提出了一项新任务——自我行动，它需要将高级指令直接落实到各种、精确的、空间感知的人形动作中。我们通过引入 EgoActor 进一步实例化该任务，EgoActor 是一种统一且可扩展​​的视觉语言模型 (VLM)，可以预测运动原语（例如行走、转弯、侧向移动、改变高度）、头部运动、操作命令和人机交互，以实时协调感知和执行。我们利用对来自现实世界演示、空间推理问答和模拟环境演示的仅以自我为中心的 RGB 数据的广泛监督，使 EgoActor 能够做出稳健的、上下文感知的决策，并使用 8B 和 4B 参数模型执行流畅的动作推理（低于 1 秒）。在模拟和现实环境中的广泛评估表明，EgoActor 有效地连接了抽象任务规划和具体运动执行，同时泛化到不同的任务和看不见的环境中。

- **2026-02-04** **Safe and Stylized Trajectory Planning for Autonomous Driving via Diffusion Model** [2602.04329](http://arxiv.org/abs/2602.04329)
  > 在复杂的现实场景中实现安全且程式化的轨迹规划仍然是自动驾驶系统的关键挑战。本文提出了 SDD Planner，这是一种基于扩散的框架，旨在有效地实时协调安全约束与驾驶风格。该框架集成了两个核心模块：多源风格感知编码器，采用距离敏感注意力来融合动态代理数据和环境上下文，以实现异构安全风格感知；风格引导的动态轨迹生成器，它在扩散去噪过程中自适应地调节优先级权重，以生成用户偏好且安全的轨迹。大量实验表明 SDD Planner 实现了最先进的性能。在 StyleDrive 基准测试中，它的 SM-PDMS 指标比最强基准 WoTE 提高了 3.9%。此外，在 NuPlan Test14 和 Test14-hard 基准测试中，SDD Planner 分别以 91.76 和 80.32 的总分排名第一，优于 PLUTO 等领先方法。实车闭环测试进一步证实SDD Planner在符合预设驾驶风格的同时保持了高安全标准，验证了其在实际部署中的实际适用性。

- **2026-02-04** **GeneralVLA: Generalizable Vision-Language-Action Models with Knowledge-Guided Trajectory Planning** [2602.04315](http://arxiv.org/abs/2602.04315)
  > 大型基础模型已经对视觉和语言中的复杂问题表现出了强大的开放世界泛化能力，但机器人技术尚未达到类似的泛化水平。一个根本挑战是模型表现出有限的零样本能力，这阻碍了它们有效推广到未见过的场景的能力。在这项工作中，我们提出了 GeneralVLA（具有知识引导轨迹规划的通用视觉语言动作模型），这是一种分层视觉语言动作（VLA）模型，可以更有效地利用基础模型的泛化，实现零样本操作并自动生成机器人数据。特别是，我们研究了一类分层 VLA 模型，其中高级 ASM（可供性分割模块）经过微调以感知场景的图像关键点可供性；中级 3DAgent 执行任务理解、技能知识和轨迹规划，以生成指示所需机器人末端执行器轨迹的 3D 路径。然后，中间 3D 路径预测将作为能够精确操纵的低级 3D 感知控制策略的指导。与其他方法相比，我们的方法不需要现实世界的机器人数据收集或人工演示，这使得它更适合不同的任务和观点。根据经验，GeneralVLA 成功生成了 14 项任务的轨迹，明显优于 VoxPoser 等最先进的方法。与使用人类演示或通过 VoxPoser、Scaling-up 和 Code-As-Policies 生成的数据进行训练相比，生成的演示可以训练更强大的行为克隆策略。我们相信 GeneralVLA 可以成为一种可扩展的方法，既可以为机器人生成数据，也可以在零样本环境中解决新任务。代码：https://github.com/AIGeeksGroup/GeneralVLA。网站：https://aigeeksgroup.github.io/GeneralVLA。

- **2026-02-04** **AppleVLM: End-to-end Autonomous Driving with Advanced Perception and Planning-Enhanced Vision-Language Models** [2602.04256](http://arxiv.org/abs/2602.04256)
  > 端到端自动驾驶已成为一种在统一学习框架内集成感知、决策和控制的有前途的范例。最近，视觉语言模型（VLM）因其在各种未知场景中增强端到端驾驶模型的鲁棒性和泛化性的潜力而受到广泛关注。然而，现有的基于 VLM 的方法仍然面临挑战，包括车道感知欠佳、语言理解偏差以及处理极端情况的困难。为了解决这些问题，我们提出了 AppleVLM，这是一种先进的感知和规划增强型 VLM 模型，可实现稳健的端到端驾驶。 AppleVLM 引入了新颖的视觉编码器和规划策略编码器，以改善感知和决策。首先，视觉编码器使用可变形变换器机制融合多个时间步长的多视图图像的时空信息，增强对相机变化的鲁棒性，并促进跨不同车辆平台的可扩展部署。其次，与传统的基于 VLM 的方法不同，AppleVLM 引入了一种专用的规划模式，可以对明确的鸟瞰空间信息进行编码，从而减轻导航指令中的语言偏差。最后，通过分层思想链进行微调的 VLM 解码器集成了视觉、语言和规划功能，以输出稳健的驾驶路径点。我们在两个 CARLA 基准的闭环实验中评估 AppleVLM，实现了最先进的驾驶性能。此外，我们在 AGV 平台上部署 AppleVLM，并成功展示了复杂户外环境下的真实端到端自动驾驶。

- **2026-02-03** **BridgeV2W: Bridging Video Generation Models to Embodied World Models via Embodiment Masks** [2602.03793](http://arxiv.org/abs/2602.03793)
  > 具身世界模型已成为机器人技术中一个有前途的范例，其中大多数利用大规模互联网视频或预训练的视频生成模型来丰富视觉和运动先验。然而，它们仍然面临关键挑战：坐标空间动作和像素空间视频之间的不对准、对相机视点的敏感性以及跨实施例的非统一架构。为此，我们提出了 BridgeV2W，它将坐标空间动作转换为根据 URDF 和相机参数渲染的像素对齐的实施例掩模。然后，这些掩模通过 ControlNet 风格的路径注入到预训练的视频生成模型中，该路径将动作控制信号与预测视频对齐，添加特定于视图的调节以适应相机视点，并在各个实施例中生成统一的世界模型架构。为了减轻对静态背景的过度拟合，BridgeV2W 进一步引入了基于流的运动损失，专注于学习动态和任务相关区域。在单臂 (DROID) 和双臂 (AgiBot-G1) 数据集上进行的实验涵盖了具有未见过的视点和场景的多样化且具有挑战性的条件，结果表明，与之前最先进的方法相比，BridgeV2W 提高了视频生成质量。我们进一步展示了 BridgeV2W 在下游现实世界任务中的潜力，包括政策评估和目标条件规划。更多结果可以在我们的项目网站 https://BridgeV2W.github.io 上找到。

- **2026-02-03** **QVLA: Not All Channels Are Equal in Vision-Language-Action Model's Quantization** [2602.03782](http://arxiv.org/abs/2602.03782)
  > 视觉-语言-动作（VLA）模型的出现代表了体现智能的重大飞跃，但其巨大的计算需求严重阻碍了在资源有限的机器人平台上的部署。直观上，低位量化是大规模模型压缩的普遍且首选的技术。然而，我们发现从根本上缺乏对VLA模型量化的系统分析。我们认为，天真地将大型语言模型（LLM）的统一位量化应用于机器人技术是有缺陷的，因为这些方法优先考虑被动数据保真度，而忽略了微小的动作偏差如何导致灾难性的任务失败。为了弥补这一差距，我们引入了 QVLA，这是第一个专门为体现控制而设计的以动作为中心的量化框架。与基于 LLM 的方法的严格、统一位量化截然不同，QVLA 引入了高度粒度、通道方式的位分配策略。其核心机制是将每个单独通道量化为各种位宽时直接测量最终的动作空间灵敏度。此过程产生精确的每通道重要性指标，指导全局优化，从而将量化和修剪（0 位）优雅地统一到一个单一的、有凝聚力的框架中。对不同基线的广泛评估证明了我们方法的优越性。在 LIBERO 中，采用我们方法的 OpenVLA-OFT 量化版本仅需要原始模型 VRAM 的 29.2%，同时保持其原始性能的 98.9%，并实现 1.49 倍的加速。这意味着比 LLM 衍生方法 SmoothQuant 的性能提高了 22.6%。我们的工作为压缩机器人领域的 VLA 模型奠定了新的原则性基础，为在现实世界的硬件上部署强大的大规模模型铺平了道路。代码将被发布。

- **2026-02-03** **LIVE: Long-horizon Interactive Video World Modeling** [2602.03747](http://arxiv.org/abs/2602.03747)
  > 自回归视频世界模型预测以动作为条件的未来视觉观察。虽然这些模型在短期内有效，但在长期生成时往往会遇到困难，因为小的预测误差会随着时间的推移而累积。现有方法通过引入预训练的教师模型和序列级分布匹配来缓解这一问题，但这会产生额外的计算成本，并且无法防止错误传播超出训练范围。在这项工作中，我们提出了 LIVE，一种长视野交互式视频世界模型，它通过新颖的循环一致性目标强制限制误差累积，从而消除了基于教师的蒸馏的需要。具体来说，LIVE 首先从真实帧执行前向推出，然后应用反向生成过程来重建初始状态。随后在重建的最终状态上计算扩散损失，为长范围误差传播提供明确的约束。此外，我们提供包含不同方法的统一观点，并引入渐进式培训课程以稳定培训。实验表明，LIVE 在长期基准测试中实现了最先进的性能，生成了远远超出训练部署长度的稳定、高质量的视频。

- **2026-02-03** **Edge-Optimized Vision-Language Models for Underground Infrastructure Assessment** [2602.03742](http://arxiv.org/abs/2602.03742)
  > 下水道和涵洞系统等地下基础设施的自主检查对于公共安全和城市可持续发展至关重要。尽管配备视觉传感器的机器人平台可以有效地检测结构缺陷，但从这些检测中自动生成人类可读的摘要仍然是一个重大挑战，特别是在资源有限的边缘设备上。本文提出了一种新颖的两级管道，用于对地下缺陷进行端到端总结，将我们的轻量级 RAPID-SCAN 分割模型与部署在边缘计算平台上的微调视觉语言模型（VLM）相结合。第一阶段采用 RAPID-SCAN（使用紧凑自适应网络的资源感知管道检查和缺陷分割），仅用 0.64M 参数即可实现 0.834 F1 分数，实现高效缺陷分割。第二阶段利用经过微调的 Phi-3.5 VLM，从分割输出中以自然语言生成简洁的、特定领域的摘要。我们引入了一个精选的检查图像数据集，其中包含用于 VLM 微调和评估的手动验证的描述。为了实现实时性能，我们采用训练后量化和特定于硬件的优化，在不影响摘要质量的情况下显着减少模型大小和推理延迟。我们在移动机器人平台上部署和评估我们的完整管道，展示其在实际检查场景中的有效性。我们的结果表明，可边缘部署的集成人工智能系统有潜力弥合自动缺陷检测和基础设施维护的可操作见解之间的差距，为更具可扩展性和自主性的检测解决方案铺平道路。

- **2026-02-03** **MVP-LAM: Learning Action-Centric Latent Action via Cross-Viewpoint Reconstruction** [2602.03668](http://arxiv.org/abs/2602.03668)
  > 从不同的人类视频中学习\emph{潜在动作}可以将机器人学习扩展到特定于实施例的机器人数据集之外，并且这些潜在动作最近已被用作视觉语言动作（VLA）模型预训练的伪动作标签。为了使 VLA 预训练有效，潜在动作应该包含有关底层代理动作的信息，尽管没有真实标签。我们提出 \textbf{M}ulti-\textbf{V}iew\textbf{P}oint \textbf{L}atent \textbf{A}ction \textbf{M}odel (\textbf{MVP-LAM})，它学习离散的潜在动作，这些动作对时间同步的多视图视频中的真实动作提供了丰富的信息。 MVP-LAM 以 \emph{跨视点重建} 为目标来训练潜在动作，因此从一个视图推断出的潜在动作必须以另一种视图解释未来，从而减少对特定于视点的线索的依赖。在 Bridge V2 上，MVP-LAM 产生更多以动作为中心的潜在动作，通过真实动作实现更高的互信息并改进动作预测，包括在分布外评估下。最后，使用 MVP-LAM 潜在动作预训练 VLA 提高了 SIMPLER 和 LIBERO-Long 基准上的下游操作性能。

- **2026-02-03** **A Lightweight Library for Energy-Based Joint-Embedding Predictive Architectures** [2602.03604](http://arxiv.org/abs/2602.03604)
  > 我们推出了 EB-JEPA，这是一个使用联合嵌入预测架构 (JEPA) 学习表示和世界模型的开源库。 JEPA 学习在表示空间而不是像素空间中进行预测，避免生成建模的陷阱，同时捕获适合下游任务的语义上有意义的特征。我们的库提供了模块化、独立的实现，说明了为图像级自监督学习开发的表示学习技术如何转移到视频（其中时间动态增加了复杂性），并最终转移到动作条件的世界模型（其中模型必须另外学习预测控制输入的效果）。每个示例都专为在几个小时内进行单 GPU 训练而设计，使基于能量的自我监督学习可用于研究和教育。我们在 CIFAR-10 上提供 JEA 组件的消融。探测这些表示的准确率达到 91%，这表明该模型学习了有用的特征。扩展到视频，我们在 Moving MNIST 上提供了一个多步骤预测示例，演示了相同的原理如何扩展到时间建模。最后，我们展示了这些表示如何驱动动作条件世界模型，从而在两室导航任务中实现 97% 的规划成功率。全面的消融揭示了每个正则化组件对于防止表示崩溃的至关重要性。代码可在 https://github.com/facebookresearch/eb_jepa 获取。

- **2026-02-03** **Multi-Player, Multi-Strategy Quantum Game Model for Interaction-Aware Decision-Making in Autonomous Driving** [2602.03571](http://arxiv.org/abs/2602.03571)
  > 尽管自动驾驶的决策已经取得了重大进展，但在现实世界中的部署仍然面临挑战。一项挑战在于解决交互意识。大多数现有方法过度简化了自我车辆与周围代理之间的交互，并且经常忽略代理本身之间的交互。常见的解决方案是使用经典博弈论对这些交互进行建模。然而，它的表述假设参与者是理性的，而人类的行为往往是不确定或非理性的。为了应对这些挑战，我们提出了量子博弈决策（QGDM）模型，这是一种将经典博弈论与量子力学原理（例如叠加、纠缠和干扰）相结合的新颖框架，用于解决多人、多策略决策问题。据我们所知，这是最早将量子博弈论应用于自动驾驶决策的研究之一。 QGDM 在标准计算机上实时运行，无需量子硬件。我们在各种场景（包括环岛、合并和高速公路）的模拟中评估 QGDM，并将其性能与多种基线方法进行比较。结果表明，与经典方法相比，QGDM 显着提高了成功率并降低了冲突率，特别是在交互性较高的场景中。

- **2026-02-03** **EHRWorld: A Patient-Centric Medical World Model for Long-Horizon Clinical Trajectories** [2602.03569](http://arxiv.org/abs/2602.03569)
  > 世界模型为模拟干预下的未来状态提供了一个原则框架，但在医学等复杂、高风险的领域实现此类模型仍然具有挑战性。最近的大语言模型（LLM）在静态医学推理任务上取得了出色的表现，这引发了一个问题：它们是否可以作为能够模拟疾病进展和治疗结果随时间变化的动态医学世界模型。在这项工作中，我们表明，仅结合医学知识的法学硕士很难在连续干预下维持一致的患者状态，导致长期临床模拟中的错误累积。为了解决这一限制，我们引入了 EHRWorld（一种在因果顺序范式下训练的以患者为中心的医学世界模型）以及 EHRWorld-110K（源自真实世界电子健康记录的大规模纵向临床数据集）。广泛的评估表明，EHRWorld 显着优于基于 LLM 的原始基线，实现了更稳定的长期模拟，改进了临床敏感事件的建模，并提高了推理效率，强调了基于因果关系、随时间变化的临床数据进行训练的必要性，以实现可靠和稳健的医学世界建模。

- **2026-02-03** **A Minimal Task Reveals Emergent Path Integration and Object-Location Binding in a Predictive Sequence Model** [2602.03490](http://arxiv.org/abs/2602.03490)
  > 适应性认知需要表示对象及其关系的结构化内部模型。预测神经网络经常被提出来形成这样的“世界模型”，但其潜在机制仍不清楚。一种假设是，动作条件序列预测足以学习这样的世界模型。在这项工作中，我们在最小的计算机环境中研究了这种可能性。从 2D 连续令牌场景中顺序采样令牌，训练循环神经网络以根据当前输入和类似扫视的位移来预测即将到来的令牌。在新颖的场景中，整个序列的预测准确性得到提高，这表明上下文学习。解码分析揭示了路径整合以及令牌身份与位置的动态绑定。介入分析表明，可以在序列后期学习新的结合，并且可以学习分布外的结合。总之，这些结果证明了依赖于灵活绑定的结构化表示如何出现来支持预测，从而提供了与认知科学相关的顺序世界建模的机械解释。

- **2026-02-03** **HetroD: A High-Fidelity Drone Dataset and Benchmark for Autonomous Driving in Heterogeneous Traffic** [2602.03447](http://arxiv.org/abs/2602.03447)
  > 我们推出 HetroD，这是一个用于在异构环境中开发自动驾驶系统的数据集和基准。 HetroD 的目标是应对由弱势道路使用者 (VRU) 主导的现实世界异构交通的严峻挑战，其中包括与车辆互动的行人、骑自行车的人和骑摩托车的人。这些混合代理类型表现出复杂的行为，例如弯道、分道和非正式的路权协商。这些行为给自动驾驶汽车带来了重大挑战，但在专注于结构化、车道管制交通的现有数据集中仍然代表性不足。为了弥补这一差距，我们收集了基于无人机的大规模数据集，通过厘米级精确的注释、高清地图和交通信号状态来提供对交通场景的整体观察。我们进一步开发了一个模块化工具包，用于提取每个代理场景以支持下游任务开发。该数据集总共包含超过 65.4k 个高保真智能体轨迹，其中 70% 来自 VRU。 HetroD 支持对密集、异构流量中的 VRU 行为进行建模，并为预测、规划和模拟任务提供标准化基准。评估结果表明，最先进的预测和规划模型正在努力应对我们的数据集带来的挑战：它们无法预测横向 VRU 运动，无法处理非结构化操作，并且在密集和多智能体场景中表现出有限的性能，这凸显了对异构流量更强大的方法的需求。有关更多示例，请参阅我们的项目页面：https://hetroddata.github.io/HetroD/


<p align=right>(<a href=#updated-on-20260209>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

