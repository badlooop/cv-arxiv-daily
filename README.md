[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.11.22
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-11-15**|**SPARS3R: Semantic Prior Alignment and Regularization for Sparse 3D Reconstruction**|最近在基于高斯Splat的新视图合成方面的努力可以实现逼真的渲染；然而，由于稀疏初始化和过度拟合浮点数，这种能力在稀疏视图场景中是有限的。深度估计和对齐的最新进展可以提供视图很少的密集点云；然而，由此产生的姿态精度不是最优的。在这项工作中，我们提出了SPARS3R，它结合了运动结构的精确姿态估计和深度估计的密集点云的优点。为此，SPARS3R首先执行全局融合对齐过程，该过程基于三角化对应关系将先前的密集点云映射到来自运动结构的稀疏点云。在此过程中应用RANSAC来区分内值和外值。SPARS3R然后执行第二个语义异常值对齐步骤，该步骤提取异常值周围的语义连贯区域，并在这些区域中执行局部对齐。随着评估过程的几项改进，我们证明SPARS3R可以实现稀疏图像的真实感渲染，并且明显优于现有方法。 et.al.|[2411.12592](http://arxiv.org/abs/2411.12592)|**[link](https://github.com/snldmt/SPARS3R)**|
|**2024-11-19**|**PR-ENDO: Physically Based Relightable Gaussian Splatting for Endoscopy**|内窥镜手术对癌症的诊断至关重要，三维重建环境以实时合成新视图可以显著提高诊断水平。我们提出了PR-ENDO，这是一个在基于物理的、可重新照明的模型中利用3D高斯散斑的框架，该模型专为内窥镜中的复杂采集条件而定制，例如受限的相机旋转和强烈的视图依赖照明。通过利用相机和光源之间的连接，我们的方法引入了一个重新照明模型，使用基于物理的渲染和MLP来捕捉光和组织之间的复杂相互作用。现有的方法在这些条件下通常会产生伪影和不一致性，PR-ENDO通过结合利用光角度和法向量的专用漫反射MLP来克服这些问题，即使在有限的训练相机旋转下也能实现稳定的重建。我们使用公开可用的数据集和新引入的具有更宽相机旋转的数据集对我们的框架进行了基准测试。与基线方法相比，我们的方法显示出卓越的图像质量。 et.al.|[2411.12510](http://arxiv.org/abs/2411.12510)|**[link](https://github.com/SanoScience/PR-ENDO)**|
|**2024-11-20**|**Beyond Gaussians: Fast and High-Fidelity 3D Splatting with Linear Kernels**|3D高斯散斑（3DGS）的最新进展大大改善了新颖的视图合成，实现了高质量的重建和实时渲染。然而，模糊伪影，如浮动基元和过度重建，仍然具有挑战性。当前的方法通过细化场景结构、增强几何表示、解决训练图像中的模糊、提高渲染一致性和优化密度控制来解决这些问题，但内核设计的作用仍未得到充分探索。我们确定高斯椭球体的软边界是这些伪影的原因之一，限制了高频区域的细节捕捉。为了弥合这一差距，我们引入了3D线性散布（3DLS），它用线性核替换高斯核，以获得更清晰、更精确的结果，特别是在高频区域。通过对三个数据集的评估，3DLS展示了最先进的保真度和准确性，以及比基线3DGS提高30%的FPS。该实施将在接受后公开。 et.al.|[2411.12440](http://arxiv.org/abs/2411.12440)|null|
|**2024-11-20**|**DGTR: Distributed Gaussian Turbo-Reconstruction for Sparse-View Vast Scenes**|新的视图合成（NVS）方法在大规模场景重建中起着至关重要的作用。然而，这些方法严重依赖于密集的图像输入和长时间的训练，使得它们不适合计算资源有限的地方。此外，在广阔的环境中，很少有拍摄方法会遇到重建质量差的问题。本文提出了DGTR，这是一种新的分布式框架，用于稀疏视图广阔场景的高效高斯重建。我们的方法将场景划分为多个区域，由具有稀疏图像输入的无人机独立处理。使用前馈高斯模型，我们预测高质量的高斯基元，然后使用全局对齐算法来确保几何一致性。综合视图和深度先验被纳入以进一步增强训练，而基于蒸馏的模型聚合机制能够实现高效的重建。我们的方法在显著减少的训练时间内实现了高质量的大规模场景重建和新颖的视图合成，在速度和可扩展性方面都优于现有方法。我们在广阔的空中场景中展示了我们的框架的有效性，在几分钟内实现了高质量的结果。代码将在我们的[https://3d-aigc.github.io/DGTR]. et.al.|[2411.12309](http://arxiv.org/abs/2411.12309)|null|
|**2024-11-19**|**LiV-GS: LiDAR-Vision Integration for 3D Gaussian Splatting SLAM in Outdoor Environments**|我们介绍了LiV GS，这是一种户外环境中的LiDAR视觉SLAM系统，它利用3D高斯作为可微分的空间表示。值得注意的是，LiV-GS是第一种在大规模室外场景中直接将离散和稀疏LiDAR数据与连续可微高斯地图对齐的方法，克服了传统LiDAR测绘中固定分辨率的局限性。该系统使用共享的协方差属性进行前端跟踪，将点云与高斯图对齐，并将法线方向整合到损失函数中以细化高斯图。为了在激光雷达视场外可靠稳定地更新高斯分布，我们引入了一种新的条件高斯约束，将这些高斯分布与最近的可靠分布紧密对齐。目标调整使LiV GS能够以7.98 FPS的速率通过新颖的视图合成实现快速准确的映射。广泛的对比实验证明了LiV-GS在SLAM、图像渲染和映射方面的卓越性能。成功的跨模态雷达LiDAR定位突显了LiV GS在跨模态语义定位和高斯图对象分割中的应用潜力。 et.al.|[2411.12185](http://arxiv.org/abs/2411.12185)|null|
|**2024-11-18**|**SpatialDreamer: Self-supervised Stereo Video Synthesis from Monocular Input**|单目输入的立体视频合成是空间计算和虚拟现实领域的一项艰巨任务。这项任务的主要挑战在于用于训练的高质量配对立体视频不足，以及难以保持帧之间的时空一致性。现有的方法主要通过将新颖的视图合成（NVS）技术直接应用于视频来解决这些问题，同时面临着无法有效地表示动态场景和需要大量训练数据等局限性。本文介绍了一种新的通过视频扩散模型的自监督立体视频合成范式，称为SpatialDreamer，它正面应对了挑战。首先，为了解决立体视频数据不足的问题，我们提出了一种基于深度的视频生成模块DVG，该模块采用前向后向渲染机制生成具有几何和时间先验的配对视频。利用DVG生成的数据，我们提出了RefinerNet以及一个自我监督的综合框架，旨在促进高效和专门的培训。更重要的是，我们设计了一个一致性控制模块，该模块由立体偏差强度度量和时间交互学习模块TIL组成，分别用于几何和时间一致性保证。我们根据各种基准方法对提出的方法进行了评估，结果显示了其优越的性能。 et.al.|[2411.11934](http://arxiv.org/abs/2411.11934)|null|
|**2024-11-16**|**DiHuR: Diffusion-Guided Generalizable Human Reconstruction**|我们介绍了DiHuR，这是一种新的扩散引导模型，用于从稀疏、最小重叠的图像中进行可推广的人体3D重建和视图合成。虽然现有的可推广的人类辐射场在新颖的视图合成方面表现出色，但它们往往难以进行全面的3D重建。同样，由于重叠有限，直接优化稀疏视图图像中的隐式有符号距离函数（SDF）场通常会产生较差的结果。为了提高3D重建质量，我们建议使用与SMPL顶点相关的可学习标记来聚合稀疏视图特征，然后指导SDF预测。这些标记学习训练数据集中不同身份的可泛化先验，利用SMPL顶点在各种人类身份的相似语义区域上的一致投影。这种一致性使得在推理过程中能够有效地将知识转移到看不见的身份。认识到SMPL在捕捉服装细节方面的局限性，我们引入了一个扩散模型作为补充，以填补缺失的信息，特别是对于复杂的服装几何形状。我们的方法以连贯的方式集成了两个关键先验：来自可推广前馈模型的先验和2D扩散先验，它只需要多视图图像训练，不需要3D监督。与现有方法相比，DiHuR在数据集内和跨数据集泛化设置中表现出卓越的性能，这在THuman、ZJU MoCap和HuMMan数据集上得到了验证。 et.al.|[2411.11903](http://arxiv.org/abs/2411.11903)|null|
|**2024-11-18**|**GPS-Gaussian+: Generalizable Pixel-wise 3D Gaussian Splatting for Real-Time Human-Scene Rendering from Sparse Views**|微分渲染技术最近在字符的自由视点视频合成方面显示出了有前景的结果。然而，无论是高斯散点还是神经隐式渲染，这些方法通常都需要针对每个主题进行优化，这不符合交互式应用程序中实时渲染的要求。我们提出了一种可推广的高斯散斑方法，用于稀疏视图相机设置下的高分辨率图像渲染。为此，我们引入了在源视图上定义的高斯参数映射，并直接回归高斯属性，用于即时新视图合成，而无需任何微调或优化。我们在纯人类数据或人类场景数据上训练高斯参数回归模块，并与深度估计模块联合将2D参数图提升到3D空间。所提出的框架在深度和渲染监督或仅渲染监督方面都是完全可区分的。我们进一步引入了正则化项和极线注意机制，以保持两个源视图之间的几何一致性，特别是在忽略深度监督的情况下。在几个数据集上的实验表明，我们的方法优于最先进的方法，同时实现了超高的渲染速度。 et.al.|[2411.11363](http://arxiv.org/abs/2411.11363)|null|
|**2024-11-17**|**Direct and Explicit 3D Generation from a Single Image**|当前的图像到3D方法存在计算成本高和缺乏高分辨率输出的可扩展性的问题。相比之下，我们引入了一种新的框架，使用多视图2D深度和RGB图像以及使用重新调整用途的稳定扩散模型的3D高斯特征直接生成显式的表面几何和纹理。我们在U-Net中引入了一个深度分支，用于高效和高质量的多视图、跨域生成，并将极线注意力纳入潜在的像素级多视图一致性解码器中。通过将生成的深度像素反向投影到3D空间中，我们创建了一个结构化的3D表示，该表示可以通过高斯散点渲染或提取到高质量网格中，从而利用额外的新颖视图合成损失来进一步提高我们的性能。大量实验表明，我们的方法在几何和纹理质量方面超越了现有的基线，同时实现了显著更快的生成时间。 et.al.|[2411.10947](http://arxiv.org/abs/2411.10947)|null|
|**2024-11-16**|**DGS-SLAM: Gaussian Splatting SLAM in Dynamic Environment**|我们介绍了动态高斯散斑SLAM（DGS-SLAM），这是第一个建立在高斯散斑基础上的动态SLAM框架。虽然密集SLAM的最新进展利用高斯散斑来增强场景表示，但大多数方法都假设是静态环境，这使得它们容易受到动态对象引起的光度和几何不一致的影响。为了应对这些挑战，我们将高斯散斑SLAM与稳健的滤波过程相结合，以处理整个管道中的动态对象，包括高斯插入和关键帧选择。在此框架内，为了进一步提高动态对象去除的准确性，我们引入了一种鲁棒的掩模生成方法，该方法在关键帧之间强制实现光度一致性，减少了不准确分割和阴影等伪影的噪声。此外，我们提出了循环感知窗口选择机制，该机制利用3D高斯的唯一关键帧ID来检测当前帧和过去帧之间的循环，从而促进当前相机姿态和高斯图的联合优化。DGS-SLAM在各种动态SLAM基准上实现了最先进的相机跟踪和新颖的视图合成性能，证明了其在处理现实世界动态场景方面的有效性。 et.al.|[2411.10722](http://arxiv.org/abs/2411.10722)|null|

<p align=right>(<a href=#updated-on-20241122>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-11-20**|**Open-World Amodal Appearance Completion**|理解和重建被遮挡的对象是一个具有挑战性的问题，特别是在类别和背景多样且不可预测的开放世界场景中。然而，传统方法通常仅限于封闭的对象类别集，限制了它们在复杂的开放世界场景中的使用。我们介绍了Open World Amodal Appearance Completion，这是一个无需训练的框架，通过接受灵活的文本查询作为输入来扩展Amodal补全功能。我们的方法推广到由直接项和抽象查询指定的任意对象。我们将这种能力推理称为amodal完成，其中系统根据提供的图像和语言查询重建查询对象的完整外观。我们的框架统一了分割、遮挡分析和修复，以处理复杂的遮挡，并将完成的对象生成为RGBA元素，从而能够无缝集成到3D重建和图像编辑等应用程序中。广泛的评估证明了我们的方法在推广到新物体和遮挡物方面的有效性，为开放世界环境中的无模完成建立了新的基准。代码和数据集将在论文验收后发布。 et.al.|[2411.13019](http://arxiv.org/abs/2411.13019)|null|
|**2024-11-20**|**M3D: Dual-Stream Selective State Spaces and Depth-Driven Framework for High-Fidelity Single-View 3D Reconstruction**|在复杂场景中从单个RGB图像精确重建3D对象是虚拟现实、自动驾驶和机器人技术的一个关键挑战。现有的神经隐式3D表示方法在平衡全局和局部特征的提取方面面临着重大困难，特别是在多样化和复杂的环境中，导致重建精度和质量不足。我们提出了M3D，一种新颖的单视图3D重建框架，以应对这些挑战。该框架采用基于选择性状态空间的双流特征提取策略，有效地平衡了全局和局部特征的提取，从而提高了场景理解和表示精度。此外，并行分支提取深度信息，有效地整合视觉和几何特征，以提高重建质量并保留复杂的细节。实验结果表明，通过双分支特征提取将多尺度特征与深度信息融合，显著提高了几何一致性和保真度，实现了最先进的重建性能。 et.al.|[2411.12635](http://arxiv.org/abs/2411.12635)|**[link](https://github.com/AnnnnnieZhang/M3D)**|
|**2024-11-19**|**3D Reconstruction by Looking: Instantaneous Blind Spot Detector for Indoor SLAM through Mixed Reality**|室内SLAM经常遇到场景漂移、双墙和盲点等问题，特别是在重建任务中物体靠近传感器（如LiDAR和摄像头）的密闭空间中。数据收集期间点云注册的实时可视化可能有助于缓解这些问题，但无法将扫描数据与实际物理环境进行深入比较仍然是一个重大限制。这些挑战阻碍了重建产品的质量，经常需要重新审视和重新扫描。为此，我们开发了LiMRSF（LiDAR MR RGB传感器融合）系统，允许用户通过混合现实（MR）耳机查看来感知现场点云注册。这个定制的框架将点云网格可视化为全息图，与透视眼镜上的实时场景无缝匹配，并自动突出显示重叠时检测到的错误。这种全息元素通过TCP服务器传输到MR耳机，在那里进行校准，使其与世界坐标、物理位置对齐。这允许用户即时查看本地化的重建产品，使他们能够快速识别盲点和错误，并在现场迅速采取行动。我们的盲点检测器实现了错误检测精度，F1分数为75.76%，通过LiMRSF系统实现了可接受的高保真度监测（在简化网格模型的五个不同部分中，最高SSIM为0.5619，PSNR为14.1004，最低MSE为0.0389，用户通过LiMRSF设备透过眼镜进行可视化）。这种方法可确保为3D模型创建详细、高质量的数据集，在建筑信息建模（BIM）中具有潜在的应用，但不仅限于此。 et.al.|[2411.12514](http://arxiv.org/abs/2411.12514)|null|
|**2024-11-19**|**Target Height Estimation Using a Single Acoustic Camera for Compensation in 2D Seabed Mosaicking**|这封信提出了一种补偿二维海底拼接中目标高度数据的新方法，用于低能见度水下感知。由于其高分辨率成像能力和对黑暗和浑浊的鲁棒性，声相机是感知海洋环境的有效传感器。然而，成像过程中仰角的损失导致原始声相机图像中缺乏目标高度信息，导致海底拼接的二维表示过于简单。在感知杂乱和未经探索的海洋环境时，目标高度数据对于避免与海洋机器人碰撞至关重要。本研究提出了一种使用单个声相机估计海底目标高度的新方法，并将高度数据整合到二维海底拼接中，以补偿海底目标缺失的三维维度。与模拟仰角损失以实现海底三维重建的经典方法不同，本研究侧重于利用可用的声投射阴影线索和简单的传感器运动来快速估计目标高度。通过水箱实验和模拟实验验证了我们建议的可行性。 et.al.|[2411.12338](http://arxiv.org/abs/2411.12338)|null|
|**2024-11-19**|**MTFusion: Reconstructing Any 3D Object from Single Image Using Multi-word Textual Inversion**|从单视图图像重建3D模型是计算机视觉中一个长期存在的问题。单图像3D重建的最新进展是从输入图像中提取文本描述，并进一步利用它来合成3D模型。然而，现有的方法侧重于捕捉图像的单个关键属性（例如，对象类型、艺术风格），而没有考虑到精确3D重建所需的多视角信息，如对象形状和材料属性。此外，对神经辐射场的依赖阻碍了它们重建复杂表面和纹理细节的能力。在这项工作中，我们提出了MTFusion，它利用图像数据和文本描述进行高保真3D重建。我们的方法包括两个阶段。首先，我们采用了一种新颖的多词文本反转技术来提取捕获图像特征的详细文本描述。然后，我们使用此描述和图像使用FlexiCubes生成3D模型。此外，MTFusion通过为有符号距离函数采用特殊的解码器网络来增强FlexiCubes，从而实现更快的训练和更精细的表面表示。广泛的评估表明，我们的MTFusion在广泛的合成和现实世界图像上超越了现有的图像到3D方法。此外，消融研究证明了我们网络设计的有效性。 et.al.|[2411.12197](http://arxiv.org/abs/2411.12197)|null|
|**2024-11-18**|**Towards Degradation-Robust Reconstruction in Generalizable NeRF**|跨场景的广义神经辐射场（GNeRF）已被证明是一种有效的方法，通过用源图像的深度图像特征表示场景来避免每场景优化。然而，尽管GNeRF具有现实应用的潜力，但关于其对源图像中存在的不同类型退化的鲁棒性的研究有限。缺乏此类研究的主要原因是缺乏适合训练退化鲁棒可推广NeRF模型的大规模数据集。为了解决这一差距并促进对3D重建任务退化鲁棒性的研究，我们构建了Objaverse模糊数据集，该数据集包含来自1000多个设置的50000张图像，具有多个级别的模糊退化。此外，我们设计了一个简单且与模型无关的模块，用于增强GNeRF的退化鲁棒性。具体而言，通过轻量级深度估计器和去噪器提取3D感知特征，所提出的模块在不同退化类型和水平下，在定量和视觉质量方面都比GNeRF中的不同流行方法有所改进。我们的数据集和代码将公开。 et.al.|[2411.11691](http://arxiv.org/abs/2411.11691)|null|
|**2024-11-18**|**VLN-Game: Vision-Language Equilibrium Search for Zero-Shot Semantic Navigation**|遵循人类指令在陌生环境中探索和搜索指定目标是移动服务机器人的一项关键技能。之前关于目标导航的大部分工作通常都集中在单一输入模态作为目标上，这可能会导致对包含详细属性和空间关系的语言描述的考虑有限。为了解决这一限制，我们提出了VLN-Game，这是一种新的用于视觉目标导航的零样本框架，可以有效地处理对象名称和描述性语言目标。更精确地说，我们的方法通过将预训练的视觉语言特征与物理环境的3D重建相结合，构建了一个以3D对象为中心的空间地图。然后，该框架确定了最有希望探索的领域，以寻找潜在的目标候选者。采用博弈论视觉语言模型来确定哪个目标与给定的语言描述最匹配。在Habitat Matterport 3D（HM3D）数据集上进行的实验表明，所提出的框架在目标导航和基于语言的导航任务中都达到了最先进的性能。此外，我们证明了VLN Game可以很容易地部署在现实世界的机器人上。VLN-Game的成功凸显了使用博弈论方法和紧凑的视觉语言模型来提高机器人系统决策能力的巨大潜力。可以通过以下链接访问补充视频和代码：https://sites.google.com/view/vln-game. et.al.|[2411.11609](http://arxiv.org/abs/2411.11609)|null|
|**2024-11-17**|**BVI-CR: A Multi-View Human Dataset for Volumetric Video Compression**|沉浸式技术和3D重建的进步使得能够创建具有精细细节的现实世界物体和环境的数字复制品。这些过程会生成大量的3D数据，需要更有效的压缩方法来满足与数据存储和传输相关的内存和带宽限制。然而，有效的3D数据压缩方法的开发和验证受到缺乏全面和高质量的体视频数据集的限制，与2D图像和视频数据库相比，这通常需要付出更多的努力来获取和消耗更多的资源。为了弥合这一差距，我们提出了一个开放的多视图体积人体数据集，称为BVI-CR，其中包含18个多视图RGB-D捕获及其相应的纹理多边形网格，描绘了一系列不同的人体动作。每个视频序列包含10个1080p分辨率的视图，持续时间为10-15秒，帧率为30FPS。使用BVI-CR，我们按照MPEG MIV通用测试条件，对三种传统的基于神经坐标的多视图视频压缩方法进行了基准测试，并根据各种质量指标报告了它们的速率质量性能。结果表明，与传统的视频编码方法相比，基于神经表示的方法在体视频压缩中具有巨大的潜力（PSNR平均编码增益高达38%）。该数据集为各种任务提供了一个开发和验证平台，包括体积重建、压缩和质量评估。数据库将在\url公开共享{https://github.com/fan-aaron-zhang/bvi-cr}. et.al.|[2411.11199](http://arxiv.org/abs/2411.11199)|null|
|**2024-11-16**|**ARM: Appearance Reconstruction Model for Relightable 3D Generation**|最近的图像到3D重建模型极大地改进了几何生成，但它们仍然难以忠实地生成逼真的外观。为了解决这个问题，我们引入了ARM，这是一种从稀疏视图图像重建高质量3D网格和逼真外观的新方法。ARM的核心在于将几何与外观解耦，在UV纹理空间内处理外观。与以前的方法不同，ARM通过明确地将测量值反向投影到纹理贴图上，并在具有全局感受野的UV空间模块中对其进行处理，从而提高了纹理质量。为了解决输入图像中材质和光照之间的歧义，ARM引入了一种材质先验，对语义外观信息进行编码，增强了外观分解的鲁棒性。仅在8个H100 GPU上训练，ARM在数量和质量上都优于现有方法。 et.al.|[2411.10825](http://arxiv.org/abs/2411.10825)|null|
|**2024-11-16**|**Poster: Reliable 3D Reconstruction for Ad-hoc Edge Implementations**|支持实时复杂视频处理应用程序（如多视图3D重建）的自组织边缘部署通常会受到时空系统中断的影响，这会极大地影响重建质量。在这篇海报论文中，我们提出了一种受投资组合理论启发的边缘资源管理策略，通过考虑可能的系统中断来确保可靠的多视图3D重建。 et.al.|[2411.10705](http://arxiv.org/abs/2411.10705)|null|

<p align=right>(<a href=#updated-on-20241122>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-11-20**|**REDUCIO! Generating 1024 $\times$ 1024 Video within 16 Seconds using Extremely Compressed Motion Latents**|商业视频生成模型已经显示出逼真、高保真的结果，但仍然受限于有限的访问。大规模应用的一个关键障碍是昂贵的训练和推理成本。在本文中，我们认为视频包含的冗余信息比图像多得多，因此可以基于内容图像用很少的运动延迟进行编码。为了实现这一目标，我们设计了一种图像条件VAE，将视频编码到极度压缩的运动潜在空间。与普通的2D VAE相比，这款神奇的Reducio魅力可以将延迟减少64倍，而不会牺牲质量。在这种紧凑的表示上训练扩散模型很容易生成1K分辨率的视频。然后，我们采用两阶段视频生成范式，依次执行文本到图像和文本图像到视频。广泛的实验表明，我们的Reducio DiT在评估中表现出色，尽管使用有限的GPU资源进行训练。更重要的是，我们的方法显著提高了视频LDM在训练和推理方面的效率。我们总共在大约3.2K个训练小时内训练了Reducio DiT，并在单个A100 GPU上在15.5秒内生成了一个16帧1024*1024的视频片段。代码发布于https://github.com/microsoft/Reducio-VAE . et.al.|[2411.13552](http://arxiv.org/abs/2411.13552)|**[link](https://github.com/microsoft/reducio-vae)**|
|**2024-11-20**|**A Survey of H I and O VI Absorption Lines in the Outskirts of $z\lesssim0.3$ Galaxy Clusters**|星系团远郊（r$>$2-3 r$_{200}$）的团内介质（ICM）与星系间介质（IGM）相互作用，理论上由弥漫的多相气体组成。这种介质可能为星系团的热力学演化以及对未来星系团的深远影响提供了重要线索。星团的漫射郊区非常适合类星体吸收线观测，能够探测到极低柱密度的气体。我们分析了哈勃太空望远镜上的宇宙起源光谱仪观测到的18个QSO光谱，其视线追踪了26个星系团的气体环境，投影范围在R$_{200}$到6R$_{100}$之间。我们测量了与前景簇相关的H I和O VI的dN/dz和覆盖分数，作为归一化影响参数的函数。我们发现H I的dN/dz与所有冲击参数箱的IGM场值一致，在2到3 R$_{200}$之间有一个有趣的轻微升高。O VI的dN/dz也与所有冲击参数箱的现场值（在3$\sigma$范围内）一致，dN/dz的潜在升高在1-2R$_{200}$范围内，在$>2\sigma$$时超过4R$_{100}$ 。我们提出了可能导致这些试探性过度的物理场景，例如外吸积激波前沿中性气体的积聚和温热IGM的特征。在检测到O VI的视线附近，我们没有发现系统性过剩的潜在关联星系；因此，检测到的O VI没有明确的环星系起源。 et.al.|[2411.13551](http://arxiv.org/abs/2411.13551)|null|
|**2024-11-20**|**HF-Diff: High-Frequency Perceptual Loss and Distribution Matching for One-Step Diffusion-Based Image Super-Resolution**|尽管与SinSR相比，最近基于扩散的单步超分辨率方法实现了更好的性能，但它们的计算复杂。为了提高SinSR的性能，我们研究了在超分辨率（SR）期间保留高频细节特征，因为降级图像缺乏详细信息。为此，我们利用在ImageNet数据集上预训练的可逆神经网络（INN）引入了高频感知损失。预训练INN的不同特征图会产生图像的不同高频方面。在训练阶段，我们强制保留超分辨率和地面真实（GT）图像的高频特征，以提高推理过程中的SR图像质量。此外，我们还利用预训练DINO-v2嵌入空间中GT和SR图像之间的Jenson-Shannon散度来匹配它们的分布。通过引入 $\textbf{h}igh$-$\textbf{f}requency$在单步$\textbf中保留损失和分布匹配约束{diff}usion-based$SR（$\textbf{HF Diff}$ ），我们在基准RealSR、RealSet65、DIV2K Val和ImageNet数据集中获得了最先进的CLIPIQA分数。此外，在几个数据集中的实验结果表明，我们的高频感知损失比基于LPIPS和VGG的感知损失产生了更好的SR图像质量。我们的代码将在https://github.com/shoaib-sami/HF-Diff. et.al.|[2411.13548](http://arxiv.org/abs/2411.13548)|null|
|**2024-11-20**|**Identity Preserving 3D Head Stylization with Multiview Score Distillation**|3D头部风格化将逼真的面部特征转化为艺术表现，增强了游戏和虚拟现实应用程序的用户参与度。虽然3D感知生成器已经取得了重大进展，但许多3D样式化方法主要提供近正面视图，并难以保留原始对象的独特身份，这往往导致输出缺乏多样性和个性。本文通过利用PanoHead模型，从全面的360度视角合成图像来解决这些挑战。我们提出了一种新的框架，该框架采用负对数似然蒸馏（LD）来增强身份保存并提高风格化质量。通过在3D GAN架构中集成多视图网格分数和镜像梯度，并引入分数排名加权技术，我们的方法实现了实质性的定性和定量改进。我们的研究结果不仅推进了3D头部样式化的状态，还为扩散模型和GAN之间的有效蒸馏过程提供了有价值的见解，重点关注身份保护的关键问题。请访问https://three-bee.github.io/head_stylization为了获得更多的视觉效果。 et.al.|[2411.13536](http://arxiv.org/abs/2411.13536)|null|
|**2024-11-20**|**Dense Suspensions in Rotary Shear**|我们介绍了一种新的非定常剪切协议，我们称之为旋转剪切（RS），其中通过在正交方向上施加两个异相振荡剪切（OS），使流动和涡旋方向围绕速度梯度方向连续旋转。我们根据这种新的RS协议对体积分数（ $\phi$）在0.40和0.55之间的刚性非布朗球形颗粒的稠密悬浮液进行了数值模拟，并与经典的OS协议进行了比较。我们发现，随着应变幅度（$\gamma_0$）的增加，悬浮液粘度显示出类似的非单调响应：在中间的、体积分数相关的应变幅度处发现了最小粘度。然而，新协议中的悬架动力学是不同的。与OS协议不同，RS下的悬浮液在任何$\gamma_0$ 处都不显示自吸附状态，也不经历可逆不可逆转变：频闪粒子动力学总是扩散的，我们将其归因于RS协议是不可逆的。为了验证这一假设，我们引入了一种可逆RS（RRS）协议，即RS和OS的组合，在该协议中，我们旋转剪切方向（如RS），直到它瞬间反转（如OS），并发现由此产生的流变学和动力学更接近OS。详细的微观结构分析表明，OS和RRS协议都会在动态可逆到不可逆的转变中产生无接触、各向同性到接触、各向异性的微观结构。RS协议没有呈现这种转变，并且对于所有应变幅度，动力学保持扩散，具有接触的各向异性微观结构。 et.al.|[2411.13463](http://arxiv.org/abs/2411.13463)|null|
|**2024-11-20**|**Sampling and Integration of Logconcave Functions by Algorithmic Diffusion**|我们研究了任意对数凹函数的采样、舍入和积分的复杂性。我们的新方法为所有三个问题的一般对数凹函数提供了近二十年来首次复杂性改进，并与凸体上均匀分布的特殊情况下最著名的复杂性相匹配。对于抽样问题，我们的输出保证比以前已知的要强得多，并导致基于依赖随机样本的统计估计的简化分析。 et.al.|[2411.13462](http://arxiv.org/abs/2411.13462)|null|
|**2024-11-20**|**From Prompt Engineering to Prompt Craft**|这张图片展示了一个正在进行的研究项目，包括到2024年进行的三个基于实践的设计研究项目，探索基于扩散的人工智能图像生成系统的启示，特别是稳定扩散。该研究采用有形和有形的互动来研究生成性人工智能的新兴定性方面，包括不确定性和物质性。我们的方法利用设计研究的灵活性和适应性来驾驭快速发展的生成人工智能领域。该图提出了快速工艺的概念，作为对快速工程的有效重构。这包括两个贡献：（1）对基于扩散的生成人工智能的物质性概念的反思，以及对生成人工智能模型中潜在空间的类似工艺导航的建议方法；（2）讨论了根据这些启示设计用户界面的交互设计策略。结果以强有力的概念或中间知识的形式呈现，适用于各种情况和领域。 et.al.|[2411.13422](http://arxiv.org/abs/2411.13422)|null|
|**2024-11-20**|**Heuristically Adaptive Diffusion-Model Evolutionary Strategy**|扩散模型代表了生成建模的一个重大进步，它采用了一种双相过程，首先通过高斯噪声对特定领域的信息进行降级，然后通过可训练的模型进行恢复。该框架支持纯噪声数据生成和图像或视频的模块化重建。同时，进化算法采用受生物学原理启发的优化方法来改进编码粗糙目标函数潜在解的数值参数集。我们的研究揭示了扩散模型和进化算法之间通过其共享的底层生成机制的基本联系：这两种方法都通过对随机初始分布的迭代细化来生成高质量的样本。通过使用基于深度学习的扩散模型作为跨不同进化任务的生成模型，并使用启发式获取的数据库迭代地改进扩散模型，我们可以迭代地对可能适应更好的后代参数进行采样，并将其整合到扩散模型的连续几代中。这种方法在保持探索多样性的同时，实现了向高适应度参数的有效收敛。扩散模型将增强的记忆能力引入进化算法，跨代保留历史信息，并利用微妙的数据相关性生成精细的样本。我们将进化算法从具有浅层启发式的过程提升到具有深层记忆的框架。通过在参数级别部署无分类器的条件采样指导，我们实现了对进化搜索动态的精确控制，以进一步实现特定的基因型、表型或全群体特征。我们的框架标志着启发式和算法的重大转变，在进化优化过程中提供了更高的灵活性、精度和控制。 et.al.|[2411.13420](http://arxiv.org/abs/2411.13420)|null|
|**2024-11-20**|**Adversarial Diffusion Compression for Real-World Image Super-Resolution**|真实世界图像超分辨率（Real ISR）旨在从因复杂未知过程而退化的低分辨率输入中重建高分辨率图像。虽然许多基于稳定扩散（SD）的Real ISR方法取得了显著的成功，但它们缓慢的多步推理阻碍了实际部署。最近基于SD的一步网络，如OSEDiff和S3Diff，缓解了这个问题，但由于它们依赖于大型预训练SD模型，仍然会产生高昂的计算成本。本文提出了一种新的Real ISR方法AdcSR，该方法在我们的对抗扩散压缩（ADC）框架下将一步扩散网络OSEDiff提取为流线型扩散GAN模型。我们仔细检查了OSEDiff的模块，将其分为两类：（1）可移除的（VAE编码器、提示提取器、文本编码器等）和（2）可修剪的（去噪UNet和VAE解码器）。由于直接删除和修剪会降低模型的生成能力，我们对修剪后的VAE解码器进行预训练，以恢复其解码图像的能力，并采用对抗性蒸馏来补偿性能损失。这种基于ADC的扩散GAN混合设计有效地将推理时间、计算时间和参数的复杂性降低了73%、78%和74%，同时保留了模型的生成能力。实验表明，我们提出的AdcSR在合成和真实数据集上都实现了具有竞争力的恢复质量，与之前的基于一步扩散的方法相比，速度提高了9.3美元。将提供代码和模型。 et.al.|[2411.13383](http://arxiv.org/abs/2411.13383)|null|
|**2024-11-20**|**New Insights on the High Reconnection Rate and the Diminishment of Ion Outflow**|最近发现的纯电子重联由于缺乏离子外流和高重联率等异常特征而引起了人们的极大兴趣。通过粒子模拟，我们研究了它们的物理机制。当用离子参数（ $R_i$）归一化时，重联速率可能会异常高，而用电子参数（$R_ e$）归一化的重联速率仍保持在~0.1。我们提出，高$R_i$的本质是电子扩散区外的场线弯曲不足，表明离子扩散区的发展不完整。这可能是由于薄电流片或小系统尺寸中的突发重连造成的。当陀螺半径（$\rho_i$）超过系统尺寸时，离子流出在高$\beta_i$时减少。低速离子仍然受到霍尔场的显著加速。然而，局部分布包括许多高速离子，这些离子在$\rho_i$ 上受到不同电场的随机加速，导致体积速度接近零。我们的研究有助于理解重联结构和不同制度之间转变的潜在物理学。 et.al.|[2411.13352](http://arxiv.org/abs/2411.13352)|null|

<p align=right>(<a href=#updated-on-20241122>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-11-20**|**GazeGaussian: High-Fidelity Gaze Redirection with 3D Gaussian Splatting**|在处理分布外数据时，凝视估计遇到了泛化挑战。为了解决这个问题，最近的方法使用神经辐射场（NeRF）来生成增强数据。然而，基于NeRF的现有方法计算成本高昂，缺乏面部细节。三维高斯散斑（3DGS）已成为神经场的主流表示。虽然3DGS已经在头部化身中得到了广泛的研究，但它面临着在不同受试者之间进行精确视线控制和泛化的挑战。在这项工作中，我们提出了GazeGaussian，这是一种高保真的视线重定向方法，它使用双流3DGS模型分别表示面部和眼睛区域。通过利用3DGS的非结构化特性，我们开发了一种基于目标凝视方向的刚性眼睛旋转的新眼睛表示。为了增强各种主题的综合泛化能力，我们集成了一个表达式条件模块来指导神经渲染器。综合实验表明，GazeGaussian在渲染速度、视线重定向精度和跨多个数据集的面部合成方面优于现有方法。我们还证明，现有的凝视估计方法可以利用GazeGaussian来提高其泛化性能。该代码将在以下网址提供：https://ucwxb.github.io/GazeGaussian/. et.al.|[2411.12981](http://arxiv.org/abs/2411.12981)|null|
|**2024-11-18**|**NeuMaDiff: Neural Material Synthesis via Hyperdiffusion**|高质量的材料合成对于复制复杂的表面特性以创建逼真的数字场景至关重要。然而，现有的方法往往在时间和内存方面效率低下，需要领域专业知识，或者需要大量的训练数据，而高维材料数据进一步限制了性能。此外，大多数方法缺乏多模态制导能力和标准化的评估指标，限制了综合任务的控制和可比性。为了解决这些局限性，我们提出了NeuMaDiff，这是一种利用超扩散的新型神经材料合成框架。我们的方法采用神经场作为低维表示，并结合了多模态条件超扩散模型来学习材料重量的分布。这使得通过材料类型、文本描述或参考图像等输入进行灵活指导成为可能，从而对合成提供了更大的控制。为了支持未来的研究，我们贡献了两个新的材料数据集，并引入了两个BRDF分布度量，以进行更严格的评估。我们通过广泛的实验证明了NeuMaDiff的有效性，包括一种新的基于统计的约束合成方法，该方法能够生成所需类别的材料。 et.al.|[2411.12015](http://arxiv.org/abs/2411.12015)|null|
|**2024-11-14**|**The Hydrodynamic Limit of Hawkes Processes on Adaptive Stochastic Networks**|我们确定了自适应网络上相互作用的霍克斯过程网络的大尺寸限制。节点变量的翻转被认为具有由传入边缘和节点的平均场给出的强度。边缘变量的翻转是传入节点变量的函数。边变量可以是对称的，也可以是不对称的。该模型受到社会学、神经科学和流行病学应用的启发。一般来说，极限概率律可以表示为具有强度函数的自洽泊松过程的不动点，该强度函数（i）是延迟的，（ii）取决于其自身的概率律。在边缘翻转仅由突触前神经元的状态决定的特定情况下（如神经科学中），证明了可以获得突触增强和神经增强双重进化的自主神经场型方程。 et.al.|[2411.09260](http://arxiv.org/abs/2411.09260)|null|
|**2024-11-09**|**Epi-NAF: Enhancing Neural Attenuation Fields for Limited-Angle CT with Epipolar Consistency Conditions**|神经场方法最初在逆渲染领域取得了成功，最近已扩展到CT重建，标志着传统技术的范式转变。虽然这些方法在稀疏视图CT重建中提供了最先进的结果，但它们在有限的角度设置中很难实现，在有限的视角范围内捕获输入投影。我们提出了一种基于X射线投影图像中相应极线之间一致性条件的新损失项，旨在规范神经衰减场优化。通过强制执行这些一致性条件，我们的方法Epi NAF将监督从有限角度范围内的输入视图传播到整个锥束CT范围内的预测投影。与基线方法相比，这种损失导致重建的定性和定量改进。 et.al.|[2411.06181](http://arxiv.org/abs/2411.06181)|null|
|**2024-11-07**|**LoFi: Scalable Local Image Reconstruction with Implicit Neural Representation**|神经场或隐式神经表示（INR）因其对图像和3D体积的有效连续表示而在机器学习和信号处理中引起了广泛关注。在这项工作中，我们以INR为基础，引入了一种基于坐标的局部处理框架来解决成像逆问题，称为LoFi（局部场）。与传统的图像重建方法不同，LoFi通过多层感知器（MLP）分别处理每个坐标处的局部信息，在该特定坐标处恢复对象。与INR类似，LoFi可以在任何连续坐标下恢复图像，从而实现多分辨率的图像重建。LoFi在图像重建方面的性能与标准CNN相当或更好，几乎与图像分辨率无关，对分布外数据和内存使用具有出色的泛化能力。值得注意的是，对1024美元×1024美元的图像进行训练只需要3GB的内存，比标准CNN通常需要的内存少20多倍。此外，LoFi的局部设计允许它在小于10个样本的极小数据集上进行训练，而不会过拟合或需要正则化或提前停止。最后，我们使用LoFi作为即插即用框架中的去噪先验，用于解决一般的逆问题，以受益于其连续的图像表示和强大的泛化能力。尽管在低分辨率图像上进行了训练，但LoFi可以用作低维先验，以解决任何分辨率的逆问题。我们通过各种成像方式验证了我们的框架，从低剂量计算机断层扫描到无线电干涉成像。 et.al.|[2411.04995](http://arxiv.org/abs/2411.04995)|null|
|**2024-11-04**|**Physically Based Neural Bidirectional Reflectance Distribution Function**|我们介绍了基于物理的神经双向反射分布函数（PBNBRDF），这是一种基于神经场的材料外观的新颖连续表示。我们的模型准确地重建了真实世界的材料，同时独特地增强了现实BRDF的物理特性，特别是通过重新参数化的亥姆霍兹互易性和通过高效分析积分的能量无源性。我们进行了系统分析，证明了遵守这些物理定律对重建材料的视觉质量的好处。此外，我们通过引入色度强制监督RGB通道的规范来提高神经BRDF的颜色精度。通过在多个测量的真实BRDF数据库上进行定性和定量实验，我们表明，遵守这些物理约束可以使神经场更忠实、更稳定地表示原始数据，并实现更高的渲染质量。 et.al.|[2411.02347](http://arxiv.org/abs/2411.02347)|null|
|**2024-11-01**|**Intensity Field Decomposition for Tissue-Guided Neural Tomography**|锥束计算机断层扫描（CBCT）通常需要数百次X射线投影，这引起了人们对辐射暴露的担忧。虽然稀疏视图重建通过使用更少的投影来减少曝光，但它很难达到令人满意的图像质量。为了应对这一挑战，本文介绍了一种新的稀疏视图CBCT重建方法，该方法为神经场赋予了人体组织正则化的能力。我们的方法被称为组织引导神经断层扫描（TNT），其动机是CBCT中骨骼和软组织之间明显的强度差异。直观地说，分离这些成分可能有助于神经场的学习过程。更确切地说，TNT包括一个异构的四重网络和相应的训练策略。该网络将强度场表示为软组织和硬组织成分及其各自纹理的组合。我们在估计的组织投影的指导下训练网络，从而能够有效地学习网络头所需的模式。大量实验表明，所提出的方法显著改善了稀疏视图CBCT重建，投影数量从10到60不等。与最先进的基于神经渲染的方法相比，我们的方法以更少的投影和更快的收敛实现了相当的重建质量。 et.al.|[2411.00900](http://arxiv.org/abs/2411.00900)|null|
|**2024-10-26**|**Neural Fields in Robotics: A Survey**|神经场已经成为计算机视觉和机器人技术中3D场景表示的一种变革性方法，能够从姿势的2D数据中准确推断几何、3D语义和动力学。利用可微分渲染，神经场包括连续隐式和显式神经表示，实现了高保真3D重建、多模态传感器数据的集成和新视点的生成。这项调查探讨了它们在机器人技术中的应用，强调了它们在增强感知、规划和控制方面的潜力。它们的紧凑性、内存效率和可微性，以及与基础模型和生成模型的无缝集成，使其成为实时应用的理想选择，提高了机器人的适应性和决策能力。本文基于200多篇论文，对机器人中的神经场进行了全面的回顾，对各个领域的应用进行了分类，并评估了它们的优势和局限性。首先，我们介绍了四个关键的神经场框架：占用网络、有符号距离场、神经辐射场和高斯散斑。其次，我们详细介绍了神经场在五个主要机器人领域的应用：姿态估计、操纵、导航、物理和自动驾驶，重点介绍了关键工作，并讨论了要点和公开挑战。最后，我们概述了神经场在机器人技术中的局限性，并为未来的研究提出了有前景的方向。项目页面：https://robonerf.github.io et.al.|[2410.20220](http://arxiv.org/abs/2410.20220)|**[link](https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics)**|
|**2024-10-24**|**3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation**|多视图图像扩散模型显著推进了开放域3D对象生成。然而，大多数现有模型依赖于缺乏固有3D偏差的2D网络架构，导致几何一致性受损。为了应对这一挑战，我们引入了3D Adapter，这是一个插件模块，旨在将3D几何感知注入预训练的图像扩散模型中。我们方法的核心是3D反馈增强的思想：对于采样循环中的每个去噪步骤，3D Adapter将中间的多视图特征解码为连贯的3D表示，然后对渲染的RGBD视图进行重新编码，通过特征添加来增强预训练的基础模型。我们研究了3D Adapter的两种变体：一种是基于高斯飞溅的快速前馈版本，另一种是利用神经场和网格的通用无训练版本。我们广泛的实验表明，3D Adapter不仅大大提高了文本到多视图模型（如Instant3D和Zero123++）的几何质量，而且还使用纯文本到图像的稳定扩散实现了高质量的3D生成。此外，我们通过在文本到3D、图像到3D、文本到纹理和文本到化身任务中呈现高质量的结果，展示了3D适配器的广泛应用潜力。 et.al.|[2410.18974](http://arxiv.org/abs/2410.18974)|**[link](https://github.com/Lakonik/MVEdit)**|
|**2024-10-22**|**Cortical Dynamics of Neural-Connectivity Fields**|皮质组织的宏观研究揭示了振荡活动的普遍性，这反映了神经相互作用的微调。本研究通过将广义振荡动力学纳入先前关于保守或半保守神经场动力学的工作中，扩展了神经场理论。先前的研究在很大程度上假设了神经单元之间的各向同性连接；然而，这项研究表明，广泛的各向异性和波动连接仍然可以维持振荡。使用拉格朗日场方法，我们研究了不同类型的连接、它们的动力学以及与神经场的潜在相互作用。基于这一理论基础，我们推导出了一个框架，该框架通过连接场的概念将Hebbian和非Hebbian学习（即可塑性）纳入神经场的研究中。 et.al.|[2410.16852](http://arxiv.org/abs/2410.16852)|null|

<p align=right>(<a href=#updated-on-20241122>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

