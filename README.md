[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.09.21
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-09-19**|**ReShader: View-Dependent Highlights for Single Image View-Synthesis**|近年来，由于3D场景表示和图像修复技术的快速发展，从单个图像进行的新颖视图合成已经取得了重大进展。虽然目前的方法能够合成几何一致的新视图，但它们往往不能正确处理视图相关的效果。具体来说，他们合成图像中的高光通常看起来粘在表面上，这使得新颖的视图不切实际。为了解决这个主要问题，我们进行了一项关键观察，即合成新视图的过程需要改变基于新相机的像素的阴影，并将它们移动到适当的位置。因此，我们建议将视图合成过程拆分为两个独立的任务，即像素重新加载和重新定位。在重影过程中，我们以单个图像为输入，并基于新型相机调整其明暗度。然后将该重新加载的图像用作现有视图合成方法的输入，以重新定位像素并产生最终的新颖视图图像。我们建议使用神经网络来执行重新加载，并生成一大组合成输入重新加载对来训练我们的网络。我们证明，我们的方法在各种现实世界场景中产生了具有逼真运动亮点的看似新颖的视图图像。 et.al.|[2309.10689](http://arxiv.org/abs/2309.10689)|null|
|**2023-09-19**|**Locally Stylized Neural Radiance Fields**|近年来，人们对将风格化应用于参考风格图像的3D场景，特别是应用于神经辐射场（NeRF）越来越感兴趣。虽然直接在NeRF上执行风格化可以保证在任意新颖视图上的外观一致性，但引导图案从风格图像转移到NeRF场景的不同部分是一个具有挑战性的问题。在这项工作中，我们提出了一个基于局部风格转移的NeRF风格化框架。特别是，我们使用哈希网格编码来学习外观和几何组件的嵌入，并表明哈希表定义的映射允许我们在一定程度上控制风格化。然后通过优化外观分支同时保持几何体分支固定来实现样式化。为了支持局部风格转移，我们提出了一种新的损失函数，该函数利用分割网络和二分匹配来建立风格图像和从体绘制中获得的内容图像之间的区域对应关系。我们的实验表明，我们的方法通过新的视图合成产生了合理的风格化结果，同时通过操纵和定制区域对应关系具有灵活的可控性。 et.al.|[2309.10684](http://arxiv.org/abs/2309.10684)|null|
|**2023-09-19**|**Anti-Aliased Neural Implicit Surfaces with Encoding Level of Detail**|我们提出了LoD-NeuS，这是一种用于高频几何细节恢复和抗锯齿新视图渲染的有效神经表示。从具有细节水平（LoD）的基于体素的表示中汲取灵感，我们引入了一种基于多尺度三平面的场景表示，该表示能够捕捉符号距离函数（SDF）的LoD和空间辐射。我们的表示聚合了来自圆锥台内沿射线的多重卷积特征的空间特征，并通过可微分渲染优化了LoD特征体积。此外，我们提出了一种误差引导采样策略，以在优化过程中引导SDF的增长。定性和定量评估都表明，与最先进的方法相比，我们的方法实现了卓越的表面重建和真实感视图合成。 et.al.|[2309.10336](http://arxiv.org/abs/2309.10336)|null|
|**2023-09-16**|**ExBluRF: Efficient Radiance Fields for Extreme Motion Blurred Images**|我们提出了ExBluRF，这是一种基于有效辐射场优化的极端运动模糊图像的新视图合成方法。我们的方法由两个主要组成部分组成：基于6自由度相机轨迹的运动模糊公式和基于体素的辐射场。从极其模糊的图像中，我们通过联合估计生成模糊图像的相机轨迹来优化清晰的辐射场。在训练中，沿着相机轨迹的多条光线被累积以重建单个模糊的颜色，这相当于物理运动模糊操作。我们最小化了模糊图像空间上的照片一致性损失，并获得了具有相机轨迹的清晰辐射场，这些轨迹解释了所有图像的模糊。模糊图像空间上的联合优化需要与模糊大小成比例地痛苦地增加计算和资源。我们的方法通过将基于MLP的框架替换为低维6自由度相机姿态和基于体素的辐射场来解决这个问题。与现有作品相比，我们的方法从具有挑战性的运动模糊视图中恢复了更清晰的3D场景，训练时间和GPU内存消耗减少了10倍。 et.al.|[2309.08957](http://arxiv.org/abs/2309.08957)|null|
|**2023-09-16**|**DynaMoN: Motion-Aware Fast And Robust Camera Localization for Dynamic NeRF**|利用神经辐射场（NeRF）进行动态重建需要精确的相机姿态。这些通常很难用现有的运动结构（SfM）管道来检索，因为相机和场景内容都可能发生变化。我们提出了DynaMoN，它利用同步定位和映射（SLAM）与运动掩蔽相结合来处理动态场景内容。我们基于SLAM的稳健跟踪模块显著加快了动态NeRF的训练过程，同时提高了合成视图的质量。对TUM RGB-D、BONN RGB-D Dynamic和DyCheck的iPhone数据集这三个真实世界的数据集进行了广泛的实验验证，显示了DynaMoN在相机姿态估计和新颖视图合成方面的优势。 et.al.|[2309.08927](http://arxiv.org/abs/2309.08927)|null|
|**2023-09-14**|**Viewpoint Textual Inversion: Unleashing Novel View Synthesis with Pretrained 2D Diffusion Models**|文本到图像的扩散模型理解物体之间的空间关系，但它们是否仅从2D监督中代表了世界的真实3D结构？我们证明，是的，3D知识被编码在2D图像扩散模型中，如稳定扩散，我们证明这种结构可以用于3D视觉任务。我们的方法，视点神经纹理反演（ViewNeTI），控制从冻结扩散模型生成的图像中对象的3D视点。我们训练一个小型神经映射器来获取相机视点参数并预测文本编码器延迟；潜伏时间然后调节扩散生成过程以产生具有期望的相机视点的图像。ViewNeTI自然地解决了新颖视图合成（NVS）问题。通过利用冻结扩散模型作为先验，我们可以用很少的输入视图来解决NVS；我们甚至可以做单一视角的小说视角合成。与先前的方法相比，我们的单视图NVS预测具有良好的语义细节和真实感。我们的方法非常适合对稀疏三维视觉问题中固有的不确定性进行建模，因为它可以有效地生成不同的样本。我们的视图控制机制是通用的，甚至可以更改用户定义提示生成的图像中的相机视图。 et.al.|[2309.07986](http://arxiv.org/abs/2309.07986)|null|
|**2023-09-14**|**CoRF : Colorizing Radiance Fields using Knowledge Distillation**|基于神经辐射场（NeRF）的方法能够实现多视图图像的高质量新视图合成。本文提出了一种从输入的灰度多视图图像中合成彩色新视图的方法。当我们在生成的灰度级新视图上应用基于图像或视频的着色方法时，我们会观察到由于视图之间的不一致而产生的伪影。在彩色灰度图像序列上训练辐射场网络也不能解决3D一致性问题。我们提出了一种基于蒸馏的方法，将颜色知识从在自然图像上训练的着色网络转移到辐射场网络。具体来说，我们的方法使用辐射场网络作为3D表示，并从现有的2D着色方法中转移知识。实验结果表明，与基线相比，该方法在保持跨视图一致性的同时，为室内和室外场景生成了更好的彩色新视图。此外，我们展示了我们的方法在应用中的有效性，如从1.）红外（IR）多视图图像和2.）旧灰度多视图图像序列训练的辐射场网络的彩色化。 et.al.|[2309.07668](http://arxiv.org/abs/2309.07668)|null|
|**2023-09-13**|**Dynamic NeRFs for Soccer Scenes**|新颖视角合成这个长期存在的问题有很多应用，尤其是在体育广播中。特别是足球动作的逼真新颖视角合成，引起了广播业的极大兴趣。然而，只有少数几个工业解决方案被提出，甚至很少能达到合成回放的近广播质量。除了在操场周围设置多个静态摄像头外，最好的专有系统几乎没有透露任何关于其内部工作的信息。由于缺乏公共数据集，利用多个静态相机执行这样的任务确实是一个文献中很少解决的挑战：用小而快速的元素重建大规模的、主要是静态的环境。最近，神经辐射场的出现在许多新颖的视图合成应用中取得了惊人的进展，利用深度学习原理在最具挑战性的环境中产生逼真的结果。在这项工作中，我们研究了基于动态NeRF的任务解决方案的可行性，即旨在重建一般动态内容的神经模型。我们构建了合成足球环境，并使用它们进行了多项实验，确定了有助于用动态NeRF重建足球场景的关键组件。我们表明，尽管这种方法不能完全满足目标应用程序的质量要求，但它为实现成本效益高的自动解决方案提供了有希望的途径。我们还公开了我们的工作数据集和代码，目的是鼓励研究界进一步致力于动态足球场景的新颖视图合成任务。有关代码、数据和视频结果，请参阅https://soccernerfs.isach.be. et.al.|[2309.06802](http://arxiv.org/abs/2309.06802)|null|
|**2023-09-13**|**SAMPLING: Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image**|最近的新颖视图合成方法对于相对较小的场景（例如，室内环境和具有少数对象的场景）获得了有希望的结果，但对于具有单个图像作为输入的无边界室外场景往往失败。在本文中，我们介绍了SAMPLING，这是一种基于改进的多平面图像（MPI）的场景自适应分层多平面图像表示，用于从单个图像合成新视图。观察到无边界户外场景的深度分布变化很大，我们为MPI采用了自适应仓策略，根据每个场景图像排列平面。为了表示复杂的几何结构和多尺度细节，我们进一步引入了一个层次细化分支，它可以产生高质量的合成新视图。我们的方法在KITTI数据集上使用单个图像合成大规模无界户外场景时表现出了相当大的性能提升，并很好地推广到了看不见的Tanks和Temples数据集。代码和模型将很快提供。 et.al.|[2309.06323](http://arxiv.org/abs/2309.06323)|null|
|**2023-09-11**|**FlowIBR: Leveraging Pre-Training for Efficient Neural Image-Based Rendering of Dynamic Scenes**|我们介绍了一种用于动态场景的单目新颖视图合成的新方法。现有技术已经显示出令人印象深刻的渲染质量，但倾向于在不利用先验知识的情况下专注于单个场景内的优化。这种限制主要归因于缺乏可用于训练的动态场景数据集以及场景动力学的多样性。我们的方法FlowIBR通过集成基于神经图像的渲染方法来规避这些问题，该方法在广泛可用的静态场景的大型语料库上进行了预训练，并具有每个场景优化的场景流场。利用该流场，我们弯曲摄影机光线以抵消场景动力学，从而将动态场景呈现为渲染网络的静态场景。所提出的方法将每个场景的优化时间减少了一个数量级，实现了与现有方法相当的结果——所有这些都在单个消费级GPU上。 et.al.|[2309.05418](http://arxiv.org/abs/2309.05418)|null|

<p align=right>(<a href=#updated-on-20230921>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-09-19**|**SHOWMe: Benchmarking Object-agnostic Hand-Object 3D Reconstruction**|最近的手-物体交互数据集显示出有限的真实物体可变性，并且依赖于拟合MANO参数模型来获得真实的手形状。为了超越这些限制并推动进一步的研究，我们引入了SHOWMe数据集，该数据集由96个视频组成，用真实和详细的手对象3D纹理网格进行注释。根据最近的工作，我们考虑了一个刚性手对象场景，其中手相对于对象的姿势在整个视频序列中保持不变。这一假设使我们能够将亚毫米精度的地面实况3D扫描注册到SHOWMe中的图像序列中。尽管更简单，但这一假设在所需精度和细节水平很重要的应用中是有意义的，例如，人机协作中的对象移交、对象扫描或操作和接触点分析。重要的是，手对象系统的刚性允许使用由刚性配准步骤和多视图重建（MVR）部分组成的两阶段流水线来处理未知手持对象的基于视频的3D重建。我们仔细评估了这两个阶段的一组非平凡基线，并表明使用SfM工具箱或手部姿态估计器来恢复刚性变换和现成的MVR算法，可以实现有前景的对象不可知的3D手部对象重建。然而，这些方法对最初的相机姿态估计仍然敏感，由于物体上缺乏纹理或手的严重遮挡，这些估计可能不精确，这为重建留下了改进的空间。代码和数据集可在https://europe.naverlabs.com/research/showme et.al.|[2309.10748](http://arxiv.org/abs/2309.10748)|null|
|**2023-09-14**|**TCGF: A unified tensorized consensus graph framework for multi-view representation learning**|多视图学习技术最近在机器学习领域获得了极大的关注，因为它们能够利用多个视图之间的一致性和互补信息。然而，对于将现有工作统一为可扩展和稳健的学习框架的广义多视图框架，仍然缺乏足够的研究，因为目前的大多数工作都集中在特定风格的多视图模型上。此外，大多数多视角学习工作严重依赖于特定的量表场景，无法有效地全面理解多个量表。这些限制阻碍了来自多个视图的重要信息的有效融合，导致泛化能力差。为了解决这些局限性，本文提出了一个通用的多视图表示学习框架，称为张量化共识图框架（TCGF）。具体而言，它首先为现有的多视图作品提供了一个统一的框架，以利用单个视图的表示，该框架旨在适用于任意假设和不同规模的数据集。然后，在对齐基础上将它们堆叠成张量，作为高阶表示，允许一致性和互补信息在所有视图中平滑传播。此外，TCGF提出通过自适应地协作所有视图来学习共享的共识嵌入，以揭示多视图数据的基本结构，该方法利用视图共识分组效应来正则化视图共识表示。为了进一步促进相关研究，我们为大规模数据集提供了TCGF的具体实现，可以通过应用交替优化策略来有效解决。在七个不同规模的数据集上进行的实验结果表明，与现有最先进的多视图学习方法相比，所提出的TCGF具有优势。 et.al.|[2309.09987](http://arxiv.org/abs/2309.09987)|null|
|**2023-09-18**|**Improving Neural Indoor Surface Reconstruction with Mask-Guided Adaptive Consistency Constraints**|从2D图像重建3D场景一直是一项长期任务。最近的研究利用神经隐式表面作为3D重建的统一表示，而不是估计每帧深度图并将其融合到3D中。这些方法配备了数据驱动的预训练几何线索，表现出了良好的性能。然而，不准确的先验估计（这通常是不可避免的）可能导致次优重建质量，特别是在一些几何复杂的区域。在本文中，我们提出了一个两阶段的训练过程，解耦视图相关和视图无关的颜色，并利用两个新的一致性约束来提高细节重建性能，而不需要额外的先验。此外，我们引入了一个基本的掩码方案来自适应地影响监督约束的选择，从而提高自监督范式中的性能。在合成数据集和真实世界数据集上的实验表明，该方法能够减少先验估计误差的干扰，并实现具有丰富几何细节的高质量场景重建。 et.al.|[2309.09739](http://arxiv.org/abs/2309.09739)|null|
|**2023-09-18**|**Robust Geometry-Preserving Depth Estimation Using Differentiable Rendering**|在这项研究中，我们解决了从单目深度估计中恢复3D场景结构的挑战。虽然传统的深度估计方法利用标记的数据集来直接预测绝对深度，但最近的进展提倡混合数据集训练，增强了在不同场景中的泛化能力。然而，这种混合数据集训练只能产生未知规模和偏移的深度预测，阻碍了精确的3D重建。现有的解决方案需要额外的3D数据集或几何体完整的深度注释，这些限制了它们的通用性。在本文中，我们提出了一种学习框架，该框架训练模型来预测几何保持深度，而不需要额外的数据或注释。为了产生逼真的3D结构，我们渲染重建场景的新颖视图，并设计损失函数，以提高不同视图之间的深度估计一致性。全面的实验强调了我们框架卓越的泛化能力，在几个基准数据集上超越了现有的最先进的方法，而不需要利用额外的训练信息。此外，我们创新的损失函数使模型能够仅使用未标记的图像自主恢复特定领域的尺度和偏移系数。 et.al.|[2309.09724](http://arxiv.org/abs/2309.09724)|null|
|**2023-09-18**|**Self-supervised Multi-view Clustering in Computer Vision: A Survey**|近年来，多视图聚类（MVC）在跨模态表示学习和数据驱动决策中具有重要意义。它通过利用多个视图之间的一致性和互补信息将样本聚类到不同的组中来实现这一点。然而，随着对比学习在计算机视觉领域的不断发展，自监督学习也取得了实质性的研究进展，并逐渐在MVC方法中占据主导地位。它通过设计代理任务来指导聚类过程，以挖掘图像和视频数据本身作为监督信息的表示。尽管自监督MVC发展迅速，但目前还没有一个全面的调查来分析和总结研究进展的现状。因此，本文探讨了自监督MVC出现的原因和优势，并讨论了常见数据集的内部联系和分类、数据问题、表示学习方法和自监督学习方法。本文不仅介绍了每一类方法的机制，还举例说明了如何使用这些技术。最后指出了一些有待进一步研究和发展的问题。 et.al.|[2309.09473](http://arxiv.org/abs/2309.09473)|null|
|**2023-09-17**|**Uncertainty-aware 3D Object-Level Mapping with Deep Shape Priors**|三维对象级映射是机器人技术中的一个基本问题，当推理过程中对象CAD模型不可用时，这一问题尤其具有挑战性。在这项工作中，我们提出了一个框架，可以为未知对象重建高质量的对象级映射。我们的方法以多个RGB-D图像作为输入，并为检测到的对象输出密集的3D形状和9-DoF姿势（包括3个比例参数）。我们方法的核心思想是利用形状类别的学习生成模型作为先验，并为3D重建制定概率、不确定性感知的优化框架。我们推导了一个概率公式，该公式通过两个新的损失函数传播形状并带来不确定性。与当前最先进的方法不同，我们在优化过程中明确地对对象形状和姿态的不确定性进行建模，从而产生高质量的对象级映射系统。此外，我们证明，由此产生的形状和姿态不确定性可以准确地反映我们物体地图的真实误差，也可以用于下游机器人任务，如主动视觉。我们对室内和室外真实世界的数据集进行了广泛的评估，实现了对最先进方法的实质性改进。我们的代码将在https://github.com/TRAILab/UncertainShapePose. et.al.|[2309.09118](http://arxiv.org/abs/2309.09118)|null|
|**2023-09-15**|**Uncertainty-Aware Multi-View Visual Semantic Embedding**|图像文本检索的关键挑战是有效地利用语义信息来测量视觉和语言数据之间的相似性。然而，使用实例级二进制标签，即每个图像与单个文本配对，无法捕捉不同语义单元之间的多个对应关系，导致多模态语义理解的不确定性。尽管最近的研究通过更复杂的模型结构或预训练技术捕获了细粒度的信息，但很少有研究直接建模对应关系的不确定性，以充分利用二进制标签。为了解决这个问题，我们提出了一个不确定性感知的多视图视觉语义嵌入（UAMVSE）}框架，该框架将整个图像-文本匹配分解为多视图-文本匹配。我们的框架引入了一个不确定性感知损失函数（UALoss），通过自适应地建模每个视图文本对应关系中的不确定性来计算每个视图文本损失的权重。不同的权重引导模型关注不同的语义信息，增强了模型理解图像和文本对应关系的能力。我们还通过对相似度矩阵进行归一化，设计了一种优化的图像-文本匹配策略，以提高模型性能。在Flicker30k和MS-COCO数据集上的实验结果表明，UAMVSE的性能优于最先进的模型。 et.al.|[2309.08154](http://arxiv.org/abs/2309.08154)|null|
|**2023-09-14**|**High-fidelity 3D Reconstruction of Solar Coronal Physics with the Updated CROBAR Method**|我们提出了一种将冠状重建到B对齐区域（CROBAR）方法扩展到线性无力场（LFFF）外推的方法，并将其应用于AIA、MDI和STEREO EUVI数据集的重建。结果表明，CROBAR不仅可以重建日冕发射结构，而且可以通过LFFF的螺旋度 $\alpha$ 参数帮助约束日冕场外推。他们还提供了一个真实世界的例子，说明CROBAR如何轻松地从多个角度整合信息，以改进其重建，我们还使用其他角度来帮助验证重建。我们还谈到了使用真实世界的发射通带，而不是使用DEM的理想化幂律型通带。最后，我们将CROBAR产生的发射与观测到的发射以及基于理想DEM的幂律产生的发射进行了比较。这些结果进一步说明了CROBAR在现实世界应用中的前景，我们提供了该软件的初步版本供下载。 et.al.|[2309.08053](http://arxiv.org/abs/2309.08053)|null|
|**2023-09-14**|**Combining Multiple View Components for Exploratory Visualization**|结构化复杂数据的分析，如基于聚类图的数据集，通常应用各种视觉表示技术和格式。目前大多数可用的探索性可视化工具和方法都建立在集成方案之上，用于同时显示研究对象和过程的多个方面。通常，这种方案将由多个视图组成的屏幕空间进行分区，并采用交互模式来关注数据驱动的项目。众所周知的概念，如概述加细节和重点加上下文，在用技术术语解释时是模棱两可的。因此，UI设计从业者需要对图形表示模块的视觉合成的基本方法进行审查和分类。我们建议对视图和焦点的基本组成部分进行描述，并概述它们的多种组合。 et.al.|[2309.07580](http://arxiv.org/abs/2309.07580)|null|
|**2023-09-13**|**Exploiting Multiple Priors for Neural 3D Indoor Reconstruction**|神经隐式建模允许在小物体上实现令人印象深刻的3D重建结果，而在大型室内场景中表现出显著的局限性。在这项工作中，我们提出了一种新的神经隐式建模方法，该方法利用多种正则化策略来实现大型室内环境的更好重建，同时仅依赖于图像。稀疏但准确的深度先验用于将场景锚定到初始模型。还引入了密集但不太准确的深度先验，它足够灵活，仍然可以让模型偏离它，以改进估计的几何结构。然后，提出了一种新的自监督策略来正则化估计的曲面法线。最后，可学习的曝光补偿方案允许应对具有挑战性的照明条件。实验结果表明，我们的方法在具有挑战性的室内场景中产生了最先进的3D重建。 et.al.|[2309.07021](http://arxiv.org/abs/2309.07021)|null|

<p align=right>(<a href=#updated-on-20230921>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-09-19**|**Assessing the capacity of a denoising diffusion probabilistic model to reproduce spatial context**|扩散模型已经成为一个流行的深度生成模型家族。在文献中，有人声称，与生成对抗性网络（GANs）相比，一类扩散模型——去噪扩散概率模型（DDPM）——表现出优越的图像合成性能。到目前为止，这些权利要求已经使用为自然图像设计的基于集成的方法或传统的图像质量测量（如结构相似性）进行了评估。然而，仍然需要了解DDPM能够在多大程度上可靠地学习医学成像领域相关信息，这在本工作中被称为“空间上下文”。为了解决这一问题，首次报道了对DDPM学习与医学成像应用相关的空间上下文的能力的系统评估。研究的一个关键方面是使用随机上下文模型（SCMs）来生成训练数据。通过这种方式，可以通过使用事后图像分析来定量评估DDPM可靠地再现空间上下文的能力。报告了DDPM生成的系综中的错误率，并将其与现代GAN对应的错误率进行了比较。这些研究揭示了关于DDPM学习空间上下文能力的新的重要见解。值得注意的是，结果表明，DDPM具有生成上下文正确图像的显著能力，这些图像在训练样本之间“插值”，这可能有利于数据增强任务，而GANs则无法做到这一点。 et.al.|[2309.10817](http://arxiv.org/abs/2309.10817)|null|
|**2023-09-19**|**PGDiff: Guiding Diffusion Models for Versatile Face Restoration via Partial Guidance**|利用预先训练的扩散模型进行恢复最近已成为传统任务特定训练方法的一种受欢迎的替代方法。先前的工作通过使用显式退化模型来限制解决方案空间，取得了显著的成功。然而，当面临复杂的降解时，这些方法往往达不到要求，因为它们通常无法精确建模。在本文中，我们通过引入部分指导提出了PGDiff，这是一个新的视角，与现有工作相比，更适合现实世界的退化。我们的方法不是专门定义退化过程，而是对所需的特性进行建模，如高质量图像的图像结构和颜色统计，并在反向扩散过程中应用这一指导。这些特性很容易获得，并且对降解过程没有任何假设。当与扩散先验相结合时，这种部分指导可以在一系列恢复任务中提供有吸引力的结果。此外，PGDiff可以扩展为通过整合多个高质量图像属性来处理合成任务，这是通过集成来自各个任务的指导来实现的。实验结果表明，我们的方法不仅优于现有的基于扩散先验的方法，而且与特定任务的模型相比具有优势。 et.al.|[2309.10810](http://arxiv.org/abs/2309.10810)|**[link](https://github.com/pq-yang/pgdiff)**|
|**2023-09-19**|**Probing the spatial and velocity anisotropies in stellar halos from the Aquarius simulations**|我们从宝瓶座模拟中分析了一组模拟恒星晕的空间各向异性和速度各向异性。每个模拟恒星晕的空间各向异性随着与晕中心距离的增加而逐渐上升，最终在外围达到最大值。排除绑定的卫星会显著降低每个光环的空间各向异性。我们将模拟恒星晕中测得的各向异性与球形化版本的各向异性进行了比较，在球形化版本中，所有形状和子结构引起的各向异性都被消除了。当绑定卫星存在时，空间各向异性的增长在整个晕圈中持续存在，但在它们被排除后，在内晕圈内（ $<60\，h^｛-1｝\，hrm-kpc｝$）仍然有限。这表明，内晕的空间各向异性是由扩散子结构和晕的形状引起的，而外晕的各向异性则由束缚卫星主导。我们发现恒星晕的外部在运动学上比内部区域更冷。恒星轨道主要是径向的，但在某些半径上，它们变得旋转主导，这些半径以显著的$\beta$下降为标志。大部分$\beta$下降在卫星移除后消失。由于弥漫的溪流和云层的存在，偶尔会出现一些浅而宽的$\beta$ 下降。我们的分析表明，对空间各向异性和速度各向异性的综合研究可以揭示恒星晕的结构和组装历史。 et.al.|[2309.10798](http://arxiv.org/abs/2309.10798)|null|
|**2023-09-19**|**The Kinematic Structure of Magnetically Aligned HI Filaments**|我们描述了位于银河系高纬度区域（ $165^\circ<\alpha<195^\cir$和$12^\cir<\adelta<24^\cir$$）的HI细丝的运动学和磁学性质。我们使用来自银河阿雷西博L波段馈电阵列HI（GALFA-HI）21厘米发射数据的\texttt｛fil3d｝提取三维丝状结构。我们的算法识别相邻速度通道中的相干发射结构。基于平均速度，我们确定了一组局部和中速云（IVC）细丝。我们发现局部（但不是IVC）HI丝的取向与从普朗克353 GHz偏振尘埃发射推断的磁场取向一致。我们分析了速度相干细丝的位置-速度图，发现只有15%的细丝表现出显著的长轴速度梯度，中值幅度为0.5 km/s$^{-1}$pc$^{-1}$ ，假设基准细丝距离为100个。我们得出结论，典型的扩散HI细丝没有表现出简单的速度梯度。所报道的细丝特性限制了未来细丝形成的理论模型。 et.al.|[2309.10777](http://arxiv.org/abs/2309.10777)|null|
|**2023-09-19**|**An optical Ising spin glass simulator with tuneable short range couplings**|非确定性多项式时间（NP）问题在几乎每个研究领域都普遍存在。最近，基于自旋玻璃伊辛哈密顿量的经典NP问题的全光方法已经被探索出来。然而，另一方面，在大规模光学伊辛模拟器中获得可编程自旋耦合仍然具有挑战性。在这里，我们演示了对完全连接的Ising系统的用户定义部分之间的交互长度的控制。这是通过利用随机介质的传输矩阵的知识并通过使用不同厚度的扩散器来实现的。最后，我们利用我们的自旋耦合控制来观察复制品到复制品的波动及其与标准复制品对称性破坏的相似性。 et.al.|[2309.10764](http://arxiv.org/abs/2309.10764)|null|
|**2023-09-19**|**Accelerating Diffusion-Based Text-to-Audio Generation with Consistency Distillation**|扩散模型支持绝大多数文本到音频（TTA）生成方法。不幸的是，由于对底层去噪网络的迭代查询，这些模型的推理速度较慢，因此不适合具有推理时间或计算约束的场景。这项工作修改了最近提出的一致性蒸馏框架，以训练只需要单个神经网络查询的TTA模型。除了将无分类器引导纳入蒸馏过程之外，我们还利用蒸馏训练期间生成的音频的可用性，在音频空间中微调具有新损失函数的一致性TTA模型，例如CLAP分数。我们对AudioCaps数据集的客观和主观评估结果表明，一致性模型保留了扩散模型的高生成质量和多样性，同时将查询数量减少了400倍。 et.al.|[2309.10740](http://arxiv.org/abs/2309.10740)|null|
|**2023-09-19**|**Reconstruct-and-Generate Diffusion Model for Detail-Preserving Image Denoising**|图像去噪是计算机视觉领域的一项基础性和挑战性任务。大多数监督去噪方法都是从噪声输入中重建干净的图像，噪声输入具有固有的光谱偏差，往往会产生过度平滑和模糊的图像。最近，研究人员探索了在图像恢复任务中生成高频细节的扩散模型，但这些模型不能保证生成的纹理与真实图像对齐，从而导致不希望的伪影。为了解决去噪任务中高频细节的视觉吸引力和保真度之间的权衡问题，我们提出了一种新的方法，称为重建和生成扩散模型（RnG）。我们的方法利用重建去噪网络来恢复大部分底层干净信号，这作为后续步骤的初始估计，以保持保真度。此外，它采用扩散算法生成残余高频细节，从而提高视觉质量。我们进一步引入了两阶段训练方案，以确保RnG的重建和生成模块之间的有效协作。为了减少扩散模型引入的不期望的纹理，我们还提出了一种自适应步长控制器，该控制器调节扩散模型应用的逆步长的数量，允许控制添加到每个补丁的高频细节的水平，并节省推理计算成本。通过我们提出的RnG，我们在感知和失真之间实现了更好的平衡。我们在合成和真实的去噪数据集上进行了大量的实验，验证了所提出方法的优越性。 et.al.|[2309.10714](http://arxiv.org/abs/2309.10714)|null|
|**2023-09-19**|**Small Molecules, Big Impact: A tale of hydrides past, present, and future**|氢化物形成于气相离子分子化学的早期阶段，它含有与一个或多个氢原子共价结合的重元素，在星际化学中发挥着重要作用，因为它们是星际介质中更大、更复杂物种的祖先。近年来，对氢化物光谱特征的仔细分析导致它们被用作星际介质的不同成分和相的示踪剂，特别是在更漫射的环境中。漫射云是恒星气体生命周期中的一个重要环节，因为它们连接着恒星进化的晚期和早期。因此，漫射云不断地被物质补充，这使它们成为重元素的储存库，因此成为研究天体化学的理想实验室。这篇综述将经历氢化物观测的复兴，详细介绍令人困惑的氢化物发现和化学奥秘，特别关注含碳氢化物，以证明这些小分子的巨大影响，并对其研究的未来发表评论。 et.al.|[2309.10712](http://arxiv.org/abs/2309.10712)|null|
|**2023-09-19**|**Ni/Bi bilayers: The effect of thickness on the superconducting properties**|镍/铋（Ni/Bi）双层由于在超导状态下发生时间反转对称性断裂而引起了人们的关注。在此，我们报道了具有几种Bi厚度的薄膜Ni/Bi双层的结构、磁性和电学特性。我们观察到由Bi和Ni的相互扩散引起的复杂层状结构的形成取决于Bi的厚度，这导致NiBi $_{3}$在Bi/Ni界面处的稳定。超导转变温度和转变宽度高度依赖于Bi厚度和层结构。在各向异性Ginzburg-Landau理论和Werthamer-Helfand-Hohenberg模型的框架内，使用垂直和平行磁场中的磁电输运测量来研究温度相关的上临界场。对于较厚的样本，我们观察到类似于NiBi$_｛3｝$体样本所示的常规行为，包括小的Maki参数（$\alpha_｛M｝$＝0）、无自旋-位散射（$\lambda_｛SO｝$=0）和几乎各向同性的相干长度（$\gamma$＝$\si_。这些性质的值与表征NiBi$_{3}$单晶的值接近。另一方面，在非常薄的样本中，Maki参数增加到大约$\alpha_{M}$=2.8。此外，相干长度变得各向异性（$\gamma$=0.32），并且必须考虑自旋轨道散射（$\lambda_{SO}$ =1.2）。我们的结果明确地表明，表征Ni/Bi超导态的性质强烈依赖于样品厚度。 et.al.|[2309.10705](http://arxiv.org/abs/2309.10705)|null|
|**2023-09-19**|**Unbiased Parameter Estimation for Partially Observed Diffusions**|在本文中，我们考虑在固定时间间隔上具有离散时间观测的部分观测扩散过程的静态参数估计。特别是，我们假设必须对部分观测到的扩散过程进行时间离散，并在有偏差的情况下使用模型，并考虑最大化由此产生的对数似然性。利用一种新的双随机化方案，在马尔可夫随机近似的基础上，我们提出了一种无偏估计静态参数的新方法，即在没有时间离散化偏差的情况下获得最大似然估计量。在假设条件下，我们证明了我们的估计量是无偏的，并在几个数值例子中研究了该方法，表明它可以在经验上优于现有的无偏方法。 et.al.|[2309.10589](http://arxiv.org/abs/2309.10589)|null|

<p align=right>(<a href=#updated-on-20230921>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-09-15**|**Breathing New Life into 3D Assets with Generative Repainting**|基于扩散的文本到图像模型引发了视觉社区、艺术家和内容创作者的巨大关注。这些模型的广泛采用是由于世代质量的显著提高以及对各种模式的有效调节，而不仅仅是文本。然而，将这些2D模型的丰富生成先验提升到3D中是具有挑战性的。最近的工作提出了由扩散模型和神经场的纠缠提供动力的各种管道。我们探索了预训练的2D扩散模型和标准3D神经辐射场作为独立工具的威力，并展示了它们以非学习方式协同工作的能力。这种模块化具有易于部分升级的内在优势，这在这样一个快节奏的领域中成为了一个重要的特性。我们的管道接受任何遗留的可渲染几何体，如纹理或无纹理网格，协调2D生成细化和3D一致性强制工具之间的交互，并以多种格式输出绘制的输入几何体。我们对ShapeNetSem数据集中的广泛对象和类别进行了大规模研究，并从定性和定量两个方面展示了我们方法的优势。项目页面：https://www.obukhov.ai/repainting_3d_assets et.al.|[2309.08523](http://arxiv.org/abs/2309.08523)|**[link](https://github.com/toshas/remesh_isotropic_planar)**|
|**2023-09-14**|**Neural Field Representations of Articulated Objects for Robotic Manipulation Planning**|传统的操作规划方法依赖于环境的显式几何模型来将给定任务公式化为优化问题。然而，从原始传感器输入推断准确的模型本身就是一个难题，尤其是对于铰接物体（例如壁橱、抽屉）。在本文中，我们提出了一种关节对象的神经场表示（NFR），可以直接从图像中进行操作规划。具体来说，在拍摄了一个新的关节物体的几张照片后，我们可以向前模拟它可能的运动，因此，可以直接使用该神经模型进行轨迹优化规划。此外，这种表示可以用于形状重建、语义分割和图像渲染，这在训练和泛化过程中提供了强大的监督信号。我们表明，我们的模型仅在合成图像上训练，能够在模拟和真实图像中为同类看不见的物体提取有意义的表示。此外，我们证明了该表示能够直接从图像中对现实世界中的关节物体进行机器人操作。 et.al.|[2309.07620](http://arxiv.org/abs/2309.07620)|null|
|**2023-09-13**|**Generalizable Neural Fields as Partially Observed Neural Processes**|神经场将信号表示为由神经网络参数化的函数，是传统离散矢量或基于网格的表示的一种很有前途的替代方案。与离散表示相比，神经表示既能很好地扩展分辨率，又是连续的，并且可以是多次可微的。然而，给定我们想要表示的信号数据集，必须为每个信号优化单独的神经场是低效的，并且不能利用信号之间的共享信息或结构。现有的泛化方法将其视为元学习问题，并采用基于梯度的元学习来学习初始化，然后通过测试时间优化对初始化进行微调，或者学习超网络来产生神经场的权重。相反，我们提出了一种新的范式，将神经表征的大规模训练视为部分观察到的神经过程框架的一部分，并利用神经过程算法来解决这一任务。我们证明，这种方法优于最先进的基于梯度的元学习方法和超网络方法。 et.al.|[2309.06660](http://arxiv.org/abs/2309.06660)|null|
|**2023-09-08**|**Single View Refractive Index Tomography with Neural Fields**|折射率层析成像是一个反问题，我们试图从2D投影图像测量中重建场景的3D折射场。折射场本身是不可见的，而是影响光线在空间中传播时路径的连续弯曲。折射场出现在各种各样的科学应用中，从显微镜中的半透明细胞样本到弯曲来自遥远星系的光的暗物质场。这个问题带来了一个独特的挑战，因为折射场直接影响光的路径，使其恢复成为一个非线性问题。此外，与传统的层析成像相比，我们试图通过利用散射在整个介质中的光源的知识，仅从单个视点使用投影图像来恢复折射场。在这项工作中，我们介绍了一种使用基于坐标的神经网络对场景中潜在的连续折射场进行建模的方法。然后，我们使用射线三维空间曲率的显式建模来优化该网络的参数，通过综合分析方法重建折射场。通过在模拟中恢复折射场，并分析光源分布对恢复的影响，证明了我们方法的有效性。然后，我们在模拟暗物质映射问题上测试了我们的方法，在该问题中，我们恢复了真实模拟暗物质分布下的折射场。 et.al.|[2309.04437](http://arxiv.org/abs/2309.04437)|null|
|**2023-09-07**|**BluNF: Blueprint Neural Field**|神经辐射场（NeRF）彻底改变了场景新颖的视图合成，提供了视觉逼真、精确和稳健的隐式重建。虽然最近的方法允许NeRF编辑，例如对象删除、3D形状修改或材料特性操纵，但在这种编辑之前的手动注释使该过程变得乏味。此外，传统的2D交互工具缺乏对3D空间的准确感知，阻碍了对场景的精确操作和编辑。在本文中，我们介绍了一种新的方法，称为蓝图神经场（BluNF），以解决这些编辑问题。BluNF提供了一个强大且用户友好的2D蓝图，实现了直观的场景编辑。通过利用隐式神经表示，BluNF使用先前的语义和深度信息构建场景的蓝图。生成的蓝图可以轻松编辑和操作NeRF表示。我们通过直观的点击和更改机制展示了BluNF的可编辑性，实现了3D操作，如遮罩、外观修改和对象移除。我们的方法对视觉内容创作做出了重大贡献，为该领域的进一步研究铺平了道路。 et.al.|[2309.03933](http://arxiv.org/abs/2309.03933)|null|
|**2023-09-07**|**SimNP: Learning Self-Similarity Priors Between Neural Points**|用于3D对象重建的现有神经场表示要么（1）利用对象级表示，但由于对全局潜在代码的限制而遭受低质量细节，要么（2）能够完美地重建观测，但未能利用对象级先验知识来推断未观察到的区域。我们提出了一种学习类别级自相似性的方法SimNP，它通过将神经点辐射场与类别级自类似性表示相连接，结合了两个世界的优点。我们的贡献是双重的。（1） 我们利用相干点云的概念设计了第一个类别级别的神经点表示。由此产生的神经点辐射场为局部支持的对象区域存储了高级别的细节。（2） 我们了解了如何以无约束和无监督的方式在神经点之间共享信息，这允许在重建过程中根据给定的观测值导出对象的未观察区域。我们表明，SimNP在重建对称的看不见物体区域方面优于以前的方法，超过了建立在类别级或像素对齐辐射场上的方法，同时提供了实例之间的语义对应 et.al.|[2309.03809](http://arxiv.org/abs/2309.03809)|null|
|**2023-09-06**|**CoNeS: Conditional neural fields with shift modulation for multi-sequence MRI translation**|多序列磁共振成像（MRI）在现代临床研究和深度学习研究中都有广泛的应用。然而，在临床实践中，由于患者的不同图像采集协议或造影剂禁忌症，经常会出现一个或多个MRI序列缺失的情况，这限制了在多序列数据上训练的深度学习模型的使用。一种很有前途的方法是利用生成模型来合成缺失的序列，这可以作为替代获取。解决这一问题的最先进方法是基于卷积神经网络（CNN），该网络通常存在频谱偏差，导致高频精细细节的重建较差。在本文中，我们提出了具有移位调制的条件神经场（CoNeS），这是一种以体素坐标为输入并学习用于多序列MRI平移的目标图像的表示的模型。所提出的模型使用多层感知器（MLP）代替CNN作为像素到像素映射的解码器。因此，每个目标图像被表示为神经场，该神经场通过利用学习的潜码的移位调制而被调节在源图像上。在BraTS 2018和前庭神经鞘瘤患者的内部临床数据集上进行的实验表明，所提出的方法在视觉和定量上都优于最先进的多序列MRI翻译方法。此外，我们进行了光谱分析，表明CoNeS能够克服传统CNN模型中常见的光谱偏差问题。为了进一步评估合成图像在临床下游任务中的使用，我们在推理时使用合成图像测试了分割网络。 et.al.|[2309.03320](http://arxiv.org/abs/2309.03320)|**[link](https://github.com/cyjdswx/cones)**|
|**2023-09-06**|**ResFields: Residual Neural Fields for Spatiotemporal Signals**|神经场是一类被训练来表示高频信号的神经网络，近年来由于其在复杂三维数据建模方面的出色性能，特别是通过单个多层感知器（MLP）的大神经符号距离（SDFs）或辐射场（NeRFs），而受到了极大的关注。然而，尽管用MLP表示信号的能力和简单性很强，但由于MLP的容量有限，这些方法在建模大而复杂的时间信号时仍然面临挑战。在本文中，我们提出了一种有效的方法来解决这一限制，将时间残差层纳入神经场，称为ResFields，这是一类专门设计用于有效表示复杂时间信号的新型网络。我们对ResFields的性质进行了全面的分析，并提出了一种矩阵分解技术来减少可训练参数的数量并增强泛化能力。重要的是，我们的公式与现有技术无缝集成，并在各种具有挑战性的任务中持续改进结果：2D视频近似、通过时间SDF的动态形状建模和动态NeRF重建。最后，我们通过展示ResFields在从轻量级捕捉系统的稀疏感官输入捕捉动态3D场景方面的有效性，展示了它的实用性。 et.al.|[2309.03160](http://arxiv.org/abs/2309.03160)|**[link](https://github.com/markomih/ResFields)**|
|**2023-09-01**|**GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields**|开发能够在非结构化现实世界环境中通过视觉观察执行各种操作任务的代理是机器人技术中的一个长期问题。为了实现这一目标，机器人需要对场景的3D结构和语义有全面的了解。在这项工作中，我们提出了 $\textbf｛GNFactor｝$，一种用于多任务机器人操作的视觉行为克隆代理，具有$\textbf｛G｝$通用$\textbf｛N｝$eural功能$\textbf｛F｝$字段。GNFactor联合优化了作为重建模块的可推广神经场（GNF）和作为决策模块的感知转换器，利用了共享的深度3D体素表示。为了在3D中结合语义，重建模块利用视觉语言基础模型（$\textit｛例如｝$ ，Stable Diffusion）将丰富的语义信息提取到深度3D体素中。我们在3个真实机器人任务中评估了GNFactor，并在10个RLBench任务中进行了详细的消融，演示次数有限。我们观察到GNFactor在可见和不可见任务中比当前最先进的方法有了实质性的改进，证明了GNFactor强大的泛化能力。我们的项目网站是https://yanjieze.com/GNFactor/。 et.al.|[2308.16891](http://arxiv.org/abs/2308.16891)|**[link](https://github.com/YanjieZe/GNFactor)**|
|**2023-08-30**|**Active Neural Mapping**|我们用不断学习的神经场景表示来解决主动映射的问题，即主动神经映射。关键在于通过有效的代理移动积极找到要探索的目标空间，从而最大限度地减少在以前看不见的环境中飞行中的地图不确定性。在本文中，我们检验了连续学习神经场的权重空间，并从经验上表明，神经变异性，即对随机权重扰动的预测鲁棒性，可以直接用于测量神经映射的瞬时不确定性。结合神经映射中继承的连续几何信息，可以引导agent找到一条可遍历的路径，以逐渐获得环境知识。我们首次提出了一种用于在线场景重建的具有基于坐标的隐式神经表示的主动映射系统。在视觉逼真的Gibson和Matterport3D环境中的实验证明了所提出方法的有效性。 et.al.|[2308.16246](http://arxiv.org/abs/2308.16246)|null|

<p align=right>(<a href=#updated-on-20230921>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

