[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.11.21
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-11-20**|**Holistic Inverse Rendering of Complex Facade via Aerial 3D Scanning**|在这项工作中，我们使用多视图航空图像，使用神经符号距离场（SDF）重建立面的几何结构、照明和材料。在不需要复杂设备的情况下，我们的方法只将无人机捕捉到的简单RGB图像作为输入，以实现基于物理和照片真实感的新颖视图渲染、重新照明和编辑。然而，现实世界中的立面通常具有复杂的外观，从具有细微细节的漫射岩石到具有镜面反射的大面积玻璃窗，这使得很难处理所有事情。因此，以前的方法可以保留几何细节，但无法重建光滑的玻璃窗或虎钳。为了应对这一挑战，我们引入了三种空间和语义自适应优化策略，包括基于零样本分割技术的语义正则化方法以提高材料一致性，频率软件几何正则化方法来平衡不同表面中的表面平滑度和细节，以及基于可见性探针的方案，以实现对大规模户外环境中的局部照明的有效建模。此外，我们还捕捉了真实世界的立面航空3D扫描图像集和相应的点云，用于训练和基准测试。实验证明，与最先进的基线相比，我们的方法在立面整体逆绘制、新颖的视图合成和场景编辑方面具有卓越的质量。 et.al.|[2311.11825](http://arxiv.org/abs/2311.11825)|null|
|**2023-11-18**|**Structure-Aware Sparse-View X-ray 3D Reconstruction**|X射线以其揭示物体内部结构的能力而闻名，有望为3D重建提供比可见光更丰富的信息。然而，现有的神经辐射场（NeRF）算法忽略了X射线的这一重要性质，导致它们在捕捉成像对象的结构内容方面存在局限性。在本文中，我们提出了一个用于稀疏视图X射线三维重建的框架，即结构感知X射线神经辐射密度场（SAX-NeRF）。首先，我们设计了一个基于线段的转换器（Lineformer）作为SAX NeRF的主干。Linefomer通过对X射线的每个线段内的相关性进行建模，捕捉三维空间中对象的内部结构。其次，我们提出了一种掩模局部全局（MLG）射线采样策略来提取二维投影中的上下文和几何信息。此外，我们还收集了一个更大规模的数据集X3D，涵盖了更广泛的X射线应用。在X3D上的实验表明，SAX-NeRF在新的视图合成和CT重建方面分别比以前的基于NeRF的方法高出12.56和2.49dB。代码、模型和数据将在https://github.com/caiyuanhao1998/SAX-NeRF et.al.|[2311.10959](http://arxiv.org/abs/2311.10959)|**[link](https://github.com/caiyuanhao1998/sax-nerf)**|
|**2023-11-16**|**Adaptive Shells for Efficient Neural Radiance Field Rendering**|神经辐射场在新视图合成中实现了前所未有的质量，但其体积公式仍然昂贵，需要大量样本才能渲染高分辨率图像。体积编码对于表示树叶和头发等模糊几何体至关重要，它们非常适合随机优化。然而，许多场景最终主要由固体表面组成，这些表面可以通过每个像素的单个采样精确渲染。基于这一见解，我们提出了一种神经辐射公式，可以在基于体积和表面的渲染之间平滑过渡，大大加快渲染速度，甚至提高视觉逼真度。我们的方法构造了一个显式网格包络，该包络在空间上限制了神经体积表示。在实体区域中，包络几乎收敛到曲面，并且通常可以使用单个采样进行渲染。为此，我们推广了NeuS公式，该公式具有学习的空间变化的核大小，该核大小对密度的扩展进行编码，将宽核与类体积区域拟合，将紧核与类表面区域拟合。然后，我们提取表面周围窄带的显式网格，其宽度由内核大小决定，并微调该窄带内的辐射场。在推断时，我们将光线投射到网格上，并仅在封闭区域内评估辐射场，从而大大减少了所需的样本数量。实验表明，我们的方法能够以非常高的保真度实现高效的渲染。我们还证明了提取的包络可以实现动画和模拟等下游应用。 et.al.|[2311.10091](http://arxiv.org/abs/2311.10091)|null|
|**2023-11-16**|**Reconstructing Continuous Light Field From Single Coded Image**|我们提出了一种从单个观测图像重建目标场景的连续光场的方法。我们的方法两全其美：用于压缩光场采集的联合孔径曝光编码和用于视图合成的神经辐射场（NeRF）。在相机中实现的联合孔径曝光编码能够将3D场景信息有效地嵌入到观察到的图像中，但在以前的工作中，它仅用于重建离散的光场视图。基于NeRF的神经渲染能够从连续视点对3D场景进行高质量的视图合成，但当只给出单个图像作为输入时，它很难实现令人满意的质量。我们的方法将这两种技术集成到一个高效且端到端可训练的管道中。经过对各种场景的训练，我们的方法可以准确高效地重建连续光场，而无需任何测试时间优化。据我们所知，这是第一项将两个世界连接起来的工作：有效获取三维信息的相机设计和神经渲染。 et.al.|[2311.09646](http://arxiv.org/abs/2311.09646)|null|
|**2023-11-11**|**Aria-NeRF: Multimodal Egocentric View Synthesis**|基于受神经辐射场（NeRFs）启发的可微分体积射线跟踪，我们寻求加快开发从以自我为中心的数据训练的丰富的多模式场景模型的研究。从以自我为中心的图像序列构建类似NeRF的模型在理解人类行为方面发挥着关键作用，并在VR/AR领域具有多种应用。这种以自我为中心的类NeRF模型可以用作现实模拟，对能够在现实世界中执行任务的智能代理的发展做出了重大贡献。以自我为中心的视图合成的未来可能会通过使用多模式传感器（如用于自我运动跟踪的IMU、用于捕捉表面纹理和人类语言上下文的音频传感器以及用于推断场景中人类注意力模式的眼睛凝视跟踪器）来增强视觉数据，从而产生超越当今NeRF的新环境表示。为了支持和促进以自我为中心的多模式场景建模的开发和评估，我们提出了一个全面的多模式自我中心视频数据集。该数据集提供了一个全面的感官数据集，包括RGB图像、眼动追踪相机镜头、麦克风录音、气压计的气压读数、GPS的位置坐标、Wi-Fi和蓝牙的连接细节，以及与磁力计配对的双频IMU数据集（1kHz和800Hz）的信息。数据集是使用Meta Aria Glasses可穿戴设备平台收集的。该数据集中捕获的各种数据模式和真实世界背景为我们进一步理解人类行为奠定了坚实的基础，并在VR、AR和机器人领域实现了更身临其境的智能体验。 et.al.|[2311.06455](http://arxiv.org/abs/2311.06455)|null|
|**2023-11-10**|**Improved Positional Encoding for Implicit Neural Representation based Compact Data Representation**|采用位置编码来捕获隐式神经表示（INR）中编码信号的高频信息。在本文中，我们提出了一种新的位置编码方法，该方法提高了INR的重建质量。所提出的嵌入方法对于紧凑的数据表示更有利，因为它比现有方法具有更多的频率基。我们的实验表明，该方法在压缩任务中没有引入任何额外的复杂性，并且在新的视图合成中具有更高的重建质量，从而在率失真性能上获得了显著的增益。 et.al.|[2311.06059](http://arxiv.org/abs/2311.06059)|null|
|**2023-11-09**|**Real-Time Neural Rasterization for Large Scenes**|提出了一种新的大场景真实感实时新视图合成方法。现有的神经渲染方法可以生成逼真的结果，但主要适用于小规模场景（<50平方米），在大规模场景（>10000平方米）中存在困难。传统的基于图形的光栅化渲染对于大型场景来说速度很快，但缺乏真实感，并且需要昂贵的手动创建资源。我们的方法结合了两全其美，将中等质量的脚手架网格作为输入，学习神经纹理场和着色器来建模与视图相关的效果，以增强真实感，同时仍然使用标准图形管道进行实时渲染。我们的方法优于现有的神经渲染方法，为大型自动驾驶和无人机场景提供了至少30倍的渲染速度和相当或更好的真实感。我们的工作是第一个实现大型真实世界场景的实时渲染。 et.al.|[2311.05607](http://arxiv.org/abs/2311.05607)|null|
|**2023-11-09**|**Reconstructing Objects in-the-wild for Realistic Sensor Simulation**|从真实世界的数据中重建物体并以新颖的视图渲染它们，对于为机器人训练和测试的模拟带来真实性、多样性和规模至关重要。在这项工作中，我们提出了NeuSim，这是一种新的方法，可以根据在距离和有限视点捕获的稀疏野外数据来估计精确的几何结构和逼真的外观。为了实现这一目标，我们将物体表面表示为神经符号距离函数，并利用激光雷达和相机传感器数据来重建平滑准确的几何体和法线。我们用一种稳健的、受物理启发的反射率表示法对物体外观进行建模，该表示法对野外数据有效。我们的实验表明，NeuSim在具有稀疏训练视图的具有挑战性的场景中具有强大的视图合成性能。此外，我们展示了将NeuSim资产组合到虚拟世界中，并生成用于评估自动驾驶感知模型的真实多传感器数据。 et.al.|[2311.05602](http://arxiv.org/abs/2311.05602)|null|
|**2023-11-09**|**BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis**|从视频中合成逼真的4D人头头像对于VR/AR、远程呈现和视频游戏应用至关重要。尽管现有的基于神经辐射场（NeRF）的方法实现了高保真度的结果，但计算费用限制了它们在实时应用中的使用。为了克服这一限制，我们引入了BakedAvatar，这是一种用于实时神经头部化身合成的新表示，可部署在标准多边形光栅化管道中。我们的方法从学习的头部等值面中提取可变形的多层网格，并计算与表情、姿势和视图相关的外观，这些外观可以烘焙到静态纹理中，以实现高效的光栅化。因此，我们提出了一种用于神经头化身合成的三阶段流水线，包括学习连续变形、流形和辐射场，提取分层网格和纹理，以及使用差分光栅化微调纹理细节。实验结果表明，我们的表示生成的合成结果质量与其他最先进的方法相当，同时显著减少了所需的推理时间。我们进一步展示了单眼视频中的各种头部化身合成结果，包括视图合成、面部再现、表情编辑和姿势编辑，所有这些都是以交互式帧率进行的。 et.al.|[2311.05521](http://arxiv.org/abs/2311.05521)|null|
|**2023-11-09**|**VoxNeRF: Bridging Voxel Representation and Neural Radiance Fields for Enhanced Indoor View Synthesis**|创建高质量的视图合成对于沉浸式应用程序至关重要，但仍然存在问题，尤其是在室内环境和实时部署中。当前的技术经常需要大量的计算时间来进行训练和渲染，并且由于不充分的几何结构，经常产生不太理想的3D表示。为了克服这一点，我们引入了VoxNeRF，这是一种利用体积表示来提高室内视图合成质量和效率的新方法。首先，VoxNeRF构建结构化的场景几何体，并将其转换为基于体素的表示。我们使用多分辨率哈希网格自适应地捕捉空间特征，有效地管理室内场景的遮挡和复杂几何结构。其次，我们提出了一种独特的体素引导的高效采样技术。这一创新有选择地将计算资源集中在射线段的最相关部分，大大减少了优化时间。我们针对三个公共室内数据集验证了我们的方法，并证明VoxNeRF优于最先进的方法。值得注意的是，它在减少训练和渲染时间的同时实现了这些收益，速度甚至超过了Instant NGP，使技术更接近实时。 et.al.|[2311.05289](http://arxiv.org/abs/2311.05289)|null|

<p align=right>(<a href=#updated-on-20231121>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-11-20**|**PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction**|我们提出了一种无姿态大型重建模型（PF-LRM），用于从一些未经处理的图像重建3D对象，即使视觉重叠很小，同时在单个A100 GPU上估计1.3秒内的相对相机姿态。PF-LRM是一种高度可扩展的方法，利用自关注块在3D对象令牌和2D图像令牌之间交换信息；我们为每个视图预测一个粗略的点云，然后使用可微分透视n-point（PnP）解算器来获得相机姿势。当在约1M个对象的大量多视图姿态数据上训练时，PF-LRM表现出强大的跨数据集泛化能力，并且在各种看不见的评估数据集上，在姿态预测精度和3D重建质量方面大大优于基线方法。我们还通过快速前馈推理证明了我们的模型在下游文本/图像到3D任务中的适用性。我们的项目网站位于：https://totoro97.github.io/pf-lrm。 et.al.|[2311.12024](http://arxiv.org/abs/2311.12024)|null|
|**2023-11-19**|**GaussianDiffusion: 3D Gaussian Splatting for Denoising Diffusion Probabilistic Models with Structured Noise**|文本到3D以其高效的生成方法和广阔的创作潜力而闻名，在AIGC领域引起了极大的关注。然而，Nerf和2D扩散模型的融合经常产生过饱和图像，由于像素绘制方法的限制，对下游工业应用造成了严重限制。高斯散射最近取代了基于NeRF的方法中流行的传统逐点采样技术，彻底改变了3D重建的各个方面。本文介绍了一种新的基于高斯飞溅的文本到3D内容生成框架，通过单个高斯球体透明度对图像饱和度进行精细控制，从而生成更逼真的图像。在三维生成中实现多视图一致性的挑战极大地阻碍了建模的复杂性和准确性。受SJC的启发，我们探索使用多视图噪声分布来干扰由3D高斯飞溅生成的图像，旨在纠正多视图几何中的不一致性。我们巧妙地设计了一种有效的方法来生成噪声，该方法从不同的角度产生高斯噪声，所有这些都源于共享的噪声源。此外，基于香草3D高斯的生成倾向于将模型困在局部极小值中，导致漂浮物、毛刺或增殖元素等伪影。为了缓解这些问题，我们提出了变分高斯飞溅技术来提高3D外观的质量和稳定性。据我们所知，我们的方法首次在整个3D内容生成过程中全面利用高斯飞溅。 et.al.|[2311.11221](http://arxiv.org/abs/2311.11221)|null|
|**2023-11-18**|**LOSTU: Fast, Scalable, and Uncertainty-Aware Triangulation**|三角测量算法通常旨在最小化重投影（ $L_2$）误差，但这仅在相机参数或相机姿态没有误差时提供最大似然估计。尽管最近的进步已经产生了估计相机参数的技术，考虑到3D点的不确定性，但大多数运动结构（SfM）管道仍然使用旧的三角测量算法。这项工作利用最近的发现，提供了一种快速、可扩展和统计优化的三角测量方法，称为LOSTU。结果表明，与传统的$L_2$ 三角测量方法相比，LOSTU始终产生较低的三维重建误差——通常允许LOSTU成功地三角测量更多的点。此外，除了提供更好的3D重建外，LOSTU可以比Levenberg-Marquardt（或类似）优化方案快得多。 et.al.|[2311.11171](http://arxiv.org/abs/2311.11171)|null|
|**2023-11-18**|**Invariant-based Mapping of Space During General Motion of an Observer**|本文探索了基于视觉运动的不变量，产生了一个新的瞬时域，其中：a）即使2D图像由于相机运动而发生连续变化，静止环境也被感知为不变，b）可以在特定的子空间中检测并潜在地避免障碍物，c）可以潜在地检测运动对象。为了实现这一点，我们使用了从可测量光流导出的非线性函数，这些函数与几何三维不变量相关联。我们展示的模拟涉及一台相对于3D对象平移和旋转的相机，捕捉相机投影图像的快照。我们表明，随着时间的推移，对象在新域中看起来没有变化。我们处理来自KITTI数据集的真实数据，并演示如何分割空间以识别自由导航区域并检测预定子空间内的障碍物。此外，我们还介绍了基于KITTI数据集的运动物体识别和分割以及形状恒定性可视化的初步结果。这种表示是直接的，依赖于用于光流的简单去旋转的函数。这种表示只需要一个相机，它是基于像素的，适合并行处理，并且它消除了3D重建技术的必要性。 et.al.|[2311.11130](http://arxiv.org/abs/2311.11130)|null|
|**2023-11-18**|**Multiple View Geometry Transformers for 3D Human Pose Estimation**|在这项工作中，我们旨在提高变形金刚在多视图三维人体姿态估计中的三维推理能力。最近的工作集中在基于端到端学习的转换器设计上，该设计难以准确地解析几何信息，尤其是在遮挡期间。相反，我们提出了一种新的混合模型MVGFormer，它具有一系列以迭代方式组织的几何和外观模块。几何模块是免学习的，并以几何方式处理所有与视点相关的3D任务，这显著提高了模型的泛化能力。外观模块是可学习的，专门用于从图像信号中端到端地估计2D姿态，这使它们即使在发生遮挡时也能实现准确的估计，从而形成一个既准确又可推广到新相机和几何结构的模型。我们针对域内和域外环境评估了我们的方法，在这些环境中，我们的模型始终优于最先进的方法，尤其是在域外环境中。我们将发布代码和模型：https://github.com/XunshanMan/MVGFormer. et.al.|[2311.10983](http://arxiv.org/abs/2311.10983)|null|
|**2023-11-18**|**Structure-Aware Sparse-View X-ray 3D Reconstruction**|X射线以其揭示物体内部结构的能力而闻名，有望为3D重建提供比可见光更丰富的信息。然而，现有的神经辐射场（NeRF）算法忽略了X射线的这一重要性质，导致它们在捕捉成像对象的结构内容方面存在局限性。在本文中，我们提出了一个用于稀疏视图X射线三维重建的框架，即结构感知X射线神经辐射密度场（SAX-NeRF）。首先，我们设计了一个基于线段的转换器（Lineformer）作为SAX NeRF的主干。Linefomer通过对X射线的每个线段内的相关性进行建模，捕捉三维空间中对象的内部结构。其次，我们提出了一种掩模局部全局（MLG）射线采样策略来提取二维投影中的上下文和几何信息。此外，我们还收集了一个更大规模的数据集X3D，涵盖了更广泛的X射线应用。在X3D上的实验表明，SAX-NeRF在新的视图合成和CT重建方面分别比以前的基于NeRF的方法高出12.56和2.49dB。代码、模型和数据将在https://github.com/caiyuanhao1998/SAX-NeRF et.al.|[2311.10959](http://arxiv.org/abs/2311.10959)|**[link](https://github.com/caiyuanhao1998/sax-nerf)**|
|**2023-11-17**|**Labeling Indoor Scenes with Fusion of Out-of-the-Box Perception Models**|图像注释阶段是训练和评估对象检测和语义分割模型所需的关键且通常是最耗时的部分。在新环境中部署现有模型通常需要检测训练数据中不存在的新语义类。此外，室内场景包含显著的视点变化，需要通过训练的感知模型来正确处理。我们建议利用最先进的自下而上分割（SAM）、对象检测（Detic）和语义分割（MaskFormer）模型的最新进展，所有这些都是在大规模数据集上训练的。我们的目标是开发一种具有成本效益的标记方法，以获得用于室内环境中的语义分割和对象实例检测的伪标签，最终目标是促进各种下游任务的轻量级模型的训练。我们还提出了一个多视图标记融合阶段，该阶段考虑了场景的多个视图可用的设置，并可用于识别和纠正单个视图的不一致性。我们在主动视觉数据集和ADE20K数据集上证明了所提出的方法的有效性。我们通过将标记过程与人工注释进行比较来评估标记过程的质量。此外，我们还证明了所获得的标签在下游任务（如目标导航和零件发现）中的有效性。在对象目标导航的背景下，与使用大型单片视觉语言预训练模型的零样本基线相比，我们描述了使用这种融合方法增强的性能。 et.al.|[2311.10883](http://arxiv.org/abs/2311.10883)|null|
|**2023-11-16**|**Collection, Collation, and Comparison of 3D Coronal CME Reconstructions**|预测日冕物质抛射的影响是当前空间天气预报工作的一个主要焦点。通常，CME的特性是从立体日冕图像中重建的，然后用于对CME的行星际演化进行正向建模。了解日冕重建的不确定性是决定任何预测不确定性的关键因素。日冕物质抛射重建的目录越来越多，但这些目录之间还没有进行广泛的比较。在这里，我们开发了一个在任何冠状重建中测量的活属性列表（LLAMACoRe），这是一个单独目录的在线集合，我们打算不断更新。在第一个版本中，我们使用了24个不同目录的结果，并在2007-2014年间使用STEREO观测进行了3D重建。我们整理了各个目录，确定哪些重建对应于相同的事件。LLAMACoRe包含1863次CME的2954次重建。其中510个日冕物质抛射包含来自不同目录的多重重建。使用每个CME的最佳约束值，我们发现组合目录再现了通常已知的太阳周期趋势。我们确定了同一事件的两次独立重建之间的典型差异，发现纬度为4.0度，经度为8.0度，倾角为24.0度，角宽为9.5度，形状参数kappa为0.1，速度为115 km/s，质量为2.5e15 g。这些仍然是整个太阳周期中最可能的值，尽管我们在朝向太阳最大值的偏差中发现了更极端的异常值。 et.al.|[2311.10712](http://arxiv.org/abs/2311.10712)|null|
|**2023-11-16**|**On the Overconfidence Problem in Semantic 3D Mapping**|语义3D映射是一个最近感兴趣的话题，它融合了多个视图之间的深度和图像分割信息，以实时构建用对象类注释的3D地图。本文强调了融合过度自信问题，在该问题中，传统的映射方法即使在不正确的情况下也会为整个映射分配高置信度，从而导致输出校准错误。提出了几种改进聚变管道不同阶段不确定度校准的方法，并在ScanNet数据集上进行了比较。我们表明，使用最广泛的贝叶斯融合策略是校准最差的策略之一，并提出了一种结合融合和校准的学习管道GLFS，它在保持实时能力的同时实现了更高的精度和3D地图校准。我们进一步说明了地图校准对下游任务的重要性，表明在模块化ObjectNav代理上结合适当的语义融合可以提高其成功率。我们的代码将在Github上提供，以便在接受后进行再现。 et.al.|[2311.10018](http://arxiv.org/abs/2311.10018)|null|
|**2023-11-16**|**DSR-Diff: Depth Map Super-Resolution with Diffusion Model**|彩色引导深度图超分辨率（CDSR）通过相应的高质量彩色图提高了低质量深度图的空间分辨率，有利于3D重建、虚拟现实和增强现实等各种应用。虽然传统的CDSR方法通常依赖于卷积神经网络或变换器，但扩散模型（DM）在高级视觉任务中表现出了显著的有效性。在这项工作中，我们提出了一种新的CDSR范式，该范式利用潜在空间内的扩散模型来生成深度图超分辨率的指导。所提出的方法包括制导生成网络（GGN）、深度图超分辨率网络（DSRN）和制导恢复网络（GRN）。GGN专门设计用于生成指南，同时管理其紧凑性。此外，我们将一个简单但有效的特征融合模块和转换器式特征提取模块集成到DSRN中，使其能够在多模型图像的提取、融合和重建中利用引导先验。考虑到准确性和效率，与最先进的方法相比，我们提出的方法在大量实验中显示出优越的性能。我们的代码将在https://github.com/shiyuan7/DSR-Diff. et.al.|[2311.09919](http://arxiv.org/abs/2311.09919)|null|

<p align=right>(<a href=#updated-on-20231121>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-11-20**|**Macroscopic description of a heavy particle immersed within a flow of light particles**|研究了一种基于轻点溶剂颗粒与重溶质颗粒弹性碰撞的微观流体动力学模型，其中轻颗粒具有与背景流相对应的速度分布。考虑到溶剂颗粒速度的一系列稳定背景流和分布，以广义Ornstein-Uhlenbeck过程的形式导出了重颗粒行为的宏观Langevin型描述。在前导阶，该过程中的漂移项取决于背景流的几何结构和重粒子的大小，而漂移项和扩散项都随轻粒子速度分布的矩而缩放。然后设计了模拟微观流体动力学模型的计算方法，以证实理论结果。为了实现长时间随机模拟，模拟是在与重粒子共同移动的框架中进行的。针对溶剂颗粒的一系列分布，导出了在共同移动框架的边界处对进入的溶剂颗粒的位置和速度分布进行采样的有效方法。仿真结果与理论结果吻合较好。 et.al.|[2311.12021](http://arxiv.org/abs/2311.12021)|null|
|**2023-11-20**|**Brownian bridge limit of path measures in the upper tail of KPZ models**|对于KPZ普适性类的模型，如平面最后通道渗流（LPP）的零温度模型和定向聚合物的正温度模型，其上尾行为是最近感兴趣的主题，特别关注相关的路径测量（即测地线或聚合物）。对于指数LPP，在巴苏甘古利建立了扩散波动。在有向景观中，利用刘和王柳的精确公式，建立了LPP的连续极限、一点的极限高斯度以及KPZ不动点的相关有限维分布。在这些工作中进一步推测，相应测地线的极限应该是布朗桥。我们在零温度和正温度下都证明了这一点；对于后者，无论是一点的极限还是波动的规模，以前都不为人所知。我们的论点不是依赖于公式（正温度文献中仍然缺少这些公式），而是几何的和概率的，以Ganguly Hegde关于上尾下重量和自由能分布的结果为起点。另一个关键因素涉及新的聚结估计，在这些模型中使用最近发现的位移不变性Borodin-Gorin-Wheeler开发。最后，我们的证明还深入了解了在上尾条件下聚合物测度的结构，在随机骨架周围建立了猝灭的局部化指数。 et.al.|[2311.12009](http://arxiv.org/abs/2311.12009)|null|
|**2023-11-20**|**Extreme heterogeneity in the microrheology of lamellar surfactant gels analyzed with neural networks**|采用粒子跟踪微流变学方法研究了基于十六烷基三甲基氯化铵（CTAC）和十六烷基硬脂醇的层状凝胶网络的粘弹性不均匀性。使用递归神经网络（RNN）结构来估计以分数布朗运动移动的探测球轨迹的小部分上的赫斯特指数 $H$。因此，通过神经网络的轨迹动态分割首次被用于微观流变学，并且它比使用均方位移要准确得多。414个粒子的系综产生在时间上次扩散的均方位移（MSD）$t$，其幂律形式为$t^｛0.74\pm0.02｝$，表明幂律粘弹性。对$H$ 概率分布的RNN分析，结合对单个轨迹的时间平均MSD的详细分析，揭示了由整体MSD的简单缩放所掩盖的不同扩散过程，例如笼化现象，这导致了层状凝胶的复杂粘弹性。 et.al.|[2311.11941](http://arxiv.org/abs/2311.11941)|null|
|**2023-11-20**|**An Image is Worth Multiple Words: Multi-attribute Inversion for Constrained Text-to-Image Synthesis**|我们考虑了用用户提供的参考图像约束扩散模型输出的问题。我们的主要目标是从这个单一的参考图像中提取多个属性（例如，颜色、对象、布局、样式），然后用它们生成新的样本。现有工作的一行提出将参考图像反转为单个文本条件向量，从而能够使用该学习令牌生成新样本。然而，这些方法不会学习将模型输出条件化为上述多个属性所必需的多个令牌。另一系列技术扩展了反演空间来学习多个嵌入，但它们只沿着层维度（例如，DDPM模型的每层一个）或时间步长维度（去噪过程中的一组时间步长一个）来学习，从而导致次优属性解纠缠。为了解决上述差距，本文的第一个贡献是进行广泛的分析，以确定在去噪过程的哪个维度中捕获了哪些属性。如上所述，我们考虑了时间步长维度（在反向去噪中）以及DDPM模型层维度。我们观察到，通常在同一组模型层和/或在相同的去噪时间步长中捕获这些属性的子集。例如，颜色和样式在相同的U-Net层中捕获，而布局和颜色在相同的时间步长阶段中捕获。因此，仅针对时间步长维度或层维度设计的反演过程不足以解开所有属性。这导致了我们的第二个贡献，即我们设计了一种新的多属性反演算法MATTE，该算法具有相关的解纠缠增强正则化损失，该算法在两个维度上运行，并明确导致四个解纠缠的标记（颜色、风格、布局和对象）。 et.al.|[2311.11919](http://arxiv.org/abs/2311.11919)|null|
|**2023-11-20**|**Evolution of internal gravity waves in meso-scale eddies**|我们研究了波-涡相互作用和在相干中尺度涡中传播的内部重力波耗散的影响，该数值模型基于六维辐射传输方程，使用一种新的数值模型称为内波能量模型进行模拟。我们使用了理想化的平均流结构和分层，其动机是对加那利洋流系统中相干涡的观测。在使用Garret-Munk模型谱作为初始条件的自旋下降模拟中，我们发现波浪能量在涡流边缘处降低。由于涡流外和边缘处水平各向异性的发展，横向剪切导致波浪能增益，而垂直剪切导致波浪能量损失，而波浪能量损失在涡流边缘处增强。垂直剪切引起的波浪耗散引起的波浪能量损失大于水平剪切。我们的结果显示了气旋和反气旋涡旋中内部重力波的相似行为。垂直波折射引起的波耗散主要发生在表面附近的涡流边缘，其中相关的垂直扩散系数范围从 $\kappa\approx\mathcal｛O｝（10^｛-7｝）$到$\mathcal｝（10 ^｛-5｝）\，\rm m^2s^｛-1｝$ 。 et.al.|[2311.11916](http://arxiv.org/abs/2311.11916)|null|
|**2023-11-20**|**Diffusion with two resetting points**|我们研究了布朗粒子在随机重置到一对位置时的目标搜索问题。平均搜索时间通过最优重置速率最小化，与众所周知的单位点情况相比，最优重置速率不是平稳变化的，但随着一个重置位点的位置变化而表现出不连续的转变，同时保持粒子的初始位置固定。不连续性在位置空间中的“液气”临界点处消失。如果进一步位置的相对权重包含在区间 $[2.9028…，8.5603…]$ 中，则该临界点存在。该设置可以映射到具有切换扩散系数的间歇搜索问题上，并代表了研究分布式重置的最小模型。 et.al.|[2311.11897](http://arxiv.org/abs/2311.11897)|null|
|**2023-11-20**|**Log-periodic oscillations as real-time signatures of hierarchical dynamics in proteins**|动力系统的时间相关弛豫可能表现出叠加了对数周期振荡的幂律行为。Sornette[Phys.Rep.297239（1998）]表明，这种行为可以用系统的离散尺度不变性来解释，该不变性与对数尺度上的离散和等距时间尺度有关。例子包括金融崩溃、随机扩散和量子拓扑材料等不同领域。最近的时间分辨实验和分子动力学模拟表明，离散尺度不变性也可能适用于蛋白质的层次动力学，其中几个快速的局部构象变化是发生缓慢全局转变的先决条件。将基于熵的时间尺度分析和马尔可夫状态建模应用于简单的一维层次模型和生物分子模拟数据，发现层次系统通常会产生对数间隔的离散时间尺度。通过引入一个一维反应坐标，该坐标共同解释了分层耦合的自由度，自由能景观呈现出具有两个亚稳态的特征阶梯形状，这导致了系统的对数周期性时间演化。原木振荡的周期反映了能源景观的有效粗糙度，在简单的情况下可以根据楼梯景观的屏障来解释。 et.al.|[2311.11839](http://arxiv.org/abs/2311.11839)|null|
|**2023-11-20**|**Holistic Inverse Rendering of Complex Facade via Aerial 3D Scanning**|在这项工作中，我们使用多视图航空图像，使用神经符号距离场（SDF）重建立面的几何结构、照明和材料。在不需要复杂设备的情况下，我们的方法只将无人机捕捉到的简单RGB图像作为输入，以实现基于物理和照片真实感的新颖视图渲染、重新照明和编辑。然而，现实世界中的立面通常具有复杂的外观，从具有细微细节的漫射岩石到具有镜面反射的大面积玻璃窗，这使得很难处理所有事情。因此，以前的方法可以保留几何细节，但无法重建光滑的玻璃窗或虎钳。为了应对这一挑战，我们引入了三种空间和语义自适应优化策略，包括基于零样本分割技术的语义正则化方法以提高材料一致性，频率软件几何正则化方法来平衡不同表面中的表面平滑度和细节，以及基于可见性探针的方案，以实现对大规模户外环境中的局部照明的有效建模。此外，我们还捕捉了真实世界的立面航空3D扫描图像集和相应的点云，用于训练和基准测试。实验证明，与最先进的基线相比，我们的方法在立面整体逆绘制、新颖的视图合成和场景编辑方面具有卓越的质量。 et.al.|[2311.11825](http://arxiv.org/abs/2311.11825)|null|
|**2023-11-20**|**Nanoswimmers in a ratchet potential: Effects of a transverse rocking force**|我们研究了化学纳米游泳运动员在棘轮电势中的动力学，该电势在横向方向上周期性地振荡。作为机械化学耦合的结果，自推进速度变得与力相关，并且粒子轨迹在棘轮调制的方向上被校正。纳米wimmer平均速度的大小和方向取决于摇摆幅度和频率。值得注意的是，对于大于旋转扩散逆相关时间的频率，速度表现出振荡行为，作为振幅和频率的函数，符号多次反转。这些发现表明，机械化学耦合可以用于控制纳米级化学活性颗粒的运动。 et.al.|[2311.11735](http://arxiv.org/abs/2311.11735)|null|
|**2023-11-20**|**Hidden asymptotics for the weak solutions of the strongly stratified Boussinesq system without rotation**|当弗劳德数为零时，强分层Boussinesq系统的渐近性已经过研究，但令人惊讶的是，所得到的极限系统并不取决于热扩散率 $\nu$'。在本文中，我们获得了更丰富的渐近性（取决于$\nu$'），并且我们对初始数据的假设更少。对于旋转流体系统，达到这些极限的唯一方法是考虑非传统的初始数据：对于经典地依赖于全空间变量的函数，我们只根据垂直坐标添加第二个。由于对极限系统结构的精细研究和调整的Strichartz估计，我们在弱Leray型解的情况下获得了收敛性，尽可能提供显式收敛速度。在更简单的情况$\nu$=$\nu$ ’中，我们能够改进Strichartz估计和收敛率。 et.al.|[2311.11731](http://arxiv.org/abs/2311.11731)|null|

<p align=right>(<a href=#updated-on-20231121>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-11-20**|**NePF: Neural Photon Field for Single-Stage Inverse Rendering**|我们提出了一种新的单级框架——神经光子场（NePF），以解决多视图图像的不适定逆绘制问题。与以前在多个阶段恢复几何、材料和照明并从不同神经场的各种多层感知器中提取特性的方法相反，我们质疑这种复杂性，并介绍了我们的方法-一个统一恢复所有特性的单阶段框架。NePF通过充分利用神经隐式曲面的权重函数背后的物理含义和与视图相关的辐射来实现这种统一。此外，我们还介绍了一种创新的基于坐标的照明模型，用于快速基于体积的物理渲染。为了正则化这种照明，我们实现了用于散射估计的次表面散射模型。我们在真实数据集和合成数据集上评估了我们的方法。结果证明了我们的方法在恢复高保真几何和视觉上合理的材料属性方面的优越性。 et.al.|[2311.11555](http://arxiv.org/abs/2311.11555)|null|
|**2023-11-15**|**RENI++ A Rotation-Equivariant, Scale-Invariant, Natural Illumination Prior**|反向渲染是一个不适定的问题。以前的工作试图通过关注对象或场景形状或外观的先验来解决这个问题。在这项工作中，我们转而关注自然照明的先验。目前的方法依赖于球面谐波照明或其他通用表示，充其量，依赖于参数的简单化先验。这导致在照明条件的表现力方面对反向设置的限制，尤其是在考虑镜面反射时。我们提出了一种基于变分自动解码器和变换器解码器的条件神经场表示。我们扩展了矢量神经元，将等方差直接构建到我们的架构中，并通过尺度不变损失函数利用深度估计的见解，实现了高动态范围（HDR）图像的精确表示。其结果是一个紧凑的、旋转等变的HDR神经照明模型，能够捕捉自然环境地图中复杂的高频特征。在一个由1.6K HDR自然场景环境图组成的精心策划的数据集上训练我们的模型，我们将其与传统表示进行比较，证明其适用于反向渲染任务，并显示部分观测的环境图完成情况。我们在https://github.com/JADGardner/ns_reni et.al.|[2311.09361](http://arxiv.org/abs/2311.09361)|**[link](https://github.com/jadgardner/ns_reni)**|
|**2023-11-15**|**Data Augmentations in Deep Weight Spaces**|在权重空间中学习，神经网络处理其他深度神经网络的权重，已成为一个很有前途的研究方向，在各个领域都有应用，从分析和编辑神经领域和隐式神经表示，到网络修剪和量化。最近的工作设计了在该空间中进行有效学习的架构，考虑到了其独特的置换等变结构。不幸的是，到目前为止，这些架构存在严重的过拟合问题，并被证明受益于大型数据集。这带来了重大挑战，因为为这种学习设置生成数据既费力又耗时，因为每个数据样本都是必须训练的一整套网络权重。在本文中，我们通过研究权重空间的数据增强来解决这一困难，这是一组能够在不需要训练额外输入权重空间元素的情况下实时生成新数据示例的技术。我们首先回顾了最近提出的几个数据增强方案%，并将其分为几类。然后，我们介绍了一种新的基于Mixup方法的增强方案。我们评估了这些技术在现有基准以及我们生成的新基准上的性能，这对未来的研究很有价值。 et.al.|[2311.08851](http://arxiv.org/abs/2311.08851)|null|
|**2023-11-14**|**Instant3D: Instant Text-to-3D Generation**|文本到三维生成，旨在通过文本提示合成生动的三维对象，引起了计算机视觉界的广泛关注。虽然已有的几项工作在这项任务上取得了令人印象深刻的成果，但它们主要依赖于耗时的优化范式。具体来说，这些方法为每个文本提示从头开始优化神经场，生成一个对象大约需要一个小时或更长时间。这种繁重和重复的培训成本阻碍了他们的实际部署。在本文中，我们提出了一种新的快速文本到三维生成框架，称为Instant3D。一旦经过训练，Instant3D就能够通过一次前馈网络运行，在不到一秒钟的时间内为看不见的文本提示创建一个3D对象。我们通过设计一个新的网络来实现这一惊人的速度，该网络直接从文本提示构建3D三平面。我们的Instant3D的核心创新在于探索将文本条件有效地注入网络的策略。此外，我们提出了一种简单而有效的激活函数，即缩放的sigmoid函数，以取代原始的sigmoid函数，它将训练收敛速度提高了十倍以上。最后，为了解决3D生成中的Janus（多头）问题，我们提出了一种自适应Perp-Neg算法，该算法可以在训练过程中根据Janus问题的严重程度动态调整其概念否定量表，有效地降低了多头效应。在各种基准数据集上进行的大量实验表明，所提出的算法在质量和数量上都优于最先进的方法，同时实现了显著更好的效率。项目页面位于https://ming1993li.github.io/Instant3DProj. et.al.|[2311.08403](http://arxiv.org/abs/2311.08403)|null|
|**2023-11-13**|**On the mathematical replication of the MacKay effect from redundant stimulation**|在这项研究中，我们研究了视觉感知与初级视觉皮层（V1）神经活动的数学建模之间的复杂联系，重点是复制麦凯效应[MacKay，Nature 1957]。虽然分叉理论一直是解决神经科学问题的一种突出的数学方法，特别是在描述V1中由于参数变化而自发形成的模式时，它在具有局部感觉输入的场景中面临挑战。例如，这一点在麦凯的心理物理学实验中很明显，在该实验中，视觉刺激信息的冗余导致了不规则的形状，使分叉理论和多尺度分析的效果较差。为了解决这个问题，我们遵循了一个基于Amari型神经场模型的输入输出可控性的数学观点。该框架将感觉输入视为一种控制功能，通过视觉刺激的视网膜-皮层图进行皮层表征，捕捉刺激的不同特征，特别是麦凯漏斗模式“麦凯射线”中的中心冗余。从控制理论的角度，讨论了Amari型方程对于线性和非线性响应函数的精确可控性。然后，应用于麦凯效应复制，我们调整了表示神经元内连接的参数，以确保在没有感觉输入的情况下，皮层活动指数稳定到静止状态，我们进行了定量和定性研究，以表明它捕捉到了麦凯报告的诱导后图像的所有基本特征 et.al.|[2311.07338](http://arxiv.org/abs/2311.07338)|null|
|**2023-11-10**|**Improved Positional Encoding for Implicit Neural Representation based Compact Data Representation**|采用位置编码来捕获隐式神经表示（INR）中编码信号的高频信息。在本文中，我们提出了一种新的位置编码方法，该方法提高了INR的重建质量。所提出的嵌入方法对于紧凑的数据表示更有利，因为它比现有方法具有更多的频率基。我们的实验表明，该方法在压缩任务中没有引入任何额外的复杂性，并且在新的视图合成中具有更高的重建质量，从而在率失真性能上获得了显著的增益。 et.al.|[2311.06059](http://arxiv.org/abs/2311.06059)|null|
|**2023-11-09**|**BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis**|从视频中合成逼真的4D人头头像对于VR/AR、远程呈现和视频游戏应用至关重要。尽管现有的基于神经辐射场（NeRF）的方法实现了高保真度的结果，但计算费用限制了它们在实时应用中的使用。为了克服这一限制，我们引入了BakedAvatar，这是一种用于实时神经头部化身合成的新表示，可部署在标准多边形光栅化管道中。我们的方法从学习的头部等值面中提取可变形的多层网格，并计算与表情、姿势和视图相关的外观，这些外观可以烘焙到静态纹理中，以实现高效的光栅化。因此，我们提出了一种用于神经头化身合成的三阶段流水线，包括学习连续变形、流形和辐射场，提取分层网格和纹理，以及使用差分光栅化微调纹理细节。实验结果表明，我们的表示生成的合成结果质量与其他最先进的方法相当，同时显著减少了所需的推理时间。我们进一步展示了单眼视频中的各种头部化身合成结果，包括视图合成、面部再现、表情编辑和姿势编辑，所有这些都是以交互式帧率进行的。 et.al.|[2311.05521](http://arxiv.org/abs/2311.05521)|null|
|**2023-11-08**|**Learning Robust Multi-Scale Representation for Neural Radiance Fields from Unposed Images**|我们介绍了一种改进的计算机视觉中基于神经图像的绘制问题的解决方案。给定一组在火车时刻从自由移动的相机拍摄的图像，所提出的方法可以在测试时刻从一个新颖的视角合成真实的场景图像。本文提出的关键思想是：（i）在神经新视图合成问题中，通过稳健的管道从未处理的日常图像中恢复准确的相机参数同样至关重要；（ii）以不同的分辨率对对象的内容进行建模更为实用，因为在日常的未渲染图像中，相机的剧烈运动极有可能发生。为了结合这些关键思想，我们利用了场景刚性、多尺度神经场景表示和单图像深度预测的基本原理。具体地说，所提出的方法使相机参数在基于神经场的建模框架中是可学习的。通过假设每个视图的深度预测是按比例进行的，我们限制了连续帧之间的相对姿态。根据相对姿态，通过多尺度神经场网络内的基于图神经网络的多运动平均来建模绝对相机姿态估计，从而产生单个损失函数。优化引入的损失函数提供了相机内在的、外在的以及从未聚焦的图像渲染的图像。我们通过例子证明，对于从日常获取的未聚焦多视图图像中精确建模多尺度神经场景表示的统一框架，在场景表示框架内进行精确的相机姿态估计同样重要。如果不考虑相机姿态估计管道中的鲁棒性措施，对多尺度混叠伪影进行建模可能会适得其反。我们在几个基准数据集上进行了大量实验，以证明我们的方法的适用性。 et.al.|[2311.04521](http://arxiv.org/abs/2311.04521)|null|
|**2023-11-06**|**Dynamic Neural Fields for Learning Atlases of 4D Fetal MRI Time-series**|我们提出了一种使用神经场快速构建生物医学图像图谱的方法。图谱是生物医学图像分析任务的关键，但传统的深度网络估计方法仍然耗时。在这项初步工作中，我们将特定主题的图谱构建框定为学习可变形时空观测的神经场。我们将我们的方法应用于学习子宫内胎儿动态BOLD MRI时间序列的受试者特异性图谱和运动稳定性。我们的方法产生了胎儿BOLD时间序列的高质量图谱，与现有工作相比，收敛速度更快。虽然我们的方法在解剖重叠方面稍逊于调整良好的基线，但它估计模板的速度要快得多，从而能够快速处理和稳定4D动态MRI采集的大型数据库。代码可在https://github.com/Kidrauh/neural-atlasing et.al.|[2311.02874](http://arxiv.org/abs/2311.02874)|**[link](https://github.com/kidrauh/neural-atlasing)**|
|**2023-11-04**|**LISNeRF Mapping: LiDAR-based Implicit Mapping via Semantic Neural Fields for Large-Scale 3D Scenes**|大规模语义映射对于户外自主代理完成规划和导航等高级任务至关重要。本文提出了一种通过单独的激光雷达测量的隐式表示进行大规模三维语义重建的新方法。我们首先利用基于八叉树的分层结构来存储隐式特征，然后通过浅层多层感知器（MLP）将这些隐式特征解码为语义信息和有符号距离值。我们采用现成的算法来预测点云的语义标签和实例ID。然后，我们使用点云几何的自监督范式和语义和全景标签的伪监督范式来联合优化隐含特征和MLP参数。随后，利用Marching Cubes算法对推理阶段的场景进行细分和可视化。对于内存受限的场景，还开发了一种地图拼接策略，将子地图合并为一个完整的地图。据我们所知，我们的方法是第一个从仅激光雷达的输入中重建语义隐含场景的工作。在SemanticKITTI、SemanticPOSS和nuScenes三个真实世界数据集上的实验证明了与当前最先进的3D映射方法相比，我们的框架的有效性和效率。 et.al.|[2311.02313](http://arxiv.org/abs/2311.02313)|null|

<p align=right>(<a href=#updated-on-20231121>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

