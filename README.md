[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.04.28
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#video-diffusion>Video Diffusion</a></li>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## Video Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-04-25**|**NoiseController: Towards Consistent Multi-view Video Generation via Noise Decomposition and Collaboration**|高质量的视频生成对许多领域至关重要，包括电影业和自动驾驶。然而，生成具有时空一致性的视频仍然具有挑战性。当前的方法通常利用注意力机制或修改噪声来实现一致的视频，忽略了有助于确保视频生成过程中空间和时间一致性的全局时空信息。本文提出了由多级噪声分解、多帧噪声协作和联合去噪组成的噪声控制器，以提高视频生成中的时空一致性。在多级噪声分解中，我们首先将初始噪声分解为场景级前景/背景噪声，捕捉不同的运动特性来模拟多视图前景/背景变化。此外，每个场景级噪声被进一步分解为单独的共享级和残差级分量。共享噪声保持一致性，而残差分量保持多样性。在多帧噪声协作中，我们引入了视点间时空协作矩阵和视点内影响协作矩阵，该矩阵捕获了相互的跨视点效果和历史跨帧影响，以提高视频质量。联合去噪包含两个并行的去噪U-Net，用于去除每个场景级的噪声，相互增强视频生成。我们在公共数据集上评估了NoiseController，重点关注视频生成和下游任务，展示了其最先进的性能。 et.al.|[2504.18448](http://arxiv.org/abs/2504.18448)|null|
|**2025-04-23**|**Subject-driven Video Generation via Disentangled Identity and Motion**|我们建议在没有额外调整的情况下，通过在零样本中将特定于主题的学习与时间动态解耦来训练主题驱动的定制视频生成模型。一种无需调整的传统视频定制方法通常依赖于大型带注释的视频数据集，这在计算上很昂贵，需要大量的注释。与之前的方法相比，我们引入了直接在训练视频定制模型上使用图像定制数据集，将视频定制分解为两部分：（1）通过图像定制数据集中的身份注入，以及（2）通过图像到视频训练方法用一小部分未标记的视频进行时间建模保存。此外，我们在图像到视频微调期间采用随机图像令牌丢弃和随机图像初始化，以减轻复制和粘贴问题。为了进一步增强学习，我们在特定主题和时间特征的联合优化过程中引入了随机切换，减轻了灾难性遗忘。我们的方法实现了强大的主题一致性和可扩展性，在零样本设置中优于现有的视频定制模型，证明了我们框架的有效性。 et.al.|[2504.17816](http://arxiv.org/abs/2504.17816)|null|
|**2025-04-24**|**Dynamic Camera Poses and Where to Find Them**|在动态互联网视频上按比例注释相机姿势对于推进逼真视频生成和模拟等领域至关重要。然而，收集这样的数据集是困难的，因为大多数互联网视频都不适合姿势估计。此外，即使对于最先进的方法来说，注释动态互联网视频也带来了重大挑战。本文介绍了DynPose-100K，这是一个用相机姿态注释的动态互联网视频的大规模数据集。我们的收集管道使用一组精心组合的任务特定和通用模型来解决过滤问题。对于姿态估计，我们结合了点跟踪、动态掩蔽和运动结构的最新技术，以实现对最先进方法的改进。我们的分析和实验表明，DynPose-100K在几个关键属性上既大规模又多样化，为各种下游应用的进步开辟了道路。 et.al.|[2504.17788](http://arxiv.org/abs/2504.17788)|null|
|**2025-04-24**|**MV-Crafter: An Intelligent System for Music-guided Video Generation**|音乐视频作为一种流行的多媒体娱乐形式，为观众提供引人入胜的视听体验，在歌手和粉丝中广受欢迎。创作者可以通过视觉元素自然地表达他们对音乐的诠释。然而，音乐视频的创作过程需要熟练掌握脚本设计、视频拍摄和音乐视频同步，这对非专业人士来说是一个重大挑战。之前的工作设计了自动音乐视频生成框架。然而，它们的输入复杂，输出质量差。作为回应，我们推出了MV Crafter，这是一个能够制作具有同步音乐视频节奏和风格的高质量音乐视频的系统。我们的方法涉及三个模拟人类创作过程的技术模块：脚本生成模块、视频生成模块和音乐视频同步模块。MV Crafter利用大型语言模型生成考虑音乐语义的脚本。为了解决短视频片段与不同长度音乐同步的挑战，我们提出了一种动态节拍匹配算法和视觉包络诱导扭曲方法，以确保精确、单调的音乐视频同步。此外，我们设计了一个用户友好的界面，通过直观的编辑功能简化了创建过程。大量实验表明，MV Crafter为提高生成的音乐视频的质量提供了一种有效的解决方案。 et.al.|[2504.17267](http://arxiv.org/abs/2504.17267)|null|
|**2025-04-24**|**DIVE: Inverting Conditional Diffusion Models for Discriminative Tasks**|扩散模型在图像和视频生成等各种生成任务中取得了显著进展。本文研究了利用预训练扩散模型执行判别任务的问题。具体来说，我们通过将预训练的布局“反转”为图像扩散模型，将预训练冻结生成扩散模型的判别能力从分类任务扩展到更复杂的对象检测任务。为此，分别提出了一种基于梯度的离散优化方法来代替繁重的预测枚举过程，以及一种更准确地使用贝叶斯规则的先验分布模型。实验结果表明，该方法与COCO数据集上的基本判别目标检测基线相当。此外，我们的方法可以在不牺牲准确性的情况下大大加快之前基于扩散的分类方法。代码和型号可在https://github.com/LiYinqi/DIVE . et.al.|[2504.17253](http://arxiv.org/abs/2504.17253)|**[link](https://github.com/LiYinqi/DIVE)**|
|**2025-04-25**|**We'll Fix it in Post: Improving Text-to-Video Generation with Neuro-Symbolic Feedback**|当前的文本到视频（T2V）生成模型越来越受欢迎，因为它们能够从文本提示中生成连贯的视频。然而，当处理涉及多个对象或连续事件的更长、更复杂的提示时，这些模型往往难以生成语义和时间一致的视频。此外，与训练或微调相关的高计算成本使得直接改进不切实际。为了克服这些局限性，我们引入了NeuS-E，这是一种新型的零训练视频细化管道，它利用神经符号反馈来自动增强视频生成，实现了与提示的卓越对齐。我们的方法首先通过分析正式的视频表示来推导神经符号反馈，并精确定位语义不一致的事件、对象及其相应的帧。然后，此反馈将指导对原始视频进行有针对性的编辑。对开源和专有T2V模型的广泛实证评估表明，NeuS-E显著提高了不同提示之间的时间和逻辑一致性，提高了近40% et.al.|[2504.17180](http://arxiv.org/abs/2504.17180)|null|
|**2025-04-23**|**BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation**|文本到视频（T2V）生成模型已经迅速发展，并在娱乐、教育和营销等领域得到了广泛应用。然而，这些模型的对抗性弱点仍然很少被探索。我们观察到，在T2V生成任务中，生成的视频通常包含文本提示中未明确指定的大量冗余信息，如环境元素、次要对象和其他细节，为恶意攻击者嵌入隐藏的有害内容提供了机会。利用这种固有的冗余，我们引入了BadVideo，这是为T2V一代量身定制的第一个后门攻击框架。我们的攻击侧重于通过两种关键策略设计目标对抗输出：（1）时空组合，它结合了不同的时空特征来编码恶意信息；（2）动态元素转换，它随着时间的推移在冗余元素中引入转换，以传达恶意信息。基于这些策略，攻击者的恶意目标与用户的文本指令无缝集成，提供了高度的隐蔽性。此外，通过利用视频的时间维度，我们的攻击成功地避开了主要分析单个帧内空间信息的传统内容审核系统。大量实验表明，BadVideo在保持原始语义和在干净输入上保持出色性能的同时，实现了高攻击成功率。总的来说，我们的工作揭示了T2V模型的对抗性脆弱性，引起了人们对潜在风险和滥用的关注。我们的项目页面位于https://wrt2000.github.io/BadVideo2025/. et.al.|[2504.16907](http://arxiv.org/abs/2504.16907)|null|
|**2025-04-23**|**ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree and Visual Guidance**|尽管机器人操作视频合成的最新进展显示出希望，但在确保有效的指令遵循和实现高视觉质量方面仍存在重大挑战。最近的方法，如RoboDreamer，利用语言分解将指令划分为单独的低级原语，在这些原语上调节世界模型，以实现组合指令跟踪。然而，这些独立的原语没有考虑它们之间存在的关系。此外，最近的方法忽略了有价值的视觉引导，包括深度和语义引导，这两者对于提高视觉质量都至关重要。本文介绍了基于动作树和视觉引导的先进世界模型ManipDreamer。为了更好地了解指令原语之间的关系，我们将指令表示为动作树，并将嵌入分配给树节点，每条指令都可以通过在动作树中导航来获取其嵌入。指令嵌入可用于指导世界模型。为了提高视觉质量，我们通过引入与世界模型兼容的视觉引导适配器，将深度和语义引导结合起来。这种视觉适配器增强了视频生成的时间和物理一致性。基于动作树和视觉引导，ManipDreamer显著提高了指令遵循能力和视觉质量。对机器人操作基准的综合评估表明，与最近的RoboDreamer模型相比，ManipDreamer在可见和不可见任务中的视频质量指标都有了很大的提高，PSNR从19.55提高到21.05，SSIM从0.7474提高到0.7982，在不可见任务中将Flow Error从3.506降低到3.201。此外，我们的方法在6个RLbench任务中平均将机器人操纵任务的成功率提高了2.5%。 et.al.|[2504.16464](http://arxiv.org/abs/2504.16464)|null|
|**2025-04-23**|**VideoMark: A Distortion-Free Robust Watermarking Framework for Video Diffusion Models**|这项工作提出了VideoMark，这是一个用于视频扩散模型的无训练鲁棒水印框架。随着传播模型在生成高度逼真的视频方面的进步，对可靠的内容归因机制的需求变得至关重要。虽然图像扩散模型的水印技术取得了进展，但由于视频长度可变和易受时间攻击，将这些方法直接扩展到视频中会带来独特的挑战。VideoMark通过使用伪随机纠错（PRC）码在生成过程中嵌入水印信息的逐帧水印策略来解决这些限制。我们的方法生成一个扩展的水印消息序列，并为每个视频随机选择起始位置，确保潜在空间中的噪声分布均匀，并保持生成质量。对于水印提取，我们引入了一个时间匹配模块（TMM），该模块使用编辑距离将解码的消息与原始水印序列对齐，从而提供对帧删除等时间攻击的鲁棒性。实验结果表明，VideoMark在保持视频质量与无水印生成相当的同时，实现了比现有方法更高的解码精度。重要的是，我们的水印在没有密钥的情况下仍然无法被攻击者检测到，与其他水印框架相比，确保了很强的不可察觉性。VideoMark为基于扩散的视频生成中的内容归因提供了一种实用的解决方案，无需额外的训练或牺牲视频质量。我们的代码和数据可在\href获得{https://github.com/KYRIE-LI11/VideoMark}{https://github.com/KYRIE-LI11/VideoMark}. et.al.|[2504.16359](http://arxiv.org/abs/2504.16359)|null|
|**2025-04-22**|**Survey of Video Diffusion Models: Foundations, Implementations, and Applications**|扩散模型的最新进展彻底改变了视频生成，与传统的基于生成对抗网络的方法相比，它提供了更优的时间一致性和视觉质量。虽然这一新兴领域在应用方面显示出巨大的前景，但它在运动一致性、计算效率和伦理考虑方面面临着重大挑战。本调查全面回顾了基于扩散的视频生成，考察了其演变、技术基础和实际应用。我们对当前的方法进行了系统的分类，分析了架构创新和优化策略，并研究了去噪和超分辨率等低级视觉任务的应用。此外，我们还探索了基于扩散的视频生成与相关领域之间的协同作用，包括视频表示学习、问答和检索。与现有的调查（Lei等人，2024a；b；Melnik等人，2024；Cao等人，2023；Xing等人，2024c）相比，这些调查侧重于视频生成的特定方面，如人体视频合成（Lei等，2024a）或长格式内容生成（Lei et al.，2024b），我们的工作为基于扩散的方法提供了更广泛、更更新、更精细的视角，并专门讨论了视频生成中的评估指标、行业解决方案和培训工程技术。这项调查为在扩散模型和视频生成交叉领域工作的研究人员和从业者提供了基础资源，为推动这一快速发展的领域的理论框架和实际实施提供了见解。本次调查涉及的相关工作的结构化列表也可在https://github.com/Eyeline-Research/Survey-Video-Diffusion. et.al.|[2504.16081](http://arxiv.org/abs/2504.16081)|null|

<p align=right>(<a href=#updated-on-20250428>back to top</a>)</p>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-04-24**|**iVR-GS: Inverse Volume Rendering for Explorable Visualization via Editable 3D Gaussian Splatting**|在体积可视化中，用户可以通过在传递函数（TF）中指定颜色和不透明度映射或调整照明参数来交互式地探索三维数据，从而有助于对底层结构进行有意义的解释。然而，渲染大规模卷需要强大的GPU和高速内存访问来实现实时性能。虽然现有的新颖视图合成（NVS）方法以较低的硬件要求提供了更快的渲染速度，但重建场景的可见部分是固定的，并受到预设TF设置的限制，这大大限制了用户的探索。本文介绍了一种创新的NVS方法——基于高斯飞溅的逆体绘制（iVR GS），该方法在降低绘制成本的同时，还支持交互式体探索的场景编辑。具体来说，我们组合了多个与基本TF相关的iVR GS模型，覆盖不相交的可见部分，使整个体积场景可见。每个基本模型都包含一组3D可编辑高斯分布，其中每个高斯分布都是一个支持实时场景渲染和编辑的3D空间点。我们在各种体积数据集上展示了iVR GS相对于其他NVS解决方案（Plenox、CCNeRF和base 3DGS）的卓越重建质量和可组合性。该代码可在以下网址获得https://github.com/TouKaienn/iVR-GS. et.al.|[2504.17954](http://arxiv.org/abs/2504.17954)|null|
|**2025-04-23**|**Visibility-Uncertainty-guided 3D Gaussian Inpainting via Scene Conceptional Learning**|3D高斯散斑（3DGS）已经成为一种强大而高效的3D表示方法，用于新颖的视图合成。本文将3DGS功能扩展到修复，其中场景中的蒙版对象被替换为与周围环境无缝融合的新内容。与2D图像修复不同，3D高斯修复（3DGI）在有效利用来自多个输入视图的互补视觉和语义线索方面具有挑战性，因为一个视图中的遮挡区域可能在其他视图中可见。为了解决这个问题，我们提出了一种方法，该方法测量不同输入视图中3D点的可见性不确定性，并使用它们来指导3DGI利用互补的视觉线索。我们还利用不确定性来学习没有遮挡对象的场景的语义概念，并使用扩散模型基于学习到的概念填充输入图像中的遮挡对象。最后，我们通过将视觉不确定性绘画引导的3DGI与场景概念学习相结合，构建了一个新的3DGI框架VISTA。VISTA生成高质量的3DGS模型，能够合成无伪影和自然修复的新颖视图。此外，我们的方法扩展到处理由时间对象变化引起的动态干扰物，增强了其在各种场景重建场景中的通用性。我们使用两个具有挑战性的数据集展示了我们的方法优于最先进技术的性能：SPIn-NeRF数据集，具有10个不同的静态3D修复场景，以及来自UTB180的水下3D修复数据集，包括作为修复目标的快速移动的鱼。 et.al.|[2504.17815](http://arxiv.org/abs/2504.17815)|null|
|**2025-04-24**|**CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from Casually Captured Videos**|最近，神经辐射场（NeRF）和3D高斯散斑（3DGS）等多视图图像的照片级逼真新视图合成因其卓越的性能而受到广泛关注。然而，大多数作品依赖于低动态范围（LDR）图像，这限制了更丰富场景细节的捕捉。一些先前的工作侧重于高动态范围（HDR）场景重建，通常需要在曝光时间内在固定的相机位置捕获具有不同曝光时间的多视图清晰图像，这在实践中既耗时又具有挑战性。为了获得更灵活的数据采集，我们提出了一种单阶段方法：\textbf{CasualHDRSplat}，即使在存在严重运动模糊和未知曝光时间变化的情况下，也能从随机捕获的视频中轻松、稳健地重建3D HDR场景，并启用自动曝光。\textbf{CasualHDRSplat}包含一个统一的可微分物理成像模型，该模型首先对成像过程应用连续时间轨迹约束，以便我们可以共同优化曝光时间、相机响应函数（CRF）、相机姿态和清晰的3D HDR场景。大量实验表明，我们的方法在鲁棒性和渲染质量方面优于现有方法。我们的源代码将在https://github.com/WU-CVGL/CasualHDRSplat et.al.|[2504.17728](http://arxiv.org/abs/2504.17728)|null|
|**2025-04-24**|**Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation**|我们提出了一种通过心理意象模拟在视觉语言模型（VLMs）中进行透视感知推理的框架。视角获取，即从另一个角度感知环境或情况的能力，是人类视觉理解的关键基准，对于与自主代理的环境交互和协作至关重要。尽管VLM在空间推理方面取得了进步，但最近的研究表明，现代VLM严重缺乏透视感知推理能力，并表现出强烈的自我中心解释倾向。为了弥合VLM和人类感知之间的差距，我们关注心理意象的作用，即人类通过抽象的表征来感知世界，从而促进视角的转变。受此启发，我们提出了一个名为抽象透视变化（APC）的透视感知推理框架，该框架有效地利用视觉基础模型，如对象检测、分割和方向估计，来构建场景抽象并实现透视变换。与各种VLM相比，我们在合成和真实图像基准上的实验表明，我们的框架在透视感知推理方面有了显著改进，进一步优于微调的空间推理模型和新的基于视图合成的方法。 et.al.|[2504.17207](http://arxiv.org/abs/2504.17207)|null|
|**2025-04-22**|**Satellite to GroundScape -- Large-scale Consistent Ground View Generation from Satellite Views**|从卫星图像生成一致的地面视图图像具有挑战性，主要是由于卫星和地面域之间的视角和分辨率存在很大差异。之前的工作主要集中在单视图生成上，这通常会导致相邻地面视图之间的不一致。在这项工作中，我们提出了一种新的交叉视图合成方法，旨在通过确保从卫星视图生成的地面视图图像的一致性来克服这些挑战。我们的方法基于固定的潜在扩散模型，引入了两个条件模块：卫星引导去噪，提取高级场景布局来指导去噪过程，以及卫星时间去噪，捕获相机运动以保持多个生成视图的一致性。我们还提供了一个包含100000多个透视对的大规模卫星地面数据集，以促进广泛的地面场景或视频生成。实验结果表明，我们的方法在感知和时间度量方面优于现有方法，在多视图输出中实现了高真实感和一致性。 et.al.|[2504.15786](http://arxiv.org/abs/2504.15786)|null|
|**2025-04-22**|**Pose Optimization for Autonomous Driving Datasets using Neural Rendering Models**|自动驾驶系统依赖于对自我汽车的准确感知和定位，以确保在具有挑战性的现实驾驶场景中的安全性和可靠性。公共数据集通过为模型开发和评估提供标准化资源，在基准测试和指导研究进展方面发挥着至关重要的作用。然而，这些数据集中传感器校准和车辆姿态的潜在不准确可能会导致对下游任务的错误评估，从而对自主系统的可靠性和性能产生不利影响。为了应对这一挑战，我们提出了一种基于神经辐射场（NeRF）的鲁棒优化方法，以细化传感器姿态和校准参数，增强数据集基准的完整性。为了验证在没有地面真实性的情况下优化姿态的准确性的提高，我们提出了一个全面的评估过程，该过程依赖于重投影指标、新视图合成渲染质量和几何对齐。我们证明，我们的方法在传感器姿态精度方面取得了显著提高。通过优化这些关键参数，我们的方法不仅提高了现有数据集的效用，还为更可靠的自动驾驶模型铺平了道路。为了促进该领域的持续进步，我们公开了优化的传感器姿态，为研究界提供了宝贵的资源。 et.al.|[2504.15776](http://arxiv.org/abs/2504.15776)|null|
|**2025-04-21**|**MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry Monocular Video**|我们提出了MoBGS，这是一种新颖的去模糊动态3D高斯散斑（3DGS）框架，能够以端到端的方式从模糊的单眼视频中重建清晰、高质量的新颖时空视图。现有的动态新颖视图合成（NVS）方法对随意捕获的视频中的运动模糊高度敏感，导致渲染质量显著下降。虽然最近的方法解决了NVS的运动模糊输入问题，但它们主要侧重于静态场景重建，缺乏针对动态对象的专用运动建模。为了克服这些局限性，我们的MoBGS引入了一种新的模糊自适应潜在相机估计（BLCE）方法，用于有效的潜在相机轨迹估计，改善了全局相机运动去模糊。此外，我们提出了一种受物理启发的潜在相机诱导曝光估计（LCEE）方法，以确保全局相机和局部对象运动的一致去模糊。我们的MoBGS框架确保了看不见的潜在时间戳的时间一致性，以及静态和动态区域的鲁棒运动分解。对立体模糊数据集和真实世界模糊视频的广泛实验表明，我们的MoBGS明显优于最新的先进方法（DyBluRF和Deblur4DGS），在运动模糊下实现了最先进的动态NVS性能。 et.al.|[2504.15122](http://arxiv.org/abs/2504.15122)|null|
|**2025-04-20**|**IXGS-Intraoperative 3D Reconstruction from Sparse, Arbitrarily Posed Real X-rays**|脊柱手术是一种高风险的干预措施，需要精确的执行，通常由基于图像的导航系统支持。最近，监督学习方法在从稀疏荧光透视数据重建3D脊柱解剖结构方面受到了关注，大大降低了对辐射密集型3D成像系统的依赖。然而，这些方法通常需要大量带注释的训练数据，并且可能难以在不同的患者解剖结构或成像条件下进行推广。高斯飞溅等实例学习方法可以避免大量的注释要求，从而提供一种替代方案。虽然高斯溅射显示出新的视图合成的前景，但它在稀疏、任意姿势的真实术中X射线中的应用在很大程度上仍未得到探索。这项工作通过扩展 $R^2$ -Gassian飞溅框架来解决这一局限性，以在这些具有挑战性的条件下重建解剖学上一致的3D体积。我们引入了一种使用样式转换的解剖引导放射学标准化步骤，提高了视图之间的视觉一致性，并提高了重建质量。值得注意的是，我们的框架不需要预训练，使其天生就能适应新的患者和解剖结构。我们使用离体数据集评估了我们的方法。专家手术评估证实了3D重建在导航方面的临床实用性，特别是在使用20到30个视图时，并强调了标准化对解剖清晰度的好处。通过定量2D指标（PSNR/SSIM）进行的基准测试证实了与理想设置相比的性能权衡，但也验证了标准化对原始输入的改进。这项工作证明了从任意稀疏视图X射线进行基于实例的体积重建的可行性，推进了手术导航的术中3D成像。 et.al.|[2504.14699](http://arxiv.org/abs/2504.14699)|null|
|**2025-04-20**|**VGNC: Reducing the Overfitting of Sparse-view 3DGS via Validation-guided Gaussian Number Control**|稀疏视图3D重建是实际3D重建应用中一项基本但具有挑战性的任务。最近，已经提出了许多基于3D高斯散斑（3DGS）框架的方法来解决稀疏视图3D重建问题。尽管这些方法取得了相当大的进步，但它们仍然存在过拟合的重大问题。为了减少过拟合，我们引入了VGNC，这是一种基于生成新视图合成（NVS）模型的新型验证引导高斯数控制（VGNC）方法。据我们所知，这是首次尝试通过生成验证图像来缓解稀疏视图3DGS的过拟合问题。具体来说，我们首先介绍了一种基于生成NVS模型的验证图像生成方法。然后，我们提出了一种高斯数控制策略，该策略利用生成的验证图像来确定最优高斯数，从而减少过拟合问题。我们在各种稀疏视图3DGS基线和数据集上进行了详细的实验，以评估VGNC的有效性。大量实验表明，我们的方法不仅减少了过拟合，而且在减少高斯点数量的同时提高了测试集的渲染质量。这种减少降低了存储需求，加速了训练和渲染。代码将被发布。 et.al.|[2504.14548](http://arxiv.org/abs/2504.14548)|null|
|**2025-04-20**|**Metamon-GS: Enhancing Representability with Variance-Guided Densification and Light Encoding**|3D高斯散点（3DGS）的引入通过利用高斯来表示场景，推进了新的视图合成。使用锚嵌入对高斯点特征进行编码显著提高了较新3DGS变体的性能。虽然已经取得了重大进展，但提高渲染性能仍然具有挑战性。特征嵌入很难在不同的光照条件下从不同的角度准确地表示颜色，这会导致外观褪色。另一个原因是缺乏适当的致密化策略来防止高斯点在初始化稀疏的区域生长，从而导致模糊和针状伪影。为了解决这些问题，我们从方差引导的致密化策略和多级哈希网格的创新角度提出了Metamon GS。方差引导的密集化策略专门针对像素中具有高梯度方差的高斯分布，并补偿了具有额外高斯分布的区域对改善重建的重要性。后者研究隐含的全局光照条件，并从不同的角度和特征嵌入准确地解释颜色。我们在公开数据集上的彻底实验表明，Metamon GS超越了其基线模型和以前的版本，在渲染新颖视图方面提供了卓越的质量。 et.al.|[2504.14460](http://arxiv.org/abs/2504.14460)|null|

<p align=right>(<a href=#updated-on-20250428>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-04-25**|**PerfCam: Digital Twinning for Production Lines Using 3D Gaussian Splatting and Vision Models**|我们介绍了PerfCam，这是一个开源的概念验证（PoC）数字孪生框架，它将相机和感官数据与3D高斯散斑和计算机视觉模型相结合，用于工业生产线中的数字孪生、对象跟踪和关键性能指标（KPI）提取。通过利用3D重建和卷积神经网络（CNN），PerfCam提供了一种半自动的对象跟踪和空间映射方法，使数字孪生能够捕获实时KPI，如可用性、性能、整体设备效率（OEE）和生产线中传送带的速度。我们通过在制药行业现实测试生产线上的实际部署验证了PerfCam的有效性，并提供了一个公开发布的数据集，以支持该领域的进一步研究和开发。结果表明，PerfCam能够通过其精确的数字孪生功能提供可操作的见解，突显了其作为在智能制造环境中开发可用数字孪生和提取运营分析的有效工具的价值。 et.al.|[2504.18165](http://arxiv.org/abs/2504.18165)|null|
|**2025-04-22**|**Object Learning and Robust 3D Reconstruction**|在这篇论文中，我们讨论了神经网络的架构设计和训练方法，使其能够在没有监督的情况下将图像分解为感兴趣的对象。2D无监督对象分割的主要挑战是区分感兴趣的前景对象和背景。FlowCapsules使用运动作为2D场景中感兴趣对象的线索。本文的最后一部分侧重于3D应用，其目标是从输入图像中检测和删除感兴趣的对象。在这些任务中，我们利用3D场景的几何一致性来检测不一致的动态对象。然后，我们的瞬态对象掩模用于设计鲁棒的优化内核，以在随意的捕捉设置中改进3D建模。本文的目标之一是展示无监督基于对象的方法在计算机视觉中的优点。此外，我们提出了在不需要监督的情况下定义感兴趣对象或前景对象的可能方向。我们希望激励和激发社区进一步探索图像理解任务中的显式对象表示。 et.al.|[2504.17812](http://arxiv.org/abs/2504.17812)|null|
|**2025-04-24**|**Range Image-Based Implicit Neural Compression for LiDAR Point Clouds**|本文提出了一种高效压缩光探测和测距（LiDAR）点云的新方案，实现了高精度的3D场景档案，这些档案为详细了解相应的3D场景铺平了道路。我们专注于2D距离图像~（RI）作为一种轻量级的格式，用于表示3D LiDAR观测结果。尽管传统的图像压缩技术可以提高RI的压缩效率，但由于比特精度的差异以及自然图像和RI之间不同的像素值分布特征，它们的实际性能预计会受到限制。我们提出了一种新的基于隐式神经表示的RI压缩方法，可以有效地处理浮点值像素。所提出的方法将RI分为深度和掩模图像，并分别使用具有模型修剪和量化的逐块和逐像素INR架构对其进行压缩。在KITTI数据集上的实验表明，在低比特率和解码延迟下，所提出的方法在3D重建和检测质量方面优于现有的基于图像、点云、RI和INR的压缩方法。 et.al.|[2504.17229](http://arxiv.org/abs/2504.17229)|null|
|**2025-04-23**|**Gaussian Splatting is an Effective Data Generator for 3D Object Detection**|我们研究了自动驾驶中3D物体检测的数据增强。我们利用基于高斯散斑的3D重建的最新进展，在驾驶场景中放置3D对象。与现有的基于扩散的合成基于边界元法布局的图像的方法不同，我们的方法通过明确施加的几何变换将3D对象直接放置在重建的3D空间中。这确保了对象放置的物理合理性和高度精确的3D姿态和位置注释。我们的实验表明，即使通过将有限数量的外部3D对象集成到真实场景中，增强数据也能显著提高3D对象检测性能，并且在对象检测方面优于现有的基于扩散的3D增强。对nuScenes数据集的广泛测试表明，与对象的外观多样性相比，在对象放置中施加高度的几何多样性会产生更大的影响。此外，我们表明，通过最大化检测损失或在相机图像中施加高视觉遮挡来生成硬示例，并不能为自动驾驶中基于相机的3D对象检测带来更有效的3D数据增强。 et.al.|[2504.16740](http://arxiv.org/abs/2504.16740)|null|
|**2025-04-23**|**Beyond Anonymization: Object Scrubbing for Privacy-Preserving 2D and 3D Vision Tasks**|我们引入了ROAR（鲁棒对象删除和重新注释），这是一个可扩展的隐私保护数据集混淆框架，可以消除敏感对象而不是修改它们。我们的方法将实例分割与生成修复相结合，在保留场景完整性的同时去除可识别的实体。对基于2D COCO的目标检测的广泛评估表明，ROAR达到了基线检测平均精度（AP）的87.5%，而图像丢弃仅达到了基线AP的74.2%，突显了擦洗在保持数据集效用方面的优势。由于遮挡和细粒度细节的丢失，小对象的退化甚至更严重。此外，在基于NeRF的3D重建中，我们的方法在保持SSIM和改善LPIPS的同时，PSNR损失最多为1.66 dB，表现出卓越的感知质量。我们的研究结果将对象移除确立为一种有效的隐私框架，以最小的性能权衡实现了强有力的隐私保证。研究结果突出了生成修复、遮挡鲁棒分割和特定任务清理方面的关键挑战，为隐私保护视觉系统的未来发展奠定了基础。 et.al.|[2504.16557](http://arxiv.org/abs/2504.16557)|null|
|**2025-04-23**|**PRaDA: Projective Radial Distortion Averaging**|我们解决了在具有挑战性的条件下自动校准径向失真相机的问题。准确确定失真参数通常需要1）解决涉及相机姿态、3D点和失真参数的完整运动结构（SfM）问题，这只有在提供了许多具有足够重叠的图像的情况下才有可能，或者2）严重依赖相对不太准确的基于学习的方法。在这项工作中，我们证明了失真校准可以与3D重建解耦，在保持基于SfM的方法的准确性的同时避免了许多相关的复杂性。这是通过在投影空间中工作来实现的，其中几何体在单应性之前是唯一的，单应性封装了除失真之外的所有相机参数。我们提出的方法，投影径向失真平均法，在完全投影的框架内对多个失真估计进行平均，而无需创建3d点和全束调整。通过依赖成对投影关系，我们的方法支持任何特征匹配方法，而无需在多幅图像上构建点轨迹。 et.al.|[2504.16499](http://arxiv.org/abs/2504.16499)|null|
|**2025-04-22**|**Intent-aware Diffusion with Contrastive Learning for Sequential Recommendation**|对比学习已被证明在训练顺序推荐模型方面是有效的，它结合了来自增强视图的自我监督信号。大多数现有方法通过随机数据增强从同一交互序列中生成多个视图，旨在对齐它们在嵌入空间中的表示。然而，用户在购买物品时通常有特定的意图（例如，购买衣服作为礼物或美容化妆品）。现有方法中使用的随机数据增强可能会引入噪声，破坏原始交互序列中隐含的潜在意图信息。此外，在对比学习中使用噪声增强序列可能会误导模型关注不相关的特征，扭曲嵌入空间，无法捕捉用户的真实行为模式和意图。为了解决这些问题，我们提出了用于顺序推荐的具有对比学习的意图感知扩散（InDiRec）。核心思想是生成与用户购买意图一致的项目序列，从而为对比学习提供更可靠的增强视图。具体来说，InDiRec首先使用K-means对序列表示进行意图聚类，以构建意图引导信号。接下来，它检索目标交互序列的意图表示，以指导条件扩散模型，生成共享相同潜在意图的积极视图。最后，对比学习被应用于最大限度地提高这些意图对齐视图与原始序列之间的表示一致性。在五个公共数据集上进行的广泛实验表明，与现有基线相比，InDiRec具有更优的性能，即使在嘈杂和稀疏的数据条件下也能学习到更稳健的表示。 et.al.|[2504.16077](http://arxiv.org/abs/2504.16077)|null|
|**2025-04-21**|**Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields**|弱引力透镜是星系形状的轻微扭曲，主要是由宇宙中暗物质的引力效应引起的。在我们的工作中，我们试图从2D望远镜图像中反转弱透镜信号，以重建宇宙暗物质场的3D图。虽然反演通常会产生暗物质场的二维投影，但暗物质分布的精确三维图对于定位感兴趣的结构和测试我们宇宙的理论至关重要。然而，3D反演带来了重大挑战。首先，与依赖于多个视点的标准3D重建不同，在这种情况下，图像仅从单个视点观察。通过观察整个体积中的星系发射器是如何被透镜化的，可以部分解决这一挑战。然而，这导致了第二个挑战：无透镜星系的形状和确切位置是未知的，只能在非常大的不确定性下进行估计。这引入了大量的噪声，几乎完全淹没了透镜信号。以前的方法通过对卷中的结构施加强有力的假设来解决这个问题。相反，我们提出了一种使用引力约束神经场来灵活模拟连续物质分布的方法。我们采用综合分析方法，通过完全可微的物理正向模型优化神经网络的权重，以再现图像测量中存在的透镜信号。我们展示了我们的模拟方法，包括模拟即将到来的望远镜调查数据的暗物质分布的真实模拟测量。我们的结果表明，我们的方法不仅可以超越以前的方法，而且重要的是还能够恢复潜在的令人惊讶的暗物质结构。 et.al.|[2504.15262](http://arxiv.org/abs/2504.15262)|null|
|**2025-04-20**|**IXGS-Intraoperative 3D Reconstruction from Sparse, Arbitrarily Posed Real X-rays**|脊柱手术是一种高风险的干预措施，需要精确的执行，通常由基于图像的导航系统支持。最近，监督学习方法在从稀疏荧光透视数据重建3D脊柱解剖结构方面受到了关注，大大降低了对辐射密集型3D成像系统的依赖。然而，这些方法通常需要大量带注释的训练数据，并且可能难以在不同的患者解剖结构或成像条件下进行推广。高斯飞溅等实例学习方法可以避免大量的注释要求，从而提供一种替代方案。虽然高斯溅射显示出新的视图合成的前景，但它在稀疏、任意姿势的真实术中X射线中的应用在很大程度上仍未得到探索。这项工作通过扩展 $R^2$ -Gassian飞溅框架来解决这一局限性，以在这些具有挑战性的条件下重建解剖学上一致的3D体积。我们引入了一种使用样式转换的解剖引导放射学标准化步骤，提高了视图之间的视觉一致性，并提高了重建质量。值得注意的是，我们的框架不需要预训练，使其天生就能适应新的患者和解剖结构。我们使用离体数据集评估了我们的方法。专家手术评估证实了3D重建在导航方面的临床实用性，特别是在使用20到30个视图时，并强调了标准化对解剖清晰度的好处。通过定量2D指标（PSNR/SSIM）进行的基准测试证实了与理想设置相比的性能权衡，但也验证了标准化对原始输入的改进。这项工作证明了从任意稀疏视图X射线进行基于实例的体积重建的可行性，推进了手术导航的术中3D成像。 et.al.|[2504.14699](http://arxiv.org/abs/2504.14699)|null|
|**2025-04-20**|**VGNC: Reducing the Overfitting of Sparse-view 3DGS via Validation-guided Gaussian Number Control**|稀疏视图3D重建是实际3D重建应用中一项基本但具有挑战性的任务。最近，已经提出了许多基于3D高斯散斑（3DGS）框架的方法来解决稀疏视图3D重建问题。尽管这些方法取得了相当大的进步，但它们仍然存在过拟合的重大问题。为了减少过拟合，我们引入了VGNC，这是一种基于生成新视图合成（NVS）模型的新型验证引导高斯数控制（VGNC）方法。据我们所知，这是首次尝试通过生成验证图像来缓解稀疏视图3DGS的过拟合问题。具体来说，我们首先介绍了一种基于生成NVS模型的验证图像生成方法。然后，我们提出了一种高斯数控制策略，该策略利用生成的验证图像来确定最优高斯数，从而减少过拟合问题。我们在各种稀疏视图3DGS基线和数据集上进行了详细的实验，以评估VGNC的有效性。大量实验表明，我们的方法不仅减少了过拟合，而且在减少高斯点数量的同时提高了测试集的渲染质量。这种减少降低了存储需求，加速了训练和渲染。代码将被发布。 et.al.|[2504.14548](http://arxiv.org/abs/2504.14548)|null|

<p align=right>(<a href=#updated-on-20250428>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-04-25**|**Robust semi-implicit multilevel SDC methods for conservation laws**|半隐式多级谱延迟校正（SI-MLSDC）方法为包括守恒定律在内的非线性演化方程的高阶时间积分提供了一种有前景的方法。然而，现有的方法缺乏鲁棒性，并且往往无法达到单级SDC的预期优势。这项工作采用了[44]中的新型SI时间积分器来提高稳定性，并用多级方法扩展了单级SI-SDC方法以提高计算效率。对流扩散问题的线性时间稳定性分析显示了SI-MLSDC方法的有利性质。通过对流扩散、Burgers、Euler和Navier-Stokes方程的数值实验，证明了涉及高阶不连续Galerkin SEM离散化的全离散方法的鲁棒性和效率。与单级SI-SDC相比，该方法在广泛的测试用例中大大减少了精细网格迭代。最后，确定并讨论了SI-MLSDC框架的当前局限性，为未来的改进提供了指导。 et.al.|[2504.18526](http://arxiv.org/abs/2504.18526)|null|
|**2025-04-25**|**RSFR: A Coarse-to-Fine Reconstruction Framework for Diffusion Tensor Cardiac MRI with Semantic-Aware Refinement**|心脏弥散张量成像（DTI）为心肌细胞排列提供了独特的见解，弥合了微观和宏观心脏功能之间的差距。然而，其临床应用受到技术挑战的限制，包括低信噪比、混叠伪影和对精确定量保真度的需求。为了解决这些局限性，我们引入了RSFR（重建、分割、融合和细化），这是一种用于心脏扩散加权图像重建的新框架。RSFR采用粗到细的策略，通过Segment Anything Model和基于Vision Mamba的强大重建骨干，利用零样本语义先验。我们的框架有效地整合了语义特征，以减少伪影并提高保真度，在高欠采样率下实现了最先进的重建质量和准确的DT参数估计。广泛的实验和消融研究表明，与现有方法相比，RSFR具有更优越的性能，突出了其鲁棒性、可扩展性以及在定量心脏DTI中临床转化的潜力。 et.al.|[2504.18520](http://arxiv.org/abs/2504.18520)|null|
|**2025-04-25**|**Complex morphology and precession indicators of AGN jets in LoTSS DR2**|低频ARray两米巡天第二次数据发布（LoTSS DR2）覆盖了北方27%的天空，包含约400万个射电源。该目录的开发涉及一个大型的公民科学项目（无线电银河动物园：LOFAR），其中116000多个解析源正在进行目视检查。我们选取了通量密度超过75 mJy、角尺寸为90美元或更大的源的子集，总共得到9985美元的源，即目视检查的源的10%。我们根据宽源类型（例如，Fanaroff-Riley I级或II级，窄尾或广角尾，松弛双尾）、明显特征（机翼、可见射流、带状物、细丝等）、环境特征（集群环境、合并、扩散发射）进行了目视检查分类。我们的具体目标是寻找与射流进动相关的特征，如未对准的射流轴、曲率和多个热点。这种特征和形态的结合使我们能够检测到越来越细粒度的有趣或不寻常来源的亚群体。我们发现，28%的源显示出一个或多个进动指标的证据，这可能使它们成为近距离双星超大质量黑洞的候选者。潜在的进动特征出现在我们样本中各种大小和亮度的源中，但似乎有利于更大质量的宿主星系。我们的工作极大地扩展了在强大的喷射源中搜索进动特征的样本量和参数空间。这项工作还展示了LOFAR调查中大型明亮射电源的多样性，无论是否存在进动指标。 et.al.|[2504.18518](http://arxiv.org/abs/2504.18518)|null|
|**2025-04-25**|**Action-Minimization Meets Generative Modeling: Efficient Transition Path Sampling with the Onsager-Machlup Functional**|过渡路径采样（TPS）涉及寻找连接能源景观上两点的可能路径，由于现实世界原子系统的复杂性，这仍然是一个挑战。当前的机器学习方法使用昂贵的、特定于任务的、无数据的训练程序，限制了它们从原子机器学习的最新进展中受益的能力，例如高质量的数据集和大规模的预训练模型。在这项工作中，我们通过将候选路径解释为从预训练生成模型的学习分数函数诱导的随机动力学中采样的轨迹来解决TPS问题，特别是去噪扩散和流匹配。在这些动态下，找到高似然转换路径相当于最小化Onsager-Machlup（OM）动作函数。这使我们能够以零样本的方式重新调整TPS的预训练生成模型的用途，与之前工作中训练的定制、任务特定的TPS模型形成对比。我们在不同的分子系统上展示了我们的方法，获得了不同的、物理上真实的过渡路径，并在预训练模型的原始训练数据集之外进行了推广。我们的方法可以很容易地整合到新的生成模型中，使其在模型随着数据可用性的增加而不断扩展和改进时具有实际意义。 et.al.|[2504.18506](http://arxiv.org/abs/2504.18506)|null|
|**2025-04-25**|**On a Cross-Diffusion System with Independent Drifts and no Self-Diffusion: The Existence of Totally Mixed Solutions**|我们建立了一个两物种交叉扩散系统的弱解的全局存在性，该系统设置在一维平面环面上，其中每个物种的进化都受两种机制的控制。第一种是扩散，它只对具有对数压力定律的物种之和起作用，第二种是漂移项，在两种物种之间可能有所不同。我们的主要结果在初始数据的完全混合假设下成立。这种假设允许存在真空，需要两种物质的初始密度比具有特定的规律性。此外，这些规律性属性被证明会随着时间的推移而传播。在证明主要存在性结果的同时，我们还建立了解的空间BV正则性。此外，我们的主要结果自然延伸到涉及反应项的类似系统。 et.al.|[2504.18484](http://arxiv.org/abs/2504.18484)|null|
|**2025-04-25**|**Interface phonon modes governing the ideal limit of thermal transport across diamond/cubic boron nitride interfaces**|了解半导体异质界面间界面热导率（ITC）的理想极限对于优化实际应用中的散热至关重要。通过采用本文训练的高精度和高效的机器学习势，我们进行了广泛的非平衡分子动力学模拟，以研究金刚石/立方氮化硼（ $c$BN）界面的ITC。理想的金刚石/$c$BN界面显示出前所未有的11.0$\pm$0.1 GW$^{-2}$K$^{-1}$ 的ITC，为异质结构界面设定了新的上限。这种特殊的电导源于声匹配引起的扩展声子模式和通过B-C键传播的局域C原子模式。然而，理想界面上的原子扩散会产生混合层，破坏这些特征声子模式，从而将热传输从其理想极限大幅抑制。我们的研究结果揭示了界面声子模式如何控制金刚石/立方氮化硼界面上的热输运，为半导体器件的热管理提供了见解。 et.al.|[2504.18473](http://arxiv.org/abs/2504.18473)|null|
|**2025-04-25**|**MROP: Modulated Rank-One Projections for compressive radio interferometric imaging**|新一代的无线电干涉（RI）阵列将以新的灵敏度和分辨率形成天空图像。这意味着可见性数据量显著增加，按 $\mathcal{O}（Q^{2}B)$Q$天线和$B$短时积分间隔（或批量），需要高效的数据降维技术。本文提出了一种新的采集数据压缩方法，即调制秩一投影（MROP）。MROP将$Q\times Q$分批协方差矩阵压缩为较小数量的$P$随机秩一预测，并通过用$B$换取较小数量的$M$ ROP测量向量的随机调制来跨时间压缩。首先，我们介绍了MROP捕获的双重视角，可以理解为随机波束形成，也可以理解为后相关压缩。其次，我们分析了MROP的噪声统计数据，并证明随机投影在测量中产生了均匀的噪声水平，与所使用的能见度加权方案无关。第三，我们建议对数据采集和图像重建阶段的内存和计算成本要求进行详细分析，并与最先进的降维方法进行比较。最后，在单色强度成像的仿真中验证了MROP模型，并与经典和基线相关平均（BDA）模型进行了比较，并使用uSARA优化算法进行图像形成。考虑了一个广泛的实验设置，地面实况图像包含漫射和微弱的发射，跨越了各种动态范围，覆盖范围与VLA和MeerKAT观测相对应。 et.al.|[2504.18446](http://arxiv.org/abs/2504.18446)|null|
|**2025-04-25**|**HepatoGEN: Generating Hepatobiliary Phase MRI with Perceptual and Adversarial Models**|动态增强磁共振成像（DCE-MRI）在肝脏局灶性病变的检测和表征中起着至关重要的作用，肝胆相（HBP）提供了必要的诊断信息。然而，获取HBP图像需要延长扫描时间，这可能会影响患者的舒适度和扫描仪的吞吐量。在这项研究中，我们提出了一种基于深度学习的方法，用于从早期对比阶段（预收缩和过渡）合成HBP图像，并比较了三种生成模型：感知U-Net、感知GAN（pGAN）和去噪扩散概率模型（DDPM）。我们策划了一个来自不同临床环境的多站点DCE-MRI数据集，并引入了对比进化评分（CES）来评估训练数据质量，从而提高了模型性能。使用像素和感知度量的定量评估，结合通过盲法放射科医生审查的定性评估，表明pGAN取得了最佳的定量性能，但在分布不均的病例中引入了异质对比。相比之下，U-Net产生了一致的肝脏增强效果，伪影较少，而DDPM由于精细结构细节的保存有限而表现不佳。这些发现证明了合成HBP图像生成作为减少扫描时间而不损害诊断效用的一种手段的可行性，突显了深度学习在肝脏MRI动态对比增强中的临床潜力。项目演示可在以下网址获得：https://jhooge.github.io/hepatogen et.al.|[2504.18405](http://arxiv.org/abs/2504.18405)|null|
|**2025-04-25**|**A Multimodal Deep Learning Approach for White Matter Shape Prediction in Diffusion MRI Tractography**|形状测量已成为白质纤维束成像的有前景的描述符，为解剖变异性以及与认知和临床表型的关联提供了补充见解。然而，由于依赖于基于体素的表示，计算形状度量的传统方法对于大规模数据集来说计算成本高昂且耗时。我们提出了Tract2Shape，这是一种新颖的多模态深度学习框架，利用几何（点云）和标量（表格）特征来预测十个白质纤维束图形状测量值。为了提高模型效率，我们利用模型的降维算法来预测五个主要形状分量。该模型在两个独立获取的数据集HCP-YA数据集和PPMI数据集上进行训练和评估。我们通过在HCP-YA数据集上进行训练和测试，并将结果与最先进的模型进行比较，来评估Tract2Shape的性能。为了进一步评估其鲁棒性和泛化能力，我们还在看不见的PPMI数据集上测试了Tract2Shape。Tract2Shape在所有十个形状度量上都优于SOTA深度学习模型，在HCP-YA数据集上实现了最高的平均Pearson r和最低的nMSE。消融研究表明，多模态输入和PCA都有助于提高性能。在看不见的测试PPMI数据集上，Tract2Shape保持了较高的Pearson r和较低的nMSE，在跨数据集评估中表现出很强的泛化能力。Tract2Shape能够从纤维束成像数据中快速、准确和通用地预测白质形状测量值，支持跨数据集的可扩展分析。该框架为未来大规模白质形状分析奠定了有前景的基础。 et.al.|[2504.18400](http://arxiv.org/abs/2504.18400)|null|
|**2025-04-25**|**Statistical Disaggregation -- a Monte Carlo Approach for Imputation under Constraints**|等式约束模型自然出现在以不同分辨率进行测量的问题中。这种情况下的挑战是，模型通常会导致难以处理的联合分布。通过蒙特卡洛方法从联合分布中取样也具有挑战性。例如，当约束的概率质量为零时，天真拒绝采样不起作用。这种受限问题的一个典型例子是基于较低分辨率的数据学习更高分辨率水平的能耗，例如，将每日读数分解为更精细水平的读数。我们介绍了一种基于朗之万扩散和拒绝采样的新型蒙特卡洛采样算法，以解决等式约束模型的采样问题。我们的方法具有对线性约束精确的优点，并且自然地处理任意约束上的多峰分布。我们在电力消耗数据集的统计分解问题上测试了我们的方法，与其他朴素/无约束方法相比，我们的方法在数据插补方面提供了更好的不确定性估计和准确性。 et.al.|[2504.18377](http://arxiv.org/abs/2504.18377)|null|

<p align=right>(<a href=#updated-on-20250428>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-04-25**|**Physics-Driven Neural Compensation For Electrical Impedance Tomography**|电阻抗断层成像（EIT）提供了一种非侵入性的便携式成像方式，在医疗和工业应用中具有巨大的潜力。尽管EIT具有优势，但它遇到了两个主要挑战：其逆问题的不适定性质和空间可变、位置相关的灵敏度分布。传统的基于模型的方法通过正则化来减轻病态性，但忽略了灵敏度的可变性，而监督深度学习方法需要大量的训练数据，缺乏泛化能力。神经领域的最新发展引入了用于图像重建的隐式正则化技术，但这些方法通常忽略了EIT背后的物理原理，从而限制了它们的有效性。在这项研究中，我们提出了PhyNC（物理驱动神经补偿），这是一个无监督的深度学习框架，结合了EIT的物理原理。PhyNC通过动态地将神经表征能力分配给灵敏度较低的区域，确保准确和平衡的电导率重建，解决了不适定逆问题和灵敏度分布问题。对模拟和实验数据的广泛评估表明，PhyNC在细节保存和抗伪影方面优于现有方法，特别是在低灵敏度区域。我们的方法增强了EIT重建的鲁棒性，并提供了一个灵活的框架，可以适应具有类似挑战的其他成像方式。 et.al.|[2504.18067](http://arxiv.org/abs/2504.18067)|null|
|**2025-04-23**|**Spot solutions to a neural field equation on oblate spheroids**|理解神经场中激发模式的动力学是神经科学的一个重要课题。神经场方程是描述相互作用神经元的激发动力学以进行理论分析的数学模型。尽管许多神经场方程的分析都集中在神经元相互作用对平面的影响上，但在对大脑等器官进行建模时，动力学的几何约束也是一个有吸引力的话题。本文报道了在球体作为模型曲面上定义的神经场方程中的模式动力学。我们将点解视为局部模式，并讨论曲面的几何特性如何改变它们的特性。为了分析具有小展平的球体上的斑点模式，我们首先在球面上构造精确的静止斑点解，并揭示它们的稳定性。然后，我们扩展了分析，以证明球状情况下驻点解的存在性和稳定性。我们的一个理论结果是推导了扁球体极点处定域的驻点解的稳定性判据。该标准决定了点解是保持在极点还是移动。最后，我们进行了数值模拟，根据我们的理论预测讨论了点解的动力学。我们的结果表明，点解的动力学取决于曲面和神经相互作用的协调。 et.al.|[2504.16342](http://arxiv.org/abs/2504.16342)|null|
|**2025-04-22**|**Low-Rank Adaptation of Neural Fields**|处理视觉数据通常涉及微小的调整或变化序列，例如图像滤波、表面平滑和视频存储。虽然现有的图形技术，如法线映射和视频压缩，利用冗余来有效地对这种小变化进行编码，但对神经场（NF）的小变化（视觉或物理功能的神经网络参数化）进行编码的问题却很少受到关注。我们提出了一种使用低秩自适应（LoRA）更新神经场的参数高效策略。LoRA是一种来自参数高效微调LLM社区的方法，它以最小的计算开销对预训练模型进行小更新编码。我们使LoRA适应特定于实例的神经场，避免了对大型预训练模型的需求，从而产生了适用于低计算硬件的流水线。我们通过图像滤波、视频压缩和几何编辑的实验验证了我们的方法，证明了它在表示神经场更新方面的有效性和通用性。 et.al.|[2504.15933](http://arxiv.org/abs/2504.15933)|null|
|**2025-04-21**|**Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields**|弱引力透镜是星系形状的轻微扭曲，主要是由宇宙中暗物质的引力效应引起的。在我们的工作中，我们试图从2D望远镜图像中反转弱透镜信号，以重建宇宙暗物质场的3D图。虽然反演通常会产生暗物质场的二维投影，但暗物质分布的精确三维图对于定位感兴趣的结构和测试我们宇宙的理论至关重要。然而，3D反演带来了重大挑战。首先，与依赖于多个视点的标准3D重建不同，在这种情况下，图像仅从单个视点观察。通过观察整个体积中的星系发射器是如何被透镜化的，可以部分解决这一挑战。然而，这导致了第二个挑战：无透镜星系的形状和确切位置是未知的，只能在非常大的不确定性下进行估计。这引入了大量的噪声，几乎完全淹没了透镜信号。以前的方法通过对卷中的结构施加强有力的假设来解决这个问题。相反，我们提出了一种使用引力约束神经场来灵活模拟连续物质分布的方法。我们采用综合分析方法，通过完全可微的物理正向模型优化神经网络的权重，以再现图像测量中存在的透镜信号。我们展示了我们的模拟方法，包括模拟即将到来的望远镜调查数据的暗物质分布的真实模拟测量。我们的结果表明，我们的方法不仅可以超越以前的方法，而且重要的是还能够恢复潜在的令人惊讶的暗物质结构。 et.al.|[2504.15262](http://arxiv.org/abs/2504.15262)|null|
|**2025-04-20**|**Efficient Implicit Neural Compression of Point Clouds via Learnable Activation in Latent Space**|隐式神经表示（INR），也称为神经场，已成为深度学习中的一种强大范式，使用基于坐标的神经网络对连续空间场进行参数化。在本文中，我们提出了\textbf{PICO}，这是一个基于INR的静态点云压缩框架。与主流的编码器-解码器范式不同，我们将点云压缩任务分解为两个单独的阶段：几何压缩和属性压缩，每个阶段都有不同的INR优化目标。受Kolmogorov-Arnold网络（KANs）的启发，我们引入了一种新的网络架构\textbf{LeAFNet}，它利用潜在空间中的可学习激活函数来更好地近似目标信号的隐函数。通过将点云压缩重新表述为神经参数压缩，我们通过量化和熵编码进一步提高了压缩效率。实验结果表明，\textbf{LeAFNet}在基于INR的点云压缩中优于传统的MLP。此外，与当前的MPEG点云压缩标准相比，\textbf{PICO}实现了卓越的几何压缩性能，D1 PSNR平均提高了4.92 $dB。在联合几何和属性压缩方面，我们的方法表现出了极具竞争力的结果，平均PCQM增益为2.7美元乘以10^{-3}$ 。 et.al.|[2504.14471](http://arxiv.org/abs/2504.14471)|null|
|**2025-04-17**|**Radial Basis Function Techniques for Neural Field Models on Surfaces**|我们提出了一种使用径向基函数（RBF）插值和求积求解曲面上神经场方程的数值框架。神经场模型描述了宏观大脑活动的演变，但建模研究往往忽视了弯曲皮质区域的复杂几何形状。传统的数值方法，如有限元或谱方法，在计算上可能很昂贵，并且在不规则域上实现具有挑战性。相比之下，基于RBF的方法提供了一种灵活的替代方案，通过提供插值和正交方案，以高阶精度有效地处理任意几何形状。我们首先为一般曲面上的神经场模型开发了一个基于RBF的插值投影框架。详细推导了平面和曲面域的求积法，确保了高阶精度和稳定性，因为它们取决于RBF超参数（基函数、增广多项式和模板大小）。通过数值实验，我们证明了我们的方法的收敛性，突出了它在灵活性和准确性方面优于传统方法。最后，我们阐述了复杂表面上时空活动的数值模拟，说明了该方法捕捉复杂波传播模式的能力。 et.al.|[2504.13379](http://arxiv.org/abs/2504.13379)|null|
|**2025-04-16**|**SCENT: Robust Spatiotemporal Learning for Continuous Scientific Data via Scalable Conditioned Neural Fields**|由于空间和时间依赖性之间的复杂相互作用、数据的高维度和可扩展性约束，时空学习具有挑战性。这些挑战在科学领域进一步加剧，在这些领域，数据通常是不规则分布的（例如，传感器故障的缺失值）和高容量的（例如高保真模拟），带来了额外的计算和建模困难。在本文中，我们提出了SCENT，这是一种用于可扩展和连续性知情的时空表示学习的新框架。SCENT在单一架构中统一了插值、重建和预测。SCENT建立在基于变换器的编码器-处理器-解码器骨干上，引入了可学习的查询来增强泛化能力，并引入了查询式交叉关注机制来有效捕获多尺度依赖关系。为了确保数据大小和模型复杂性的可扩展性，我们引入了稀疏注意力机制，实现了灵活的输出表示和任意分辨率的高效评估。我们通过广泛的模拟和真实世界的实验来验证SCENT，在实现卓越可扩展性的同时，在多个具有挑战性的任务中展示了最先进的性能。 et.al.|[2504.12262](http://arxiv.org/abs/2504.12262)|null|
|**2025-04-14**|**DNF-Avatar: Distilling Neural Fields for Real-time Animatable Avatar Relighting**|从单眼视频中创建可重现和可动画化的人类化身是一个新兴的研究课题，具有广泛的应用，例如虚拟现实、体育和视频游戏。之前的研究利用神经场和基于物理的渲染（PBR）来估计人类化身的几何形状并解开其外观属性。然而，这些方法的一个缺点是由于昂贵的蒙特卡洛射线追踪导致渲染速度较慢。为了解决这个问题，我们提出将隐式神经场（教师）的知识提取为显式的2D高斯飞溅（学生）表示，以利用高斯飞溅的快速光栅化特性。为了避免光线追踪，我们对PBR外观采用了分裂和近似。我们还提出了用于阴影计算的新型部分式环境遮挡探头。阴影预测是通过每像素只查询一次这些探测器来实现的，这为化身的实时重新照明铺平了道路。这些技术相结合，可以提供高质量的重新照明效果和逼真的阴影效果。我们的实验表明，所提出的学生模型与我们的教师模型实现了相当甚至更好的重新照明结果，同时在推理时快了370倍，达到了67 FPS的渲染速度。 et.al.|[2504.10486](http://arxiv.org/abs/2504.10486)|null|
|**2025-04-11**|**SN-LiDAR: Semantic Neural Fields for Novel Space-time View LiDAR Synthesis**|最近的研究已经开始探索激光雷达点云的新颖视图合成（NVS），旨在从看不见的视点生成逼真的激光雷达扫描。然而，大多数现有的方法都不能重建语义标签，而语义标签对于自动驾驶和机器人感知等许多下游应用至关重要。与受益于强大分割模型的图像不同，LiDAR点云缺乏如此大规模的预训练模型，这使得语义标注既费时又费力。为了应对这一挑战，我们提出了SN LiDAR，这是一种联合执行精确语义分割、高质量几何重建和逼真LiDAR合成的方法。具体来说，我们采用从粗到细的平面网格特征表示来从多帧点云中提取全局特征，并利用基于CNN的编码器从当前帧点云中提取局部语义特征。SemanticKITTI和KITTI-360的大量实验证明了SN LiDAR在语义和几何重建方面的优越性，有效地处理了动态对象和大规模场景。代码将在https://github.com/dtc111111/SN-Lidar. et.al.|[2504.08361](http://arxiv.org/abs/2504.08361)|**[link](https://github.com/dtc111111/sn-lidar)**|
|**2025-04-08**|**econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic Gaussians**|最近关于开放词汇神经场的工作的主要重点是从VLM中提取精确的语义特征，然后将它们有效地整合到多视图一致的3D神经场表示中。然而，大多数现有的工作都是在受信任的SAM上进行的，以规范图像级CLIP，而无需进一步细化。此外，一些现有的研究通过在与3DGS语义场融合之前对2D VLM的语义特征进行降维来提高效率，这不可避免地导致了多视图不一致。在这项工作中，我们提出了使用3DGS进行开放式词汇语义分割的econSG。我们的econSG由以下部分组成：1）置信区间引导正则化（CRR），它相互细化SAM和CLIP，以获得具有完整和精确边界的精确语义特征的两全其美。2）低维上下文空间，通过融合反投影的多视图2D特征来增强3D多视图一致性，同时提高计算效率，然后直接对融合的3D特征进行降维，而不是分别对每个2D视图进行操作。与现有方法相比，我们的econSG在四个基准数据集上显示了最先进的性能。此外，我们也是所有方法中最有效的培训。 et.al.|[2504.06003](http://arxiv.org/abs/2504.06003)|null|

<p align=right>(<a href=#updated-on-20250428>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

