[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.12.19
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-15**|**SlimmeRF: Slimmable Radiance Fields**|神经辐射场（NeRF）及其变体最近已成为新型视图合成和3D场景重建的成功方法。然而，大多数当前的NeRF模型要么使用大的模型尺寸来实现高精度，要么通过权衡精度来实现高存储效率。这限制了任何单个模型的适用范围，因为高精度模型可能不适合低内存设备，而高效内存模型可能无法满足高质量要求。为此，我们提出了SlimmeRF模型，该模型允许通过精简在模型大小和准确性之间进行即时测试时间权衡，从而使模型同时适用于具有不同计算预算的场景。我们通过一种新提出的名为张量秩增量（TRaIn）的算法来实现这一点，该算法在训练过程中逐渐增加模型张量表示的秩。我们还观察到，我们的模型允许在稀疏视图场景中进行更有效的权衡，有时甚至在精简后实现更高的精度。我们将此归功于这样一个事实，即错误信息（如浮动信息）往往存储在与更高级别相对应的组件中。我们的实施可在https://github.com/shiran-yuan/slimmerf. et.al.|[2312.10034](http://arxiv.org/abs/2312.10034)|**[link](https://github.com/shiran-yuan/slimmerf)**|
|**2023-12-15**|**RANRAC: Robust Neural Scene Representations via Random Ray Consensus**|我们介绍了RANRAC，这是一种用于处理遮挡和分心图像的3D对象的鲁棒重建算法，这是现有鲁棒重建方法无法处理的一个特别具有挑战性的场景。我们的解决方案通过涉及光场网络支持单镜头重建，也适用于基于神经辐射场的真实世界图像的照片逼真、鲁棒、多视图重建。虽然该算法对场景表示以及支持的场景类型施加了一定的限制，但它可靠地检测并排除了不一致的视角，从而产生了没有浮动伪影的干净图像。我们的解决方案基于随机样本一致性范式的模糊自适应，使其能够应用于大规模模型。我们将确定模型参数的最小样本数解释为可调超参数。这是适用的，因为更干净的样本集提高了重建质量。此外，此过程还处理异常值。特别是对于条件模型，它可以在潜在空间中产生与完全干净集相同的局部最小值。我们报告了在遮挡场景中新视图合成的显著改进，与基线相比，PSNR高达8dB。 et.al.|[2312.09780](http://arxiv.org/abs/2312.09780)|null|
|**2023-12-15**|**SLS4D: Sparse Latent Space for 4D Novel View Synthesis**|神经辐射场（NeRF）在静态场景的新视图合成和三维表示方面取得了巨大成功。现有的动态NeRF通常利用局部密集网格来拟合变形场；然而，它们未能捕捉到全局动力学，并随之产生重参数模型。我们观察到4D空间本质上是稀疏的。首先，由于运动的连续性，变形场在空间上是稀疏的，但在时间上是密集的。其次，辐射场仅在底层场景的表面有效，通常只占整个空间的一小部分。因此，我们建议使用可学习的稀疏潜在空间（也称为SLS4D）来表示4D场景。具体而言，SLS4D首先使用密集的可学习时隙特征来描述时间空间，从该时间空间中，变形场与线性多层感知（MLP）相拟合，以预测任何时候3D位置的位移。然后，它使用另一个稀疏的潜在空间来学习3D位置的空间特征。这是通过利用注意力机制学习每个潜在代码的自适应权重来实现的。大量实验证明了我们的SLS4D的有效性：它仅使用最近工作的大约 $6\%$ 参数就实现了最佳的4D新视图合成。 et.al.|[2312.09743](http://arxiv.org/abs/2312.09743)|null|
|**2023-12-15**|**TIFace: Improving Facial Reconstruction through Tensorial Radiance Fields and Implicit Surfaces**|本报告描述了在ICCV 2023研讨会上获得“人类头部视图综合挑战（VSCHH）”第一名的解决方案。考虑到人类头部的稀疏视图图像，这一挑战的目标是从新的视点合成图像。由于面部纹理的复杂性和光线的影响，基线方法TensoRF产生的结果具有显著的伪影，严重影响了面部重建。为了解决这个问题，我们提出了TI Face，它分别通过张量辐射场（T-Face）和隐式曲面（I-Face）来改进面部重建。具体来说，我们采用基于SAM的方法来获得前景遮罩，从而过滤掉背景中的强烈照明。此外，我们还设计了基于掩模的约束和稀疏性约束，以有效地消除渲染伪影。实验结果证明了所提出的改进方法的有效性和我们的方法在人脸重建方面的优越性能。代码将在https://github.com/ruijiezhu94/ti-face. et.al.|[2312.09527](http://arxiv.org/abs/2312.09527)|**[link](https://github.com/ruijiezhu94/ti-face)**|
|**2023-12-14**|**LatentEditor: Text Driven Local Editing of 3D Scenes**|虽然神经领域在视图合成和场景重建方面取得了重大进展，但由于其对来自多视图输入的几何和纹理信息的隐式编码，编辑它们带来了巨大的挑战。在本文中，我们介绍了\textsc｛LatentEditor｝，这是一个创新的框架，旨在让用户能够使用文本提示对神经字段进行精确和本地控制的编辑。利用去噪扩散模型，我们成功地将真实世界的场景嵌入到潜在空间中，与传统方法相比，产生了更快、更具适应性的NeRF主干进行编辑。为了提高编辑精度，我们引入了一个delta分数来计算潜在空间中的2D掩模，该分数可以作为局部修改的指南，同时保留不相关的区域。我们新颖的像素级评分方法利用InstructPix2Pix（IP2P）的能力来辨别潜在空间中IP2P条件和无条件噪声预测之间的差异。然后在训练集中迭代地更新以2D掩码为条件的编辑的潜伏时间，以实现3D局部编辑。与现有的3D编辑模型相比，我们的方法实现了更快的编辑速度和卓越的输出质量，弥合了文本指令和潜在空间中高质量3D场景编辑之间的差距。我们在LLFF、IN2N、NeRFStudio和NeRFArt四个基准3D数据集上展示了我们的方法的优势。 et.al.|[2312.09313](http://arxiv.org/abs/2312.09313)|**[link](https://github.com/umarkhalidAI/LatentEditor)**|
|**2023-12-15**|**ColNeRF: Collaboration for Generalizable Sparse Input Neural Radiance Field**|神经辐射场（NeRF）在从密集输入合成新视图方面表现出了令人印象深刻的潜力，然而，在处理稀疏输入时，其有效性受到了挑战。现有的方法结合了额外的深度或语义监督，可以在一定程度上缓解这一问题。然而，监督收集的过程不仅成本高昂，而且可能不准确，导致在不同场景下的表现和泛化能力较差。在我们的工作中，我们介绍了一种新的模型：协作神经辐射场（ColNeRF），设计用于处理稀疏输入。ColNeRF中的协作包括稀疏输入图像之间的协作和神经辐射场的输出之间的协作。通过这一点，我们构建了一个新的协作模块，该模块将来自不同视图的信息对齐，同时施加自监督约束，以确保多视图在几何和外观上的一致性。提出了一种协作跨视图体积集成模块（CCVI）来捕捉复杂的遮挡并隐含地推断对象的空间位置。此外，我们引入了对多个方向上投影的目标射线的自监督，以确保相邻区域的几何和颜色一致性。得益于输入端和输出端的协作，ColNeRF能够捕捉更丰富、更通用的场景表示，从而促进新视图合成的更高质量结果。大量实验表明，ColNeRF优于最先进的稀疏输入可推广NeRF方法。此外，与基于场景优化的NeRF方法相比，我们的方法在微调以适应新场景方面表现出优势，实现了有竞争力的性能，同时显著降低了计算成本。我们的代码位于：https://github.com/eezkni/colnerf. et.al.|[2312.09095](http://arxiv.org/abs/2312.09095)|**[link](https://github.com/eezkni/colnerf)**|
|**2023-12-15**|**ProSGNeRF: Progressive Dynamic Neural Scene Graph with Frequency Modulated Auto-Encoder in Urban Scenes**|隐式神经表示在大型复杂场景的视图合成中已经显示出有希望的结果。然而，现有的方法要么无法捕捉快速移动的对象，要么需要在没有相机自我运动的情况下构建场景图，导致场景的合成视图质量低。我们旨在共同解决大规模城市场景和快速移动车辆的视图合成问题，这更具实用性和挑战性。为此，我们首先利用图结构来学习动态对象和背景的局部场景表示。然后，我们设计了一个渐进方案，该方案动态地分配用时间窗口内的帧训练的新的局部场景图，允许我们将表示放大到任意大的场景。此外，城市场景的训练视图相对稀疏，这导致动态对象的重建精度显著下降。因此，我们设计了一个频率自动编码器网络来对潜在代码进行编码，并正则化对象的频率范围，这可以增强动态对象的表示，解决图像输入稀疏的问题。此外，我们使用激光雷达点投影来保持大规模城市场景中的几何一致性。实验结果表明，我们的方法实现了最先进的视图合成精度、对象操纵和场景漫游能力。该代码将在论文验收后开源。 et.al.|[2312.09076](http://arxiv.org/abs/2312.09076)|null|
|**2023-12-14**|**Scene 3-D Reconstruction System in Scattering Medium**|随着新模型和扩展的发展，用于新视图合成的神经辐射场研究经历了爆炸式增长。适用于水下场景或散射介质的NERF算法也在不断发展。现有的水下三维重建系统仍然面临训练时间长、渲染效率低等挑战。本文提出了一种改进的水下三维重建系统来解决这些问题，并实现快速、高质量的三维重建。首先，我们增强了单眼相机拍摄的水下视频，以纠正水介质物理特性造成的图像质量差的问题，同时确保相邻帧增强的一致性。随后，我们对视频帧进行关键帧选择，以优化资源利用率，消除动态对象对重建结果的影响。所选关键帧在使用COLMAP进行姿态估计后，使用基于多分辨率哈希编码的神经辐射场进行三维重建改进过程，用于模型构建和渲染。 et.al.|[2312.09005](http://arxiv.org/abs/2312.09005)|null|
|**2023-12-14**|**VaLID: Variable-Length Input Diffusion for Novel View Synthesis**|新视图合成（NVS）是3D视觉中的一个基本问题，它试图在给定源视图图像及其相应姿态的情况下，在目标视图上生成逼真的图像。由于这项任务严重受限，最近的一些工作，如Zero123，试图通过生成建模来解决这个问题，特别是使用预先训练的扩散模型。尽管这种策略很好地适用于新场景，但与基于神经辐射场的方法相比，它提供的灵活性很低。例如，尽管现实应用程序通常提供多个输入图像，但它只能接受单个视图图像作为输入。这是因为源视图图像和相应的姿势是单独处理的，并在不同阶段注入到模型中。因此，一旦模型可用，将其推广到多视图源图像中并非易事。为了解决这个问题，我们试图分别处理每个姿势图像对，然后将它们融合为统一的视觉表示，将其注入模型中，以指导目标视图的图像合成。然而，不一致性和计算成本随着输入源视图图像的数量的增加而增加。为了解决这些问题，提出了多视图交叉形成器模块，该模块将可变长度的输入数据映射到固定大小的输出数据。为了进一步提高训练时间的效率，引入了两阶段训练策略。在多个数据集上进行的定性和定量评估证明了所提出的方法相对于以前的方法的有效性。代码将根据验收结果发布。 et.al.|[2312.08892](http://arxiv.org/abs/2312.08892)|null|
|**2023-12-14**|**CF-NeRF: Camera Parameter Free Neural Radiance Fields with Incremental Learning**|神经辐射场（NeRF）在新的视图合成中表现出了令人印象深刻的性能。然而，NeRF及其大多数变体仍然依赖于传统的复杂管道来提供外在和内在的相机参数，如COLMAP。最近的工作，如NeRFmm、BARF和L2G NeRF，直接将相机参数视为可学习的，并通过差分体绘制进行估计。然而，这些方法适用于具有轻微运动的前瞻性场景，在实践中无法解决旋转场景。为了克服这一限制，我们提出了一种新颖的下划线{c}amera参数\下划线{f}ree神经辐射场（CF NeRF），其增量重建3D表示并从运动中恢复受增量结构启发的相机参数（SfM）。给定一系列图像，CF-NeRF逐个估计图像的相机参数，并通过初始化、隐式定位和隐式优化重建场景。为了评估我们的方法，我们使用了一个具有挑战性的真实世界数据集NeRFBuster，该数据集提供了复杂轨迹下的12个场景。结果表明，CF-NeRF对相机旋转具有鲁棒性，并且在不提供先验信息和约束的情况下实现了最先进的结果。 et.al.|[2312.08760](http://arxiv.org/abs/2312.08760)|null|

<p align=right>(<a href=#updated-on-20231219>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-14**|**Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D Reconstruction with Transformers**|生成模型的发展推动了从单个图像进行3D重建的最新进展。其中最突出的是基于分数蒸馏采样（SDS）的方法和3D域中扩散模型的自适应。尽管这些技术取得了进展，但由于优化或渲染过程缓慢，导致训练和优化时间过长，这些技术往往面临限制。在本文中，我们介绍了一种新的单视图重建方法，该方法通过前馈推理从单个图像有效地生成3D模型。我们的方法利用两个基于变换器的网络，即点解码器和三平面解码器，使用混合三平面高斯中间表示来重建3D对象。这种混合表示实现了平衡，与隐式表示相比，实现了更快的渲染速度，同时提供了比显式表示更高的渲染质量。点解码器被设计用于从单个图像生成点云，提供显式表示，然后由三平面解码器使用该显式表示来查询每个点的高斯特征。这种设计选择解决了与直接回归以其非结构性质为特征的显式三维高斯属性相关的挑战。随后，通过MLP对3D高斯进行解码，以实现通过飞溅的快速渲染。这两个解码器都建立在可扩展的、基于转换器的架构上，并在大规模3D数据集上进行了有效的训练。对合成数据集和真实世界图像进行的评估表明，与以前最先进的技术相比，我们的方法不仅实现了更高的质量，而且确保了更快的运行时间。请参阅我们的项目页面https://zouzx.github.io/triplanegaussian/. et.al.|[2312.09147](http://arxiv.org/abs/2312.09147)|null|
|**2023-12-14**|**Living Scenes: Multi-object Relocalization and Reconstruction in Changing 3D Environments**|对动态3D场景理解的研究主要集中在密集观测的短期变化跟踪上，而很少关注稀疏观测的长期变化。我们用MoRE解决了这一差距，MoRE是一种在进化环境中进行多对象重新定位和重建的新方法。我们将这些环境视为“真实场景”，并考虑将在不同时间点进行的扫描转换为对象实例的3D重建的问题，其准确性和完整性会随着时间的推移而提高。我们方法的核心是在合成数据上训练的单个编码器-解码器网络中的SE（3）-等变表示。这种表示使我们能够无缝地处理实例匹配、注册和重建。我们还引入了一种联合优化算法，该算法有助于在不同时间点进行的多次扫描中积累源自同一实例的点云。我们在合成和真实世界的数据上验证了我们的方法，并在端到端性能和单个子任务中展示了最先进的性能。 et.al.|[2312.09138](http://arxiv.org/abs/2312.09138)|null|
|**2023-12-14**|**Learned Fusion: 3D Object Detection using Calibration-Free Transformer Feature Fusion**|使用传感器融合的3D对象检测的现有技术在很大程度上依赖于校准质量，这在实验室环境之外的大规模部署中很难维持。我们提出了第一种用于三维物体检测的无校准方法。因此，消除了对复杂且昂贵的校准程序的需要。我们的方法使用转换器在多个抽象级别上映射不同传感器的多个视图之间的特征。在对物体检测的广泛评估中，我们不仅表明我们的方法在BEV mAP中比单模态设置好14.1%，而且转换器确实学习了映射。通过表明传感器融合不需要校准，我们希望激励其他研究人员遵循无校准融合的方向。此外，由此产生的方法对旋转和平移变化具有相当大的弹性。 et.al.|[2312.09082](http://arxiv.org/abs/2312.09082)|null|
|**2023-12-14**|**Scene 3-D Reconstruction System in Scattering Medium**|随着新模型和扩展的发展，用于新视图合成的神经辐射场研究经历了爆炸式增长。适用于水下场景或散射介质的NERF算法也在不断发展。现有的水下三维重建系统仍然面临训练时间长、渲染效率低等挑战。本文提出了一种改进的水下三维重建系统来解决这些问题，并实现快速、高质量的三维重建。首先，我们增强了单眼相机拍摄的水下视频，以纠正水介质物理特性造成的图像质量差的问题，同时确保相邻帧增强的一致性。随后，我们对视频帧进行关键帧选择，以优化资源利用率，消除动态对象对重建结果的影响。所选关键帧在使用COLMAP进行姿态估计后，使用基于多分辨率哈希编码的神经辐射场进行三维重建改进过程，用于模型构建和渲染。 et.al.|[2312.09005](http://arxiv.org/abs/2312.09005)|null|
|**2023-12-13**|**ProNeRF: Learning Efficient Projection-Aware Ray Sampling for Fine-Grained Implicit Neural Radiance Fields**|神经渲染的最新进展表明，尽管速度较慢，但隐式紧凑模型可以从多个视图中学习场景的几何图形和视图相关外观。为了保持如此小的内存占用，但实现更快的推理时间，最近的工作采用了“采样器”网络，该网络自适应地对隐式神经辐射场中沿每条射线的一小部分点进行采样。尽管这些方法在渲染时间上减少了10美元\倍，但与香草NeRF相比，它们的质量仍有相当大的下降。相反，我们提出了ProNeRF，它在内存占用（类似于NeRF）、速度（比HyperReel快）和质量（比K-Planes好）之间提供了最佳折衷。ProNeRF配备了一种新的投影感知采样（PAS）网络，以及一种用于射线探测和利用的新训练策略，从而实现高效的细粒度粒子采样。我们的ProNeRF产生了最先进的指标，比NeRF快15-23倍，PSNR比NeRF高0.65dB，比已发表的最佳基于采样器的方法HyperReel高0.95dB。我们的探索和开发训练策略使ProNeRF能够学习完整场景的颜色和密度分布，同时学习聚焦于最高密度区域的高效光线采样。我们提供了广泛的实验结果，分别在广泛采用的前向和360数据集LLFF和Blender上支持我们的方法的有效性。 et.al.|[2312.08136](http://arxiv.org/abs/2312.08136)|null|
|**2023-12-13**|**Denoising diffusion-based synthetic generation of three-dimensional (3D) anisotropic microstructures from two-dimensional (2D) micrographs**|集成计算材料工程（ICME）显著增强了对微观结构与材料性能之间关系的系统分析，为高性能材料的发展铺平了道路。然而，由于缺乏三维（3D）微观结构数据集，分析微观结构敏感材料的行为仍然具有挑战性。此外，如果微观结构是各向异性的，这一挑战会被放大，因为这也会导致材料的各向异性。在本文中，我们提出了一种仅基于二维（2D）显微照片使用基于条件扩散的生成模型（DGM）重建各向异性微观结构的框架。所提出的框架涉及多个2D条件DGM的空间连接，每个条件DGM都经过训练以生成三个不同正交平面的2D微观结构样本。连接的多个反向扩散过程使得能够对马尔可夫链进行有效建模，以将噪声转换为3D微观结构样本。此外，采用改进的协调采样来提高样本质量，同时在3D空间中保持各向异性微观结构样本切片之间的空间连接。为了验证所提出的框架，根据空间相关函数和物理材料行为对二维到三维重建的各向异性微观结构样品进行了评估。结果表明，该框架不仅能够再现材料相的统计分布，而且能够再现三维空间中的材料性质。这突出了所提出的二维到三维重建框架在建立微观结构-性能联系方面的潜在应用，这可能有助于未来研究的高通量材料设计 et.al.|[2312.07832](http://arxiv.org/abs/2312.07832)|null|
|**2023-12-12**|**Adaptive Confidence Multi-View Hashing for Multimedia Retrieval**|多视图哈希方法将多个视图中的异构数据转换为二进制哈希码，是多媒体检索的关键技术之一。然而，目前的方法主要探讨多个观点之间的互补性，而缺乏信心学习和融合。此外，在实际应用场景中，单视图数据包含冗余噪声。为了进行置信度学习并消除不必要的噪声，我们提出了一种新的自适应置信度多视图哈希（ACMVH）方法。首先，开发了置信网络来从各种单视图特征中提取有用信息并去除噪声信息。此外，采用自适应置信度多视图网络来测量每个视图的置信度，然后通过加权求和来融合多视图特征。最后，设计了一个扩展网络来进一步增强融合特征的特征表示。据我们所知，我们率先将置信学习应用于多媒体检索领域。在两个公共数据集上进行的大量实验表明，所提出的ACMVH比最先进的方法性能更好（最大增加了3.24%）。源代码可在https://github.com/hackerhyper/acmvh. et.al.|[2312.07327](http://arxiv.org/abs/2312.07327)|**[link](https://github.com/hackerhyper/acmvh)**|
|**2023-12-11**|**Gaussian Splatting SLAM**|我们首次将3D高斯散射应用于使用单个移动单目或RGB-D相机的增量3D重建。我们的同步定位和映射（SLAM）方法以3fps实时运行，使用高斯作为唯一的3D表示，统一了所需的表示，以实现准确、高效的跟踪、映射和高质量渲染。需要一些创新来从现场摄像机连续重建具有高保真度的3D场景。首先，为了超越最初的3DGS算法，该算法需要来自离线运动结构（SfM）系统的精确姿态，我们使用针对3D高斯的直接优化来制定3DGS的相机跟踪，并表明这能够实现快速而稳健的跟踪，并具有广泛的收敛范围。其次，通过利用高斯的显式性质，我们引入了几何验证和正则化来处理增量三维密集重建中出现的模糊性。最后，我们介绍了一个完整的SLAM系统，它不仅在新的视图合成和轨迹估计方面取得了最先进的结果，而且还重建了微小甚至透明的物体。 et.al.|[2312.06741](http://arxiv.org/abs/2312.06741)|null|
|**2023-12-10**|**UNeR3D: Versatile and Scalable 3D RGB Point Cloud Generation from 2D Images in Unsupervised Reconstruction**|在从2D图像进行3D重建的领域中，一个持续的挑战是在不依赖3D地面实况数据的情况下实现高精度重建。我们介绍了UNeR3D，这是一种开创性的无监督方法，为仅从2D视图生成详细的3D重建设定了新标准。我们的模型显著降低了与监督方法相关的训练成本，并将RGB着色引入3D点云，丰富了视觉体验。UNeR3D采用反向距离加权技术进行颜色渲染，可确保无缝的颜色转换，增强视觉逼真度。我们的模型的灵活架构支持使用任何数量的视图进行训练，而且唯一的是，在执行重建时，它不受训练期间使用的视图数量的限制。它可以在推理过程中使用任意数量的视图进行推理，提供了无与伦比的多功能性。此外，该模型的连续空间输入域允许以任何所需分辨率生成点云，从而能够创建高分辨率的3D RGB点云。我们用一种新颖的多视图几何损失和颜色损失来巩固重建过程，证明我们的模型在单视图输入及其他方面都很出色，从而重塑了3D视觉中无监督学习的范式。我们的贡献标志着3D视觉的巨大飞跃，为各种应用程序的内容创作提供了新的视野。代码位于https://github.com/hongbinlin3589/uner3d. et.al.|[2312.06706](http://arxiv.org/abs/2312.06706)|null|
|**2023-12-11**|**Nuvo: Neural UV Mapping for Unruly 3D Representations**|现有的UV映射算法被设计为在性能良好的网格上操作，而不是由最先进的3D重建和生成技术产生的几何表示。因此，将这些方法应用于由神经辐射场和相关技术（或从这些场三角化的网格）恢复的体积密度会导致纹理图谱过于分散，无法用于视图合成或外观编辑等任务。我们提出了一种UV映射方法，旨在对通过3D重建和生成技术产生的几何体进行操作。我们的方法Nuvo不是计算在网格顶点上定义的映射，而是使用神经场来表示连续的UV映射，并将其优化为仅针对一组可见点（即仅影响场景外观的点）的有效且性能良好的映射。我们展示了我们的模型对不良几何体带来的挑战是稳健的，并且它生成了可以表示详细外观的可编辑UV映射。 et.al.|[2312.05283](http://arxiv.org/abs/2312.05283)|null|

<p align=right>(<a href=#updated-on-20231219>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-15**|**Movement Primitive Diffusion: Learning Gentle Robotic Manipulation of Deformable Objects**|机器人辅助手术（RAS）中的策略学习缺乏数据高效和通用的方法，无法为精细的手术干预提供所需的运动质量。为此，我们介绍了运动原始扩散（MPD），这是一种在RAS中进行模仿学习（IL）的新方法，专注于对可变形对象的温和操作。该方法将基于扩散的模仿学习（DIL）的多功能性与概率动态运动原语（ProDMPs）的高质量运动生成能力相结合。这种组合使MPD能够实现对可变形对象的温和操作，同时保持对演示数据稀缺的RAS应用程序至关重要的数据效率。我们在各种模拟任务和真实世界的机器人设置中评估状态和图像观测的MPD。MPD在成功率、运动质量和数据效率方面优于最先进的DIL方法。 et.al.|[2312.10008](http://arxiv.org/abs/2312.10008)|null|
|**2023-12-15**|**Shear viscosity in interacting two-dimensional Fermi liquids**|在中等温度下以相互作用为主的二维电子气中，电子输运不像传统的Drude图中那样具有扩散性，而是具有流体动力学性质。在这种情况下，相关的传输系数是剪切粘度。在这里，我们开发了一个数值精确的基展开式来求解费米液体方程，并将其应用于计算具有屏蔽库仑相互作用的电子气的剪切粘度。我们的计算在所有温度下都是有效的，特别是描述了超过渐近低温极限的响应，其中存在微扰方法。我们表明，即使在这个低温极限下，剪切粘度也有非解析交换的贡献，这突出了费米液体方程需要一个完整的非扰动解。我们希望这项工作中开发的技术将作为一个平台来确定相互作用的费米液体的响应。 et.al.|[2312.09977](http://arxiv.org/abs/2312.09977)|null|
|**2023-12-15**|**Contributions to the geomagnetic secular variation from a reanalysis of core surface dynamics**|我们在空间和时间约束下反演地核表面的运动，这些约束偏离了通常用于确保流解的谱收敛的数学平滑。我们的空间约束源自地球动力学模拟。该模型是使用与地磁急动发生相关的随机微分方程在时间上进行平差的。这些空间和时间约束与卡尔曼滤波器一起，使核心流量能够作为长度和时间尺度的函数进行估计。从综合实验中，我们发现考虑子网格误差对于获得无偏重建至关重要。这是通过增强状态方法实现的。我们表明，即使在短周期内，也应考虑扩散对地磁长期变化的重大贡献，因为扩散与核心表面下快速变化的流量在动力学上有关。我们的方法应用于1950-2015年期间的地球物理观测，可以获得与数据不匹配的合理解决方案。我们强调了东赤道地区扩散的一个重要特征，在那里，偏心的向西环流到达低纬度地区，与重要的上升/下降流有关。我们的结果还证实，在过去几十年中观察到的偶极衰变主要是由平流过程驱动的。我们的方法使我们能够为核心流量和长期变化的预测提供概率密度。 et.al.|[2312.09942](http://arxiv.org/abs/2312.09942)|null|
|**2023-12-15**|**A quasi-Trefftz discontinuous Galerkin method for the homogeneous diffusion-advection-reaction equation with piecewise-smooth coefficients**|我们描述并分析了求解具有分段光滑系数的齐次扩散-平流反应方程边值问题的拟Trefftz DG方法。Trefftz格式是高阶Galerkin方法，其离散函数是底层偏微分方程的元素精确解。对于许多线性、齐次和分段常系数的偏微分方程，可以计算Trefftz基函数。然而，如果方程具有变化的系数，一般来说，精确解是不可用的，因此不可能构造离散的Trefftz空间。为了克服这一限制，引入了拟Trefftz方法，它依赖于作为PDE的元素“近似解”的函数的离散空间。最近研究了一种求解光滑变系数声波方程的时空拟Trefftz-DG方法；由于它已经显示出很好的结果，我们提出了一种可以应用于二阶椭圆型方程的相关方法。利用内部惩罚参数和逆风数值通量推导了DG弱公式。我们选择多项式拟Trefftz基函数，其系数可以用基于PDE系数的泰勒展开的简单算法来计算。与更经典的方案相比，Trefftz和准Trefftz方案的主要优点是对于可比较的自由度数量具有更高的精度。我们证明了拟Trefftz空间的维数小于相同次数的全多项式空间的维数，并且得到了相同的最优收敛速度。拟Trefftz DG方法是适定的、一致的和稳定的，我们证明了它的高阶收敛性。我们给出了一些二维数值实验，这些实验在近似和收敛速度方面显示出优异的性质。 et.al.|[2312.09919](http://arxiv.org/abs/2312.09919)|null|
|**2023-12-15**|**Assimilation of ground and satellite magnetic measurements: inference of core surface magnetic and velocity field changes**|我们直接使用地面天文台的时间序列和CHAMP和Swarm卫星的测量结果，联合反演了1997-2017年期间核心表面的磁场和速度场。卫星数据被简化为虚拟天文台时间序列的形式，分布在空间的规则网格上。这样的顺序存储有助于将大量的现代磁数据合并到随机卡尔曼滤波器中，从而基于从数值地球动力学模型的统计中导出的范数来合并空间约束。我们的算法在与数据的不匹配和估计的后验模型不确定性方面都产生了一致的解。我们从球形谐波场模型的分析中检索了先前记录的核心流特征，例如偏心反气旋环流。我们发现，印度尼西亚和非洲的扩散模式都有所增强。与大西洋半球下强而太平洋下弱的稳定气流相反，年际运动在两个半球上均匀分布。恢复的年际到十年的流量变化主要是关于切线圆柱体外的赤道对称的。相比之下，在北太平洋下，我们发现了高纬度急流的增强，但在南半球没有看到相应特征的证据。在所研究的时代，我们分离出的最大流动加速度与曲流有关，曲流附属于东半球行星涡旋的赤道经向分支，即l et.al.|[2312.09878](http://arxiv.org/abs/2312.09878)|null|
|**2023-12-15**|**Integrating New Technologies into Science: The case of AI**|新技术具有使科学发生革命性变化的力量。这种情况已经发生在过去，随着人工智能（AI）和机器学习（ML）等新计算工具的出现，这种情况正在再次发生。尽管这些技术的影响有据可查，但在科学界对其采用过程的理解仍存在重大差距。在本文中，我们借鉴科技人力资本（STHC）理论，研究人工智能在科学研究中的整合，重点关注科学家的人力资本及其合作者和机构网络中可用的外部资源。我们在OpenAlex的大量出版物样本上验证了我们的假设，这些出版物涵盖了1980年至2020年的所有科学。我们发现，人工智能的传播在很大程度上是由社会机制驱动的，这些机制组织了人力资本的部署和创造，以补充技术。我们的研究结果表明，人工智能是由具有“探索品味”的领域科学家开创的，他们嵌入了一个由计算机科学家、经验丰富的人工智能科学家和早期职业研究人员组成的网络；它们也来自具有较高引用影响力和相对强大的人工智能出版历史的机构。各科学学科的模式相似，但高性能计算（HPC）除外，它在化学和医学科学中很重要，但在其他领域则不那么重要。一旦人工智能被纳入研究，大多数采用因素将继续影响其后续的重用。讨论了人工智能驱动的发现时代对科学组织和管理的启示。 et.al.|[2312.09843](http://arxiv.org/abs/2312.09843)|null|
|**2023-12-15**|**Socio-Economic Deprivation Analysis: Diffusion Maps**|这份报告提出了一个模型，利用人口普查数据预测城市中最贫困地区的位置。人口普查数据的维度非常高，需要简化。我们使用一种新的算法来降维和寻找模式：扩散图。特征由定义扩散图的拉普拉斯矩阵的特征向量定义。与最小特征值相对应的特征向量表示特定的群体特征。先前的工作定性地发现，描述布里斯托尔人口普查数据的第二个最重要维度与贫困有关。在这份报告中，我们通过与公认的衡量标准进行比较，分析了这个维度作为预测贫困的模型有多好。Pearson相关系数大于0.7。对同样位于布里斯托尔的英国前10%的贫困地区进行提取，以测试该模型的准确性。有52个最贫困的地区，通过与模型的比较，38个地区被正确识别。与模型不相关的IMD域的分数、非剥夺OA的特征向量2条目和特征向量的正交性的影响导致模型无法预测14个剥夺区域。然而，总体而言，该模型在预测项目所考虑的整体区域的未来贫困方面表现出了很高的性能。该项目预计将支持政府分配资源和资金。 et.al.|[2312.09830](http://arxiv.org/abs/2312.09830)|null|
|**2023-12-15**|**Comparison of Quasi-Geostrophic, Hybrid and 3D models of planetary core convection**|我们对与行星核心相关的厚球壳几何形状中的快速旋转对流进行了研究，比较了准地转、3D和混合QG-3D模型的结果。报道的170个计算跨越Ekman数， $Ek$，在$10^{-4}$和$10^｛-10}$之间，Rayleigh数，$Ra$，在$2$和$150$倍超临界之间，以及Prandtl数，$Pr$，在$10000和$10^｛-2}$之间。一般来说，我们发现对流主要由壳中深处的纬向喷流控制，当驱动较弱时，热Rossby波在靠近外边界处突出。对于此处研究的特定几何形状，混合方法最适合于研究适度强迫下的对流，$Ra\leq10\，当$Pr=1$时，Ra_c$，并且在较高的$Ra$时偏离3D模型结果，显示出系统较低的热传输。我们发现，浮力中温度和速度之间缺乏等式反对称和$z$-相关性，导致混合公式中的流动较弱。另一方面，对于这里探索的特定参数范围，QG模型产生了与3D模型大致相似的结果。我们不能指出这两个数据集在$Pr\geq0.1$之间的主要分歧，尽管QG模型比混合情况更有效地受到驱动。当$Pr$减少时，混合模型和3D模型之间的一致性范围扩大，这表明混合方法可能更适合研究$Pr\ll 1$ 状态下的对流。检索了先前提出的快速旋转对流的标度定律：我们的模拟总体上很好地描述为科里奥利力、惯性力和阿基米德力之间的三重平衡，对流的长度标度遵循无扩散Rhines标度。 et.al.|[2312.09826](http://arxiv.org/abs/2312.09826)|null|
|**2023-12-15**|**Dynamic control of the Bose-Einstein-like condensation transition in scalar active matter**|研究了一类具有扩散边缘的标量活性物质在限制势中的动力学，其中振幅由时间相关协议控制。对于这种非平衡系统，当单粒子密度场达到临界阈值时，扩散系数消失，从而引发形式上类似于玻色-爱因斯坦凝聚的凝聚跃迁。我们证明，即使对于没有达到稳态的系统，这种转变也会发生，从而导致有限时间内的冷凝。由于可以通过演化系统在固定的有效温度下诱导转变，我们有效地证明了时间坐标构成了调整转变特性的替代控制参数。对于恒定振幅协议，我们的广义热力学在稳态极限下减少到早期结果。最后，我们用数值方法证明，对于电位振幅的周期性调制，凝聚跃迁是重入的。 et.al.|[2312.09823](http://arxiv.org/abs/2312.09823)|null|
|**2023-12-15**|**Neural networks for turbulent transport prediction in a simplified model of tokamak plasmas**|探讨了在简化的托卡马克等离子体模型中使用神经网络预测湍流输运的方法。神经网络是在平板几何近似中通过传输模型的测试粒子模拟获得的数据库上进行训练的。它包括输运模型参数的五维输入和作为输出的径向扩散系数。神经网络显示出快速有效的收敛性，验证误差低于2 $\%$ ，预测与真实数据非常一致，比测试粒子模拟快几个数量级。与样条插值相比，神经网络表现出更好的预测和外推能力。我们证明了该方法的精确性和有效性，作为概念验证，为未来更全面地研究使用神经网络进行托卡马克等离子体输运预测奠定了一种很有前途的方法。 et.al.|[2312.09807](http://arxiv.org/abs/2312.09807)|null|

<p align=right>(<a href=#updated-on-20231219>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2023-12-14**|**LatentEditor: Text Driven Local Editing of 3D Scenes**|虽然神经领域在视图合成和场景重建方面取得了重大进展，但由于其对来自多视图输入的几何和纹理信息的隐式编码，编辑它们带来了巨大的挑战。在本文中，我们介绍了\textsc｛LatentEditor｝，这是一个创新的框架，旨在让用户能够使用文本提示对神经字段进行精确和本地控制的编辑。利用去噪扩散模型，我们成功地将真实世界的场景嵌入到潜在空间中，与传统方法相比，产生了更快、更具适应性的NeRF主干进行编辑。为了提高编辑精度，我们引入了一个delta分数来计算潜在空间中的2D掩模，该分数可以作为局部修改的指南，同时保留不相关的区域。我们新颖的像素级评分方法利用InstructPix2Pix（IP2P）的能力来辨别潜在空间中IP2P条件和无条件噪声预测之间的差异。然后在训练集中迭代地更新以2D掩码为条件的编辑的潜伏时间，以实现3D局部编辑。与现有的3D编辑模型相比，我们的方法实现了更快的编辑速度和卓越的输出质量，弥合了文本指令和潜在空间中高质量3D场景编辑之间的差距。我们在LLFF、IN2N、NeRFStudio和NeRFArt四个基准3D数据集上展示了我们的方法的优势。 et.al.|[2312.09313](http://arxiv.org/abs/2312.09313)|**[link](https://github.com/umarkhalidAI/LatentEditor)**|
|**2023-12-14**|**ZeroRF: Fast Sparse View 360° Reconstruction with Zero Pretraining**|我们提出了ZeroRF，这是一种新的每场景优化方法，解决了神经场表示中稀疏视图360重建的挑战。目前的突破，如神经辐射场（NeRF）已经证明了高保真度的图像合成，但难以处理稀疏的输入视图。现有的方法，如可泛化的NeRF和每场景优化方法，在数据依赖性、计算成本和跨不同场景的泛化方面面临限制。为了克服这些挑战，我们提出了ZeroRF，其关键思想是将定制的深度图像先验集成到因子分解的NeRF表示中。与传统方法不同，ZeroRF使用神经网络生成器对特征网格进行参数化，从而实现高效的稀疏视图360重建，而无需任何预训练或额外的正则化。大量实验展示了ZeroRF在质量和速度方面的多功能性和优势，在基准数据集上取得了最先进的结果。ZeroRF的意义延伸到3D内容生成和编辑的应用。项目页面：https://sarahweiii.github.io/zerorf/ et.al.|[2312.09249](http://arxiv.org/abs/2312.09249)|null|
|**2023-12-12**|**SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration**|最近的实时视图合成技术在保真度和速度上迅速进步，现代方法能够以交互式帧速率渲染接近照片级真实感的场景。与此同时，在易于光栅化的显式场景表示和基于射线行进的神经场之间出现了紧张关系，后者的最先进实例在质量上超过了前者，同时对于实时应用来说成本高得令人望而却步。在这项工作中，我们介绍了SMERF，这是一种视图合成方法，在占地面积高达3亿 $^2$、体积分辨率为3.5毫米$^3$ 的大型场景中，它实现了实时方法中最先进的精度。我们的方法建立在两个主要贡献之上：一个是分层模型划分方案，它在限制计算和内存消耗的同时增加了模型容量，另一个是蒸馏训练策略，它同时产生高保真度和内部一致性。我们的方法能够在网络浏览器中实现全六自由度（6DOF）导航，并在商品智能手机和笔记本电脑上实时渲染。大量实验表明，我们的方法在实时新视图合成方面，在标准基准上超过了当前最先进的0.78 dB，在大型场景上超过了1.78 dB，渲染帧的速度比最先进的辐射场模型快三个数量级，并在包括智能手机在内的各种商品设备上实现了实时性能。我们鼓励读者在我们的项目网站上亲自探索这些模型：https://smerf-3d.github.io. et.al.|[2312.07541](http://arxiv.org/abs/2312.07541)|null|
|**2023-12-09**|**Robo360: A 3D Omnispective Multi-Material Robotic Manipulation Dataset**|长期以来，制造能够自动化劳动密集型任务的机器人一直是计算机视觉和机器人界进步的核心动力。最近人们对利用3D算法，特别是神经领域的兴趣，导致了机器人在操作场景中的感知和物理理解方面的进步。然而，现实世界的复杂性带来了重大挑战。为了应对这些挑战，我们提出了Robo360，这是一个以机器人操作为特征的数据集，具有密集的视图覆盖范围，能够实现高质量的3D神经表示学习，以及一组具有各种物理和光学特性的不同对象，有助于各种对象操作和物理世界建模任务的研究。我们使用现有的动态NeRF来确认我们的数据集的有效性，并评估其在学习多视图策略方面的潜力。我们希望Robo360能够在理解3D物理世界和机器人控制的交叉点上开辟新的研究方向。 et.al.|[2312.06686](http://arxiv.org/abs/2312.06686)|null|
|**2023-12-11**|**Representing stimulus motion with waves in adaptive neural fields**|神经活动的行波在皮层网络中自发出现，并对刺激做出反应。波的时空结构可以指示它们编码的信息以及维持它们的生理过程。在这里，我们研究了作为视觉运动处理模型的自适应神经场中出现的行波的刺激响应关系。神经场方程将皮层组织的活动建模为连续的可兴奋介质，自适应过程提供负反馈，产生局部活动模式。在我们的模型中，突触连接由一个积分核来描述，该积分核由于依赖于活动的突触抑制而动态减弱，导致边缘稳定的行进前沿（具有衰减的后部）或固定速度的脉冲。我们的分析量化了弱刺激如何随着时间的推移改变这些波的相对位置，其特征是我们扰动地获得的波响应函数。持续和连续可见的刺激模拟移动的视觉对象。在视觉空间中跳跃的间歇性闪光可以产生流畅的视觉运动体验。我们的理论和数值模拟很好地描述了波对两种运动刺激的夹带，提供了视觉运动感知的机制描述。 et.al.|[2312.06100](http://arxiv.org/abs/2312.06100)|null|
|**2023-12-10**|**Accurate Differential Operators for Hybrid Neural Fields**|神经场已广泛应用于从形状表示到神经渲染以及求解偏微分方程（PDE）的各个领域。随着混合神经场表示的出现，如利用小MLP和显式表示的即时NGP，这些模型训练迅速，可以适应大型场景。然而，在渲染和模拟等许多应用中，混合神经场可能会导致明显且不合理的伪影。这是因为它们不能产生这些下游应用所需的精确的空间导数。在这项工作中，我们提出了两种规避这些挑战的方法。我们的第一种方法是一种事后算子，它使用局部多项式拟合从预先训练的混合神经场中获得更准确的导数。此外，我们还提出了一种自监督微调方法，该方法在保留初始信号的同时，对神经场进行细化，以直接产生准确的导数。我们展示了我们的方法在渲染、碰撞模拟和求解偏微分方程中的应用。我们观察到，使用我们的方法可以产生更准确的导数，减少伪影，并在下游应用中实现更准确的模拟。 et.al.|[2312.05984](http://arxiv.org/abs/2312.05984)|null|
|**2023-12-11**|**Nuvo: Neural UV Mapping for Unruly 3D Representations**|现有的UV映射算法被设计为在性能良好的网格上操作，而不是由最先进的3D重建和生成技术产生的几何表示。因此，将这些方法应用于由神经辐射场和相关技术（或从这些场三角化的网格）恢复的体积密度会导致纹理图谱过于分散，无法用于视图合成或外观编辑等任务。我们提出了一种UV映射方法，旨在对通过3D重建和生成技术产生的几何体进行操作。我们的方法Nuvo不是计算在网格顶点上定义的映射，而是使用神经场来表示连续的UV映射，并将其优化为仅针对一组可见点（即仅影响场景外观的点）的有效且性能良好的映射。我们展示了我们的模型对不良几何体带来的挑战是稳健的，并且它生成了可以表示详细外观的可编辑UV映射。 et.al.|[2312.05283](http://arxiv.org/abs/2312.05283)|null|
|**2023-12-08**|**Dynamic LiDAR Re-simulation using Compositional Neural Fields**|我们介绍了DyNFL，这是一种新的基于神经场的方法，用于动态驾驶场景中激光雷达扫描的高保真度重新模拟。DyNFL处理来自动态环境的激光雷达测量，并伴随着移动物体的边界框，以构建可编辑的神经场。该字段包括单独重建的静态背景和动态对象，允许用户在重新模拟的场景中修改视点、调整对象位置以及无缝添加或删除对象。我们方法的一个关键创新是神经场合成技术，该技术通过光线下降测试有效地集成了来自各种场景的重建神经资产，考虑到了遮挡和透明表面。我们对合成和真实世界环境的评估表明，\ShortName大大改进了基于激光雷达扫描的动态场景模拟，提供了物理保真度和灵活编辑功能的组合。 et.al.|[2312.05247](http://arxiv.org/abs/2312.05247)|null|
|**2023-12-08**|**TriHuman : A Real-time and Controllable Tri-plane Representation for Detailed Human Geometry and Appearance Synthesis**|仅从视频数据中创建可控、逼真和几何细节的真人数字替身是计算机图形学和视觉领域的一个关键挑战，尤其是在需要实时性能的情况下。最近的方法将神经辐射场（NeRF）连接到关节结构，例如身体模型或骨骼，以将点映射到姿势规范空间中，同时将NeRF调节在骨骼姿势上。这些方法通常使用多层感知器（MLP）对神经场进行参数化，导致运行时间缓慢。为了解决这一缺点，我们提出了一种新的人体定制、可变形和高效的三平面表示TriHuman，它实现了实时性能、最先进的姿态可控几何合成以及逼真的渲染质量。在核心，我们将全局光线样本非刚性地扭曲到未变形的三平面纹理空间中，这有效地解决了全局点映射到相同三平面位置的问题。然后，我们展示了如何将这种三平面特征表示以骨骼运动为条件，以考虑动态外观和几何结构的变化。我们的研究结果表明，在人类的几何形状和外观建模以及运行时性能方面，朝着更高质量迈出了明确的一步。 et.al.|[2312.05161](http://arxiv.org/abs/2312.05161)|null|
|**2023-12-08**|**GIR: 3D Gaussian Inverse Rendering for Relightable Scene Factorization**|本文提出了一种用于可重照明场景分解的三维高斯逆绘制方法GIR。与利用离散网格或神经隐式场进行反向渲染的现有方法相比，我们的方法利用3D高斯从多视图图像中估计对象的材料特性、照明和几何结构。我们的研究动机是有证据表明，在性能、多功能性和效率方面，3D高斯是比神经领域更有前途的主干。在本文中，我们旨在回答以下问题：“如何应用3D高斯来提高反向渲染的性能？”为了解决基于离散且通常在均匀分布的3D高斯表示中估计法线的复杂性，我们提出了一种高效的自正则化方法，该方法有助于在不需要额外监督的情况下对曲面法线进行建模。为了重建间接照明，我们提出了一种模拟光线跟踪的方法。大量实验证明，在反向渲染中，我们提出的GIR在各种广泛使用的数据集上跨多个任务的性能优于现有方法。这证实了它的功效和广泛的适用性，突出了它作为重新照明和重建中有影响力的工具的潜力。项目页面：https://3dgir.github.io et.al.|[2312.05133](http://arxiv.org/abs/2312.05133)|null|

<p align=right>(<a href=#updated-on-20231219>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

