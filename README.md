[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.10.08
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-07**|**DreamSat: Towards a General 3D Model for Novel View Synthesis of Space Objects**|新颖的视图合成（NVS）能够生成场景的新图像或将一组2D图像转换为全面的3D模型。在空间领域意识的背景下，由于空间变得越来越拥挤，NVS可以准确地绘制空间物体和碎片的地图，提高空间操作的安全性和效率。同样，在会合和近距离作战任务中，3D模型可以提供目标物体的形状、大小和方向的详细信息，从而更好地规划和预测目标的行为。在这项工作中，我们探索了这些重建技术的泛化能力，旨在通过在190个高质量航天器模型的高质量数据集上微调最先进的单视图重建模型Zero123 XL，并将其集成到DreamGaussian框架中，提出一种从单视图图像重建3D航天器的新方法DreamSat，从而避免对每个新场景进行再训练的必要性。我们展示了在多个指标上重建质量的一致改进，包括对比语言图像预训练（CLIP）得分（+0.33%）、峰值信噪比（PSNR）（+2.53%）、结构相似性指数（SSIM）（+2.38%）和学习感知图像补丁相似性（LPIPS）（+0.16%）。%）在30张以前从未见过的航天器图像的测试集上。我们的方法通过利用最先进的扩散模型和3D高斯溅射技术，解决了航天工业中缺乏特定领域的3D重建工具的问题。这种方法保持了DreamGaussian框架的效率，同时提高了航天器重建的准确性和细节。这项工作的代码可以在GitHub上访问(https://github.com/ARCLab-MIT/space-nvs). et.al.|[2410.05097](http://arxiv.org/abs/2410.05097)|**[link](https://github.com/arclab-mit/space-nvs)**|
|**2024-10-07**|**6DGS: Enhanced Direction-Aware Gaussian Splatting for Volumetric Rendering**|随着神经辐射场（NeRF）和3D高斯散射（3DGS）的发展，新型视图合成技术取得了显著进步。然而，在不影响实时渲染的情况下实现高质量仍然具有挑战性，特别是对于具有视图相关效果的基于物理的光线跟踪。最近，N维高斯（N-DG）引入了6D空间角度表示，以更好地结合视图相关的效果，但高斯表示和控制方案都是次优的。在本文中，我们重新审视了6D高斯分布，并引入了6D高斯散斑（6DGS），它增强了颜色和不透明度表示，并利用6D空间中的额外方向信息来优化高斯控制。我们的方法与3DGS框架完全兼容，并通过更好地建模视图相关效果和精细细节，显著提高了实时辐射场渲染。实验证明，6DGS明显优于3DGS和N-DG，与3DGS相比，PSNR提高了15.73dB，高斯点减少了66.5%。 et.al.|[2410.04974](http://arxiv.org/abs/2410.04974)|null|
|**2024-10-07**|**TeX-NeRF: Neural Radiance Fields from Pseudo-TeX Vision**|神经辐射场（NeRF）因其卓越的视觉效果而受到广泛关注。然而，大多数现有的NeRF方法都是从可见光相机捕获的RGB图像中重建3D场景。在黑暗、低光照或恶劣天气等实际情况下，可见光摄像头会变得无效。因此，我们提出了TeX-NeRF，这是一种仅使用红外图像的3D重建方法，它先验地引入了物体材料的发射率，使用伪TeX视觉对红外图像进行预处理，并将场景的温度（T）、发射率（e）和纹理（X）分别映射到HSV颜色空间的饱和度（S）、色调（H）和值（V）通道中。使用处理后的图像的新颖视图合成产生了优异的结果。此外，我们介绍了3D TeX数据集，这是第一个包含红外图像及其相应的伪TeX视觉图像的数据集。实验证明，我们的方法不仅与高质量RGB图像实现的场景重建质量相匹配，而且为场景中的对象提供了准确的温度估计。 et.al.|[2410.04873](http://arxiv.org/abs/2410.04873)|null|
|**2024-10-06**|**Deformable NeRF using Recursively Subdivided Tetrahedra**|虽然神经辐射场（NeRF）在新颖的视图合成中显示出希望，但它们的隐式表示限制了对对象操纵的显式控制。现有的研究提出了整合显式几何代理来实现变形。然而，这些方法面临着两个主要挑战：第一，耗时且计算量大的四面体化过程；其次，处理复杂或薄的结构通常会导致四面体网格过多、存储密集或质量差，从而损害变形能力。为了应对这些挑战，我们提出了DeformRF，这是一种将四面体网格的可操作性与特征网格表示的高质量渲染能力无缝集成的方法。为了避免每个对象的四面体形状不好和四面体化，我们提出了一种两阶段训练策略。从几乎规则的四面体网格开始，我们的模型最初保留了对象周围的关键四面体，随后在第二阶段使用更细粒度的网格细化对象细节。我们还提出了递归细分四面体的概念，以隐式创建更高分辨率的网格。这实现了多分辨率编码，同时只需要存储在第一训练阶段生成的粗略四面体网格。我们在合成和真实捕获的数据集上对DeformRF进行了全面评估。定量和定性结果都证明了我们的方法在新的视图合成和变形任务中的有效性。项目页面：https://ustc3dv.github.io/DeformRF/ et.al.|[2410.04402](http://arxiv.org/abs/2410.04402)|null|
|**2024-10-06**|**StreetSurfGS: Scalable Urban Street Surface Reconstruction with Planar-based Gaussian Splatting**|重建城市街道场景至关重要，因为它在自动驾驶和城市规划等应用中起着至关重要的作用。这些场景的特点是长而窄的相机轨迹、遮挡、复杂的对象关系和跨多个尺度的数据稀疏性。尽管最近取得了进展，但主要针对以对象为中心的场景设计的现有表面重建方法很难有效地适应街道场景的独特特征。为了应对这一挑战，我们引入了StreetSurfGS，这是第一种采用高斯散斑法的方法，专门为可扩展的城市街道场景表面重建而定制。StreetSurfGS利用基于平面的八叉树表示和分段训练来降低内存成本，适应独特的相机特性，并确保可扩展性。此外，为了减轻对象重叠引起的深度不准确，我们提出了一种正则化中的引导平滑策略，以消除不准确的边界点和异常值。此外，为了解决稀疏视图和多尺度挑战，我们使用了一种利用相邻和长期信息的双步匹配策略。大量实验验证了StreetSurfGS在新颖视图合成和曲面重建方面的有效性。 et.al.|[2410.04354](http://arxiv.org/abs/2410.04354)|null|
|**2024-10-05**|**Test-Time Adaptation for Keypoint-Based Spacecraft Pose Estimation Based on Predicted-View Synthesis**|由于在训练过程中难以复制真实条件，当在合成数据上训练并应用于实际操作数据时，航天器姿态估计的监督算法的性能会下降。为了解决这个问题，我们提出了一种测试时间自适应方法，该方法利用了近距离操作期间获取的图像之间的时间冗余。我们的方法包括从连续的航天器图像中提取特征，估计它们的姿态，然后使用这些信息合成重建的视图。我们通过将综合视图与实际视图进行比较，建立了一个自我监督学习目标。在训练过程中，我们监督姿态估计和图像合成，而在测试时，我们优化自我监督目标。此外，我们引入了正则化损失，以防止与航天器关键点结构不一致的解决方案。我们的代码可在以下网址获得：https://github.com/JotaBravo/spacecraft-tta. et.al.|[2410.04298](http://arxiv.org/abs/2410.04298)|**[link](https://github.com/jotabravo/spacecraft-tta)**|
|**2024-10-03**|**Flash-Splat: 3D Reflection Removal with Flash Cues and Gaussian Splats**|我们介绍了一种简单而有效的分离透射光和反射光的方法。我们的关键见解是，现代逆渲染方法（例如，~3D高斯散点）提供的强大的新颖视图合成功能允许人们使用不成对的测量值进行闪光/无闪光反射分离——这种松弛大大简化了传统成对闪光/无闪光反射分离方法的图像采集。通过广泛的现实世界实验，我们展示了我们的方法Flash Splat，可以准确地重建3D中的透射和反射场景。我们的方法在很大程度上优于不利用照明控制的现有3D反射分离方法。我们的项目网页位于https://flash-splat.github.io/. et.al.|[2410.02764](http://arxiv.org/abs/2410.02764)|null|
|**2024-10-03**|**GI-GS: Global Illumination Decomposition on Gaussian Splatting for Inverse Rendering**|我们提出了GI-GS，这是一种新颖的逆渲染框架，它利用3D高斯散斑（3DGS）和延迟着色来实现照片级逼真的新颖视图合成和重新照明。在逆渲染中，精确建模对象的着色过程对于实现高保真结果至关重要。因此，至关重要的是结合全局照明来考虑在场景中多次反弹后到达对象的间接照明。以前基于3DGS的方法试图通过将间接照明表征为可学习的照明体积或每个高斯的附加属性来模拟间接照明，同时使用烘焙遮挡来表示阴影效果。然而，这些方法无法准确模拟光和物体之间复杂的物理相互作用，使得在重新照明过程中无法构建逼真的间接照明。为了解决这一局限性，我们建议使用具有延迟着色的有效路径跟踪来计算间接照明。在我们的框架中，我们首先渲染一个G缓冲区，以捕获场景的详细几何体和材质属性。然后，我们仅对直接照明执行基于物理的渲染（PBR）。使用G缓冲区和之前的渲染结果，可以通过轻量级路径跟踪计算间接照明。我们的方法有效地模拟了任何给定照明条件下的间接照明，从而实现了更好的新颖视图合成和重新照明。定量和定性结果表明，我们的GI-GS在渲染质量和效率方面都优于现有的基线。 et.al.|[2410.02619](http://arxiv.org/abs/2410.02619)|null|
|**2024-10-03**|**SuperGS: Super-Resolution 3D Gaussian Splatting via Latent Feature Field and Gradient-guided Splitting**|最近，3D高斯散斑（3DGS）以其实时渲染能力和卓越的质量在新颖的视图合成中脱颖而出。然而，由于从低分辨率输入视图导出的基元的粗糙性质，它面临着高分辨率新视图合成（HRNVS）的挑战。为了解决这个问题，我们提出了超分辨率3DGS（SuperGS），它是3DGS的扩展，采用两阶段粗到细的训练框架设计，利用预训练的低分辨率场景表示作为超分辨率优化的初始化。此外，我们引入了多分辨率特征高斯散斑（MFGS），以结合潜在特征场进行灵活的特征采样，并引入梯度引导的选择性分裂（GSS）进行有效的高斯上采样。通过将这些策略整合到从粗到细的框架中，可以确保高保真度和内存效率。大量实验表明，SuperGS在仅使用低分辨率输入挑战现实世界数据集方面超越了最先进的HRNVS方法。 et.al.|[2410.02571](http://arxiv.org/abs/2410.02571)|null|
|**2024-10-02**|**MVGS: Multi-view-regulated Gaussian Splatting for Novel View Synthesis**|最近在体绘制方面的工作，例如NeRF和3D高斯散点（3DGS），在学习到的隐式神经辐射场或3D高斯分布的帮助下，显著提高了渲染质量和效率。在显式表示的基础上进行渲染，vanilla 3DGS及其变体通过在训练过程中每次迭代都进行单视图监督来优化参数模型，从而提供实时效率。因此，某些视图被过度拟合，导致新颖的视图合成和不精确的3D几何中的外观不令人满意。为了解决上述问题，我们提出了一种新的3DGS优化方法，该方法体现了四个关键的新贡献：1）我们将传统的单视图训练范式转变为多视图训练策略。通过我们提出的多视图调节，3D高斯属性得到了进一步优化，而不会过拟合某些训练视图。作为通用解决方案，我们提高了各种场景和不同高斯变体的整体精度。2） 受其他观点带来的好处的启发，我们进一步提出了一种跨内在指导方案，从而针对不同分辨率进行了从粗到细的训练过程。3） 基于我们的多视图调节训练，我们进一步提出了一种交叉射线致密化策略，从一系列视图中在射线交叉区域致密化更多的高斯核。4） 通过进一步研究致密化策略，我们发现当某些观点明显不同时，致密化的效果应该得到增强。作为一种解决方案，我们提出了一种新的多视图增强致密化策略，其中鼓励3D高斯模型相应地被致密化到足够的数量，从而提高了重建精度。 et.al.|[2410.02103](http://arxiv.org/abs/2410.02103)|null|

<p align=right>(<a href=#updated-on-20241008>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-07**|**DreamSat: Towards a General 3D Model for Novel View Synthesis of Space Objects**|新颖的视图合成（NVS）能够生成场景的新图像或将一组2D图像转换为全面的3D模型。在空间领域意识的背景下，由于空间变得越来越拥挤，NVS可以准确地绘制空间物体和碎片的地图，提高空间操作的安全性和效率。同样，在会合和近距离作战任务中，3D模型可以提供目标物体的形状、大小和方向的详细信息，从而更好地规划和预测目标的行为。在这项工作中，我们探索了这些重建技术的泛化能力，旨在通过在190个高质量航天器模型的高质量数据集上微调最先进的单视图重建模型Zero123 XL，并将其集成到DreamGaussian框架中，提出一种从单视图图像重建3D航天器的新方法DreamSat，从而避免对每个新场景进行再训练的必要性。我们展示了在多个指标上重建质量的一致改进，包括对比语言图像预训练（CLIP）得分（+0.33%）、峰值信噪比（PSNR）（+2.53%）、结构相似性指数（SSIM）（+2.38%）和学习感知图像补丁相似性（LPIPS）（+0.16%）。%）在30张以前从未见过的航天器图像的测试集上。我们的方法通过利用最先进的扩散模型和3D高斯溅射技术，解决了航天工业中缺乏特定领域的3D重建工具的问题。这种方法保持了DreamGaussian框架的效率，同时提高了航天器重建的准确性和细节。这项工作的代码可以在GitHub上访问(https://github.com/ARCLab-MIT/space-nvs). et.al.|[2410.05097](http://arxiv.org/abs/2410.05097)|**[link](https://github.com/arclab-mit/space-nvs)**|
|**2024-10-07**|**Real-time Ship Recognition and Georeferencing for the Improvement of Maritime Situational Awareness**|在海洋基础设施至关重要的时代，先进的态势感知解决方案变得越来越重要。光学相机系统的使用可以实时使用海上录像。本文研究了如何利用深度学习和计算机视觉来推进实时船舶识别和地理参考，以提高海上态势感知能力。介绍了一种新的数据集ShipSG，其中包含3505张图像和11625个具有相应类别和地理位置的船面具。在探索了最先进的技术之后，为NVIDIA Jetson AGX Xavier嵌入式系统设计了一种定制的实时分割架构ScatYOLOv8+CBAM。该架构将2D散射变换和注意力机制添加到YOLOv8中，实现了75.46%的mAP和每帧25.3ms，比最先进的方法高出5%以上。为了提高嵌入式系统上高分辨率图像中小型和远程船舶的识别能力，引入了一种增强的切片机制，将mAP提高了8%至11%。此外，还提出了一种地理参考方法，对于距离400米以内的船舶，实现了18米的定位误差，对于400米至1200米之间的船舶，则实现了44米的定位精度。这些发现也适用于现实世界的场景，如检测异常的船舶行为、相机完整性评估和3D重建。本文的方法优于现有方法，并为将识别和地理参考的船舶集成到实时系统中提供了一个框架，提高了海事利益相关者的运营效率和决策能力。本文通过建立船舶分割和地理参考研究的基准，为海洋计算机视觉领域做出了贡献，展示了基于深度学习的识别和地理参考方法在实时海洋监测中的可行性。 et.al.|[2410.04946](http://arxiv.org/abs/2410.04946)|null|
|**2024-10-07**|**TeX-NeRF: Neural Radiance Fields from Pseudo-TeX Vision**|神经辐射场（NeRF）因其卓越的视觉效果而受到广泛关注。然而，大多数现有的NeRF方法都是从可见光相机捕获的RGB图像中重建3D场景。在黑暗、低光照或恶劣天气等实际情况下，可见光摄像头会变得无效。因此，我们提出了TeX-NeRF，这是一种仅使用红外图像的3D重建方法，它先验地引入了物体材料的发射率，使用伪TeX视觉对红外图像进行预处理，并将场景的温度（T）、发射率（e）和纹理（X）分别映射到HSV颜色空间的饱和度（S）、色调（H）和值（V）通道中。使用处理后的图像的新颖视图合成产生了优异的结果。此外，我们介绍了3D TeX数据集，这是第一个包含红外图像及其相应的伪TeX视觉图像的数据集。实验证明，我们的方法不仅与高质量RGB图像实现的场景重建质量相匹配，而且为场景中的对象提供了准确的温度估计。 et.al.|[2410.04873](http://arxiv.org/abs/2410.04873)|null|
|**2024-10-06**|**Multimodal 3D Fusion and In-Situ Learning for Spatially Aware AI**|增强现实中虚拟世界和物理世界的无缝集成得益于系统对物理环境的语义“理解”。AR研究长期以来一直专注于上下文感知的潜力，展示了利用3D环境中的语义进行各种对象级交互的新功能。与此同时，计算机视觉界在神经视觉语言理解方面取得了长足的进步，以增强自主任务的环境感知。在这项工作中，我们引入了一种多模态3D对象表示，该表示将语义和语言知识与几何表示相结合，实现了涉及物理对象的用户引导机器学习。我们首先提出了一种快速的多模态3D重建流水线，通过将CLIP视觉语言特征融合到环境和对象模型中，为AR带来语言理解。然后，我们提出了“原位”机器学习，它与多模态表示相结合，使用户能够以空间和语言上有意义的方式与物理空间和对象进行交互。我们通过Magic Leap 2上的两个现实AR应用程序展示了所提出系统的有用性：a）使用自然语言在物理环境中进行空间搜索；b）跟踪对象随时间变化的智能库存系统。我们还提供完整的实施和演示数据，网址为(https://github.com/cy-xu/spatially_aware_AI)鼓励对空间感知人工智能的进一步探索和研究。 et.al.|[2410.04652](http://arxiv.org/abs/2410.04652)|**[link](https://github.com/cy-xu/spatially_aware_ai)**|
|**2024-10-05**|**IceCloudNet: 3D reconstruction of cloud ice from Meteosat SEVIRI**|IceCloudNet是一种基于机器学习的新方法，能够预测高质量的垂直分辨云冰水含量（IWC）和冰晶数浓度（N $_\textrm{ice}$）。这些预测基于地球静止卫星观测（SEVIRI）的时空覆盖和分辨率以及主动卫星反演（DARDAR）的垂直分辨率。IceCloudNet由基于ConvNeXt的U-Net和3D PatchGAN鉴别器模型组成，并通过从共置的SEVIRI图像中预测DAR轮廓进行训练。尽管由于其狭窄的立交桥，DARDAR数据的可用性很低，但IceCloudNet能够高精度地预测云的出现、空间结构和微物理特性。该模型已应用于十年的SEVIRI数据，生成了一个垂直分辨率的IWC数据集和N$\textrm{ice}$ 的含冰云数据集，其分辨率为3 kmx3 kmx240 mx15分钟，空间域为西经30度至东经30度，南纬30度至北纬30度。所生成的数据集将DARDAR可用期间的垂直云剖面的可用性提高了六个数量级以上，此外，IceCloudNet能够生成DARDARDAR基础上最近结束的卫星任务寿命之外的垂直云轮廓。 et.al.|[2410.04135](http://arxiv.org/abs/2410.04135)|null|
|**2024-10-05**|**Hybrid NeRF-Stereo Vision: Pioneering Depth Estimation and 3D Reconstruction in Endoscopy**|当使用传统的单眼内窥镜时，微创内窥镜手术中手术区域的3D重建带来了巨大的挑战。现有的3D重建方法经常受到次优精度和有限泛化能力的阻碍。在这项研究中，我们介绍了一种使用神经辐射场（NeRF）进行3D重建的创新管道。我们的方法利用初步的NeRF重建，得到一个粗略的模型，然后在重建的环境中创建一个双目场景，通过立体视觉得到初始深度图。该初始深度图作为后续NeRF迭代的深度监督，以更高的精度逐步完善3D重建。迭代地重新计算双眼深度，并继续进行细化过程，直到深度图收敛，并且表现出可忽略的变化。通过这个递归过程，从逼真的颅骨体模的单眼内窥镜视频中生成高保真深度图。通过与X射线计算机断层扫描相比对最终3D重建的重复测量，相关临床距离的所有差异都导致了亚毫米级的精度。 et.al.|[2410.04041](http://arxiv.org/abs/2410.04041)|null|
|**2024-10-04**|**Img2CAD: Conditioned 3D CAD Model Generation from Single Image with Structured Visual Geometry**|在本文中，我们提出了Img2CAD，这是我们所知的第一种方法，它使用2D图像输入来生成具有可编辑参数的CAD模型。与现有的使用文本或图像输入生成3D模型的AI方法不同，Img2CAD通常依赖于基于网格的表示，这与CAD工具不兼容，缺乏可编辑性和精细控制性，Img2AD实现了基于AI的3D重建和CAD软件之间的无缝集成。我们已经确定了一种名为结构化视觉几何（SVG）的创新中间表示，其特征是从对象中提取的矢量化线框。这种表示法显著提高了生成条件CAD模型的性能。此外，我们引入了两个新的数据集来进一步支持这一领域的研究：ABC mono，这是已知最大的数据集，包含超过200000个带有渲染图像的3D CAD模型，以及KOCAD，这是第一个包含真实世界捕获对象及其地面真实CAD模型的数据集。 et.al.|[2410.03417](http://arxiv.org/abs/2410.03417)|null|
|**2024-10-04**|**3D Segmentation of Neuronal Nuclei and Cell-Type Identification using Multi-channel Information**|背景使用自动方法分析图像以准确估计大脑中不同细胞类型的数量是神经科学的主要目标。神经元的自动和选择性检测和分割将是神经解剖学研究的重要一步。新方法我们提出了一种改进神经元核3D重建的方法，该方法允许对神经元核进行分割，不包括非神经元细胞类型的核。结果我们在一个复杂的场景中（大量图像、不均匀染色和三个不同的通道来可视化不同的细胞标记），在大鼠新皮层的图像堆栈上测试了该算法。它能够提供良好的神经元核识别率和3D分割。与现有方法的比较：事实上，目前有许多自动工具可用，但由于标记和成像技术以及用于检测细胞的算法的差异，即使在相同的大脑区域，不同的方法也会产生不同的细胞计数估计。此外，一些可用的自动化软件方法提供了细胞数量的估计，据报道，在神经解剖学家评估后，这些估计是不准确或不一致的。结论：拥有一个能够区分神经元、神经胶质细胞和血管周围细胞的自动分割工具至关重要。这将大大加快目前手动执行的任务，并使细胞计数系统化，避免人为偏见。此外，不同细胞类型的3D重建结果可用于生成细胞空间分布的模型。 et.al.|[2410.03248](http://arxiv.org/abs/2410.03248)|null|
|**2024-10-02**|**Learning from the Giants: A Practical Approach to Underwater Depth and Surface Normals Estimation**|单目深度和表面法线估计（MDSNE）对于3D重建、自主导航和水下勘探等任务至关重要。当前的方法要么依赖于与透明或反射表面斗争的判别模型，要么依赖于生成模型，尽管生成模型准确，但计算成本很高。本文提出了一种新的MDSNE深度学习模型，该模型专门针对水下环境量身定制，使用了一种混合架构，将卷积神经网络（CNN）与Transformers集成在一起，利用了这两种方法的优势。训练有效的MDSNE模型往往受到现实世界数据集噪声和合成数据集泛化能力有限的阻碍。为了解决这个问题，我们使用多个预训练的MDSNE模型生成伪标记的真实数据。为了确保这些数据的质量，我们提出了深度法线评估和选择算法（DNESA），该算法使用领域特定的度量来评估和选择最可靠的伪标记样本。然后，在这个精心策划的数据集上训练一个轻量级的学生模型。我们的模型将参数减少了90%，训练成本减少了80%，允许在资源受限的设备上进行实时3D感知。主要贡献包括：一种新颖高效的MDSNE模型、DNESA算法、特定领域的数据管道，以及对实时性能和可扩展性的关注。我们的模型专为现实世界的水下应用而设计，便于在水下机器人和自动驾驶车辆中进行低成本部署，弥合了研究与实际实施之间的差距。 et.al.|[2410.02072](http://arxiv.org/abs/2410.02072)|null|
|**2024-10-02**|**Enhancing Screen Time Identification in Children with a Multi-View Vision Language Model and Screen Time Tracker**|能够准确监测幼儿的屏幕暴露对于研究与屏幕使用相关的现象（如儿童肥胖、体育活动和社会互动）非常重要。大多数现有的研究都依赖于笨重的可穿戴传感器的自我报告或手动测量，因此在捕获定量屏幕曝光数据方面缺乏效率和准确性。在这项工作中，我们开发了一种新的传感器信息学框架，该框架利用了来自可穿戴传感器（称为屏幕时间跟踪器（STT））的以自我为中心的图像和视觉语言模型（VLM）。特别是，我们设计了一种多视图VLM，它从以自我为中心的图像序列中获取多个视图，并动态解释屏幕曝光。我们通过使用儿童自由生活活动的数据集验证了我们的方法，证明了其在普通视觉语言模型和对象检测模型方面比现有方法的显著改进。结果支持了这种监测方法的前景，它可以优化儿童自然环境中屏幕暴露的行为研究。 et.al.|[2410.01966](http://arxiv.org/abs/2410.01966)|null|

<p align=right>(<a href=#updated-on-20241008>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-07**|**DART: A Diffusion-Based Autoregressive Motion Model for Real-Time Text-Driven Motion Control**|文本条件下的人体运动生成，允许用户通过自然语言进行交互，已经变得越来越流行。现有方法通常基于单个输入句子生成简短、孤立的运动。然而，人类的运动是连续的，可以长时间延伸，具有丰富的语义。创建能够精确响应文本描述流的长而复杂的动作，特别是在在线和实时环境中，仍然是一个重大挑战。此外，将空间约束合并到文本条件运动生成中会带来额外的挑战，因为它需要将文本描述指定的运动语义与几何信息（如目标位置和3D场景几何）对齐。为了解决这些局限性，我们提出了DART，这是一种基于扩散的自回归运动原语模型，用于实时文本驱动的运动控制。我们的模型DART使用潜在扩散模型有效地学习了一个基于运动历史和文本输入的紧凑运动原始空间。通过基于先前历史和当前文本输入自回归生成运动原语，DART实现了由自然语言描述驱动的实时、顺序运动生成。此外，学习的运动原始空间允许精确的空间运动控制，我们将其表述为潜在的噪声优化问题或通过强化学习解决的马尔可夫决策过程。我们为这两种方法提出了有效的算法，展示了我们的模型在各种运动合成任务中的通用性和卓越性能。实验表明，我们的方法在运动真实性、效率和可控性方面优于现有的基线。视频结果可在项目页面上查看：https://zkf1997.github.io/DART/. et.al.|[2410.05260](http://arxiv.org/abs/2410.05260)|null|
|**2024-10-07**|**GS-VTON: Controllable 3D Virtual Try-on with Gaussian Splatting**|基于扩散的2D虚拟试穿（VTON）技术最近表现出了很强的性能，而3D VTON的发展在很大程度上落后了。尽管最近在文本引导的3D场景编辑方面取得了进展，但将2D VTON集成到这些管道中以实现生动的3D VTON仍然具有挑战性。原因有两个。首先，文本提示在描述服装时无法提供足够的细节。其次，从同一3D场景的不同视点生成的2D VTON结果缺乏连贯性和空间关系，因此经常导致外观不一致和几何失真。为了解决这些问题，我们引入了一种图像提示的3D VTON方法（称为GS-VTON），该方法利用3D高斯散斑（3DGS）作为3D表示，能够将预训练的知识从2D VTON模型转移到3D，同时提高交叉视图的一致性。（1） 具体来说，我们提出了一种个性化扩散模型，该模型利用低秩自适应（LoRA）微调将个性化信息整合到预训练的2D VTON模型中。为了实现有效的LoRA训练，我们引入了一种参考驱动的图像编辑方法，该方法能够同时编辑多视图图像，同时确保一致性。（2） 此外，我们提出了一种角色感知的3DGS编辑框架，以促进有效的编辑，同时保持一致的交叉视图外观和高质量的3D几何。（3） 此外，我们还建立了一个新的3D VTON基准，即3D VTONBench，它有助于进行全面的定性和定量3D VTON评估。通过广泛的实验和与现有方法的比较分析，所提出的\OM已经证明了其卓越的保真度和先进的编辑能力，证实了其对3D VTON的有效性。 et.al.|[2410.05259](http://arxiv.org/abs/2410.05259)|null|
|**2024-10-07**|**SePPO: Semi-Policy Preference Optimization for Diffusion Alignment**|基于人类反馈的强化学习（RLHF）方法正在成为一种微调视觉生成扩散模型（DM）的方法。然而，常用的政策策略受到奖励模型泛化能力的限制，而非政策方法需要大量难以获得的成对人类注释数据，特别是在视觉生成任务中。为了解决政策内和政策外RLHF的局限性，我们提出了一种偏好优化方法，该方法将DM与偏好对齐，而不依赖于奖励模型或成对的人类注释数据。具体来说，我们引入了一种半策略偏好优化（SePPO）方法。SePPO利用以前的检查点作为参考模型，同时使用它们生成策略参考样本，以替换偏好对中的“丢失图像”。这种方法允许我们仅使用非政策“获胜图像”进行优化。此外，我们设计了一种参考模型选择策略，扩展了政策空间的探索。值得注意的是，我们不会简单地将参考样本视为学习的负面例子。相反，我们设计了一个基于锚点的标准来评估参考样本是可能获胜还是失败的图像，使模型能够有选择地从生成的参考样本中学习。这种方法减轻了参考样品质量不确定性造成的性能下降。我们在文本到图像和文本到视频基准测试中验证了SePPO。SePPO在文本到图像基准测试中超越了所有先前的方法，在文本到视频基准测试中也表现出了出色的性能。代码将于发布https://github.com/DwanZhang-AI/SePPO. et.al.|[2410.05255](http://arxiv.org/abs/2410.05255)|**[link](https://github.com/dwanzhang-ai/seppo)**|
|**2024-10-07**|**Tritium-Lean Fusion Power Plants with Asymmetric Deuterium-Tritium Transport and Pumping**|氘氚（D-T）粒子输运和偏滤器泵送速度的不对称性被证明可以提高聚变发电厂中氚的自给自足能力。使用连接等离子体核心、分离器和偏滤器区域的扩散粒子输运模型，结果表明，在增加氘输运的同时减少氚输运可以提高氚燃烧效率和整体聚变功率。通过选择性地增加氘输运，可以进一步优化氚燃烧效率，前提是非对称D-T燃料和先进的偏滤器技术可用。这些不对称性在高氚燃烧效率下变得特别有利。在一个例子中，通过将D-T粒子扩散率比和D-T偏滤器泵速比分别提高五倍，在固定聚变功率下，氚燃烧效率从0.026提高到0.29，提高了十一倍。我们提出了一种利用部分电离等离子体离心机的偏滤器再注入系统实现不对称D-T泵浦的新方法。在ARC级发电厂中，这种方法可以使氚燃烧效率提高一个数量级。这些发现推动了减少堆芯氚输运和提高氚偏滤器泵送速度的技术和工艺的发展。 et.al.|[2410.05238](http://arxiv.org/abs/2410.05238)|null|
|**2024-10-07**|**DiffuseReg: Denoising Diffusion Model for Obtaining Deformation Fields in Unsupervised Deformable Image Registration**|可变形图像配准旨在精确对齐来自不同模态或时间的医学图像。传统的深度学习方法虽然有效，但在配准推理过程中往往缺乏可解释性、实时可观测性和调整能力。通过将配准重新表述为迭代图像去噪，去噪扩散模型提供了一种替代方案。然而，现有的扩散配准方法没有充分利用能力，忽略了在推理过程中实现连续可观测性的关键采样阶段。因此，我们引入了DiffuseReg，这是一种基于扩散的创新方法，它对变形场而不是图像进行去噪，以提高透明度。我们还提出了一种基于Swin Transformer的新型去噪网络，该网络在整个去噪过程中更好地将运动和固定图像与扩散时间步长相结合。此外，我们通过一种新的相似性一致性正则化来增强对去噪配准过程的控制。在ACDC数据集上的实验表明，DiffuseReg在Dice得分上比现有的扩散配准方法高出1.32。DiffuseReg中的采样过程实现了以前深度模型无法比拟的实时输出可观测性和调整。 et.al.|[2410.05234](http://arxiv.org/abs/2410.05234)|null|
|**2024-10-07**|**Presto! Distilling Steps and Layers for Accelerating Music Generation**|尽管基于扩散的文本到音乐（TTM）方法取得了进展，但高效、高质量的生成仍然是一个挑战。我们介绍Presto！，一种通过减少采样步骤和每步骤成本来加速基于分数的扩散变换器推理的方法。为了减少步骤，我们为EDM系列扩散模型开发了一种新的基于分数的分布匹配蒸馏（DMD）方法，这是TTM的第一种基于GAN的蒸馏方法。为了降低每一步的成本，我们对最近的一种分层蒸馏方法进行了简单但强大的改进，该方法通过更好地保留隐藏状态方差来改善学习。最后，我们将分步蒸馏和分层蒸馏方法结合在一起，形成了一种双面方法。我们独立评估我们的分步和分层蒸馏方法，并展示每种方法的最佳性能。我们的组合蒸馏方法可以产生具有改进多样性的高质量输出，将我们的基础模型加速10-18倍（32秒单声道/立体声44.1kHz的230/435ms延迟，比同类SOTA快15倍）——据我们所知，这是最快的高质量TTM。声音的例子可以在https://presto-music.github.io/web/. et.al.|[2410.05167](http://arxiv.org/abs/2410.05167)|null|
|**2024-10-07**|**A Simulation-Free Deep Learning Approach to Stochastic Optimal Control**|我们提出了一种无仿真算法来解决随机最优控制（SOC）中的一般问题。与现有方法不同，我们的方法不需要解决伴随问题，而是利用Girsanov定理直接计算SOC目标在政策上的梯度。这使我们能够加快神经网络参数化控制策略的优化，因为它完全避免了通过神经SDE框架中使用的随机微分方程（SDE）进行昂贵的反向传播步骤。特别是，它使我们能够在高维和长时间范围内解决SOC问题。我们证明了我们的方法在各种应用领域的效率，包括标准随机最优控制问题、通过构建薛定谔-F过程从非正态分布中采样，以及对预训练扩散模型的微调。在所有情况下，我们的方法在计算时间和内存效率方面都优于现有方法。 et.al.|[2410.05163](http://arxiv.org/abs/2410.05163)|null|
|**2024-10-07**|**Formation of Anisotropic Polarons in Antimony Selenide**|硒化锑（Sb $_2$Se$_3$ ）是一种有吸引力的光伏材料，但效率尚不令人满意。除了缺陷，人们还提出了由晶格畸变引起的极化子形成来解释捕获自由载流子，以及随后的光激发动力学和光电性能，但这种机制仍然缺乏结构观测。在这里，我们通过光学和电子衍射泵浦探针方法直接跟踪光激发后载流子和晶格演化的路径，揭示了两个自由度动力学之间的时间相关性。观察到Se2-Sb2和Sb2-Sb1原子对在几皮秒内的相反分离变化，以及持续几十皮秒的局部结构畸变引起的中间态，分别与光学声子布居和耦合以及载流子的捕获过程相吻合，以及极化子模型的原子位移场对扩散散射的调制分析，表明形成了大尺寸的各向异性极化子。我们的发现提供了载体和结构信息，有助于阐明Sb2Se3中的极化子场景，并可能在开发新型光电子中流行的具有各向异性结构和软晶格的材料中。 et.al.|[2410.05155](http://arxiv.org/abs/2410.05155)|null|
|**2024-10-07**|**Editing Music with Melody and Text: Using ControlNet for Diffusion Transformer**|尽管在可控音乐生成和编辑方面取得了重大进展，但由于使用了梅尔谱图表示和基于UNet的模型结构，生成音乐的质量和长度仍然存在挑战。为了解决这些局限性，我们提出了一种使用扩散变换器（DiT）的新方法，并使用ControlNet添加了一个额外的控制分支。这允许通过文本和旋律提示控制长格式和可变长度的音乐生成和编辑。为了更精确和细粒度的旋律控制，我们引入了一种新的top- $k$ constant-Q Transform表示作为旋律提示，与之前的表示（例如色度）相比，减少了歧义，特别是对于具有多个曲目或宽范围音高值的音乐。为了有效地平衡来自文本和旋律提示的控制信号，我们采用了一种逐步掩盖旋律提示的课程学习策略，从而实现了更稳定的训练过程。使用开源乐器录音数据对文本到音乐生成和音乐风格转换任务进行了实验。结果表明，通过扩展预训练的文本控制DiT模型StableAudio，我们的方法能够实现卓越的旋律控制编辑，同时保持良好的文本到音乐生成性能。这些结果在基于文本的生成和用于编辑的旋律保存方面都优于强大的MusicGen基线。音频示例可以在以下网址找到https://stable-audio-control.github.io/web/. et.al.|[2410.05151](http://arxiv.org/abs/2410.05151)|null|
|**2024-10-07**|**Leveraging Multimodal Diffusion Models to Accelerate Imaging with Side Information**|扩散模型作为解决逆问题的表达先验取得了惊人的成功，但它们从自然图像扩展到更结构化的科学领域仍然有限。受材料科学应用的启发，我们的目标是通过利用更便宜的辅助模态的辅助信息，减少昂贵的成像模态所需的测量次数。为了处理正向模型的不可微性和黑箱性质，我们提出了一种在联合模态上训练多模态扩散模型的框架，将具有黑箱正向模型的逆问题转化为简单的线性修复问题。从数值上讲，我们证明了在材料图像数据上训练扩散模型的可行性，并表明我们的方法通过利用可用的辅助信息实现了卓越的图像重建，而从昂贵的显微镜模态中需要的数据量要少得多。 et.al.|[2410.05143](http://arxiv.org/abs/2410.05143)|null|

<p align=right>(<a href=#updated-on-20241008>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-07**|**Fast Training of Sinusoidal Neural Fields via Scaling Initialization**|神经场是一种新兴的范式，它将数据表示为由神经网络参数化的连续函数。尽管有许多优点，但神经场通常具有较高的训练成本，这阻碍了更广泛的采用。在本文中，我们关注一个流行的神经场家族，称为正弦神经场（SNF），并研究如何初始化它以最大限度地提高训练速度。我们发现，基于信号传播原理设计的SNF标准初始化方案是次优的。特别是，我们证明，通过简单地将每个权重（最后一层除外）乘以一个常数，我们可以将SNF训练加速10 $\times$。这种方法被称为$\textit{weight scaling}$ ，在各种数据域上持续提供显著的加速，使SNF的训练速度比最近提出的架构更快。为了理解为什么权重缩放效果良好，我们进行了广泛的理论和实证分析，结果表明，权重缩放不仅有效地解决了频谱偏差，而且具有良好的优化轨迹。 et.al.|[2410.04779](http://arxiv.org/abs/2410.04779)|null|
|**2024-10-04**|**End-to-End Reaction Field Energy Modeling via Deep Learning based Voxel-to-voxel Transform**|在计算生物化学和生物物理学中，理解静电相互作用的作用对于阐明生物分子的结构、动力学和功能至关重要。泊松-玻尔兹曼（PB）方程是通过描述带电分子内部和周围的静电势来模拟这些相互作用的基础工具。然而，由于生物分子表面的复杂性和需要考虑可移动离子，求解PB方程带来了重大的计算挑战。虽然求解PB方程的传统数值方法是准确的，但它们的计算成本很高，并且随着系统规模的增加而扩展性较差。为了应对这些挑战，我们引入了PBNeF，这是一种新的机器学习方法，灵感来自基于神经网络的偏微分方程求解器的最新进展。我们的方法将PB方程的输入和边界静电条件转化为可学习的体素表示，使神经场变换器能够预测PB解，进而预测反应场势能。大量实验表明，与传统的PB求解器相比，PBNeF的速度提高了100倍以上，同时保持了与广义玻恩（GB）模型相当的精度。 et.al.|[2410.03927](http://arxiv.org/abs/2410.03927)|null|
|**2024-09-30**|**DressRecon: Freeform 4D Human Reconstruction from Monocular Video**|我们提出了一种从单目视频中重建时间一致的人体模型的方法，重点是极其宽松的衣服或手持物体的交互。之前在人体重建方面的工作要么局限于没有物体交互的紧身衣服，要么需要校准的多视图捕捉或个性化的模板扫描，而大规模收集这些数据成本很高。我们对高质量但灵活的重建的关键见解是，将关于关节体形状的通用人类先验（从大规模训练数据中学习）与视频特定的关节“骨骼袋”变形（通过测试时间优化适合单个视频）仔细结合。我们通过学习一个神经隐式模型来实现这一点，该模型将身体和衣服的变形作为单独的运动模型层来解开。为了捕捉服装的微妙几何形状，我们在优化过程中利用了基于图像的先验，如人体姿势、表面法线和光流。由此产生的神经场可以提取到时间一致的网格中，或进一步优化为显式3D高斯分布，以实现高保真交互式渲染。在具有高度挑战性的服装变形和物体交互的数据集上，DressReston可以产生比现有技术更高保真的3D重建。项目页面：https://jefftan969.github.io/dressrecon/ et.al.|[2409.20563](http://arxiv.org/abs/2409.20563)|null|
|**2024-09-25**|**TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans**|我们介绍了一种新的框架，该框架从单眼视频中学习全身说话的人的动态神经辐射场（NeRF）。之前的工作只代表身体姿势或面部。然而，人类通过全身进行交流，结合身体姿势、手势和面部表情。在这项工作中，我们提出了TalkinNeRF，这是一个基于NeRF的统一网络，代表了整体4D人体运动。给定一个受试者的单眼视频，我们学习身体、面部和手的相应模块，这些模块结合在一起生成最终结果。为了捕捉复杂的手指关节，我们学习了手的额外变形场。我们的多身份表示能够同时训练多个科目，以及在完全看不见的姿势下进行强大的动画。只要输入一段短视频，它也可以推广到新的身份。我们展示了最先进的性能，用于为全身说话的人类制作动画，具有精细的手部发音和面部表情。 et.al.|[2409.16666](http://arxiv.org/abs/2409.16666)|null|
|**2024-09-24**|**Generative 3D Cardiac Shape Modelling for In-Silico Trials**|我们提出了一种深度学习方法，基于将形状表示为神经有符号距离场的零级集，对合成主动脉形状进行建模和生成，该方法受一系列可训练的嵌入向量的约束，并对每个形状的几何特征进行编码。通过使神经场在采样表面点上消失并强制其空间梯度具有单位范数，在从CT图像重建的主动脉根部网格数据集上训练网络。实证结果表明，我们的模型可以高保真地表示主动脉形状。此外，通过从学习到的嵌入向量中采样，我们可以生成类似于真实患者解剖结构的新形状，可用于计算机模拟试验。 et.al.|[2409.16058](http://arxiv.org/abs/2409.16058)|null|
|**2024-09-21**|**MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors**|由于缺乏几何指导和不完美的视图相关2D先验，从单眼图像中精确重建密集和语义注释的3D网格仍然是一项具有挑战性的任务。尽管我们已经见证了隐式神经场景表示的最新进展，能够简单地从多视图图像中进行精确的2D渲染，但很少有研究仅使用单眼先验来解决3D场景理解问题。在本文中，我们提出了MOSE，这是一种神经场语义重建方法，可以将推断的图像级噪声先验提升到3D，在3D和2D空间中产生精确的语义和几何。我们方法的关键动机是利用通用类不可知的分段掩码作为指导，在训练过程中促进渲染语义的局部一致性。在语义的帮助下，我们进一步将平滑正则化应用于无纹理区域，以获得更好的几何质量，从而实现几何和语义的互惠互利。在ScanNet数据集上的实验表明，我们的MOSE在3D语义分割、2D语义分割和3D表面重建任务的所有指标上都优于相关基线。 et.al.|[2409.14019](http://arxiv.org/abs/2409.14019)|null|
|**2024-09-17**|**SplatFields: Neural Gaussian Splats for Sparse 3D and 4D Reconstruction**|从多视图图像中数字化3D静态场景和4D动态事件长期以来一直是计算机视觉和图形学领域的一个挑战。最近，3D高斯散斑（3DGS）已经成为一种实用且可扩展的重建方法，由于其令人印象深刻的重建质量、实时渲染能力以及与广泛使用的可视化工具的兼容性而越来越受欢迎。然而，该方法需要大量的输入视图来实现高质量的场景重建，这引入了一个重大的实际瓶颈。在捕捉动态场景时，这一挑战尤为严峻，因为部署广泛的相机阵列的成本可能高得令人望而却步。在这项工作中，我们发现斑点特征缺乏空间自相关性是导致3DGS技术在稀疏重建环境中性能不佳的因素之一。为了解决这个问题，我们提出了一种优化策略，通过将splat特征建模为相应隐式神经场的输出，有效地正则化splat特征。这导致在各种场景中重建质量的一致提高。我们的方法有效地处理了静态和动态情况，这在不同设置和场景复杂性的广泛测试中得到了证明。 et.al.|[2409.11211](http://arxiv.org/abs/2409.11211)|null|
|**2024-10-02**|**Neural Fields for Adaptive Photoacoustic Computed Tomography**|光声计算机断层扫描（PACT）是一种具有广泛医学应用的非侵入性成像技术。传统的PACT图像重建算法受到组织中声速不均匀（SOS）引起的波前失真的影响，导致图像质量下降。考虑到这些影响可以提高图像质量，但测量SOS分布的实验成本很高。另一种方法是仅使用PA信号对初始压力图像和SOS进行联合重建。现有的关节重建方法存在局限性：计算成本高，无法直接恢复SOS，以及依赖于不准确的简化假设。隐式神经表示或神经场是计算机视觉中的一种新兴技术，用于通过基于坐标的神经网络学习物理场的有效和连续表示。在这项工作中，我们介绍了NF-APACT，这是一种高效的自监督框架，利用神经场来估计SOS，以实现准确和鲁棒的多通道解卷积。我们的方法比现有方法更快、更准确地消除了SOS像差。我们在一个新的数值体模以及实验收集的体模和体内数据上证明了我们的方法的成功。我们的代码和数字幻影可在https://github.com/Lukeli0425/NF-APACT. et.al.|[2409.10876](http://arxiv.org/abs/2409.10876)|null|
|**2024-09-09**|**Lagrangian Hashing for Compressed Neural Field Representations**|我们提出了拉格朗日散列，这是一种神经场的表示，结合了依赖于欧拉网格（即~InstantNGP）的快速训练NeRF方法的特征，以及使用配备有特征的点作为表示信息的方法（例如3D高斯散点或PointNeRF）。我们通过将基于点的表示合并到InstantNGP表示的分层哈希表的高分辨率层中来实现这一点。由于我们的点具有影响域，我们的表示可以被解释为哈希表中存储的高斯混合。我们提出的损失鼓励我们的高斯人向需要更多代表预算才能充分代表的地区移动。我们的主要发现是，我们的表示允许使用更紧凑的表示来重建信号，而不会影响质量。 et.al.|[2409.05334](http://arxiv.org/abs/2409.05334)|null|
|**2024-09-08**|**Exploring spectropolarimetric inversions using neural fields. Solar chromospheric magnetic field under the weak-field approximation**|全斯托克斯偏振数据集来源于狭缝光谱仪或窄带滤光片图，如今已被常规采集。随着二维光谱偏振仪和允许长时间高质量观测序列的观测技术的出现，数据速率正在增加。在光谱偏振反演中，显然需要通过利用推断物理量的时空相干性来超越传统的逐像素策略。我们探索了神经网络作为时间和空间（也称为神经场）上物理量的连续表示的潜力，用于光谱极化反演。我们已经实现并测试了一个神经场，以在弱场近似（WFA）下执行磁场矢量的推理（也称为物理知情神经网络的方法）。通过使用神经场来描述磁场矢量，我们可以通过假设物理量是坐标的连续函数来在空间和时间域中正则化解。我们研究了Ca II 8542 A谱线的合成和真实观测结果。我们还探讨了其他显式正则化的影响，例如使用外推磁场的信息或色球原纤维的取向。与传统的逐像素反演相比，神经场方法提高了磁场矢量重建的保真度，特别是横向分量。这种隐式正则化是一种提高观测值有效信噪比的方法。虽然它比逐像素WFA估计慢，但这种方法通过减少自由参数的数量并在解决方案中引入时空约束，显示出深度分层反演的巨大潜力。 et.al.|[2409.05156](http://arxiv.org/abs/2409.05156)|**[link](https://github.com/cdiazbas/neural_wfa)**|

<p align=right>(<a href=#updated-on-20241008>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

