[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.05.14
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#video-diffusion>Video Diffusion</a></li>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## Video Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-05-13**|**Symbolically-Guided Visual Plan Inference from Uncurated Video Data**|视觉规划通过为目标条件的低级策略提供一系列中间视觉子目标，在长期操纵任务上取得了良好的性能。为了获得子目标，现有的方法通常求助于视频生成模型，但存在模型幻觉和计算成本的问题。我们提出了Vis2Plan，这是一个高效、可解释和白盒的视觉规划框架，由符号指导提供支持。从原始的、未标记的游戏数据中，Vis2Plan利用视觉基础模型自动提取一组紧凑的任务符号，这允许为多目标、多阶段规划构建高级符号转换图。在测试时，给定一个期望的任务目标，我们的规划者在符号层面进行规划，并根据底层符号表示组装一系列物理上一致的中间子目标图像。我们的Vis2Plan在真实机器人环境中的总成功率提高了53%，同时生成视觉计划的速度提高了35倍，优于基于强扩散视频生成的视觉计划。结果表明，Vis2Plan能够生成物理上一致的图像目标，同时提供完全可检查的推理步骤。 et.al.|[2505.08444](http://arxiv.org/abs/2505.08444)|null|
|**2025-05-13**|**ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image**|我们将自适应视图规划引入多视图合成，旨在提高单视图3D重建的遮挡显示和3D一致性。我们不是独立或同时生成一组无序的视图，而是生成一系列视图，利用时间一致性来增强3D一致性。最重要的是，我们的视图序列不是由预先确定的相机设置决定的。相反，我们计算自适应相机轨迹（ACT），具体来说，是相机视图的轨迹，它最大限度地提高了要重建的3D对象的遮挡区域的可见性。一旦找到最佳轨道，我们将其输入视频扩散模型，以生成轨道周围的新视图，然后将其传递给多视图3D重建模型，以获得最终重建。我们的多视图合成管道非常高效，因为它不涉及运行时训练/优化，只涉及通过应用预训练的模型进行遮挡分析和多视图合成的前向推理。我们的方法预测了相机轨迹，有效地揭示了遮挡并产生了一致的新视图，在看不见的GSO数据集上显著改善了SOTA的3D重建，无论是定量还是定性。 et.al.|[2505.08239](http://arxiv.org/abs/2505.08239)|null|
|**2025-05-12**|**DanceGRPO: Unleashing GRPO on Visual Generation**|生成模型的最新突破，特别是扩散模型和校正流，彻底改变了视觉内容的创作，但将模型输出与人类偏好相匹配仍然是一个关键挑战。现有的基于强化学习（RL）的视觉生成方法面临着关键的局限性：与现代基于常微分方程（ODE）的采样范式不兼容，大规模训练中的不稳定性，以及缺乏对视频生成的验证。本文介绍了DanceGRPO，这是第一个将组相对策略优化（GRPO）应用于视觉生成范式的统一框架，它在两个生成范式（扩散模型和校正流）、三个任务（文本到图像、文本到视频、图像到视频）、四个基础模型（稳定扩散、浑源视频、FLUX、SkyReel-I2V）和五个奖励模型（图像/视频美学、文本图像对齐、视频运动质量和二进制奖励）中释放了一个统一的RL算法。据我们所知，DanceGRPO是第一个基于强化学习的统一框架，能够无缝适应不同的生成范式、任务、基础模型和奖励模型。DanceGRPO表现出持续和实质性的改进，在HPS-v2.1、CLIP Score、VideoAlign和GenEval等基准上比基线高出181%。值得注意的是，DanceGRPO不仅可以稳定复杂视频生成的策略优化，还可以使生成策略更好地捕获Best-of-N推理缩放的去噪轨迹，并从稀疏二进制反馈中学习。我们的研究结果表明，DanceGRPO是一种强大而通用的解决方案，用于在视觉生成中扩展基于人类反馈的强化学习（RLHF）任务，为协调强化学习和视觉合成提供了新的见解。代码将被发布。 et.al.|[2505.07818](http://arxiv.org/abs/2505.07818)|null|
|**2025-05-12**|**ShotAdapter: Text-to-Multi-Shot Video Generation with Diffusion Models**|目前基于扩散的文本到视频方法仅限于制作单镜头的短视频片段，并且缺乏生成具有离散过渡的多镜头视频的能力，在这些过渡中，同一角色在相同或不同的背景下执行不同的活动。为了解决这一局限性，我们提出了一个框架，其中包括数据集收集管道和视频扩散模型的架构扩展，以实现文本到多镜头视频的生成。我们的方法能够将多镜头视频生成为单个视频，在所有镜头的所有帧上都能全神贯注，确保角色和背景的一致性，并允许用户通过镜头特定的调节来控制镜头的数量、持续时间和内容。这是通过将转换标记合并到文本到视频模型中来实现的，以控制新镜头开始的帧，以及控制转换标记效果并允许镜头特定提示的局部注意力掩蔽策略。为了获得训练数据，我们提出了一种新的数据收集管道，从现有的单镜头视频数据集中构建多镜头视频数据集。大量实验表明，对预训练的文本到视频模型进行数千次迭代的微调就足以使该模型随后能够生成具有镜头特定控制的多镜头视频，优于基线。您可以在中找到更多详细信息https://shotadapter.github.io/ et.al.|[2505.07652](http://arxiv.org/abs/2505.07652)|null|
|**2025-05-13**|**Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model**|在眼科手术中，开发一个能够解释手术视频并预测后续手术的人工智能系统需要大量具有高质量注释的眼科手术视频，由于隐私问题和劳动力消耗，这些视频很难收集。文本引导视频生成（T2V）是一种有前景的解决方案，通过基于外科医生的指令生成眼科手术视频来克服这一问题。在这篇论文中，我们介绍了Ophora，这是一种可以按照自然语言指令生成眼科手术视频的开创性模型。为了构建Ophora，我们首先提出了一个综合数据治疗管道，将叙述性眼科手术视频转换为大规模、高质量的数据集，其中包括160K多个视频指令对Ophora-160K。然后，我们提出了一种渐进式视频指令调整方案，从在自然视频文本数据集上预训练的T2V模型中转移丰富的时空知识，用于基于Ophora-160K的隐私保护眼科手术视频生成。通过定量分析和眼科医生反馈进行视频质量评估的实验表明，Ophora可以根据外科医生的指示生成逼真可靠的眼科手术视频。我们还验证了Ophora在理解眼科手术工作流程的下游任务方面的能力。代码可在以下网址获得https://github.com/mar-cry/Ophora. et.al.|[2505.07449](http://arxiv.org/abs/2505.07449)|**[link](https://github.com/mar-cry/ophora)**|
|**2025-05-12**|**Generative Pre-trained Autoregressive Diffusion Transformer**|在这项工作中，我们提出了GPDiT，这是一种生成式预训练自回归扩散变换器，它在连续的潜在空间内统一了扩散和自回归建模的优点，用于长距离视频合成。GPDiT不是预测离散令牌，而是使用扩散损失自回归预测未来的潜在帧，从而能够对帧之间的运动动力学和语义一致性进行自然建模。这种连续自回归框架不仅提高了发电质量，还赋予了模型表示能力。此外，我们引入了一种轻量级的因果注意变体和一种基于无参数旋转的时间调节机制，提高了训练和推理效率。大量实验表明，GPDiT在视频生成质量、视频表示能力和少量镜头学习任务方面表现出色，突显了其作为连续空间视频建模有效框架的潜力。 et.al.|[2505.07344](http://arxiv.org/abs/2505.07344)|null|
|**2025-05-11**|**DAPE: Dual-Stage Parameter-Efficient Fine-Tuning for Consistent Video Editing with Diffusion Models**|基于扩散模型的视频生成是一项具有挑战性的多模式任务，视频编辑成为该领域的一个关键方向。最近的视频编辑方法主要分为两类：需要培训和不需要培训的方法。虽然基于训练的方法会产生很高的计算成本，但无训练的替代方案往往会产生次优性能。为了解决这些局限性，我们提出了DAPE，这是一种用于视频编辑的高质量但经济高效的两阶段参数高效微调（PEFT）框架。在第一阶段，我们设计了一种有效的范数调整方法来增强生成视频的时间一致性。第二阶段引入视觉友好型适配器以提高视觉质量。此外，我们还发现了现有基准测试中的关键缺陷，包括类别多样性有限、对象分布不平衡和帧数不一致。为了缓解这些问题，我们策划了一个大型数据集基准测试，包括232个具有丰富注释和6个编辑提示的视频，可以对高级方法进行客观和全面的评估。对现有数据集（BalanceCC、LOVEU-TGVE、RAVE）和我们提出的基准进行的广泛实验表明，DAPE显著提高了时间连贯性和文本视频对齐，同时优于以前最先进的方法。 et.al.|[2505.07057](http://arxiv.org/abs/2505.07057)|null|
|**2025-05-11**|**BridgeIV: Bridging Customized Image and Video Generation through Test-Time Autoregressive Identity Propagation**|零样本和基于调整的定制文本到图像（CT2I）生成在讲故事内容创作方面都取得了重大进展。相比之下，对定制文本到视频（CT2V）生成的研究仍然相对有限。现有的零样本CT2V方法具有较差的泛化能力，而另一种直接将基于调谐的T2I模型与时间运动模块相结合的工作通常会导致结构和纹理信息的丢失。为了弥合这一差距，我们提出了一种自回归结构和纹理传播模块（STPM），该模块从参考对象中提取关键的结构和纹理特征，并将其自回归地注入到每个视频帧中以提高一致性。此外，我们引入了一种测试时间奖励优化（TTRO）方法，以进一步细化细粒度细节。定量和定性实验验证了STPM和TTRO的有效性，表明CLIP-I和DINO一致性指标分别比基线提高了7.8和13.1。 et.al.|[2505.06985](http://arxiv.org/abs/2505.06985)|null|
|**2025-05-10**|**Jailbreaking the Text-to-Video Generative Models**|在扩散模型的快速发展推动下，文本到视频生成模型取得了重大进展，其中著名的例子包括Pika、Luma、Kling和Sora。尽管它们具有非凡的生成能力，但它们容易受到越狱攻击，即生成不安全的内容，包括色情、暴力和歧视，这引发了严重的安全问题。现有的努力，如T2VSafetyBench，为评估文本到视频模型在不安全提示下的安全性提供了宝贵的基准，但缺乏有效利用其漏洞的系统研究。在本文中，我们提出了针对文本到视频模型的\textit{first}优化越狱攻击，这是专门设计的。我们的方法将提示生成任务表述为一个优化问题，有三个关键目标：（1）最大化输入和生成的提示之间的语义相似性，（2）确保生成的提示可以避开文本到视频模型的安全过滤器，以及（3）最大化生成的视频和原始输入提示之间的语法相似性。为了进一步增强生成提示的鲁棒性，我们引入了一种提示变异策略，在每次迭代中创建多个提示变体，根据平均得分选择最有效的一个。该策略不仅提高了攻击成功率，还提高了生成视频的语义相关性。我们在多个文本到视频模型上进行了广泛的实验，包括Open Sora、Pika、Luma和Kling。结果表明，与基线方法相比，我们的方法不仅实现了更高的攻击成功率，而且生成了与原始输入提示具有更大语义相似性的视频。 et.al.|[2505.06679](http://arxiv.org/abs/2505.06679)|null|
|**2025-05-10**|**Video Dataset Condensation with Diffusion Models**|近年来，数据集大小的快速扩展和深度学习模型复杂性的增加大大增加了对数据存储和模型训练的计算资源的需求。数据集蒸馏已成为一种有前景的解决方案，通过生成一个紧凑的合成数据集来解决这一挑战，该数据集保留了大型真实数据集中的基本信息。然而，现有的方法往往性能有限，数据质量差，特别是在视频领域。在本文中，我们通过采用视频扩散模型来生成高质量的合成视频，重点研究视频数据集的提取。为了提高代表性，我们引入了视频时空U-Net（VST-UNet），这是一种旨在选择多样化和信息丰富的视频子集的模型，可以有效地捕捉原始数据集的特征。为了进一步优化计算效率，我们探索了一种无需训练的聚类算法，即基于时间感知聚类的蒸馏（TAC-DT），以选择具有代表性的视频，而不需要额外的训练开销。我们通过在四个基准数据集上进行广泛的实验来验证我们方法的有效性，与最先进的技术相比，性能提高了高达10.61%。我们的方法在所有数据集上都始终优于现有方法，为视频数据集蒸馏建立了一个新的基准。 et.al.|[2505.06670](http://arxiv.org/abs/2505.06670)|null|

<p align=right>(<a href=#updated-on-20250514>back to top</a>)</p>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-05-13**|**FOCI: Trajectory Optimization on Gaussian Splats**|3D高斯散斑（3DGS）最近作为3D重建和视图合成方法中神经辐射场（NeRF）的更快替代方案而受到欢迎。利用3DGS中编码的空间信息，这项工作提出了FOCI（场重叠碰撞积分），这是一种能够直接在高斯本身上优化轨迹的算法。FOCI利用高斯重叠积分的概念，为3DGS利用了一种新颖且可解释的碰撞公式。与其他方法相反，这些方法用保守的边界框表示机器人，低估了环境的可穿越性，我们建议将环境和机器人表示为高斯散点。这不仅具有理想的计算特性，而且允许进行方向感知规划，使机器人能够穿过非常狭窄的空间。我们在合成和真实高斯Splats中广泛测试了我们的算法，展示了ANYmal腿式机器人的无碰撞轨迹，即使有数十万高斯人组成环境，也可以在几秒钟内计算出来。项目页面和代码可在https://rffr.leggedrobotics.com/works/foci/ et.al.|[2505.08510](http://arxiv.org/abs/2505.08510)|null|
|**2025-05-13**|**ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image**|我们将自适应视图规划引入多视图合成，旨在提高单视图3D重建的遮挡显示和3D一致性。我们不是独立或同时生成一组无序的视图，而是生成一系列视图，利用时间一致性来增强3D一致性。最重要的是，我们的视图序列不是由预先确定的相机设置决定的。相反，我们计算自适应相机轨迹（ACT），具体来说，是相机视图的轨迹，它最大限度地提高了要重建的3D对象的遮挡区域的可见性。一旦找到最佳轨道，我们将其输入视频扩散模型，以生成轨道周围的新视图，然后将其传递给多视图3D重建模型，以获得最终重建。我们的多视图合成管道非常高效，因为它不涉及运行时训练/优化，只涉及通过应用预训练的模型进行遮挡分析和多视图合成的前向推理。我们的方法预测了相机轨迹，有效地揭示了遮挡并产生了一致的新视图，在看不见的GSO数据集上显著改善了SOTA的3D重建，无论是定量还是定性。 et.al.|[2505.08239](http://arxiv.org/abs/2505.08239)|null|
|**2025-05-13**|**TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin Benchmark Dataset**|城市数字双胞胎（UDTs）已成为管理城市和整合来自不同来源的复杂异构数据的关键。创建UDT涉及多个过程阶段的挑战，包括获取准确的3D源数据、重建高保真3D模型、维护模型的更新，以及确保与下游任务的无缝互操作性。当前的数据集通常仅限于处理链的一部分，阻碍了全面的UDT验证。为了应对这些挑战，我们推出了第一个全面的多模式城市数字孪生基准数据集：TUM2TWIN。该数据集包括地理参考、语义对齐的3D模型和网络，以及各种地面、移动、空中和卫星观测，拥有32个数据子集，数据量约为100000美元，目前为767 GB。通过确保地理参考的室内外采集、高精度和多模态数据集成，该基准支持传感器的稳健分析和先进重建方法的开发。此外，我们还探索了展示TUM2TWIN潜力的下游任务，包括NeRF和高斯散斑的新颖视图合成、太阳势分析、点云语义分割和LoD3建筑重建。我们相信，这一贡献为克服UDT创建中的当前局限性奠定了基础，为更智能、数据驱动的城市环境培养了新的研究方向和实用的解决方案。该项目可在以下网址获得：https://tum2t.win et.al.|[2505.07396](http://arxiv.org/abs/2505.07396)|null|
|**2025-05-12**|**Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild**|使用体绘制技术的神经隐式表面重建最近在从多个2D图像创建高保真表面方面取得了重大进展。然而，目前的方法主要针对具有一致照明的场景，并且难以在具有瞬态遮挡或不同外观的不受控制的环境中准确重建3D几何体。虽然一些基于神经辐射场（NeRF）的变体可以更好地管理复杂场景中的光度变化和瞬态对象，但由于有限的表面约束，它们被设计用于新颖的视图合成，而不是精确的表面重建。为了克服这一局限性，我们引入了一种新方法，该方法将多个几何约束应用于隐式曲面优化过程，从而能够从无约束图像集合中进行更精确的重建。首先，我们利用运动结构中的稀疏3D点（SfM）来细化重建表面的带符号距离函数估计，并通过位移补偿来适应稀疏点中的噪声。此外，我们采用从法线预测器导出的鲁棒法线先验，并通过边缘先验滤波和多视图一致性约束进行增强，以改善与实际表面几何形状的对齐。对Heritage Recon基准和其他数据集的广泛测试表明，所提出的方法可以从野外图像中准确重建表面，与现有技术相比，可以产生具有更高精度和粒度的几何形状。我们的方法能够对各种地标进行高质量的3D重建，使其适用于各种场景，如文化遗产的数字保护。 et.al.|[2505.07373](http://arxiv.org/abs/2505.07373)|null|
|**2025-05-11**|**NeuGen: Amplifying the 'Neural' in Neural Radiance Fields for Domain Generalization**|神经辐射场（NeRF）显著推进了新视图合成领域，但它们在不同场景和条件下的泛化仍然具有挑战性。为了解决这个问题，我们建议将一种新的大脑启发的归一化技术神经泛化（NeuGen）集成到领先的NeRF架构中，包括MVSNeRF和GeoNeRF。NeuGen提取域不变特征，从而增强模型的泛化能力。它可以无缝集成到NeRF架构中，并培养出一套全面的功能集，显著提高了图像渲染的准确性和鲁棒性。通过这种集成，NeuGen在最先进的NeRF架构的不同数据集上的基准测试中表现出了更高的性能，使其能够在不同的场景中更好地推广。我们的定量和定性综合评估证实，我们的方法不仅在泛化能力上超越了现有模型，而且显著提高了渲染质量。我们的工作展示了将神经科学原理与深度学习框架相结合的潜力，为提高新视图合成的泛化能力和效率树立了新的先例。我们的研究演示可在https://neugennerf.github.io. et.al.|[2505.06894](http://arxiv.org/abs/2505.06894)|null|
|**2025-05-10**|**Gaussian Wave Splatting for Computer-Generated Holography**|最先进的神经渲染方法从几张照片中优化高斯场景表示，以实现新颖的视图合成。基于这些表示，我们开发了一种高效的算法，称为高斯波散布，将这些高斯波转化为全息图。与现有的计算机生成全息术（CGH）算法不同，高斯波散布通过利用神经渲染的最新进展，为照片级真实感场景支持精确的遮挡和视图相关效果。具体来说，我们为支持遮挡和阿尔法混合的2D高斯到全息图变换推导了一个封闭形式的解决方案。受经典计算机图形学技术的启发，我们还推导出了傅里叶域中上述过程的有效近似值，该近似值易于并行化，并使用自定义CUDA内核实现。通过将新兴的神经渲染管道与全息显示技术相结合，我们基于高斯的CGH框架为下一代全息显示器铺平了道路。 et.al.|[2505.06582](http://arxiv.org/abs/2505.06582)|null|
|**2025-05-09**|**RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects**|现代3D重建和新颖的视图合成方法在具有不透明朗伯对象的场景中表现出了很强的性能。然而，大多数假设光路是直的，因此无法正确处理折射和反射材料。此外，专门针对这些效应的数据集有限，阻碍了评估性能和开发合适技术的努力。在这项工作中，我们引入了一个合成的RefRef数据集和基准，用于从姿态图像中重建具有折射和反射物体的场景。我们的数据集有50个不同复杂度的对象，从单材质凸形到多材质非凸形，每个对象都放置在三种不同的背景类型中，从而产生150个场景。我们还提出了一种预言方法，在给定物体几何形状和折射率的情况下，计算神经渲染的精确光路，并在此基础上提出了一个避免这些假设的方法。我们将这些方法与几种最先进的方法进行了比较，并表明所有方法都明显落后于oracle，突显了任务和数据集的挑战。 et.al.|[2505.05848](http://arxiv.org/abs/2505.05848)|null|
|**2025-05-08**|**UltraGauss: Ultrafast Gaussian Reconstruction of 3D Ultrasound Volumes**|超声成像因其安全性、可负担性和实时性而被广泛使用，但其二维解释高度依赖于操作员，导致可变性和认知需求增加。2D到3D重建通过提供标准化的体积视图来缓解这些挑战，但现有的方法通常计算成本高、内存密集或与超声物理不兼容。我们介绍了UltraGauss：第一个超声专用高斯散斑框架，将视图合成技术扩展到超声波传播。与传统的基于透视的溅射不同，UltraGauss在3D中模拟探头平面交点，与声像形成对齐。我们推导了一种用于GPU并行化的高效光栅化边界公式，并引入了数值稳定的协方差参数化，提高了计算效率和重建精度。在真实的临床超声数据上，UltraGauss在5分钟内实现了最先进的重建，并在单个GPU上在20分钟内达到0.99 SSIM。一项对专家临床医生的调查证实，UltraGauss的重建是竞争方法中最现实的。我们的CUDA实施将在发布后发布。 et.al.|[2505.05643](http://arxiv.org/abs/2505.05643)|null|
|**2025-05-08**|**Steepest Descent Density Control for Compact 3D Gaussian Splatting**|3D高斯散斑（3DGS）已成为实时、高分辨率新颖视图合成的强大技术。通过将场景表示为高斯基元的混合，3DGS利用GPU光栅化管道进行高效的渲染和重建。为了优化场景覆盖并捕捉精细细节，3DGS采用致密化算法来生成额外的点。然而，这一过程通常会导致冗余的点云，从而导致内存使用过度、性能下降和大量存储需求，给资源受限的设备上的部署带来了重大挑战。为了解决这一局限性，我们提出了一个理论框架，该框架揭开了3DGS中密度控制的神秘面纱并加以改进。我们的分析表明，分裂对于逃离鞍点至关重要。通过优化理论方法，我们建立了致密化的必要条件，确定了子高斯数的最小值，确定了最佳参数更新方向，并为归一化弹簧不透明度提供了解析解。基于这些见解，我们引入了SteepGS，它结合了最陡密度控制，这是一种原则性的策略，可以在保持紧凑点云的同时最大限度地减少损失。SteepGS在不影响渲染质量的情况下实现了高斯点减少约50%，显著提高了效率和可扩展性。 et.al.|[2505.05587](http://arxiv.org/abs/2505.05587)|null|
|**2025-05-07**|**SGCR: Spherical Gaussians for Efficient 3D Curve Reconstruction**|神经渲染技术在生成逼真的3D场景方面取得了重大进展。最新的3D高斯散点技术实现了高质量的新颖视图合成以及快速的渲染速度。然而，尽管3D高斯算子具有明确的原始表示，但它们在定义精确的3D几何结构方面缺乏熟练程度。这是因为高斯的属性主要是通过其各向异性来定制和微调的，以渲染各种2D图像。为了为高效的3D重建铺平道路，我们提出了球面高斯，这是一种简单有效的3D几何边界表示方法，我们可以从一组校准的多视图图像中直接重建3D特征曲线。球面高斯从网格初始化开始进行优化，具有基于视图的渲染损失，其中在特定视图处渲染2D边缘图，然后将其与从相应图像中提取的地面真实边缘图进行比较，而不需要任何3D指导或监督。考虑到球面高斯作为鲁棒边缘表示的媒介，我们进一步引入了一种新的基于优化的算法SGCR，可以直接从对齐的球面高斯中提取精确的参数曲线。我们证明，SGCR在3D边缘重建方面优于现有的最先进方法，同时具有很高的效率。 et.al.|[2505.04668](http://arxiv.org/abs/2505.04668)|**[link](https://github.com/martinyxr/sgcr)**|

<p align=right>(<a href=#updated-on-20250514>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-05-13**|**FOCI: Trajectory Optimization on Gaussian Splats**|3D高斯散斑（3DGS）最近作为3D重建和视图合成方法中神经辐射场（NeRF）的更快替代方案而受到欢迎。利用3DGS中编码的空间信息，这项工作提出了FOCI（场重叠碰撞积分），这是一种能够直接在高斯本身上优化轨迹的算法。FOCI利用高斯重叠积分的概念，为3DGS利用了一种新颖且可解释的碰撞公式。与其他方法相反，这些方法用保守的边界框表示机器人，低估了环境的可穿越性，我们建议将环境和机器人表示为高斯散点。这不仅具有理想的计算特性，而且允许进行方向感知规划，使机器人能够穿过非常狭窄的空间。我们在合成和真实高斯Splats中广泛测试了我们的算法，展示了ANYmal腿式机器人的无碰撞轨迹，即使有数十万高斯人组成环境，也可以在几秒钟内计算出来。项目页面和代码可在https://rffr.leggedrobotics.com/works/foci/ et.al.|[2505.08510](http://arxiv.org/abs/2505.08510)|null|
|**2025-05-13**|**A Survey of 3D Reconstruction with Event Cameras: From Event-based Geometry to Neural 3D Rendering**|事件相机已成为3D重建的有前景的传感器，因为它们能够异步捕获每像素的亮度变化。与传统的基于帧的相机不同，它们产生稀疏且时间丰富的数据流，这使得能够进行更精确的3D重建，并为在高速运动、低光照或高动态范围场景等极端环境中进行重建开辟了可能性。在这项调查中，我们提供了第一个专门针对使用事件相机进行3D重建的全面综述。该调查根据输入模态将现有作品分为三大类——立体、单眼和多模态系统，并通过重建方法进一步对其进行分类，包括基于几何、基于深度学习和最近的神经渲染技术，如神经辐射场和3D高斯散斑。具有相似研究重点的方法按时间顺序分为最细分的组。我们还总结了与基于事件的3D重建相关的公共数据集。最后，我们强调了当前在数据可用性、评估、表示和动态场景处理方面的研究局限性，并概述了未来有前景的研究方向。这项调查旨在为事件驱动的3D重建的未来发展提供全面的参考和路线图。 et.al.|[2505.08438](http://arxiv.org/abs/2505.08438)|null|
|**2025-05-13**|**ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image**|我们将自适应视图规划引入多视图合成，旨在提高单视图3D重建的遮挡显示和3D一致性。我们不是独立或同时生成一组无序的视图，而是生成一系列视图，利用时间一致性来增强3D一致性。最重要的是，我们的视图序列不是由预先确定的相机设置决定的。相反，我们计算自适应相机轨迹（ACT），具体来说，是相机视图的轨迹，它最大限度地提高了要重建的3D对象的遮挡区域的可见性。一旦找到最佳轨道，我们将其输入视频扩散模型，以生成轨道周围的新视图，然后将其传递给多视图3D重建模型，以获得最终重建。我们的多视图合成管道非常高效，因为它不涉及运行时训练/优化，只涉及通过应用预训练的模型进行遮挡分析和多视图合成的前向推理。我们的方法预测了相机轨迹，有效地揭示了遮挡并产生了一致的新视图，在看不见的GSO数据集上显著改善了SOTA的3D重建，无论是定量还是定性。 et.al.|[2505.08239](http://arxiv.org/abs/2505.08239)|null|
|**2025-05-12**|**RDD: Robust Feature Detector and Descriptor using Deformable Transformer**|作为从运动和SLAM构建结构的核心步骤，尽管存在普遍性，但在诸如显著视点变化等具有挑战性的场景下，鲁棒的特征检测和描述仍未得到解决。虽然最近的工作已经确定了局部特征在建模几何变换中的重要性，但这些方法未能学习到长距离关系中存在的视觉线索。我们提出了鲁棒可变形检测器（RDD），这是一种利用可变形变换器的新型鲁棒关键点检测器/描述符，它通过可变形的自关注机制捕获全局上下文和几何不变性。具体来说，我们观察到可变形注意力集中在关键位置，有效地降低了搜索空间的复杂性，并对几何不变性进行了建模。此外，除了标准的MegaDepth数据集外，我们还收集了一个空对地数据集进行训练。我们提出的方法在稀疏匹配任务中优于所有最先进的关键点检测/描述方法，并且还能够进行半密集匹配。为了确保全面评估，我们引入了两个具有挑战性的基准：一个强调大视角和尺度变化，另一个是空对地基准——这是一种最近在不同高度的3D重建中越来越受欢迎的评估设置。 et.al.|[2505.08013](http://arxiv.org/abs/2505.08013)|null|
|**2025-05-12**|**Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild**|使用体绘制技术的神经隐式表面重建最近在从多个2D图像创建高保真表面方面取得了重大进展。然而，目前的方法主要针对具有一致照明的场景，并且难以在具有瞬态遮挡或不同外观的不受控制的环境中准确重建3D几何体。虽然一些基于神经辐射场（NeRF）的变体可以更好地管理复杂场景中的光度变化和瞬态对象，但由于有限的表面约束，它们被设计用于新颖的视图合成，而不是精确的表面重建。为了克服这一局限性，我们引入了一种新方法，该方法将多个几何约束应用于隐式曲面优化过程，从而能够从无约束图像集合中进行更精确的重建。首先，我们利用运动结构中的稀疏3D点（SfM）来细化重建表面的带符号距离函数估计，并通过位移补偿来适应稀疏点中的噪声。此外，我们采用从法线预测器导出的鲁棒法线先验，并通过边缘先验滤波和多视图一致性约束进行增强，以改善与实际表面几何形状的对齐。对Heritage Recon基准和其他数据集的广泛测试表明，所提出的方法可以从野外图像中准确重建表面，与现有技术相比，可以产生具有更高精度和粒度的几何形状。我们的方法能够对各种地标进行高质量的3D重建，使其适用于各种场景，如文化遗产的数字保护。 et.al.|[2505.07373](http://arxiv.org/abs/2505.07373)|null|
|**2025-05-10**|**3D Characterization of Smoke Plume Dispersion Using Multi-View Drone Swarm**|本研究提出了一种先进的多视图无人机群成像系统，用于烟羽扩散动力学的三维表征。该系统由一架经理无人机和四架工人无人机组成，每架无人机都配备了高分辨率摄像头和精确的GPS模块。管理者无人机使用图像反馈自主检测并定位自己在羽流上方，然后命令工作人员无人机以同步的圆形飞行模式绕该区域飞行，捕获多角度图像。首先估计这些图像的相机姿态，然后将图像分批分组，并使用神经辐射场（NeRF）进行处理，以生成随时间变化的羽流动力学的高分辨率3D重建。现场测试证明，该系统能够以约1秒的时间分辨率捕获关键的羽流特征，包括体积动力学、风驱动的方向变化和放样行为。该系统生成的3D重建为增强烟流扩散和火灾蔓延的预测模型提供了独特的现场数据。从广义上讲，无人机群系统为野火、火山爆发、规定烧伤和工业过程中污染物排放和运输的高分辨率测量提供了一个多功能平台，最终支持更有效的消防决策并降低野火风险。 et.al.|[2505.06638](http://arxiv.org/abs/2505.06638)|null|
|**2025-05-09**|**VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction**|Next Best View（NBV）算法旨在使用最少的资源、时间或捕获次数来获取一组最佳图像，以实现场景的高效3D重建。现有的方法通常依赖于先前的场景知识或额外的图像捕获，并经常制定最大化覆盖范围的策略。然而，对于许多具有复杂几何形状和自遮挡的真实场景，覆盖最大化并不能直接带来更好的重建质量。本文提出了视图自检网络（VIN）和VIN-NBV策略，该网络经过训练可以直接预测视图的重建质量改进。一种基于贪婪顺序采样的策略，在每个采集步骤，我们对多个查询视图进行采样，并选择VIN预测改进得分最高的视图。我们设计VIN来执行基于先前采集的重建的3D感知特征化，并为每个查询视图创建一个可以解码为改进分数的特征。然后，我们使用模仿学习来训练VIN，以预测重建改进分数。我们发现，在采集次数或运动时间受到限制的情况下，VIN-NBV在覆盖最大化基线上将重建质量提高了约30%。 et.al.|[2505.06219](http://arxiv.org/abs/2505.06219)|null|
|**2025-05-09**|**RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects**|现代3D重建和新颖的视图合成方法在具有不透明朗伯对象的场景中表现出了很强的性能。然而，大多数假设光路是直的，因此无法正确处理折射和反射材料。此外，专门针对这些效应的数据集有限，阻碍了评估性能和开发合适技术的努力。在这项工作中，我们引入了一个合成的RefRef数据集和基准，用于从姿态图像中重建具有折射和反射物体的场景。我们的数据集有50个不同复杂度的对象，从单材质凸形到多材质非凸形，每个对象都放置在三种不同的背景类型中，从而产生150个场景。我们还提出了一种预言方法，在给定物体几何形状和折射率的情况下，计算神经渲染的精确光路，并在此基础上提出了一个避免这些假设的方法。我们将这些方法与几种最先进的方法进行了比较，并表明所有方法都明显落后于oracle，突显了任务和数据集的挑战。 et.al.|[2505.05848](http://arxiv.org/abs/2505.05848)|null|
|**2025-05-08**|**The Moon's Many Faces: A Single Unified Transformer for Multimodal Lunar Reconstruction**|多模态学习是跨多个学科的新兴研究课题，但很少应用于行星科学。在这篇文章中，我们发现反射率参数估计和基于图像的月球图像3D重建可以被表述为一个多模态学习问题。我们提出了一种单一的、统一的变换器架构，该架构经过训练，可以学习多个源之间的共享表示，如灰度图像、数字高程模型、表面法线和反照率图。该架构支持从任何输入模态到任何目标模态的灵活转换。从灰度图像预测DEM和反照率图同时解决了行星表面的3D重建任务，并解开了光度参数和高度信息。我们的结果表明，我们的基础模型在这四种模式中学习了物理上合理的关系。未来添加更多的输入模式将实现光度归一化和共配准等任务。 et.al.|[2505.05644](http://arxiv.org/abs/2505.05644)|null|
|**2025-05-08**|**UltraGauss: Ultrafast Gaussian Reconstruction of 3D Ultrasound Volumes**|超声成像因其安全性、可负担性和实时性而被广泛使用，但其二维解释高度依赖于操作员，导致可变性和认知需求增加。2D到3D重建通过提供标准化的体积视图来缓解这些挑战，但现有的方法通常计算成本高、内存密集或与超声物理不兼容。我们介绍了UltraGauss：第一个超声专用高斯散斑框架，将视图合成技术扩展到超声波传播。与传统的基于透视的溅射不同，UltraGauss在3D中模拟探头平面交点，与声像形成对齐。我们推导了一种用于GPU并行化的高效光栅化边界公式，并引入了数值稳定的协方差参数化，提高了计算效率和重建精度。在真实的临床超声数据上，UltraGauss在5分钟内实现了最先进的重建，并在单个GPU上在20分钟内达到0.99 SSIM。一项对专家临床医生的调查证实，UltraGauss的重建是竞争方法中最现实的。我们的CUDA实施将在发布后发布。 et.al.|[2505.05643](http://arxiv.org/abs/2505.05643)|null|

<p align=right>(<a href=#updated-on-20250514>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-05-13**|**NavDP: Learning Sim-to-Real Navigation Diffusion Policy with Privileged Information Guidance**|在动态开放世界环境中学习导航是机器人一项重要但具有挑战性的技能。以前的大多数方法都依赖于精确的定位和映射，或者从昂贵的现实世界演示中学习。在本文中，我们提出了导航扩散策略（NavDP），这是一种仅在模拟中训练的端到端框架，可以在不同的现实世界环境中零样本转移到不同的实施例。NavDP网络的关键组成部分是基于扩散的轨迹生成和轨迹选择的批评函数的组合，这两个函数仅以共享策略转换器编码的本地观测令牌为条件。考虑到模拟中全球环境的特权信息，我们扩大了高质量的演示来训练扩散策略，并使用对比负样本制定了临界值函数目标。我们的演示生成方法每天实现约2500个轨迹/GPU，比真实世界的数据收集效率高20美元/倍，并产生了一个跨越1244个场景的363.2公里轨迹的大规模导航数据集。经过此仿真数据集的训练，NavDP在各种室内和室外环境中的四足、轮式和人形机器人上实现了最先进的性能和始终如一的出色泛化能力。此外，我们还初步尝试使用高斯散斑进行域内实数到sim的微调，以进一步弥合sim到实数的差距。实验表明，在sim中添加这种实数数据可以在不损害其泛化能力的情况下将成功率提高30%。 et.al.|[2505.08712](http://arxiv.org/abs/2505.08712)|null|
|**2025-05-13**|**Controllable Image Colorization with Instance-aware Texts and Masks**|近年来，深度学习在图像着色中的应用受到了广泛关注。扩散模型的成熟进一步推动了图像着色模型的发展。然而，当前主流的图像着色模型仍然面临着诸如渗色和颜色绑定错误等问题，并且无法在实例级别对图像进行着色。本文提出了一种基于扩散的着色方法——MT-Color，以实现精确的实例感知着色，并提供了使用指导。为了解决颜色溢出问题，我们设计了一种像素级掩模注意机制，通过交叉注意将潜在特征和条件灰度图像特征集成在一起。我们使用分割掩码来构建交叉注意力掩码，防止像素信息在不同实例之间交换。我们还引入了一个实例掩码和文本引导模块，该模块提取每个实例的实例掩码和文字表示，然后通过自我注意将其与潜在特征融合，利用实例掩码形成自我注意掩码，以防止实例文本引导其他区域的着色，从而减轻颜色绑定错误。此外，我们应用了一种多实例采样策略，该策略涉及分别对每个实例区域进行采样，然后融合结果。此外，我们通过利用现有图像数据集上的大型视觉语言模型，为实例级着色任务GPT颜色创建了一个专门的数据集。定性和定量实验表明，我们的模型和数据集优于以前的方法和数据集。 et.al.|[2505.08705](http://arxiv.org/abs/2505.08705)|null|
|**2025-05-13**|**Global exponential stability of stationary profiles in a thin film equation with second-order diffusion**|我们研究了具有约束势和二阶简并扩散项的薄膜方程弱解的存在性和长期行为。众所周知，在没有二阶效应的情况下，一般初始数据的解在时间上以指数速率收敛到唯一的平稳分布。我们的主要结果是，如果附加力的强度足够小，这种全局指数平衡行为会以稍小的速度持续存在。我们的证明使用了方程的公式作为Wasserstein梯度流，以及辅助的低阶李雅普诺夫泛函。 et.al.|[2505.08641](http://arxiv.org/abs/2505.08641)|null|
|**2025-05-13**|**Augmented Reality for RObots (ARRO): Pointing Visuomotor Policies Towards Visual Robustness**|最近，在人类专家演示中训练的Visuomotor策略在各种机器人操纵任务中表现出了强大的性能。然而，这些策略对背景或机器人实施例变化引起的领域变化仍然高度敏感，这限制了它们的泛化能力。在本文中，我们提出了ARRO，这是一种新的无校准视觉表示，它利用零样本开放词汇分割和对象检测模型，在不需要额外训练的情况下有效地屏蔽场景中与任务相关的区域。通过在训练和推理过程中过滤视觉干扰并叠加虚拟引导，ARRO提高了对场景变化的鲁棒性，并减少了对额外数据收集的需求。我们广泛评估了ARRO与扩散策略在模拟和现实环境中的几个桌面操作任务，并进一步证明了其与通用机器人策略（如Octo和OpenVLA）的兼容性和有效性。在我们评估的所有设置中，ARRO都能产生一致的性能增益，允许在不同对象之间进行选择性掩蔽选择，并且即使在具有挑战性的分割条件下也表现出鲁棒性。展示我们研究结果的视频可在以下网址获得：augment-reality-for-robots.github.io et.al.|[2505.08627](http://arxiv.org/abs/2505.08627)|null|
|**2025-05-13**|**Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with Language Models**|DALL-E和Stable Diffusion等文本到图像生成模型彻底改变了各种应用程序的视觉内容创作，包括广告、个性化媒体和设计原型。然而，制定有效的文本提示来指导这些模型仍然具有挑战性，通常需要大量的试验和错误。现有的快速反演方法，如软提示和硬提示技术，由于可解释性有限和提示生成不连贯，效果不佳。为了解决这些问题，我们提出了视觉引导解码（VGD），这是一种无梯度的方法，利用大型语言模型（LLM）和基于CLIP的引导来生成连贯和语义对齐的提示。本质上，VGD利用LLM的强大文本生成功能来生成人类可读的提示。此外，通过使用CLIP分数来确保与用户指定的视觉概念保持一致，VGD增强了提示生成的可解释性、通用性和灵活性，而不需要额外的训练。我们的实验表明，VGD在生成可理解和上下文相关的提示方面优于现有的提示反转技术，有助于与文本到图像模型进行更直观和可控的交互。 et.al.|[2505.08622](http://arxiv.org/abs/2505.08622)|null|
|**2025-05-13**|**Boosting Zero-shot Stereo Matching using Large-scale Mixed Images Sources in the Real World**|立体匹配方法依赖于密集的像素级地面真实标签，这很难获得，特别是对于现实世界的数据集。标记数据的稀缺以及合成图像和现实世界图像之间的领域差距也带来了显著的挑战。在这篇论文中，我们提出了一个新的框架\textbf{BooSTer}，它利用了视觉基础模型和大规模混合图像源，包括合成、真实和单视图图像。首先，为了充分释放大规模单视图图像的潜力，我们设计了一种结合单目深度估计和扩散模型的数据生成策略，从单视图图像中生成密集的立体匹配数据。其次，为了解决现实世界数据集中的稀疏标签问题，我们使用伪单目深度标签和动态尺度和移位不变损失来转移单目深度估计模型的知识，以进行额外的监督。此外，我们将视觉基础模型作为编码器，以提取鲁棒和可转移的特征，提高准确性和泛化能力。对基准数据集的广泛实验证明了我们方法的有效性，与现有方法相比，我们的方法在准确性方面有了显著提高，特别是在标记数据有限和领域变化的情况下。 et.al.|[2505.08607](http://arxiv.org/abs/2505.08607)|null|
|**2025-05-13**|**Convergence and Wave Propagation for a System of Branching Rank-Based Interacting Brownian Particles**|在这项工作中，我们研究了实线上扩散过程的分支粒子系统，通过它们在系统中的秩相互作用。也就是说，每个粒子都遵循一个独立的布朗运动，但只允许最右侧的K $\ge$1粒子以恒定速率分支，而其余粒子则具有强度$\chi$>0的额外正漂移。这就是所谓的Go or Grow假说，它是一个基本假说，用于模拟毛细管中细胞沿化学梯度向上移动的过程。尽管粒子运动及其人口事件的系数具有不连续性，但我们首先通过将个体加权1/K来获得群体的极限行为K$\rightarrow$\infty$。然后，在K固定的微观水平上，我们数值研究了粒子的传播速度，并根据与已知极限行为一致的参数$\chi$恢复了阈值行为。最后，通过对祖先谱系的数值研究，我们根据关键参数$\chi$ 将行进前沿分为推拉。 et.al.|[2505.08563](http://arxiv.org/abs/2505.08563)|null|
|**2025-05-13**|**Are We Paying Attention to Her? Investigating Gender Disambiguation and Attention in Machine Translation**|虽然现代神经机器翻译（NMT）系统中的性别偏见受到了广泛关注，但传统的评估指标并不能完全反映这些系统整合上下文性别线索的程度。我们提出了一种新的评估指标，称为最小对准确性（MPA），用于衡量模型对性别线索的依赖程度，以消除性别歧义。MPA旨在超越表面层面的性别准确性指标，关注模型是否适应最小对中的性别线索——仅在性别代词上不同的句子对，即源语言（EN）中目标实体性别的明确指标。我们使用这一指标评估了英语-意大利语（EN-IT）语言对上的许多NMT模型，我们发现，在大多数情况下，它们忽略了可用的性别线索，转而支持（统计）刻板的性别解释。我们进一步表明，在反刻板印象的情况下，这些模型倾向于更一致地考虑男性的性别线索，而忽略女性的线索。此外，我们分析了编码器组件中的注意力权重，并表明，虽然所有模型都在一定程度上编码了性别信息，但与对女性性别线索的更集中和更专业的反应相比，男性线索会引发更广泛的反应。 et.al.|[2505.08546](http://arxiv.org/abs/2505.08546)|null|
|**2025-05-13**|**Diffusion-assisted Model Predictive Control Optimization for Power System Real-Time Operation**|本文提出了一种用于实时电力系统运行的改进模型预测控制（MPC）框架。该框架包含一个为时间序列生成量身定制的扩散模型，以提高系统运行中使用的负荷预测模块的准确性。在没有明确的状态转换定律的情况下，利用模型识别程序来推导系统动力学，从而消除了将MPC应用于可再生能源主导的电力系统时的障碍。工业园区系统和IEEE 30节点系统的案例研究结果表明，使用扩散模型来增强训练数据集显著提高了负荷预测的准确性，推断的系统动力学适用于太阳能和风能的实时电网运行。 et.al.|[2505.08535](http://arxiv.org/abs/2505.08535)|null|
|**2025-05-13**|**Building-Block Aware Generative Modeling for 3D Crystals of Metal Organic Frameworks**|金属有机框架（MOF）将无机节点、有机边和拓扑网络结合成可编程的多孔晶体，但它们的天文设计空间无法通过暴力合成。生成建模具有最终的希望，但现有的模型要么回收已知的构建块，要么仅限于小的单元。我们介绍了积木感知MOF扩散（BBA MOF扩散），这是一种SE（3）等变扩散模型，可以学习单个积木的3D全原子表示，显式编码晶体学拓扑网络。BBA MOF Diffusion在CoRE MOF数据库上接受过培训，能够轻松地对含有1000个原子的晶胞MOF进行采样，具有很高的几何有效性、新颖性和多样性，反映了实验数据库。它的原生构建块表示产生了前所未有的金属节点和有机边缘，将可访问的化学空间扩展了几个数量级。合成了一种由模型预测的高分[Zn（1,4-TDC）（EtOH）2]MOF，其中粉末X射线衍射、热重分析和N2吸附证实了其结构保真度。因此，BBA-Diff为合成高性能MOF提供了一条实用的途径。 et.al.|[2505.08531](http://arxiv.org/abs/2505.08531)|null|

<p align=right>(<a href=#updated-on-20250514>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-04-30**|**Neural Co-Optimization of Structural Topology, Manufacturable Layers, and Path Orientations for Fiber-Reinforced Composites**|我们提出了一种基于神经网络的计算框架，用于同时优化结构拓扑、弯曲层和路径方向，以在确保可制造性的同时实现纤维增强热塑性复合材料的强各向异性强度。我们的框架采用三个隐式神经场来表示几何形状、层序列和纤维取向。这使得设计和可制造性目标（如各向异性强度、结构体积、机器运动控制、层曲率和层厚度）能够直接公式化为一个集成和可微分的优化过程。通过将这些目标作为损失函数，该框架确保了所得复合材料具有优化的机械强度，同时保持了其在不同硬件平台上基于长丝的多轴3D打印的可制造性。物理实验表明，与具有顺序优化结构和制造顺序的复合材料相比，我们的协同优化方法产生的复合材料的破坏载荷可以提高33.1%。 et.al.|[2505.03779](http://arxiv.org/abs/2505.03779)|null|
|**2025-05-05**|**A New Perspective To Understanding Multi-resolution Hash Encoding For Neural Fields**|Instant NGP是近年来最先进的神经场架构。其令人难以置信的信号拟合能力通常归因于其多分辨率哈希网格结构，并在许多后续工作中得到了使用和改进。然而，目前尚不清楚这种哈希网格结构如何以及为什么能够如此大幅度地提高神经网络的能力。对哈希网格缺乏原则性的理解也意味着，伴随Instant NGP的大量超参数只能通过经验进行调整，而没有太多的启发式方法。为了直观地解释哈希网格的工作原理，我们提出了一种新的视角，即域操作。这一视角提供了一种全新的解释，即特征网格如何学习目标信号，并通过人工创建多个预先存在的线性段来提高神经场的表现力。我们对精心构建的一维信号进行了大量实验，以实证支持我们的主张，并辅助我们的说明。虽然我们的分析主要集中在一维信号上，但我们表明这个想法可以推广到更高的维度。 et.al.|[2505.03042](http://arxiv.org/abs/2505.03042)|**[link](https://github.com/stevolopolis/cp)**|
|**2025-04-27**|**HumMorph: Generalized Dynamic Human Neural Fields from Few Views**|我们介绍了HumMorph，这是一种新的广义方法，用于在显式姿态控制下对动态人体进行自由视点渲染。HumMorph以任意姿势渲染给定几个观察到的视图（从一个开始）的任何指定姿势的人类演员。我们的方法能够实现快速推理，因为它只依赖于通过模型的前馈传递。我们首先在规范T姿势中构建演员的粗略表示，该表示结合了来自个体部分观察的视觉特征，并使用学习到的先验知识填充缺失的信息。粗表示由直接从观察到的视图中提取的细粒度像素对齐特征补充，这些特征提供了高分辨率的外观信息。我们证明，当只有一个输入视图可用时，HumMorph与最先进的技术具有竞争力，但是，在仅进行2次单目观察的情况下，我们可以获得明显更好的视觉质量。此外，之前的广义方法假设可以使用同步的多相机设置获得精确的身体形状和姿势参数。相比之下，我们考虑了一种更实际的场景，其中这些身体参数直接从观察到的视图中进行噪声估计。我们的实验结果表明，我们的架构对噪声参数中的误差更具鲁棒性，在这种情况下明显优于最新技术。 et.al.|[2504.19390](http://arxiv.org/abs/2504.19390)|null|
|**2025-04-24**|**Geometry aware inference of steady state PDEs using Equivariant Neural Fields representations**|神经场的最新进展使学习神经算子的强大离散不变方法成为可能，这些算子在一般几何上近似偏微分方程（PDE）的解。基于这些发展，我们引入了enf2enf，这是一种基于最近提出的等变神经场架构的编码器-解码器方法，用于预测具有非参数化几何变异性的稳态偏微分方程。在enf2enf中，输入几何被编码为潜在的点云嵌入，这些嵌入固有地保留了几何基础并捕获了局部现象。然后将得到的表示与全局参数相结合，并直接解码为连续的输出场，从而有效地对几何和物理之间的耦合进行建模。通过利用局部性和平移不变性的归纳偏差，我们的方法能够捕捉精细尺度的物理特征以及复杂的形状变化，从而增强泛化能力和物理顺应性。对高保真空气动力学数据集、超弹性材料基准和多元素翼型几何形状的广泛实验表明，与最先进的基于图、操作员学习和神经场的方法相比，所提出的模型具有更优越或更具竞争力的性能。值得注意的是，我们的方法支持实时推理和零样本超分辨率，能够在低分辨率网格上进行高效训练，同时保持全尺寸离散化的高精度。 et.al.|[2504.18591](http://arxiv.org/abs/2504.18591)|null|
|**2025-04-28**|**Physics-Driven Neural Compensation For Electrical Impedance Tomography**|电阻抗断层成像（EIT）提供了一种非侵入性的便携式成像方式，在医疗和工业应用中具有巨大的潜力。尽管EIT具有优势，但它遇到了两个主要挑战：其逆问题的不适定性质和空间可变、位置相关的灵敏度分布。传统的基于模型的方法通过正则化来减轻病态性，但忽略了灵敏度的可变性，而监督深度学习方法需要大量的训练数据，缺乏泛化能力。神经领域的最新发展引入了用于图像重建的隐式正则化技术，但这些方法通常忽略了EIT背后的物理原理，从而限制了它们的有效性。在这项研究中，我们提出了PhyNC（物理驱动神经补偿），这是一个无监督的深度学习框架，结合了EIT的物理原理。PhyNC通过动态地将神经表征能力分配给灵敏度较低的区域，确保准确和平衡的电导率重建，解决了不适定逆问题和灵敏度分布问题。对模拟和实验数据的广泛评估表明，PhyNC在细节保存和抗伪影方面优于现有方法，特别是在低灵敏度区域。我们的方法增强了EIT重建的鲁棒性，并提供了一个灵活的框架，可以适应具有类似挑战的其他成像方式。 et.al.|[2504.18067](http://arxiv.org/abs/2504.18067)|null|
|**2025-04-23**|**Spot solutions to a neural field equation on oblate spheroids**|理解神经场中激发模式的动力学是神经科学的一个重要课题。神经场方程是描述相互作用神经元的激发动力学以进行理论分析的数学模型。尽管许多神经场方程的分析都集中在神经元相互作用对平面的影响上，但在对大脑等器官进行建模时，动力学的几何约束也是一个有吸引力的话题。本文报道了在球体作为模型曲面上定义的神经场方程中的模式动力学。我们将点解视为局部模式，并讨论曲面的几何特性如何改变它们的特性。为了分析具有小展平的球体上的斑点模式，我们首先在球面上构造精确的静止斑点解，并揭示它们的稳定性。然后，我们扩展了分析，以证明球状情况下驻点解的存在性和稳定性。我们的一个理论结果是推导了扁球体极点处定域的驻点解的稳定性判据。该标准决定了点解是保持在极点还是移动。最后，我们进行了数值模拟，根据我们的理论预测讨论了点解的动力学。我们的结果表明，点解的动力学取决于曲面和神经相互作用的协调。 et.al.|[2504.16342](http://arxiv.org/abs/2504.16342)|null|
|**2025-04-22**|**Low-Rank Adaptation of Neural Fields**|处理视觉数据通常涉及微小的调整或变化序列，例如图像滤波、表面平滑和视频存储。虽然现有的图形技术，如法线映射和视频压缩，利用冗余来有效地对这种小变化进行编码，但对神经场（NF）的小变化（视觉或物理功能的神经网络参数化）进行编码的问题却很少受到关注。我们提出了一种使用低秩自适应（LoRA）更新神经场的参数高效策略。LoRA是一种来自参数高效微调LLM社区的方法，它以最小的计算开销对预训练模型进行小更新编码。我们使LoRA适应特定于实例的神经场，避免了对大型预训练模型的需求，从而产生了适用于低计算硬件的流水线。我们通过图像滤波、视频压缩和几何编辑的实验验证了我们的方法，证明了它在表示神经场更新方面的有效性和通用性。 et.al.|[2504.15933](http://arxiv.org/abs/2504.15933)|null|
|**2025-04-21**|**Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields**|弱引力透镜是星系形状的轻微扭曲，主要是由宇宙中暗物质的引力效应引起的。在我们的工作中，我们试图从2D望远镜图像中反转弱透镜信号，以重建宇宙暗物质场的3D图。虽然反演通常会产生暗物质场的二维投影，但暗物质分布的精确三维图对于定位感兴趣的结构和测试我们宇宙的理论至关重要。然而，3D反演带来了重大挑战。首先，与依赖于多个视点的标准3D重建不同，在这种情况下，图像仅从单个视点观察。通过观察整个体积中的星系发射器是如何被透镜化的，可以部分解决这一挑战。然而，这导致了第二个挑战：无透镜星系的形状和确切位置是未知的，只能在非常大的不确定性下进行估计。这引入了大量的噪声，几乎完全淹没了透镜信号。以前的方法通过对卷中的结构施加强有力的假设来解决这个问题。相反，我们提出了一种使用引力约束神经场来灵活模拟连续物质分布的方法。我们采用综合分析方法，通过完全可微的物理正向模型优化神经网络的权重，以再现图像测量中存在的透镜信号。我们展示了我们的模拟方法，包括模拟即将到来的望远镜调查数据的暗物质分布的真实模拟测量。我们的结果表明，我们的方法不仅可以超越以前的方法，而且重要的是还能够恢复潜在的令人惊讶的暗物质结构。 et.al.|[2504.15262](http://arxiv.org/abs/2504.15262)|null|
|**2025-04-20**|**Efficient Implicit Neural Compression of Point Clouds via Learnable Activation in Latent Space**|隐式神经表示（INR），也称为神经场，已成为深度学习中的一种强大范式，使用基于坐标的神经网络对连续空间场进行参数化。在本文中，我们提出了\textbf{PICO}，这是一个基于INR的静态点云压缩框架。与主流的编码器-解码器范式不同，我们将点云压缩任务分解为两个单独的阶段：几何压缩和属性压缩，每个阶段都有不同的INR优化目标。受Kolmogorov-Arnold网络（KANs）的启发，我们引入了一种新的网络架构\textbf{LeAFNet}，它利用潜在空间中的可学习激活函数来更好地近似目标信号的隐函数。通过将点云压缩重新表述为神经参数压缩，我们通过量化和熵编码进一步提高了压缩效率。实验结果表明，\textbf{LeAFNet}在基于INR的点云压缩中优于传统的MLP。此外，与当前的MPEG点云压缩标准相比，\textbf{PICO}实现了卓越的几何压缩性能，D1 PSNR平均提高了4.92 $dB。在联合几何和属性压缩方面，我们的方法表现出了极具竞争力的结果，平均PCQM增益为2.7美元乘以10^{-3}$ 。 et.al.|[2504.14471](http://arxiv.org/abs/2504.14471)|null|
|**2025-04-17**|**Radial Basis Function Techniques for Neural Field Models on Surfaces**|我们提出了一种使用径向基函数（RBF）插值和求积求解曲面上神经场方程的数值框架。神经场模型描述了宏观大脑活动的演变，但建模研究往往忽视了弯曲皮质区域的复杂几何形状。传统的数值方法，如有限元或谱方法，在计算上可能很昂贵，并且在不规则域上实现具有挑战性。相比之下，基于RBF的方法提供了一种灵活的替代方案，通过提供插值和正交方案，以高阶精度有效地处理任意几何形状。我们首先为一般曲面上的神经场模型开发了一个基于RBF的插值投影框架。详细推导了平面和曲面域的求积法，确保了高阶精度和稳定性，因为它们取决于RBF超参数（基函数、增广多项式和模板大小）。通过数值实验，我们证明了我们的方法的收敛性，突出了它在灵活性和准确性方面优于传统方法。最后，我们阐述了复杂表面上时空活动的数值模拟，说明了该方法捕捉复杂波传播模式的能力。 et.al.|[2504.13379](http://arxiv.org/abs/2504.13379)|null|

<p align=right>(<a href=#updated-on-20250514>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

