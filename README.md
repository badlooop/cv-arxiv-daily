[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.06.24
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-21**|**E2GS: Event Enhanced Gaussian Splatting**|事件摄像机以其高动态范围、无运动模糊和低能耗而闻名，由于这些特性，最近得到了广泛的应用。在过去的几年里，基于事件的三维重建领域取得了显著进展，基于神经辐射场（NeRF）的方法展示了真实感视图合成的结果。然而，NeRF的体绘制范式需要大量的训练和绘制时间。在本文中，我们介绍了事件增强高斯散射（E2GS），这是一种将事件数据合并到高斯散射中的新方法，最近在新视图合成领域取得了重大进展。我们的E2GS有效地利用了模糊图像和事件数据，显著改善了图像去模糊，并产生了高质量的新视图合成。我们在合成和真实世界数据集上的全面实验表明，我们的E2GS可以生成视觉上吸引人的渲染，同时提供更快的训练和渲染速度（140 FPS）。我们的代码可在https://github.com/deguchihiroyuki/E2GS. et.al.|[2406.14978](http://arxiv.org/abs/2406.14978)|null|
|**2024-06-21**|**Relighting Scenes with Object Insertions in Neural Radiance Fields**|将对象插入场景和重新照明是增强现实（AR）中常用的应用。以前的方法侧重于使用CAD模型插入虚拟对象或从单视图图像中插入真实对象，导致AR应用场景非常有限。我们提出了一种新的基于NeRF的管道，用于将对象NeRF插入场景NeRF，实现新的视图合成和逼真的重新照明，支持物理交互，如从描绘对象和场景的两组图像中相互投射阴影。照明环境是球面谐波和球面高斯的混合表示，非常好地表示了高频和低频照明组件，并支持非朗伯曲面。具体而言，我们利用体积渲染的优势，通过比较相机视图和光源视图之间的深度图并生成生动的软阴影，引入了一种高效阴影渲染的创新方法。所提出的方法在广泛的实验评估中实现了现实的再照明效果。 et.al.|[2406.14806](http://arxiv.org/abs/2406.14806)|null|
|**2024-06-20**|**Deblurring Neural Radiance Fields with Event-driven Bundle Adjustment**|神经辐射场（NeRF）以高质量的多视图图像作为输入，实现了令人印象深刻的3D表示学习和新颖的视图合成结果。然而，图像中的运动模糊经常发生在低光照和高速运动场景中，这显著降低了NeRF的重建质量。以前的去模糊NeRF方法难以估计曝光时间内的信息，无法准确地对运动模糊进行建模。相比之下，以高时间分辨率测量强度变化的仿生事件相机弥补了这一信息不足。在本文中，我们提出了用于去模糊神经辐射场的事件驱动束调整（EBAD NeRF），以通过利用混合事件RGB数据来联合优化可学习姿态和NeRF参数。引入强度变化度量事件损失和照片度量模糊损失来加强相机运动模糊的显式建模。对合成数据和真实捕获数据的实验结果表明，与先前的工作相比，EBAD NeRF可以在曝光时间内获得准确的相机姿态，并学习更清晰的3D表示。 et.al.|[2406.14360](http://arxiv.org/abs/2406.14360)|null|
|**2024-06-19**|**Simultaneous Map and Object Reconstruction**|在本文中，我们提出了一种利用激光雷达对大规模城市场景进行动态表面重建的方法。基于深度的重建往往侧重于小规模对象或将移动对象视为异常值的大规模SLAM重建。我们采用整体视角，优化动态场景的组成模型，将世界分解为刚性移动的对象和背景。为了实现这一点，我们从最近的新颖视图合成方法中获得灵感，并将重建问题作为全局优化，最小化我们预测的表面和输入激光雷达扫描之间的距离。我们展示了如何将这种全局优化分解为配准和表面重建步骤，这些步骤可以通过现成的方法很好地处理，而无需任何重新训练。通过对连续时间运动进行仔细建模，我们的重建可以补偿旋转激光雷达传感器的滚动快门效应。这允许第一个系统（据我们所知）对刚性移动物体的激光雷达扫描进行适当的运动补偿，补充了广泛使用的静态场景运动补偿技术。除了将动态重建本身作为一个目标之外，我们还表明，这样的系统可以用于自动标记部分注释的序列，并为难以标记的问题（如深度完成和场景流）生成地面实况注释。 et.al.|[2406.13896](http://arxiv.org/abs/2406.13896)|null|
|**2024-06-19**|**Splatter a Video: Video Gaussian Representation for Versatile Processing**|视频表示是一个长期存在的问题，对各种下游任务至关重要，如跟踪、深度预测、分割、视图合成和编辑。然而，由于缺乏3D结构，当前的方法要么难以对复杂的运动进行建模，要么依赖于不适合操纵任务的隐式3D表示。为了应对这些挑战，我们引入了一种新的显式3D表示视频高斯表示——将视频嵌入到3D高斯中。我们提出的表示使用显式高斯作为代理对3D规范空间中的视频外观进行建模，并将每个高斯与视频运动的3D运动相关联。这种方法提供了比分层图集或体积像素矩阵更内在和更明确的表示。为了获得这样的表示，我们从基础模型中提取二维先验，如光流和深度，以在这种不适定的环境中正则化学习。广泛的应用证明了我们新视频表示的多功能性。它已被证明在许多视频处理任务中有效，包括跟踪、一致的视频深度和特征细化、运动和外观编辑以及立体视频生成。项目页面：https://sunyangtian.github.io/spatter_a_video_web/ et.al.|[2406.13870](http://arxiv.org/abs/2406.13870)|null|
|**2024-06-18**|**HumanSplat: Generalizable Single-Image Human Gaussian Splatting with Structure Priors**|尽管高保真度人体重建技术最近取得了进展，但对密集捕获图像或耗时的每次优化的要求大大阻碍了它们在更广泛场景中的应用。为了解决这些问题，我们提出了HumanSplat，它以可推广的方式从单个输入图像中预测任何人的3D高斯飞溅特性。特别是，HumanSplat包括一个2D多视图扩散模型和一个具有人体结构先验的潜在重建转换器，这些先验能够在一个统一的框架内熟练地集成几何先验和语义特征。进一步设计了一种包含人体语义信息的层次损失，以实现高保真纹理建模，并更好地约束估计的多个视图。在标准基准和野外图像上的综合实验表明，HumanSplat在实现真实感新颖视图合成方面超越了现有的最先进方法。 et.al.|[2406.12459](http://arxiv.org/abs/2406.12459)|**[link](https://github.com/humansplat/humansplat.github.io)**|
|**2024-06-17**|**DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features**|我们提出了DistilleNeRF，这是一种自监督学习框架，解决了在自动驾驶中从有限的2D观测中理解3D环境的挑战。我们的方法是一个可推广的前馈模型，它从稀疏的单帧多视图相机输入中预测丰富的神经场景表示，并通过可微分渲染进行自监督训练，以重建RGB、深度或特征图像。我们的第一个见解是通过生成密集的深度和虚拟相机目标进行训练，利用每场景优化的神经辐射场（NeRF），从而帮助我们的模型从稀疏的非重叠图像输入中学习3D几何。其次，为了学习语义丰富的3D表示，我们建议从预先训练的2D基础模型（如CLIP或DINOv2）中提取特征，从而实现各种下游任务，而不需要昂贵的3D人工注释。为了利用这两个见解，我们引入了一种新的模型架构，该架构具有两级提升-飞溅-拍摄编码器和参数化稀疏分层体素表示。在NuScenes数据集上的实验结果表明，DistilleNeRF在场景重建、新视图合成和深度估计方面显著优于现有的可比自监督方法；并且它允许竞争性的零样本3D语义占用预测，以及通过提取的基础模型特征来理解开放世界场景。演示和代码将在https://distillnerf.github.io/. et.al.|[2406.12095](http://arxiv.org/abs/2406.12095)|null|
|**2024-06-17**|**A Hierarchical 3D Gaussian Representation for Real-Time Rendering of Very Large Datasets**|近年来，新型视图合成取得了重大进展，3D高斯飞溅提供了卓越的视觉质量、快速训练和实时渲染。然而，训练和渲染所需的资源不可避免地限制了可以以良好视觉质量表示的捕捉场景的大小。我们引入了一种3D高斯层次结构，它可以为非常大的场景保留视觉质量，同时提供了一种高效的细节级别（LOD）解决方案，通过有效的级别选择和级别之间的平滑过渡来高效渲染远处的内容。我们引入了一种分而治之的方法，使我们能够在独立的块中训练非常大的场景。我们将块合并到一个层次结构中，该层次结构可以进行优化，以进一步提高合并到中间节点的高斯图的视觉质量。非常大的捕获通常具有稀疏的场景覆盖，这对原始的3D高斯飞溅训练方法提出了许多挑战；我们调整并规范培训以解决这些问题。我们提供了一个完整的解决方案，能够实时渲染非常大的场景，并且由于我们的LOD方法，可以适应可用的资源。我们使用一个简单且价格合理的设备显示了拍摄场景的结果，其中包含多达数万张图像，覆盖的轨迹长达数公里，持续时间长达一小时。项目页面：https://repo-sam.inria.fr/fungraph/hierarchical-3d-gaussians/ et.al.|[2406.12080](http://arxiv.org/abs/2406.12080)|null|
|**2024-06-17**|**MegaScenes: Scene-Level View Synthesis at Scale**|场景级新颖视图合成（NVS）是许多视觉和图形应用的基础。最近，姿态条件扩散模型通过从2D基础模型中提取3D信息取得了显著进展，但这些方法受到缺乏场景级训练数据的限制。常见的数据集选择要么由孤立的对象（Ob厌恶对象）组成，要么由姿势分布有限的以对象为中心的场景（DTU、CO3D）组成。在本文中，我们从互联网照片集创建了一个大规模的场景级数据集，称为MegaScenes，其中包含来自世界各地的超过100K的运动结构（SfM）重建。互联网照片代表了一个可扩展的数据源，但也带来了照明和瞬态物体等挑战。我们解决这些问题是为了进一步创建适合NVS任务的子集。此外，我们分析了最先进的NVS方法的失败案例，并显著提高了生成一致性。通过广泛的实验，我们验证了我们的数据集和方法在野外场景生成方面的有效性。有关数据集和代码的详细信息，请参阅我们的项目页面https://megascenes.github.io . et.al.|[2406.11819](http://arxiv.org/abs/2406.11819)|null|
|**2024-06-15**|**Federated Neural Radiance Field for Distributed Intelligence**|新型视图合成（NVS）是许多AR和VR应用的重要技术。最近提出的神经辐射场（NeRF）方法在NVS任务上表现出了优越的性能，并已应用于其他相关领域。然而，由于严格的法规和隐私问题，具有分布式数据存储的某些应用场景可能会对NeRF方法获取训练图像带来挑战。为了克服这一挑战，我们将重点放在FedNeRF上，这是一种基于联合学习（FL）的NeRF方法，它利用不同数据所有者的可用图像，同时保护数据隐私。在本文中，我们首先构建了一个资源丰富、功能多样的联合学习测试平台。然后，我们在这样一个实际的FL系统中部署了FedNeRF算法，并进行了部分客户端选择的FedNeRF实验。预计本文对FedNeRF方法的研究将有助于促进NeRF方法在分布式数据存储场景中的未来应用。 et.al.|[2406.10474](http://arxiv.org/abs/2406.10474)|null|

<p align=right>(<a href=#updated-on-20240624>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-21**|**E2GS: Event Enhanced Gaussian Splatting**|事件摄像机以其高动态范围、无运动模糊和低能耗而闻名，由于这些特性，最近得到了广泛的应用。在过去的几年里，基于事件的三维重建领域取得了显著进展，基于神经辐射场（NeRF）的方法展示了真实感视图合成的结果。然而，NeRF的体绘制范式需要大量的训练和绘制时间。在本文中，我们介绍了事件增强高斯散射（E2GS），这是一种将事件数据合并到高斯散射中的新方法，最近在新视图合成领域取得了重大进展。我们的E2GS有效地利用了模糊图像和事件数据，显著改善了图像去模糊，并产生了高质量的新视图合成。我们在合成和真实世界数据集上的全面实验表明，我们的E2GS可以生成视觉上吸引人的渲染，同时提供更快的训练和渲染速度（140 FPS）。我们的代码可在https://github.com/deguchihiroyuki/E2GS. et.al.|[2406.14978](http://arxiv.org/abs/2406.14978)|null|
|**2024-06-19**|**MVSBoost: An Efficient Point Cloud-based 3D Reconstruction**|高效准确的3D重建对于各种应用至关重要，包括增强现实和虚拟现实、医学成像和电影特效。虽然传统的多视图立体（MVS）系统在这些应用中是基础，但在隐式3D场景建模中使用神经隐式场为处理复杂拓扑和连续曲面带来了新的可能性。然而，神经隐式场往往存在计算效率低、过拟合和严重依赖数据质量的问题，限制了其实际应用。本文提出了一种增强的MVS框架，该框架通过运动结构（SfM）和用于点云致密化、网格重建和纹理化的高级图像处理，将多视图360度图像与稳健的相机姿态估计相结合。我们的方法显著改进了传统的MVS方法，在真实合成360数据集上使用切角距离度量进行验证，提供了卓越的准确性和精度。所开发的MVS技术增强了3D重建的细节和清晰度，并在复杂场景重建中展示了卓越的计算效率和稳健性，有效地处理了遮挡和不同的视点。这些改进表明，我们的MVS框架可以与当前最先进的神经隐场方法竞争，并有可能超越这些方法，尤其是在需要实时处理和可扩展性的场景中。 et.al.|[2406.13515](http://arxiv.org/abs/2406.13515)|null|
|**2024-06-19**|**Assessing the 3D resolution of refocused correlation plenoptic images using a general-purpose image quality estimator**|相关全光成像（CPI）是一种很有前途的光场成像（LFI）方法，这是一种能够同时测量场景中光强分布和传播方向的技术。LFI允许单次3D采样，为广泛的应用提供快速的3D重建。然而，LFI中通常用于获得3D信息的微透镜阵列限制了图像分辨率，图像分辨率随着体积重建能力的增强而迅速下降。CPI通过使用两个具有空间分辨率的光电探测器来解耦光场信息测量，从而消除了对微透镜的需求，从而解决了这一限制。3D信息被编码在四维相关函数中，该函数在后处理中被解码以重建图像，而没有传统LFI中看到的分辨率损失。本文评估了CPI的断层成像性能，证明了重新聚焦重建方法提供了与传统成像系统相当的轴向切片能力。提出了一种基于图像保真度的通用分析方法来定量研究轴向和横向分辨率。该分析充分表征了任何CPI架构的体积分辨率，提供了对其成像性能的全面评估。 et.al.|[2406.13501](http://arxiv.org/abs/2406.13501)|null|
|**2024-06-19**|**Self-Supervised Diffusion Model for 3-D Seismic Data Reconstruction**|地震数据重建是补偿不均匀和不完全地震几何的有效工具。与二维地震数据重建方法相比，三维重建方法可以更多地考虑地震数据中的空间结构相关性。在早期的研究中，三维重建方法主要是理论驱动的，由于其对地震数据的先验假设，因此存在一些局限性。为了释放这些局限性，基于深度学习的重建方法兴起，并在处理重建问题方面显示出潜力。然而，现有的深度学习方法主要有两个缺点。一方面，现有的大多数基于深度学习的方法都采用卷积神经网络，在处理复杂或时变分布的数据时存在一些困难。最近，有报道称，扩散模型能够通过逐渐使数据分布复杂化来优化网络，从而解决具有复杂分布的数据。另一方面，现有的方法需要足够的成对数据来训练网络，这是很难获得的，尤其是对于缺乏的三维地震数据。基于深度先验的无监督和基于采样的自监督网络为这个问题提供了一个可用的解决方案。在本文中，我们开发了一个用于三维地震数据重建的自监督扩散模型（S2DM）。所提出的模型主要包括扩散恢复模型和变分时空模块。大量的合成和现场实验证明了所提出的S2DM算法的优越性。 et.al.|[2406.13252](http://arxiv.org/abs/2406.13252)|null|
|**2024-06-18**|**Semantic Graph Consistency: Going Beyond Patches for Regularizing Self-Supervised Vision Transformers**|具有视觉转换器（ViTs）的自监督学习（SSL）已被证明对表示学习有效，在各种下游任务上的出色表现证明了这一点。尽管取得了这些成功，但现有的基于ViT的SSL架构并没有完全利用ViT主干，尤其是ViT的补丁令牌。在本文中，我们引入了一个新的语义图一致性（SGC）模块来规范基于ViT的SSL方法，并有效地利用补丁令牌。我们将图像重新定义为图，将图像补丁作为节点，并通过使用图神经网络将显式消息传递到SSL框架中来注入关系归纳偏差。我们的SGC损失充当了一个正则化因子，利用未充分开发的ViTs补丁令牌来构建图，并在图像的多个视图中增强图特征之间的一致性。在包括ImageNet、RESISC和Food-101在内的各种数据集上进行的广泛实验表明，我们的方法显著提高了学习表示的质量，当有限的标记数据用于线性评估时，性能提高了5-10%。这些实验与一系列全面的消融相结合，证明了我们的方法在各种环境中的前景。 et.al.|[2406.12944](http://arxiv.org/abs/2406.12944)|null|
|**2024-06-18**|**HumanSplat: Generalizable Single-Image Human Gaussian Splatting with Structure Priors**|尽管高保真度人体重建技术最近取得了进展，但对密集捕获图像或耗时的每次优化的要求大大阻碍了它们在更广泛场景中的应用。为了解决这些问题，我们提出了HumanSplat，它以可推广的方式从单个输入图像中预测任何人的3D高斯飞溅特性。特别是，HumanSplat包括一个2D多视图扩散模型和一个具有人体结构先验的潜在重建转换器，这些先验能够在一个统一的框架内熟练地集成几何先验和语义特征。进一步设计了一种包含人体语义信息的层次损失，以实现高保真纹理建模，并更好地约束估计的多个视图。在标准基准和野外图像上的综合实验表明，HumanSplat在实现真实感新颖视图合成方面超越了现有的最先进方法。 et.al.|[2406.12459](http://arxiv.org/abs/2406.12459)|**[link](https://github.com/humansplat/humansplat.github.io)**|
|**2024-06-18**|**Fast Global Localization on Neural Radiance Field**|神经辐射场（NeRF）提供了一种新的场景表示方法，允许从2D图像进行高质量的3D重建。在取得显著成就后，NeRF地图中的全球定位是实现广泛应用的重要任务。最近，Loc-NeRF展示了一种将传统蒙特卡罗定位与NeRF相结合的定位方法，显示了使用NeRF作为环境图的有希望的结果。然而，尽管Loc-NeRF取得了进步，但它仍面临着时间密集型光线渲染过程的挑战，这在实际应用中可能是一个重大限制。为了解决这个问题，我们引入了Fast Loc NeRF，它利用从粗到细的方法来实现更高效、更准确的基于NeRF地图的全局定位。具体而言，Fast Loc NeRF在从低到高分辨率的多分辨率上匹配渲染像素和观察到的图像。因此，它加快了昂贵的粒子更新过程，同时保持了精确的定位结果。此外，为了拒绝异常粒子，我们提出了粒子拒绝加权，该加权通过利用NeRF的特性来估计粒子的不确定性，并在粒子加权过程中考虑它们。我们的Fast Loc NeRF在几个基准上设置了新的最先进的定位性能，使其准确性和效率令人信服。 et.al.|[2406.12202](http://arxiv.org/abs/2406.12202)|null|
|**2024-06-17**|**FAWN: Floor-And-Walls Normal Regularization for Direct Neural TSDF Reconstruction**|利用3D语义进行直接的3D重建具有巨大的潜力。例如，通过假设墙壁是垂直的，地板是平面和水平的，我们可以纠正扭曲的房间形状，并消除局部伪影，如洞、坑和山丘。在本文中，我们提出了FAWN，这是截断符号距离函数（TSDF）重建方法的一种改进，它通过检测场景中的墙壁和地板来考虑场景结构，并对偏离水平和垂直方向的相应表面法线进行惩罚。作为一个3D稀疏卷积模块实现，FAWN可以合并到任何预测TSDF的可训练管道中。由于FAWN只需要用于训练的3D语义，因此对进一步使用没有额外的限制。我们证明，与现有的基于语义的方法相比，FAWN修改的方法更有效地使用了语义。此外，我们将我们的修改应用于最先进的TSDF重建方法，并在SCANNET、ICL-NUIM、TUM RGB-D和7SCENES基准中证明了质量增益。 et.al.|[2406.12054](http://arxiv.org/abs/2406.12054)|null|
|**2024-06-18**|**Effective Rank Analysis and Regularization for Enhanced 3D Gaussian Splatting**|从多视图图像中进行三维重建是计算机视觉和图形学的基本挑战之一。近年来，三维高斯散射（3DGS）已经成为一种很有前途的技术，能够实时渲染和高质量的三维重建。该方法利用了三维高斯表示和基于瓦片的飞溅技术，绕过了昂贵的神经场查询。尽管3DGS具有潜力，但由于高斯收敛为具有一个主导方差的各向异性高斯，3DGS仍面临挑战，包括针状伪影、次优几何结构和不准确法线。我们建议使用有效秩分析来检查3D高斯基元的形状统计，并识别高斯确实收敛为有效秩为1的针状形状。为了解决这个问题，我们引入了有效秩作为正则化，它约束高斯的结构。我们的新正则化方法增强了法线和几何重建，同时减少了针状伪影。该方法可以作为附加模块集成到其他3DGS变体中，在不影响视觉逼真度的情况下提高其质量。 et.al.|[2406.11672](http://arxiv.org/abs/2406.11672)|null|
|**2024-06-15**|**fNeRF: High Quality Radiance Fields from Practical Cameras**|近年来，神经辐射场的发展使人们能够从多视图相机数据中对场景和物体进行前所未有的逼真3D重建。然而，以前的方法使用过于简化的针孔相机模型，导致散焦模糊被“烘焙”到重建的辐射场中。我们提出了一种对光线投射的修改，该修改利用透镜的光学特性来增强在存在散焦模糊的情况下的场景重建。这使我们能够从具有有限孔径的实际相机的测量中提高辐射场重建的质量。我们表明，与针孔模型和散焦模糊模型的其他近似值相比，所提出的模型更符合实际相机的散焦模糊行为，特别是在存在部分遮挡的情况下。这使我们能够实现更清晰的重建，在合成和真实数据集上验证所有对焦图像时将PSNR提高高达3dB。 et.al.|[2406.10633](http://arxiv.org/abs/2406.10633)|null|

<p align=right>(<a href=#updated-on-20240624>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-21**|**Network-Based Optimal Control of Pollution Growth**|本文研究了污染扩散在时间和空间上的最优控制模型（由我们称之为规划器的集中经济主体）。控制是对生产和去污染的投资，目标是最大化跨期效用函数。主要的新颖之处在于空间组件具有网络结构。此外，在这样的时空环境中，我们还分析了使用绿色技术和非绿色技术之间的权衡：在这样的环境中，这似乎也是一种新奇的东西。扩展以前论文的方法，我们可以明确地解决线性污染成本的情况下的问题。 et.al.|[2406.15338](http://arxiv.org/abs/2406.15338)|null|
|**2024-06-21**|**Masked Extended Attention for Zero-Shot Virtual Try-On In The Wild**|虚拟试穿（VTON）是一个非常活跃的研究领域，需求不断增加。它旨在将图像中的一件衣服替换为另一件衣服，同时保留人和衣服的特征以及图像的保真度。目前的文献对这项任务采取了有监督的方法，削弱了泛化能力，并增加了大量的计算量。本文提出了一种新颖的无零样本训练的服装修补方法。我们的方法采用了扩散模型的先验，不需要额外的训练，充分利用了其固有的泛化能力。该方法利用扩展注意力将图像信息从参考图像转移到目标图像，克服了两个重大挑战。我们首先使用深层特征将参考服装扭曲到目标人体上，以缓解“纹理粘连”。然后，我们通过仔细的掩蔽来利用扩展注意力机制，消除参考背景的泄漏和不必要的影响。通过与最先进的方法进行用户研究、定性和定量比较，我们展示了与看不见的衣服或人形相比，卓越的图像质量和服装保存效果。 et.al.|[2406.15331](http://arxiv.org/abs/2406.15331)|null|
|**2024-06-21**|**Global existence of solutions to a nonlocal equation with degenerate anisotropic diffusion**|在高维无通量边界条件下，建立了非局部扩散-平流反应方程极弱解的全局存在性。该方程以退化近视扩散和非局部粘附为特征，是最近在arXiv:2308.05676中导出的质量守恒模型的扩展。扩散张量的容许简并性用上盒分形维数来表征。 et.al.|[2406.15318](http://arxiv.org/abs/2406.15318)|null|
|**2024-06-21**|**Interacting phase fields yielding phase separation on surfaces**|在本文中，我们研究了两相生物膜的扩散界面模型。我们将从 $\mathbb｛R｝^n$上的扩散界面模型开始，该模型由两个耦合的相场$u，v$定义。第一相场$u$是膜内部的扩散近似；第二相场$v$是膜的两相的扩散近似。我们证明了相位函数对$（u_\varepsilon，v_\varepilon）$的紧致性结果和$\Gamma$ 收敛意义下的下界。作为第一个结果的应用，我们考虑两相Willmore函数加线张力能量的扩散近似。 et.al.|[2406.15300](http://arxiv.org/abs/2406.15300)|null|
|**2024-06-21**|**Symmetry-controlled SrRuO3/SrTiO3/SrRuO3 magnetic tunnel junctions:Spin polarization and its relevance to tunneling magnetoresistance**|磁性隧道结（MTJ）由两个由绝缘势垒层分隔的铁磁电极组成，具有与自旋相关的隧穿相关的非平凡的基本特性。特别令人感兴趣的是完全结晶的MTJ，其中依赖于自旋的隧穿由波矢量的对称群控制。在这项工作中，使用第一性原理量子输运计算，我们探索了全晶体SrRuO3/SrTiO3/SrRuO3（001）MTJ中的自旋相关隧穿，并预测了近3000%的隧穿磁阻（TMR）。我们证明了这种巨大的TMR效应是由SrRuO3（001）电极中的入射和出射Bloch态以及SrTiO3（0.001）势垒中的倏逝态的对称匹配（失配）驱动的。我们认为，在对称控制输运的条件下，无论使用什么定义，自旋极化都不是自旋相关隧穿的相关度量。然而，在存在扩散散射的情况下，例如，由于隧道势垒的带隙中的局部状态，对称匹配不再有效，并且SrRuO3/SrTiO3/SrRuO3（001）MTJ中的TMR被强烈降低。在这些条件下，界面传输函数的自旋极化成为TMR的有效度量。这些结果为理解和优化全氧化物MTJ中的TMR提供了重要的见解。 et.al.|[2406.15290](http://arxiv.org/abs/2406.15290)|null|
|**2024-06-21**|**The random walk of intermittently self-propelled particles**|受最近各种实验发现的启发，我们提出了一个间歇性自推进粒子的动力学模型：在两种运动模式之间循环切换的主动粒子，即主动运行状态和转弯状态，其中不存在自推进。这些运动模式的持续时间是从任意的等待时间分布中推导出来的。我们推导了输运特性的精确形式，如均方位移和扩散系数的表达式来描述这种过程。此外，还给出了在长时间极限中出现亚扩散和超扩散的条件。我们举了一些重要过程的例子，这些过程是我们系统的极限情况，包括细菌的奔跑和翻滚运动、垂直行走、跳跃和陷阱动力学、间歇性扩散和连续时间随机行走。 et.al.|[2406.15277](http://arxiv.org/abs/2406.15277)|null|
|**2024-06-21**|**You Only Acquire Sparse-channel (YOAS): A Unified Framework for Dense-channel EEG Generation**|密集通道脑电图（EEG）信号的高精度采集经常受到设备昂贵和缺乏便携性的阻碍。相反，从稀疏通道有效生成密集通道脑电图信号显示出前景和经济可行性。然而，稀疏通道脑电图带来了一些挑战，如空间分辨率降低、信息丢失、信号混合以及对噪声和干扰的易感性增加。为了应对这些挑战，我们首先从理论上将密集通道脑电图生成问题公式化为通过优化一组跨通道脑电图信号生成问题。然后，我们提出了从稀疏通道脑电图信号生成密集通道数据的YOAS框架。YOAS总共由四个顺序阶段组成：数据准备、数据预处理、偏置脑电图生成和合成脑电图生成。数据准备和预处理仔细考虑了脑电电极的分布和脑电信号的低信噪比问题。Biased EEG Generation包括BiasEEGAnFormer和BiasEEGDiffFormer的子模块，这两个子模块有助于注意力的长期特征提取，并分别通过将电极位置对准与扩散模型相结合来生成信号。合成脑电图生成综合最终信号，采用多通道脑电图生成的演绎范式。大量实验证实了YOAS的可行性、有效性和理论有效性，甚至显著提高了数据的可分辨性。这一从稀疏通道数据生成密集通道脑电信号的突破为脑电信号处理和应用开辟了新的探索途径。 et.al.|[2406.15269](http://arxiv.org/abs/2406.15269)|null|
|**2024-06-21**|**Can cosmic rays explain the high ionisation rates in the Galactic Centre?**| $\mathrm{H}_2根据对H$_3^+$线的观测，位于银河系中心区域的中心分子带的电离率估计为$\zeta\sim2\times10^{-14}~\mathrm{s}^{-1}$。这个数值比银河系其他任何地方测得的数值都大2-3个数量级。高宇宙射线密度被用来解释异常高的电离率。然而，在该区域由高能宇宙射线产生的$\gamma$-射线发射中没有看到这种过剩。因此，预计只有在低能宇宙射线光谱中才会出现过剩。在这里，我们推导出宇宙射线光谱中这种假设的低能量成分的约束条件，并质疑其合理性。为此，我们数值求解了中心分子带中的宇宙射线输运方程，考虑了空间扩散、银河风中的平流、环境湍流中的再加速以及与星际介质中的物质和辐射相互作用造成的能量损失。我们在假设宇宙射线是由位于银河系中心的源连续注入的情况下推导出固定解。然后将宇宙射线光谱中的高能成分与可用的$\gamma$-射线和无线电数据进行拟合，并将陡峭的低能成分添加到宇宙射线光谱，以解释大的电离率。我们发现，对于低于$p的质子，$p^{-7}$的注入光谱_{enh,p}c\对于低于$p的电子，simeq780~\mathrm{MeV}$和$p^{-5.2}$_{enh,e}c＝1.5~\mathrm｛GeV｝$才能达到观察到的电离率。这对应于在银河中心注入的一个数量级为$\sim10^｛40-41｝~\mathrm｛erg｝\，\mathrm{s｝^｛-1｝$ 的超大宇宙射线功率。我们得出的结论是，仅靠宇宙射线无法解释银河系中心区域的高电离率。 et.al.|[2406.15260](http://arxiv.org/abs/2406.15260)|null|
|**2024-06-21**|**Drag reduction in surfactant-contaminated superhydrophobic channels at high Péclet numbers**|受微流体应用的启发，我们研究了具有被可溶性表面活性剂污染的顺流周期性超疏水表面（SHSs）的通道中层流压力驱动流的减阻。我们在长波和弱扩散极限下建立了一个模型，其中顺流SHS周期与通道高度相比较大，并且P’clet数较大。采用渐近和数值技术，我们根据扩散的相对强度、Marangoni效应和整体表面交换来确定表面活性剂引起的阻力。在具有强体相表面交换的情况下，减阻表现出对体相浓度边界层厚度和表面活性剂强度的复杂依赖性。强的Marangoni效应通过线性表面活性剂分布固定界面，而弱的Marangoi效应产生具有复杂渐近结构的准停滞帽，该结构由弱本体扩散介导。随着本体表面交换的减弱，本体和界面解耦：当表面活性剂较强时，表面活性剂的分布是线性的，当表面活性素较弱时，形成经典的停滞帽。渐近解提供了在大部分参数空间内减阻的闭合形式预测，提供了实用性，并增强了对SHSs流动中表面活性剂动力学的理解。 et.al.|[2406.15251](http://arxiv.org/abs/2406.15251)|null|
|**2024-06-21**|**Unconstrained dynamic gel swelling generates transient surface deformations**|聚合物凝胶由三维交联网络组成，该网络通常能够承受与溶胀和去溶胀相关的机械变形。因此，凝胶可以设计出既需要产生应力又需要消散的智能行为，使其非常适合许多应用，包括膜技术、水捕获设备和药物递送系统。与完全膨胀的平衡状态相反，有限的研究表征了平衡之前的非稳态膨胀状态。正是在这种情况下，才会发生独特的表面变形。在这里，我们展示了在无约束的三维膨胀过程中，如何利用内部网络约束和外部扩散压力来操纵聚乙二醇凝胶的膨胀动力学和表面变形。我们发现，与水相比，增加交联剂分子量和在乙醇中的溶胀都是增加达到平衡所需时间的有效途径，但这是通过不同的机制实现的。具有较少内部约束的网络，通过交联链长度操纵，在更长的时间内吸收更多的溶剂。相反，在乙醇中的溶胀减少了网络吸收的溶剂量，同时增加了达到平衡的时间。肿胀过程中表面图案的测量表明，在肿胀的前五分钟内，表面会立即快速松弛。然而，这些特征的密度和持久性随溶剂质量而变化。这些结果为软材料如何经历动态变形建立了一个框架。设计瞬态表面特性，同时减轻不必要的不稳定性，为智能防污和传感器等新兴技术打开了大门。 et.al.|[2406.15224](http://arxiv.org/abs/2406.15224)|null|

<p align=right>(<a href=#updated-on-20240624>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-06-17**|**DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features**|我们提出了DistilleNeRF，这是一种自监督学习框架，解决了在自动驾驶中从有限的2D观测中理解3D环境的挑战。我们的方法是一个可推广的前馈模型，它从稀疏的单帧多视图相机输入中预测丰富的神经场景表示，并通过可微分渲染进行自监督训练，以重建RGB、深度或特征图像。我们的第一个见解是通过生成密集的深度和虚拟相机目标进行训练，利用每场景优化的神经辐射场（NeRF），从而帮助我们的模型从稀疏的非重叠图像输入中学习3D几何。其次，为了学习语义丰富的3D表示，我们建议从预先训练的2D基础模型（如CLIP或DINOv2）中提取特征，从而实现各种下游任务，而不需要昂贵的3D人工注释。为了利用这两个见解，我们引入了一种新的模型架构，该架构具有两级提升-飞溅-拍摄编码器和参数化稀疏分层体素表示。在NuScenes数据集上的实验结果表明，DistilleNeRF在场景重建、新视图合成和深度估计方面显著优于现有的可比自监督方法；并且它允许竞争性的零样本3D语义占用预测，以及通过提取的基础模型特征来理解开放世界场景。演示和代码将在https://distillnerf.github.io/. et.al.|[2406.12095](http://arxiv.org/abs/2406.12095)|null|
|**2024-06-18**|**Effective Rank Analysis and Regularization for Enhanced 3D Gaussian Splatting**|从多视图图像中进行三维重建是计算机视觉和图形学的基本挑战之一。近年来，三维高斯散射（3DGS）已经成为一种很有前途的技术，能够实时渲染和高质量的三维重建。该方法利用了三维高斯表示和基于瓦片的飞溅技术，绕过了昂贵的神经场查询。尽管3DGS具有潜力，但由于高斯收敛为具有一个主导方差的各向异性高斯，3DGS仍面临挑战，包括针状伪影、次优几何结构和不准确法线。我们建议使用有效秩分析来检查3D高斯基元的形状统计，并识别高斯确实收敛为有效秩为1的针状形状。为了解决这个问题，我们引入了有效秩作为正则化，它约束高斯的结构。我们的新正则化方法增强了法线和几何重建，同时减少了针状伪影。该方法可以作为附加模块集成到其他3DGS变体中，在不影响视觉逼真度的情况下提高其质量。 et.al.|[2406.11672](http://arxiv.org/abs/2406.11672)|null|
|**2024-06-13**|**Well-posedness and regularity of solutions to neural field problems with dendritic processing**|我们研究了最近提出的神经场模型的解决方案，在该模型中，树突被建模为源自体细胞层的垂直纤维的连续体。由于电压通过具有非局部源的电缆方程沿树枝状方向传播，因此该模型具有各向异性扩散算子以及突触耦合的积分项。因此，相应的柯西问题与经典的神经场方程明显不同。我们证明了问题的弱公式允许一个唯一的解，嵌入估计类似于非线性局部反应扩散方程的嵌入估计。我们的分析依赖于无扩散问题的扰动弱解，即标准神经场，迄今为止尚未对其弱问题进行研究。我们找到了有扩散和无扩散问题的严格渐近估计，并证明了这两个模型的解在有限时间间隔上在适当的范数下保持接近。我们提供了微扰结果的数值证据。 et.al.|[2406.09222](http://arxiv.org/abs/2406.09222)|null|
|**2024-06-13**|**Preserving Identity with Variational Score for General-purpose 3D Editing**|我们提出了Piva（用变分分数蒸馏保持同一性），这是一种新的基于优化的方法，用于编辑基于扩散模型的图像和3D模型。具体来说，我们的方法受到了最近提出的2D图像编辑方法——德尔塔去噪分数（DDS）的启发。我们指出了DDS在二维和三维编辑中的局限性，这会导致细节丢失和过饱和。为了解决这一问题，我们提出了一个额外的分数提取术语，以强制执行身份保护。这导致了更稳定的编辑过程，逐步优化NeRF模型以匹配目标提示，同时保留关键的输入特征。我们证明了我们的方法在零样本图像和神经场编辑中的有效性。我们的方法成功地改变了视觉属性，添加了微妙和实质性的结构元素，转换了形状，并在标准的2D和3D编辑基准上取得了有竞争力的结果。此外，我们的方法没有施加任何约束，如掩蔽或预训练，使其与广泛的预训练扩散模型兼容。这允许进行多功能编辑，而不需要神经场到网格的转换，提供更用户友好的体验。 et.al.|[2406.08953](http://arxiv.org/abs/2406.08953)|null|
|**2024-06-12**|**Category-level Neural Field for Reconstruction of Partially Observed Objects in Indoor Environment**|通过各种成功案例，神经隐式表示在三维重建中引起了人们的关注。对于进一步的应用，如场景理解或编辑，一些作品已经显示出在对象组成重建方面的进展。尽管它们在观测区域具有优越的性能，但在重建部分观测到的对象时，它们的性能仍然有限。为了更好地处理这个问题，我们引入了类别级神经场，该神经场在场景中属于同一类别的对象之间学习有意义的公共3D信息。我们的主要想法是根据观察到的形状对对象进行子分类，以便更好地训练类别级模型。然后，我们利用神经场，通过选择基于射线的不确定性选择的代表性对象并与之对齐，来执行配准部分观测对象的挑战性任务。在模拟和真实世界数据集上的实验表明，我们的方法改进了几个类别的未观察零件的重建。 et.al.|[2406.08176](http://arxiv.org/abs/2406.08176)|**[link](https://github.com/Taekbum/category-nerf-reconstruction-official)**|
|**2024-06-12**|**OpenObj: Open-Vocabulary Object-Level Neural Radiance Fields with Fine-Grained Understanding**|近年来，人们对由视觉语言模型（VLM）促进的开放词汇三维场景重建产生了浓厚的兴趣，VLM在开放集检索中展示了非凡的能力。然而，现有的方法面临一些局限性：它们要么专注于学习逐点特征，导致语义理解模糊，要么只处理对象级重建，从而忽略对象内部的复杂细节。为了应对这些挑战，我们引入了OpenObj，这是一种创新的方法，用于构建具有细粒度理解的开放词汇表对象级神经辐射场（NeRF）。从本质上讲，OpenObj建立了一个健壮的框架，用于在对象级别进行高效和严密的场景建模和理解。此外，我们将零件级特征融入神经领域，从而实现物体内部的细致入微的表示。这种方法捕获对象级实例，同时保持细粒度的理解。在多个数据集上的结果表明，OpenObj在零样本语义分割和检索任务中取得了优异的性能。此外，OpenObj支持多尺度的真实世界机器人任务，包括全局移动和局部操纵。 et.al.|[2406.08009](http://arxiv.org/abs/2406.08009)|**[link](https://github.com/BIT-DYN/OpenObj)**|
|**2024-06-11**|**Image Neural Field Diffusion Models**|扩散模型在对复杂数据分布建模方面表现出了令人印象深刻的能力，与GANs相比具有几个关键优势，例如稳定的训练、更好地覆盖训练分布的模式，以及在没有额外训练的情况下解决反问题的能力。然而，大多数扩散模型学习固定分辨率图像的分布。我们建议通过在图像神经场上训练扩散模型来学习连续图像的分布，该模型可以以任何分辨率渲染，并显示出其相对于固定分辨率模型的优势。为了实现这一点，一个关键的挑战是获得一个代表真实感图像神经场的潜在空间。受最近几项技术的启发，我们提出了一种简单有效的方法，但有一些关键的变化，使图像神经场具有真实感。我们的方法可以用于将现有的潜在扩散自动编码器转换为图像神经场自动编码器。我们证明，图像神经场扩散模型可以使用混合分辨率图像数据集进行训练，优于固定分辨率扩散模型和超分辨率模型，并且可以有效地解决不同尺度条件下的逆问题。 et.al.|[2406.07480](http://arxiv.org/abs/2406.07480)|null|
|**2024-06-10**|**Space-Time Continuous PDE Forecasting using Equivariant Neural Fields**|最近，条件神经场（NeF）通过将解学习为条件NeF的潜在空间中的流，已成为偏微分方程的强大建模范式。尽管受益于NeFs的有利特性，如网格不可知性和时空连续动力学建模，但这种方法限制了将PDE的已知约束强加给解决方案的能力，例如对称性或边界条件，有利于建模的灵活性。相反，我们提出了一种基于时空连续NeF的求解框架，该框架通过在潜在空间中保留几何信息，尊重PDE的已知对称性。我们表明，将解建模为感兴趣组 $G$ 上的点云流，可以提高泛化和数据效率。我们验证了我们的框架很容易推广到看不见的空间和时间位置，以及初始条件的几何变换——在其他基于NeF的PDE预测方法失败的地方——并在一些具有挑战性的几何结构中超过基线进行改进。 et.al.|[2406.06660](http://arxiv.org/abs/2406.06660)|null|
|**2024-06-11**|**LOP-Field: Brain-inspired Layout-Object-Position Fields for Robotic Scene Understanding**|空间认知使动物具有非常高效的导航能力，这在很大程度上取决于对空间环境的场景级理解。最近，人们发现，大鼠大脑嗅后皮层的神经群体比场景中的物体更能强烈地适应空间布局。受局部场景中空间布局表示的启发，我们提出了实现布局对象位置（LOP）关联的LOP域，以对机器人场景理解的层次表示进行建模。在基础模型和隐式场景表示的支持下，神经场被实现为机器人的场景存储器，存储具有位置、对象和布局信息的场景的可查询表示。为了验证所建立的LOP关联，对该模型进行了测试，以使用定量指标从3D位置推断区域信息，实现了超过88%的平均准确度。还表明，与最先进的定位方法相比，所提出的使用区域信息的方法可以在文本和RGB输入的情况下实现改进的对象和视图定位结果。 et.al.|[2406.05985](http://arxiv.org/abs/2406.05985)|null|
|**2024-06-17**|**Grounding Continuous Representations in Geometry: Equivariant Neural Fields**|最近，神经场已经成为表示连续信号的强大建模范式。在条件神经领域中，一个领域由一个潜在变量表示，该变量对NeF进行了调节，否则其参数化将在整个数据集上共享。我们提出了基于交叉注意力变换器的等变神经场，其中NeFs以几何条件变量，即潜在点云为条件，从而实现从潜在到场的等变解码。我们的等变方法引入了一个可操纵性性质，通过该性质，场和势能都以几何为基础，并服从变换定律。如果场变换，势能相应地表示变换，反之亦然。至关重要的是，等变关系确保潜在的能够（1）真实地表示几何模式，允许在潜在空间中进行几何推理，（2）在空间相似的模式上进行权重共享，允许有效地学习场的数据集。与其他非等变NeF方法相比，使用分类实验和拟合整个数据集的能力验证了这些主要特性。我们通过展示独特的局部场编辑特性，进一步验证了ENF的潜力。 et.al.|[2406.05753](http://arxiv.org/abs/2406.05753)|null|

<p align=right>(<a href=#updated-on-20240624>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

