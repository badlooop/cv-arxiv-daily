[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.07.31
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-07-29**|**Radiance Fields for Robotic Teleoperation**|神经辐射场（NeRFs）或3D高斯散斑（3DGS）等辐射场方法彻底改变了图形和新颖的视图合成。它们能够合成具有照片级真实感的新视点，以及捕捉复杂的体积和镜面场景，使其成为机器人遥操作设置的理想可视化工具。直接摄像机遥操作以牺牲机动性为代价提供高保真度操作，而基于重建的方法提供了保真度较低的可控场景。考虑到这一点，我们建议用在线辐射场取代机器人遥操作管道的传统重建可视化组件，提供具有照片级真实感的高度可操作场景。因此，对现有技术有三个主要贡献：（1）使用来自多个相机的实时数据对辐射场进行在线训练，（2）支持包括NeRF和3DGS在内的各种辐射方法，（3）这些方法的可视化套件，包括虚拟现实场景。为了实现与现有设置的无缝集成，这些组件在多种配置下用多个机器人进行了测试，并使用传统工具和VR耳机进行了显示。将不同方法和机器人的结果与网格重建的基线进行了定量比较，并进行了一项用户研究来比较不同的可视化方法。有关视频和代码，请查看https://leggedrobotics.github.io/rffr.github.io/. et.al.|[2407.20194](http://arxiv.org/abs/2407.20194)|null|
|**2024-07-25**|**Towards the Spectral bias Alleviation by Normalizations in Coordinate Networks**|最近，使用坐标网络表示信号主导了逆问题领域，并广泛应用于各种科学计算任务中。尽管如此，坐标网络中仍存在光谱偏差的问题，限制了学习高频分量的能力。这个问题是由坐标网络的神经切线核（NTK）特征值的病理分布引起的。我们发现，使用经典归一化技术（批归一化和层归一化）可以改善这种病理分布，这些技术通常用于卷积神经网络，但很少用于坐标网络。我们证明，归一化技术大大降低了NTK特征值的最大值和方差，同时略微修改了均值，考虑到最大特征值远大于最大值，这种方差变化导致特征值分布从较低的分布向较高的分布偏移，因此可以减轻谱偏差。此外，我们通过以不同的方式组合这两种技术，提出了两种新的归一化技术。通过将基于归一化的坐标网络应用于各种任务，包括图像压缩、计算机断层扫描重建、形状表示、磁共振成像、新视图合成和多视图立体重建，这些归一化技术的有效性得到了显著改进和最新技术水平的证实。 et.al.|[2407.17834](http://arxiv.org/abs/2407.17834)|**[link](https://github.com/aiolus-x/norm-inr)**|
|**2024-07-24**|**SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency**|我们提出了稳定视频4D（SV4D），这是一种用于多帧和多视图一致动态3D内容生成的潜在视频扩散模型。与之前依赖于单独训练的生成模型进行视频生成和新颖视图合成的方法不同，我们设计了一个统一的扩散模型来生成动态3D对象的新颖视图视频。具体来说，给定单眼参考视频，SV4D为每个视频帧生成时间上一致的新视图。然后，我们使用生成的新颖视图视频来有效地优化隐式4D表示（动态NeRF），而不需要大多数先前工作中使用的繁琐的基于SDS的优化。为了训练我们的统一新颖视图视频生成模型，我们从现有的Objaverse数据集中策划了一个动态3D对象数据集。多个数据集和用户研究的广泛实验结果表明，与先前的工作相比，SV4D在新视图视频合成和4D生成方面具有最先进的性能。 et.al.|[2407.17470](http://arxiv.org/abs/2407.17470)|null|
|**2024-07-24**|**Pose Estimation from Camera Images for Underwater Inspection**|高精度定位是水下复验任务的关键。惯性导航系统、多普勒速度记录仪和声学定位等传统定位方法面临着重大挑战，对于某些应用来说成本效益不高。在这种情况下，视觉定位是一种经济高效的替代方案，利用检查车辆上已经配备的摄像头从周围场景的图像中估计姿态。其中，基于机器学习的图像姿态估计在水下环境中显示出前景，使用基于先前映射场景训练的模型进行高效的重新定位。我们探索了基于学习的姿态估计器在清水和浑浊水检查任务中的有效性，评估了图像格式、模型架构和训练数据多样性的影响。我们通过采用新颖的视图合成模型来生成增强训练数据，从而显著增强了未探索区域的姿态估计。此外，我们通过扩展卡尔曼滤波器将姿态估计器输出与传感器数据相结合，提高了定位精度，证明了轨迹平滑度和精度的提高。 et.al.|[2407.16961](http://arxiv.org/abs/2407.16961)|null|
|**2024-07-29**|**DHGS: Decoupled Hybrid Gaussian Splatting for Driving Scene**|现有的高斯飞溅方法在驾驶场景中往往无法实现令人满意的新颖视图合成，这主要是由于所涉及的元素缺乏巧妙的设计和几何约束。本文介绍了一种新的神经渲染方法，称为解耦混合高斯散点（DHGS），旨在提高静态驾驶场景新型视图合成的渲染质量。这项工作的新颖之处在于，它为道路和非道路层提供了解耦和混合像素级混合器，而不需要为整个场景提供传统的统一可微渲染逻辑，同时通过提出的深度有序混合渲染策略仍然保持一致和连续的叠加。此外，对由符号距离场（SDF）组成的隐式道路表示进行训练，以监控具有微妙几何属性的路面。伴随着辅助透射率损失和一致性损失的使用，最终获得了具有不可察觉边界和高保真度的新图像。在Waymo数据集上进行的大量实验证明，DHGS的性能优于最先进的方法。提供更多视频证据的项目页面是：https://ironbrotherstyle.github.io/dhgs_web. et.al.|[2407.16600](http://arxiv.org/abs/2407.16600)|null|
|**2024-07-23**|**HDRSplat: Gaussian Splatting for High Dynamic Range 3D Scene Reconstruction from Raw Images**|最近出现的3D高斯散斑（3DGS）彻底改变了3D场景重建空间，实现了实时高保真的新颖视图合成。然而，除了RawNeRF之外，所有先前的基于3DGS和NeRF的方法都依赖于8位色调映射的低动态范围（LDR）图像进行场景重建。这种方法难以在需要更高动态范围的场景中实现精确的重建。示例包括在夜间或光线不足的室内空间中拍摄的具有低信噪比的场景，以及阴影区域表现出极端对比度的日光场景。我们提出的方法HDRSplat定制3DGS，在近暗环境中直接在14位线性原始图像上训练，保留了场景的完整动态范围和内容。我们的主要贡献有两个方面：首先，我们提出了一种适合线性HDR空间损耗的方法，可以同时从嘈杂的暗区和接近饱和的亮区中有效地提取场景信息，同时处理与视图相关的颜色，而不会增加球谐波的程度。其次，通过仔细的光栅化调整，我们隐含地克服了3DGS对点云初始化的严重依赖和敏感性。这对于在低纹理、高景深和低照度区域进行精确重建至关重要。HDRSplat是迄今为止最快的方法，可以在15分钟/场景内完成14位（HDR）3D场景重建（比之前最先进的RawNeRF快30倍）。它还拥有最快的推理速度，为120fps。我们通过展示各种应用，如合成散焦、密集深度图提取以及曝光、色调映射和视点的捕捉后控制，进一步证明了HDR场景重建的适用性。 et.al.|[2407.16503](http://arxiv.org/abs/2407.16503)|**[link](https://github.com/shreyesss/hdrsplat)**|
|**2024-07-22**|**BoostMVSNeRFs: Boosting MVS-based NeRFs to Generalizable View Synthesis in Large-scale Scenes**|虽然神经辐射场（NeRFs）表现出了卓越的质量，但其漫长的训练时间仍然是一个限制。可推广和基于MVS的NeRF虽然能够缩短训练时间，但往往会在质量上进行权衡。本文提出了一种称为BoostMVSNeRFs的新方法，以提高基于MVS的NeRF在大规模场景中的渲染质量。我们首先确定了基于MVS的NeRF方法的局限性，例如受限的视口覆盖和由于有限的输入视图引起的伪影。然后，我们通过提出一种在体绘制过程中选择和组合多个成本体积的新方法来解决这些局限性。我们的方法不需要训练，可以以前馈方式适应任何基于MVS的NeRF方法，以提高渲染质量。此外，我们的方法也是端到端可训练的，允许对特定场景进行微调。我们通过在大规模数据集上的实验证明了我们的方法的有效性，在大规模场景和无界户外场景中显示出显著的渲染质量改进。BoostMVSNeRFs的源代码发布于https://su-terry.github.io/BoostMVSNeRFs/. et.al.|[2407.15848](http://arxiv.org/abs/2407.15848)|null|
|**2024-07-22**|**6DGS: 6D Pose Estimation from a Single Image and a 3D Gaussian Splatting Model**|我们提出了6DGS来估计给定表示场景的3D高斯散斑（3DGS）模型的目标RGB图像的相机姿态。6DGS避免了典型的合成分析方法（如iNeRF）的迭代过程，该方法还需要初始化相机姿态才能收敛。相反，我们的方法通过反转3DGS渲染过程来估计6DoF姿态。从物体表面开始，我们定义了一个辐射Ellicell，它均匀地生成从每个椭球体出发的光线，这些椭球体对3DGS模型进行了参数化。每个Ellicell光线都与每个椭球体的渲染参数相关联，这些参数又用于获得目标图像像素和投射光线之间的最佳绑定。然后对这些像素光线绑定进行排序，以选择得分最高的光线束，它们的交点提供了相机中心，进而提供了相机旋转。所提出的解决方案消除了初始化时“先验”姿态的必要性，并以封闭形式解决了6DoF姿态估计问题，而不需要迭代。此外，与现有的用于姿态估计的新视图合成（NVS）基线相比，6DGS可以在真实场景中将整体平均旋转精度提高12%，平移精度提高22%，尽管不需要任何初始化姿态。同时，我们的方法近乎实时运行，在消费类硬件上达到15fps。 et.al.|[2407.15484](http://arxiv.org/abs/2407.15484)|null|
|**2024-07-19**|**SparseCraft: Few-Shot Neural Reconstruction through Stereopsis Guided Geometric Linearization**|我们提出了一种从少数彩色图像中恢复3D形状和视图相关外观的新方法，实现了高效的3D重建和新颖的视图合成。我们的方法以符号距离函数（SDF）和辐射场的形式学习隐式神经表示。该模型通过支持光线行进的体积渲染逐步训练，并使用无需学习的多视图立体（MVS）线索进行正则化。我们贡献的关键是一种新的隐式神经形状函数学习策略，该策略鼓励我们的SDF场在水平集附近尽可能线性，从而使训练对监督和正则化信号发出的噪声具有鲁棒性。在不使用任何预训练先验的情况下，我们的方法SparseCraft在新的视图合成和标准基准中从稀疏视图重建方面都达到了最先进的性能，同时只需要不到10分钟的训练时间。 et.al.|[2407.14257](http://arxiv.org/abs/2407.14257)|null|
|**2024-07-19**|**Mono-ViFI: A Unified Learning Framework for Self-supervised Single- and Multi-frame Monocular Depth Estimation**|自监督单目深度估计引起了人们的极大兴趣，因为它可以将训练从对深度注释的依赖中解放出来。在单目视频训练的情况下，最近的方法只在现有的摄像机视图之间进行视图合成，导致引导不足。为了解决这个问题，我们试图通过基于流的视频帧插值（VFI）来合成更多的虚拟相机视图，称为时间增强。对于多帧推理，为了避开基于显式几何的方法（如ManyDepth）遇到的动态对象问题，我们回到了特征融合范式，并设计了一个VFI辅助的多帧融合模块，使用基于流的VFI模型获得的运动和遮挡信息来对齐和聚合多帧特征。最后，我们构建了一个统一的自监督学习框架，名为Mono ViFI，以双向连接单帧和多帧深度。在这个框架中，通过图像仿射变换进行空间数据增强以实现数据多样性，同时进行正则化的三重深度一致性损失。单帧和多帧模型可以共享权重，使我们的框架紧凑且内存高效。大量实验表明，我们的方法可以为当前的先进架构带来重大改进。源代码可在https://github.com/LiuJF1226/Mono-ViFI. et.al.|[2407.14126](http://arxiv.org/abs/2407.14126)|**[link](https://github.com/liujf1226/mono-vifi)**|

<p align=right>(<a href=#updated-on-20240731>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-07-29**|**TeleOR: Real-time Telemedicine System for Full-Scene Operating Room**|远程医疗的出现代表了利用技术将专业医疗专业知识扩展到远程手术的变革性发展，在这个领域，专家指导的即时性至关重要。然而，手术室（OR）场景的复杂动态给远程医疗带来了独特的挑战，特别是在障碍物和带宽限制下实现高保真、实时的场景重建和传输。本文介绍了TeleOR，这是一个开创性的系统，旨在通过远程干预的实时OR场景重建来应对这些挑战。TeleOR以三种创新方法脱颖而出：动态自校准，利用固有的场景特征进行校准，无需预设标记，允许避障和实时调整相机；选择性OR重建，侧重于动态变化的场景片段，以降低重建复杂度；基于实时客户端反馈优化数据传输以在带宽限制内有效地提供高质量的3D重建。4D-OR手术场景数据集的综合实验证明了TeleOR的优越性和适用性，阐明了通过克服远程手术指导固有的空间和技术障碍来彻底改变远程干预的潜力。 et.al.|[2407.19763](http://arxiv.org/abs/2407.19763)|null|
|**2024-07-29**|**SALVE: A 3D Reconstruction Benchmark of Wounds from Consumer-grade Videos**|管理慢性伤口是一项全球性挑战，可以通过采用消费级视频的临床伤口评估自动系统来缓解。虽然2D图像分析方法不足以处理伤口的3D特征，但利用3D重建方法的现有方法尚未得到彻底评估。为了解决这一差距，本文对消费级视频的3D伤口重建进行了全面的研究。具体来说，我们介绍了SALVE数据集，其中包括用不同相机拍摄的逼真伤口幻影的视频记录。使用此数据集，我们评估了最先进的3D重建方法的准确性和精度，从传统的摄影测量管道到先进的神经渲染方法。在我们的实验中，我们观察到摄影测量方法不能提供适合精确临床测量伤口的光滑表面。神经渲染方法在解决这一问题方面显示出希望，推动了这项技术在伤口护理实践中的应用。 et.al.|[2407.19652](http://arxiv.org/abs/2407.19652)|null|
|**2024-07-28**|**Cycle3D: High-quality and Consistent Image-to-3D Generation via Generation-Reconstruction Cycle**|最近的3D大型重建模型通常采用两阶段过程，包括首先通过多视图扩散模型生成多视图图像，然后利用前馈模型将图像重建为3D内容。然而，多视图扩散模型通常会产生低质量和不一致的图像，对最终3D重建的质量产生不利影响。为了解决这个问题，我们提出了一种名为Cycle3D的统一3D生成框架，该框架在多步扩散过程中循环利用基于2D扩散的生成模块和前馈3D重建模块。具体而言，2D扩散模型用于生成高质量的纹理，重建模型保证了多视图的一致性。此外，2D扩散模型可以进一步控制生成的内容，并为看不见的视图注入参考视图信息，从而增强去噪过程中3D生成的多样性和纹理一致性。大量实验证明，与最先进的基线相比，我们的方法具有创建高质量和一致性的3D内容的卓越能力。 et.al.|[2407.19548](http://arxiv.org/abs/2407.19548)|null|
|**2024-07-27**|**A Bayesian Approach Toward Robust Multidimensional Ellipsoid-Specific Fitting**|这项工作提出了一种新颖有效的方法，用于在噪声和异常值污染的情况下将多维椭球体拟合到散射数据中。我们将该问题视为贝叶斯参数估计过程，并在给定数据的情况下最大化某个椭球解的后验概率。我们基于贝叶斯框架内的预测分布在这些点之间建立了更稳健的相关性。我们采用均匀的先验分布来约束在椭球域内搜索原始参数，确保无论输入如何，都能得到椭球特定的结果。然后，我们通过贝叶斯规则建立测量点和模型数据之间的连接，以增强该方法对噪声的鲁棒性。由于与空间维度无关，所提出的方法不仅为具有挑战性的细长椭球体提供了高质量的拟合，而且很好地推广到多维空间。为了解决以往方法经常忽视的异常值干扰，我们在预测分布的基础上进一步引入了均匀分布，以显著增强算法对异常值的鲁棒性。我们引入了一种加速技术，大大加快了EM的收敛速度。据我们所知，这是第一种能够在各种干扰下在贝叶斯优化范式内进行多维椭球体特定拟合的综合方法。我们在存在强噪声、异常值和轴比大幅变化的情况下，在低维和高维空间中对其进行评估。此外，我们将其应用于广泛的实际应用，如显微镜细胞计数、3D重建、几何形状近似和磁力计校准任务。 et.al.|[2407.19269](http://arxiv.org/abs/2407.19269)|**[link](https://github.com/zikai1/bayfit)**|
|**2024-07-26**|**Floating No More: Object-Ground Reconstruction from a Single Image**|从单个图像重建3D对象的最新进展主要集中在提高对象形状的准确性上。然而，这些技术往往无法准确捕捉物体、地面和相机之间的相互关系。因此，当放置在平面上时，重建的对象通常会出现浮动或倾斜。这一限制严重影响了3D感知图像编辑应用程序，如阴影渲染和对象姿态操纵。为了解决这个问题，我们引入了ORG（地面对象重建），这是一项旨在结合地面重建3D对象几何的新任务。我们的方法使用两个紧凑的像素级表示来描述相机、物体和地面之间的关系。实验表明，与传统的单图像3D重建技术相比，所提出的ORG模型可以在看不见的数据上有效地重建目标地面几何，显著提高了阴影生成和姿态操纵的质量。 et.al.|[2407.18914](http://arxiv.org/abs/2407.18914)|null|
|**2024-07-26**|**IOVS4NeRF:Incremental Optimal View Selection for Large-Scale NeRFs**|现代应用的城市级三维重建需要高渲染保真度，同时最大限度地降低计算成本。神经辐射场（NeRF）的出现增强了3D重建，但它在多个视点下表现出伪影。本文提出了一种新的NeRF框架方法来解决这些问题。我们的方法使用图像内容和姿势数据来迭代地规划下一个最佳视图。该方法的一个关键方面涉及不确定性估计，指导从候选集中选择具有最大信息增益的视图。随着时间的推移，这种迭代过程提高了渲染质量。同时，我们引入了Vonoroi图和阈值采样以及飞行分类器，以提高效率，同时保持原始NeRF网络的完整性。它可以作为一个插件工具来帮助更好的渲染，优于基线和类似的先前工作。 et.al.|[2407.18611](http://arxiv.org/abs/2407.18611)|null|
|**2024-07-25**|**UMono: Physical Model Informed Hybrid CNN-Transformer Framework for Underwater Monocular Depth Estimation**|水下单目深度估计是水下场景三维重建等任务的基础。然而，由于光和介质的影响，水下环境经历了独特的成像过程，这给从单幅图像中准确估计深度带来了挑战。现有的方法未能考虑水下环境的独特特征，导致估计结果不足，泛化性能有限。此外，水下深度估计需要提取和融合局部和全局特征，这在现有方法中没有得到充分探索。本文提出了一种用于水下单目深度估计的端到端学习框架UMono，该框架将水下图像形成模型特征融入网络架构，有效地利用了水下图像的局部和全局特征。实验结果表明，该方法对水下单目深度估计是有效的，在定量和定性分析方面都优于现有方法。 et.al.|[2407.17838](http://arxiv.org/abs/2407.17838)|null|
|**2024-07-24**|**SMA-Hyper: Spatiotemporal Multi-View Fusion Hypergraph Learning for Traffic Accident Prediction**|预测交通事故是可持续城市管理的关键，这需要有效解决城市的动态和复杂的时空特征。当前的数据驱动模型经常与数据稀疏性作斗争，通常忽视了不同城市数据源的集成及其内部的高阶依赖关系。此外，它们经常依赖于预定义的拓扑或权重，限制了它们在时空预测中的适应性。为了解决这些问题，我们引入了时空多视图自适应超图学习（SMA Hyper）模型，这是一种为交通事故预测设计的动态深度学习框架。基于先前的研究，这一创新模型结合了双重自适应时空图学习机制，通过超图和动态适应不断变化的城市数据，实现了高阶跨区域学习。它还利用对比学习来增强稀疏数据集中的全局和局部数据表示，并采用预先注意机制来融合事故数据和城市功能特征的多种视图，从而丰富了对风险因素的上下文理解。对伦敦交通事故数据集的广泛测试表明，SMA Hyper模型在各种时间范围和多步输出方面明显优于基线模型，证实了其多视图融合和自适应学习策略的有效性。结果的可解释性进一步强调了其通过利用复杂的时空城市数据来改善城市交通管理和安全的潜力，提供了一个适应不同城市环境的可扩展框架。 et.al.|[2407.17642](http://arxiv.org/abs/2407.17642)|null|
|**2024-07-22**|**Enhancement of 3D Gaussian Splatting using Raw Mesh for Photorealistic Recreation of Architectures**|建筑场景的真实感重建和渲染在电影、游戏和交通等行业有着广泛的应用。它在城市规划、建筑设计和城市推广方面也发挥着重要作用，特别是在保护历史文化遗产方面。由于其优于NeRF的性能，3D高斯散斑已成为3D重建的主流技术。它唯一的输入是一组图像，但它在很大程度上依赖于SfM过程计算的几何参数。与此同时，现有大量的原始3D模型可以为某些建筑物的结构感知提供信息，但无法应用。在这篇论文中，我们提出了一种直接的方法，利用这些原始的3D模型来引导3D高斯人捕捉建筑物的基本形状，并在非系统地捕捉照片时提高纹理和细节的视觉质量。这一探索为提高3D重建技术在建筑设计领域的有效性开辟了新的可能性。 et.al.|[2407.15435](http://arxiv.org/abs/2407.15435)|null|
|**2024-07-21**|**3D Reconstruction of the Human Colon from Capsule Endoscope Video**|随着受胃肠系统疾病影响的人数不断增加，对预防性筛查的更高要求是不可避免的。这将大大增加胃肠病学家的工作量。为了帮助减少工作量，计算机视觉工具可能会有所帮助。在这篇论文中，我们研究了使用无线胶囊内窥镜视频中的图像序列构建人体结肠整个切片的3D模型的可能性，为胃肠病学家提供了增强的观看体验。由于胶囊内窥镜图像包含失真和伪影，这对许多3D重建算法来说是不理想的，因此这个问题具有挑战性。然而，最近基于虚拟图形的人体胃肠系统模型的发展，可以启用或禁用失真和伪影，从而可以“剖析”这个问题。图形模型还提供了一个地面真实值，可以计算3D重建方法引入的几何失真。在这篇论文中，大多数失真和伪影被排除在外，以确定通过现有方法重建人体胃肠系统的整个部分是否可行。我们证明了使用同步定位和映射可以进行3D重建。此外，为了从密度变化很大的点云重建胃肠壁表面，泊松表面重建是一个不错的选择。研究结果很有希望，鼓励对这个问题进行进一步的研究。 et.al.|[2407.15228](http://arxiv.org/abs/2407.15228)|null|

<p align=right>(<a href=#updated-on-20240731>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-07-29**|**Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing**|当用户的输入指令不明确时，基于文本的编辑扩散模型表现出有限的性能。为了解决这个问题，我们提出了 $\textit｛Specify ANd Edit｝$ （SANE），这是一种用于基于扩散的编辑系统的零样本推理管道。我们使用大型语言模型（LLM）将输入指令分解为特定的指令，即定义良好的干预措施，应用于输入图像以满足用户的请求。得益于专为该任务设计的新颖去噪指导策略，我们受益于原始指令中的LLM衍生指令。我们在三个基线和两个数据集上的实验证明了SANE在所有设置中的优势。此外，我们的管道提高了编辑模型的可解释性，并提高了输出的多样性。我们还证明了我们的方法可以应用于任何编辑，无论是否模糊。我们的代码公开于https://github.com/fabvio/SANE. et.al.|[2407.20232](http://arxiv.org/abs/2407.20232)|null|
|**2024-07-30**|**cDVAE: Multimodal Generative Conditional Diffusion Guided by Variational Autoencoder Latent Embedding for Virtual 6D Phase Space Diagnostics**|目前，在单次拍摄中对粒子加速器中光束的6D相空间进行成像是不可能的。单次光束测量仅适用于某些二维光束投影，这些方法具有破坏性。可以生成光束6D相空间准确预测的虚拟诊断对于精确控制光束非常有用。在这项工作中，开发了一种基于生成条件扩散的方法，用于创建光束6D相空间的所有15个唯一2D投影的虚拟诊断。扩散过程由标量参数和图像的组合引导，这些参数和图像由变分自动编码器（VAE）转换为低维潜在向量表示。我们证明，由VAE（cDVAE）引导的条件扩散可以准确地重建HiRES紧凑型加速器电荷粒子束6相空间的所有15个独特的2D投影。 et.al.|[2407.20218](http://arxiv.org/abs/2407.20218)|null|
|**2024-07-29**|**On the leptonic contribution to the ultra high-energy diffuse gamma-ray background**|超高能（UHE）漫射伽马射线背景包含了宇宙射线在银河系中传播的重要信息。然而，其测量受到未解决来源的污染，其重要性尚不清楚。在这封信中，我们根据ATNF和LHAASO目录中的信息，提出了一种新的数据驱动的未解析轻子源贡献估计。我们发现，在银河系内部，LHAASO在10美元时测量的扩散通量中，最多有60%可能来自未解析的轻子源，而在100美元时，这一部分的能量下降到不到20%。在外星系中，未解决的轻子源的贡献总是次要的。当价格为10美元时，它低于20美元，高于25美元时，低于8美元。我们得出结论，UHE漫射背景应该主要由来自几十美元以上强子起源的光子主导。 et.al.|[2407.20186](http://arxiv.org/abs/2407.20186)|null|
|**2024-07-29**|**LatentArtiFusion: An Effective and Efficient Histological Artifacts Restoration Framework**|组织学伪影给病理学家和计算机辅助诊断（CAD）系统带来了挑战，导致分析错误。目前基于生成对抗网络（GAN）和像素级扩散模型的组织伪影恢复方法存在性能限制和计算效率低下的问题。在这篇论文中，我们提出了一种新的框架LatentArtiFusion，它利用潜在扩散模型（LDM）以高性能和计算效率重建组织伪影。与传统的像素级扩散框架不同，LatentArtiFusion在较低维的潜在空间中执行恢复过程，显著提高了计算效率。此外，我们引入了一种新的潜在空间区域伪影重建算法，以防止非伪影区域的误译，将我们的方法与基于GAN的方法区分开来。通过在真实世界的组织学数据集上进行广泛的实验，LatentArtiFusion表现出了惊人的速度，比最先进的像素级扩散框架高出30倍以上。它在多个评估指标上也始终超过基于GAN的方法至少5%。此外，我们评估了我们提出的框架在下游组织分类任务中的有效性，展示了它的实用性。代码可在以下网址获得https://github.com/bugs-creator/LatentArtiFusion. et.al.|[2407.20172](http://arxiv.org/abs/2407.20172)|**[link](https://github.com/bugs-creator/latentartifusion)**|
|**2024-07-29**|**Diffusion Feedback Helps CLIP See Better**|对比语言图像预训练（CLIP）擅长抽象跨领域和模态的开放世界表示，已成为各种视觉和多模态任务的基础。然而，最近的研究表明，CLIP具有严重的视觉缺陷，例如难以区分方向、数量、颜色、结构等。这些视觉缺陷也限制了基于CLIP构建的多模态大型语言模型（MLLM）的感知能力。主要原因可能是用于训练CLIP的图像-文本对由于缺乏文本的独特性和图像的多样性而具有固有的偏见。在这项工作中，我们提出了一种简单的CLIP模型后训练方法，该方法通过自监督扩散过程在很大程度上克服了其视觉缺陷。我们介绍DIVA，它使用DIffusion模型作为CLIP的可视化助手。具体来说，DIVA利用文本到图像扩散模型的生成反馈来优化CLIP表示，只使用图像（没有相应的文本）。我们证明，DIVA在具有挑战性的MMVP-VLM基准上提高了CLIP的性能，该基准在很大程度上评估了细粒度视觉能力（例如3-7%），并提高了MLLM和视觉模型在多模态理解和分割任务上的性能。对29个图像分类和检索基准的广泛评估证实，我们的框架保留了CLIP强大的零样本能力。该代码将在以下网址提供https://github.com/baaivision/DIVA. et.al.|[2407.20171](http://arxiv.org/abs/2407.20171)|null|
|**2024-07-29**|**A unified framework for $N$-phase Navier-Stokes Cahn-Hilliard Allen-Cahn mixture models with non-matching densities**|在过去的几十年里，已经提出了许多具有非匹配密度的N$相不可压缩扩散界面流模型。尽管旨在描述相同的物理学，但这些模型通常是不同的，并且缺乏一个总体的建模框架。本文为具有单一动量方程的N$相不可压缩Navier-Stokes-Cahn-Hilliard-Allen Cahn混合模型提供了一个统一的框架。该框架自然地出现在连续体混合理论中，表现出能量耗散结构，并且对基本变量的选择不变。这为探索现有$N$相模型之间的联系打开了大门，并促进了基于连续混合理论的$N$ 相流模型的计算。 et.al.|[2407.20145](http://arxiv.org/abs/2407.20145)|null|
|**2024-07-29**|**DDAP: Dual-Domain Anti-Personalization against Text-to-Image Diffusion Models**|基于扩散的个性化视觉内容生成技术取得了重大突破，只需从几张参考照片中学习即可创建特定对象。然而，当这些技术被滥用于制造针对个人的假新闻或令人不安的内容时，可能会造成相当大的社会危害。为了解决这个问题，当前的方法通过对抗性地最大化训练损失来生成对抗性样本，从而破坏用这些样本训练的任何个性化生成模型的输出。然而，现有的方法未能实现有效的防御并保持隐蔽性，因为它们忽视了扩散模型的内在特性。本文介绍了一种新的双域反个性化框架（DDAP）。具体来说，我们通过利用图像编码器在个性化生成中的固定和扰动敏感特性，开发了空间扰动学习（SPL）。随后，我们设计了一种频率扰动学习（FPL）方法，该方法利用了频域中扩散模型的特性。SPL会破坏生成图像的整体纹理，而FPL则专注于图像细节。通过交替使用这两种方法，我们构建了DDAP框架，有效地利用了这两个领域的优势。为了进一步提高对抗样本的视觉质量，我们设计了一个定位模块来准确捕捉关注区域，同时确保攻击的有效性并避免背景中不必要的干扰。对面部基准的广泛实验表明，所提出的DDAP增强了对个性化生成模型的破坏，同时在对抗性样本中保持了高质量，使其在实际应用中更有效地保护隐私。 et.al.|[2407.20141](http://arxiv.org/abs/2407.20141)|null|
|**2024-07-29**|**Diffusion-DICE: In-Sample Diffusion Guidance for Offline Reinforcement Learning**|分布校正估计（DICE）方法的一个重要特性是，解决方案是优化策略和数据收集策略之间的最优平稳分布比。在这项工作中，我们表明基于DICE的方法可以被视为从行为分布到最优策略分布的转换。基于此，我们提出了一种新的方法，扩散DICE，它直接使用扩散模型执行这种转换。我们发现最优策略的得分函数可以分解为两个项：行为策略的得分功能和取决于最优分配比的引导项的梯度。第一项可以从在数据集上训练的扩散模型中获得，我们提出了一个样本内学习目标来学习第二项。由于最优策略分布中包含的多模态，扩散DICE中的转换可能会引导这些局部最优模式。因此，我们生成了一些候选动作，并从中仔细选择以接近全局最优。与所有其他基于扩散的离线RL方法不同，该指南在扩散DICE中选择范式，只使用样本动作进行训练，并在值函数中带来最小的误差利用。我们使用一个diatic toycase示例来展示以前基于扩散的方法如何由于利用这些错误而无法生成最佳操作，以及扩散DICE如何成功避免这种情况。然后，我们在基准数据集上进行了广泛的实验，以展示Diffusion DICE的强大性能。 et.al.|[2407.20109](http://arxiv.org/abs/2407.20109)|null|
|**2024-07-29**|**Generative Diffusion Model Bootstraps Zero-shot Classification of Fetal Ultrasound Images In Underrepresented African Populations**|开发用于胎儿超声图像分析的强大深度学习模型需要全面、高质量的数据集，以有效地学习该领域内的信息数据表示。然而，标记超声图像的稀缺性带来了巨大的挑战，特别是在资源匮乏的环境中。为了应对这一挑战，我们利用合成数据来增强深度学习模型的泛化能力。本研究提出了一种基于扩散的方法，胎儿超声LoRA（FU-LoRA），该方法涉及使用LoRA技术微调潜在扩散模型以生成合成胎儿超声图像。这些合成图像被集成到一个混合数据集中，该数据集结合了真实世界和合成图像，以提高零样本分类器在低资源环境中的性能。我们对来自非洲队列的胎儿超声图像的实验结果表明，FU-LoRA的分类准确率比基线方法提高了13.73%。此外，FU-LoRA的准确率最高，为82.40%，F评分最高，为86.54%，AUC最高，为89.78%。这表明FU-LoRA方法在低资源环境下对胎儿超声图像进行零样本分类是有效的。我们的代码和数据可在以下网站上公开访问https://github.com/13204942/FU-LoRA. et.al.|[2407.20072](http://arxiv.org/abs/2407.20072)|null|
|**2024-07-29**|**ImagiNet: A Multi-Content Dataset for Generalizable Synthetic Image Detection via Contrastive Learning**|生成模型，如扩散模型（DM）、变分自编码器（VAE）和生成对抗网络（GAN），产生的图像具有一定程度的真实性，使其与真实照片和艺术品几乎无法区分。虽然这种能力对许多行业都有利，但识别合成图像的困难使在线媒体平台容易受到模仿和错误信息的攻击。为了支持防御方法的发展，我们引入了ImagiNet，这是一个用于合成图像检测的高分辨率和平衡的数据集，旨在减轻现有资源中的潜在偏差。它包含20万个示例，涵盖四个内容类别：照片、绘画、面部和未分类。合成图像是使用开源和专有生成器生成的，而相同内容类型的真实图像是从公共数据集中收集的。ImagiNet的结构允许双轨评估系统：i）分类为真实或合成，ii）识别生成模型。为了建立基线，我们为每条轨道使用自监督对比目标（SelfCon）训练ResNet-50模型。该模型在既定的基准测试中展示了最先进的性能和高推理速度，即使在涉及压缩和调整大小的社交网络条件下，AUC也达到了高达0.99的水平，平衡准确率在86%至95%之间。我们的数据和代码可在https://github.com/delyan-boychev/imaginet. et.al.|[2407.20020](http://arxiv.org/abs/2407.20020)|**[link](https://github.com/delyan-boychev/imaginet)**|

<p align=right>(<a href=#updated-on-20240731>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-07-29**|**Aero-Nef: Neural Fields for Rapid Aircraft Aerodynamics Simulations**|本文提出了一种基于隐式神经表示（INR）在网格域上学习稳态流体动力学模拟替代模型的方法。所提出的模型可以直接应用于不同流动条件下的非结构化域，处理非参数3D几何变化，并推广到测试时看不见的形状。基于坐标的公式自然会导致离散化的鲁棒性，从而在计算成本（内存占用和训练时间）和精度之间实现了极好的权衡。该方法在两个工业相关应用中得到了验证：跨音速翼型上二维可压缩流的RANS数据集和三维机翼上表面压力分布的数据集，包括形状、流入条件和控制表面偏转变化。在所考虑的测试用例中，与最先进的图神经网络架构相比，我们的方法实现了三倍多的测试误差，并显著改善了看不见的几何形状的泛化误差。值得注意的是，该方法在RANS跨音速翼型数据集上的推理速度比高保真求解器快五个数量级。代码可在以下网址获得https://gitlab.isae-supaero.fr/gi.catalani/aero-nepf et.al.|[2407.19916](http://arxiv.org/abs/2407.19916)|null|
|**2024-07-26**|**ObjectCarver: Semi-automatic segmentation, reconstruction and separation of 3D objects**|隐式神经场在从多幅图像重建3D表面方面取得了显著进展；然而，在分离场景中的单个对象时，他们遇到了挑战。之前的工作试图通过引入一个框架来解决这个问题，该框架为N个对象中的每一个同时训练单独的带符号距离场（SDF），并使用正则化项来防止对象重叠。然而，所有这些方法都需要提供分割掩模，这并不总是容易获得的。我们介绍了我们的方法ObjectCarver，来解决在单个视图中从点击输入中分离对象的问题。给定摆出的多视图图像和一组用户输入点击来提示分割单个对象，我们的方法将场景分解为单独的对象，并为每个对象重建高质量的3D表面。我们引入了一个损失函数，可以防止漂浮物，避免因遮挡而造成不适当的雕刻。此外，我们引入了一种新的场景初始化方法，与之前的方法相比，该方法在保留几何细节的同时显著加快了过程。尽管不需要地面真实掩模或单眼线索，但我们的方法在定性和定量上都优于基线。此外，我们引入了一个新的基准数据集进行评估。 et.al.|[2407.19108](http://arxiv.org/abs/2407.19108)|null|
|**2024-07-24**|**Neural field equations with time-periodic external inputs and some applications to visual processing**|这项工作的目的是为研究视觉处理任务中的闪烁输入提供一个数学框架。当与几何图案结合时，这些输入会影响并诱发有趣的心理物理现象，如麦凯效应和比洛克-邹效应，在这些效应中，受试者感知到通常由闪烁频率调制的特定余像。由于输入的对称破缺结构，经典分叉理论和多尺度分析技术在我们的背景下不是很有效。因此，我们采用了一种基于Amari型神经场控制理论的输入-输出框架的方法。这使我们能够证明，当受到周期性输入的驱动时，动态会收敛到周期性状态。此外，我们研究了在哪些假设下，这些非线性动力学可以有效地线性化，在这种情况下，我们提出了短程兴奋性和远程抑制性神经元相互作用的积分核的精确近似值。最后，对于集中在具有闪烁背景的视野中心的输入，我们直接将余像中出现的虚幻轮廓的宽度与闪烁频率和抑制强度联系起来。 et.al.|[2407.17294](http://arxiv.org/abs/2407.17294)|null|
|**2024-07-23**|**Fluorescence Diffraction Tomography using Explicit Neural Fields**|从荧光图像中求解3D折射率（RI）可以提供有关生物样本的荧光和相位信息。然而，在大体积、高分辨率和反射模式下准确检索部分相干光的相位以重建无标签相位物体的未知RI仍然具有挑战性。为了应对这一挑战，我们开发了具有显式神经场的荧光衍射断层扫描（FDT），可以从散焦荧光散斑图像重建3D RI。使用FDT成功重建3D RI依赖于四个关键组件：粗到细建模、自校准、差分多层渲染模型和部分相干掩模。具体而言，显式表示与粗到细建模有效地集成在一起，以实现高速、高分辨率的重建。此外，我们将多层方程推进到微分多层渲染模型，这使得系统的外部和内部参数能够进行自校准。自校准有助于高精度的正向图像预测和RI重建。部分相干掩模是数字掩模，用于准确有效地解决相干光模型和部分相干光数据之间的差异。FDT成功地从荧光图像中重建了24个z $层上1024$×1024像素的530$×530$×300$μm^3$ 体积的3D培养无标记3D MuSCs管的RI，证明了在体外对体积庞大和异质的生物样本进行高保真3D RI重建。 et.al.|[2407.16657](http://arxiv.org/abs/2407.16657)|null|
|**2024-07-22**|**Iterative approach to reconstructing neural disparity fields from light-field data**|本研究提出了一种神经视差场（NDF），该场基于神经场建立了场景视差的隐式连续表示，并采用迭代方法解决了从光场数据重建NDF的逆问题。NDF能够无缝和精确地表征三维场景中的视差变化，并可以以任何任意分辨率对视差进行离散化，克服了传统视差图容易出现采样误差和插值不准确的局限性。所提出的NDF网络架构利用哈希编码结合多层感知器来捕获纹理级别的详细差异，从而增强其表示复杂场景几何信息的能力。通过利用光场数据中固有的空间角度一致性，开发了一种可微分正向模型，用于从光场数据生成中心视图图像。基于正向模型，建立了一种使用可微传播算子的NDF重建逆问题的优化方案。此外，在优化方案中，采用迭代求解方法重建NDF，该方法不需要训练数据集，适用于各种采集方法捕获的光场数据。实验结果表明，使用所提出的方法可以从光场数据中重建高质量的NDF。NDF可以有效地恢复高分辨率视差，证明了其隐式、连续表示场景视差的能力。 et.al.|[2407.15380](http://arxiv.org/abs/2407.15380)|null|
|**2024-07-19**|**Contextual modulation of language comprehension in a dynamic neural model of lexical meaning**|我们提出并计算实现了一个词汇意义的动态神经模型，并对其行为预测进行了实验测试。我们使用英语词汇“have”作为测试用例来演示模型的架构和行为，重点关注其多义词的使用。在该模型中，“have”映射到由两个连续的概念维度（连通性和控制不对称性）定义的语义空间，这两个维度之前被提出用于参数化语言的概念系统。映射被建模为表示词条的神经节点和表示概念维度的神经场之间的耦合。虽然词汇知识被建模为稳定的耦合模式，但实时词汇意义检索被建模为神经激活模式在对应于语义解释或阅读的亚稳态之间的运动。模型模拟捕捉到了两个先前报道的实证观察结果：（1）词汇语义解释的语境调制，以及（2）这种调制幅度的个体差异。模拟还产生了一种新的预测，即句子阅读时间和可接受性之间的试验关系应该根据上下文进行调节。结合自定进度阅读和可接受性判断的实验复制了之前的结果，并证实了新的模型预测。总之，研究结果支持了一种关于词汇多义的新观点：一个词的许多相关含义是亚稳态的神经激活状态，这是由控制连续语义维度解释的神经群体的非线性动力学引起的。 et.al.|[2407.14701](http://arxiv.org/abs/2407.14701)|null|
|**2024-07-18**|**MeshFeat: Multi-Resolution Features for Neural Fields on Meshes**|参数特征网格编码作为神经场的编码方法受到了广泛关注，因为它们允许更小的MLP，这大大缩短了模型的推理时间。在这项工作中，我们提出了MeshFeat，这是一种针对网格量身定制的参数特征编码，为此我们采用了欧几里德空间的多分辨率特征网格的思想。我们从给定顶点拓扑提供的结构开始，使用网格简化算法直接在网格上构建多分辨率特征表示。该方法允许在网格上的神经场中使用小MLP，与之前的表示相比，我们显示出显著的加速，同时保持了纹理重建和BRDF表示的可比重建质量。鉴于其与顶点的内在耦合，该方法特别适用于变形网格上的表示，使其非常适合对象动画。 et.al.|[2407.13592](http://arxiv.org/abs/2407.13592)|null|
|**2024-07-16**|**Adaptive Environment-Aware Robotic Arm Reaching Based on a Bio-Inspired Neurodynamical Computational Framework**|仿生机器人系统具有自适应学习、可扩展控制和高效信息处理的能力。为这些系统提供实时决策对于应对环境的动态变化至关重要。我们专注于在开放区域使用带有鸟瞰摄像头的机器人六自由度操纵器进行动态目标跟踪，并部署神经动力学计算框架（NeuCF）进行视觉反馈。NeuCF是最近开发的一种基于动态神经场（DNF）和随机最优控制（SOC）理论的仿生目标跟踪模型。它已经过训练，可以在平面上对局部视觉信标进行到达动作，并且可以根据环境的变化（例如，出现了新的目标，或者删除了现有的目标）实时重新定位或生成停止信号。我们在各种目标达成场景下评估了我们的系统。在所有实验中，与基线三次多项式轨迹生成器相比，NeuCF具有较高的末端执行器位置精度，生成了平滑的轨迹，并提供了更短的路径长度。总之，开发的系统提供了一种强大的、动态感知的机器人操纵方法，可以提供实时决策。 et.al.|[2407.11377](http://arxiv.org/abs/2407.11377)|null|
|**2024-07-12**|**Physics-Informed Learning of Characteristic Trajectories for Smoke Reconstruction**|我们通过稀疏视图RGB视频深入研究了烟雾和障碍物的物理信息神经重建，解决了复杂动力学观测有限带来的挑战。现有的基于物理信息的神经网络通常强调短期物理约束，对长期守恒的适当保护探索较少。我们引入了神经特征轨迹场，这是一种利用欧拉神经场隐式建模拉格朗日流体轨迹的新表示方法。这种无拓扑、可自动微分的表示便于在任意帧之间进行高效的流图计算，以及通过自动微分进行高效的速度提取。因此，它实现了涵盖长期保护和短期物理先验的端到端监督。在此基础上，我们提出了基于物理的轨迹学习和集成到基于NeRF的场景重建中。我们通过自我监督的场景分解和无缝集成的边界约束来实现高级障碍物处理。我们的结果展示了克服遮挡不确定性、密度-颜色模糊性和静态-动态纠缠等挑战的能力。代码和示例测试位于\url{https://github.com/19reborn/PICT_smoke}. et.al.|[2407.09679](http://arxiv.org/abs/2407.09679)|**[link](https://github.com/19reborn/pict_smoke)**|
|**2024-07-10**|**Neural Localizer Fields for Continuous 3D Human Pose and Shape Estimation**|随着可用训练数据的爆炸性增长，单图像3D人体建模领先于向以数据为中心的范式过渡。成功利用数据规模的关键是设计灵活的模型，这些模型可以从不同研究人员或供应商生产的各种异构数据源进行监督。为此，我们提出了一种简单而强大的范式，用于无缝统一不同的人体姿势和形状相关的任务和数据集。我们的公式侧重于在训练和测试时查询人体体积的任意点并在3D中获得其估计位置的能力。我们通过学习身体点定位器函数的连续神经场来实现这一点，每个函数都是基于不同参数化的3D热图卷积点定位器（检测器）。为了生成参数输出，我们提出了一种高效的后处理步骤，用于将SMPL族身体模型拟合到非参数关节和顶点预测中。通过这种方法，我们可以自然地利用不同注释的数据源，包括网格、2D/3D骨架和密集姿势，而无需在它们之间进行转换，从而训练出大规模的3D人体网格和骨架估计模型，这些模型在3DPW、EMDB和SSP-3D等几个公共基准上的表现远远优于最先进的水平。 et.al.|[2407.07532](http://arxiv.org/abs/2407.07532)|null|

<p align=right>(<a href=#updated-on-20240731>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

