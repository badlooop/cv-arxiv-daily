[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.05.28
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#video-diffusion>Video Diffusion</a></li>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## Video Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-05-27**|**Dynamic-I2V: Exploring Image-to-Video Generation Models via Multimodal LLM**|图像到视频（I2V）生成的最新进展在传统场景中显示出有前景的性能。然而，在处理需要深入理解细微运动和复杂物体动作关系的复杂场景时，这些方法仍然面临着重大挑战。为了应对这些挑战，我们提出了Dynamic-I2V，这是一个创新的框架，它集成了多模态大型语言模型（MLLM），为扩散变换器（DiT）架构联合编码视觉和文本条件。通过利用MLLM的先进多模态理解能力，我们的模型显著提高了合成视频中的运动可控性和时间相干性。Dynamic-I2V固有的多模态进一步实现了对各种条件输入的灵活支持，将其适用性扩展到各种下游生成任务。通过系统分析，我们发现了当前I2V基准测试的一个关键局限性：由于运动复杂性和视觉质量指标之间的平衡不足，人们明显倾向于支持低动态视频。为了解决这一评估差距，我们提出了DIVE——一种专门为I2V生成中的综合动态质量测量而设计的新型评估基准。总之，大量的定量和定性实验证实，Dynamic-I2V在图像到视频生成方面达到了最先进的性能，特别是与现有方法相比，通过DIVE指标评估，动态范围、可控性和质量分别显著提高了42.5%、7.9%和11.8%。 et.al.|[2505.19901](http://arxiv.org/abs/2505.19901)|null|
|**2025-05-26**|**TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning**|为强化学习（RL）开发可扩展和可推广的奖励工程对于创建通用代理至关重要，特别是在具有挑战性的机器人操纵领域。虽然视觉语言模型（VLMs）在奖励工程方面的最新进展显示出了希望，但它们的稀疏奖励性质极大地限制了样本效率。本文介绍了TeViR，这是一种利用预训练的文本到视频扩散模型通过将预测的图像序列与当前观测值进行比较来生成密集奖励的新方法。11个复杂机器人任务的实验结果表明，TeViR优于利用稀疏奖励和其他最先进（SOTA）方法的传统方法，在没有地面真实环境奖励的情况下实现了更好的采样效率和性能。TeViR在复杂环境中高效引导代理的能力突显了其在机器人操纵中推进强化学习应用的潜力。 et.al.|[2505.19769](http://arxiv.org/abs/2505.19769)|null|
|**2025-05-26**|**DriveCamSim: Generalizable Camera Simulation via Explicit Camera Modeling for Autonomous Driving**|相机传感器模拟在自动驾驶（AD）中起着至关重要的作用，例如评估基于视觉的AD算法。虽然现有的方法利用生成模型来生成可控的图像/视频，但它们仍然局限于生成具有固定摄像机视点和视频频率的多视图视频序列，这大大限制了它们的下游应用。为了解决这个问题，我们提出了一个通用的相机仿真框架DriveCamSim，其核心创新在于提出的显式相机建模（ECM）机制。ECM不是通过普通注意力进行隐式交互，而是在多视图和多帧维度上建立明确的像素对应关系，使模型与训练数据中呈现的特定相机配置（内在/外在参数、视图数量）和时间采样率的过拟合解耦。对于可控生成，我们识别了现有条件编码和注入管道中固有的信息丢失问题，提出了一种信息保持控制机制。这种控制机制不仅提高了条件可控性，还可以扩展为身份感知，以增强前景对象渲染中的时间一致性。通过上述设计，我们的模型在视觉质量和可控性方面表现出卓越的性能，以及跨空间级（相机参数变化）和时间级（视频帧率变化）的泛化能力，从而能够根据不同的应用场景灵活定制用户可定制的相机模拟。代码可在以下网址获得https://github.com/swc-17/DriveCamSim以促进未来的研究。 et.al.|[2505.19692](http://arxiv.org/abs/2505.19692)|null|
|**2025-05-26**|**TDVE-Assessor: Benchmarking and Evaluating the Quality of Text-Driven Video Editing with LMMs**|文本驱动的视频编辑正在迅速发展，但由于缺乏能够辨别编辑质量细微差别的专用视频质量评估（VQA）模型，其严格的评估仍然具有挑战性。为了解决这一关键差距，我们引入了TDVE-DB，这是一个用于文本驱动视频编辑的大规模基准数据集。TDVE-DB由8个编辑类别的12个不同模型生成的3857个编辑视频组成，并沿三个关键维度（即编辑视频质量、编辑对齐和结构一致性）标注了173565个人类主观评分。基于TDVE-DB，我们首先对12种最先进的编辑模型进行了全面评估，揭示了当前视频技术的优缺点，然后在文本驱动视频编辑评估的背景下对现有的VQA方法进行了基准测试。基于这些见解，我们提出了TDVE Assessor，这是一种专门为文本驱动的视频编辑评估而设计的新型VQA模型。TDVE Assessor将空间和时间视频特征整合到一个大型语言模型（LLM）中，以获得丰富的上下文理解，从而提供全面的质量评估。广泛的实验表明，TDVE Assessor在所有三个评估维度上都大大优于TDVE-DB上的现有VQA模型，开创了新的最先进水平。TDVE-DB和TDVE Assessor将在发布后发布。 et.al.|[2505.19535](http://arxiv.org/abs/2505.19535)|null|
|**2025-05-26**|**The Role of Video Generation in Enhancing Data-Limited Action Understanding**|现实场景中的视频动作理解任务总是受到数据限制。在本文中，我们通过弥合数据稀缺来解决数据受限的行动理解问题。我们提出了一种新方法，该方法采用文本到视频扩散变换器来生成用于模型训练的带注释数据。这种范式能够在没有人为干预的情况下生成无限规模的真实注释数据。我们提出了信息增强策略和基于不确定性的标签平滑，以生成样本训练。通过定量和定性分析，我们观察到真实样本通常比生成的样本包含更丰富的信息。基于这一观察，提出了信息增强策略，从环境和特征两个方面增强生成样本的信息含量。此外，我们观察到，一些低质量生成的样本可能会对模型训练产生负面影响。为了解决这个问题，我们设计了基于不确定性的标签平滑策略，以增加这些样本的平滑度，从而减少它们的影响。我们在五个任务的四个数据集上证明了所提出方法的有效性，并实现了零样本动作识别的最先进性能。 et.al.|[2505.19495](http://arxiv.org/abs/2505.19495)|null|
|**2025-05-26**|**Force Prompting: Video Generation Models Can Learn and Generalize Physics-based Control Signals**|视频生成模型的最新进展引发了人们对能够模拟真实环境的世界模型的兴趣。虽然导航已经得到了很好的探索，但模拟现实世界力量的具有物理意义的交互在很大程度上仍然没有得到充分的研究。在这项工作中，我们研究了使用物理力作为视频生成的控制信号，并提出了力提示，使用户能够通过局部点力（如戳动植物）和全局风力场（如风吹过织物）与图像进行交互。我们证明，这些力提示可以通过利用原始预训练模型中的视觉和运动先验，使视频能够真实地响应物理控制信号，而无需在推理时使用任何3D资产或物理模拟器。力提示的主要挑战是难以获得高质量的成对力视频训练数据，无论是在现实世界中，由于难以获得力信号，还是在合成数据中，由于物理模拟器的视觉质量和领域多样性的限制。我们的主要发现是，当视频生成模型适应Blender合成的视频中的物理力条件时，即使对少数对象的演示有限，也可以很好地进行泛化。我们的方法可以生成模拟不同几何形状、设置和材料的力的视频。我们还试图了解这种泛化的来源，并进行消融，揭示两个关键要素：视觉多样性和训练过程中特定文本关键字的使用。我们的方法在四个A100 GPU上仅在一天内对约15k个训练示例进行训练，在力粘附和物理真实性方面优于现有方法，使世界模型更接近现实世界的物理交互。我们在项目页面上发布所有数据集、代码、权重和交互式视频演示。 et.al.|[2505.19386](http://arxiv.org/abs/2505.19386)|null|
|**2025-05-25**|**From Single Images to Motion Policies via Video-Generation Environment Representations**|自主机器人通常需要构建周围环境的表示，并使其运动适应环境的几何形状。在这里，我们解决了从单个输入RGB图像构建与环境一致的无碰撞运动生成策略模型的问题。从单个图像中提取3D结构通常涉及单眼深度估计。深度估计的发展催生了大型预训练模型，如DepthAnything。然而，由于产生的截头锥体形状误差，使用这些模型的输出进行下游运动生成具有挑战性。相反，我们提出了一种称为视频生成环境表示（VGER）的框架，该框架利用大规模视频生成模型的进步来生成基于输入图像的运动相机视频。然后，将形成多视图数据集的视频帧输入到预先训练的3D基础模型中，以生成密集的点云。然后，我们引入了一种多尺度噪声方法来训练环境结构的隐式表示，并构建了一个符合表示几何形状的运动生成模型。我们广泛评估了VGER在各种室内和室外环境中的表现。我们展示了它产生平滑运动的能力，这些运动可以解释场景的捕获几何形状，所有这些都来自单个RGB输入图像。 et.al.|[2505.19306](http://arxiv.org/abs/2505.19306)|null|
|**2025-05-25**|**SRDiffusion: Accelerate Video Diffusion Inference via Sketching-Rendering Cooperation**|利用扩散变换器（DiT）架构，Sora、CogVideoX和Wan等模型在文本到视频、图像到视频和视频编辑任务方面取得了显著进展。尽管取得了这些进步，但基于扩散的视频生成仍然是计算密集型的，特别是对于高分辨率、长持续时间的视频。先前的工作通过跳过计算来加速其推理，通常以严重的质量下降为代价。在本文中，我们提出了SRDiffusion，这是一种利用大型和小型模型之间的协作来降低推理成本的新框架。大模型处理高噪声步骤以确保语义和运动保真度（草图），而小模型在低噪声步骤中细化视觉细节（渲染）。实验结果表明，我们的方法优于现有的方法，Wan的加速超过3美元，VBench几乎没有质量损失，CogVideoX的加速为2美元。我们的方法被引入为与现有加速策略正交的新方向，为可扩展视频生成提供了一种实用的解决方案。 et.al.|[2505.19151](http://arxiv.org/abs/2505.19151)|null|
|**2025-05-25**|**WorldEval: World Model as Real-World Robot Policies Evaluator**|机器人领域在制定多面手机器人操作策略方面取得了重大进展。然而，在现实世界中评估这些政策仍然耗时且具有挑战性，特别是随着任务数量的增加和环境条件的变化。在这项工作中，我们证明了世界模型可以作为现实世界机器人政策评估的可扩展、可重复和可靠的代理。一个关键的挑战是从真实反映机器人行为的世界模型中生成准确的政策视频。我们观察到，直接输入机器人动作或使用高维编码方法往往无法生成动作跟踪视频。为了解决这个问题，我们提出了Policy2Vec，这是一种简单而有效的方法，可以将视频生成模型转化为世界模拟器，根据潜在动作生成机器人视频。然后，我们介绍WorldEval，这是一个自动化管道，旨在完全在线评估现实世界的机器人政策。WorldEval有效地将各种机器人策略和单个检查点排列在一个策略中，并充当安全检测器，以防止新开发的机器人模型的危险行为。通过对现实世界环境中操纵策略的全面配对评估，我们证明了WorldEval中的策略性能与现实世界场景之间存在很强的相关性。此外，我们的方法明显优于常用的方法，如real-to-sim方法。 et.al.|[2505.19017](http://arxiv.org/abs/2505.19017)|null|
|**2025-05-24**|**Sparse VideoGen2: Accelerate Video Generation with Sparse Attention via Semantic-Aware Permutation**|扩散变换器（DiTs）对于视频生成至关重要，但由于注意力的二次复杂性，存在明显的延迟。通过只计算关键令牌，稀疏注意力降低了计算成本，并提供了一种有前景的加速方法。然而，我们发现，在相同的计算预算下，现有方法无法达到最佳生成质量，原因有两个：（1）关键令牌识别不准确：当前方法基于位置而不是语义对令牌进行聚类，导致不精确的聚合表示。（2）计算浪费过多：关键令牌分散在非关键令牌中，导致GPU上的计算浪费，GPU针对处理连续令牌进行了优化。在本文中，我们提出了SVG2，这是一种无需训练的框架，可以最大限度地提高识别精度并减少计算浪费，实现发电质量和效率之间的帕累托前沿权衡。SVG2的核心是语义感知置换，它使用k-means基于语义相似性对标记进行聚类和重新排序。这种方法确保了精确的集群表示，提高了识别精度，并实现了关键令牌的加密布局，从而实现了无填充的高效计算。此外，SVG2集成了top-p动态预算控制和定制内核实现，在HunyuanVideo和Wan 2.1上分别实现了高达2.30倍和1.89倍的加速，同时保持了高达30和26的PSNR。 et.al.|[2505.18875](http://arxiv.org/abs/2505.18875)|null|

<p align=right>(<a href=#updated-on-20250528>back to top</a>)</p>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-05-26**|**ErpGS: Equirectangular Image Rendering enhanced with 3D Gaussian Regularization**|使用由360度相机获取的多视图图像可以重建具有宽区域的3D空间。基于NeRF和3DGS的等矩形图像三维重建方法，以及新颖的视图合成（NVS）方法。另一方面，当使用等矩形图像时，有必要克服由360度相机的投影模型引起的大失真。在基于3DGS的方法中，360度相机模型的大失真会产生极大的3D高斯分布，导致渲染精度差。我们提出了基于3DGS的全向GS ErpGS来实现NVS，以解决这些问题。ErpGS介绍了一些提高渲染精度的技术：几何正则化、尺度正则化、失真感知权重和掩模，以抑制等矩形图像中障碍物的影响。通过在公共数据集上的实验，我们证明ErpGS可以比传统方法更准确地渲染新的视图图像。 et.al.|[2505.19883](http://arxiv.org/abs/2505.19883)|null|
|**2025-05-26**|**Sparse2DGS: Sparse-View Surface Reconstruction using 2D Gaussian Splatting with Dense Point Cloud**|高斯散斑（GS）作为一种快速有效的新视图合成方法，引起了人们的关注。它也被应用于使用多视图图像的3D重建，可以实现快速准确的3D重建。然而，GS假设输入包含大量多视图图像，因此，当只有有限数量的输入图像可用时，重建精度会显著降低。主要原因之一是通过运动结构（SfM）获得的稀疏点云中的3D点数量不足，这导致优化高斯基元的初始化效果不佳。我们提出了一种新的3D重建方法，称为稀疏2DGS，可以在仅使用三幅图像重建物体时增强2DGS。Sparse2DGS采用立体图像的基本模型DUSt3R以及COLMAP MVS来生成高度精确和密集的3D点云，然后用于初始化2D高斯。通过在DTU数据集上的实验，我们表明Sparse2DGS可以使用三幅图像准确地重建物体的3D形状。 et.al.|[2505.19854](http://arxiv.org/abs/2505.19854)|null|
|**2025-05-26**|**GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis**|神经辐射场（NeRF）通过直接从图像中建模特定场景的体积表示，改变了新颖的视图合成。虽然可推广的NeRF模型可以通过学习潜在光线表示在未知场景中生成新的视图，但它们的性能在很大程度上取决于大量的多视图观测。然而，由于输入视图有限，这些方法的渲染质量会显著下降。为了解决这一局限性，我们提出了GoLF NRT：一种基于全局和局部特征融合的神经渲染变换器。GoLF NRT通过利用具有高效稀疏注意力的3D变换器来捕获全局场景上下文，从而增强了从少数输入视图进行的可泛化神经渲染。同时，它整合了沿极线提取的局部几何特征，从而能够从1到3个输入视图中进行高质量的场景重建。此外，我们引入了一种基于注意力权重和核回归的自适应采样策略，提高了基于变换器的神经渲染的准确性。在公共数据集上的广泛实验表明，GoLF NRT在不同数量的输入视图上实现了最先进的性能，突显了我们方法的有效性和优越性。代码可在以下网址获得https://github.com/KLMAV-CUC/GoLF-NRT. et.al.|[2505.19813](http://arxiv.org/abs/2505.19813)|null|
|**2025-05-26**|**Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction**|最近，通过在附近视图之间进行插值，可推广的新颖视图合成取得了令人印象深刻的质量。然而，由于需要对所有光线进行密集采样，渲染高分辨率图像仍然需要大量的计算。认识到自然场景通常是分段平滑的，对所有光线进行采样通常是多余的，我们提出了一种新的深度引导束采样策略来加速渲染。通过将相邻的光线分组到一个束中并集体采样，生成了一个共享表示，用于解码束中的所有光线。为了进一步优化效率，我们的自适应采样策略根据深度置信度动态分配样本，将更多样本集中在复杂区域，同时将它们减少到更平滑的区域。当应用于ENeRF时，我们的方法在DTU数据集上实现了高达1.27 dB的PSNR改善和47%的FPS提高。对合成和真实世界数据集的广泛实验表明，与现有的通用方法相比，渲染质量达到了最先进的水平，渲染速度提高了2倍。代码可在以下网址获得https://github.com/KLMAV-CUC/GDB-NeRF. et.al.|[2505.19793](http://arxiv.org/abs/2505.19793)|null|
|**2025-05-25**|**Improving Novel view synthesis of 360 $^\circ$ Scenes in Extremely Sparse Views by Jointly Training Hemisphere Sampled Synthetic Images**|从极其稀疏的输入视图在360°场景中进行新颖的视图合成对于虚拟现实和增强现实等应用至关重要。本文提出了一种在极稀疏视图情况下进行新颖视图合成的新框架。由于运动方法的典型结构无法在极其稀疏的视图情况下估计相机姿态，我们应用DUSt3R来估计相机姿态并生成密集的点云。使用估计的相机的姿态，我们从场景的上半球空间密集地采样额外的视图，从中我们与点云一起渲染合成图像。在稀疏视图的参考图像和密集采样的合成图像的组合上训练3D高斯散斑模型，可以在3D空间中实现更大的场景覆盖，解决稀疏视图情况下由于输入有限而导致的过拟合挑战。在我们创建的数据集上重新训练基于扩散的图像增强模型，我们通过消除伪影进一步提高了点云渲染图像的质量。我们在只有四个输入视图的情况下将我们的框架与基准方法进行了比较，证明了在360°场景的极稀疏视图条件下，新视图合成的显著改进。 et.al.|[2505.19264](http://arxiv.org/abs/2505.19264)|null|
|**2025-05-25**|**Triangle Splatting for Real-Time Radiance Field Rendering**|神经辐射场和3D高斯散斑等模型彻底改变了计算机图形学领域，取代三角形作为摄影测量的主要表示。在本文中，我们主张三角回归。我们开发了一种可微分渲染器，通过端到端梯度直接优化三角形。我们通过将每个三角形渲染为可微平面来实现这一点，将三角形的效率与基于独立基元的自适应表示密度相结合。与流行的2D和3D高斯散斑方法相比，我们的方法实现了更高的视觉保真度、更快的收敛速度和更高的渲染吞吐量。在Mip-NeRF360数据集上，我们的方法在视觉保真度方面优于并发的非体积基元，并在室内场景中实现了比最先进的Zip-NeRF更高的感知质量。三角形很简单，与标准图形堆栈和GPU硬件兼容，效率很高：对于\textit{Garden}场景，我们使用现成的网格渲染器以1280x720的分辨率实现了超过2400 FPS的帧率。这些结果突出了基于三角形表示的高质量新颖视图合成的效率和有效性。三角形通过将经典计算机图形学与现代可微渲染框架相结合，使我们更接近基于网格的优化。项目页面为https://trianglesplatting.github.io/ et.al.|[2505.19175](http://arxiv.org/abs/2505.19175)|null|
|**2025-05-25**|**Veta-GS: View-dependent deformable 3D Gaussian Splatting for thermal infrared Novel-view Synthesis**|最近，基于热红外（TIR）成像的3D高斯散斑（3D-GS）在新型视图合成中引起了人们的关注，显示了实时渲染。然而，使用热红外图像的新型视图合成存在透射效应、发射率和低分辨率的问题，导致渲染图像中出现浮动和模糊效应。为了解决这些问题，我们引入了Veta GS，它利用视图相关的变形场和热特征提取器（TFE）来精确捕获细微的热变化并保持鲁棒性。具体来说，我们设计了依赖于视图的变形场，该变形场利用相机位置和观察方向来捕捉热变化。此外，我们介绍了热特征提取器（TFE）和MonoSSIM损耗，它们考虑了外观、边缘和频率以保持鲁棒性。在TI-NSD基准上的大量实验表明，我们的方法比现有方法具有更好的性能。 et.al.|[2505.19138](http://arxiv.org/abs/2505.19138)|null|
|**2025-05-25**|**Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency**|我们介绍了一种新的几何引导的在线视频视图合成方法，该方法具有增强的视图和时间一致性。传统方法从密集的多视图相机设置中实现了高质量的合成，但需要大量的计算资源。相比之下，选择性输入方法降低了成本，但往往会影响质量，导致多视图和时间不一致，如闪烁伪影。我们的方法解决了这一挑战，即提供具有视图和时间一致性的高效、高质量的新颖视图合成。我们方法的关键创新在于使用全局几何来指导基于图像的渲染管道。为了实现这一点，我们随着时间的推移使用色差掩模逐步细化深度图。然后，这些深度图通过合成视图图像空间中的截断带符号距离场进行累积。这种深度表示是视图和时间一致的，用于指导预训练的混合网络，该网络融合了多个前向渲染的输入视图图像。因此，鼓励网络在多个视图和时间上输出几何一致的合成结果。我们的方法实现了一致的高质量视频合成，同时以在线方式高效运行。 et.al.|[2505.18932](http://arxiv.org/abs/2505.18932)|null|
|**2025-05-24**|**SuperGS: Consistent and Detailed 3D Super-Resolution Scene Reconstruction via Gaussian Splatting**|最近，3D高斯散斑（3DGS）以其实时渲染能力和卓越的质量在新颖视图合成（NVS）方面表现出色。然而，由于从低分辨率输入视图导出的基元的粗糙性质，它在高分辨率新颖视图合成（HRNVS）方面遇到了挑战。为了解决这个问题，我们提出了SuperGS，这是Scaffold GS的扩展，采用两阶段从粗到细的训练框架设计。在低分辨率阶段，我们引入了一个潜在的特征场来表示低分辨率场景，它既是超分辨率优化的初始化信息，也是基础信息。在高分辨率阶段，我们提出了一种多视图一致的致密化策略，该策略基于误差图对高分辨率深度图进行反投影，并采用多视图投票机制，减轻了2D先验模型提供的伪标签中多视图不一致引起的模糊性，同时避免了高斯冗余。此外，我们通过变分特征学习对不确定性进行建模，并利用它来指导进一步的场景表示细化，调整伪标签的监督效果，确保一致和详细的场景重建。大量实验表明，SuperGS在面向前和360度数据集上都优于最先进的HRNVS方法。 et.al.|[2505.18649](http://arxiv.org/abs/2505.18649)|null|
|**2025-05-23**|**CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting**|最近，高斯散斑方法已经成为现有辐射场方法的理想替代品，用于对用多视图图像或视频捕获的场景进行新颖的视图合成。在这项工作中，我们提出了一种针对动态场景的4D高斯散斑的新扩展。借鉴残差学习的思想，我们将动态场景分层分解为“视频片段帧”结构，片段由光流动态调整。然后，我们不是直接预测时间依赖信号，而是将信号建模为视频常数值、片段常数值和帧特定残差的总和，这是残差学习成功的启发。这种方法允许更灵活的模型适应高度可变的场景。我们在几个已建立的数据集上展示了最先进的视觉质量和实时渲染，在具有大运动、遮挡和精细细节的复杂场景中有最大的改进，而当前的方法在这些场景中退化最严重。 et.al.|[2505.18306](http://arxiv.org/abs/2505.18306)|null|

<p align=right>(<a href=#updated-on-20250528>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-05-26**|**OB3D: A New Dataset for Benchmarking Omnidirectional 3D Reconstruction Using Blender**|辐射场渲染的最新进展，以神经辐射场（NeRF）和3D高斯散斑（3DGS）为例，显著推进了3D建模和重建。由于在数据采集和全面场景捕捉方面的优势，在这些任务中使用多个360度全向图像越来越受到青睐。然而，常见全向表示中的固有几何失真，如等矩形投影（在极地地区特别严重，随纬度变化），对实现高保真3D重建构成了重大挑战。当前的数据集虽然有价值，但往往缺乏系统地基准测试和推动克服这些全向特定挑战所需的特定焦点、场景组成和地面真实粒度。为了解决这一关键差距，我们引入了全向Blender 3D（OB3D），这是一种新的合成数据集，旨在从多幅全向图像中推进3D重建。OB3D以Blender 3D项目生成的多样化和复杂的3D场景为特色，刻意强调具有挑战性的场景。该数据集提供了全面的地面实况，包括全向RGB图像、精确的全向相机参数以及深度和法线的像素对齐等矩形图，以及评估指标。通过提供一个受控但具有挑战性的环境，OB3D旨在促进对现有方法的严格评估，并促进新技术的发展，以提高从全向图像进行3D重建的准确性和可靠性。 et.al.|[2505.20126](http://arxiv.org/abs/2505.20126)|null|
|**2025-05-26**|**ErpGS: Equirectangular Image Rendering enhanced with 3D Gaussian Regularization**|使用由360度相机获取的多视图图像可以重建具有宽区域的3D空间。基于NeRF和3DGS的等矩形图像三维重建方法，以及新颖的视图合成（NVS）方法。另一方面，当使用等矩形图像时，有必要克服由360度相机的投影模型引起的大失真。在基于3DGS的方法中，360度相机模型的大失真会产生极大的3D高斯分布，导致渲染精度差。我们提出了基于3DGS的全向GS ErpGS来实现NVS，以解决这些问题。ErpGS介绍了一些提高渲染精度的技术：几何正则化、尺度正则化、失真感知权重和掩模，以抑制等矩形图像中障碍物的影响。通过在公共数据集上的实验，我们证明ErpGS可以比传统方法更准确地渲染新的视图图像。 et.al.|[2505.19883](http://arxiv.org/abs/2505.19883)|null|
|**2025-05-26**|**Sparse2DGS: Sparse-View Surface Reconstruction using 2D Gaussian Splatting with Dense Point Cloud**|高斯散斑（GS）作为一种快速有效的新视图合成方法，引起了人们的关注。它也被应用于使用多视图图像的3D重建，可以实现快速准确的3D重建。然而，GS假设输入包含大量多视图图像，因此，当只有有限数量的输入图像可用时，重建精度会显著降低。主要原因之一是通过运动结构（SfM）获得的稀疏点云中的3D点数量不足，这导致优化高斯基元的初始化效果不佳。我们提出了一种新的3D重建方法，称为稀疏2DGS，可以在仅使用三幅图像重建物体时增强2DGS。Sparse2DGS采用立体图像的基本模型DUSt3R以及COLMAP MVS来生成高度精确和密集的3D点云，然后用于初始化2D高斯。通过在DTU数据集上的实验，我们表明Sparse2DGS可以使用三幅图像准确地重建物体的3D形状。 et.al.|[2505.19854](http://arxiv.org/abs/2505.19854)|null|
|**2025-05-26**|**NeuSym-RAG: Hybrid Neural Symbolic Retrieval with Multiview Structuring for PDF Question Answering**|越来越多的学术论文对研究人员有效获取关键细节提出了重大挑战。虽然检索增强生成（RAG）在基于大型语言模型（LLM）的自动问答中显示出巨大的前景，但之前的工作往往将神经和符号检索隔离开来，尽管它们具有互补的优势。此外，传统的单视图分块忽略了PDF的丰富结构和布局，例如部分和表格。在这项工作中，我们提出了NeuSym-RAG，这是一种混合神经符号检索框架，它在一个交互过程中结合了这两种范式。通过利用多视图分块和基于模式的解析，NeuSym RAG将半结构化的PDF内容组织到关系数据库和向量库中，使LLM代理能够迭代地收集上下文，直到足以生成答案。在三个完整的基于PDF的QA数据集（包括一个自注释的AIRQA-REAL）上的实验表明，NeuSym RAG稳定地击败了基于向量的RAG和各种结构化基线，突出了其统一两种检索方案和利用多个视图的能力。代码和数据可在以下网址公开获取https://github.com/X-LANCE/NeuSym-RAG. et.al.|[2505.19754](http://arxiv.org/abs/2505.19754)|null|
|**2025-05-25**|**Staircase Recognition and Location Based on Polarization Vision**|楼梯是人工场景中最常见的结构之一。然而，如果没有传感器和智能算法的帮助，人形机器人和下肢残疾或视力受损的人很难穿过场景。楼梯场景感知技术是识别和定位的先决条件。该技术对于机器人的模式切换和足迹位置的计算以适应不连续的地形具有重要意义。然而，仍有许多问题限制了该技术的应用，例如识别精度低、传感器初始噪声高、输出信号不稳定和计算要求高。在场景重建方面，场景的双目和飞行时间（TOF）重建很容易受到环境光和目标物体表面材料的影响。相比之下，由于偏振器的特殊结构，偏振可以选择性地沿特定方向透射偏振光，这种重建方法依赖于物体表面的偏振信息。因此，偏振重建的优点得到了体现，它受环境光的影响较小，不依赖于物体表面的纹理信息。为了实现楼梯的检测，本文提出了一种结合偏振和光强信息的对比度增强算法，并基于YOLOv11集成了点云分割。为了实现高质量的重建，我们提出了一种融合偏振双目和TOF深度信息的方法，以实现楼梯的三维重建。此外，还提出了一种基于ICP配准的单目相机和TOF相机的联合校准算法和改进的灰狼优化算法。 et.al.|[2505.19026](http://arxiv.org/abs/2505.19026)|null|
|**2025-05-25**|**Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency**|我们介绍了一种新的几何引导的在线视频视图合成方法，该方法具有增强的视图和时间一致性。传统方法从密集的多视图相机设置中实现了高质量的合成，但需要大量的计算资源。相比之下，选择性输入方法降低了成本，但往往会影响质量，导致多视图和时间不一致，如闪烁伪影。我们的方法解决了这一挑战，即提供具有视图和时间一致性的高效、高质量的新颖视图合成。我们方法的关键创新在于使用全局几何来指导基于图像的渲染管道。为了实现这一点，我们随着时间的推移使用色差掩模逐步细化深度图。然后，这些深度图通过合成视图图像空间中的截断带符号距离场进行累积。这种深度表示是视图和时间一致的，用于指导预训练的混合网络，该网络融合了多个前向渲染的输入视图图像。因此，鼓励网络在多个视图和时间上输出几何一致的合成结果。我们的方法实现了一致的高质量视频合成，同时以在线方式高效运行。 et.al.|[2505.18932](http://arxiv.org/abs/2505.18932)|null|
|**2025-05-23**|**Canonical Pose Reconstruction from Single Depth Image for 3D Non-rigid Pose Recovery on Limited Datasets**|由于可能的变形范围很大，从2D输入进行3D重建，特别是对于像人类这样的非刚性物体，带来了独特的挑战。传统方法通常难以处理非刚性形状，这需要大量的训练数据来覆盖整个变形空间。本研究通过提出一种规范姿态重建模型来解决这些局限性，该模型将可变形形状的单视图深度图像转换为规范形式。这种对齐通过应用刚性对象重建技术来促进形状重建，并支持在重建任务中恢复体素表示中的输入姿态，同时利用原始和变形的深度图像。值得注意的是，我们的模型仅使用约300个样本的小数据集就取得了有效的结果。动物和人类数据集的实验结果表明，我们的模型优于其他最先进的方法。 et.al.|[2505.17992](http://arxiv.org/abs/2505.17992)|null|
|**2025-05-23**|**Is Single-View Mesh Reconstruction Ready for Robotics?**|本文评估了用于在机器人操作中创建数字孪生环境的单视图网格重建模型。从单个视点进行3D重建的计算机视觉的最新进展为有效地为机器人环境创建物理环境的虚拟副本提供了潜在的突破。然而，它们对物理模拟和机器人应用的适用性仍未得到探索。我们为机器人环境中的3D重建建立了基准标准，包括处理典型输入、生成无碰撞和稳定的重建、管理遮挡和满足计算约束。我们使用真实的机器人数据集进行的实证评估表明，尽管在计算机视觉基准测试中取得了成功，但现有的方法无法满足机器人的特定要求。与之前侧重于多视图方法的工作相比，我们定量研究了单视图重建在实际机器人实现中的局限性。我们的研究结果突出了计算机视觉进步和机器人需求之间的关键差距，指导了这一交叉领域的未来研究。 et.al.|[2505.17966](http://arxiv.org/abs/2505.17966)|null|
|**2025-05-23**|**Towards Dynamic 3D Reconstruction of Hand-Instrument Interaction in Ophthalmic Surgery**|手和仪器的精确3D重建对于眼科显微手术的视觉分析至关重要，但由于缺乏逼真的大规模数据集和可靠的注释工具，进展受到了阻碍。在这项工作中，我们介绍了OphNet-3D，这是第一个用于眼科手术的广泛的RGB-D动态3D重建数据集，由40名外科医生的41个序列组成，总计710万帧，对12个手术阶段、10个器械类别、密集的MANO手部网格和完整的6-DoF器械姿势进行了精细注释。为了可扩展地生成高保真标签，我们设计了一个多阶段自动注释管道，该管道集成了多视图数据观察、数据驱动的运动先验、交叉视图几何一致性和生物力学约束，以及用于仪器交互的碰撞感知交互约束的组合。在OphNet-3D的基础上，我们建立了两个具有挑战性的基准——双手姿势估计和手-仪器交互重建，并提出了两个专用架构：用于双手网格恢复的H-Net和用于双手-双手-仪器交互联合重建的OH-Net。这些模型利用了一种新颖的空间推理模块，该模块具有弱透视相机建模和基于碰撞感知中心的表示。这两种架构都远远优于现有方法，分别在手部和仪器重建的平均每关节位置误差（MPJPE）方面提高了2mm以上，在ADD-S指标方面提高了23%。 et.al.|[2505.17677](http://arxiv.org/abs/2505.17677)|null|
|**2025-05-23**|**From Flight to Insight: Semantic 3D Reconstruction for Aerial Inspection via Gaussian Splatting and Language-Guided Segmentation**|高保真3D重建对于基础设施监测、结构评估和环境测量等航空检查任务至关重要。虽然传统的摄影测量技术能够进行几何建模，但它们缺乏语义可解释性，限制了它们在自动化检测工作流程中的有效性。神经渲染和3D高斯散斑（3DGS）的最新进展提供了高效、逼真的重建，但同样缺乏场景级的理解。在这项工作中，我们提出了一种基于无人机的管道，该管道扩展了Feature-3DGS，用于语言引导的3D分割。我们利用基于LSeg的特征字段和CLIP嵌入来生成热图，以响应语言提示。这些被阈值化以产生粗略的分割，然后将最高得分点用作SAM或SAM2的提示，以便在新颖的视图渲染上进行精细的2D分割。我们的研究结果突出了各种特征场主干（CLIP-LSeg、SAM、SAM2）在捕捉大规模室外环境中有意义结构方面的优势和局限性。我们证明，这种混合方法能够与逼真的3D重建进行灵活的、语言驱动的交互，为语义航空检查和场景理解开辟了新的可能性。 et.al.|[2505.17402](http://arxiv.org/abs/2505.17402)|null|

<p align=right>(<a href=#updated-on-20250528>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-05-26**|**HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters**|近年来，音频驱动的人体动画取得了重大进展。然而，关键的挑战仍然存在于（i）生成高度动态的视频，同时保持角色的一致性，（ii）实现角色和音频之间的精确情感对齐，以及（iii）实现多角色音频驱动的动画。为了应对这些挑战，我们提出了HunyuanVideo Avatar，这是一种基于多模态扩散变换（MM-DiT）的模型，能够同时生成动态、情绪可控和多字符对话视频。具体来说，Hunyuan Video Avatar引入了三个关键创新：（i）设计了一个字符图像注入模块，以取代传统的基于加法的字符调节方案，消除了训练和推理之间固有的条件不匹配。这保证了动态运动和强烈的人物一致性；（ii）引入音频情感模块（AEM），以从情感参考图像中提取情感线索并将其传输到目标生成的视频中，从而实现细粒度和准确的情感风格控制；（iii）提出了一种面部感知音频适配器（FAA），用于将音频驱动的角色与潜在级别的面罩隔离开来，从而在多角色场景中通过交叉注意力实现独立的音频注入。这些创新使浑源视频化身超越了基准数据集和新提出的野生数据集上的最先进方法，在动态、沉浸式场景中生成逼真的化身。 et.al.|[2505.20156](http://arxiv.org/abs/2505.20156)|null|
|**2025-05-26**|**On the chaos induced by the Galactic bar on the orbits of nearby halo stars**|银河系的许多吸积子结构已在能量 $E$、角动量分量$L_z$和$L_{\bot}$的空间中被发现和研究。在静态轴对称系统中，这些量是轨道运动的积分（合理的近似值）。然而，在像银河系这样具有三轴旋转杆的星系中，这些量都不守恒，唯一已知的积分是雅可比能量$E_J$。这可能会导致轨道混乱，特别是对于内晕恒星。在这里，我们研究了条对附近晕星动力学的影响，更具体地说，它对它们在$（E，L_z，L_{\bot}）$空间中的分布的影响。为此，我们整合并表征了距离太阳1kpc以内的晕星的轨道。我们计算了它们的轨道频率，并使用李雅普诺夫指数和频率扩散率量化了混沌程度和相关的时间尺度。我们发现，该条在我们的样本中的恒星上引入了很大程度的混沌性：发现超过一半的恒星处于混沌轨道上，对于处于非常束缚和/或径向轨道上的恒星，这一比例最高。这些恒星在比哈勃时间更短的时间尺度上在$（E，L_z，L_{\bot}）$空间中徘徊。这引入了一些重叠，从而在先前确定的具有这些轨道特征的吸积子结构之间造成了污染，尽管我们的评估是这相对有限。该条还引起了恒星晕中的许多共振，这对较低倾角的顺行轨道更为重要。由于银河系条对局部晕的影响对于处于非常束缚和/或径向轨道的恒星很重要，因此在这些区域进行聚类分析时应该小心。在这种分析中用$E_J$ 代替能量可能是一种改进。 et.al.|[2505.20143](http://arxiv.org/abs/2505.20143)|null|
|**2025-05-26**|**MolEditRL: Structure-Preserving Molecular Editing via Discrete Diffusion and Reinforcement Learning**|分子编辑旨在修改给定的分子，以优化所需的化学性质，同时保持结构相似性。然而，目前的方法通常依赖于基于字符串或连续的表示，这无法充分捕捉分子的离散、图形结构的性质，导致结构保真度有限，可控性差。在这篇论文中，我们提出了MolEditRL，这是一个分子编辑框架，它明确地将结构约束与精确的属性优化相结合。具体来说，MolEditRL包括两个阶段：（1）预训练的离散图扩散模型，用于重建基于源结构和自然语言指令的目标分子；（2）一个具有编辑意识的强化学习微调阶段，通过在图约束下明确优化编辑决策，进一步增强属性对齐和结构保存。为了进行全面评估，我们构建了MolEdit Instruct，这是最大、属性最丰富的分子编辑数据集，包含300万个不同的示例，涵盖10个化学属性的单属性和多属性任务。实验结果表明，MolEditRL在属性优化精度和结构保真度方面明显优于最先进的方法，在使用更少98%的参数的同时，编辑成功率提高了74%。 et.al.|[2505.20131](http://arxiv.org/abs/2505.20131)|null|
|**2025-05-26**|**Understanding Generalization in Diffusion Models via Probability Flow Distance**|扩散模型已经成为一类强大的生成模型，能够生成高质量的样本，其泛化能力超越了训练数据。然而，评估这种泛化仍然具有挑战性：理论度量对于高维数据来说往往不切实际，而没有实际度量严格衡量泛化。在这项工作中，我们通过引入概率流距离（ $\texttt{PFD}$）来弥合这一差距，这是一种理论上有根据且计算效率高的度量来衡量分布泛化。具体来说，$\texttt{PFD}$通过将分布的噪声与概率流ODE引起的数据映射进行比较来量化分布之间的距离。此外，通过在师生评估协议下使用$\texttt{PFD}$ ，我们实证发现了扩散模型中的几个关键泛化行为，包括：（1）从记忆到泛化的缩放行为，（2）早期学习和双下降训练动态，以及（3）偏差方差分解。除了这些见解，我们的工作为未来关于扩散模型泛化的实证和理论研究奠定了基础。 et.al.|[2505.20123](http://arxiv.org/abs/2505.20123)|null|
|**2025-05-26**|**Refining Few-Step Text-to-Multiview Diffusion via Reinforcement Learning**|从单个文本提示生成连贯多视图图像的文本到多视图（T2MV）生成仍然是计算密集型的，而使用少步扩散模型的加速T2MV方法通常会牺牲图像保真度和视图一致性。为了解决这个问题，我们提出了一种新的强化学习（RL）微调框架，专为单步T2MV扩散模型量身定制，以联合优化每视图保真度和跨视图一致性。具体来说，我们首先将所有视图的T2MV去噪重新表述为一个统一的马尔可夫决策过程，从而实现了由联合视图奖励目标驱动的多视图感知策略优化。接下来，我们介绍ZMV采样，这是一种测试时间T2MV采样技术，它添加了一个反转去噪过程来加强视点和文本条件，从而以牺牲推理时间为代价改进了T2MV的生成。为了将其性能增益内化到基础采样策略中，我们开发了MV-ZigAL，这是一种新的策略优化策略，它利用ZMV采样相对于标准采样的奖励优势作为策略更新的学习信号。最后，注意到联合视图奖励目标未充分优化每视图保真度，但天真地优化单视图度量忽略了跨视图对齐，我们将T2MV扩散模型的RL微调重新定义为一个约束优化问题，在明确的联合视图约束下使每视图保真度最大化，从而实现更有效和平衡的策略更新。通过将这种约束优化范式与MV-ZigAL集成，我们建立了完整的RL微调框架，称为MVC-ZigAL，该框架在保真度和一致性方面有效地改进了少步T2MV扩散基线，同时保持了其少步效率。 et.al.|[2505.20107](http://arxiv.org/abs/2505.20107)|null|
|**2025-05-26**|**SwarmThinkers: Learning Physically Consistent Atomic KMC Transitions at Scale**|一个科学模拟系统能否在物理上保持一致，可以通过设计进行解释，并且可以在不同的制度下同时扩展？尽管取得了几十年的进展，但这三者仍然难以捉摸。动力学蒙特卡罗等经典方法确保了热力学精度，但规模较差；基于学习的方法提供了效率，但往往牺牲了物理一致性和可解释性。我们提出了SwarmThinkers，这是一个强化学习框架，它将原子尺度模拟重塑为一个物理上基于群体智能的系统。每个扩散粒子都被建模为一个局部决策代理，该代理通过在热力学约束下训练的共享策略网络选择转换。重新加权机制将学习到的偏好与转换率融合在一起，在保持统计保真度的同时，实现了可解释的逐步决策。培训遵循集中培训、分散执行的范式，允许政策在不进行再培训的情况下跨系统规模、浓度和温度进行推广。在模拟辐射诱导的铁铜合金沉淀的基准测试中，SwarmThinkers是第一个在单个A100 GPU上实现全面、物理一致模拟的系统，以前只能通过超级计算机上的OpenKMC实现。它的计算速度高达4963x（平均3185倍），内存使用率低485x。通过将粒子视为决策者，而不是被动的采样器，SwarmThinkers标志着科学模拟的范式转变——通过代理驱动的智能将物理一致性、可解释性和可扩展性统一起来。 et.al.|[2505.20094](http://arxiv.org/abs/2505.20094)|null|
|**2025-05-26**|**Crystallographic control of hydrogen ingress in bcc-Iron: Insights from ab initio simulations**|氢吸收到体心立方（bcc）铁中是随后氢脆的根本原因，是从表面开始的。在本文中，我们量化了H从表面扩散到体中的容易程度。我们考虑了一组低指数、邻近和一般的铁表面，并将氢渗透视为一个两步过程。首先，密度泛函计算确定了孤立H原子在每个晶体学上不同的表面位置的吸附能。其次，对于每个吸附位点，我们绘制了将原子带到表面下方并进入晶格的最小能量路径。在所研究的所有十个方向上，出现了一个明显的趋势：结合氢最弱（吸附能最高）的位点是进入金属内部的最低势垒扩散通道的起点。因此，最不利的吸附袋充当了有效地下渗透的门户。这些见解提供了一个实用的设计规则：通过适当的表面纹理或取向控制来抑制或尽量减少这种高能吸附基序的暴露，应使bcc铁部件不易吸收氢气和相关的脆化。 et.al.|[2505.20071](http://arxiv.org/abs/2505.20071)|null|
|**2025-05-26**|**PAMD: Plausibility-Aware Motion Diffusion Model for Long Dance Generation**|计算舞蹈生成在许多领域都至关重要，如艺术、人机交互、虚拟现实和数字娱乐，特别是在生成连贯和富有表现力的长舞蹈序列方面。基于扩散的音乐到舞蹈生成已经取得了重大进展，但现有的方法仍然难以产生物理上合理的动作。为了解决这个问题，我们提出了合理性感知运动扩散（PAMD），这是一个用于生成音乐上一致且物理上逼真的舞蹈的框架。PAMD的核心在于合理运动约束（PMC），它利用神经距离场（NDF）对实际姿态流形进行建模，并将生成的运动引导到物理上有效的姿态流形。为了在生成过程中提供更有效的指导，我们引入了先验运动指导（PMG），它使用站立姿势作为音乐功能的辅助条件。为了进一步增强复杂动作的真实感，我们引入了脚-地面接触运动细化（MRFC）模块，该模块通过弥合线性关节位置空间中的优化目标与非线性旋转空间中的数据表示之间的差距来解决脚滑伪影问题。大量实验表明，PAMD显著改善了音乐对齐，并提高了所生成动作的物理合理性。此项目页面可在以下网址获得：https://mucunzhuzhu.github.io/PAMD-page/. et.al.|[2505.20056](http://arxiv.org/abs/2505.20056)|null|
|**2025-05-26**|**Multimodal LLM-Guided Semantic Correction in Text-to-Image Diffusion**|扩散模型已成为文本到图像生成的主流架构，在视觉质量和即时可控性方面取得了显著进展。然而，目前的推理管道在整个去噪过程中通常缺乏可解释的语义监督和纠正机制。大多数现有方法仅依赖于最终图像的事后评分、提示过滤或启发式重采样策略，这使得它们在为纠正生成轨迹提供可操作的指导方面无效。因此，模型经常遭受对象混淆、空间错误、计数不准确和语义元素缺失的困扰，严重影响了即时图像对齐和图像质量。为了应对这些挑战，我们提出了MLLM语义校正乒乓球先行扩散（PPAD），这是一种新的框架，首次引入了多模态大语言模型（MLLM）作为推理过程中的语义观察者。PPAD对中间代进行实时分析，识别潜在的语义不一致，并将反馈转化为可控信号，积极指导剩余的去噪步骤。该框架支持纯推理和训练增强设置，并且仅在极少数扩散步骤中执行语义校正，具有很强的通用性和可扩展性。大量实验证明了PPAD的显著改进。 et.al.|[2505.20053](http://arxiv.org/abs/2505.20053)|null|
|**2025-05-26**|**Graph Wave Networks**|动力学建模已被引入作为图神经网络（GNN）消息传递（MP）的一种新范式。现有的方法将节点之间的MP视为一个热扩散过程，并利用热方程来模拟嵌入空间中节点的时间演化。然而，在图形信号处理中，热方程很难描述图形信号的波动性质。此外，热方程本质上是一个涉及时间一阶偏导数的偏微分方程（PDE），其数值解通常稳定性较低，导致模型训练效率低下。在本文中，我们想在MP中描述更多的波细节，因为图信号本质上是波信号，可以看作是特征向量形式的一系列波的叠加。这促使我们将MP视为一个波传播过程，以捕捉空间中波信号的时间演变。基于物理学中的波动方程，我们创新性地开发了一个图形波动方程，以利用图形上的波动传播。详细地说，我们证明了图波方程可以连接到传统的谱GNN，促进了基于各种拉普拉斯算子的图波网络的设计，并提高了谱GNN的性能。此外，图波动方程特别是一个涉及时间二阶偏导数的偏微分方程，它在图上的稳定性比涉及时间一阶偏微分的热方程更强。此外，我们从理论上证明了从图波动方程导出的数值解是恒定稳定的，能够在保证其性能的同时显著提高模型效率。大量实验表明，GWN在基准数据集上实现了SOTA和高效性能，并在解决具有挑战性的图问题（如过度平滑和异质性）方面表现出色。 et.al.|[2505.20034](http://arxiv.org/abs/2505.20034)|null|

<p align=right>(<a href=#updated-on-20250528>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-05-26**|**FruitNeRF++: A Generalized Multi-Fruit Counting Method Utilizing Contrastive Learning and Neural Radiance Fields**|我们介绍了FruitNeRF++，这是一种新的水果计数方法，将对比学习与神经辐射场相结合，从果园的非结构化输入照片中计数水果。我们的工作基于FruitNeRF，它采用神经语义场结合水果特定的聚类方法。每种水果类型的适应性要求限制了该方法的适用性，使其难以在实践中使用。为了消除这一限制，我们设计了一个与形状无关的多水果计数框架，该框架用视觉基础模型预测的实例掩码来补充RGB和语义数据。掩码用于将每个水果的身份编码为实例嵌入到神经实例字段中。通过对神经场进行体积采样，我们提取了一个嵌入实例特征的点云，该点云可以以与水果无关的方式进行聚类，以获得水果数量。我们使用包含苹果、李子、柠檬、梨、桃子和芒果的合成数据集以及真实世界的基准苹果数据集来评估我们的方法。我们的研究结果表明，FruitNeRF++更容易控制，与其他最先进的方法相比具有优势。 et.al.|[2505.19863](http://arxiv.org/abs/2505.19863)|null|
|**2025-05-26**|**K-Buffers: A Plug-in Method for Enhancing Neural Fields with Multiple Buffers**|神经领域现在是3D视觉和计算机图形学研究的中心焦点。现有的方法主要集中在各种场景表示上，如神经点和3D高斯。然而，很少有人研究渲染过程来增强神经场。在这项工作中，我们提出了一种名为K-Buffers的插件方法，该方法利用多个缓冲区来提高渲染性能。我们的方法首先从场景表示中渲染K个缓冲区，并构建K个像素级特征图。然后，我们引入了一个K特征融合网络（KFN）来合并K个像素的特征图。最后，我们采用特征解码器来生成渲染图像。我们还引入了一种加速策略来提高渲染速度和质量。我们将我们的方法应用于众所周知的辐射场基线，包括神经点场和3D高斯散斑（3DGS）。大量实验表明，我们的方法有效地提高了神经点场和3DGS的渲染性能。 et.al.|[2505.19564](http://arxiv.org/abs/2505.19564)|null|
|**2025-05-24**|**The Kinetic Limit of Balanced Neural Networks**|平衡神经网络理论是对大脑活动高度可变性和随机性的一种非常流行的解释。粗略地说，它意味着典型的神经元接收许多兴奋性和抑制性输入。网络范围内的平均输入相互抵消，剩下的是平均值的随机波动。本文确定了描述种群密度的动力学方程。内在动力学是非线性的，乘性噪声扰乱了每个神经元的状态。这些方程具有空间维度，因此神经元之间的连接强度是它们空间位置的函数。我们的证明方法是将状态变量分解为（i）网络范围内的平均活动，以及（ii）该平均值的波动。在极限中，我们确定了两个耦合的极限方程。系统平衡的要求产生了平均活动演变的隐式方程。在大的n极限下，波动的种群密度根据福克-普朗克方程演变。如果再假设内在动力学是线性的，噪声不是乘法的，那么就得到了一个空间分布的神经场方程。 et.al.|[2505.18481](http://arxiv.org/abs/2505.18481)|null|
|**2025-05-25**|**Stochastic collocation schemes for Neural Field Equations with random data**|我们开发并分析了神经场方程中不确定性量化的数值方案，该方案受突触核、放电率、外部刺激和初始条件中的随机参数数据的影响。这些方案将用于空间离散化的通用投影方法与用于随机变量的随机配置方案相结合。我们研究了算子形式的问题，并根据空间投影仪推导了方案总误差的估计。我们给出了保证半离散解作为Banach值函数的可分析性的投影随机数据的条件。我们说明了如何从分析随机数据和空间投影的选择开始验证假设。我们提供的证据表明，在线性和非线性神经场问题的各种数值实验中都发现了预测的收敛速度。 et.al.|[2505.16443](http://arxiv.org/abs/2505.16443)|null|
|**2025-05-25**|**Neural Field Equations with random data**|我们研究了神经场方程，这是受随机数据影响的大规模皮层活动的原型模型。我们将这个空间扩展的非局部演化方程视为抽象Banach空间上的柯西问题，突触核、放电率函数、外部刺激和初始条件具有随机性。我们确定了随机数据上的条件，这些条件保证了解在适当的Banach空间中的存在性、唯一性和可测性，并检验了解相对于输入规律性的规律性。我们给出了线性和非线性神经场的结果，以及该问题数值分析中最常见的两种函数设置的结果。除了连续性问题，我们还以抽象形式分析了空间离散的神经场，为分析不确定性量化（UQ）方案奠定了基础。 et.al.|[2505.16343](http://arxiv.org/abs/2505.16343)|null|
|**2025-05-21**|**Equivariant Eikonal Neural Networks: Grid-Free, Scalable Travel-Time Prediction on Homogeneous Spaces**|我们介绍了一种将等变神经场（ENF）与神经Eikonal求解器集成在一起的新框架——等变神经Eikonals求解器。我们的方法采用了一个单一的神经场，其中统一的共享骨干网以信号特定的潜在变量（表示为李群中的点云）为条件，来模拟不同的Eikonal解。ENF集成确保了从这些潜在表示到解域的等变映射，提供了三个关键好处：通过权重共享提高表示效率、稳健的几何基础和解的可操纵性。这种可操纵性允许应用于潜在点云的变换，以在最终的Eikonal解中引起可预测的、具有几何意义的修改。通过将这些可操纵表示与物理知情神经网络（PINN）耦合，我们的框架准确地模拟了Eikonal旅行时间解，同时推广到具有正则群作用的任意黎曼流形。这包括齐次空间，如欧几里德、位置定向、球面和双曲流形。我们通过在二维和三维基准数据集的地震走时建模中的应用来验证我们的方法。实验结果表明，与现有的基于神经算子的Eikonal求解器方法相比，该方法具有更优的性能、可扩展性、适应性和用户可控性。 et.al.|[2505.16035](http://arxiv.org/abs/2505.16035)|null|
|**2025-05-20**|**Neural Inverse Scattering with Score-based Regularization**|从显微镜到遥感，逆散射是许多成像应用中的一个基本挑战。解决这个问题通常需要联合估计两个未知数——图像和物体内部的散射场——在正则化推理之前需要有效的图像。本文提出了一种正则化神经场（NF）方法，该方法集成了基于分数的生成模型中使用的去噪分数函数。神经场公式为执行联合估计提供了方便的灵活性，而去噪得分函数则赋予了图像丰富的结构先验。我们在三个高对比度模拟对象上的结果表明，与最先进的NF方法相比，所提出的方法产生了更好的成像质量，其中正则化基于总变差。 et.al.|[2505.14560](http://arxiv.org/abs/2505.14560)|null|
|**2025-05-20**|**Ergodicity for stochastic neural field equations**|我们研究了在可能无界域上具有高斯噪声的一般连续神经场模型的适定性和长期行为。特别是，我们通过将解流限制在具有非局部度量的不变子空间中，给出了不变概率测度存在的条件。在假设相对于噪声强度有足够大的衰减参数、连通核的增长和激活函数的Lipschitz正则性的情况下，我们建立了相关Markovian-Feller半群的指数遍历性和指数混合性，以及具有二阶矩的不变测度的唯一性。 et.al.|[2505.14012](http://arxiv.org/abs/2505.14012)|null|
|**2025-05-19**|**Direction-Aware Neural Acoustic Fields for Few-Shot Interpolation of Ambisonic Impulse Responses**|声场的特征与声源和听众周围环境的几何和空间特性有着内在的联系。声音传播的物理过程被捕获在称为房间脉冲响应（RIR）的时域信号中。之前使用神经场（NF）的工作允许从有限的RIR测量中学习RIR的空间连续表示。然而，之前基于NF的方法主要关注单声道全向或最多双耳听众，这并不能精确地捕捉到单个点处真实声场的方向特性。我们提出了一种方向感知神经场（DANF），它通过Ambisonic格式的RIR更明确地结合了方向信息。虽然DANF固有地捕捉了源和听众之间的空间关系，但我们进一步提出了一种方向感知损失。此外，我们还研究了DANF以各种方式适应新房间的能力，包括低等级适应。 et.al.|[2505.13617](http://arxiv.org/abs/2505.13617)|null|
|**2025-05-19**|**Neural Functional: Learning Function to Scalar Maps for Neural PDE Surrogates**|近年来，已经提出了许多神经PDE替代物的架构，主要基于神经网络或算子学习。在这项工作中，我们推导并提出了一种新的架构，即神经泛函，它学习函数到标量的映射。它的实现利用了算子学习和神经场的见解，我们展示了神经泛函隐式学习函数导数的能力。这是第一次通过学习哈密顿泛函并优化其泛函导数，将哈密顿力学扩展到神经PDE替代物。我们证明了哈密顿神经泛函可以通过提高1D和2D PDE的稳定性和守恒类能量来成为一种有效的替代模型。除了偏微分方程，泛函在物理学中也很普遍；函数逼近及其梯度学习可能还有其他用途，例如在分子动力学或设计优化中。 et.al.|[2505.13275](http://arxiv.org/abs/2505.13275)|**[link](https://github.com/anthonyzhou-1/hamiltonian_pdes)**|

<p align=right>(<a href=#updated-on-20250528>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

