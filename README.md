[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.07.22
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-07-19**|**SparseCraft: Few-Shot Neural Reconstruction through Stereopsis Guided Geometric Linearization**|我们提出了一种从少数彩色图像中恢复3D形状和视图相关外观的新方法，实现了高效的3D重建和新颖的视图合成。我们的方法以符号距离函数（SDF）和辐射场的形式学习隐式神经表示。该模型通过支持光线行进的体积渲染逐步训练，并使用无需学习的多视图立体（MVS）线索进行正则化。我们贡献的关键是一种新的隐式神经形状函数学习策略，该策略鼓励我们的SDF场在水平集附近尽可能线性，从而使训练对监督和正则化信号发出的噪声具有鲁棒性。在不使用任何预训练先验的情况下，我们的方法SparseCraft在新的视图合成和标准基准中从稀疏视图重建方面都达到了最先进的性能，同时只需要不到10分钟的训练时间。 et.al.|[2407.14257](http://arxiv.org/abs/2407.14257)|null|
|**2024-07-19**|**Mono-ViFI: A Unified Learning Framework for Self-supervised Single- and Multi-frame Monocular Depth Estimation**|自监督单目深度估计引起了人们的极大兴趣，因为它可以将训练从对深度注释的依赖中解放出来。在单目视频训练的情况下，最近的方法只在现有的摄像机视图之间进行视图合成，导致引导不足。为了解决这个问题，我们试图通过基于流的视频帧插值（VFI）来合成更多的虚拟相机视图，称为时间增强。对于多帧推理，为了避开基于显式几何的方法（如ManyDepth）遇到的动态对象问题，我们回到了特征融合范式，并设计了一个VFI辅助的多帧融合模块，使用基于流的VFI模型获得的运动和遮挡信息来对齐和聚合多帧特征。最后，我们构建了一个统一的自监督学习框架，名为Mono ViFI，以双向连接单帧和多帧深度。在这个框架中，通过图像仿射变换进行空间数据增强以实现数据多样性，同时进行正则化的三重深度一致性损失。单帧和多帧模型可以共享权重，使我们的框架紧凑且内存高效。大量实验表明，我们的方法可以为当前的先进架构带来重大改进。源代码可在https://github.com/LiuJF1226/Mono-ViFI. et.al.|[2407.14126](http://arxiv.org/abs/2407.14126)|null|
|**2024-07-18**|**Shape of Motion: 4D Reconstruction from a Single Video**|由于单眼动态重建任务的高度不适定性，它是一个具有挑战性和长期存在的视觉问题。现有的方法存在局限性，因为它们要么依赖于模板，要么仅在准静态场景中有效，要么无法明确地对3D运动进行建模。在这项工作中，我们介绍了一种能够从随意捕获的单眼视频中重建具有显式、全序列长3D运动的通用动态场景的方法。我们通过两个关键的见解来解决这个问题的欠约束性质：首先，我们通过用一组紧凑的SE3运动基表示场景运动来利用3D运动的低维结构。每个点的运动都表示为这些基的线性组合，有助于将场景软分解为多个刚性移动的组。其次，我们利用了一套全面的数据驱动先验，包括单眼深度图和长距离2D轨迹，并设计了一种方法来有效地整合这些嘈杂的监控信号，从而得到动态场景的全局一致表示。实验表明，我们的方法在长距离3D/2D运动估计和动态场景上的新颖视图合成方面都取得了最先进的性能。项目页面：https://shape-of-motion.github.io/ et.al.|[2407.13764](http://arxiv.org/abs/2407.13764)|null|
|**2024-07-18**|**Streetscapes: Large-scale Consistent Street View Generation Using Autoregressive Video Diffusion**|我们提出了一种通过动态合成的城市尺度场景生成街景长序列视图的方法。我们这一代人受到语言输入（如城市名称、天气）以及承载所需轨迹的底层地图/布局的制约。与最近的视频生成或3D视图合成模型相比，我们的方法可以扩展到更远的摄像机轨迹，跨越几个街区，同时保持视觉质量和一致性。为了实现这一目标，我们基于最近在视频扩散方面的工作，在一个可以轻松扩展到长序列的自回归框架内使用。特别是，我们引入了一种新的时间插补方法，可以防止我们的自回归方法偏离现实城市图像的分布。我们使用来自谷歌街景的令人信服的数据源来训练我们的街景系统，这些数据源包括图像，以及上下文地图数据，这些数据允许用户根据任何所需的城市布局生成城市景观，并具有可控的摄像器姿态。请在我们的项目页面上查看更多结果https://boyangdeng.com/streetscapes. et.al.|[2407.13759](http://arxiv.org/abs/2407.13759)|null|
|**2024-07-18**|**KFD-NeRF: Rethinking Dynamic NeRF with Kalman Filter**|我们介绍了KFD NeRF，这是一种新型的动态神经辐射场，与基于卡尔曼滤波的高效高质量运动重建框架相结合。我们的关键思想是将动态辐射场建模为一个动态系统，其时变状态基于两个知识来源进行估计：观测和预测。我们介绍了一种新的插件卡尔曼滤波器引导的变形场，该变形场能够根据场景观测和预测进行精确的变形估计。我们使用浅层多层感知器（MLP）进行观测，并将运动建模为局部线性，以使用运动方程计算预测。为了进一步提高观测MLP的性能，我们在规范空间中引入正则化，以提高网络学习不同帧扭曲的能力。此外，我们采用了一种高效的三平面表示来编码规范空间，该表示已被实验证明可以快速、高质量地收敛。这使我们能够使用较浅的观测MLP，在我们的实现中仅由两层组成。我们对合成数据和真实数据进行了实验，并与过去的动态NeRF方法进行了比较。我们的KFD NeRF在相当的计算时间内表现出类似甚至更优的渲染性能，并通过彻底的训练实现了最先进的视图合成性能。 et.al.|[2407.13185](http://arxiv.org/abs/2407.13185)|null|
|**2024-07-17**|**Generalizable Human Gaussians for Sparse View Synthesis**|神经渲染的最新进展带来了开创性的方法，如NeRF和高斯散斑，这些方法彻底改变了AR/VR、游戏和内容创建等各个领域的视图渲染。虽然这些方法擅长在训练数据中插值，但从非常稀疏的视图推广到新场景和对象的挑战仍然存在。具体来说，由于人体几何形状的固有复杂性，从稀疏视图对3D人体进行建模存在巨大的障碍，导致几何和纹理的重建不准确。为了应对这一挑战，本文利用高斯散布的最新进展，介绍了一种学习可推广的人类高斯分布的新方法，该方法允许以前馈方式从有限的稀疏视图集中对新的人类对象进行逼真和精确的视图渲染。我们方法的一个关键创新是将3D高斯参数的学习重新表述为在人类模板的2D UV空间上定义的回归过程，这允许利用强几何先验和2D卷积的优点。此外，还提出了一种多脚手架来有效地表示偏移细节。我们的方法在数据集内泛化和跨数据集泛化设置上都优于最近的方法。 et.al.|[2407.12777](http://arxiv.org/abs/2407.12777)|null|
|**2024-07-17**|**Efficient Depth-Guided Urban View Synthesis**|隐式场景表示的最新进展实现了高保真街景新视图合成。然而，现有的方法严重依赖密集的训练图像和大量的计算资源，为每个场景优化神经辐射场。为了减轻这一缺点，我们引入了一种名为高效深度引导城市景观合成（EDUS）的新方法，用于快速前馈推理和高效的每场景微调。与基于特征匹配推断几何的先前可推广方法不同，EDUS利用噪声预测的几何先验作为指导，从稀疏输入图像中实现可推广的城市景观合成。几何先验允许我们直接在3D空间中应用我们的可推广模型，在各种稀疏级别上获得鲁棒性。通过在KITTI-360和Waymo数据集上的综合实验，我们展示了对新颖街道场景的有前景的泛化能力。此外，我们的结果表明，当与快速测试时间优化相结合时，EDUS在稀疏视图设置中实现了最先进的性能。 et.al.|[2407.12395](http://arxiv.org/abs/2407.12395)|null|
|**2024-07-17**|**Splatfacto-W: A Nerfstudio Implementation of Gaussian Splatting for Unconstrained Photo Collections**|由于光度变化和瞬态遮挡使精确的场景重建复杂化，从无约束的野生图像集合中进行新的视图合成仍然是一项重要但具有挑战性的任务。以前的方法通过在神经辐射场（NeRF）中集成每幅图像的外观特征嵌入来解决这些问题。尽管3D高斯散斑（3DGS）提供了更快的训练和实时渲染，但由于架构的显著不同，将其应用于无约束的图像集合并非易事。在本文中，我们介绍了Splatfacto-W，这是一种将每高斯神经颜色特征和每图像外观嵌入集成到光栅化过程中的方法，以及基于球面谐波的背景模型，用于表示不同的光度外观并更好地描绘背景。我们的主要贡献包括潜在外观建模、高效的瞬态对象处理和精确的背景建模。Splatfacto-W提供高质量、实时的新颖视图合成，在野外场景中提高了场景一致性。与3DGS相比，我们的方法将峰值信噪比（PSNR）平均提高了5.3 dB，与基于NeRF的方法相比，训练速度提高了150倍，并实现了与3DGS相似的渲染速度。集成到Nerfstudio中的其他视频结果和代码可在以下网址获得https://kevinxu02.github.io/splatfactow/. et.al.|[2407.12306](http://arxiv.org/abs/2407.12306)|null|
|**2024-07-16**|**NeuSurfEmb: A Complete Pipeline for Dense Correspondence-based 6D Object Pose Estimation without CAD Models**|6D物体姿态估计的最新方法假设CAD模型的可用性，并要求用户手动设置基于物理的渲染（PBR）管道以生成合成训练数据。这两个因素都限制了这些方法在现实世界场景中的应用。在这项工作中，我们提出了一种不需要CAD模型的管道，并允许训练最先进的姿态估计器，只需要一小部分真实图像作为输入。我们的方法基于NeuS2对象表示，我们通过基于运动结构（SfM）和对象无关分割的半自动过程来学习。我们利用NeuS2的新颖视图合成能力和简单的剪切粘贴增强来自动生成逼真的对象渲染，我们用它来训练基于对应的SurfEmb姿态估计器。我们在LINEMOD Occlusion数据集上评估了我们的方法，广泛研究了其各个组件的影响，并展示了基于CAD模型和PBR数据的方法的竞争性能。我们还展示了我们的管道在自我收集的真实世界对象上的易用性和有效性，表明我们的方法优于最先进的无CAD模型方法，对轻度遮挡具有更好的准确性和鲁棒性。为了让机器人社区从该系统中受益，我们将在https://www.github.com/ethz-asl/neusurfemb. et.al.|[2407.12207](http://arxiv.org/abs/2407.12207)|**[link](https://github.com/ethz-asl/neusurfemb)**|
|**2024-07-18**|**IPA-NeRF: Illusory Poisoning Attack Against Neural Radiance Fields**|神经辐射场（NeRF）代表了计算机视觉的一个重大进步，提供了隐式的基于神经网络的场景表示和新颖的视图合成功能。它的应用涵盖了不同的领域，包括机器人、城市地图、自主导航、虚拟现实/增强现实等，其中一些被认为是高风险的人工智能应用。然而，尽管NeRF被广泛采用，但其稳健性和安全性在很大程度上仍未得到探索。在这项研究中，我们通过引入针对神经辐射场的幻觉中毒攻击（IPA-NeRF）为这一领域做出了贡献。这种攻击涉及在NeRF中嵌入一个隐藏的后门视图，使其在提供指定的后门视图时能够产生预定的输出，即虚幻的输出，同时保持标准输入的正常性能。我们的攻击是专门为在特定位置欺骗用户或下游模型而设计的，同时确保从其他角度无法检测到NeRF中的任何异常。实验结果证明了我们的幻觉中毒攻击的有效性，在指定的视点上成功地呈现了所需的幻觉，而不会影响其他视图。值得注意的是，我们通过仅向训练集引入小扰动来实现这种攻击。代码可以在以下网址找到https://github.com/jiang-wenxiang/IPA-NeRF. et.al.|[2407.11921](http://arxiv.org/abs/2407.11921)|**[link](https://github.com/jiang-wenxiang/ipa-nerf)**|

<p align=right>(<a href=#updated-on-20240722>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-07-19**|**SparseCraft: Few-Shot Neural Reconstruction through Stereopsis Guided Geometric Linearization**|我们提出了一种从少数彩色图像中恢复3D形状和视图相关外观的新方法，实现了高效的3D重建和新颖的视图合成。我们的方法以符号距离函数（SDF）和辐射场的形式学习隐式神经表示。该模型通过支持光线行进的体积渲染逐步训练，并使用无需学习的多视图立体（MVS）线索进行正则化。我们贡献的关键是一种新的隐式神经形状函数学习策略，该策略鼓励我们的SDF场在水平集附近尽可能线性，从而使训练对监督和正则化信号发出的噪声具有鲁棒性。在不使用任何预训练先验的情况下，我们的方法SparseCraft在新的视图合成和标准基准中从稀疏视图重建方面都达到了最先进的性能，同时只需要不到10分钟的训练时间。 et.al.|[2407.14257](http://arxiv.org/abs/2407.14257)|null|
|**2024-07-19**|**I Know About "Up"! Enhancing Spatial Reasoning in Visual Language Models Through 3D Reconstruction**|视觉语言模型（VLMs）对于各种任务，特别是视觉推理任务至关重要，因为它们具有强大的多模态信息集成、视觉推理能力和上下文感知能力。然而，现有的视觉空间推理能力往往不足，即使在区分左右等基本任务上也很困难。为了解决这个问题，我们提出了我们的模型，旨在增强VLMS的视觉空间推理能力。ZeroVLM采用Zero1-to-3，这是一种3D重建模型，用于获得输入图像的不同视图，并结合了提示机制，以进一步改善视觉空间推理。在四个视觉空间推理数据集上的实验结果表明，我们的{}实现了高达19.48%的准确率提高，这表明了ZeroVLM的3D重建和提示机制的有效性。 et.al.|[2407.14133](http://arxiv.org/abs/2407.14133)|null|
|**2024-07-19**|**FAVis: Visual Analytics of Factor Analysis for Psychological Research**|心理学研究通常涉及通过对问卷收集的数据进行因子分析来理解心理结构，问卷可能包括数百个问题。如果没有用于解释因子模型的交互系统，研究人员经常会受到主观性的影响，这可能会导致误解或忽视关键信息。本文介绍了FAVis，这是一种新型的交互式可视化工具，旨在帮助研究人员解释和评估因子分析结果。FAVis通过支持多种视图来可视化因素载荷和相关性，使用户能够从不同角度分析信息，从而增强了对变量和因素之间关系的理解。FAVis的主要功能是使用户能够为因子负载设置最佳阈值，以平衡清晰度和信息保留。FAVis还允许用户为变量分配标签，通过将它们与相关的心理结构联系起来，增强对因素的理解。我们的用户研究证明了FAVis在各种任务中的实用性。 et.al.|[2407.14072](http://arxiv.org/abs/2407.14072)|null|
|**2024-07-19**|**DirectL: Efficient Radiance Fields Rendering for 3D Light Field Displays**|尽管经过几十年的发展，自动立体显示器尚未得到广泛应用，主要是因为非专业人士在3D内容创作方面面临着艰巨的挑战。辐射场作为一种创新的3D表示的出现，显著地彻底改变了3D重建和生成的领域。这项技术大大简化了普通用户的3D内容创建，扩大了光场显示器（LFD）的适用范围。然而，这两个领域的结合在很大程度上仍未得到探索。为基于视差的光场显示器创建最佳内容的标准范式要求渲染至少45个略微偏移的视图，最好是每帧高分辨率，这是实时渲染的一个重大障碍。我们介绍了DirectL，这是一种用于3D显示器上辐射场的新型渲染范式。我们深入分析了空间光线到屏幕子像素的交织映射，精确地确定了进入人眼的光线，并提出了子像素的重新利用，以显著减少渲染所需的像素数。针对两个主要的辐射场——神经辐射场（NeRFs）和3D高斯散斑（3DGS），我们提出了相应的优化渲染管道，直接渲染光场图像，而不是多视图图像。在各种显示器和用户研究中进行的广泛实验表明，与标准范式相比，DirectL在不牺牲视觉质量的情况下将渲染速度提高了40倍。仅对其渲染过程进行修改，即可无缝集成到后续的辐射场任务中。最后，我们将DirectL集成到各种应用中，展示了令人惊叹的视觉体验以及LFD和Radiance Fields之间的协同作用，这为商业化应用带来了巨大的潜力。\href{direct-l.github.io}{\textbf{项目主页} et.al.|[2407.14053](http://arxiv.org/abs/2407.14053)|null|
|**2024-07-18**|**MaRINeR: Enhancing Novel Views by Matching Rendered Images with Nearby References**|从3D重建中渲染逼真的图像是许多计算机视觉和机器人管道的重要任务，特别是对于混合现实应用以及在模拟环境中训练自主代理。然而，新颖视图的质量在很大程度上取决于源重建，由于噪声或缺少几何和外观，源重建往往是不完美的。受最近基于参考的超分辨率网络成功的启发，我们提出了MaRINeR，这是一种利用附近映射图像的信息来改善目标视点渲染的细化方法。我们首先基于深度特征在目标视点的场景几何的原始渲染图像和附近的参考之间建立匹配，然后进行分层细节传递。我们从显式和隐式场景表示的定量指标和定性示例中展示了改进的渲染。我们进一步将我们的方法应用于伪地面真实性验证、合成数据增强和细节恢复等下游任务，用于简化3D重建的渲染。 et.al.|[2407.13745](http://arxiv.org/abs/2407.13745)|null|
|**2024-07-18**|**EaDeblur-GS: Event assisted 3D Deblur Reconstruction with Gaussian Splatting**|随着神经辐射场（NeRF）和3D高斯散斑（3DGS）的发展，3D去模糊重建技术最近取得了重大进展。尽管这些技术可以从模糊的图像输入中恢复相对清晰的3D重建，但在处理严重模糊和复杂的相机运动方面仍然存在局限性。为了解决这些问题，我们提出了高斯散斑事件辅助3D去模糊重建（EaDeblur GS），它集成了事件相机数据，以增强3DGS对运动模糊的鲁棒性。通过采用自适应偏差估计器（ADE）网络来估计高斯中心偏差，并使用新的损失函数，EaDeblur GS实时实现了清晰的3D重建，其性能可与最先进的方法相媲美。 et.al.|[2407.13520](http://arxiv.org/abs/2407.13520)|null|
|**2024-07-17**|**Edge Projection-Based Adaptive View Selection for Cone-Beam CT**|附加制造部件的工业锥束X射线计算机断层扫描（CT）扫描从部件围绕单个轴的多个预定旋转角度采集的投影测量中产生3D重建。通常，需要大量的投影来实现高质量的重建，这一过程可能会持续几个小时或几天，具体取决于零件尺寸、材料成分和所需的分辨率。本文介绍了一种新颖的实时系统，旨在通过基于物体的几何形状和计算机辅助设计（CAD）模型智能选择最佳的下一个角度来优化扫描过程。这种选择过程在战略上平衡了与零件长边对齐的测量需求和保持一组不同的整体测量需求。通过模拟，我们证明，与传统方法相比，我们的算法显著减少了实现高质量重建所需的投影数量。 et.al.|[2407.12963](http://arxiv.org/abs/2407.12963)|null|
|**2024-07-17**|**HDLCopilot: Hardware Design Library Querying with Natural Language**|硬件设计工程师经常使用来自不同制造实验室的多个工艺设计套件（PDK），每个套件都包含几个标准单元库，针对速度、功率或密度等特定指标进行了优化。这些库包括多个视图，如用于计时信息的liberty文件、用于抽象布局细节的LEF文件和用于过程设计规则的技术LEF。在这个复杂的环境中导航以检索有关闸门或设计规则的特定信息通常既耗时又容易出错。为了解决这个问题，我们提出了HDLCopilot，这是一个基于LLM的PDK查询系统，允许工程师简化与自然语言格式的PDK的交互，使信息检索更加准确和高效。HDLCopilot在由各种复杂的自然语言查询组成的评估集上实现了94.23%的准确率。HDLCopilot将自己定位为硬件设计过程中的强大助手，提高了生产率并减少了潜在的人为错误。 et.al.|[2407.12749](http://arxiv.org/abs/2407.12749)|null|
|**2024-07-17**|**SG-NeRF: Neural Surface Reconstruction with Scene Graph Optimization**|从图像中重建3D表面对于许多应用至关重要。最近，神经辐射场（NeRFs）已经成为一种有前景的3D建模框架。然而，NeRF需要精确的相机姿态作为输入，现有的方法很难处理在现实世界场景中常见的噪声很大的姿态估计（即异常值）。为了应对这一挑战，我们提出了一种新方法，通过场景图优化辐射场，以减轻异常姿态的影响。我们的方法结合了一种基于场景图的自适应内层离群值置信度估计方案，强调图像与邻域的高度兼容性和渲染质量的一致性。我们还引入了一种有效的联合交叉（IoU）损失来优化相机姿态和表面几何形状，以及一种从粗到细的策略来促进训练。此外，我们提出了一个包含典型异常姿态的新数据集，用于详细评估。在各种数据集上的实验结果一致证明了我们的方法相对于现有方法的有效性和优越性，展示了它在处理异常值和生成高质量3D重建方面的鲁棒性。我们的代码和数据可在以下网址获得：\url{https://github.com/Iris-cyy/SG-NeRF}. et.al.|[2407.12667](http://arxiv.org/abs/2407.12667)|**[link](https://github.com/iris-cyy/sg-nerf)**|
|**2024-07-17**|**Serialized Point Mamba: A Serialized Point Cloud Mamba Segmentation Model**|点云分割对于机器人视觉感知和环境理解至关重要，可以实现机器人导航和3D重建等应用。然而，处理点云数据的稀疏和无序特性给高效和准确的分割带来了挑战。受Mamba模型在自然语言处理中的成功启发，我们提出了序列化点云Mamba分段模型（序列化点Mamba），该模型利用状态空间模型动态压缩序列，减少内存使用，提高计算效率。Serialized Point Mamba将局部全局建模功能与线性复杂性相结合，在室内和室外数据集上实现了最先进的性能。这种方法包括分阶段点云序列学习、网格池和条件位置编码等新技术，促进了不同点云任务的有效分割。我们的方法在Scannet上实现了76.8 mIoU，在S3DIS上实现了70.3 mIoU。在Scannetv2实例分段中，它记录了40.0 mAP。它还具有最低的延迟和合理的内存使用，使其成为基于曼巴的点语义分割模型中的SOTA。 et.al.|[2407.12319](http://arxiv.org/abs/2407.12319)|null|

<p align=right>(<a href=#updated-on-20240722>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-07-19**|**DEPICT: Diffusion-Enabled Permutation Importance for Image Classification Tasks**|我们提出了一种基于置换的图像分类器解释方法。当前的图像模型解释，如激活图，仅限于像素空间中的基于实例的解释，这使得理解全局模型行为变得困难。相比之下，基于置换的表格数据分类器解释通过比较置换特征前后数据的模型性能来衡量特征重要性。我们提出了一种基于图像的模型的解释方法，该方法在数据集图像之间排列可解释的概念。给定一个标记有特定概念（如标题）的图像数据集，我们在文本空间中的示例之间排列一个概念，然后通过文本条件扩散模型生成图像。然后，特征重要性通过模型性能相对于未经处理的数据的变化来反映。当应用于一组概念时，该方法会生成特征重要性的排名。我们展示了这种方法在合成和真实世界的图像分类任务中恢复了底层模型特征的重要性。 et.al.|[2407.14509](http://arxiv.org/abs/2407.14509)|null|
|**2024-07-19**|**M2D2M: Multi-Motion Generation from Text with Discrete Diffusion Models**|我们介绍了多运动离散扩散模型（M2D2M），这是一种利用离散扩散模型的优势，从多个动作的文本描述中生成人体运动的新方法。这种方法巧妙地解决了生成多运动序列的挑战，确保了运动的无缝过渡和一系列动作的连贯性。M2D2M的优势在于其在离散扩散模型中的动态转移概率，该模型根据运动标记之间的接近度来调整转移概率，从而鼓励不同模式之间的混合。通过包括独立和联合去噪步骤的两阶段采样策略的补充，M2D2M利用为单运动生成训练的模型，有效地生成了长期、平滑和上下文连贯的人体运动序列。大量实验表明，M2D2M超越了当前最先进的文本描述运动生成基准，展示了其在解释语言语义和生成动态、逼真运动方面的有效性。 et.al.|[2407.14502](http://arxiv.org/abs/2407.14502)|null|
|**2024-07-19**|**Co-synthesis of Histopathology Nuclei Image-Label Pairs using a Context-Conditioned Joint Diffusion Model**|在多类组织病理学核分析任务中，缺乏训练数据成为基于学习的方法性能的主要瓶颈。为了应对这一挑战，以前的方法利用生成模型通过生成合成样本来增加数据。然而，现有的方法往往忽视了在合成数据中考虑生物组织背景（如形状、空间布局和组织类型）的重要性。此外，尽管生成模型在合成逼真的组织病理学图像方面表现出了卓越的性能，但现有的方法都无法同时生成图像标签对。在本文中，我们介绍了一种使用上下文条件联合扩散模型共同合成组织病理学核图像和成对语义标签的新框架。我们建议使用核质心布局和结构相关的文本提示来调节扩散模型，以将空间和结构上下文信息纳入生成目标。此外，我们通过使用与图像和语义标签同时合成的距离图生成实例核标签来增强合成语义标签的粒度。我们展示了我们的框架在多机构、多器官和多模态数据集上生成高质量样本的有效性。我们的合成数据在核分割和分类的下游任务中始终优于现有的增强方法。 et.al.|[2407.14434](http://arxiv.org/abs/2407.14434)|null|
|**2024-07-19**|**Controllable and Efficient Multi-Class Pathology Nuclei Data Augmentation using Text-Conditioned Diffusion Models**|在计算病理学领域，深度学习算法在核分割和分类等任务中取得了重大进展。然而，由于缺乏可用的标记数据，这些先进方法的潜力受到限制。尽管通过最近的生成模型进行的图像合成已被积极探索以应对这一挑战，但现有的工作几乎没有解决标签增强问题，而且大多局限于单类和无条件标签生成。本文介绍了一种新的两阶段框架，用于使用文本条件扩散模型进行多类核数据增强。在第一阶段，我们创新了核心标签合成，通过由指定标签结构信息的文本提示约束的联合扩散模型生成多类语义标签和相应的实例映射。在第二阶段，我们利用语义和文本条件潜在扩散模型有效地生成与生成的核标记图像对齐的高质量病理图像。我们展示了我们的方法在大型和多样化的病理核数据集上的有效性，评估包括定性和定量分析，以及对下游任务的评估。 et.al.|[2407.14426](http://arxiv.org/abs/2407.14426)|null|
|**2024-07-19**|**HOTS3D: Hyper-Spherical Optimal Transport for Semantic Alignment of Text-to-3D Generation**|最近的CLIP引导的3D生成方法取得了有希望的结果，但由于文本和图像嵌入之间的差距，难以生成符合输入文本的忠实3D形状。为此，本文提出了HOTS3D，它首次尝试通过球形最优传输（SOT）将文本特征与图像特征对齐，从而有效地弥合这一差距。然而，在高维情况下，解决SOT仍然是一个挑战。为了获得从两种模态的CLIP编码中获得的高维特征的SOT图，我们基于Villani定理进行了数学公式化和推导，该定理可以直接对齐两个超球面分布，而无需流形指数图。此外，我们通过利用输入凸神经网络（ICNN）来实现最优Kantorovich势。利用最佳映射的特征，随后利用基于扩散的生成器和基于Nerf的解码器将其转换为3D形状。与最新技术的广泛定性和定性比较表明，所提出的HOTS3D在3D形状生成方面具有优势，特别是在与文本语义的一致性方面。 et.al.|[2407.14419](http://arxiv.org/abs/2407.14419)|null|
|**2024-07-19**|**Uniqueness of the inverse source problem for fractional diffusion-wave equations**|本研究解决了分数扩散波动方程的逆源问题，其特征是源包括空间和时间分量。调查主要关注事件发生后收集数据的实际情况。我们建立了源的空间或时间分量的唯一性，前提是时间分量在无穷远处表现出渐近展开。以异常扩散为例，我们收集了以下量之一的渐近行为：部分内部区域或区域内某点的浓度，或部分边界或边界上某点的通量。该证明基于分数扩散波动方程解的渐近展开。值得注意的是，我们的方法不依赖于源分量的传统消失条件。我们还观察到，唯一性的程度取决于分数阶。 et.al.|[2407.14413](http://arxiv.org/abs/2407.14413)|null|
|**2024-07-19**|**Natural convection in the cytoplasm: Theoretical predictions of buoyancy-driven flows inside a cell**|真核细胞内温度梯度的存在被认为是细胞质中自然对流的来源，即由于温差引起的密度梯度导致的整体流体运动。最近的计算预测，细胞核和细胞膜之间约1$K的温差可能足以驱动显著的细胞内物质运输。我们使用数值计算和理论计算来重新审视这个问题，以进一步了解温度梯度对细胞内流动产生和平流输送的影响。令人惊讶的是，我们的计算得出的流量比之前在细胞核相对于细胞膜的相同相对大小和位置下获得的流量弱一个数量级。为了理解这种差异，对于轴对称细胞几何形状的情况（即当细胞核从细胞中心的位移与重力对齐时），我们使用双球坐标框架开发了模型细胞内对流的半解析解。我们还计算了当细胞核同心地位于细胞内时的流动的精确解。这两个理论分析的结果与我们的数值结果一致，从而提供了对细胞质自然对流强度的稳健估计，并证明这些对流比之前预测的要弱得多。最后，我们研究了上述流动在细胞内重新分配溶质的能力。我们的计算表明，在所有情况下，除了不切实际的情况外，细胞质对流对增强细胞物质的扩散主导传质的贡献可以忽略不计。 et.al.|[2407.14385](http://arxiv.org/abs/2407.14385)|null|
|**2024-07-19**|**As Generative Models Improve, People Adapt Their Prompts**|在一项有1891名参与者的在线实验中，我们收集并分析了18000多个提示，以探索随着生成性人工智能模型的能力不断提高，提示的重要性将如何变化。我们实验中的每个参与者都被随机和盲目地分配使用三种文本到图像扩散模型中的一种：DALL-E 2、其更先进的继任者DALL-E 3或具有自动提示修订功能的DALL-E 4版本。然后，参与者被要求写提示，在连续10次尝试中尽可能接近地再现目标图像。我们发现，使用DALL-E 3的参与者的任务表现高于使用DALL-E 2的参与者。这种性能差距对应于参与者图像与目标图像相似性的显著差异，并且是由以下因素引起的：（1）DALL-E 3技术能力的提高，以及（2）参与者对这些能力提高的内在反应。更具体地说，尽管对分配给他们的模型视而不见，但分配给DALL-E 3的参与者写了更长的提示，这些提示在语义上更相似，包含更多的描述性单词。此外，尽管分配到DALL-E 3并进行快速修订的参与者仍然优于分配到DALL-DAL 2的参与者，但自动快速修订使使用DALL-E 2的益处降低了58%。总的来说，我们的研究结果表明，随着模型的不断进步，人们将继续调整他们的提示，以利用新模型的能力。 et.al.|[2407.14333](http://arxiv.org/abs/2407.14333)|null|
|**2024-07-19**|**Panoptic Segmentation of Mammograms with Text-To-Image Diffusion Model**|乳腺造影对癌症的监测和早期诊断至关重要。然而，分析乳房X线照片对放射科医生来说是一项艰巨的任务，他们经常每天审查数百张乳房X线照片，导致过度诊断和过度治疗。已经开发了计算机辅助诊断（CAD）系统来协助这一过程，但它们的能力，特别是在病变分割方面的能力仍然有限。随着深度学习的当代进步，它们的性能可能会得到改善。最近，视觉语言扩散模型出现了，在图像生成和向各种下游任务的可转移性方面表现出色。我们的目标是利用它们在全景环境中进行乳腺病变分割的能力，其中包括语义和实例级别的预测。具体来说，我们建议利用稳定扩散模型的预训练特征作为最先进的全景分割架构的输入，从而准确描绘单个乳腺病变。为了弥合自然和医学成像领域之间的差距，我们将乳房X线摄影专用的MAM-E扩散模型和BiomedCLIP图像和文本编码器纳入了这个框架。我们在最近发布的两个乳房X线摄影数据集CDD-CESM和VinDr Mammo上评估了我们的方法。对于实例分割任务，我们注意到40.25 AP0.1和46.82 AP0.05，以及25.44 PQ0.1和26.92 PQ0.05。对于语义分割任务，我们分别获得了38.86和40.92的Dice分数。 et.al.|[2407.14326](http://arxiv.org/abs/2407.14326)|null|
|**2024-07-19**|**Time-dependent condensate formation in ultracold atoms with energy-dependent transport coefficients**|在非线性扩散模型中研究了超冷原子中时变玻色-爱因斯坦凝聚体（BEC）的形成。对于恒定的输运系数，该模型已经过解析求解。在这里，我们将其扩展到包括能量依赖的输运系数，并数值求解非线性方程。我们的结果与早期恒定输运系数的分析模型以及最近不同散射长度下K-39的深猝灭数据进行了比较。使用能量相关漂移和扩散解决了常系数模型的一些非物理预测。 et.al.|[2407.14307](http://arxiv.org/abs/2407.14307)|null|

<p align=right>(<a href=#updated-on-20240722>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-07-18**|**MeshFeat: Multi-Resolution Features for Neural Fields on Meshes**|参数特征网格编码作为神经场的编码方法受到了广泛关注，因为它们允许更小的MLP，这大大缩短了模型的推理时间。在这项工作中，我们提出了MeshFeat，这是一种针对网格量身定制的参数特征编码，为此我们采用了欧几里德空间的多分辨率特征网格的思想。我们从给定顶点拓扑提供的结构开始，使用网格简化算法直接在网格上构建多分辨率特征表示。该方法允许在网格上的神经场中使用小MLP，与之前的表示相比，我们显示出显著的加速，同时保持了纹理重建和BRDF表示的可比重建质量。鉴于其与顶点的内在耦合，该方法特别适用于变形网格上的表示，使其非常适合对象动画。 et.al.|[2407.13592](http://arxiv.org/abs/2407.13592)|null|
|**2024-07-16**|**Adaptive Environment-Aware Robotic Arm Reaching Based on a Bio-Inspired Neurodynamical Computational Framework**|仿生机器人系统具有自适应学习、可扩展控制和高效信息处理的能力。为这些系统提供实时决策对于应对环境的动态变化至关重要。我们专注于在开放区域使用带有鸟瞰摄像头的机器人六自由度操纵器进行动态目标跟踪，并部署神经动力学计算框架（NeuCF）进行视觉反馈。NeuCF是最近开发的一种基于动态神经场（DNF）和随机最优控制（SOC）理论的仿生目标跟踪模型。它已经过训练，可以在平面上对局部视觉信标进行到达动作，并且可以根据环境的变化（例如，出现了新的目标，或者删除了现有的目标）实时重新定位或生成停止信号。我们在各种目标达成场景下评估了我们的系统。在所有实验中，与基线三次多项式轨迹生成器相比，NeuCF具有较高的末端执行器位置精度，生成了平滑的轨迹，并提供了更短的路径长度。总之，开发的系统提供了一种强大的、动态感知的机器人操纵方法，可以提供实时决策。 et.al.|[2407.11377](http://arxiv.org/abs/2407.11377)|null|
|**2024-07-12**|**Physics-Informed Learning of Characteristic Trajectories for Smoke Reconstruction**|我们通过稀疏视图RGB视频深入研究了烟雾和障碍物的物理信息神经重建，解决了复杂动力学观测有限带来的挑战。现有的基于物理信息的神经网络通常强调短期物理约束，对长期守恒的适当保护探索较少。我们引入了神经特征轨迹场，这是一种利用欧拉神经场隐式建模拉格朗日流体轨迹的新表示方法。这种无拓扑、可自动微分的表示便于在任意帧之间进行高效的流图计算，以及通过自动微分进行高效的速度提取。因此，它实现了涵盖长期保护和短期物理先验的端到端监督。在此基础上，我们提出了基于物理的轨迹学习和集成到基于NeRF的场景重建中。我们通过自我监督的场景分解和无缝集成的边界约束来实现高级障碍物处理。我们的结果展示了克服遮挡不确定性、密度-颜色模糊性和静态-动态纠缠等挑战的能力。代码和示例测试位于\url{https://github.com/19reborn/PICT_smoke}. et.al.|[2407.09679](http://arxiv.org/abs/2407.09679)|null|
|**2024-07-10**|**Neural Localizer Fields for Continuous 3D Human Pose and Shape Estimation**|随着可用训练数据的爆炸性增长，单图像3D人体建模领先于向以数据为中心的范式过渡。成功利用数据规模的关键是设计灵活的模型，这些模型可以从不同研究人员或供应商生产的各种异构数据源进行监督。为此，我们提出了一种简单而强大的范式，用于无缝统一不同的人体姿势和形状相关的任务和数据集。我们的公式侧重于在训练和测试时查询人体体积的任意点并在3D中获得其估计位置的能力。我们通过学习身体点定位器函数的连续神经场来实现这一点，每个函数都是基于不同参数化的3D热图卷积点定位器（检测器）。为了生成参数输出，我们提出了一种高效的后处理步骤，用于将SMPL族身体模型拟合到非参数关节和顶点预测中。通过这种方法，我们可以自然地利用不同注释的数据源，包括网格、2D/3D骨架和密集姿势，而无需在它们之间进行转换，从而训练出大规模的3D人体网格和骨架估计模型，这些模型在3DPW、EMDB和SSP-3D等几个公共基准上的表现远远优于最先进的水平。 et.al.|[2407.07532](http://arxiv.org/abs/2407.07532)|null|
|**2024-07-03**|**Cerebral cortex inspired representation of neural field network**|进化及其智能元素在探索中带来了刺激和挑战。然而，物种如何拥有记忆、检索记忆并保持连续性是根本问题。大多数现象只能由研究人员假设，通过实验验证它们是一个很大的挑战。将大脑视为理想的智能机器并对其进行建模，为计算算法开辟了新的维度。本文提出了一个假设，即类似于大脑皮层的记忆创造。大脑皮层的区域隐含着特定功能的特异性，构成了一维的矢量形式的神经场。整个皮层的神经场相互连接形成了一个网络。这些网络与生存本能、情绪和奖励相关联，构成了对暴露环境的记忆，或者说学习。具有多维控制点的图形工具NURBS被隐式地用于将这些网络表示为一组三次方程。通过数据学习是智能系统的主要模块，本文试图将数据转换为低维模式，而不是实时智能系统的现有绝对形式。 et.al.|[2407.04741](http://arxiv.org/abs/2407.04741)|null|
|**2024-07-01**|**Fast and Efficient: Mask Neural Fields for 3D Scene Segmentation**|理解3D场景是计算机视觉研究中的一个关键挑战，其应用跨越多个领域。最近在将2D视觉语言基础模型提取到神经领域（如NeRF和3DGS）方面取得的进展，使3D场景能够从2D多视图图像中进行开放式词汇分割，而不需要精确的3D注释。然而，虽然有效，但高维CLIP特征的每像素蒸馏会引入模糊性，并需要复杂的正则化策略，从而在训练过程中增加效率。本文介绍了MaskField，它能够在弱监督下利用神经场实现快速高效的3D开放式分词。与以前的方法不同，MaskField提取掩模而不是密集的高维CLIP特征。MaskFields使用神经场作为二进制掩模生成器，并使用SAM生成的掩模对其进行监督，并通过粗略的CLIP特征进行分类。MaskField通过在训练过程中自然引入SAM分割的对象形状而无需额外的正则化来克服模糊的对象边界。通过在训练过程中避免直接处理高维CLIP特征，MaskField与3DGS等显式场景表示特别兼容。我们广泛的实验表明，MaskField不仅超越了现有的最先进的方法，而且实现了非常快的收敛速度，仅需5分钟的训练就超越了以前的方法。我们希望MaskField能够激发对如何训练神经场以从2D模型中理解3D场景的进一步探索。 et.al.|[2407.01220](http://arxiv.org/abs/2407.01220)|null|
|**2024-07-15**|**3D Feature Distillation with Object-Centric Priors**|将自然语言与物理世界联系起来是一个无处不在的话题，在计算机视觉和机器人技术中有着广泛的应用。最近，CLIP等二维视觉语言模型因其在二维图像中具有令人印象深刻的开放词汇基础能力而得到了广泛推广。最近的工作旨在通过特征提取将2D CLIP特征提升到3D，但要么学习特定于场景的神经场，因此缺乏泛化能力，要么专注于需要访问多个摄像头视图的室内房间扫描数据，这在机器人操作场景中是不可行的。此外，相关方法通常在像素级融合特征，并假设所有相机视图都具有相同的信息量。在这项工作中，我们表明这种方法在接地精度和分割清晰度方面都会导致次优的3D特征。为了缓解这一问题，我们提出了一种多视图特征融合策略，该策略采用以对象为中心的先验来消除基于语义信息的无信息视图，并通过实例分割掩码在对象级别融合特征。为了提取我们以对象为中心的3D特征，我们生成了一个大规模的合成多视图数据集，其中包含杂乱的桌面场景，从3300多个独特的对象实例中生成了15k个场景，我们将其公之于众。我们表明，我们的方法在从单视图RGB-D重建3D CLIP特征的同时，提高了接地容量和空间一致性，从而偏离了测试时多个相机视图的假设。最后，我们证明了我们的方法可以推广到新的桌面领域，并可以在不进行微调的情况下重新用于3D实例分割，并证明了它在混乱中的语言引导机器人抓取中的实用性 et.al.|[2406.18742](http://arxiv.org/abs/2406.18742)|null|
|**2024-06-25**|**Masked Generative Extractor for Synergistic Representation and 3D Generation of Point Clouds**|在二维图像生成建模和表示学习领域，掩模生成编码器（MAGE）已经证明了生成建模与表示学习之间的协同潜力。受此启发，我们提出Point MAGE将这一概念扩展到点云数据。具体来说，该框架首先利用矢量量化变分自编码器（VQVAE）重建3D形状的神经场表示，从而学习点补丁的离散语义特征。随后，通过将掩蔽模型与可变掩蔽比相结合，我们实现了生成和表示学习的同步训练。此外，我们的框架与现有的点云自监督学习（SSL）模型无缝集成，从而提高了它们的性能。我们广泛评估了Point MAGE的表示学习和生成能力。在形状分类任务中，Point MAGE在ModelNet40数据集上的准确率达到94.2%，在ScanObjectNN数据集上达到92.9%（+1.3%）。此外，它在少数镜头学习和零件分割任务中取得了最新的性能。实验结果还证实，Point MAGE可以在无条件和有条件的设置下生成详细和高质量的3D形状。 et.al.|[2406.17342](http://arxiv.org/abs/2406.17342)|null|
|**2024-06-17**|**DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features**|我们提出了DistillNeRF，这是一个自监督学习框架，解决了在自动驾驶中从有限的2D观察中理解3D环境的挑战。我们的方法是一种可推广的前馈模型，它从稀疏的单帧多视图相机输入中预测丰富的神经场景表示，并通过可微渲染进行自我监督训练，以重建RGB、深度或特征图像。我们的第一个见解是通过生成密集的深度和虚拟相机目标进行训练，利用每场景优化的神经辐射场（NeRF），从而帮助我们的模型从稀疏的非重叠图像输入中学习3D几何。其次，为了学习语义丰富的3D表示，我们建议从预先训练的2D基础模型（如CLIP或DINOv2）中提取特征，从而实现各种下游任务，而不需要昂贵的3D人工注释。为了利用这两个见解，我们引入了一种新的模型架构，该架构具有两级提升-飞溅-射击编码器和参数化的稀疏分层体素表示。NuScenes数据集的实验结果表明，DistillNeRF在场景重建、新颖视图合成和深度估计方面明显优于现有的可比自监督方法；并且它允许竞争性的零样本3D语义占用预测，以及通过提取的基础模型特征来理解开放世界场景。演示和代码将在https://distillnerf.github.io/. et.al.|[2406.12095](http://arxiv.org/abs/2406.12095)|null|
|**2024-06-18**|**Effective Rank Analysis and Regularization for Enhanced 3D Gaussian Splatting**|从多视图图像进行3D重建是计算机视觉和图形学中的基本挑战之一。最近，3D高斯散斑（3DGS）已经成为一种有前景的技术，能够实时渲染高质量的3D重建。该方法利用3D高斯表示和基于图块的飞溅技术，绕过了昂贵的神经场查询。尽管3DGS具有潜力，但由于高斯收敛为具有一个主要方差的各向异性高斯，它遇到了挑战，包括针状伪影、次优几何形状和不准确的法线。我们建议使用有效秩分析来检查3D高斯基元的形状统计，并识别高斯真的收敛到有效秩为1的针状形状。为了解决这个问题，我们引入了有效秩作为正则化，它约束了高斯的结构。我们的新正则化方法增强了法线和几何重建，同时减少了针状伪影。该方法可以作为附加模块集成到其他3DGS变体中，在不损害视觉保真度的情况下提高其质量。 et.al.|[2406.11672](http://arxiv.org/abs/2406.11672)|null|

<p align=right>(<a href=#updated-on-20240722>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

