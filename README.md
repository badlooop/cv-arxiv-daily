[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.11.20
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-11-15**|**SPARS3R: Semantic Prior Alignment and Regularization for Sparse 3D Reconstruction**|最近在基于高斯Splat的新视图合成方面的努力可以实现逼真的渲染；然而，由于稀疏初始化和过度拟合浮点数，这种能力在稀疏视图场景中是有限的。深度估计和对齐的最新进展可以提供视图很少的密集点云；然而，由此产生的姿态精度不是最优的。在这项工作中，我们提出了SPARS3R，它结合了运动结构的精确姿态估计和深度估计的密集点云的优点。为此，SPARS3R首先执行全局融合对齐过程，该过程基于三角化对应关系将先前的密集点云映射到来自运动结构的稀疏点云。在此过程中应用RANSAC来区分内值和外值。SPARS3R然后执行第二个语义异常值对齐步骤，该步骤提取异常值周围的语义连贯区域，并在这些区域中执行局部对齐。随着评估过程的几项改进，我们证明SPARS3R可以实现稀疏图像的真实感渲染，并且明显优于现有方法。 et.al.|[2411.12592](http://arxiv.org/abs/2411.12592)|**[link](https://github.com/snldmt/SPARS3R)**|
|**2024-11-19**|**PR-ENDO: Physically Based Relightable Gaussian Splatting for Endoscopy**|内窥镜手术对癌症的诊断至关重要，三维重建环境以实时合成新视图可以显著提高诊断水平。我们提出了PR-ENDO，这是一个在基于物理的、可重新照明的模型中利用3D高斯散斑的框架，该模型专为内窥镜中的复杂采集条件而定制，例如受限的相机旋转和强烈的视图依赖照明。通过利用相机和光源之间的连接，我们的方法引入了一个重新照明模型，使用基于物理的渲染和MLP来捕捉光和组织之间的复杂相互作用。现有的方法在这些条件下通常会产生伪影和不一致性，PR-ENDO通过结合利用光角度和法向量的专用漫反射MLP来克服这些问题，即使在有限的训练相机旋转下也能实现稳定的重建。我们使用公开可用的数据集和新引入的具有更宽相机旋转的数据集对我们的框架进行了基准测试。与基线方法相比，我们的方法显示出卓越的图像质量。 et.al.|[2411.12510](http://arxiv.org/abs/2411.12510)|**[link](https://github.com/SanoScience/PR-ENDO)**|
|**2024-11-19**|**Beyond Gaussians: Fast and High-Fidelity 3D Splatting with Linear Kernels**|3D高斯散斑（3DGS）的最新进展大大改善了新颖的视图合成，实现了高质量的重建和实时渲染。然而，模糊伪影，如浮动基元和过度重建，仍然具有挑战性。当前的方法通过细化场景结构、增强几何表示、解决训练图像中的模糊、提高渲染一致性和优化密度控制来解决这些问题，但内核设计的作用仍未得到充分探索。我们确定高斯椭球体的软边界是这些伪影的原因之一，限制了高频区域的细节捕捉。为了弥合这一差距，我们引入了3D线性散布（3DLS），它用线性核替换高斯核，以获得更清晰、更精确的结果，特别是在高频区域。通过对三个数据集的评估，3DLS展示了最先进的保真度和准确性，以及比基线3DGS提高30%的FPS。该实施将在接受后公开。\freefootnote{*通讯作者。 et.al.|[2411.12440](http://arxiv.org/abs/2411.12440)|null|
|**2024-11-19**|**DGTR: Distributed Gaussian Turbo-Reconstruction for Sparse-View Vast Scenes**|新的视图合成（NVS）方法在大规模场景重建中起着至关重要的作用。然而，这些方法严重依赖于密集的图像输入和长时间的训练，使得它们不适合计算资源有限的地方。此外，在广阔的环境中，很少有拍摄方法会遇到重建质量差的问题。本文提出了DGTR，这是一种新的分布式框架，用于稀疏视图广阔场景的高效高斯重建。我们的方法将场景划分为多个区域，由具有稀疏图像输入的无人机独立处理。使用前馈高斯模型，我们预测高质量的高斯基元，然后使用全局对齐算法来确保几何一致性。综合视图和深度先验被纳入以进一步增强训练，而基于蒸馏的模型聚合机制能够实现高效的重建。我们的方法在显著减少的训练时间内实现了高质量的大规模场景重建和新颖的视图合成，在速度和可扩展性方面都优于现有方法。我们在广阔的空中场景中展示了我们的框架的有效性，在几分钟内实现了高质量的结果。代码将在我们的！[项目页面](https://3d-aigc.github.com/DGTR). et.al.|[2411.12309](http://arxiv.org/abs/2411.12309)|null|
|**2024-11-19**|**LiV-GS: LiDAR-Vision Integration for 3D Gaussian Splatting SLAM in Outdoor Environments**|我们介绍了LiV GS，这是一种户外环境中的LiDAR视觉SLAM系统，它利用3D高斯作为可微分的空间表示。值得注意的是，LiV-GS是第一种在大规模室外场景中直接将离散和稀疏LiDAR数据与连续可微高斯地图对齐的方法，克服了传统LiDAR测绘中固定分辨率的局限性。该系统使用共享的协方差属性进行前端跟踪，将点云与高斯图对齐，并将法线方向整合到损失函数中以细化高斯图。为了在激光雷达视场外可靠稳定地更新高斯分布，我们引入了一种新的条件高斯约束，将这些高斯分布与最近的可靠分布紧密对齐。目标调整使LiV GS能够以7.98 FPS的速率通过新颖的视图合成实现快速准确的映射。广泛的对比实验证明了LiV-GS在SLAM、图像渲染和映射方面的卓越性能。成功的跨模态雷达LiDAR定位突显了LiV GS在跨模态语义定位和高斯图对象分割中的应用潜力。 et.al.|[2411.12185](http://arxiv.org/abs/2411.12185)|null|
|**2024-11-18**|**SpatialDreamer: Self-supervised Stereo Video Synthesis from Monocular Input**|单目输入的立体视频合成是空间计算和虚拟现实领域的一项艰巨任务。这项任务的主要挑战在于用于训练的高质量配对立体视频不足，以及难以保持帧之间的时空一致性。现有的方法主要通过将新颖的视图合成（NVS）技术直接应用于视频来解决这些问题，同时面临着无法有效地表示动态场景和需要大量训练数据等局限性。本文介绍了一种新的通过视频扩散模型的自监督立体视频合成范式，称为SpatialDreamer，它正面应对了挑战。首先，为了解决立体视频数据不足的问题，我们提出了一种基于深度的视频生成模块DVG，该模块采用前向后向渲染机制生成具有几何和时间先验的配对视频。利用DVG生成的数据，我们提出了RefinerNet以及一个自我监督的综合框架，旨在促进高效和专门的培训。更重要的是，我们设计了一个一致性控制模块，该模块由立体偏差强度度量和时间交互学习模块TIL组成，分别用于几何和时间一致性保证。我们根据各种基准方法对提出的方法进行了评估，结果显示了其优越的性能。 et.al.|[2411.11934](http://arxiv.org/abs/2411.11934)|null|
|**2024-11-16**|**DiHuR: Diffusion-Guided Generalizable Human Reconstruction**|我们介绍了DiHuR，这是一种新的扩散引导模型，用于从稀疏、最小重叠的图像中进行可推广的人体3D重建和视图合成。虽然现有的可推广的人类辐射场在新颖的视图合成方面表现出色，但它们往往难以进行全面的3D重建。同样，由于重叠有限，直接优化稀疏视图图像中的隐式有符号距离函数（SDF）场通常会产生较差的结果。为了提高3D重建质量，我们建议使用与SMPL顶点相关的可学习标记来聚合稀疏视图特征，然后指导SDF预测。这些标记学习训练数据集中不同身份的可泛化先验，利用SMPL顶点在各种人类身份的相似语义区域上的一致投影。这种一致性使得在推理过程中能够有效地将知识转移到看不见的身份。认识到SMPL在捕捉服装细节方面的局限性，我们引入了一个扩散模型作为补充，以填补缺失的信息，特别是对于复杂的服装几何形状。我们的方法以连贯的方式集成了两个关键先验：来自可推广前馈模型的先验和2D扩散先验，它只需要多视图图像训练，不需要3D监督。与现有方法相比，DiHuR在数据集内和跨数据集泛化设置中表现出卓越的性能，这在THuman、ZJU MoCap和HuMMan数据集上得到了验证。 et.al.|[2411.11903](http://arxiv.org/abs/2411.11903)|null|
|**2024-11-18**|**GPS-Gaussian+: Generalizable Pixel-wise 3D Gaussian Splatting for Real-Time Human-Scene Rendering from Sparse Views**|微分渲染技术最近在字符的自由视点视频合成方面显示出了有前景的结果。然而，无论是高斯散点还是神经隐式渲染，这些方法通常都需要针对每个主题进行优化，这不符合交互式应用程序中实时渲染的要求。我们提出了一种可推广的高斯散斑方法，用于稀疏视图相机设置下的高分辨率图像渲染。为此，我们引入了在源视图上定义的高斯参数映射，并直接回归高斯属性，用于即时新视图合成，而无需任何微调或优化。我们在纯人类数据或人类场景数据上训练高斯参数回归模块，并与深度估计模块联合将2D参数图提升到3D空间。所提出的框架在深度和渲染监督或仅渲染监督方面都是完全可区分的。我们进一步引入了正则化项和极线注意机制，以保持两个源视图之间的几何一致性，特别是在忽略深度监督的情况下。在几个数据集上的实验表明，我们的方法优于最先进的方法，同时实现了超高的渲染速度。 et.al.|[2411.11363](http://arxiv.org/abs/2411.11363)|null|
|**2024-11-17**|**Direct and Explicit 3D Generation from a Single Image**|当前的图像到3D方法存在计算成本高和缺乏高分辨率输出的可扩展性的问题。相比之下，我们引入了一种新的框架，使用多视图2D深度和RGB图像以及使用重新调整用途的稳定扩散模型的3D高斯特征直接生成显式的表面几何和纹理。我们在U-Net中引入了一个深度分支，用于高效和高质量的多视图、跨域生成，并将极线注意力纳入潜在的像素级多视图一致性解码器中。通过将生成的深度像素反向投影到3D空间中，我们创建了一个结构化的3D表示，该表示可以通过高斯散点渲染或提取到高质量网格中，从而利用额外的新颖视图合成损失来进一步提高我们的性能。大量实验表明，我们的方法在几何和纹理质量方面超越了现有的基线，同时实现了显著更快的生成时间。 et.al.|[2411.10947](http://arxiv.org/abs/2411.10947)|null|
|**2024-11-16**|**DGS-SLAM: Gaussian Splatting SLAM in Dynamic Environment**|我们介绍了动态高斯散斑SLAM（DGS-SLAM），这是第一个建立在高斯散斑基础上的动态SLAM框架。虽然密集SLAM的最新进展利用高斯散斑来增强场景表示，但大多数方法都假设是静态环境，这使得它们容易受到动态对象引起的光度和几何不一致的影响。为了应对这些挑战，我们将高斯散斑SLAM与稳健的滤波过程相结合，以处理整个管道中的动态对象，包括高斯插入和关键帧选择。在此框架内，为了进一步提高动态对象去除的准确性，我们引入了一种鲁棒的掩模生成方法，该方法在关键帧之间强制实现光度一致性，减少了不准确分割和阴影等伪影的噪声。此外，我们提出了循环感知窗口选择机制，该机制利用3D高斯的唯一关键帧ID来检测当前帧和过去帧之间的循环，从而促进当前相机姿态和高斯图的联合优化。DGS-SLAM在各种动态SLAM基准上实现了最先进的相机跟踪和新颖的视图合成性能，证明了其在处理现实世界动态场景方面的有效性。 et.al.|[2411.10722](http://arxiv.org/abs/2411.10722)|null|

<p align=right>(<a href=#updated-on-20241120>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-11-19**|**M3D: Dual-Stream Selective State Spaces and Depth-Driven Framework for High-Fidelity Single-View 3D Reconstruction**|在复杂场景中从单个RGB图像精确重建3D对象是虚拟现实、自动驾驶和机器人技术的一个关键挑战。现有的神经隐式3D表示方法在平衡全局和局部特征的提取方面面临着重大困难，特别是在多样化和复杂的环境中，导致重建精度和质量不足。我们提出了M3D，一种新颖的单视图3D重建框架，以应对这些挑战。该框架采用基于选择性状态空间的双流特征提取策略，有效地平衡了全局和局部特征的提取，从而提高了场景理解和表示精度。此外，并行分支提取深度信息，有效地整合视觉和几何特征，以提高重建质量并保留复杂的细节。实验结果表明，通过双分支特征提取将多尺度特征与深度信息融合，显著提高了几何一致性和保真度，实现了最先进的重建性能。 et.al.|[2411.12635](http://arxiv.org/abs/2411.12635)|**[link](https://github.com/AnnnnnieZhang/M3D)**|
|**2024-11-19**|**3D Reconstruction by Looking: Instantaneous Blind Spot Detector for Indoor SLAM through Mixed Reality**|室内SLAM经常遇到场景漂移、双墙和盲点等问题，特别是在重建任务中物体靠近传感器（如LiDAR和摄像头）的密闭空间中。数据收集期间点云注册的实时可视化可能有助于缓解这些问题，但无法将扫描数据与实际物理环境进行深入比较仍然是一个重大限制。这些挑战阻碍了重建产品的质量，经常需要重新审视和重新扫描。为此，我们开发了LiMRSF（LiDAR MR RGB传感器融合）系统，允许用户通过混合现实（MR）耳机查看来感知现场点云注册。这个定制的框架将点云网格可视化为全息图，与透视眼镜上的实时场景无缝匹配，并自动突出显示重叠时检测到的错误。这种全息元素通过TCP服务器传输到MR耳机，在那里进行校准，使其与世界坐标、物理位置对齐。这允许用户即时查看本地化的重建产品，使他们能够快速识别盲点和错误，并在现场迅速采取行动。我们的盲点检测器实现了错误检测精度，F1分数为75.76%，通过LiMRSF系统实现了可接受的高保真度监测（在简化网格模型的五个不同部分中，最高SSIM为0.5619，PSNR为14.1004，最低MSE为0.0389，用户通过LiMRSF设备透过眼镜进行可视化）。这种方法可确保为3D模型创建详细、高质量的数据集，在建筑信息建模（BIM）中具有潜在的应用，但不仅限于此。 et.al.|[2411.12514](http://arxiv.org/abs/2411.12514)|null|
|**2024-11-19**|**Target Height Estimation Using a Single Acoustic Camera for Compensation in 2D Seabed Mosaicking**|这封信提出了一种补偿二维海底拼接中目标高度数据的新方法，用于低能见度水下感知。由于其高分辨率成像能力和对黑暗和浑浊的鲁棒性，声相机是感知海洋环境的有效传感器。然而，成像过程中仰角的损失导致原始声相机图像中缺乏目标高度信息，导致海底拼接的二维表示过于简单。在感知杂乱和未经探索的海洋环境时，目标高度数据对于避免与海洋机器人碰撞至关重要。本研究提出了一种使用单个声相机估计海底目标高度的新方法，并将高度数据整合到二维海底拼接中，以补偿海底目标缺失的三维维度。与模拟仰角损失以实现海底三维重建的经典方法不同，本研究侧重于利用可用的声投射阴影线索和简单的传感器运动来快速估计目标高度。通过水箱实验和模拟实验验证了我们建议的可行性。 et.al.|[2411.12338](http://arxiv.org/abs/2411.12338)|null|
|**2024-11-19**|**MTFusion: Reconstructing Any 3D Object from Single Image Using Multi-word Textual Inversion**|从单视图图像重建3D模型是计算机视觉中一个长期存在的问题。单图像3D重建的最新进展是从输入图像中提取文本描述，并进一步利用它来合成3D模型。然而，现有的方法侧重于捕捉图像的单个关键属性（例如，对象类型、艺术风格），而没有考虑到精确3D重建所需的多视角信息，如对象形状和材料属性。此外，对神经辐射场的依赖阻碍了它们重建复杂表面和纹理细节的能力。在这项工作中，我们提出了MTFusion，它利用图像数据和文本描述进行高保真3D重建。我们的方法包括两个阶段。首先，我们采用了一种新颖的多词文本反转技术来提取捕获图像特征的详细文本描述。然后，我们使用此描述和图像使用FlexiCubes生成3D模型。此外，MTFusion通过为有符号距离函数采用特殊的解码器网络来增强FlexiCubes，从而实现更快的训练和更精细的表面表示。广泛的评估表明，我们的MTFusion在广泛的合成和现实世界图像上超越了现有的图像到3D方法。此外，消融研究证明了我们网络设计的有效性。 et.al.|[2411.12197](http://arxiv.org/abs/2411.12197)|null|
|**2024-11-16**|**DiHuR: Diffusion-Guided Generalizable Human Reconstruction**|我们介绍了DiHuR，这是一种新的扩散引导模型，用于从稀疏、最小重叠的图像中进行可推广的人体3D重建和视图合成。虽然现有的可推广的人类辐射场在新颖的视图合成方面表现出色，但它们往往难以进行全面的3D重建。同样，由于重叠有限，直接优化稀疏视图图像中的隐式有符号距离函数（SDF）场通常会产生较差的结果。为了提高3D重建质量，我们建议使用与SMPL顶点相关的可学习标记来聚合稀疏视图特征，然后指导SDF预测。这些标记学习训练数据集中不同身份的可泛化先验，利用SMPL顶点在各种人类身份的相似语义区域上的一致投影。这种一致性使得在推理过程中能够有效地将知识转移到看不见的身份。认识到SMPL在捕捉服装细节方面的局限性，我们引入了一个扩散模型作为补充，以填补缺失的信息，特别是对于复杂的服装几何形状。我们的方法以连贯的方式集成了两个关键先验：来自可推广前馈模型的先验和2D扩散先验，它只需要多视图图像训练，不需要3D监督。与现有方法相比，DiHuR在数据集内和跨数据集泛化设置中表现出卓越的性能，这在THuman、ZJU MoCap和HuMMan数据集上得到了验证。 et.al.|[2411.11903](http://arxiv.org/abs/2411.11903)|null|
|**2024-11-18**|**Towards Degradation-Robust Reconstruction in Generalizable NeRF**|跨场景的广义神经辐射场（GNeRF）已被证明是一种有效的方法，通过用源图像的深度图像特征表示场景来避免每场景优化。然而，尽管GNeRF具有现实应用的潜力，但关于其对源图像中存在的不同类型退化的鲁棒性的研究有限。缺乏此类研究的主要原因是缺乏适合训练退化鲁棒可推广NeRF模型的大规模数据集。为了解决这一差距并促进对3D重建任务退化鲁棒性的研究，我们构建了Objaverse模糊数据集，该数据集包含来自1000多个设置的50000张图像，具有多个级别的模糊退化。此外，我们设计了一个简单且与模型无关的模块，用于增强GNeRF的退化鲁棒性。具体而言，通过轻量级深度估计器和去噪器提取3D感知特征，所提出的模块在不同退化类型和水平下，在定量和视觉质量方面都比GNeRF中的不同流行方法有所改进。我们的数据集和代码将公开。 et.al.|[2411.11691](http://arxiv.org/abs/2411.11691)|null|
|**2024-11-18**|**VLN-Game: Vision-Language Equilibrium Search for Zero-Shot Semantic Navigation**|遵循人类指令在陌生环境中探索和搜索指定目标是移动服务机器人的一项关键技能。之前关于目标导航的大部分工作通常都集中在单一输入模态作为目标上，这可能会导致对包含详细属性和空间关系的语言描述的考虑有限。为了解决这一限制，我们提出了VLN-Game，这是一种新的用于视觉目标导航的零样本框架，可以有效地处理对象名称和描述性语言目标。更精确地说，我们的方法通过将预训练的视觉语言特征与物理环境的3D重建相结合，构建了一个以3D对象为中心的空间地图。然后，该框架确定了最有希望探索的领域，以寻找潜在的目标候选者。采用博弈论视觉语言模型来确定哪个目标与给定的语言描述最匹配。在Habitat Matterport 3D（HM3D）数据集上进行的实验表明，所提出的框架在目标导航和基于语言的导航任务中都达到了最先进的性能。此外，我们证明了VLN Game可以很容易地部署在现实世界的机器人上。VLN-Game的成功凸显了使用博弈论方法和紧凑的视觉语言模型来提高机器人系统决策能力的巨大潜力。可以通过以下链接访问补充视频和代码：https://sites.google.com/view/vln-game. et.al.|[2411.11609](http://arxiv.org/abs/2411.11609)|null|
|**2024-11-17**|**BVI-CR: A Multi-View Human Dataset for Volumetric Video Compression**|沉浸式技术和3D重建的进步使得能够创建具有精细细节的现实世界物体和环境的数字复制品。这些过程会生成大量的3D数据，需要更有效的压缩方法来满足与数据存储和传输相关的内存和带宽限制。然而，有效的3D数据压缩方法的开发和验证受到缺乏全面和高质量的体视频数据集的限制，与2D图像和视频数据库相比，这通常需要付出更多的努力来获取和消耗更多的资源。为了弥合这一差距，我们提出了一个开放的多视图体积人体数据集，称为BVI-CR，其中包含18个多视图RGB-D捕获及其相应的纹理多边形网格，描绘了一系列不同的人体动作。每个视频序列包含10个1080p分辨率的视图，持续时间为10-15秒，帧率为30FPS。使用BVI-CR，我们按照MPEG MIV通用测试条件，对三种传统的基于神经坐标的多视图视频压缩方法进行了基准测试，并根据各种质量指标报告了它们的速率质量性能。结果表明，与传统的视频编码方法相比，基于神经表示的方法在体视频压缩中具有巨大的潜力（PSNR平均编码增益高达38%）。该数据集为各种任务提供了一个开发和验证平台，包括体积重建、压缩和质量评估。数据库将在\url公开共享{https://github.com/fan-aaron-zhang/bvi-cr}. et.al.|[2411.11199](http://arxiv.org/abs/2411.11199)|null|
|**2024-11-16**|**ARM: Appearance Reconstruction Model for Relightable 3D Generation**|最近的图像到3D重建模型极大地改进了几何生成，但它们仍然难以忠实地生成逼真的外观。为了解决这个问题，我们引入了ARM，这是一种从稀疏视图图像重建高质量3D网格和逼真外观的新方法。ARM的核心在于将几何与外观解耦，在UV纹理空间内处理外观。与以前的方法不同，ARM通过明确地将测量值反向投影到纹理贴图上，并在具有全局感受野的UV空间模块中对其进行处理，从而提高了纹理质量。为了解决输入图像中材质和光照之间的歧义，ARM引入了一种材质先验，对语义外观信息进行编码，增强了外观分解的鲁棒性。仅在8个H100 GPU上训练，ARM在数量和质量上都优于现有方法。 et.al.|[2411.10825](http://arxiv.org/abs/2411.10825)|null|
|**2024-11-16**|**Poster: Reliable 3D Reconstruction for Ad-hoc Edge Implementations**|支持实时复杂视频处理应用程序（如多视图3D重建）的自组织边缘部署通常会受到时空系统中断的影响，这会极大地影响重建质量。在这篇海报论文中，我们提出了一种受投资组合理论启发的边缘资源管理策略，通过考虑可能的系统中断来确保可靠的多视图3D重建。 et.al.|[2411.10705](http://arxiv.org/abs/2411.10705)|null|

<p align=right>(<a href=#updated-on-20241120>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-11-19**|**Quantum-assisted hλ-adaptive finite element method**|我们提出了一种用于奇异摄动平流扩散反应问题的新型有限元方法方案，该方案将某些量子辅助稳定方案与经典的h自适应方法相结合，以提供自动误差控制和相应的近似细化。证明了适当的有限元后验误差估计。所描述的方法证明了通过将误差控制平滑应用于有限元近似来克服奇异扰动的可能性。讨论了所提出的有限元方案的可能好处，并与典型的自适应方案进行了数值比较。 et.al.|[2411.12687](http://arxiv.org/abs/2411.12687)|null|
|**2024-11-19**|**PoM: Efficient Image and Video Generation with the Polynomial Mixer**|基于多头注意力（MHA）的扩散模型已经无处不在，可以生成高质量的图像和视频。然而，将图像或视频编码为补丁序列会导致代价高昂的注意力模式，因为内存和计算方面的要求都是二次增长的。为了缓解这个问题，我们提出了一种称为多项式混合器（PoM）的MHA替代品，其优点是将整个序列编码为显式状态。PoM的复杂性与代币数量呈线性关系。这种显式状态还允许我们以顺序方式生成帧，最大限度地减少内存和计算需求，同时仍然能够并行训练。我们证明多项式混合器是一个通用的序列到序列近似器，就像常规的MHA一样。我们采用了几种扩散变换器（DiT）来生成图像和视频，其中PoM取代了MHA，我们在使用较少计算资源的同时获得了高质量的样本。该代码可在以下网址获得https://github.com/davidpicard/HoMM. et.al.|[2411.12663](http://arxiv.org/abs/2411.12663)|**[link](https://github.com/davidpicard/homm)**|
|**2024-11-19**|**Implementation and performance of a fiber-coupled CMOS camera in an ultrafast reflective high-energy electron diffraction experiment**|报道了在我们的超高真空（UHV）超快反射高能电子衍射装置中实现基于单片光纤光学耦合CMOS的TemCam-XF416相机。可泵送闸阀和自建冷却环的组合允许在不需要拆除热敏器件的情况下达到特高压条件。水冷环安装在相机外壳上，可防止探测器在特高压室烘烤时发热。TemCam提供的空间分辨率比以前使用的基于微通道板（MCP）的探测器（Burle Chevron 3040FM）高一个数量级，这使得在互易空间中的分辨率提高了30%。低背景强度和4倍大的动态范围使得能够分析像菊池线和带这样的衍射图案的漫射强度。与之前的MCP探测器相比，一个关键的优势是完全没有高光溢出效应，这使得能够对衍射斑点进行定量斑点轮廓分析。光泵实验中固有的光敏性可以通过使用h<1.12 eV的光子（即硅的间接带隙）或屏蔽任何杂散光来克服。 et.al.|[2411.12660](http://arxiv.org/abs/2411.12660)|null|
|**2024-11-19**|**Scaling invariance for the diffusion coefficient in a dissipative standard mapping**|由于违反了Liouville定理，在高非线性状态下观察到的标准映射的无界扩散被耗散抑制。扩散系数对于描述缩放不变性，特别是对于抑制无界作用扩散，变得非常重要。当动力学在低作用状态下开始时，扩散系数长时间保持恒定，保证了粒子系综的扩散。最终，它演变成一种衰变机制，标志着粒子作用增长的抑制。我们证明了它对控制参数和交叉时间具有标度不变性，用于识别从常数域到扩散的转换，对于标记扩散饱和的衰变机制，对于耗散时间相关台球系统中从有界到无界扩散的转换具有相同的临界指数 $z=-1$ 。 et.al.|[2411.12648](http://arxiv.org/abs/2411.12648)|null|
|**2024-11-19**|**Improving Controllability and Editability for Pretrained Text-to-Music Generation Models**|人工智能辅助音乐创作领域取得了重大进展，但现有系统往往难以满足迭代和细致入微的音乐制作需求。这些挑战包括对生成的内容提供足够的控制，并允许灵活、精确的编辑。本文通过引入一系列逐步相互构建的进步来解决这些问题，提高了文本到音乐生成模型的可控性和可编辑性。首先，我们介绍Loop Copilot，这是一个试图解决音乐创作中迭代细化需求的系统。Loop Copilot利用大型语言模型（LLM）来协调多个专业的AI模型，使用户能够通过对话界面交互式地生成和改进音乐。该系统的核心是全局属性表，它在整个迭代过程中记录和维护关键的音乐属性，确保在任何阶段的修改都能保持音乐的整体连贯性。虽然Loop Copilot擅长编排音乐创作过程，但它并没有直接解决对生成内容进行详细编辑的需求。为了克服这一局限性，MusicMagus被提出作为编辑人工智能生成音乐的进一步解决方案。MusicMagus引入了零样本文本到音乐的编辑方法，允许修改特定的音乐属性，如流派、情绪和乐器，而无需再培训。通过操纵预训练扩散模型中的潜在空间，MusicMagus确保这些编辑在风格上连贯一致，非目标属性保持不变。该系统在编辑过程中特别有效地保持了音乐的结构完整性，但在更复杂和真实的音频场景中遇到了挑战。。。 et.al.|[2411.12641](http://arxiv.org/abs/2411.12641)|null|
|**2024-11-19**|**ChemSICal: Evaluating a Stochastic Chemical Reaction Network for Molecular Multiple Access**|作为未来生物纳米物联网一部分的分子通信网络的提议变得更加复杂，实际实施的问题也变得越来越重要。一种选择是应用详细的化学建模来捕捉生物系统中计算过程的更真实的效果。在本文中，我们提出了ChemSICal，这是一个详细的模型，用于在基于扩散的分子通信网络中实现连续干扰消除（SIC）算法，作为化学反应网络（CRN）。我们将模型的结构描述为许多较小的反应块，它们的速度由反应速率常数（RRCs）控制。利用确定性和随机性方法，首先迭代地改进RRC的选择，然后根据错误概率研究模型的性能。我们分析了模型对参数变化的敏感性，发现非化学模型的分析最优值不一定转化为化学域。这需要仔细优化，特别是RRC，这对ChemSICal系统的成功运行至关重要。 et.al.|[2411.12637](http://arxiv.org/abs/2411.12637)|null|
|**2024-11-19**|**Instant Policy: In-Context Imitation Learning via Graph Diffusion**|在大型变压器的上下文学习能力令人印象深刻之后，上下文模仿学习（ICIL）为机器人技术提供了一个有前景的机会。我们引入了即时策略，它只需一两次演示即可立即学习新任务（无需进一步培训），通过两个关键组件实现ICIL。首先，我们通过图表示引入归纳偏差，并将ICIL建模为具有学习扩散过程的图生成问题，从而对演示、观察和行动进行结构化推理。其次，我们证明，这种模型可以使用伪演示（模拟中生成的任意轨迹）作为几乎无限的训练数据池进行训练。模拟和真实实验表明，即时策略能够快速学习各种日常机器人任务。我们还展示了它如何作为交叉实施和零样本转移到语言定义任务的基础。代码和视频可在https://www.robot-learning.uk/instant-policy. et.al.|[2411.12633](http://arxiv.org/abs/2411.12633)|null|
|**2024-11-19**|**Exploring the Manifold of Neural Networks Using Diffusion Geometry**|从流形假设中汲取动力，该假设认为大多数高维数据位于低维流形上或附近，我们将流形学习应用于神经网络空间。我们通过在神经网络的隐藏层表示之间引入距离来学习数据点是神经网络的流形。然后，这些距离被馈送到非线性降维算法PHATE，以创建神经网络的流形。我们使用表示特征来表征这个流形，包括类分离、层次聚类结构、谱熵和拓扑结构。我们的分析表明，高性能网络在流形中聚集在一起，在所有这些特征上显示出一致的嵌入模式。最后，我们证明了该方法通过从流形采样来指导超参数优化和神经架构搜索的实用性。 et.al.|[2411.12626](http://arxiv.org/abs/2411.12626)|null|
|**2024-11-19**|**CHANG-ES XXXV: Cosmic Ray Transport and Magnetic Field Structure of NGC 3556 at 3 GHz**|边缘星系的射电晕对于研究星系环境中的宇宙射线传播和磁场结构至关重要。我们呈现了对螺旋星系NGC 3556的VLA C配置S波段（2-4 GHz）观测，该星系是EVLA巡天（CHANG-ES）附近星系连续晕的目标。我们通过H $\alpha$和中红外数据的组合来估计对无线电发射的热贡献，并采用旋转测量合成来揭示磁场结构。在我们的数据中，NGC 3556显示出一个从星系平面延伸近7kpc的箱形射电晕。晕中总S带强度的标度高度为1.68美元/分0.29美元/千帕，而非热强度的标化高度为1.93美元/分0.23美元/千巴。将数据拟合到1-D宇宙射线输运模型中，我们发现平流比扩散更好地描述了光环内的宇宙射线传播，平流速度分别为圆盘上方和下方245美元/分钟15美元/公里^{-1}$和205美元/分钟25美元/公里^{-1}$。磁场在整个星系中零星地被探测到，在旋转测量图中显示出环形结构。平均均分磁场强度在磁盘中约为8.3美元-G，在光环中约为4.5美元-G。此外，一个气泡状结构延伸到南晕近3~kpc，与极化强度和H$\alpha$ 图像对齐，表明核区最近恒星形成反馈产生的超级风。 et.al.|[2411.12564](http://arxiv.org/abs/2411.12564)|null|
|**2024-11-19**|**When Theory Meets Experiment: What Does it Take to Accurately Predict $^1$H NMR Dipolar Relaxation Rates in Neat Liquid Water from Theory?**|在这篇文章中，我们计算了液态水在环境条件下的核磁共振（NMR）弛豫速率。我们正在使用以CCSD（T）电子结构精度生成的耦合团簇分子动力学（CCMD）轨迹的结构和动力学信息，同时除了参考X射线和中子散射实验的信息外，还考虑了核量子效应。我们的分析基于最近提出的计算框架，用于确定分子动力学（MD）模拟中自旋1/2$核的频率相关NMR偶极-偶极弛豫率，该框架允许有效地解开其结构和动力学贡献，并包括对具有周期性边界条件的MD模拟固有的有限尺寸效应的校正。根据H-H向量$D_0\times\tau_\mathrm{HH}$的自扩散系数和重新定向相关时间的乘积，如果考虑CCMD轨迹的结构和动力学信息，包括旋转和平移动力学的重新平衡，则与实验弛豫数据几乎完全一致。模拟表明，当考虑到核量子效应时，这种平衡会发生显著变化。我们的分析表明，分子间和分子内对液态水$^1$ H NMR弛豫速率的贡献在幅度上几乎相似，这与之前经典MD模拟的预测不同。 et.al.|[2411.12545](http://arxiv.org/abs/2411.12545)|null|

<p align=right>(<a href=#updated-on-20241120>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-11-18**|**NeuMaDiff: Neural Material Synthesis via Hyperdiffusion**|高质量的材料合成对于复制复杂的表面特性以创建逼真的数字场景至关重要。然而，现有的方法往往在时间和内存方面效率低下，需要领域专业知识，或者需要大量的训练数据，而高维材料数据进一步限制了性能。此外，大多数方法缺乏多模态制导能力和标准化的评估指标，限制了综合任务的控制和可比性。为了解决这些局限性，我们提出了NeuMaDiff，这是一种利用超扩散的新型神经材料合成框架。我们的方法采用神经场作为低维表示，并结合了多模态条件超扩散模型来学习材料重量的分布。这使得通过材料类型、文本描述或参考图像等输入进行灵活指导成为可能，从而对合成提供了更大的控制。为了支持未来的研究，我们贡献了两个新的材料数据集，并引入了两个BRDF分布度量，以进行更严格的评估。我们通过广泛的实验证明了NeuMaDiff的有效性，包括一种新的基于统计的约束合成方法，该方法能够生成所需类别的材料。 et.al.|[2411.12015](http://arxiv.org/abs/2411.12015)|null|
|**2024-11-14**|**The Hydrodynamic Limit of Hawkes Processes on Adaptive Stochastic Networks**|我们确定了自适应网络上相互作用的霍克斯过程网络的大尺寸限制。节点变量的翻转被认为具有由传入边缘和节点的平均场给出的强度。边缘变量的翻转是传入节点变量的函数。边变量可以是对称的，也可以是不对称的。该模型受到社会学、神经科学和流行病学应用的启发。一般来说，极限概率律可以表示为具有强度函数的自洽泊松过程的不动点，该强度函数（i）是延迟的，（ii）取决于其自身的概率律。在边缘翻转仅由突触前神经元的状态决定的特定情况下（如神经科学中），证明了可以获得突触增强和神经增强双重进化的自主神经场型方程。 et.al.|[2411.09260](http://arxiv.org/abs/2411.09260)|null|
|**2024-11-09**|**Epi-NAF: Enhancing Neural Attenuation Fields for Limited-Angle CT with Epipolar Consistency Conditions**|神经场方法最初在逆渲染领域取得了成功，最近已扩展到CT重建，标志着传统技术的范式转变。虽然这些方法在稀疏视图CT重建中提供了最先进的结果，但它们在有限的角度设置中很难实现，在有限的视角范围内捕获输入投影。我们提出了一种基于X射线投影图像中相应极线之间一致性条件的新损失项，旨在规范神经衰减场优化。通过强制执行这些一致性条件，我们的方法Epi NAF将监督从有限角度范围内的输入视图传播到整个锥束CT范围内的预测投影。与基线方法相比，这种损失导致重建的定性和定量改进。 et.al.|[2411.06181](http://arxiv.org/abs/2411.06181)|null|
|**2024-11-07**|**LoFi: Scalable Local Image Reconstruction with Implicit Neural Representation**|神经场或隐式神经表示（INR）因其对图像和3D体积的有效连续表示而在机器学习和信号处理中引起了广泛关注。在这项工作中，我们以INR为基础，引入了一种基于坐标的局部处理框架来解决成像逆问题，称为LoFi（局部场）。与传统的图像重建方法不同，LoFi通过多层感知器（MLP）分别处理每个坐标处的局部信息，在该特定坐标处恢复对象。与INR类似，LoFi可以在任何连续坐标下恢复图像，从而实现多分辨率的图像重建。LoFi在图像重建方面的性能与标准CNN相当或更好，几乎与图像分辨率无关，对分布外数据和内存使用具有出色的泛化能力。值得注意的是，对1024美元×1024美元的图像进行训练只需要3GB的内存，比标准CNN通常需要的内存少20多倍。此外，LoFi的局部设计使其能够在小于10个样本的极小数据集上进行训练，而不会过拟合或需要正则化或提前停止。最后，我们使用LoFi作为即插即用框架中的去噪先验，用于解决一般的逆问题，以受益于其连续的图像表示和强大的泛化能力。尽管在低分辨率图像上进行了训练，但LoFi可以用作低维先验，以解决任何分辨率的逆问题。我们通过各种成像方式验证了我们的框架，从低剂量计算机断层扫描到无线电干涉成像。 et.al.|[2411.04995](http://arxiv.org/abs/2411.04995)|null|
|**2024-11-04**|**Physically Based Neural Bidirectional Reflectance Distribution Function**|我们介绍了基于物理的神经双向反射分布函数（PBNBRDF），这是一种基于神经场的材料外观的新颖连续表示。我们的模型准确地重建了真实世界的材料，同时独特地增强了现实BRDF的物理特性，特别是通过重新参数化的亥姆霍兹互易性和通过高效分析积分的能量无源性。我们进行了系统分析，证明了遵守这些物理定律对重建材料的视觉质量的好处。此外，我们通过引入色度强制监督RGB通道的规范来提高神经BRDF的颜色精度。通过在多个测量的真实BRDF数据库上进行定性和定量实验，我们表明，遵守这些物理约束可以使神经场更忠实、更稳定地表示原始数据，并实现更高的渲染质量。 et.al.|[2411.02347](http://arxiv.org/abs/2411.02347)|null|
|**2024-11-01**|**Intensity Field Decomposition for Tissue-Guided Neural Tomography**|锥束计算机断层扫描（CBCT）通常需要数百次X射线投影，这引起了人们对辐射暴露的担忧。虽然稀疏视图重建通过使用更少的投影来减少曝光，但它很难达到令人满意的图像质量。为了应对这一挑战，本文介绍了一种新的稀疏视图CBCT重建方法，该方法为神经场赋予了人体组织正则化的能力。我们的方法被称为组织引导神经断层扫描（TNT），其动机是CBCT中骨骼和软组织之间明显的强度差异。直观地说，分离这些成分可能有助于神经场的学习过程。更确切地说，TNT包括一个异构的四重网络和相应的训练策略。该网络将强度场表示为软组织和硬组织成分及其各自纹理的组合。我们在估计的组织投影的指导下训练网络，从而能够有效地学习网络头所需的模式。大量实验表明，所提出的方法显著改善了稀疏视图CBCT重建，投影数量从10到60不等。与最先进的基于神经渲染的方法相比，我们的方法以更少的投影和更快的收敛实现了相当的重建质量。 et.al.|[2411.00900](http://arxiv.org/abs/2411.00900)|null|
|**2024-10-26**|**Neural Fields in Robotics: A Survey**|神经场已经成为计算机视觉和机器人技术中3D场景表示的一种变革性方法，能够从姿势的2D数据中准确推断几何、3D语义和动力学。利用可微分渲染，神经场包括连续隐式和显式神经表示，实现了高保真3D重建、多模态传感器数据的集成和新视点的生成。这项调查探讨了它们在机器人技术中的应用，强调了它们在增强感知、规划和控制方面的潜力。它们的紧凑性、内存效率和可微性，以及与基础模型和生成模型的无缝集成，使其成为实时应用的理想选择，提高了机器人的适应性和决策能力。本文基于200多篇论文，对机器人中的神经场进行了全面的回顾，对各个领域的应用进行了分类，并评估了它们的优势和局限性。首先，我们介绍了四个关键的神经场框架：占用网络、有符号距离场、神经辐射场和高斯散斑。其次，我们详细介绍了神经场在五个主要机器人领域的应用：姿态估计、操纵、导航、物理和自动驾驶，重点介绍了关键工作，并讨论了要点和公开挑战。最后，我们概述了神经场在机器人技术中的局限性，并为未来的研究提出了有前景的方向。项目页面：https://robonerf.github.io et.al.|[2410.20220](http://arxiv.org/abs/2410.20220)|**[link](https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics)**|
|**2024-10-24**|**3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation**|多视图图像扩散模型显著推进了开放域3D对象生成。然而，大多数现有模型依赖于缺乏固有3D偏差的2D网络架构，导致几何一致性受损。为了应对这一挑战，我们引入了3D Adapter，这是一个插件模块，旨在将3D几何感知注入预训练的图像扩散模型中。我们方法的核心是3D反馈增强的思想：对于采样循环中的每个去噪步骤，3D Adapter将中间的多视图特征解码为连贯的3D表示，然后对渲染的RGBD视图进行重新编码，通过特征添加来增强预训练的基础模型。我们研究了3D Adapter的两种变体：一种是基于高斯飞溅的快速前馈版本，另一种是利用神经场和网格的通用无训练版本。我们广泛的实验表明，3D Adapter不仅大大提高了文本到多视图模型（如Instant3D和Zero123++）的几何质量，而且还使用纯文本到图像的稳定扩散实现了高质量的3D生成。此外，我们通过在文本到3D、图像到3D、文本到纹理和文本到化身任务中呈现高质量的结果，展示了3D适配器的广泛应用潜力。 et.al.|[2410.18974](http://arxiv.org/abs/2410.18974)|**[link](https://github.com/Lakonik/MVEdit)**|
|**2024-10-22**|**Cortical Dynamics of Neural-Connectivity Fields**|皮质组织的宏观研究揭示了振荡活动的普遍性，这反映了神经相互作用的微调。本研究通过将广义振荡动力学纳入先前关于保守或半保守神经场动力学的工作中，扩展了神经场理论。先前的研究在很大程度上假设了神经单元之间的各向同性连接；然而，这项研究表明，广泛的各向异性和波动连接仍然可以维持振荡。使用拉格朗日场方法，我们研究了不同类型的连接、它们的动力学以及与神经场的潜在相互作用。基于这一理论基础，我们推导出了一个框架，该框架通过连接场的概念将Hebbian和非Hebbian学习（即可塑性）纳入神经场的研究中。 et.al.|[2410.16852](http://arxiv.org/abs/2410.16852)|null|
|**2024-10-15**|**Deep vectorised operators for pulsatile hemodynamics estimation in coronary arteries from a steady-state prior**|心血管血流动力学场为冠状动脉疾病提供了有价值的医学决策标志。计算流体动力学（CFD）是体内准确、无创评估这些量的金标准。在这项工作中，我们提出了一种基于机器学习的时间高效替代模型，用于基于稳态先验估计脉动血流动力学。我们引入了深度矢量化算子，这是一种用于在无限维函数空间上进行离散化独立学习的建模框架。基础神经结构是一个以血流动力学边界条件为条件的神经场。重要的是，我们展示了如何将逐点动作的要求放宽到置换等变，从而产生一系列可以通过消息传递和自我关注层进行参数化的模型。我们在从冠状动脉计算机断层扫描血管造影（CCTA）中提取的74条狭窄冠状动脉的数据集上评估了我们的方法，并将患者特异性脉动CFD模拟作为基本事实。我们证明，我们的模型能够准确估计脉动速度和压力，同时不受源域重新采样的影响（离散化独立性）。这表明，深度矢量化算子是冠状动脉及其他动脉心血管血流动力学估计的强大建模工具。 et.al.|[2410.11920](http://arxiv.org/abs/2410.11920)|null|

<p align=right>(<a href=#updated-on-20241120>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

