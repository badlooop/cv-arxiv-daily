[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.10.23
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-21**|**FrugalNeRF: Fast Convergence for Few-shot Novel View Synthesis without Learned Priors**|神经辐射场（NeRF）在少数拍摄场景中面临着重大挑战，主要是由于高保真渲染的过拟合和长训练时间。现有的方法，如FreeNeRF和SparseNeRF，使用频率正则化或预训练先验，但难以应对复杂的调度和偏差。我们介绍了FrugalNeRF，这是一种新颖的少镜头NeRF框架，它利用跨多个尺度的权重共享体素来有效地表示场景细节。我们的主要贡献是一种跨尺度几何自适应方案，该方案基于跨尺度的重投影误差来选择伪地面真值深度。这可以指导培训，而不依赖于外部学习的先验知识，从而充分利用培训数据。它还可以整合预先训练的先验，在不减缓收敛的情况下提高质量。在LLFF、DTU和RealEstate-10K上的实验表明，FrugalNeRF优于其他少镜头NeRF方法，同时显著减少了训练时间，使其成为高效准确的3D场景重建的实用解决方案。 et.al.|[2410.16271](http://arxiv.org/abs/2410.16271)|null|
|**2024-10-21**|**3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors**|新颖的视图合成旨在从多个输入图像或视频中生成场景的新颖视图，最近的进步，如3D高斯飞溅（3DGS），在使用高效管道生成逼真的渲染方面取得了显著成功。然而，由于采样不足区域的信息不足，在稀疏输入视图等具有挑战性的设置下生成高质量的新颖视图仍然很困难，这通常会导致明显的伪影。本文介绍了一种用于提高3DGS表示质量的新型流水线3DGS增强器。我们利用2D视频扩散先验来解决具有挑战性的3D视图一致性问题，将其重新表述为在视频生成过程中实现时间一致性。3DGS增强器恢复渲染的新颖视图的视图一致性潜在特征，并通过时空解码器将其与输入视图集成。然后，增强的视图用于微调初始3DGS模型，显著提高其渲染性能。在无界场景的大规模数据集上进行的广泛实验表明，与最先进的方法相比，3DGS Enhancer具有更优的重建性能和高保真渲染结果。项目网页为https://xiliu8006.github.io/3DGS-Enhancer-project . et.al.|[2410.16266](http://arxiv.org/abs/2410.16266)|null|
|**2024-10-22**|**Fully Explicit Dynamic Gaussian Splatting**|3D高斯散斑通过利用密集的3D先验和显式表示，在静态场景中显示了快速高质量的渲染结果。不幸的是，先验和表示的好处并不涉及动态运动的新颖视图合成。具有讽刺意味的是，这是因为主要的障碍是对它们的依赖，这需要增加训练和渲染时间来解释动态运动。本文设计了一种显式4D高斯散斑（Ex4DGS）。我们的核心思想是在训练过程中首先分离静态和动态高斯分布，并在稀疏时间戳下明确采样动态高斯分布的位置和旋转。然后对采样的位置和旋转进行插值，以表示动态场景中对象在空间和时间上的连续运动，并降低计算成本。此外，我们引入了一种渐进式训练方案和一种点回溯技术，以提高Ex4DGS的收敛性。我们最初使用短时间戳训练Ex4DGS，并逐步扩展时间戳，这使得它在一些点云上运行良好。点回溯用于量化每个高斯函数随时间的累积误差，从而能够检测和去除动态场景中的错误高斯函数。在各种场景上的综合实验证明了我们的方法具有最先进的渲染质量，在单个2080Ti GPU上实现了62 fps的快速渲染。 et.al.|[2410.15629](http://arxiv.org/abs/2410.15629)|null|
|**2024-10-18**|**Learning autonomous driving from aerial imagery**|在这项工作中，我们考虑了仅从航拍图像中学习端到端感知以控制地面车辆的问题。摄影测量模拟器允许通过将预先生成的资产转换为新视图来合成新视图。然而，它们的设置成本很高，需要仔细收集数据，并且通常需要人工来创建可用的模拟器。我们使用神经辐射场（NeRF）作为中间表示，从地面车辆的角度合成新的视图。然后，这些新颖的观点可用于几个下游的自主导航应用。在这项工作中，我们通过应用从图像和深度数据中训练端到端学习策略，展示了新颖视图合成的实用性。在传统的真实到模拟到真实的框架中，收集的数据将被转换为视觉模拟器，然后可用于生成新的视图。相比之下，使用NeRF可以实现紧凑的表示，并能够在环境中收集更多数据时优化视觉模拟器的参数。我们通过在机器人汽车上部署模仿策略，证明了我们的方法在定制的迷你城市环境中的有效性。我们还考虑了位置定位的任务，并证明我们的方法能够在现实世界中重新定位汽车。 et.al.|[2410.14177](http://arxiv.org/abs/2410.14177)|null|
|**2024-10-18**|**DaRePlane: Direction-aware Representations for Dynamic Scene Reconstruction**|最近许多建模和重新渲染动态场景的方法都利用了基于平面的显式表示，解决了与神经辐射场（NeRF）和高斯飞溅（GS）等模型相关的训练时间慢的问题。然而，仅仅将4D动态场景分解为多个基于2D平面的表示不足以对具有复杂运动的场景进行高保真度重渲染。作为回应，我们提出了DaRePlane，这是一种新的方向感知表示方法，可以从六个不同的方向捕获场景动态。这种学习表示经过逆双树复小波变换（DTCWT）以恢复基于平面的信息。在NeRF管道中，DaRePlane通过融合来自这些恢复平面的向量来计算每个时空点的特征，然后传递给一个微小的MLP进行颜色回归。当应用于高斯飞溅时，DaRePlane计算高斯点的特征，然后使用微小的多头MLP进行时空变形预测。值得注意的是，为了解决六个实数和六个虚数方向感知小波系数引入的冗余问题，我们引入了一种可训练的掩蔽方法，在不显著降低性能的情况下缓解了存储问题。为了证明DaRePlane的通用性和效率，我们在常规和手术动态场景下对NeRF和GS系统进行了测试。大量实验表明，DaRePlane在各种复杂动态场景的新颖视图合成中具有最先进的性能。 et.al.|[2410.14169](http://arxiv.org/abs/2410.14169)|null|
|**2024-10-17**|**DepthSplat: Connecting Gaussian Splatting and Depth**|高斯散射和单/多视图深度估计通常是单独研究的。本文中，我们提出了DepthSplat来连接高斯溅射和深度估计，并研究了它们之间的相互作用。更具体地说，我们首先通过利用预先训练的单眼深度特征来贡献一个稳健的多视图深度模型，从而得到高质量的前馈3D高斯飞溅重建。我们还表明，高斯飞溅可以作为一种无监督的预训练目标，用于从大规模未标记的数据集中学习强大的深度模型。我们通过广泛的消融和跨任务转移实验验证了高斯溅射和深度估计之间的协同作用。我们的DepthSplat在ScanNet、RealEstate10K和DL3DV数据集上实现了深度估计和新颖视图合成方面的最先进性能，展示了连接这两个任务的互惠互利。我们的代码、模型和视频结果可在https://haofeixu.github.io/depthsplat/. et.al.|[2410.13862](http://arxiv.org/abs/2410.13862)|**[link](https://github.com/cvg/depthsplat)**|
|**2024-10-17**|**Hybrid bundle-adjusting 3D Gaussians for view consistent rendering with pose optimization**|新型视图合成在3D计算机视觉领域取得了重大进展。然而，从不完美的相机姿态渲染视图一致的新颖视图仍然具有挑战性。本文介绍了一种混合束调整3D高斯模型，该模型能够实现具有姿态优化的视图一致性渲染。该模型联合提取基于图像和神经的3D表示，以在面向前方的场景中同时生成视图一致的图像和相机姿态。我们的模型的有效性通过在真实和合成数据集上进行的广泛实验得到了证明。这些实验清楚地表明，我们的模型可以有效地优化神经场景表示，同时解决明显的相机姿态失准问题。源代码可在https://github.com/Bistu3DV/hybridBA. et.al.|[2410.13280](http://arxiv.org/abs/2410.13280)|**[link](https://github.com/bistu3dv/hybridba)**|
|**2024-10-18**|**UniG: Modelling Unitary 3D Gaussians for View-consistent 3D Reconstruction**|在这项工作中，我们提出了UniG，这是一种视图一致的3D重建和新颖的视图合成模型，可以从稀疏图像中生成3D高斯的高保真表示。现有的基于3D高斯的方法通常对每个视图的每个像素进行高斯回归，分别为每个视图创建3D高斯，并通过点连接将其合并。这种与视图无关的重建方法通常会导致视图不一致问题，其中来自不同视图的同一3D点的预测位置可能存在差异。为了解决这个问题，我们开发了一个类似DETR（DEtect TRansformer）的框架，该框架将3D高斯视为解码器查询，并通过在多个输入图像上执行多视图交叉注意（MVDFA）来逐层更新其参数。通过这种方式，多个视图自然有助于对3D高斯的统一表示进行建模，从而使3D重建更加视图一致。此外，由于用作解码器查询的3D高斯数与输入视图的数量无关，因此允许任意数量的输入图像，而不会导致内存爆炸。大量的实验验证了我们的方法的优势，在定量和定性上展示了优于现有方法的性能（在Objaverse上训练并在GSO基准上测试时，PSNR提高了4.2 dB）。该代码将于https://github.com/jwubz123/UNIG. et.al.|[2410.13195](http://arxiv.org/abs/2410.13195)|**[link](https://github.com/jwubz123/UNIG)**|
|**2024-10-16**|**Triplet: Triangle Patchlet for Mesh-Based Inverse Rendering and Scene Parameters Approximation**|辐射场的最新进展显著改善了新颖的视图合成。然而，在许多现实世界的应用中，更高级的挑战在于逆渲染，它试图推导场景的物理属性，包括光、几何、纹理和材质。然而，网格作为许多模拟管道采用的传统表示方法，在逆渲染的辐射场中仍然显示出有限的影响。本文介绍了一种名为三角形补丁（缩写为Triplet）的新框架，这是一种基于网格的表示方法，可以全面近似这些场景参数。我们首先用随机生成的点或从相机校准中获得的稀疏点组装三元组，其中所有人脸都被视为一个独立的元素。接下来，我们模拟光的物理交互，并使用光栅化和光线跟踪等传统图形渲染技术优化场景参数，同时进行密度控制和传播。还提出了一种迭代网格提取过程，在该过程中，我们继续通过基于图的操作对几何形状和材料进行优化。我们还引入了几个监管术语，以便更好地概括材料性能。我们的框架可以在没有统一框架中的光、材料和几何先验的情况下，通过网格精确估计光、材料及几何。实验表明，我们的方法可以在重建高质量几何和精确材料属性的同时实现最先进的视觉质量。 et.al.|[2410.12414](http://arxiv.org/abs/2410.12414)|**[link](https://github.com/rando11199/triplet)**|
|**2024-10-16**|**GAN Based Top-Down View Synthesis in Reinforcement Learning Environments**|人类的行为是基于对环境的心理感知。即使环境的所有方面都不可见，人类也有一个内部心理模型，可以将部分可见的场景概括为完全构建和连接的视图。这种内部心理模型使用过去遇到的环境的空间和时间方面的学习抽象表示。强化学习环境中的人工智能也受益于从经验中学习环境的表示。它为代理提供了不直接可见的观点，帮助其做出更好的策略决策。它还可以用于预测环境的未来状态。该项目探索了基于人工智能的第一人称视图观察，使用生成对抗网络（GAN）学习强化学习环境的自上而下视图。自顶向下视图很有用，因为它通过构建整个环境的地图来提供环境的完整概述。它提供有关对象的尺寸和形状以及它们彼此之间的相对位置的信息。最初，当代理只能看到环境的部分观察时，只会生成部分自上而下的视图。当代理通过一组操作探索环境时，生成的自上而下的视图就完成了。这种生成的自上而下的视图可以帮助代理推断出更好的策略决策。该项目的重点是学习强化学习环境的自上而下的视图。它不处理任何强化学习任务。 et.al.|[2410.12372](http://arxiv.org/abs/2410.12372)|null|

<p align=right>(<a href=#updated-on-20241023>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-21**|**MvDrag3D: Drag-based Creative 3D Editing via Multi-view Generation-Reconstruction Priors**|在图像生成模型的推动下，基于拖动的编辑在2D内容创建中变得流行起来。然而，将这项技术扩展到3D仍然是一个挑战。现有的基于3D拖动的编辑方法，无论是采用显式空间变换还是依赖于有限容量3D生成模型中的隐式潜在优化，在处理重大拓扑变化或跨不同对象类别生成新纹理方面都存在不足。为了克服这些局限性，我们引入了MVDrag3D，这是一种利用多视图生成和重建先验进行更灵活、更有创意的基于拖动的3D编辑的新框架。我们方法的核心是使用多视图扩散模型作为强生成模型，然后在多个渲染视图上执行一致的拖动编辑，接着是重建模型，重建编辑对象的3D高斯分布。虽然初始的3D高斯分布可能会在不同视图之间出现错位，但我们通过视图特定的变形网络来解决这个问题，该网络可以调整高斯分布的位置以使其很好地对齐。此外，我们提出了一种多视图评分函数，从多个视图中提取生成先验，以进一步提高视图的一致性和视觉质量。大量实验表明，MVDrag3D为基于3D拖动的编辑提供了一种精确、生成和灵活的解决方案，支持各种对象类别和3D表示的更通用的编辑效果。 et.al.|[2410.16272](http://arxiv.org/abs/2410.16272)|null|
|**2024-10-22**|**LucidFusion: Generating 3D Gaussians with Arbitrary Unposed Images**|最近的大型重建模型在从单个图像生成高质量3D对象方面取得了显著进展。然而，这些方法往往难以控制，因为它们缺乏来自多个视图的信息，导致不完整或不一致的3D重建。为了解决这一局限性，我们引入了LucidFusion，这是一种灵活的端到端前馈框架，利用了相对坐标图（RCM）。与传统的通过姿势将图像与3D世界联系起来的方法不同，LucidFusion利用RCM在不同的视图中连贯地对齐几何特征，使其高度适用于从任意、未经处理的图像生成3D。此外，LucidFusion与原始的单图像到3D流水线无缝集成，以512美元乘以512美元的分辨率生成详细的3D高斯分布，使其非常适合广泛的应用。 et.al.|[2410.15636](http://arxiv.org/abs/2410.15636)|null|
|**2024-10-19**|**EndoMetric: Near-light metric scale monocular SLAM**|近年来，内窥镜图像的几何重建和SLAM取得了重大进展。在大多数医学专业中，使用的内窥镜是单眼的，所应用的算法通常是为外部环境设计的算法的扩展，从而产生高达未知比例因子的3D重建。在这篇论文中，我们利用了这样一个事实，即标准内窥镜配备了近光源，这些近光源位于距离相机较小但非零的基线处。通过利用光衰减的平方反比定律，我们首次实现了具有精确度量尺度的单眼重建。这为将任何内窥镜转换为公制设备铺平了道路，这对于测量息肉、狭窄或受疾病影响的组织范围等实际应用至关重要。 et.al.|[2410.15065](http://arxiv.org/abs/2410.15065)|null|
|**2024-10-17**|**Object Pose Estimation Using Implicit Representation For Transparent Objects**|物体姿态估计是计算机视觉中的一项重要任务。物体姿态给出了物体在现实空间中的方向和平移，这允许各种应用，如操纵、增强现实等。各种物体对光表现出不同的特性，如反射、吸收等。这使得理解物体在RGB和深度通道中的结构具有挑战性。最近的研究一直在向基于学习的方法发展，这些方法利用深度学习为对象姿态估计提供了一种更灵活、更通用的方法。一种这样的方法是渲染和比较方法，该方法从多个视图渲染对象并将其与给定的2D图像进行比较，这通常需要CAD模型形式的对象表示。我们认为CAD模型的合成纹理可能不适合渲染和比较操作。我们发现，如果对象以神经辐射场（NeRF）的形式表示为隐式（神经）表示，它会对实际场景进行更逼真的渲染，并保留关键的空间特征，这使得比较更加通用。我们在透明数据集上评估了渲染和比较方法的NeRF实现，发现它超过了当前最先进的结果。 et.al.|[2410.13465](http://arxiv.org/abs/2410.13465)|null|
|**2024-10-18**|**Context-Enhanced Multi-View Trajectory Representation Learning: Bridging the Gap through Self-Supervised Models**|使用通用密集表示对轨迹数据进行建模已成为各种下游应用的流行范式，如轨迹分类、行程时间估计和相似性计算。然而，现有的方法通常依赖于单一空间视图的轨迹，限制了它们捕获丰富上下文信息的能力，而丰富上下文信息对于深入了解不同地理空间背景下的运动模式至关重要。为此，我们提出了MVTraj，这是一种用于轨迹表示学习的新型多视图建模方法。MVTraj整合了从GPS到道路网络和兴趣点的各种背景知识，以更全面地了解轨迹数据。为了在多个视图之间对齐学习过程，我们利用GPS轨迹作为桥梁，并采用自我监督的借口任务来捕捉和区分不同空间视图之间的运动模式。在此之后，我们将来自不同视角的轨迹视为不同的模态，并应用分层跨模态交互模块来融合表示，从而丰富了从多个来源获得的知识。对真实世界数据集的广泛实验表明，MVTraj在与各种空间视图相关的任务中明显优于现有基线，验证了其在时空建模中的有效性和实用性。 et.al.|[2410.13196](http://arxiv.org/abs/2410.13196)|null|
|**2024-10-18**|**UniG: Modelling Unitary 3D Gaussians for View-consistent 3D Reconstruction**|在这项工作中，我们提出了UniG，这是一种视图一致的3D重建和新颖的视图合成模型，可以从稀疏图像中生成3D高斯的高保真表示。现有的基于3D高斯的方法通常对每个视图的每个像素进行高斯回归，分别为每个视图创建3D高斯，并通过点连接将其合并。这种与视图无关的重建方法通常会导致视图不一致问题，其中来自不同视图的同一3D点的预测位置可能存在差异。为了解决这个问题，我们开发了一个类似DETR（DEtect TRansformer）的框架，该框架将3D高斯视为解码器查询，并通过在多个输入图像上执行多视图交叉注意（MVDFA）来逐层更新其参数。通过这种方式，多个视图自然有助于对3D高斯的统一表示进行建模，从而使3D重建更加视图一致。此外，由于用作解码器查询的3D高斯数与输入视图的数量无关，因此允许任意数量的输入图像，而不会导致内存爆炸。大量的实验验证了我们的方法的优势，在定量和定性上展示了优于现有方法的性能（在Objaverse上训练并在GSO基准上测试时，PSNR提高了4.2 dB）。该代码将于https://github.com/jwubz123/UNIG. et.al.|[2410.13195](http://arxiv.org/abs/2410.13195)|**[link](https://github.com/jwubz123/UNIG)**|
|**2024-10-16**|**Configurable Embodied Data Generation for Class-Agnostic RGB-D Video Segmentation**|本文提出了一种生成大规模数据集的方法，以改善不同形状因子的机器人之间的类无关视频分割。具体来说，我们考虑的问题是，如果在数据生成过程中考虑了机器人的实施方式，那么在通用分割数据上训练的视频分割模型是否对特定的机器人平台更有效。为了回答这个问题，制定了一个管道，用于使用3D重建（例如来自HM3DSem）生成分段视频，这些视频可以根据机器人的实施例（例如传感器类型、传感器放置和照明源）进行配置。由此产生的大量RGB-D视频全景分割数据集（MVPd）被引入，用于与基础和视频分割模型进行广泛的基准测试，并支持视频分割中以实施例为重点的研究。我们的实验结果表明，在将基础模型转移到某些机器人实施例（如特定的相机放置）时，使用MVPd进行微调可以提高性能。这些实验还表明，使用3D模态（深度图像和相机姿态）可以提高视频分割的准确性和一致性。项目网页可在https://topipari.com/projects/MVPd et.al.|[2410.12995](http://arxiv.org/abs/2410.12995)|null|
|**2024-10-16**|**Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans**|骨关节炎是一种影响骨骼和软骨的退行性疾病，通常导致骨赘形成、骨密度降低和关节间隙狭窄。恢复正常关节功能的治疗方案因病情的严重程度而异。这项工作引入了一种处理肩部CT扫描的创新深度学习框架。它具有肱骨近端和肩胛骨的语义分割、骨表面的3D重建、肩关节（GH）关节区域的识别以及三种常见骨关节炎相关病理的分期：骨赘形成（OS）、GH间隙缩小（JS）和肱骨肩胛骨对齐（HSA）。该流水线包括两个级联的CNN架构：用于分割的3D CEL-UNet和用于三重分类的3D Arthro-Net。使用571次CT扫描的回顾性数据集，对患有不同程度GH骨关节炎相关疾病的患者进行训练、验证和测试。肱骨三维重建的均方根误差和豪斯多夫距离中值分别为0.22mm和1.48mm，肩胛骨为0.24mm和1.48mm。其性能优于最先进的架构，可能适用于基于PSI的肩关节置换术前计划。OS、JS和HSA在所有三个类别中的分类准确率始终达到90%左右。推理管道的计算时间不到15秒，展示了该框架的效率和与骨科放射学实践的兼容性。这些结果代表了人工智能工具在医学翻译方面的一个有前景的进步。这一进展旨在简化术前计划流程，提供高质量的骨表面，并支持外科医生根据独特的患者关节状况选择最合适的手术方法。 et.al.|[2410.12641](http://arxiv.org/abs/2410.12641)|null|
|**2024-10-15**|**Stochastic 3D reconstruction of cracked polycrystalline NMC particles using 2D SEM data**|锂离子电池的性能受到其阴极性能的强烈影响，因此也受到阴极所含颗粒的3D微观结构的影响。在压延和循环过程中，阴极颗粒内会产生裂纹，这可能会以多种方式影响性能。一方面，裂纹降低了内部连接性，从而阻碍了阴极粒子内的电子传输。另一方面，颗粒内裂纹可以增加阴极反应表面。由于这些相互矛盾的影响，有必要定量研究电池循环如何影响开裂，以及开裂又如何影响电池性能。因此，有必要用结构描述符表征3D颗粒形态，并将其与有效电池性能定量关联。通常，使用图像数据进行3D结构表征。然而，信息丰富的3D成像技术耗时、昂贵且很少可用，因此分析通常必须依赖于2D图像数据。本文提出了一种新的体视学方法，用于生成虚拟3D阴极粒子，这些粒子表现出与实验测量粒子的2D截面中观察到的裂纹网络在统计上等效的裂纹网络。因此，更容易获得的2D图像数据足以得出破裂阴极颗粒的完整3D特征。在未来的研究中，虚拟生成的3D粒子将被用作空间分辨电化学机械模拟的几何输入，以加深我们对锂离子电池阴极结构-性能关系的理解。 et.al.|[2410.12020](http://arxiv.org/abs/2410.12020)|null|
|**2024-10-15**|**Robotic Arm Platform for Multi-View Image Acquisition and 3D Reconstruction in Minimally Invasive Surgery**|微创手术（MIS）具有显著的优势，如缩短恢复时间和最大限度地减少患者创伤，但在可见性和可及性方面存在挑战，使精确的3D重建成为手术规划和导航的重要工具。这项工作介绍了一种机器人手臂平台，用于在MIS环境中进行高效的多视图图像采集和精确的3D重建。我们将腹腔镜改装成机器人手臂，并在不同的照明条件（手术室和腹腔镜）和轨迹（球形和腹腔镜）下捕获了几个绵羊器官的离体图像。我们采用了最近发布的基于学习的特征匹配器与COLMAP相结合来生成我们的重建。通过高精度激光扫描对重建进行定量评估。我们的结果表明，虽然重建在真实的MIS照明和轨迹下遭受的损失最大，但我们的管道的许多版本都达到了接近亚毫米的精度，平均均方根误差为1.05毫米，倒角距离为0.82毫米。我们最好的重建结果发生在手术室照明和球形轨迹上。我们的机器人平台为MIS环境中的3D生成提供了一种受控、可重复的多视图数据采集工具，我们希望这能为训练基于学习的模型带来新的数据集。 et.al.|[2410.11703](http://arxiv.org/abs/2410.11703)|null|

<p align=right>(<a href=#updated-on-20241023>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-21**|**MvDrag3D: Drag-based Creative 3D Editing via Multi-view Generation-Reconstruction Priors**|在图像生成模型的推动下，基于拖动的编辑在2D内容创建中变得流行起来。然而，将这项技术扩展到3D仍然是一个挑战。现有的基于3D拖动的编辑方法，无论是采用显式空间变换还是依赖于有限容量3D生成模型中的隐式潜在优化，在处理重大拓扑变化或跨不同对象类别生成新纹理方面都存在不足。为了克服这些局限性，我们引入了MVDrag3D，这是一种利用多视图生成和重建先验进行更灵活、更有创意的基于拖动的3D编辑的新框架。我们方法的核心是使用多视图扩散模型作为强生成模型，然后在多个渲染视图上执行一致的拖动编辑，接着是重建模型，重建编辑对象的3D高斯分布。虽然初始的3D高斯分布可能会在不同视图之间出现错位，但我们通过视图特定的变形网络来解决这个问题，该网络可以调整高斯分布的位置以使其很好地对齐。此外，我们提出了一种多视图评分函数，从多个视图中提取生成先验，以进一步提高视图的一致性和视觉质量。大量实验表明，MVDrag3D为基于3D拖动的编辑提供了一种精确、生成和灵活的解决方案，支持各种对象类别和3D表示的更通用的编辑效果。 et.al.|[2410.16272](http://arxiv.org/abs/2410.16272)|null|
|**2024-10-21**|**3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors**|新颖的视图合成旨在从多个输入图像或视频中生成场景的新颖视图，最近的进步，如3D高斯飞溅（3DGS），在使用高效管道生成逼真的渲染方面取得了显著成功。然而，由于采样不足区域的信息不足，在稀疏输入视图等具有挑战性的设置下生成高质量的新颖视图仍然很困难，这通常会导致明显的伪影。本文介绍了一种用于提高3DGS表示质量的新型流水线3DGS增强器。我们利用2D视频扩散先验来解决具有挑战性的3D视图一致性问题，将其重新表述为在视频生成过程中实现时间一致性。3DGS增强器恢复渲染的新颖视图的视图一致性潜在特征，并通过时空解码器将其与输入视图集成。然后，增强的视图用于微调初始3DGS模型，显著提高其渲染性能。在无界场景的大规模数据集上进行的广泛实验表明，与最先进的方法相比，3DGS Enhancer具有更优的重建性能和高保真渲染结果。项目网页为https://xiliu8006.github.io/3DGS-Enhancer-project . et.al.|[2410.16266](http://arxiv.org/abs/2410.16266)|null|
|**2024-10-21**|**Role of obstacle softness in the diffusive behavior of active Particles**|我们数值研究了活性布朗粒子在充满软障碍物的二维受限通道中的扩散行为，其柔软度由参数 $K$控制。在这里，活性粒子受到外部偏压$F$。粒子扩散受到熵势垒的影响，熵势垒是由于所选通道几何形状的变化而产生的。我们观察到，障碍物柔软度、熵障碍物和外部偏压之间的相互作用导致了活性粒子的显著输运特性。例如，随着$F$的增加，非线性迁移率表现出非单调行为，有效扩散大大增强，在存在软障碍物的情况下出现多个峰值。此外，作为$K$和$F$ 的函数，粒子表现出各种扩散行为，例如，正常扩散——障碍物的作用微不足道，次扩散或超扩散——粒子部分被障碍物捕获，最终被障碍物困住。这些发现有助于理解活性剂在拥挤环境中扩散的物理情况。 et.al.|[2410.16223](http://arxiv.org/abs/2410.16223)|null|
|**2024-10-21**|**A Framework for Evaluating Predictive Models Using Synthetic Image Covariates and Longitudinal Data**|我们提出了一种新的框架，用于合成具有复杂协变量（如眼部扫描）和纵向观察（如随时间变化的视敏度）的患者数据，以解决医疗保健研究中的隐私问题。我们的方法在生成每种数据形态的潜在空间中引入了受控关联，从而能够创建复杂的协变量纵向观察对。该框架促进了预测模型的开发，并为医疗保健研究提供了公开可用的基准数据集。我们使用光学相干断层扫描（OCT）扫描来演示我们的框架，尽管它适用于跨领域。使用109309个2D OCT扫描切片，我们训练了一个结合变分自动编码器和扩散模型的图像生成模型。使用非线性混合效应（NLME）模型从低维随机效应空间模拟纵向观测。我们生成了110万个OCT扫描切片，并在受控关联水平（受试者间差异的100%、50%、10%、5.26%和2%）下进行了五组纵向观察。为了评估该框架，我们使用另一个NLME模型对合成纵向观察进行建模，计算随机效应的经验贝叶斯估计，并训练ResNet从合成OCT扫描中预测这些估计。然后，我们将ResNet预测纳入NLME模型，以进行患者个性化预测。由于图像和纵向测量之间的关联减少，对保留数据的预测精度按预期下降。值得注意的是，除了2%的情况外，我们在保留的数据上实现了理论上最佳预测的50%以内，这证明了我们甚至能够检测到微弱的信号。这证实了我们的框架在生成具有受控关联水平的合成数据方面的有效性，为医疗保健研究提供了有价值的工具。 et.al.|[2410.16177](http://arxiv.org/abs/2410.16177)|null|
|**2024-10-21**|**Validity of Prandtl's boundary layer from the Boltzmann theory**|我们从玻尔兹曼方程的流体动力学极限证明了普朗特方程和高阶普朗特展开。我们的流体数据的形式为 $\text{剪切流}$，加上$（x_1，x_2）\in\mathbb T^2$中解析空间中的$\sqrt{\kappa}$序项和$x_3\in\machbb中的Sobolev{R}_+$ . 这项工作首次从玻尔兹曼方程的流体动力学极限严格证明了普朗特方程。新颖之处在于在分析空间中获得具有普朗特层剪切流周围扩散边界条件的线性玻尔兹曼方程的估计值。关键技术涉及精细的换向器估计和局部守恒定律的使用。 et.al.|[2410.16160](http://arxiv.org/abs/2410.16160)|null|
|**2024-10-22**|**Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models**|天真地使用图像模型来解决逆视频问题通常会在生成的视频中出现闪烁、纹理残留和时间不一致的问题。为了解决这些问题，在本文中，我们将帧视为2D空间中的连续函数，将视频视为不同帧之间的连续扭曲变换序列。这种视角使我们能够仅在图像上训练函数空间扩散模型，并利用它们来解决时间相关的逆问题。函数空间扩散模型需要相对于底层空间变换是等变的。为了确保时间一致性，我们引入了一个简单的事后测试时间指导，用于（自）等变解。我们的方法允许我们部署最先进的潜在扩散模型，如Stable diffusion XL，来解决视频逆问题。我们证明了我们的方法在视频修复和8倍视频超分辨率方面的有效性，优于基于噪声变换的现有技术。我们提供生成的视频结果：https://giannisdaras.github.io/warped_diffusion.github.io/. et.al.|[2410.16152](http://arxiv.org/abs/2410.16152)|null|
|**2024-10-21**|**Universal Linear Response of the Mean First-Passage Time**|第一通道过程在许多科学领域都很普遍，但理解它们对外部扰动的反应的一般框架仍然难以捉摸。虽然波动耗散定理为稳态系统提供了完整的线性响应理论，但它不适用于瞬态首次通过过程。我们通过关注罕见而非微弱的扰动来应对这一挑战。令人惊讶的是，我们发现平均首次通过时间（MFPT）对这种扰动的线性响应是普遍的。它仅取决于未受扰动的第一次通过时间的前两个时刻和扰动激活后的平均完成时间，而不需要对底层系统的动力学做出任何假设。为了证明我们的发现的实用性，我们分析了漂移扩散过程在两种情况下的MFPT响应：（i）具有信息反馈的随机重置，以及（ii）从线性电位到对数电位的突然转变。值得注意的是，我们的方法绕过了明确解决问题的需要，使我们能够解开和解释这些系统的高度非平凡的响应相空间。我们的结果简化了对复杂系统的分析，为预测各种场景和研究领域中扰动对首次通过过程的影响提供了强大的工具。 et.al.|[2410.16129](http://arxiv.org/abs/2410.16129)|null|
|**2024-10-21**|**SeaDAG: Semi-autoregressive Diffusion for Conditional Directed Acyclic Graph Generation**|我们介绍了SeaDAG，这是一种用于有向无环图（DAG）条件生成的半自回归扩散模型。考虑到它们固有的逐层结构，我们通过为不同层设计不同的去噪速度来模拟逐层自回归生成。与缺乏全局图结构视图的传统自回归生成不同，我们的方法在每个扩散步骤都保持一个完整的图结构，从而实现了需要完整图结构的属性控制等操作。利用这一能力，我们在训练过程中通过使用图属性解码器来评估DAG属性。我们明确地训练模型学习带有条件损失的图条件化，这增强了扩散模型生成既真实又符合指定属性的图的能力。我们在两个具有代表性的条件DAG生成任务上评估了我们的方法：（1）从真值表生成电路，其中精确的DAG结构对于实现电路功能至关重要，以及（2）基于量子特性的分子生成。我们的方法显示出有希望的结果，生成了与给定条件紧密一致的高质量和逼真的DAGs。 et.al.|[2410.16119](http://arxiv.org/abs/2410.16119)|null|
|**2024-10-21**|**Continuous Speech Synthesis using per-token Latent Diffusion**|具有离散标记的自回归变换器模型的成功启发了基于量化的连续模态方法，尽管这些方法通常会限制重建质量。因此，我们引入了SALAD，这是一个用于零样本文本到速度的per-token潜在扩散模型，对连续表示进行操作。SALAD基于最近提出的用于图像生成的富有表现力的扩散头，并将其扩展为生成可变长度的输出。我们的方法利用语义标记来提供上下文信息并确定停止条件。我们为我们的方法提出了三种连续变体，扩展了流行的离散语音合成技术。此外，我们为每个变体实现了离散基线，并对离散与连续语音建模技术进行了比较分析。我们的结果表明，连续和离散方法都具有很高的能力，SALAD在获得与地面真实音频相当的语音质量和说话者相似性的同时，实现了卓越的可理解性得分。 et.al.|[2410.16048](http://arxiv.org/abs/2410.16048)|null|
|**2024-10-21**|**The essential m-dissipativity for degenerate infinite dimensional stochastic Hamiltonian systems and applications**|我们考虑一个具有乘性噪声的退化无穷维随机哈密顿系统，并在相应的Kolmogorov（向后）算子的 $L^2（\mu^{\Phi}）$上建立了本质的m-耗散性。这里，$\Phi$是势，$\mu^{\Phi}$是密度为$e^{-\Phi}$的不变测度，相对于无限维非退化高斯测度。除了Kolmogorov算子的非扇区性之外，主要的困难是覆盖一大类势。我们包括既没有有界梯度也没有Lipschitz连续梯度的势。本质的m-耗散性是建立由Kolmogorov算子生成的强连续收缩半群$（T_T）_{T\geq 0}$的低熵性的起点。通过使用最初由Dolbeault、Mouhot和Schmeiser引入的Grothaus和Stilgenbauer的改进抽象Hilbert空间低熵方法，我们构建了一个具有弱连续路径和无限寿命的$mu^{\Phi}$不变Hunt过程，其转移半群与$（T_T）_{T\geq0}$相关联。该过程为具有乘性噪声的退化无穷维随机哈密顿系统提供了一个随机和分析弱解。$（T_T）_{T\geq 0}$的低矫顽性和$（T_T）_{T=geq 0}$ 与过程转移半群的识别导致了指数遍历性。最后，我们将我们的结果应用于具有乘性噪声的退化二阶时间随机反应扩散方程。对控制这些方程的适用势和系数类的讨论完成了我们的分析。 et.al.|[2410.15993](http://arxiv.org/abs/2410.15993)|null|

<p align=right>(<a href=#updated-on-20241023>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2024-10-15**|**Deep vectorised operators for pulsatile hemodynamics estimation in coronary arteries from a steady-state prior**|心血管血流动力学场为冠状动脉疾病提供了有价值的医学决策标志。计算流体动力学（CFD）是体内准确、无创评估这些量的金标准。在这项工作中，我们提出了一种基于机器学习的时间高效替代模型，用于基于稳态先验估计脉动血流动力学。我们引入了深度矢量化算子，这是一种用于在无限维函数空间上进行离散化独立学习的建模框架。基础神经结构是一个以血流动力学边界条件为条件的神经场。重要的是，我们展示了如何将逐点动作的要求放宽到置换等变，从而产生一系列可以通过消息传递和自我关注层进行参数化的模型。我们在从冠状动脉计算机断层扫描血管造影（CCTA）中提取的74条狭窄冠状动脉的数据集上评估了我们的方法，并将患者特异性脉动CFD模拟作为基本事实。我们证明，我们的模型能够准确估计脉动速度和压力，同时不受源域重新采样的影响（离散化独立性）。这表明，深度矢量化算子是冠状动脉及其他动脉心血管血流动力学估计的强大建模工具。 et.al.|[2410.11920](http://arxiv.org/abs/2410.11920)|null|
|**2024-10-07**|**Fast Training of Sinusoidal Neural Fields via Scaling Initialization**|神经场是一种新兴的范式，它将数据表示为由神经网络参数化的连续函数。尽管有许多优点，但神经场通常具有较高的训练成本，这阻碍了更广泛的采用。在本文中，我们关注一个流行的神经场家族，称为正弦神经场（SNF），并研究如何初始化它以最大限度地提高训练速度。我们发现，基于信号传播原理设计的SNF标准初始化方案是次优的。特别是，我们证明，通过简单地将每个权重（最后一层除外）乘以一个常数，我们可以将SNF训练加速10 $\times$。这种方法被称为$\textit{weight scaling}$ ，在各种数据域上持续提供显著的加速，使SNF的训练速度比最近提出的架构更快。为了理解为什么权重缩放效果良好，我们进行了广泛的理论和实证分析，结果表明，权重缩放不仅有效地解决了频谱偏差，而且具有良好的优化轨迹。 et.al.|[2410.04779](http://arxiv.org/abs/2410.04779)|null|
|**2024-10-04**|**End-to-End Reaction Field Energy Modeling via Deep Learning based Voxel-to-voxel Transform**|在计算生物化学和生物物理学中，理解静电相互作用的作用对于阐明生物分子的结构、动力学和功能至关重要。泊松-玻尔兹曼（PB）方程是通过描述带电分子内部和周围的静电势来模拟这些相互作用的基础工具。然而，由于生物分子表面的复杂性和需要考虑可移动离子，求解PB方程带来了重大的计算挑战。虽然求解PB方程的传统数值方法是准确的，但它们的计算成本很高，并且随着系统规模的增加而扩展性较差。为了应对这些挑战，我们引入了PBNeF，这是一种新的机器学习方法，灵感来自基于神经网络的偏微分方程求解器的最新进展。我们的方法将PB方程的输入和边界静电条件转化为可学习的体素表示，使神经场变换器能够预测PB解，进而预测反应场势能。大量实验表明，与传统的PB求解器相比，PBNeF的速度提高了100倍以上，同时保持了与广义玻恩（GB）模型相当的精度。 et.al.|[2410.03927](http://arxiv.org/abs/2410.03927)|null|
|**2024-10-08**|**DressRecon: Freeform 4D Human Reconstruction from Monocular Video**|我们提出了一种从单目视频中重建时间一致的人体模型的方法，重点是极其宽松的衣服或手持物体的交互。之前在人体重建方面的工作要么局限于没有物体交互的紧身衣服，要么需要校准的多视图捕捉或个性化的模板扫描，而大规模收集这些数据成本很高。我们对高质量但灵活的重建的关键见解是，将关于关节体形状的通用人类先验（从大规模训练数据中学习）与视频特定的关节“骨骼袋”变形（通过测试时间优化适合单个视频）仔细结合。我们通过学习一个神经隐式模型来实现这一点，该模型将身体和衣服的变形作为单独的运动模型层来解开。为了捕捉服装的微妙几何形状，我们在优化过程中利用了基于图像的先验，如人体姿势、表面法线和光流。由此产生的神经场可以提取到时间一致的网格中，或进一步优化为显式3D高斯分布，以实现高保真交互式渲染。在具有高度挑战性的服装变形和物体交互的数据集上，DressReston可以产生比现有技术更高保真的3D重建。项目页面：https://jefftan969.github.io/dressrecon/ et.al.|[2409.20563](http://arxiv.org/abs/2409.20563)|null|
|**2024-09-25**|**TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans**|我们介绍了一种新的框架，该框架从单眼视频中学习全身说话的人的动态神经辐射场（NeRF）。之前的工作只代表身体姿势或面部。然而，人类通过全身进行交流，结合身体姿势、手势和面部表情。在这项工作中，我们提出了TalkinNeRF，这是一个基于NeRF的统一网络，代表了整体4D人体运动。给定一个受试者的单眼视频，我们学习身体、面部和手的相应模块，这些模块结合在一起生成最终结果。为了捕捉复杂的手指关节，我们学习了手的额外变形场。我们的多身份表示能够同时训练多个科目，以及在完全看不见的姿势下进行强大的动画。只要输入一段短视频，它也可以推广到新的身份。我们展示了最先进的性能，用于为全身说话的人类制作动画，具有精细的手部发音和面部表情。 et.al.|[2409.16666](http://arxiv.org/abs/2409.16666)|null|
|**2024-09-24**|**Generative 3D Cardiac Shape Modelling for In-Silico Trials**|我们提出了一种深度学习方法，基于将形状表示为神经有符号距离场的零级集，对合成主动脉形状进行建模和生成，该方法受一系列可训练的嵌入向量的约束，并对每个形状的几何特征进行编码。通过使神经场在采样表面点上消失并强制其空间梯度具有单位范数，在从CT图像重建的主动脉根部网格数据集上训练网络。实证结果表明，我们的模型可以高保真地表示主动脉形状。此外，通过从学习到的嵌入向量中采样，我们可以生成类似于真实患者解剖结构的新形状，可用于计算机模拟试验。 et.al.|[2409.16058](http://arxiv.org/abs/2409.16058)|null|
|**2024-09-21**|**MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors**|由于缺乏几何指导和不完美的视图相关2D先验，从单眼图像中精确重建密集和语义注释的3D网格仍然是一项具有挑战性的任务。尽管我们已经见证了隐式神经场景表示的最新进展，能够简单地从多视图图像中进行精确的2D渲染，但很少有研究仅使用单眼先验来解决3D场景理解问题。在本文中，我们提出了MOSE，这是一种神经场语义重建方法，可以将推断的图像级噪声先验提升到3D，在3D和2D空间中产生精确的语义和几何。我们方法的关键动机是利用通用类不可知的分段掩码作为指导，在训练过程中促进渲染语义的局部一致性。在语义的帮助下，我们进一步将平滑正则化应用于无纹理区域，以获得更好的几何质量，从而实现几何和语义的互惠互利。在ScanNet数据集上的实验表明，我们的MOSE在3D语义分割、2D语义分割和3D表面重建任务的所有指标上都优于相关基线。 et.al.|[2409.14019](http://arxiv.org/abs/2409.14019)|null|
|**2024-09-17**|**SplatFields: Neural Gaussian Splats for Sparse 3D and 4D Reconstruction**|从多视图图像中数字化3D静态场景和4D动态事件长期以来一直是计算机视觉和图形学领域的一个挑战。最近，3D高斯散斑（3DGS）已经成为一种实用且可扩展的重建方法，由于其令人印象深刻的重建质量、实时渲染能力以及与广泛使用的可视化工具的兼容性而越来越受欢迎。然而，该方法需要大量的输入视图来实现高质量的场景重建，这引入了一个重大的实际瓶颈。在捕捉动态场景时，这一挑战尤为严峻，因为部署广泛的相机阵列的成本可能高得令人望而却步。在这项工作中，我们发现斑点特征缺乏空间自相关性是导致3DGS技术在稀疏重建环境中性能不佳的因素之一。为了解决这个问题，我们提出了一种优化策略，通过将splat特征建模为相应隐式神经场的输出，有效地正则化splat特征。这导致在各种场景中重建质量的一致提高。我们的方法有效地处理了静态和动态情况，这在不同设置和场景复杂性的广泛测试中得到了证明。 et.al.|[2409.11211](http://arxiv.org/abs/2409.11211)|null|
|**2024-10-02**|**Neural Fields for Adaptive Photoacoustic Computed Tomography**|光声计算机断层扫描（PACT）是一种具有广泛医学应用的非侵入性成像技术。传统的PACT图像重建算法受到组织中声速不均匀（SOS）引起的波前失真的影响，导致图像质量下降。考虑到这些影响可以提高图像质量，但测量SOS分布的实验成本很高。另一种方法是仅使用PA信号对初始压力图像和SOS进行联合重建。现有的关节重建方法存在局限性：计算成本高，无法直接恢复SOS，以及依赖于不准确的简化假设。隐式神经表示或神经场是计算机视觉中的一种新兴技术，用于通过基于坐标的神经网络学习物理场的有效和连续表示。在这项工作中，我们介绍了NF-APACT，这是一种高效的自监督框架，利用神经场来估计SOS，以实现准确和鲁棒的多通道解卷积。我们的方法比现有方法更快、更准确地消除了SOS像差。我们在一个新的数值体模以及实验收集的体模和体内数据上证明了我们的方法的成功。我们的代码和数字幻影可在https://github.com/Lukeli0425/NF-APACT. et.al.|[2409.10876](http://arxiv.org/abs/2409.10876)|null|
|**2024-09-09**|**Lagrangian Hashing for Compressed Neural Field Representations**|我们提出了拉格朗日散列，这是一种神经场的表示，结合了依赖于欧拉网格（即~InstantNGP）的快速训练NeRF方法的特征，以及使用配备有特征的点作为表示信息的方法（例如3D高斯散点或PointNeRF）。我们通过将基于点的表示合并到InstantNGP表示的分层哈希表的高分辨率层中来实现这一点。由于我们的点具有影响域，我们的表示可以被解释为哈希表中存储的高斯混合。我们提出的损失鼓励我们的高斯人向需要更多代表预算才能充分代表的地区移动。我们的主要发现是，我们的表示允许使用更紧凑的表示来重建信号，而不会影响质量。 et.al.|[2409.05334](http://arxiv.org/abs/2409.05334)|null|

<p align=right>(<a href=#updated-on-20241023>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

