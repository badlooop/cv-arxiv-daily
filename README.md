[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.04.10
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#video-diffusion>Video Diffusion</a></li>
    <li><a href=#3d>3D</a></li>
    <li><a href=#3d-reconstruction>3D Reconstruction</a></li>
    <li><a href=#diffusion>Diffusion</a></li>
    <li><a href=#nerf>NeRF</a></li>
  </ol>
</details>

## Video Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-04-09**|**EIDT-V: Exploiting Intersections in Diffusion Trajectories for Model-Agnostic, Zero-Shot, Training-Free Text-to-Video Generation**|零样本、无训练、基于图像的文本到视频生成是一个新兴领域，旨在使用现有的基于图像的扩散模型生成视频。该领域的当前方法需要对图像生成模型进行特定的架构更改，这限制了它们的适应性和可扩展性。与这些方法相比，我们提供了一种与模型无关的方法。我们在扩散轨迹中使用交点，只处理潜在值。仅通过轨迹的交点，我们无法获得局部的逐帧一致性和多样性。因此，我们转而使用基于网格的方法。上下文训练的LLM用于生成连贯的逐帧提示；另一个用于识别帧之间的差异。基于这些，我们获得了一个基于CLIP的注意力掩码，该掩码控制着每个网格单元的提示切换时间。较早的转换导致更高的方差，而较晚的转换导致更多的连贯性。因此，我们的方法可以确保帧的连贯性和方差之间的适当控制。我们的方法可实现最先进的性能，同时在处理各种图像生成模型时更加灵活。使用定量指标和用户研究的实证分析证实了我们的模型具有卓越的时间一致性、视觉保真度和用户满意度，从而为获得无训练、基于图像的文本到视频生成提供了一种新方法。 et.al.|[2504.06861](http://arxiv.org/abs/2504.06861)|null|
|**2025-04-09**|**DyDiT++: Dynamic Diffusion Transformers for Efficient Visual Generation**|扩散变换器（DiT）是一种新兴的视觉生成扩散模型，其性能优越，但计算成本高昂。我们的研究表明，这些成本主要源于\emph{静态}推理范式，它不可避免地在某些\emph{diffusion timestep}和\emph}空间区域引入了冗余计算。为了克服这种低效，我们提出\textbf{Dy}namic\textbf{Di}ffusion\textbf{T}ransformer（DyDiT）是一种架构，它可以沿emph{timestep}和emph{spatial}维度动态调整其计算。具体来说，我们引入了一种\ emph{时间步长动态宽度}（TDW）方法，该方法根据生成时间步长调整模型宽度。此外，我们设计了一种{Spatial wise Dynamic Token}（SDT）策略，以避免在不必要的空间位置进行冗余计算。TDW和SDT可以无缝集成到DiT中，大大加快了发电过程。在这些设计的基础上，我们在三个关键方面进一步增强了DyDiT。首先，DyDiT与基于流匹配的生成无缝集成，增强了其多功能性。此外，我们增强了DyDiT，以处理更复杂的视觉生成任务，包括视频生成和文本到图像生成，从而拓宽了其在现实世界中的应用。最后，为了解决完全微调和技术访问民主化的高成本问题，我们研究了以参数高效的方式训练DyDiT的可行性，并引入了基于时间步长的动态LoRA（TD-LoRA）。对不同视觉生成模型（包括DiT、SiT、Latte和FLUX）的广泛实验证明了DyDiT的有效性。 et.al.|[2504.06803](http://arxiv.org/abs/2504.06803)|null|
|**2025-04-09**|**RAGME: Retrieval Augmented Video Generation for Enhanced Motion Realism**|视频生成正在经历快速增长，这得益于扩散模型的进步以及更好、更大数据集的发展。然而，由于高维数据和任务的复杂性，制作高质量视频仍然具有挑战性。最近的努力主要集中在提高视觉质量和解决时间不一致性，如闪烁。尽管在这些领域取得了进展，但生成的视频在运动复杂性和物理合理性方面往往不足，许多输出要么看起来是静态的，要么表现出不切实际的运动。在这项工作中，我们提出了一个框架来提高生成视频中运动的真实感，探索了与现有文献的互补方向。具体来说，我们主张在生成阶段引入检索机制。检索到的视频充当接地信号，为模型提供物体如何移动的演示。我们的管道旨在应用于任何文本到视频的扩散模型，通过最小的微调对检索到的样本进行预训练模型的调节。我们通过既定的指标、最近提出的基准和定性结果展示了我们方法的优越性，并强调了该框架的其他应用。 et.al.|[2504.06672](http://arxiv.org/abs/2504.06672)|null|
|**2025-04-09**|**Patch Matters: Training-free Fine-grained Image Caption Enhancement via Local Perception**|高质量的图像字幕在提高跨模式应用程序的性能方面发挥着至关重要的作用，如文本到图像生成、文本到视频生成和文本图像检索。为了生成长格式、高质量的字幕，最近的许多研究都采用了多模态大语言模型（MLLM）。然而，目前的MLLM通常会产生缺乏细粒度细节的字幕或产生幻觉，这在开源和闭源模型中都是一个挑战。受特征整合理论的启发，该理论认为注意力必须集中在特定区域才能有效地整合视觉信息，我们提出了一种\textbf{分割然后聚合}策略。我们的方法首先将图像划分为语义和空间块，以提取细粒度的细节，增强模型对图像的局部感知。然后，这些局部细节被分层聚合，以生成全面的全局描述。为了解决生成的字幕中的幻觉和不一致问题，我们在层次聚合过程中应用了语义级过滤过程。这种无需训练的管道可以应用于开源模型（LLaVA-1.5、LLaVA-1.6、Mini Gemini）和闭源模型（Claude-3.5-Sonnet、GPT-4o、GLM-4V-Plus）。大量实验表明，我们的方法生成了更详细、更可靠的字幕，在不需要模型再训练的情况下推进了多模态描述生成。源代码可以在https://https://GeWu-Lab/Patch-Matters上找到 et.al.|[2504.06666](http://arxiv.org/abs/2504.06666)|null|
|**2025-04-08**|**CamContextI2V: Context-aware Controllable Video Generation**|最近，图像到视频（I2V）扩散模型已经证明了令人印象深刻的场景理解和生成质量，结合了图像条件来指导生成。然而，这些模型主要为静态图像制作动画，而不会超出其提供的上下文。引入额外的约束，如相机轨迹，可以增强多样性，但往往会降低视觉质量，限制了它们在需要忠实场景表示的任务中的适用性。我们提出了CamContextI2V，这是一种I2V模型，它将多种图像条件与3D约束以及相机控制相结合，以丰富全局语义和细粒度视觉细节。这使得视频生成更加连贯和上下文感知。此外，我们强调了时间意识对于有效语境表征的必要性。我们对RealEstate10K数据集的全面研究表明，视觉质量和相机可控性得到了改善。我们在以下网址公开我们的代码和模型：https://github.com/LDenninger/CamContextI2V. et.al.|[2504.06022](http://arxiv.org/abs/2504.06022)|null|
|**2025-04-07**|**One-Minute Video Generation with Test-Time Training**|今天的变形金刚仍然很难制作一分钟的视频，因为自我关注层在长时间的背景下效率低下。曼巴图层等替代方案难以处理复杂的多场景故事，因为它们的隐藏状态表现力较弱。我们尝试了测试时间训练（TTT）层，其隐藏状态本身可以是神经网络，因此更具表现力。将TTT层添加到预训练的Transformer中，使其能够从文本故事板生成一分钟的视频。为了验证概念，我们根据《猫和老鼠》漫画策划了一个数据集。与Mamba~2、门控DeltaNet和滑动窗口注意力层等基线相比，TTT层生成了更连贯的视频，讲述了复杂的故事，在每种方法100个视频的人类评估中领先34个Elo点。尽管有希望，但结果仍然包含伪影，这可能是由于预训练的5B模型的能力有限。我们的执行效率也可以提高。由于资源限制，我们只尝试了一分钟的视频，但这种方法可以扩展到更长的视频和更复杂的故事。示例视频、代码和注释可在以下网址获得：https://test-time-training.github.io/video-dit et.al.|[2504.05298](http://arxiv.org/abs/2504.05298)|null|
|**2025-04-07**|**Video-Bench: Human-Aligned Video Generation Benchmark**|视频生成评估对于确保生成模型在符合人类期望的同时生成视觉逼真、高质量的视频至关重要。当前的视频生成基准分为两大类：传统基准，它使用度量和嵌入来评估跨多个维度生成的视频质量，但往往与人类判断不一致；基于大型语言模型（LLM）的基准测试虽然能够进行类似人类的推理，但受到对视频质量指标和跨模态一致性理解有限的限制。为了应对这些挑战并建立一个更符合人类偏好的基准，本文介绍了Video Bench，这是一个全面的基准，具有丰富的提示套件和广泛的评估维度。该基准测试首次尝试在生成模型中系统地利用MLLM进行与视频生成评估相关的所有维度。通过结合少量镜头评分和查询链技术，Video Bench为生成的视频评估提供了一种结构化、可扩展的方法。在包括Sora在内的先进模型上的实验表明，Video Bench在所有维度上都与人类偏好高度一致。此外，在我们的框架评估与人类评估不同的情况下，它始终如一地提供更客观和准确的见解，这表明它比传统的人类判断具有更大的潜在优势。 et.al.|[2504.04907](http://arxiv.org/abs/2504.04907)|null|
|**2025-04-07**|**FantasyTalking: Realistic Talking Portrait Generation via Coherent Motion Synthesis**|从单个静态肖像创建逼真的可动画化身仍然具有挑战性。现有的方法往往很难捕捉到微妙的面部表情、相关的全局身体动作和动态背景。为了解决这些局限性，我们提出了一种新的框架，该框架利用预训练的视频扩散变换器模型来生成具有可控运动动态的高保真、连贯的谈话肖像。我们工作的核心是双阶段视听对齐策略。在第一阶段，我们采用剪辑级训练方案，通过在整个场景中对齐音频驱动的动态来建立连贯的全局运动，包括参考肖像、上下文对象和背景。在第二阶段，我们使用嘴唇跟踪掩模在帧级别细化嘴唇运动，确保与音频信号的精确同步。为了在不影响运动灵活性的情况下保持身份，我们用一个面部聚焦的交叉注意力模块取代了常用的参考网络，该模块在整个视频中有效地保持了面部的一致性。此外，我们还集成了一个运动强度调制模块，该模块明确控制表情和身体运动强度，从而能够对肖像运动进行可控的操纵，而不仅仅是嘴唇运动。大量的实验结果表明，我们提出的方法实现了更高的质量，具有更好的真实感、连贯性、运动强度和身份保持。我们的项目页面：https://fantasy-amap.github.io/fantasy-talking/. et.al.|[2504.04842](http://arxiv.org/abs/2504.04842)|null|
|**2025-04-05**|**Video4DGen: Enhancing Video and 4D Generation through Mutual Optimization**|4D（即顺序3D）生成的进步为各种应用中的逼真体验开辟了新的可能性，用户可以从任何角度探索动态对象或角色。与此同时，视频生成模型因其能够生成逼真和富有想象力的帧而受到特别关注。这些模型也被观察到具有很强的3D一致性，表明它们有可能成为世界模拟器。在这项工作中，我们提出了Video4DGen，这是一个新颖的框架，擅长从单个或多个生成的视频中生成4D表示，以及生成4D引导视频。该框架对于创建保持空间和时间一致性的高保真虚拟内容至关重要。Video4DGen生成的4D输出使用我们提出的动态高斯曲面（DGS）表示，DGS优化了时变扭曲函数，将高斯曲面（曲面元素）从静态转换为动态扭曲状态。我们设计了高斯表面的扭曲状态几何正则化和细化，以保持结构的完整性和细粒度的外观细节。为了从多个视频中执行4D生成，并在空间、时间和姿势维度上捕获表示，我们设计了多视频对齐、根姿势优化和姿势引导帧采样策略。利用连续扭曲场还可以精确描绘每个视频帧的姿态、运动和变形。此外，为了提高观察所有相机姿态的整体保真度，Video4DGen在4D内容的指导下进行了新颖的视图视频生成，并使用所提出的置信度滤波DGS来提高生成序列的质量。凭借4D和视频生成的能力，Video4DGen为虚拟现实、动画等领域的应用提供了强大的工具。 et.al.|[2504.04153](http://arxiv.org/abs/2504.04153)|null|
|**2025-04-05**|**Multi-identity Human Image Animation with Structural Video Diffusion**|从单个图像生成人类视频，同时确保高视觉质量和精确控制是一项具有挑战性的任务，特别是在涉及多个人和与物体交互的复杂场景中。现有的方法虽然对单个人类案例有效，但往往无法处理复杂的多身份交互，因为它们很难将正确的人类外观和姿势条件配对，并对3D感知动态的分布进行建模。为了解决这些局限性，我们提出了结构化视频扩散，这是一种为生成逼真的多人视频而设计的新框架。我们的方法引入了两个核心创新：身份特定的嵌入，以保持个体之间的一致外观，以及一种结构学习机制，该机制结合了深度和表面法线线索来模拟人与物体的交互。此外，我们用25K个新视频扩展了现有的人类视频数据集，这些视频具有不同的多人和对象交互场景，为训练提供了坚实的基础。实验结果表明，结构化视频扩散在为多个主题生成逼真、连贯的视频方面表现出色，具有动态和丰富的交互，推进了以人为中心的视频生成状态。 et.al.|[2504.04126](http://arxiv.org/abs/2504.04126)|null|

<p align=right>(<a href=#updated-on-20250410>back to top</a>)</p>

## 3D

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-04-09**|**Glossy Object Reconstruction with Cost-effective Polarized Acquisition**|基于图像的光滑物体3D重建的挑战在于从捕获的图像中分离出光滑表面上的漫反射和镜面反射分量，这项任务因仅使用RGB数据识别照明条件和材质属性的模糊性而变得复杂。虽然最先进的方法依赖于定制和/或高端设备进行数据采集，这可能既麻烦又耗时，但这项工作引入了一种可扩展的极化辅助方法，该方法采用了具有成本效益的采集工具。通过将线性偏振器连接到现成的RGB相机上，可以捕获多视图偏振图像，而不需要预先校准或精确测量偏振器角度，从而大大降低了系统建设成本。所提出的方法将极化BRDF、斯托克斯矢量和物体表面的极化状态表示为神经隐式场。通过优化输入偏振图像的渲染损失，结合偏振器角度，可以恢复这些场。通过利用偏振渲染的隐式表示的基本物理原理，我们的方法通过在公共数据集和真实捕获的图像中进行重建和新视图合成的实验，证明了其优于现有技术。 et.al.|[2504.07025](http://arxiv.org/abs/2504.07025)|null|
|**2025-04-09**|**SVG-IR: Spatially-Varying Gaussian Splatting for Inverse Rendering**|由于其不适定特性，从图像重建3D资产（称为逆渲染（IR））仍然是一项具有挑战性的任务。3D高斯散斑（3DGS）在新的视图合成（NVS）任务中表现出了令人印象深刻的能力。方法通过将辐射分离为BRDF参数和照明来将其应用于重新照明，但由于每个高斯函数的能力有限，每个高斯函数具有恒定的材料参数和法线，并且没有间接照明的物理约束，因此会产生伪影和不自然的间接照明，从而产生较差的重新照明质量。在本文中，我们提出了一种称为空间维高斯逆渲染（SVG-IR）的新框架，旨在提高NVS和重新照明质量。为此，我们提出了一种新的表示空间变化高斯（SVG），它允许每高斯空间变化的参数。这种增强的表示方式由SVG飞溅方案补充，类似于传统图形管道中的顶点/片段着色。此外，我们整合了一个基于物理的间接照明模型，实现了更逼真的重新照明。所提出的SVG-IR框架显著提高了渲染质量，在峰值信噪比（PSNR）方面比最先进的基于NeRF的方法高出2.5 dB，在重新点亮任务方面比现有的基于高斯的技术高出3.5 dB，同时保持实时渲染速度。 et.al.|[2504.06815](http://arxiv.org/abs/2504.06815)|null|
|**2025-04-09**|**Collision avoidance from monocular vision trained with novel view synthesis**|碰撞避免可以在显式环境模型中进行检查，如高程图或占用网格，但将这些模型与运动策略集成需要准确的状态估计。在这项工作中，我们考虑了从隐式环境模型中避免碰撞的问题。我们使用单眼RGB图像作为输入，并从2D高斯飞溅生成的逼真图像中训练碰撞避免策略。我们在现实世界的实验中评估了在速度命令下产生的管道，该命令使机器人在有障碍物的拦截过程中。我们的研究结果表明，RGB图像足以在收集训练数据的房间和非分布环境中做出避免碰撞的决定。 et.al.|[2504.06651](http://arxiv.org/abs/2504.06651)|null|
|**2025-04-09**|**Stochastic Ray Tracing of 3D Transparent Gaussians**|3D高斯散点最近被广泛用作新颖的视图合成、重新照明和文本到3D生成任务的3D表示，通过一组带有不透明度和视图相关颜色的显式3D高斯分布，提供逼真和详细的结果。然而，许多透明图元的高效渲染仍然是一个重大挑战。现有的方法要么对3D高斯进行光栅化，按视图进行近似排序，要么依赖于高端RTX GPU来彻底处理所有光线高斯交点（通过网格边界高斯）。本文提出了一种随机光线追踪方法来渲染透明图元的3D云。与按顺序处理所有光线高斯交点不同，每条光线只穿过加速度结构一次，随机接受并着色单个交点（或使用简单扩展的N个交点）。这种方法最大限度地减少了着色时间，避免了沿光线对高斯分布进行排序，同时最大限度地降低了寄存器的使用率，即使在低端GPU上也最大限度地提高了并行性。穿过高斯资产的光线成本与标准网格相交光线的成本相当。虽然我们的方法引入了噪声，但阴影是无偏的，方差很小，因为随机接受度是基于累积不透明度进行重要抽样的。与蒙特卡洛哲学的一致性简化了实现，并很容易将我们的方法集成到传统的路径跟踪框架中。 et.al.|[2504.06598](http://arxiv.org/abs/2504.06598)|null|
|**2025-04-08**|**HiMoR: Monocular Deformable Gaussian Reconstruction with Hierarchical Motion Representation**|我们提出了分层运动表示（HiMoR），这是一种用于3D高斯基元的新型变形表示，能够实现高质量的单目动态3D重建。HiMoR背后的见解是，日常场景中的运动可以分解为更粗糙的运动，作为更精细细节的基础。使用树结构，HiMoR的节点表示不同级别的运动细节，较浅的节点对粗略运动进行建模以实现时间平滑，较深的节点捕获更精细的运动。此外，我们的模型使用一些共享的运动基来表示不同节点集的运动，这与运动趋于平滑和简单的假设相一致。这种运动表示设计为高斯模型提供了更结构化的变形，最大限度地利用时间关系来解决单目动态3D重建的挑战性任务。我们还建议使用更可靠的感知度量作为替代方案，因为用于评估单眼动态3D重建的像素级度量有时可能无法准确反映重建的真实质量。大量实验证明了我们的方法在从具有复杂运动的挑战性单眼视频中实现卓越的新颖视图合成方面的有效性。 et.al.|[2504.06210](http://arxiv.org/abs/2504.06210)|null|
|**2025-04-08**|**Meta-Continual Learning of Neural Fields**|神经场（NF）作为一种用于复杂数据表示的通用框架，已经获得了突出地位。这项工作揭示了一个新的问题设置，称为“神经场元连续学习”（MCL-NF），并引入了一种新的策略，该策略采用模块化架构与基于优化的元学习相结合。我们的策略侧重于克服现有神经场连续学习方法的局限性，如灾难性遗忘和缓慢收敛，实现了高质量的重建，显著提高了学习速度。我们进一步引入了神经辐射场的Fisher信息最大化损失（FIM-NeRF），它在样本级别最大化信息增益以增强学习泛化，并证明了收敛保证和泛化界限。我们在六个不同的数据集上对图像、音频、视频重建和视图合成任务进行了广泛的评估，证明了我们的方法在重建质量和速度方面优于现有的MCL和CL-NF方法。值得注意的是，我们的方法在降低参数要求的情况下，实现了神经场对城市级NeRF渲染的快速适应。 et.al.|[2504.05806](http://arxiv.org/abs/2504.05806)|null|
|**2025-04-07**|**DeclutterNeRF: Generative-Free 3D Scene Recovery for Occlusion Removal**|最近的新颖视图合成（NVS）技术，包括神经辐射场（NeRF）和3D高斯散斑（3DGS），极大地推进了具有高质量渲染和逼真细节恢复的3D场景重建。在保留场景细节的同时有效地消除遮挡可以进一步增强这些技术的鲁棒性和适用性。然而，现有的对象和遮挡去除方法主要依赖于生成先验，尽管填充了由此产生的洞，但会引入新的伪影和模糊。此外，用于评估遮挡去除方法的现有基准数据集缺乏现实的复杂性和视点变化。为了解决这些问题，我们引入了DeclutterSet，这是一个新的数据集，具有不同的场景，在前景、中景和背景上分布着明显的遮挡，在视点之间表现出大量的相对运动。我们进一步介绍了DeclutterNeRF，这是一种没有生成先验的咬合去除方法。DeclutterNeRF引入了可学习相机参数的联合多视图优化、遮挡退火正则化，并采用了可解释的随机结构相似性损失，确保从不完整图像中进行高质量、无伪影的重建。实验表明，在我们提出的DeclutterSet上，DeclutterNeRF的表现明显优于最先进的方法，为未来的研究奠定了坚实的基础。 et.al.|[2504.04679](http://arxiv.org/abs/2504.04679)|null|
|**2025-04-05**|**3R-GS: Best Practice in Optimizing Camera Poses Along with 3DGS**|3D高斯散点（3DGS）以其效率和质量彻底改变了神经渲染，但与许多新颖的视图合成方法一样，它在很大程度上依赖于运动结构（SfM）系统的精确相机姿态。尽管最近的SfM管道取得了令人印象深刻的进展，但如何同时进一步提高其在具有挑战性的条件下（例如无纹理场景）的鲁棒性能和相机参数估计的精度仍然是个问题。我们提出了3R-GS，这是一个3D高斯散布框架，通过联合优化来自大型重建先验MASt3R SfM的3D高斯和相机参数来弥合这一差距。我们注意到，天真地执行联合3D高斯和相机优化面临着两个挑战：对SfM初始化质量的敏感性，以及其有限的全局优化能力，导致次优重建结果。我们的3R-GS通过整合优化实践克服了这些问题，即使在相机配准不完美的情况下也能实现稳健的场景重建。大量实验表明，3R-GS提供了高质量的新颖视图合成和精确的相机姿态估计，同时保持了计算效率。项目页面：https://zsh523.github.io/3R-GS/ et.al.|[2504.04294](http://arxiv.org/abs/2504.04294)|null|
|**2025-04-04**|**WildGS-SLAM: Monocular Gaussian Splatting SLAM in Dynamic Environments**|我们介绍了WildGS SLAM，这是一个强大而高效的单目RGB SLAM系统，旨在通过利用不确定性感知几何映射来处理动态环境。与假设静态场景的传统SLAM系统不同，我们的方法集成了深度和不确定性信息，以提高存在运动物体时的跟踪、映射和渲染性能。我们引入了一个由浅层多层感知器和DINOv2特征预测的不确定性映射，以指导跟踪和映射过程中的动态对象去除。该不确定性图增强了密集束调整和高斯图优化，提高了重建精度。我们的系统在多个数据集上进行了评估，并演示了无伪影的视图合成。结果显示，与最先进的方法相比，WildGS SLAM在动态环境中具有卓越的性能。 et.al.|[2504.03886](http://arxiv.org/abs/2504.03886)|null|
|**2025-04-04**|**3D Scene Understanding Through Local Random Access Sequence Modeling**|从单个图像中理解3D场景是计算机视觉中的一个关键问题，在图形、增强现实和机器人技术中有许多下游应用。虽然基于扩散的建模方法显示出了希望，但它们往往难以保持对象和场景的一致性，尤其是在复杂的现实世界场景中。为了解决这些局限性，我们提出了一种称为局部随机访问序列（LRAS）建模的自回归生成方法，该方法使用局部补丁量化和随机序列生成。通过利用光流作为3D场景编辑的中间表示，我们的实验表明，LRAS实现了最先进的新颖视图合成和3D对象操纵功能。此外，我们通过对序列设计的简单修改，证明了我们的框架可以自然地扩展到自监督深度估计。通过在多个3D场景理解任务上实现强大的性能，LRAS为构建下一代3D视觉模型提供了一个统一有效的框架。 et.al.|[2504.03875](http://arxiv.org/abs/2504.03875)|null|

<p align=right>(<a href=#updated-on-20250410>back to top</a>)</p>

## 3D Reconstruction

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-04-09**|**Glossy Object Reconstruction with Cost-effective Polarized Acquisition**|基于图像的光滑物体3D重建的挑战在于从捕获的图像中分离出光滑表面上的漫反射和镜面反射分量，这项任务因仅使用RGB数据识别照明条件和材质属性的模糊性而变得复杂。虽然最先进的方法依赖于定制和/或高端设备进行数据采集，这可能既麻烦又耗时，但这项工作引入了一种可扩展的极化辅助方法，该方法采用了具有成本效益的采集工具。通过将线性偏振器连接到现成的RGB相机上，可以捕获多视图偏振图像，而不需要预先校准或精确测量偏振器角度，从而大大降低了系统建设成本。所提出的方法将极化BRDF、斯托克斯矢量和物体表面的极化状态表示为神经隐式场。通过优化输入偏振图像的渲染损失，结合偏振器角度，可以恢复这些场。通过利用偏振渲染的隐式表示的基本物理原理，我们的方法通过在公共数据集和真实捕获的图像中进行重建和新视图合成的实验，证明了其优于现有技术。 et.al.|[2504.07025](http://arxiv.org/abs/2504.07025)|null|
|**2025-04-09**|**SIGMAN:Scaling 3D Human Gaussian Generation with Millions of Assets**|长期以来，3D人体数字化一直是一项备受追求但具有挑战性的任务。现有的方法旨在从单个或多个视图生成高质量的3D数字人，但主要受到当前范式和3D人力资源稀缺的限制。具体而言，最近的方法分为几种范式：基于优化和前馈（单视图回归和带重建的多视图生成）。然而，由于遮挡和不可见性，它们在将低维平面映射到高维空间时分别受到速度慢、质量低、级联推理和模糊性的限制。此外，现有的3D人力资源规模仍然很小，不足以进行大规模培训。为了应对这些挑战，我们提出了一种用于3D人体数字化的潜在空间生成范式，该范式涉及通过UV结构化VAE将多视图图像压缩为高斯图像，以及基于DiT的条件生成，我们将不适定的低维到高维映射问题转化为可学习的分布偏移，这也支持端到端推理。此外，我们采用多视图优化方法结合合成数据构建HGS-1M数据集，其中包含100万美元的3D高斯资产，以支持大规模训练。实验结果表明，我们的范式在大规模训练的支持下，产生了具有复杂纹理、面部细节和宽松服装变形的高质量3D人体高斯模型。 et.al.|[2504.06982](http://arxiv.org/abs/2504.06982)|null|
|**2025-04-09**|**Wheat3DGS: In-field 3D Reconstruction, Instance Segmentation and Phenotyping of Wheat Heads with Gaussian Splatting**|植物形态特征的自动提取对于通过高通量田间表型分析（HTFP）支持作物育种和农业管理至关重要。基于多视图RGB图像的解决方案因其可扩展性和可负担性而具有吸引力，能够实现2D方法无法直接捕获的体积测量。虽然神经辐射场（NeRFs）等先进方法显示出了希望，但它们的应用仅限于从少数植物或器官中计数或提取特征。此外，由于田间条件下作物冠层的遮挡和密集排列，准确测量研究作物产量所必需的单个小麦头等复杂结构仍然特别具有挑战性。3D高斯散斑（3DGS）的最新发展为HTFP提供了一种有前景的替代方案，因为它具有高质量的重建和显式的基于点的表示。在本文中，我们提出了Wheat3DGS，这是一种利用3DGS和Segment Anything模型（SAM）自动对数百个小麦头进行精确3D实例分割和形态测量的新方法，代表了3DGS在HTFP中的首次应用。我们根据高分辨率激光扫描数据验证了小麦头提取的准确性，获得了长度、宽度和体积的平均绝对百分比误差分别为15.1%、18.3%和40.2%。我们提供了与基于NeRF的方法和传统多视图立体声（MVS）的额外比较，展示了卓越的结果。我们的方法能够大规模快速、无损地测量与产量相关的关键性状，这对加快作物育种和提高我们对小麦发育的理解具有重要意义。 et.al.|[2504.06978](http://arxiv.org/abs/2504.06978)|null|
|**2025-04-09**|**S-EO: A Large-Scale Dataset for Geometry-Aware Shadow Detection in Remote Sensing Applications**|我们介绍S-EO数据集：一个大规模、高分辨率的数据集，旨在推进几何感知阴影检测。我们的数据集来自不同的公共领域来源，包括挑战数据集和美国地质调查局等政府提供商，包括美国各地的702个地理参考图块，每个图块覆盖500x500米。每个图块包括多日期、多角度WorldView-3泛色RGB图像、全色图像和从激光雷达扫描获得的该地区的地面实况DSM。对于每张图像，我们提供了一个基于几何形状和太阳位置的阴影掩模、一个基于NDVI指数的植被掩模和一个捆绑调整的RPC模型。S-EO数据集拥有约20000张图像，为遥感图像中的阴影检测及其在3D重建中的应用建立了一个新的公共资源。为了证明数据集的影响，我们训练和评估了一个阴影探测器，展示了它的泛化能力，甚至是对航空图像的泛化能力。最后，我们扩展了EO-NeRF——一种最先进的卫星图像NeRF方法——以利用我们的阴影预测来改进3D重建。 et.al.|[2504.06920](http://arxiv.org/abs/2504.06920)|null|
|**2025-04-09**|**GSta: Efficient Training Scheme with Siestaed Gaussians for Monocular 3D Scene Reconstruction**|高斯散斑（GS）是一种流行的3D重建方法，主要是因为它能够合理快速地收敛，忠实地表示场景，并以快速的方式渲染（新颖的）视图。然而，它存在较大的存储和内存需求，其训练速度仍然落后于基于哈希网格的辐射场方法（如Instant NGP），这使得在机器人场景中部署它们变得特别困难，在这些场景中，3D重建对于精确操作至关重要。在本文中，我们提出了GSta，它基于高斯分布的位置和颜色梯度规范，动态识别在训练过程中收敛良好的高斯分布。通过迫使这些高斯人午睡并在训练过程中停止更新（冻结），与现有技术相比，我们以具有竞争力的准确性提高了训练速度。我们还提出了一种基于在训练图像子集上计算的PSNR值的早期停止机制。结合其他改进，如集成学习率调度器，GSta在保持质量的同时，在收敛速度、内存和存储要求方面实现了改进的帕累托前沿。我们还表明，GSta可以改进其他方法，并在提高效率方面补充正交方法；一旦与Trick GS结合使用，GSta的训练速度将提高5倍，磁盘大小比普通GS小16倍，同时具有相当的准确性，只消耗一半的峰值内存。更多可视化信息请访问https://anilarmagan.github.io/SRUK-GSta. et.al.|[2504.06716](http://arxiv.org/abs/2504.06716)|null|
|**2025-04-08**|**D^2USt3R: Enhancing 3D Reconstruction with 4D Pointmaps for Dynamic Scenes**|我们解决了动态场景中的3D重建任务，其中对象运动会降低先前3D点图回归方法的质量，例如最初为静态3D场景重建设计的DUSt3R。尽管这些方法在静态环境中提供了一种优雅而强大的解决方案，但它们在仅基于相机姿态的动态运动中难以实现。为了克服这一点，我们提出了D^2USt3R，它对4D点图进行回归，以前馈方式同时捕获静态和动态3D场景几何。通过明确地结合空间和时间方面，我们的方法成功地封装了与所提出的4D点图的时空密集对应关系，增强了下游任务。广泛的实验评估表明，我们提出的方法在具有复杂运动的各种数据集上始终实现了卓越的重建性能。 et.al.|[2504.06264](http://arxiv.org/abs/2504.06264)|null|
|**2025-04-08**|**HiMoR: Monocular Deformable Gaussian Reconstruction with Hierarchical Motion Representation**|我们提出了分层运动表示（HiMoR），这是一种用于3D高斯基元的新型变形表示，能够实现高质量的单目动态3D重建。HiMoR背后的见解是，日常场景中的运动可以分解为更粗糙的运动，作为更精细细节的基础。使用树结构，HiMoR的节点表示不同级别的运动细节，较浅的节点对粗略运动进行建模以实现时间平滑，较深的节点捕获更精细的运动。此外，我们的模型使用一些共享的运动基来表示不同节点集的运动，这与运动趋于平滑和简单的假设相一致。这种运动表示设计为高斯模型提供了更结构化的变形，最大限度地利用时间关系来解决单目动态3D重建的挑战性任务。我们还建议使用更可靠的感知度量作为替代方案，因为用于评估单眼动态3D重建的像素级度量有时可能无法准确反映重建的真实质量。大量实验证明了我们的方法在从具有复杂运动的挑战性单眼视频中实现卓越的新颖视图合成方面的有效性。 et.al.|[2504.06210](http://arxiv.org/abs/2504.06210)|null|
|**2025-04-08**|**Flash Sculptor: Modular 3D Worlds from Objects**|现有的文本到3D和图像到3D模型经常难以处理涉及多个对象和复杂交互的复杂场景。尽管最近的一些尝试已经探索了这种组合场景，但它们仍然需要一个广泛的优化整个布局的过程，这即使不是完全不可行，也是非常繁琐的。为了克服这些挑战，我们在本文中提出了Flash Sculptor，这是一个简单而有效的框架，用于从单个图像重建合成3D场景/对象。Flash Sculptor的核心是一种分而治之的策略，它将构图场景重建分解为一系列子任务，包括处理每个单独实例的外观、旋转、缩放和平移。具体来说，对于旋转，我们引入了一种从粗到细的方案，可以同时实现效率和准确性的最佳效果，而对于平移，我们开发了一种基于异常值去除的算法，可以确保在一步中实现稳健和精确的参数，而无需任何迭代优化。大量实验表明，Flash Sculptor的速度至少是现有合成3D方法的3倍，同时为合成3D重建性能设定了新的基准。代码可在以下网址获得https://github.com/YujiaHu1109/Flash-Sculptor. et.al.|[2504.06178](http://arxiv.org/abs/2504.06178)|null|
|**2025-04-08**|**Micro-splatting: Maximizing Isotropic Constraints for Refined Optimization in 3D Gaussian Splatting**|3D高斯散斑技术的最新进展为大规模场景实现了令人印象深刻的可扩展性和实时渲染，但在捕捉细粒度细节方面往往不足。依赖于相对较大的协方差参数的传统方法往往会产生模糊的表示，而直接减小协方差大小会导致稀疏性。在这项工作中，我们引入了微飞溅（最大化各向同性约束以实现3D高斯飞溅中的精细优化），这是一种旨在克服这些局限性的新框架。我们的方法利用协方差正则化项来惩罚过大的高斯分布，以确保每个斑点保持紧凑和各向同性。这项工作实现了一种自适应致密化策略，通过降低分割阈值，然后增强损失函数，动态细化具有高图像梯度的区域。此策略在需要时产生更密集、更详细的高斯均值，而不会牺牲渲染效率。使用L1、L2、PSNR、SSIM和LPIPS等指标的定量评估以及定性比较表明，我们的方法显著增强了3D重建中的精细细节。 et.al.|[2504.05740](http://arxiv.org/abs/2504.05740)|null|
|**2025-04-08**|**POMATO: Marrying Pointmap Matching with Temporal Motion for Dynamic 3D Reconstruction**|动态场景中的3D重建主要依赖于几何估计和匹配模块的组合，其中后一项任务对于区分动态区域至关重要，这有助于减轻相机和物体运动带来的干扰。此外，匹配模块显式地对对象运动进行建模，从而能够跟踪特定目标并在复杂场景中推进运动理解。最近，DUSt3R中点图的表示提出了一种潜在的解决方案，可以统一3D空间中的几何估计和匹配，但它仍然在动态区域中难以进行模糊匹配，这可能会阻碍进一步的改进。在这项工作中，我们提出了POMATO，这是一个通过将点图匹配与时间运动相结合进行动态3D重建的统一框架。具体来说，我们的方法首先通过将来自不同视图的动态和静态区域的RGB像素映射到统一坐标系内的3D点图来学习显式匹配关系。此外，我们引入了一个用于动态运动的时间运动模块，该模块确保了不同帧之间的尺度一致性，并提高了需要精确几何和可靠匹配的任务的性能，最明显的是3D点跟踪。我们通过展示多个下游任务（包括视频深度估计、3D点跟踪和姿态估计）的显著性能，展示了所提出的点图匹配和时间融合范式的有效性。代码和模型可在以下网址公开获取https://github.com/wyddmw/POMATO. et.al.|[2504.05692](http://arxiv.org/abs/2504.05692)|null|

<p align=right>(<a href=#updated-on-20250410>back to top</a>)</p>

## Diffusion

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-04-09**|**The Lyman-alpha and Continuum Origins Survey II: the uneventful journey of escaping Ly $α$ and ionizing radiation through the neutral ISM and CGM of galaxies**|星系演化研究目前面临的挑战之一是建立控制电离辐射从星系逃逸的机制。在这项工作中，我们研究了Lyman连续体（LyC）逃逸与星系周围介质（CGM）条件之间的联系，正如Lyα晕（LAHs）在发射中所探测到的那样。我们使用Lyman alpha和continuum Origins Survey（LaCOS）的Ly$\alpha$和UV连续成像数据，通过LyC观测（逃逸分数为$f_{\rm esc}^{\rm LyC}\simeq 0.01-0.49$）瞄准附近的42个恒星形成星系（$z\simeq 0.3$）。LaCOS星系普遍显示出扩展的Ly$\alpha$发射，与非LCE相比，LyC发射体（LCE）相对于紫外线尺寸具有更紧凑的Ly$\ alpha$形态，Ly$\alpha$空间偏移不超过紫外线连续体的范围。我们使用组合的Sersic加指数二维轮廓对漫射LAH进行建模，发现Ly$\alpha$的特征尺度长度平均是UV尺度长度的十倍。我们揭示了$f_{\rm esc}^{\rm LyC}$与Ly$\alpha$Halo分数（HF，或晕对Ly$\alpha$总光度的贡献）之间的紧密反相关性，我们建议将其作为新的LyC指标。我们的观测还表明，HF与ISM中的中性气体呈正相关，揭示了一幅图像，其中LCE中的Ly$\alpha$和LyC光子通过清晰的视线直接从中心星爆中出现，并且在Ly$\alpha$的情况下，最大限度地减少了CGM中的散射相互作用次数。LaCOS中LAH的性质类似于$z\geq 3$的LAH，这表明依赖Ly$\alpha$空间性质的$f_{\rm esc}^{\rm LyC}$ 预测器缺乏进化，并确保了这些指标适用于高红移星系的观测。 et.al.|[2504.07074](http://arxiv.org/abs/2504.07074)|null|
|**2025-04-09**|**Glossy Object Reconstruction with Cost-effective Polarized Acquisition**|基于图像的光滑物体3D重建的挑战在于从捕获的图像中分离出光滑表面上的漫反射和镜面反射分量，这项任务因仅使用RGB数据识别照明条件和材质属性的模糊性而变得复杂。虽然最先进的方法依赖于定制和/或高端设备进行数据采集，这可能既麻烦又耗时，但这项工作引入了一种可扩展的极化辅助方法，该方法采用了具有成本效益的采集工具。通过将线性偏振器连接到现成的RGB相机上，可以捕获多视图偏振图像，而不需要预先校准或精确测量偏振器角度，从而大大降低了系统建设成本。所提出的方法将极化BRDF、斯托克斯矢量和物体表面的极化状态表示为神经隐式场。通过优化输入偏振图像的渲染损失，结合偏振器角度，可以恢复这些场。通过利用偏振渲染的隐式表示的基本物理原理，我们的方法通过在公共数据集和真实捕获的图像中进行重建和新视图合成的实验，证明了其优于现有技术。 et.al.|[2504.07025](http://arxiv.org/abs/2504.07025)|null|
|**2025-04-09**|**Latent Diffusion U-Net Representations Contain Positional Embeddings and Anomalies**|扩散模型在合成逼真图像方面表现出了卓越的能力，激发了人们对将其表示用于各种下游任务的兴趣。为了更好地理解这些表示的鲁棒性，我们使用表示相似性和范数分析了流行的稳定扩散模型。我们的发现揭示了三种现象：（1）在中间表示中存在学习位置嵌入，（2）高相似性角伪影，以及（3）异常高范数伪影。这些发现强调了在将扩散模型表示用于需要鲁棒特征的下游任务之前，需要进一步研究其特性。项目页面：https://jonasloos.github.io/sd-representation-anomalies et.al.|[2504.07008](http://arxiv.org/abs/2504.07008)|null|
|**2025-04-09**|**A Krylov projection algorithm for large symmetric matrices with dense spectra**|我们考虑了具有密集谱的大s.p.d $A\in\mathbb{R}^{n\times n}$和$B\in\machbb{R}^{n&times p}$的$B^T（A+sI）^{-1}B$的近似值，$p\n$。我们的目标是计算具有连续谱度量的问题的大规模离散化的多输入多输出（MIMO）传递函数，例如无界域上的线性时不变（LTI）PDE。已知传统的Krylov方法，如Lanczos或CG算法，对于计算$（A+sI）是最优的^{-1}B$与真正的正$s$相匹配，从而适应了明显离散和不均匀的光谱。然而，对于具有密集谱的矩阵，自适应性会受到抑制。[Zimmerling，Druskin，Simoncini，Journal of Scientific Computing 103（1），5（2025）]中证明，使用块Lanczos方法计算的Gau和Gau-Radau二次曲线的平均值显著降低了此类问题的近似误差。在这里，我们介绍一个自适应Kre\u{i}n-Nudelman扩展（块）Lanczos递归，允许以可忽略的$o（n）$成本进一步加速。与Gau-Radau求积法类似，对（块）Lanczos矩阵应用了低秩修改。然而，与Gau-Radau求积法不同，这种修改取决于$\sqrt{s}$ ，可以在Hermite-Pad'e近似的框架内考虑，众所周知，Hermite-Pad’e近似对分支切割问题有效，可以很好地近似密集谱间隔。无界域中热扩散和准静磁麦克斯韦算子的大规模离散化的数值结果证实了所提出方法的有效性。 et.al.|[2504.06998](http://arxiv.org/abs/2504.06998)|null|
|**2025-04-09**|**Cerebral blood flow monitoring using a deep learning implementation of the two-layer DCS analytical model with a 512 512 SPAD array**|扩散相关光谱（DCS）分析红细胞散射的光子的自相关函数，从而能够在床边无创地连续测量深层组织血流。多层DCS模型（两层和三层）增强了脑血流指数（CBFi）的敏感性，并减轻了脑外组织的干扰。然而，这些模型需要多个预定义的参数，并且计算量很大，使其不适用于实时床边监测。为了应对这一挑战，我们将单光子雪崩二极管（SPAD）阵列与基于深度学习（DL）的方法集成在一起，该方法基于两层分析模型生成的数据进行训练。这种方法绕过了传统的模型拟合，实现了实时CBFi监测，同时最大限度地减少了浅表组织污染。我们首先使用蒙特卡洛模拟测试数据集验证了我们的方法，证明了相对CBFi估计的优越准确性（5.8%的误差比传统拟合的19.1%）和增强的CBFi灵敏度（87.1%比55.4%）。此外，我们的方法有效地隔离了浅层血流变化，在现实情况下比单指数拟合快750倍。我们进一步评估了健康成年人的系统，在使用512 512 SPAD阵列传感器进行脑活动测试期间实现了实时CBFi监测和脉动波形恢复。这些结果突显了我们的方法在实时大脑活动监测方面的潜力。 et.al.|[2504.06997](http://arxiv.org/abs/2504.06997)|null|
|**2025-04-09**|**Enhancing TiFe Alloy Activation for Hydrogen Storage Through Al, Cr, Co, and Cu Substitutions as a Step Towards Future Recycling**|本研究调查了 $TiFe_{0.80}$-$X_{0.20}$（X=Co，Cu，Cr，Al）合金的活化行为，以从循环经济的角度确定从回收来源生产储氢合金的最有效材料。使用两种方法测试活化：室温和64巴氢气下的Sievert容量仪，以及在高达400℃的热循环下使用50巴氢气的高压差示扫描量热法。通过评估分别受氢气表面和体扩散影响的孵育和完全充电时间来分析活化性能。结果表明，由于TiCr_{2}$ 化合物的存在，Cr取代合金被快速激活，而含铝合金则立即吸收氢。相比之下，由于二次相数量较少和扩散通道有限，钴和铜替代合金需要延长活化时间。 et.al.|[2504.06990](http://arxiv.org/abs/2504.06990)|null|
|**2025-04-09**|**Exact Current Fluctuations in a Tight-Binding Chain with Dephasing Noise**|对于无限区间上具有退相噪声的紧束缚链，我们精确计算了平均密度为 $\rho_a$（负轴）和$\rh0_b$（正轴）的阶跃初始条件下积分电流的方差。我们的精确解表明，退相的存在，无论多么小，都会改变电流波动的性质，使其在长期极限内从弹道波动变为扩散波动。该推导依赖于积分电流的矩生成函数的无穷区间和非平凡参数依赖性（称为$\omega$ -依赖性）的Bethe ansatz。此外，我们证明了方差的渐近形式和数值获得的累积量生成函数与对称简单排除过程中的一致。 et.al.|[2504.06989](http://arxiv.org/abs/2504.06989)|null|
|**2025-04-09**|**PathSegDiff: Pathology Segmentation using Diffusion model representations**|图像分割在许多计算病理学管道中至关重要，包括准确的疾病诊断、亚型、结果和生存能力预测。训练分割模型的常用方法依赖于预训练的特征提取器和成对图像和掩模注释的数据集。这些用于训练轻量级预测模型，将特征转换为每像素类。特征提取器的选择是最终分割模型性能的核心，最近的文献主要关注寻找任务来预训练特征提取器。在这篇论文中，我们提出了PathSegDiff，这是一种用于组织病理学图像分割的新方法，它利用潜在扩散模型（LDMs）作为预训练的特征提取器。我们的方法利用由自我监督编码器引导的病理特异性LDM，从H&E染色的组织病理学图像中提取丰富的语义信息。我们使用一个简单的、完全卷积的网络来处理从LDM中提取的特征，并生成分割掩模。我们的实验表明，在BCSS和GlaS数据集上，与传统方法相比，我们有了显著的改进，突出了领域特异性扩散预训练在捕获复杂组织结构和提高组织病理学图像分割精度方面的有效性。 et.al.|[2504.06950](http://arxiv.org/abs/2504.06950)|null|
|**2025-04-09**|**Density Approximation of Affine Jump Diffusions via Closed-Form Moment Matching**|我们开发了一种递归方法，用于推导具有状态无关跳跃强度的仿射跳跃扩散的条件和无条件矩的闭式解。使用这些矩解，我们通过矩匹配为条件和无条件分布构建了闭式密度近似值（高达归一化常数）。我们的框架支持重要的金融应用，包括有效的期权定价和仿射跳跃扩散的精确模拟。数值实验表明，与现有的模拟技术相比，该方法具有更高的计算效率，同时保持了数值精度。 et.al.|[2504.06942](http://arxiv.org/abs/2504.06942)|null|
|**2025-04-09**|**MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs**|本文介绍了MedSegFactory，这是一个多功能的医学合成框架，可以跨模态和任务生成高质量的成对医学图像和分割掩模。它旨在作为一个无限的数据存储库，提供图像掩模对以增强现有的分割工具。MedSegFactory的核心是双流扩散模型，其中一个流合成医学图像，另一个流生成相应的分割掩模。为了确保图像掩模对之间的精确对齐，我们引入了联合交叉注意（JCA），通过流之间的动态交叉调节实现了协作去噪范式。这种双向交互允许两种表示相互指导生成，增强生成对之间的一致性。MedSegFactory通过用户定义的提示解锁按需生成配对的医学图像和分割掩模，这些提示指定了目标标签、成像方式、解剖区域和病理条件，从而促进了可扩展和高质量的数据生成。这种新的医学图像合成范式能够无缝集成到各种医学成像工作流程中，提高效率和准确性。大量实验表明，MedSegFactory生成的数据具有卓越的质量和可用性，在2D和3D分割任务中实现了具有竞争力或最先进的性能，同时解决了数据稀缺和监管限制的问题。 et.al.|[2504.06897](http://arxiv.org/abs/2504.06897)|null|

<p align=right>(<a href=#updated-on-20250410>back to top</a>)</p>

## NeRF

|Publish Date|Title|Abstract|PDF|Code|
|---|---|---|---|---|
|**2025-04-08**|**econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic Gaussians**|最近关于开放词汇神经场的工作的主要重点是从VLM中提取精确的语义特征，然后将它们有效地整合到多视图一致的3D神经场表示中。然而，大多数现有的工作都是在受信任的SAM上进行的，以规范图像级CLIP，而无需进一步细化。此外，一些现有的研究通过在与3DGS语义场融合之前对2D VLM的语义特征进行降维来提高效率，这不可避免地导致了多视图不一致。在这项工作中，我们提出了使用3DGS进行开放式词汇语义分割的econSG。我们的econSG由以下部分组成：1）置信区间引导正则化（CRR），它相互细化SAM和CLIP，以获得具有完整和精确边界的精确语义特征的两全其美。2） 一个低维上下文空间，通过融合反投影的多视图2D特征来增强3D多视图一致性，同时提高计算效率，然后直接对融合的3D特征进行降维，而不是分别对每个2D视图进行操作。与现有方法相比，我们的econSG在四个基准数据集上显示了最先进的性能。此外，我们也是所有方法中最有效的培训。 et.al.|[2504.06003](http://arxiv.org/abs/2504.06003)|null|
|**2025-04-08**|**Meta-Continual Learning of Neural Fields**|神经场（NF）作为一种用于复杂数据表示的通用框架，已经获得了突出地位。这项工作揭示了一个新的问题设置，称为“神经场元连续学习”（MCL-NF），并引入了一种新的策略，该策略采用模块化架构与基于优化的元学习相结合。我们的策略侧重于克服现有神经场连续学习方法的局限性，如灾难性遗忘和缓慢收敛，实现了高质量的重建，显著提高了学习速度。我们进一步引入了神经辐射场的Fisher信息最大化损失（FIM-NeRF），它在样本级别最大化信息增益以增强学习泛化，并证明了收敛保证和泛化界限。我们在六个不同的数据集上对图像、音频、视频重建和视图合成任务进行了广泛的评估，证明了我们的方法在重建质量和速度方面优于现有的MCL和CL-NF方法。值得注意的是，我们的方法在降低参数要求的情况下，实现了神经场对城市级NeRF渲染的快速适应。 et.al.|[2504.05806](http://arxiv.org/abs/2504.05806)|null|
|**2025-04-06**|**Dynamic Neural Field Modeling of Visual Contrast for Perceiving Incoherent Looming**|Amari的动态神经场（DNF）框架提供了一种受大脑启发的方法来模拟神经元群的平均激活。利用单一领域，DNF已成为机器人应用中低能耗隐约感知模块的有前景的基础。然而，之前的DNF方法在检测不连贯或不一致的迫在眉睫的特征方面面临着重大挑战，这些特征在现实世界场景中很常见，例如雨天的碰撞检测。果蝇和蝗虫视觉系统的见解表明，编码ON/OFF视觉对比在增强迫在眉睫的选择性方面起着至关重要的作用。此外，横向激发机制可能会改善织机敏感神经元对连贯和非连贯刺激的反应。这些共同为改进迫在眉睫的感知模型提供了宝贵的指导。基于这些生物学证据，我们通过结合on/OFF视觉对比度的建模来扩展之前的单场DNF框架，每个对比度都由一个专用的DNF控制。使用归一化高斯核对每个ON/OFF对比场内的横向激励进行公式化，并将其输出整合到求和字段中以生成碰撞警报。实验评估表明，所提出的模型有效地解决了非相干逼近检测的挑战，并且明显优于最先进的蝗虫启发模型。它在各种刺激下表现出了强大的性能，包括合成雨效应，突显了它在复杂、嘈杂的环境中，在视觉线索不一致的情况下，具有可靠的隐约感知的潜力。 et.al.|[2504.04551](http://arxiv.org/abs/2504.04551)|null|
|**2025-04-03**|**A Physics-Informed Meta-Learning Framework for the Continuous Solution of Parametric PDEs on Arbitrary Geometries**|在这项工作中，我们引入了隐式有限算子学习（iFOL），用于任意几何上偏微分方程（PDE）的连续和参数解。我们提出了一种基于物理信息的编解码器网络，以建立连续参数和解空间之间的映射。解码器通过利用以潜在或特征码为条件的隐式神经场网络来构建参数解场。实例特定代码是通过基于二阶元学习技术的PDE编码过程导出的。在训练和推理中，在PDE编码和解码过程中，物理信息损失函数被最小化。iFOL以能量或加权残差形式表示损失函数，并使用从标准数值PDE方法导出的离散残差对其进行评估。这种方法在训练和推理过程中都会导致离散残差的反向传播。iFOL具有几个关键特性：（1）其独特的损失公式消除了以前在PDE的条件神经场算子学习中使用的传统编码过程-解码流水线的需要；（2） 它不仅提供精确的参数和连续场，而且提供参数梯度的解，而不需要额外的损失项或灵敏度分析；（3） 它可以有效地捕捉溶液中的尖锐不连续性；（4）它消除了对几何和网格的约束，使其适用于任意几何和空间采样（零样本超分辨率能力）。我们批判性地评估了这些特征，并分析了网络在稳态和瞬态PDE中推广到看不见的样本的能力。所提出的方法的整体性能是有希望的，证明了它适用于计算力学中一系列具有挑战性的问题。 et.al.|[2504.02459](http://arxiv.org/abs/2504.02459)|null|
|**2025-04-01**|**Flow Matching on Lie Groups**|流匹配（FM）是一种最新的生成建模技术：我们的目标是学习如何从分布中采样{X}_1 $通过从某些分布中流动样本$\mathfrak{X}_0$很容易取样。关键技巧是，在$\mathfrak中对端点进行调节的同时，可以训练这个流场{X}_1$：给定终点，只需沿直线段移动到终点（Lipman等人，2022）。然而，直线段仅在欧几里德空间上定义良好。因此，Chen和Lipman（2023）将该方法推广到黎曼流形上的FM，用测地线或其谱近似代替线段。我们采取了另一种观点：我们通过用指数曲线代替线段来推广李群上的FM。这导致了许多矩阵李群的简单、内在和快速实现，因为所需的李群运算（积、逆、指数、对数）仅由相应的矩阵运算给出。然后，李群上的FM可用于生成建模，数据由特征集（在$\mathbb{R}^n$ 中）和姿势集（在某些李群中）组成，例如等变神经场的潜在码（Wessels等人，2025）。 et.al.|[2504.00494](http://arxiv.org/abs/2504.00494)|**[link](https://github.com/finnsherry/FlowMatching)**|
|**2025-03-29**|**NeuralGS: Bridging Neural Fields and 3D Gaussian Splatting for Compact 3D Representations**|3D高斯散点（3DGS）显示了卓越的质量和渲染速度，但有数百万的3D高斯分布和巨大的存储和传输成本。最近的3DGS压缩方法主要集中在压缩脚手架GS上，取得了令人印象深刻的性能，但增加了体素结构和复杂的编码和量化策略。在这篇论文中，我们的目标是开发一种简单而有效的方法，称为NeuralGS，它以另一种方式探索将原始3DGS压缩成紧凑的表示，而不需要体素结构和复杂的量化策略。我们的观察是，像NeRF这样的神经场可以用多层感知器（MLP）神经网络表示复杂的3D场景，只需要几兆字节。因此，NeuralGS有效地采用神经场表示来用MLP对3D高斯的属性进行编码，即使对于大规模场景，也只需要很小的存储空间。为了实现这一点，我们采用了一种聚类策略，并根据高斯的重要性得分作为拟合权重，为每个聚类用不同的微小MLP对高斯进行拟合。我们在多个数据集上进行实验，在不损害视觉质量的情况下实现了平均模型大小减少45倍。我们的方法在原始3DGS上的压缩性能与基于Scaffold GS的专用压缩方法相当，这表明了用神经场直接压缩原始3DGS的巨大潜力。 et.al.|[2503.23162](http://arxiv.org/abs/2503.23162)|null|
|**2025-03-27**|**Renormalization group analysis of noisy neural field**|大脑中的神经元在个体特性和与其他神经元的连接方面表现出极大的多样性。为了深入了解神经元多样性如何在大尺度上促进大脑动力学和功能，我们借鉴了复制方法的框架，该框架已成功应用于平衡统计力学中一大类具有淬灭噪声的问题。我们分析了Wilson Cowan模型的两个线性化版本，其随机系数在空间上是相关的。特别是：（A）神经元本身的性质是异质的，（B）它们的连接是各向异性的。在这两个模型中，淬火随机性的平均会产生额外的非线性。这些非线性在威尔逊重整化群的框架内进行了分析。我们发现，对于模型A，如果噪声的空间相关性随距离衰减，指数小于-2 $，则在大的空间尺度上，噪声的影响消失了。相比之下，对于模型B，只有当空间相关性以小于-1$ 的指数衰减时，噪声对神经元连接的影响才会消失。我们的计算还表明，在某些条件下，噪声的存在可能会在大尺度上产生类似行波的行为，尽管这一结果在微扰理论的高阶下是否仍然有效还有待观察。 et.al.|[2503.21605](http://arxiv.org/abs/2503.21605)|null|
|**2025-03-25**|**Thin-Shell-SfT: Fine-Grained Monocular Non-rigid 3D Surface Tracking with Neural Deformation Fields**|从单目RGB视频中重建高度可变形的表面（如布料）是一个具有挑战性的问题，没有任何解决方案可以提供一致和准确的细粒度表面细节恢复。为了解释环境的病态性，现有的方法使用具有统计、神经或物理先验的变形模型。它们还主要依赖于非自适应离散曲面表示（例如多边形网格），逐帧优化导致误差传播，并受到基于网格的可微渲染器梯度差的影响。因此，织物褶皱等精细表面细节往往无法以所需的精度恢复。针对这些局限性，我们提出了ThinShell SfT，这是一种用于非刚性3D跟踪的新方法，将表面表示为隐式和连续的时空神经场。我们采用基于基尔霍夫-洛夫模型的连续薄壳物理先验进行空间正则化，这与早期作品的离散化替代方案形成了鲜明对比。最后，我们利用3D高斯溅射将表面可微分地渲染到图像空间中，并根据合成原理分析优化变形。我们的薄壳SfT在定性和定量上都优于先前的工作，这要归功于我们的连续表面公式以及专门定制的模拟先验和表面诱导的3D高斯。请访问我们的项目页面https://4dqv.mpiinf.mpg.de/ThinShellSfT. et.al.|[2503.19976](http://arxiv.org/abs/2503.19976)|null|
|**2025-03-25**|**Decoupled Dynamics Framework with Neural Fields for 3D Spatio-temporal Prediction of Vehicle Collisions**|本研究提出了一种神经框架，通过独立建模全局刚体运动和局部结构变形来预测3D车辆碰撞动力学。与直接预测绝对位移的方法不同，这种方法明确地将车辆的整体平移和旋转与其结构变形分开。两个专门的网络构成了该框架的核心：一个基于四元数的刚性网络用于刚性运动，一个基于坐标的变形网络用于局部变形。通过独立处理根本不同的物理现象，所提出的架构实现了准确的预测，而不需要对每个组件进行单独的监督。该模型仅在10%的可用模拟数据上进行训练，其性能明显优于基线模型，包括单层感知器（MLP）和深度算子网络（DeepONet），预测误差降低了83%。广泛的验证表明，它对训练范围外的碰撞条件具有很强的泛化能力，即使在涉及极端速度和大冲击角度的严重冲击下，也能准确预测响应。此外，该框架成功地从低分辨率输入重建了高分辨率变形细节，而无需增加计算工作量。因此，所提出的方法为在复杂的碰撞场景中快速可靠地评估车辆安全提供了一种有效、计算高效的方法，大大减少了所需的模拟数据和时间，同时保持了预测的保真度。 et.al.|[2503.19712](http://arxiv.org/abs/2503.19712)|null|
|**2025-03-21**|**Towards Understanding the Benefits of Neural Network Parameterizations in Geophysical Inversions: A Study With Neural Fields**|在这项工作中，我们采用了神经场，它使用神经网络以测试时学习的方式将坐标映射到该坐标处的相应物理属性值。对于测试时学习方法，与需要使用训练数据集训练网络的传统方法相比，在反演过程中学习权重。首先展示了地震层析成像和直流电阻率反演中的合成示例结果。然后，我们对这两种情况下的神经网络权重的雅可比矩阵进行奇异值分解分析（SVD分析），以探索神经网络对恢复模型的影响。结果表明，测试时间学习方法可以消除恢复的地下物理性质模型中由测量和物理敏感性引起的不必要的伪影。因此，在某些情况下，与常规反演相比，NFs-Inv可以改善反演结果，例如恢复倾角或预测主要目标的边界。在SVD分析中，我们观察到左奇异向量中的相似模式，就像在计算机视觉中的生成任务中以监督方式训练的一些扩散模型中观察到的那样。这一观察结果提供了证据，表明神经网络结构中固有的隐式偏差在监督学习和测试时学习模型中很有用。这种隐式偏差有可能对地球物理反演中的模型恢复有用。 et.al.|[2503.17503](http://arxiv.org/abs/2503.17503)|null|

<p align=right>(<a href=#updated-on-20250410>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

