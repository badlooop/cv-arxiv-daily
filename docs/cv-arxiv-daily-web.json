{
    "Video Diffusion": {
        "2512.23258": "|**2025-12-29**|**Plug-and-Play Fidelity Optimization for Diffusion Transformer Acceleration via Cumulative Error Minimization**|尽管扩散变压器（DiT）已成为图像和视频生成的主要架构，但其迭代去噪过程导致推理缓慢，从而阻碍了更广泛的适用性和发展。基于缓存的方法实现了免训练加速，但会产生相当大的计算误差。现有的方法通常结合纠错策略，例如修剪或预测来减轻它。然而，它们的固定缓存策略无法适应去噪过程中复杂的误差变化，这限制了纠错的全部潜力。为了应对这一挑战，我们通过累积误差最小化为现有的纠错方法提出了一种新颖的保真度优化插件，名为 CEM。 CEM预定义了误差来表征模型对受时间步长和缓存间隔共同影响的加速的敏感性。在此先验的指导下，我们制定了一种具有累积误差近似的动态规划算法来进行策略优化，实现了缓存误差最小化，从而显着提高了生成保真度。 CEM 与模型无关，并且具有很强的泛化性，可适应任意加速预算。它可以无缝集成到现有的纠错框架和量化模型中，而不会引入任何额外的计算开销。对九个生成模型和跨三个任务的量化方法进行的大量实验表明，CEM 显着提高了现有加速模型的生成保真度，并且在 FLUX.1-dev、PixArt-$α$、StableDiffusion1.5 和 Hunyuan 上优于原始生成性能。该代码将公开。|[2512.23258](http://arxiv.org/abs/2512.23258)|null|\n",
        "2512.23222": "|**2025-12-29**|**Bridging Your Imagination with Audio-Video Generation via a Unified Director**|现有的人工智能驱动的视频创作系统通常将剧本起草和关键镜头设计视为两个互不相交的任务：前者依赖于大型语言模型，而后者依赖于图像生成模型。我们认为这两项任务应该统一在一个框架内，因为逻辑推理和想象力都是电影导演的基本素质。在这项工作中，我们提出了 UniMAGE，这是一种统一的导演模型，它将用户提示与结构良好的脚本联系起来，从而使非专家能够利用现有的音视频生成模型来制作长上下文、多镜头的电影。为了实现这一目标，我们采用了 Mixture-of-Transformers 架构来统一文本和图像生成。为了进一步增强叙事逻辑和关键帧一致性，我们引入了“先交错，然后解开”的训练范例。具体来说，我们首先执行交错概念学习，它利用交错的文本图像数据来促进模型对脚本的更深入理解和富有想象力的解释。然后，我们进行解开专家学习，将脚本编写与关键帧生成分离，从而在讲故事时实现更大的灵活性和创造力。大量实验表明，UniMAGE 在开源模型中实现了最先进的性能，生成逻辑连贯的视频脚本和视觉一致的关键帧图像。|[2512.23222](http://arxiv.org/abs/2512.23222)|null|\n",
        "2512.23042": "|**2025-12-28**|**3D sans 3D Scans: Scalable Pre-training from Video-Generated Point Clouds**|尽管 3D 自监督学习最近取得了进展，但收集大规模 3D 场景扫描仍然昂贵且劳动密集型。在这项工作中，我们研究是否可以从没有任何真实 3D 传感器录制的未标记视频中学习 3D 表示。我们提出了 Laplacian-Aware Multi-level 3D Clustering with Sinkhorn-Knopp (LAM3C)，这是一个自监督框架，可以从未标记视频中的视频生成的点云中学习。我们首先介绍 RoomTours，这是一个视频生成的点云数据集，通过从网络上收集房间漫游视频（例如房地产游览）并使用现成的前馈重建模型生成 49,219 个场景来构建。我们还提出了一种噪声正则化损失，通过强制局部几何平滑度并确保噪声点云下的特征稳定性来稳定表示学习。值得注意的是，在不使用任何真实 3D 扫描的情况下，LAM3C 在室内语义和实例分割方面实现了比以前的自监督方法更高的性能。这些结果表明，未标记的视频代表了 3D 自监督学习的丰富数据源。|[2512.23042](http://arxiv.org/abs/2512.23042)|null|\n",
        "2512.22854": "|**2025-12-28**|**ByteLoom: Weaving Geometry-Consistent Human-Object Interactions through Progressive Curriculum Learning**|人机交互（HOI）视频生成因其在数字人类、电子商务、广告和机器人模仿学习中的前景广阔的应用而受到越来越多的关注。然而，现有方法面临两个关键限制：（1）缺乏有效的机制将对象的多视图信息注入模型，导致跨视图一致性差；（2）严重依赖细粒度的手部网格注释来建模交互遮挡。为了应对这些挑战，我们引入了 ByteLoom，这是一种基于 Diffusion Transformer (DiT) 的框架，可使用简化的人体调节和 3D 对象输入生成具有几何一致的对象插图的逼真 HOI 视频。我们首先提出了一种 RCM 缓存机制，该机制利用相对坐标图（RCM）作为通用表示来保持对象的几何一致性，同时精确控制 6-DoF 对象变换。为了弥补 HOI 数据集的稀缺性并利用现有数据集，我们进一步设计了培训课程，以渐进的方式增强模型能力并放宽手网格的要求。大量的实验表明，我们的方法忠实地保留了人类身份和物体的多视图几何形状，同时保持平滑的运动和物体操纵。|[2512.22854](http://arxiv.org/abs/2512.22854)|null|\n",
        "2512.22688": "|**2025-12-27**|**Autoregressive Flow Matching for Motion Prediction**|人们在不同的背景下研究了运动预测，使用在窄分布上训练的模型并将其应用于人体运动预测和机器人技术的下游任务。与此同时，最近在缩放视频预测方面的努力已经展示了令人印象深刻的视觉真实感，但尽管规模巨大，但它们仍难以准确地建模复杂的运动。受视频生成规模的启发，我们开发了自回归流匹配（ARFM），这是一种对连续连续数据进行概率建模的新方法，并在不同的视频数据集上对其进行训练，以在长范围内生成未来的点轨迹位置。为了评估我们的模型，我们开发了评估运动预测模型预测人类和机器人运动能力的基准。我们的模型能够预测复杂的运动，并且我们证明，在预测的未来轨迹上调节机器人动作预测和人体运动预测可以显着提高下游任务性能。代码和模型可公开获取：https://github.com/Johnathan-Xie/arfm-motion-prediction。|[2512.22688](http://arxiv.org/abs/2512.22688)|null|\n",
        "2512.22626": "|**2025-12-27**|**Envision: Embodied Visual Planning via Goal-Imagery Video Diffusion**|具身视觉规划旨在通过想象场景如何朝着期望的目标演变并使用想象的轨迹来指导行动来实现操纵任务。视频扩散模型通过其图像到视频的生成能力，为这种视觉想象提供了有希望的基础。然而，现有的方法主要是前向预测，根据初始观察生成轨迹，没有明确的目标建模，因此常常导致空间漂移和目标错位。为了应对这些挑战，我们提出了 Envision，一个基于扩散的框架，可以为具体代理执行视觉规划。通过使用目标图像显式约束生成，我们的方法在整个生成的轨迹中强制执行物理合理性和目标一致性。具体来说，远景能源分两个阶段运营。首先，目标图像模型识别任务相关区域，在场景和指令之间执行区域感知交叉注意，并合成捕获期望结果的连贯目标图像。然后，基于第一帧和最后一帧条件视频扩散模型 (FL2V) 构建的环境目标视频模型在初始观察和目标图像之间进行插值，产生连接起始状态和目标状态的平滑且物理上合理的视频轨迹。对象操作和图像编辑基准测试表明，与基线相比，Envision 实现了卓越的目标对齐、空间一致性和对象保存。由此产生的视觉计划可以直接支持下游机器人规划和控制，为实体代理提供可靠的指导。|[2512.22626](http://arxiv.org/abs/2512.22626)|null|\n",
        "2512.22536": "|**2025-12-27**|**CoAgent: Collaborative Planning and Consistency Agent for Coherent Video Generation**|保持叙事连贯性和视觉一致性仍然是开放域视频生成的核心挑战。现有的文本到视频模型通常独立处理每个镜头，导致身份漂移、场景不一致和不稳定的时间结构。我们提出了 CoAgent，这是一种用于相干视频生成的协作闭环框架，它将该过程制定为计划-合成-验证管道。给定用户提示、风格参考和节奏约束，故事板规划器将输入分解为具有明确实体、空间关系和时间线索的结构化镜头级计划。全局上下文管理器维护实体级内存，以保持镜头之间的外观和身份一致性。然后，合成模块在视觉一致性控制器的指导下生成每个镜头，而验证器代理使用视觉语言推理评估中间结果，并在检测到不一致时触发选择性再生。最后，具有节奏意识的剪辑师会完善时间节奏和过渡，以匹配所需的叙事流程。大量实验表明，CoAgent 显着提高了长视频生成的连贯性、视觉一致性和叙事质量。|[2512.22536](http://arxiv.org/abs/2512.22536)|null|\n",
        "2512.23705": "|**2025-12-29**|**Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation**|透明物体对于感知系统来说仍然是出了名的困难：折射、反射和透射打破了立体、ToF 和纯粹辨别单眼深度背后的假设，导致空洞和暂时不稳定的估计。我们的主要观察结果是，现代视频扩散模型已经合成了令人信服的透明现象，这表明它们已经内化了光学规则。我们构建了 TransPhy3D，一个透明/反射场景的合成视频语料库：使用 Blender/Cycles 渲染的 11k 序列。场景由一组精心策划的类别丰富的静态资产和形状丰富的程序资产与玻璃/塑料/金属材料搭配而成。我们使用基于物理的光线追踪和 OptiX 去噪来渲染 RGB + 深度 + 法线。从大型视频扩散模型开始，我们通过轻量级 LoRA 适配器学习深度（和法线）的视频到视频转换器。在训练过程中，我们连接 DiT 主干中的 RGB 和（噪声）深度潜值，并在 TransPhy3D 和现有的逐帧合成数据集上进行联合训练，从而为任意长度的输入视频生成时间一致的预测。由此产生的模型 DKT 在涉及透明度的真实和合成视频基准上实现了零样本 SOTA：ClearPose、DREDS (CatKnown/CatNovel) 和 TransPhy3D-Test。它提高了强图像/视频基线的准确性和时间一致性，并且法线变体在 ClearPose 上设置了最佳视频法线估计结果。紧凑型 1.3B 版本的运行速度约为 0.17 秒/帧。 DKT 的深度集成到抓取堆栈中，提高了半透明、反射和漫射表面的成功率，优于之前的估计器。总之，这些结果支持了一个更广泛的主张：“扩散知道透明度。”生成视频先验可以有效且无标签地重新利用，形成强大的、时间连贯的感知，以应对现实世界的操纵。|[2512.23705](http://arxiv.org/abs/2512.23705)|null|\n",
        "2512.23576": "|**2025-12-29**|**LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation**|通过扩散生成实时视频对于构建通用多模式交互式人工智能系统至关重要。然而，通过扩散模型中的迭代过程对所有视频帧进行双向关注的同时去噪会阻碍实时交互。虽然现有的蒸馏方法可以使模型自回归并减少采样步骤来缓解这种情况，但它们主要关注文本到视频的生成，导致人机交互不自然且效率较低。本文的目标是在多模态环境（包括文本、图像和音频）下进行实时交互式视频传播，以弥补这一差距。鉴于观察到领先的策略蒸馏方法 Self Forcing 在多模式条件下遇到了挑战（闪烁、黑框和质量下降等视觉伪影），我们研究了一种改进的蒸馏方法，重点关注条件输入的质量以及策略优化的初始化和时间表。在包括 HDTF、AVSpeech 和 CelebV-HQ 在内的多模态条件（音频、图像和文本）头像视频生成基准上，我们的蒸馏模型与相似或更大尺寸的全步双向基线的视觉质量相匹配，推理成本和延迟降低了 20 倍。此外，我们将我们的模型与音频语言模型和长格式视频推理技术 Anchor-Heavy Identity Sinks 相结合，构建了 LiveTalk，一个实时多模式交互式化身系统。对我们策划的多轮交互基准的系统级评估表明，LiveTalk 在多轮视频一致性和内容质量方面优于最先进的模型（Sora2、Veo3），同时将响应延迟从 1 到 2 分钟缩短到实时生成，从而实现无缝的人机人工智能多模式交互。|[2512.23576](http://arxiv.org/abs/2512.23576)|null|\n",
        "2512.23421": "|**2025-12-29**|**DriveLaW:Unifying Planning and Video Generation in a Latent Driving World**|世界模型对于自动驾驶至关重要，因为它们可以了解场景如何随着时间的推移而演变，以解决现实世界的长尾挑战。然而，当前的方法将世界模型限制在有限的角色中：它们在表面上统一的架构中运行，而这些架构仍然将世界预测和运动规划保持为解耦的过程。为了弥补这一差距，我们提出了 DriveLaW，这是一种统一视频生成和运动规划的新颖范例。通过直接将视频生成器中的潜在表示注入规划器中，DriveLaW 确保了高保真未来生成与可靠轨迹规划之间的内在一致性。具体来说，DriveLaW 由两个核心组件组成：DriveLaW-Video，我们强大的世界模型，可通过富有表现力的潜在表示生成高保真度预测；DriveLaW-Act，一种扩散规划器，可从 DriveLaW-Video 的潜在特征生成一致且可靠的轨迹，这两个组件均通过三阶段渐进训练策略进行优化。我们统一范式的力量通过这两项任务的新的最先进的结果得到了证明。 DriveLaW 不仅显着提高了视频预测的性能，在 FID 中超越了最佳表现 33.3%，在 FVD 中超越了 1.8%，而且还在 NAVSIM 规划基准上创造了新记录。|[2512.23421](http://arxiv.org/abs/2512.23421)|null|\n",
        "2512.24724": "|**2025-12-31**|**FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation**|在这项工作中，我们表明模型容量的影响随时间步长的不同而变化：它对于早期和晚期阶段至关重要，但在中间阶段基本上可以忽略不计。因此，我们提出了 FlowBlending，一种阶段感知的多模型采样策略，分别在容量敏感阶段和中间阶段采用大模型和小模型。我们进一步引入简单的标准来选择阶段边界，并提供速度发散分析作为识别容量敏感区域的有效代理。在 LTX-Video (2B/13B) 和 WAN 2.1 (1.3B/14B) 中，FlowBlending 的推理速度提高了 1.65 倍，失败次数减少了 57.35%，同时保持了大型模型的视觉保真度、时间连贯性和语义对齐。 FlowBlending 还与现有的采样加速技术兼容，可实现高达 2 倍的额外加速。项目页面位于：https://jibin86.github.io/flowblending_project_page。|[2512.24724](http://arxiv.org/abs/2512.24724)|null|\n",
        "2512.24551": "|**2025-12-31**|**PhyGDPO: Physics-Aware Groupwise Direct Preference Optimization for Physically Consistent Text-to-Video Generation**|文本到视频（T2V）生成的最新进展已经实现了良好的视觉质量，但合成忠实遵循物理定律的视频仍然是一个开放的挑战。现有的主要基于图形或提示扩展的方法很难推广到简单的模拟环境之外或学习隐式物理推理。缺乏具有丰富物理相互作用和现象的训练数据也是一个问题。在本文中，我们首先介绍了一种物理增强视频数据构建管道 PhyAugPipe，它利用具有思维链推理的视觉语言模型 (VLM) 来收集大规模训练数据集 PhyVidGen-135K。然后，我们制定了一个有原则的物理感知分组直接偏好优化（PhyGDPO）框架，该框架建立在分组 Plackett-Luce 概率模型的基础上，以捕获超越成对比较的整体偏好。在 PhyGDPO 中，我们设计了一种物理引导奖励 (PGR) 方案，该方案嵌入基于 VLM 的物理奖励，以引导优化实现物理一致性。我们还提出了一种 LoRA-Switch Reference (LoRA-SR) 方案，该方案消除了内存繁重的参考重复，以实现高效训练。实验表明，我们的方法在 PhyGenBench 和 VideoPhy2 上显着优于最先进的开源方法。请查看我们的项目页面 https://caiyuanhao1998.github.io/project/PhyGDPO 以获取更多视频结果。我们的代码、模型和数据将发布在https://github.com/caiyuanhao1998/Open-PhyGDPO|[2512.24551](http://arxiv.org/abs/2512.24551)|null|\n",
        "2512.24271": "|**2025-12-30**|**Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation**|多模态大语言模型（MLLM）在视频理解方面取得了显着进展。然而，它们存在一个严重的弱点：过度依赖语言先验，这可能会导致视觉上的无根据的幻觉，特别是在处理违背常识的反事实视频时。这种限制源于文本和视频之间固有的数据不平衡，由于收集和注释反事实数据的成本高昂，因此很难解决。为了解决这个问题，我们引入了 DualityForge，这是一种新颖的反事实数据合成框架，它采用可控的、基于扩散的视频编辑将现实世界的视频转换为反事实场景。通过将结构化上下文信息嵌入到视频编辑和 QA 生成过程中，该框架会自动生成高质量的 QA 对以及原始编辑的视频对，以进行对比训练。基于此，我们构建了 DualityVidQA，一个旨在减少 MLLM 幻觉的大规模视频数据集。此外，为了充分利用配对数据的对比性质，我们提出了对偶归一化优势训练（DNA-Train），这是一种两阶段 SFT-RL 训练机制，其中 RL 阶段应用成对 $\\ell_1$ 优势归一化，从而实现更稳定、更高效的策略优化。 DualityVidQA-Test 的实验表明，我们的方法大大减少了反事实视频上的模型幻觉，比 Qwen2.5-VL-7B 基线相对提高了 24.0%。此外，我们的方法在幻觉和通用基准方面都取得了显着的进步，表明了强大的泛化能力。我们将开源我们的数据集和代码。|[2512.24271](http://arxiv.org/abs/2512.24271)|null|\n",
        "2512.24227": "|**2025-12-30**|**Mirage: One-Step Video Diffusion for Photorealistic and Coherent Asset Editing in Driving Scenes**|以视觉为中心的自动驾驶系统依靠多样化且可扩展的训练数据来实现稳健的性能。虽然视频对象编辑为数据增强提供了一条有前途的途径，但现有方法通常难以保持高视觉保真度和时间连贯性。在这项工作中，我们提出了 \\textbf{Mirage}，这是一种一步式视频扩散模型，用于驾驶场景中逼真且连贯的资产编辑。 Mirage 建立在文本到视频的扩散之上，以确保跨帧的时间一致性。然而，3D 因果变分自动编码器通常会因压缩而遭受空间保真度下降的影响，并且直接将 3D 编码器特征传递到解码器层会破坏时间因果关系。为了解决这个问题，我们将时间无关的潜在变量从预训练的 2D 编码器注入到 3D 解码器中，以恢复细节，同时保留因果结构。此外，由于场景对象和插入的资产在不同的目标下进行优化，因此它们的高斯表现出分布不匹配，从而导致姿势不对齐。为了缓解这个问题，我们引入了一种两阶段数据对齐策略，将粗略的 3D 对齐和精细的 2D 细化相结合，从而改善对齐并提供更清晰的监督。大量实验表明 Mirage 在不同的编辑场景中实现了高度的真实感和时间一致性。除了资产编辑之外，Mirage 还可以推广到其他视频到视频翻译任务，为未来研究提供可靠的基准。我们的代码可在 https://github.com/wm-research/mirage 获取。|[2512.24227](http://arxiv.org/abs/2512.24227)|null|\n",
        "2512.24086": "|**2025-12-30**|**RainFusion2.0: Temporal-Spatial Awareness and Hardware-Efficient Block-wise Sparse Attention**|在视频和图像生成任务中，扩散变压器（DiT）模型由于注意力机制而产生极高的计算成本，这限制了其实际应用。此外，随着硬件的进步，除图形处理单元（GPU）之外的各种设备，例如专用集成电路（ASIC），已越来越多地用于模型推理。稀疏注意力通过跳过对无关紧要标记的计算来利用注意力固有的稀疏性，是减轻计算成本的有效方法。然而，现有的稀疏注意力方法有两个关键限制：稀疏模式预测的开销和缺乏硬件通用性，因为这些方法大多数都是为 GPU 设计的。为了应对这些挑战，本研究提出了 RainFusion2.0，旨在开发一种在线自适应、硬件高效且低开销的稀疏注意力机制，以加速视频和图像生成模型，并在不同的硬件平台上具有强大的性能。关键技术见解包括：（1）利用逐块平均值作为稀疏掩模预测的代表标记； (2) 实现时空感知的令牌排列； (3)引入专门针对视频生成场景设计的首帧接收机制。实验结果表明，RainFusion2.0可以实现80%的稀疏度，同时在不影响视频质量的情况下实现1.5~1.8倍的端到端加速。此外，RainFusion2.0 展示了跨各种生成模型的有效性，并验证了其跨不同硬件平台的泛化能力。|[2512.24086](http://arxiv.org/abs/2512.24086)|null|\n",
        "2512.23994": "|**2025-12-30**|**PhyAVBench: A Challenging Audio Physics-Sensitivity Benchmark for Physically Grounded Text-to-Audio-Video Generation**|文本转音频视频 (T2AV) 生成支持需要逼真视听内容的广泛应用，包括虚拟现实、世界建模、游戏和电影制作。然而，现有的 T2AV 模型仍然无法产生物理上合理的声音，这主要是由于它们对物理原理的理解有限。为了定位当前的研究进展，我们推出了 PhyAVBench，这是一个具有挑战性的音频物理灵敏度基准测试，旨在系统地评估现有 T2AV 模型的音频物理接地能力。 PhyAVBench 包含 1,000 组配对文本提示以及受控物理变量，这些变量隐含地引起声音变化，从而能够对模型对基础声学条件变化的敏感度进行细粒度评估。我们将这种评估范式称为音频物理灵敏度测试（APST）。与之前主要关注音视频同步的基准测试不同，PhyAVBench 明确评估模型对声音生成物理机制的理解，涵盖 6 个主要音频物理维度、4 个日常场景（音乐、音效、语音及其混合）和 50 个细粒度测试点，范围从声音衍射等基本方面到亥姆霍兹共振等更复杂的现象。每个测试点由多组配对提示组成，其中每个提示都以至少 20 个新录制或收集的真实视频为基础，从而最大限度地降低模型预训练期间数据泄漏的风险。提示和视频都经过严格的人为纠错和质量控制迭代完善，以确保高质量。我们认为，只有真正掌握与音频相关的物理原理的模型才能生成物理上一致的视听内容。我们希望 PhyAVBench 能够促进这一关键但很大程度上尚未探索的领域的未来进展。|[2512.23994](http://arxiv.org/abs/2512.23994)|null|\n",
        "2512.23983": "|**2025-12-30**|**DriveExplorer: Images-Only Decoupled 4D Reconstruction with Progressive Restoration for Driving View Extrapolation**|本文提出了自动驾驶场景中视图外推的有效解决方案。最近的方法侧重于使用扩散模型从给定的视点生成移位的新颖视图图像。然而，这些方法严重依赖于 LiDAR 点云、3D 边界框和车道注释等先验知识，这些先验知识需要昂贵的传感器或劳动密集型标签，限制了在实际部署中的适用性。在这项工作中，仅使用图像和可选的相机姿势，我们首先估计全局静态点云和每帧动态点云，将它们融合成统一的表示。然后，我们采用可变形 4D 高斯框架来重建场景。最初训练的 4D 高斯模型渲染退化图像和伪图像来训练视频扩散模型。随后，通过扩散模型迭代地改进逐渐平移的高斯渲染，并将增强的结果合并回作为 4DGS 的训练数据。这个过程一直持续到外推达到目标视点为止。与基线相比，我们的方法在新颖的外推视点产生更高质量的图像。|[2512.23983](http://arxiv.org/abs/2512.23983)|null|\n",
        "2512.23953": "|**2025-12-30**|**T2VAttack: Adversarial Attack on Text-to-Video Diffusion Models**|文本到视频 (T2V) 扩散模型的快速发展推动了从自然语言描述生成高质量、时间连贯的视频方面的显着进步。尽管取得了这些成就，但它们面对对抗性攻击的脆弱性在很大程度上仍未得到探索。在本文中，我们介绍了 T2VAtack，这是一项从语义和时间角度对 T2V 扩散模型的对抗性攻击的综合研究。考虑到视频数据固有的动态性质，我们提出了两个不同的攻击目标：评估视频文本对齐的语义目标和评估时间动态的时间目标。为了实现有效且高效的攻击过程，我们提出了两种对抗性攻击方法：（i）T2VAtack-S，它识别提示中语义或时间上的关键单词，并通过贪婪搜索将其替换为同义词；（ii）T2VAtack-I，它以最小扰动迭代地插入优化单词到提示中。通过结合这些目标和策略，我们对几种最先进的 T2V 模型（包括 ModelScope、CogVideoX、Open-Sora 和 HunyuanVideo）的对抗鲁棒性进行了全面评估。我们的实验表明，即使是微小的即时修改，例如替换或插入单个单词，也可能导致语义保真度和时间动态的大幅下降，凸显了当前 T2V 扩散模型中的关键漏洞。|[2512.23953](http://arxiv.org/abs/2512.23953)|null|\n",
        "2512.25075": "|**2025-12-31**|**SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time**|我们提出了 SpaceTimePilot，这是一种视频扩散模型，可以解开空间和时间以实现可控的生成渲染。给定单目视频，SpaceTimePilot 可以在生成过程中独立改变摄像机视点和运动序列，重新渲染场景，以实现跨空间和时间的连续和任意探索。为了实现这一目标，我们在扩散过程中引入了一种有效的动画时间嵌入机制，允许对输出视频相对于源视频的运动序列进行显式控制。由于没有数据集提供具有连续时间变化的同一动态场景的配对视频，我们提出了一种简单而有效的时间扭曲训练方案，该方案重新利用现有的多视图数据集来模拟时间差异。该策略有效地监督模型学习时间控制并实现鲁棒的时空解缠结。为了进一步提高双重控制的精度，我们引入了两个额外的组件：改进的相机调节机制，允许从第一帧开始改变相机，以及CamxTime，第一个合成时空全覆盖渲染数据集，可在场景内提供完全自由的时空视频轨迹。对时间扭曲方案和 CamxTime 数据集的联合训练可以产生更精确的时间控制。我们在现实世界和合成数据上评估了 SpaceTimePilot，与之前的工作相比，展示了清晰的时空解离和强大的结果。项目页面：https://zheninghuang.github.io/Space-Time-Pilot/ 代码：https://github.com/ZheningHuang/spacetimepilot|[2512.25075](http://arxiv.org/abs/2512.25075)|null|\n",
        "2512.24952": "|**2025-12-31**|**VIPER: Process-aware Evaluation for Generative Video Reasoning**|视频生成领域的最新突破展示了一种称为帧链 (CoF) 推理的新兴功能，其中模型通过生成连续帧来解决复杂的任务。虽然这些模型显示出生成视频推理 (GVR) 的前景，但现有的评估框架通常依赖于单帧评估，这可能会导致结果黑客攻击，即模型通过错误的过程得出正确的结论。为了解决这个问题，我们提出了一种流程感知的评估范式。我们推出了 VIPER，这是一个涵盖时间、结构、符号、空间、物理和规划推理等 16 项任务的综合基准测试。此外，我们提出了过程结果一致性（POC@r），这是一种新的指标，利用带有分层标题的 VLM-as-Judge 来评估中间步骤和最终结果的有效性。我们的实验表明，最先进的视频模型仅实现了约 20% POC@1.0，并且表现出显着的结果黑客攻击。我们进一步探讨了测试时间缩放和采样鲁棒性的影响，强调了当前视频生成和真正的广义视觉推理之间的巨大差距。我们的基准将公开发布。|[2512.24952](http://arxiv.org/abs/2512.24952)|null|\n",
        "2512.24766": "|**2025-12-31**|**Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow**|生成视频建模已成为一种引人注目的工具，可以对开放世界操纵的合理物理交互进行零镜头推理。然而，将这种人类主导的运动转化为机器人系统所需的低级动作仍然是一个挑战。我们观察到，在给定初始图像和任务指令的情况下，这些模型擅长合成合理的物体运动。因此，我们引入了 Dream2Flow，这是一个通过 3D 对象流作为中间表示来桥接视频生成和机器人控制的框架。我们的方法从生成的视频中重建 3D 对象运动，并将操作制定为对象轨迹跟踪。通过将状态变化与实现这些变化的执行器分离，Dream2Flow 克服了实施例差距，并实现了预训练视频模型的零镜头引导，以操纵不同类别的对象，包括刚性、铰接式、可变形和粒状。通过轨迹优化或强化学习，Dream2Flow 将重建的 3D 对象流转换为可执行的低级命令，而无需特定于任务的演示。仿真和现实世界实验强调 3D 对象流作为通用且可扩展的接口，用于使视频生成模型适应开放世界的机器人操作。视频和可视化可在 https://dream2flow.github.io/ 上获取。|[2512.24766](http://arxiv.org/abs/2512.24766)|null|\n"
    },
    "3D": {
        "2512.23333": "|**2025-12-29**|**CME-CAD: Heterogeneous Collaborative Multi-Expert Reinforcement Learning for CAD Code Generation**|计算机辅助设计 (CAD) 在工业设计中至关重要，但传统 CAD 建模和工作流程的复杂性对自动生成高精度、可编辑 CAD 模型提出了重大挑战。现有的从草图重建 3D 模型的方法通常会产生不可编辑的近似模型，无法满足工业设计中对精度和可编辑性的严格要求。此外，对文本或基于图像的输入的依赖通常需要大量的手动注释，限制了它们在工业环境中的可扩展性和适用性。为了克服这些挑战，我们提出了异构协作多专家强化学习 (CME-CAD) 范式，这是一种用于 CAD 代码生成的新型训练范式。我们的方法集成了这些模型的互补优势，促进协作学习并提高模型生成准确、约束兼容且完全可编辑的 CAD 模型的能力。我们引入了一个两阶段的训练过程：多专家微调（MEFT）和多专家强化学习（MERL）。此外，我们还推出了 CADExpert，这是一个由 17,299 个实例组成的开源基准测试，包括具有精确尺寸注释的正交投影、专家生成的思想链 (CoT) 流程、可执行 CADQuery 代码和渲染的 3D 模型。|[2512.23333](http://arxiv.org/abs/2512.23333)|null|\n",
        "2512.23317": "|**2025-12-29**|**Essential Convergence Rates of Continuous-Time Models for Optimization Methods**|通过表示为常微分方程 (ODE) 的连续时间模型来设计和分析优化方法，因其直观性和简单性而成为一种很有前途的方法。然而，一个关键问题是此类模型的收敛速度可以通过时间重新缩放任意修改，从而使得寻求“快速”收敛的 ODE 的任务变得毫无意义。为了消除速率的模糊性，我们引入了基本收敛速率的概念。我们通过证明在适当的离散化假设下，通过离散 ODE 获得的任何方法都无法实现比其基本收敛速度更快的速度来证明这一概念。|[2512.23317](http://arxiv.org/abs/2512.23317)|null|\n",
        "2512.23284": "|**2025-12-29**|**Revealing design archetypes and flexibility in e-molecule import pathways using Modeling to Generate Alternatives and interpretable machine learning**|鉴于绿色电子分子进口在欧洲能源转型中的核心作用，许多研究优化了进口途径并确定了单一成本最优的解决方案。然而，成本优化是脆弱的，因为现实世界的实施取决于监管、空间和利益相关者的约束，这些约束很难在优化模型中表示，并且可能导致成本优化设计不可行。为了解决这一限制，我们使用建模生成替代方案，在可接受的成本边际内生成一组接近成本最优的替代方案，并考虑到未建模的不确定性。然后应用可解释的机器学习从生成的解决方案空间中提取见解。该方法适用于以氢、氨、甲烷和甲醇为载体的氢进口途径。结果揭示了一个广阔的接近最优的空间，具有很大的灵活性：太阳能、风能和存储并不严格要求保持在最佳成本的 10% 以内。风能限制有利于太阳能储存甲醇途径，而有限的储存有利于基于风能的氨或甲烷途径。|[2512.23284](http://arxiv.org/abs/2512.23284)|null|\n",
        "2512.23255": "|**2025-12-29**|**Contour Information Aware 2D Gaussian Splatting for Image Representation**|图像表示是计算机视觉中的一项基本任务。最近，Gaussian Splatting 已成为一种高效的表示框架，其对 2D 图像表示的扩展可以实现轻量级且富有表现力的视觉内容建模。虽然最近的 2D 高斯分布 (2DGS) 方法提供紧凑的存储和实时解码，但由于缺乏轮廓感知，当高斯数量较少时，它们经常会产生模糊或不清晰的边界。在这项工作中，我们提出了一种轮廓信息感知的 2D 高斯分布框架，它将对象分割先验纳入基于高斯的图像表示中。通过在光栅化过程中将每个高斯约束到特定的分割区域，我们的方法可以防止跨边界混合并在高压缩下保留边缘结构。我们还引入了热身方案来稳定训练并提高收敛性。对合成颜色图表和 DAVIS 数据集的实验表明，与现有的 2DGS 方法相比，我们的方法在对象边缘周围实现了更高的重建质量。在高斯很少的场景中，这种改进尤其明显，而我们的方法仍然保持快速渲染和低内存使用。|[2512.23255](http://arxiv.org/abs/2512.23255)|null|\n",
        "2512.23238": "|**2025-12-29**|**Frenet Immersed Finite Element Spaces on Triangular Meshes**|在本文中，我们针对椭圆界面问题开发了三角形网格上符合几何形状的浸入式有限元（GC-IFE）空间。这些 IFE 空间是通过 Frenet-Serret 映射构建的，该映射将界面曲线转换为直线，从而允许精确施加界面跳跃条件。将[7,8]的框架从矩形网格扩展到三角形网格，我们引入了构建高阶 Frenet-IFE 空间的三种过程：基于单项式基的初始构造、使用正交多项式的广义构造以及旨在改进相关质量矩阵的条件的重建方法。通过数值例子证明了所提出的 IFE 空间的最佳逼近能力。我们进一步将这些空间合并到椭圆界面问题的内部惩罚不连续伽辽金方法中，并观察 $H^1$ 和 $L^2$ 范数中的最佳收敛率。|[2512.23238](http://arxiv.org/abs/2512.23238)|null|\n",
        "2512.23223": "|**2025-12-29**|**The five-vertex model as a discrete log-gas**|我们考虑方形晶格的矩形域上的五顶点模型，具有所谓的“标量积”边界条件。我们解决了在缩放极限下模型自由能密度的评估，即当站点数量被发送到无穷大并且晶格网格为零时，同时保持域的大小恒定。为此，我们根据离散对数气体重新制定模型的配分函数，并研究其在热力学极限下的行为。我们重现了之前通过微分方程方法获得的结果。此外，我们提供了所有可能的方案中解决方案的明确形式。这项工作是进一步研究模型中极限形状现象的初步工作。|[2512.23223](http://arxiv.org/abs/2512.23223)|null|\n",
        "2512.23192": "|**2025-12-29**|**PGOT: A Physics-Geometry Operator Transformer for Complex PDEs**|虽然 Transformers 在偏微分方程 (PDE) 建模方面表现出了巨大的潜力，但对具有复杂几何形状的大规模非结构化网格进行建模仍然是一项重大挑战。现有的高效架构通常采用特征降维策略，这会无意中引起几何混叠，导致关键物理边界信息的丢失。为了解决这个问题，我们提出了物理-几何运算符变换器（PGOT），旨在通过显式几何感知重建物理特征学习。具体来说，我们提出了频谱保留几何注意力（SpecGeo-Attention）。利用“物理切片几何注入”机制，该模块结合了多尺度几何编码，显式保留多尺度几何特征，同时保持线性计算复杂度$O(N)$。此外，PGOT 基于空间坐标将计算动态路由到平滑区域的低阶线性路径和冲击波和不连续性的高阶非线性路径，从而实现空间自适应和高精度物理场建模。PGOT 在四个标准中实现了一致的最先进性能在包括机翼和汽车设计在内的大型工业任务中树立标杆并表现出色。|[2512.23192](http://arxiv.org/abs/2512.23192)|null|\n",
        "2512.23182": "|**2025-12-29**|**A Two-Stage Finite Element Approach for High-precision Guaranteed Lower Eigenvalue Bounds**|尽管标准高阶一致有限元 (FEM) 很容易产生极其尖锐的上限，但获得高精度保证的特征值下界仍然很困难。最近开发的严格方法（例如 Crouzeix-Raviart 或线性顺应元素）不能很好地扩展到高阶 FEM。一些非标准 FEM 方法可以提供尖锐的特征值界限，但在技术上有所涉及。通过标准高阶符合 FEM 实现的准确上限和同样尖锐的严格下限之间持续存在的差距使得该问题在技术上要求很高且竞争激烈。在本文中，我们提出了一种新的两阶段严格算法，通过在分级网格上采用高阶有限元并产生与相应高阶上限一样尖锐的严格下特征值界来缩小这一差距，如我们的数值示例所示。方形域和哑铃域上的拉普拉斯和 Steklov 特征值问题的数值实验表明了该方法的准确性和效率，特别是在分级或高度不均匀的网格上。这些结果证实，所提出的方法为获取尖锐、可靠的下特征值界的长期困难提供了实用且有竞争力的解决方案。|[2512.23182](http://arxiv.org/abs/2512.23182)|null|\n",
        "2512.23176": "|**2025-12-29**|**GVSynergy-Det: Synergistic Gaussian-Voxel Representations for Multi-View 3D Object Detection**|基于图像的 3D 对象检测旨在仅使用 RGB 图像来识别和定位 3D 空间中的对象，从而无需基于点云的方法所需的昂贵的深度传感器。现有的基于图像的方法面临两个关键挑战：实现高精度的方法通常需要密集的 3D 监督，而那些没有这种监督的方法很难仅从图像中提取准确的几何形状。在本文中，我们提出了 GVSynergy-Det，这是一种通过协同高斯体素表示学习增强 3D 检测的新颖框架。我们的主要见解是，连续高斯和离散体素表示捕获互补的几何信息：高斯擅长建模细粒度的表面细节，而体素提供结构化的空间上下文。我们引入了一种双表示架构：1）采用可推广的高斯分布来提取检测任务的互补几何特征，2）开发一种交叉表示增强机制，利用高斯场的几何细节丰富体素特征。与以前依赖耗时的每个场景优化或仅利用高斯表示进行深度正则化的方法不同，我们的协同策略通过可学习的集成直接利用两种表示的特征，从而实现更准确的对象定位。大量实验表明，GVSynergy-Det 在具有挑战性的室内基准测试中取得了最先进的结果，在 ScanNetV2 和 ARKitScenes 数据集上的性能显着优于现有方法，所有这些都不需要任何深度或密集的 3D 几何监督（例如点云或 TSDF）。|[2512.23176](http://arxiv.org/abs/2512.23176)|null|\n",
        "2512.23147": "|**2025-12-29**|**GeoTeacher: Geometry-Guided Semi-Supervised 3D Object Detection**|半监督 3D 物体检测旨在探索未标记数据以增强 3D 物体检测器，近年来已成为一个活跃的研究领域。以前的一些方法通过采用异构教师模型来提供高质量的伪标签或强制教师和学生网络之间的特征视角一致性，已经显示出显着的改进。然而，这些方法忽视了这样一个事实，即模型通常对标记数据有限的物体几何表现出较低的敏感性，从而难以捕获几何信息，而这对于增强学生模型的物体感知和定位能力至关重要。在本文中，我们提出 GeoTeacher 来增强学生模型在有限训练数据（尤其是未标记数据）的情况下捕获对象几何关系的能力。我们设计了一个基于关键点的几何关系监督模块，将教师模型的物体几何知识传递给学生，从而提高学生理解几何关系的能力。此外，我们引入了体素数据增强策略，该策略增加了对象几何形状的多样性，从而进一步提高了学生模型理解几何结构的能力。为了在增强过程中保持远处物体的完整性，我们将距离衰减机制纳入该策略中。此外，GeoTeacher可以与不同的SS3D方法相结合，进一步提高其性能。对 ONCE 和 Waymo 数据集的广泛实验表明了我们方法的有效性和泛化性，并且我们取得了新的最先进的结果。代码可在 https://github.com/SII-Whaleice/GeoTeacher 获取|[2512.23147](http://arxiv.org/abs/2512.23147)|null|\n",
        "2512.23705": "|**2025-12-29**|**Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation**|透明物体对于感知系统来说仍然是出了名的困难：折射、反射和透射打破了立体、ToF 和纯粹辨别单眼深度背后的假设，导致空洞和暂时不稳定的估计。我们的主要观察结果是，现代视频扩散模型已经合成了令人信服的透明现象，这表明它们已经内化了光学规则。我们构建了 TransPhy3D，一个透明/反射场景的合成视频语料库：使用 Blender/Cycles 渲染的 11k 序列。场景由一组精心策划的类别丰富的静态资产和形状丰富的程序资产与玻璃/塑料/金属材料搭配而成。我们使用基于物理的光线追踪和 OptiX 去噪来渲染 RGB + 深度 + 法线。从大型视频扩散模型开始，我们通过轻量级 LoRA 适配器学习深度（和法线）的视频到视频转换器。在训练过程中，我们连接 DiT 主干中的 RGB 和（噪声）深度潜值，并在 TransPhy3D 和现有的逐帧合成数据集上进行联合训练，从而为任意长度的输入视频生成时间一致的预测。由此产生的模型 DKT 在涉及透明度的真实和合成视频基准上实现了零样本 SOTA：ClearPose、DREDS (CatKnown/CatNovel) 和 TransPhy3D-Test。它提高了强图像/视频基线的准确性和时间一致性，并且法线变体在 ClearPose 上设置了最佳视频法线估计结果。紧凑型 1.3B 版本的运行速度约为 0.17 秒/帧。 DKT 的深度集成到抓取堆栈中，提高了半透明、反射和漫射表面的成功率，优于之前的估计器。总之，这些结果支持了一个更广泛的主张：“扩散知道透明度。”生成视频先验可以有效且无标签地重新利用，形成强大的、时间连贯的感知，以应对现实世界的操纵。|[2512.23705](http://arxiv.org/abs/2512.23705)|null|\n",
        "2512.23696": "|**2025-12-29**|**OpenPBR: Novel Features and Implementation Details**|OpenPBR 是一种基于物理的标准化超级着色器，专为跨 VFX、动画和设计可视化工作流程的可互操作材质创作和渲染而开发。本文档作为官方规范的配套文件，提供对模型开发的更深入了解和更详细的实施指南，包括代码示例和数学推导。   我们首先描述模型的形式结构和理论基础——涵盖基于平板的分层、统计混合和微面理论——然后再转向其物理组件。这些包括金属、介电、次表面和光泽漫射基底，然后是薄膜虹彩层、涂层和绒毛层。还描述了渲染薄壁物体的特殊情况模式。   其他部分更深入地探讨了技术主题，例如镜面反射率与透射率的解耦、次表面散射参数化的选择以及涂层变暗和薄膜干涉的详细物理原理。我们还讨论了计划中的扩展，包括模糊镜面反射和逆向反射。|[2512.23696](http://arxiv.org/abs/2512.23696)|null|\n",
        "2512.23654": "|**2025-12-29**|**Scattering Amplitudes and Conservative Binary Dynamics at $O(G^5)$ without Self-Force Truncation**|我们计算了广义相对论中两个非旋转体的保守径向作用和散射角的完整势引力子贡献，精确到牛顿常数的五阶，包括二阶自力 (2SF) 效应。计算在散射幅度框架下进行，结合了双拷贝、有效场论以及基于分部积分和微分方程的多环积分技术。为了解决主要的计算瓶颈，我们开发了改进的分部分积分算法，使该顺序的计算变得易于处理。振幅以级数展开的形式呈现，遵循先前在最大超重力中使用的策略。对于仅涉及多对数函数的第一个自力扇区，我们还提供了封闭式解析表达式。对于第二个自力部分，与早期的超重力工作一样，我们发现与卡拉比-丘几何支持的积分相关的贡献之间存在不平凡的抵消。|[2512.23654](http://arxiv.org/abs/2512.23654)|null|\n",
        "2512.23648": "|**2025-12-29**|**A High-Order Spectral Element Solver for Steady-State Free Surface Flows**|我们提出了一个适用于自由表面的稳定不可压缩纳维-斯托克斯方程的谱元求解器。利用自由表面边界的运动学行为，提出了迭代伪时间程序来确定先验未知的自由表面轮廓。数值模型在开源有限元框架 Firedrake 中实现，该框架能够通过弱公式在非结构化网格上使用高阶多项式基础。此外，自由表面和水下体的曲率是通过超限线性混合获得的曲线元素结合起来的，这保留了整体方案的高阶收敛特性。该模型应用于两个空间维度的多个基准案例。最初，它解决固定域问题，包括盖驱动的空腔流动和围绕圆柱体和 NACA 翼型等物体的流动。随后，在存在自由表面的情况下，将其扩展以确定测深凸起和浸没的 NACA 翼型周围的流动。结果通过收敛研究证实了模型的高阶精度，并证明了相对于低阶数值方案的显着加速。|[2512.23648](http://arxiv.org/abs/2512.23648)|null|\n",
        "2512.23635": "|**2025-12-29**|**Rethinking the Spatio-Temporal Alignment of End-to-End 3D Perception**|时空对齐对于自动驾驶 (AD) 中端到端 (E2E) 感知的时间建模至关重要，可提供有价值的结构和纹理先验信息。现有方法通常依赖于注意力机制来跨帧对齐对象，通过统一的显式物理模型（恒定速度等）简化运动模型。这些方法更喜欢隐式对齐的语义特征，挑战了传统感知范式中显式运动建模的重要性。然而，跨类别和帧的运动状态和对象特征的变化使得这种对齐不是最佳的。为了解决这个问题，我们提出了 HAT，一种时空对齐模块，它允许每个对象在没有直接监督的情况下从多个假设中自适应地解码最佳对齐建议。具体来说，HAT 首先利用多个显式运动模型来生成历史实例的空间锚点和运动感知特征建议。然后，它通过合并嵌入在缓存对象查询中的语义和运动线索来执行多假设解码，最终为目标帧提供最佳对齐建议。在 nuScenes 上，HAT 持续改进跨不同基线的 3D 时间检测器和跟踪器。与 DETR3D 检测器配对时，它在测试集上实现了最先进的跟踪结果，AMOTA 为 46.0%。在以对象为中心的E2E AD方法中，HAT提高了感知精度（+1.3% mAP，+3.1% AMOTA），并将碰撞率降低了32%。当语义被破坏时（nuScenes-C），HAT 增强的运动建模可以在 E2E AD 中实现更稳健的感知和规划。|[2512.23635](http://arxiv.org/abs/2512.23635)|null|\n",
        "2512.23621": "|**2025-12-29**|**Learning Lévy density via adaptive RKHS regression with bi-level optimization**|我们提出了一种非参数方法，从由非局部 Fokker-Planck 方程控制的概率密度数据中学习 Lévy 密度。我们将问题重新定义为从离散数据中识别非局部积分算子中的核，这会导致不适定的逆问题。为了对其进行正则化，我们构建了一个自适应再现内核希尔伯特空间（RKHS），其内核直接根据数据构建。在标准源和光谱衰减条件下，我们表明网格尺寸的重建误差以接近最佳的速率衰减。重要的是，我们开发了一种基于广义奇异值分解（GSVD）的双层优化算法来选择正则化参数，从而实现正则化估计器的高效且鲁棒的计算。对几种 Lévy 密度、漂移场和数据类型（基于 PDE 的密度和基于样本集合的 KDE 重建）的数值实验表明，我们的双层 RKHS 方法优于经典的 L 曲线和广义交叉验证策略，并且自适应 RKHS 范数比基于 $L^2_ρ$ 和 $\\ell^2$ 的正则化更准确和鲁棒。|[2512.23621](http://arxiv.org/abs/2512.23621)|null|\n",
        "2512.23513": "|**2025-12-29**|**Incorporating Tissue Composition Information in Total-Body PET Metabolic Quantification of Bone Marrow through Dual-Energy CT**|使用 18F-氟脱氧葡萄糖 (FDG) 正电子发射断层扫描 (PET) 进行骨髓 (BM) 代谢定量对于分期和随访时准确评估 BM 具有广泛的临床意义，特别是在涉及免疫治疗时。然而，目前量化 BM 的方法可能不准确，因为用于测量骨髓的体积也可能由一小部分骨小梁组成，其中 18F-FDG 活性可以忽略不计，从而可能低估真正的 BM 摄取。在这项研究中，我们证明了这种骨主导的组织成分效应，并提出了一种使用 X 射线双能计算机断层扫描 (DECT) 材料分解的骨分数校正 (BFC) 方法。这项研究包括 5 名癌症患者的 10 次扫描，这些患者使用 uEXPLORER 全身 PET/CT 系统进行了基线和后续动态 18F-FDG PET 和 DECT 扫描。通过 DECT 估算体素骨体积分数，然后将其纳入 BFC 的 PET 测量公式中。在使用和不使用 BFC 的情况下估计 BM 区域的标准化摄取值 (SUV)、18F-FDG 输送率 K1 和净流入率 Ki 值，并使用统计分析进行比较。结果首先证明了使用 DECT 进行代谢 BM 成像进行体素材料分解的可行性。使用 BFC 后，BM 区域的 SUV、K1 和 Ki 值比不使用 BFC 的区域显着增加，平均增加了 13.28%（均 P<0.0001），表明 BFC 对 BM 量化的影响。 BFC 参数成像进一步证实了区域分析。我们使用 DECT 进行的研究表明，由于存在显着的骨体积分数，PET 中当前的 SUV 和 BM 动力学量化可能被低估。通过 BFC 纳入组织成分信息可以改善 BM 代谢量化。|[2512.23513](http://arxiv.org/abs/2512.23513)|null|\n",
        "2512.23437": "|**2025-12-29**|**RealX3D: A Physically-Degraded 3D Benchmark for Multi-view Visual Restoration and Reconstruction**|我们推出 RealX3D，这是一种在不同物理退化下进行多视图视觉恢复和 3D 重建的真实捕获基准。 RealX3D 将损坏分为四个系列，包括照明、散射、遮挡和模糊，并使用统一的采集协议以多个严重级别捕获每个系列，从而生成像素对齐的 LQ/GT 视图。每个场景都包含高分辨率捕获、原始图像和密集激光扫描，我们从中得出世界范围的网格和公制深度。对各种基于优化和前馈方法的基准测试表明，物理损坏下重建质量大幅下降，凸显了当前多视图管道在现实世界充满挑战的环境中的脆弱性。|[2512.23437](http://arxiv.org/abs/2512.23437)|null|\n",
        "2512.23396": "|**2025-12-29**|**PINNs for Electromagnetic Wave Propagation**|物理信息神经网络 (PINN) 是一种旨在通过将偏微分方程约束直接嵌入到神经网络训练过程中来求解物理系统的方法。在电磁学领域，FDTD 和 FEM 等成熟的方法已经存在，新的方法有望提供明显的优势而被接受。尽管 PINN 具有无网格特性并且适用于反演问题，但与 FDTD 解决方案相比，PINN 在精度和能量指标方面仍存在缺陷。这项研究表明，混合训练策略可以使 PINN 更接近 FDTD 级别的精度和能量一致性。   这项研究提出了一种混合方法，解决波传播场景中的常见挑战。时间相关 PINN 训练中的因果关系崩溃问题通过时间推进和因果关系感知加权来解决。为了减轻时间推进引入的不连续性，应用了两阶段界面连续性损失。为了抑制损耗累积（表现为电磁波中的累积能量漂移），开发了一种基于局部坡印廷的正则化器。   在开发的 PINN 模型中，随着时间的推移，平均误差为 0.09\\% $NRMSE$ 和 1.01\\% $L^2$，从而实现了高场精度。 PINN 侧实现了节能，在 2D PEC 腔场景中相对能量失配仅为 0.024%。训练是在没有标记的现场数据的情况下进行的，仅使用基于物理的残余损失； FDTD 仅用于训练后评估。结果表明，PINN 可以在典型电磁示例中实现与 FDTD 竞争的结果，并且是一种可行的替代方案。|[2512.23396](http://arxiv.org/abs/2512.23396)|null|\n",
        "2512.23340": "|**2025-12-29**|**The Law of Multi-Model Collaboration: Scaling Limits of Model Ensembling for Large Language Models**|大型语言模型 (LLM) 的最新进展很大程度上是由单个模型的缩放定律驱动的，该定律预测随着模型参数和数据量的增加，性能会提高。然而，任何单一法学硕士的能力本质上都是有限的。一种解决方案源于多个法学硕士之间复杂的相互作用，使它们的集体表现超越任何组成模型的表现。尽管模型路由和事后集成等多模型集成技术迅速普及，但仍然缺乏用于多模型协作的性能扩展的统一理论框架。在这项工作中，我们提出了多模型协作定律，这是一种基于聚合参数预算预测 LLM 集成的性能限制的缩放定律。为了量化多模型协作的内在上限，我们采用与方法无关的公式，并假设一个理想化的集成预言机，其中每个样本的总交叉熵损失由模型池中任何模型的最小损失确定。实验结果表明，多模型系统在总参数数量方面遵循幂律缩放，​​与单模型缩放相比，表现出更显着的改进趋势和更低的理论损失底线。此外，异构模型系列的集合比单个模型系列中形成的集合实现了更好的性能扩展，这表明模型多样性是协作收益的主要驱动力。这些发现表明，模型协作是扩展法学硕士智力前沿的关键轴。|[2512.23340](http://arxiv.org/abs/2512.23340)|null|\n",
        "2512.24742": "|**2025-12-31**|**Splatwizard: A Benchmark Toolkit for 3D Gaussian Splatting Compression**|最近出现的 3D 高斯分布 (3DGS) 标志着实时新颖视图合成的重大突破。然而，基于 3DGS 的算法的快速普及迫切需要标准化和综合的评估工具，尤其是压缩任务。现有的基准测试通常缺乏全面评估不同方法的独特特征所需的具体指标，例如渲染速度、率失真权衡、内存效率和几何精度。为了弥补这一差距，我们推出了 Splatwizard，这是一个专门为 3DGS 压缩模型进行基准测试而设计的统一基准测试工具包。 Splatwizard 提供了一个易于使用的框架来实现新的 3DGS 压缩模型并利用先前工作提出的最先进的技术。此外，框架中还包含一个集成管道，可自动计算关键性能指标，包括基于图像的质量指标、重建网格的倒角距离、渲染帧速率和计算资源消耗。代码可在 https://github.com/splatwizard/splatwizard 获取|[2512.24742](http://arxiv.org/abs/2512.24742)|null|\n",
        "2512.24647": "|**2025-12-31**|**Solving the inverse Source Problems for wave equation with final time measurements by a data driven approach**|本文开发了一种离散数据驱动的方法，用于通过最终时间测量来解决波动方程的逆源问题。重点关注 $L^2$-Tikhonov 正则化方法，我们使用噪声离散空间观测来分析其在两种不同噪声模型下的收敛性。通过利用前向算子的谱分解并将噪声分离技术引入变分框架，我们为重构解 $u$ 和源项 $f$ 建立了误差界限，而不需要经典源条件。此外，源误差的预期收敛速度是在较弱的拓扑中导出的。我们还将分析扩展到具有有限元离散化的完全离散情况，表明总体误差仅取决于噪声水平、正则化参数、时间步长和空间网格大小。这些估计为在没有先验信息的情况下以数据驱动的方式选择最佳正则化参数提供了基础。数值实验验证了理论结果并证明了所提算法的效率。|[2512.24647](http://arxiv.org/abs/2512.24647)|null|\n",
        "2512.24577": "|**2025-12-31**|**QAOA-MaxCut has barren plateaus for almost all graphs**|近年来，QAOA 一直是深入研究的主题，但相对应的动态李代数 (DLA)——VQA 表达性和可训练性的关键指标——除了高度对称的实例之外，仍然知之甚少。指数级缩放的 DLA 维度与优化领域中所谓的贫瘠高原 (BP) 的存在相关，这使得训练变得棘手。在这项工作中，我们研究了应用于规范 MaxCut 的 QAOA 的 DLA，适用于加权图和未加权图。对于加权图，我们表明，当从连续分布中提取权重时，对于除路径和循环之外的所有连通图，DLA 维数几乎肯定会增长为 $θ(4^n)$。在更常见的未加权设置中，我们表明，除指数消失部分之外的所有图都渐近地具有 $ θ(4 ^ n) $ 大 DLA 维度。还确定了相应 DLA 的整个简单李代数分解，从中我们证明损失函数的方差为 $O(1/2^n)$，这意味着这些加权和未加权图上的 QAOA 都受到 BP 的影响。此外，我们还给出了 DLA 具有指数维数的图族的显式构造，包括 MaxCut 在 $\\mathsf P$ 中的情况。我们对未加权情况的证明基于许多分裂引理和 DLA 自由条件，这些条件允许人们将极其复杂的李代数问题转换为合适的图论问题。这些构成了新算法的基础，该算法计算此类 DLA 的速度比以前的方法快几个数量级，从而将标准硬件上的运行时间从几天缩短到几秒钟。我们将此算法应用于 MQLib，这是一个经典的 MaxCut 基准套件，覆盖超过 3,500 个实例，最多 53,130 个顶点，并发现，忽略边权重，至少 75% 的实例拥有维度至少为 $2^{128}$ 的 DLA。|[2512.24577](http://arxiv.org/abs/2512.24577)|null|\n",
        "2512.24564": "|**2025-12-31**|**CPR: Causal Physiological Representation Learning for Robust ECG Analysis under Distribution Shifts**|用于心电图 (ECG) 诊断的深度学习模型已经取得了显着的准确性，但在对抗对抗性扰动方面表现出脆弱性，特别是模仿生物形态的平滑对抗性扰动 (SAP)。现有的防御措施面临着严峻的困境：对抗训练（AT）提供了鲁棒性，但会产生令人望而却步的计算负担，而随机平滑（RS）等经过认证的方法会引入显着的推理延迟，使得它们对于实时临床监测来说不切实际。我们认为这种脆弱性源于模型对非鲁棒虚假相关性的依赖，而不是不变的病理特征。为了解决这个问题，我们提出因果生理表征学习（CPR）。与不受语义限制的标准去噪方法不同，CPR 在因果解开框架内结合了生理结构先验。通过结构因果模型 (SCM) 对心电图生成进行建模，CPR 强制实施结构干预，将不变的病理形态（P-QRS-T 复合波）与非因果伪影严格分开。 PTB-XL 的经验结果表明，CPR 明显优于标准临床预处理方法。具体来说，在 SAP 攻击下，CPR 的 F1 得分为 0.632，超过 Median Smoothing (0.541 F1) 9.1%。至关重要的是，CPR 与随机平滑经过认证的稳健性相匹配，同时保持单遍推理效率，在稳健性、效率和临床可解释性之间提供卓越的权衡。|[2512.24564](http://arxiv.org/abs/2512.24564)|null|\n",
        "2512.24534": "|**2025-12-31**|**BF-APNN: A Low-Memory Method for Accelerating the Solution of Radiative Transfer Equations**|辐射传递方程（RTE）表现出高维和多尺度特征，使得传统数值方法计算量大。现有的深度学习方法在低维或线性 RTE 中表现良好，但在高维或非线性 RTE 中仍然面临许多挑战。为了克服这些挑战，我们提出了基函数渐近保持神经网络（BF-APNN），该框架继承了辐射传递渐近保持神经网络（RT-APNN）的优点并加速了求解过程。通过对微观组件采用基函数扩展（源自微观-宏观分解），BF-APNN 有效减轻了训练期间与评估高维积分相关的计算负担。数值实验涉及具有非线性、不连续性和多尺度行为特征的具有挑战性的 RTE 场景，结果表明，与 RT-APNN 相比，BF-APNN 大大减少了训练时间，同时保持了较高的解精度。此外，BF-APNN 在解决复杂的高维 RTE 问题方面表现出卓越的性能，凸显了其作为辐射传输计算的强大工具的潜力。|[2512.24534](http://arxiv.org/abs/2512.24534)|null|\n",
        "2512.24506": "|**2025-12-30**|**Generalising E-prop to Deep Networks**|循环网络通常通过时间反向传播（BPTT）进行训练。然而，BPTT 需要存储网络中所有状态的历史记录，然后按时间顺序向后回放它们。对于大脑来说，这种计算似乎极不可能实现。实时循环学习 (RTRL) 提出了一种数学上等效的替代方案，其中梯度信息与常规前向传播一起在本地及时向前传播，但它的计算复杂度明显高于 BPTT，这使得它对于大型网络来说不切实际。 E-prop 提出了 RTRL 的近似，将其复杂性降低到 BPTT 的水平，同时保持纯粹的在线前向更新，可以通过每个突触的资格跟踪来实现。然而，RTRL 和 E-prop 上的工作普遍研究具有循环动态的单层学习。然而，大脑中的学习跨越多个层次，由深度和时间的层次动态组成。在这篇数学笔记中，我们扩展了 E-prop 框架来处理任意深度的网络，推导出一种新颖的跨深度递归关系，将 E-prop 的资格痕迹扩展到更深的层。因此，我们的结果表明，在线学习算法可以同时在时间和深度上执行准确的信用分配，从而允许在不随时间反向传播的情况下训练深度循环网络。|[2512.24506](http://arxiv.org/abs/2512.24506)|null|\n",
        "2512.24483": "|**2025-12-30**|**Decentralized Optimization over Time-Varying Row-Stochastic Digraphs**|有向图的分散优化对于机器人群、传感器网络和分布式学习等应用至关重要。在许多实际场景中，底层网络是时变广播网络（TVBN），由于无法访问出度信息，只能构造行随机混合矩阵。在 TVBN 上实现精确收敛仍然是一个长期悬而未决的问题，因为时变行随机混合矩阵的限制分布取决于不可预测的未来图实现，使得标准偏差校正技术不可行。   本文通过开发第一个仅使用时变行随机矩阵实现精确收敛的算法来解决这个悬而未决的问题。我们提出 PULM（Pull-with-Memory），这是一种八卦协议，通过行随机混合和局部调整之间的交替来达到指数收敛的平均共识。在 PULM 的基础上，我们开发了 PULM-DGD，它收敛到 $\\mathcal{O}(\\ln(T)/T)$ 的平稳解，以实现平滑的非凸目标。我们的结果显着地将去中心化优化扩展到高度动态的通信环境。|[2512.24483](http://arxiv.org/abs/2512.24483)|null|\n",
        "2512.24456": "|**2025-12-30**|**Fast high-order spectral solvers for PDEs on triangulated surfaces with applications to deforming surfaces**|在本文中，我们将基于经典四边形的分层庞加莱-斯特克洛夫（HPS）框架扩展到三角几何。传统上，HPS 方法将非结构化高阶四边形网格作为输入，并依赖于每个元素的张量积谱离散化。为了克服这一限制，我们引入了两种互补的三角形元素高阶策略：一种易于实现的简化四边形化方法，以及基于 Dubiner 多项式的基于三角形的谱元素方法。我们以数值方式表明，这些扩展保留了 HPS 框架的光谱精度、效率和快速直接求解器结构。该方法进一步扩展到时间相关和演化的表面，其性能通过反应扩散系统和几何驱动的表面演化的数值实验得到证明。|[2512.24456](http://arxiv.org/abs/2512.24456)|null|\n",
        "2512.24450": "|**2025-12-30**|**Robust reduced rank regression under heavy-tailed noise and missing data via non-convex penalization**|降阶回归 (RRR) 是通过低维潜在结构对多重响应进行建模的基本工具，可在高维设置中提供可解释性和强大的预测性能。然而，经典的 RRR 方法通常依赖于平方损失和高斯噪声假设，这使得它们对重尾误差、异常值和数据污染敏感。此外，缺失数据的存在（在现代应用中很常见）使可靠的低秩估计变得更加复杂。在本文中，我们提出了一个强大的降级回归框架，该框架可同时解决重尾噪声、异常值和缺失数据。我们的方法将稳健的 Huber 损失与非凸谱正则化相结合，特别是极小最大凹罚分 (MCP) 和平滑剪切绝对偏差 (SCAD)。与凸核范数正则化不同，所提出的非凸惩罚减轻了过度收缩，并能够更准确地恢复底层低秩结构。该方法还可以容纳响应矩阵中缺失的数据，而无需插补。我们开发了一种基于交替更新和定制光谱阈值的高效近端梯度算法。广泛的模拟研究表明，在重尾噪声和污染下，所提出的方法大大优于基于核规范和非鲁棒的替代方法。癌细胞系数据集的应用进一步说明了所提出的稳健 RRR 框架的实际优势。   我们的方法是在 R 包 rrpackrobust 中实现的，该包位于 https://github.com/tienmt/rrpackrobust。|[2512.24450](http://arxiv.org/abs/2512.24450)|null|\n",
        "2512.24428": "|**2025-12-30**|**Subsecond 3D Mesh Generation for Robot Manipulation**|3D 网格是计算机科学和工程中广泛使用的基本表示形式。在机器人技术中，它们特别有价值，因为它们捕获物体的形式与机器人与物理世界的交互方式直接一致，从而实现预测稳定抓取、检测碰撞和模拟动力学等核心功能。尽管自动 3D 网格生成方法近年来取得了可喜的进展，有可能为实时机器人感知提供一条途径，但仍然存在两个关键挑战。首先，生成高保真网格对于实时使用来说非常慢，每个对象通常需要数十秒。其次，网格生成本身是不够的。在机器人技术中，网格必须基于上下文，即从场景中正确分割并以正确的比例和姿势进行注册。此外，除非这些背景基础步骤仍然有效，否则它们只会引入新的瓶颈。在这项工作中，我们引入了一个端到端系统来解决这些挑战，在一秒内从单个 RGB-D 图像生成高质量、基于上下文的 3D 网格。我们的管道集成了开放词汇对象分割、加速的基于扩散的网格生成和强大的点云配准，每项都针对速度和准确性进行了优化。我们展示了它在现实世界操纵任务中的有效性，表明它使网格能够用作机器人感知和规划的实用、按需表示。|[2512.24428](http://arxiv.org/abs/2512.24428)|null|\n",
        "2512.25075": "|**2025-12-31**|**SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time**|我们提出了 SpaceTimePilot，这是一种视频扩散模型，可以解开空间和时间以实现可控的生成渲染。给定单目视频，SpaceTimePilot 可以在生成过程中独立改变摄像机视点和运动序列，重新渲染场景，以实现跨空间和时间的连续和任意探索。为了实现这一目标，我们在扩散过程中引入了一种有效的动画时间嵌入机制，允许对输出视频相对于源视频的运动序列进行显式控制。由于没有数据集提供具有连续时间变化的同一动态场景的配对视频，我们提出了一种简单而有效的时间扭曲训练方案，该方案重新利用现有的多视图数据集来模拟时间差异。该策略有效地监督模型学习时间控制并实现鲁棒的时空解缠结。为了进一步提高双重控制的精度，我们引入了两个额外的组件：改进的相机调节机制，允许从第一帧开始改变相机，以及CamxTime，第一个合成时空全覆盖渲染数据集，可在场景内提供完全自由的时空视频轨迹。对时间扭曲方案和 CamxTime 数据集的联合训练可以产生更精确的时间控制。我们在现实世界和合成数据上评估了 SpaceTimePilot，与之前的工作相比，展示了清晰的时空解离和强大的结果。项目页面：https://zheninghuang.github.io/Space-Time-Pilot/ 代码：https://github.com/ZheningHuang/spacetimepilot|[2512.25075](http://arxiv.org/abs/2512.25075)|null|\n",
        "2512.25071": "|**2025-12-31**|**Edit3r: Instant 3D Scene Editing from Sparse Unposed Images**|我们提出了 Edit3r，这是一个前馈框架，可以从未摆姿势、视图不一致、指令编辑的图像中一次性重建和编辑 3D 场景。与之前需要针对场景进行优化的方法不同，Edit3r 直接预测指令对齐的 3D 编辑，从而无需优化或姿态估计即可实现快速且逼真的渲染。训练这种模型的一个关键挑战在于缺乏用于监督的多视图一致编辑图像。我们通过（i）基于 SAM2 的重新着色策略来解决这个问题，该策略生成可靠的、跨视图一致的监督，以及（ii）不对称输入策略，将重新着色的参考视图与原始辅助视图配对，鼓励网络融合和对齐不同的观察结果。据推断，我们的模型可以有效地处理通过 InstructPix2Pix 等 2D 方法编辑的图像，尽管在训练期间没有接触到此类编辑。对于大规模定量评估，我们引入了DL3DV-Edit-Bench，这是一个基于DL3DV测试分割构建的基准测试，具有20个不同的场景、4种编辑类型和总共100个编辑。全面的定量和定性结果表明，与最近的基线相比，Edit3r 实现了卓越的语义对齐和增强的 3D 一致性，同时以显着更高的推理速度运行，使其在实时 3D 编辑应用程序中具有广阔的前景。|[2512.25071](http://arxiv.org/abs/2512.25071)|null|\n",
        "2512.24986": "|**2025-12-31**|**PhysTalk: Language-driven Real-time Physics in 3D Gaussian Scenes**|逼真的视觉模拟无处不在，但它们的创作需要计算时间、渲染和专业的动画知识。从文本输入生成开放词汇视觉效果是一种很有前景的解决方案，可以释放巨大的创造潜力。然而，当前的管道缺乏物理现实性和有效的语言接口，需要缓慢的离线优化。相比之下，PhysTalk 采用 3D 高斯溅射 (3DGS) 场景作为输入，并将任意用户提示转换为实时、基于物理的交互式 4D 动画。大型语言模型 (LLM) 生成可执行代码，通过轻量级代理和粒子动力学直接修改 3DGS 参数。值得注意的是，PhysTalk 是第一个将 3DGS 与物理模拟器直接耦合的框架，无需依赖耗时的网格提取。在保留开放词汇的同时，该设计通过对任意多材质对象的碰撞感知、基于物理的操作来实现交互式 3D 高斯动画。最后，PhysTalk 无需训练且计算量轻：这使得 4D 动画可以广泛使用，并将这些工作流程从“渲染和等待”范式转变为与现代物理信息管道的交互式对话。|[2512.24986](http://arxiv.org/abs/2512.24986)|null|\n",
        "2512.24985": "|**2025-12-31**|**DarkEQA: Benchmarking Vision-Language Models for Embodied Question Answering in Low-Light Indoor Environments**|视觉语言模型（VLM）越来越多地被采用作为实体代理的中央推理模块。现有的基准测试是在理想、光线充足的条件下评估其功能，但强大的 24/7 运行要求在各种视觉退化情况下都具有性能，包括夜间低光条件或黑暗环境中——这是一个在很大程度上被忽视的核心必要条件。为了解决这一尚未充分探索的挑战，我们提出了 DarkEQA，这是一个开源基准，用于在多级低光条件下评估 EQA 相关的感知基元。 DarkEQA 通过在受控降级下评估以自我为中心的观察的问答来隔离感知瓶颈，从而实现归因稳健性分析。 DarkEQA 的一个关键设计特点是其物理保真度：在线性 RAW 空间中对视觉退化进行建模，模拟基于物理的照明下降和传感器噪声，然后采用 ISP 启发的渲染管道。我们通过评估各种最先进的 VLM 和低光图像增强 (LLIE) 模型来展示 DarkEQA 的实用性。我们的分析系统地揭示了 VLM 在这些具有挑战性的视觉条件下运行时的局限性。我们的代码和基准数据集将在接受后发布。|[2512.24985](http://arxiv.org/abs/2512.24985)|null|\n",
        "2512.24970": "|**2025-12-31**|**Random Batch Sum-of-Gaussians Method for Molecular Dynamics of Born-Mayer-Huggins Systems**|玻恩-梅耶-哈金斯 (BMH) 势结合了库仑相互作用、色散和短程指数斥力，广泛用于熔盐等离子材料。然而，BMH 系统的大规模分子动力学模拟通常受到计算、通信和内存成本的限制。我们最近提出了随机批量高斯和（RBSOG）方法，该方法通过使用高斯和（SOG）分解将势分解为短程和长程部分，并在傅里叶空间中对长程部分应用重要性采样，从而加速库仑计算。在这项工作中，我们将 RBSOG 扩展到 BMH 系统，并结合随机批处理列表 (RBL) 方案来进一步加速短程部分，从而产生一个统一的框架，用于具有 BMH 潜力的高效模拟。 SOG 分解和 RBL 的结合能够有效且可扩展地处理 BMH 系统中的长程和短程相互作用，特别是 RBL 可以通过随机批量邻居列表很好地处理中程指数排斥和色散。提供误差估计以显示 RBL 力的理论收敛性。我们在 2048 美元的 CPU 核心上使用高达 5\\times10^6$ 原子的熔融氯化钠和混合碱金属卤化物来评估该框架。与基于 Ewald 的粒子-粒子粒子网格方法和仅 RBSOG 方法相比，我们的方法在使用 $1000$ 核心时分别实现了大约 $4\\sim10\\times$ 和 $2\\times$ 加速，在相同水平的结构和热力学精度下，并且内存使用量减少。这些结果证明了我们的方法在远程交互 MD 模拟的准确性和可扩展性方面具有有吸引力的性能。|[2512.24970](http://arxiv.org/abs/2512.24970)|null|\n",
        "2512.24951": "|**2025-12-31**|**Laser intracavity absorption magnetometry for optical quantum sensing**|腔内吸收光谱 (ICAS) 是一种成熟的技术，用于以超高灵敏度检测微弱吸收信号。在这里，我们将这一概念扩展到使用金刚石中的氮空位（NV）中心的磁力测量。我们引入了激光腔内吸收磁力计（LICAM），这一概念原则上适用于更广泛的光学量子传感器，包括光泵磁力计。使用可自我维持运行的电驱动、边缘发射二极管激光器，我们证明 LICAM 可以实现在环境条件下运行的高灵敏度磁力计。在接近激光阈值时，与传统的单通道几何结构相比，我们的光学对比度提高了 475 倍，磁灵敏度提高了 180 倍。单模二极管激光器的速率方程模型准确地描述了实验结果。根据我们的测量，我们确定了 $\\mathrm{pT}\\,\\mathrm{Hz}^{-1/2}$ 范围内的预计散粒噪声限制灵敏度，并表明，通过实际设备的改进，可以实现低至 $\\mathrm{fT}\\,\\mathrm{Hz}^{-1/2}$ 范围的灵敏度。|[2512.24951](http://arxiv.org/abs/2512.24951)|null|\n",
        "2512.24848": "|**2025-12-31**|**PrivacyBench: A Conversational Benchmark for Evaluating Privacy in Personalized AI**|个性化人工智能代理依赖于对用户数字足迹的访问，其中通常包括来自私人电子邮件、聊天和购买历史记录的敏感数据。然而，这种访问会带来根本性的社会和隐私风险：缺乏社会情境意识的系统可能会无意中泄露用户秘密，从而威胁到数字福祉。我们引入了 PrivacyBench，这是一个基准，具有包含嵌入式秘密的基于社会的数据集和用于衡量秘密保存的多轮对话评估。测试检索增强生成 (RAG) 助手表明，他们在高达 26.56% 的交互中泄露秘密。隐私意识提示可将泄漏率降低至 5.12%，但该措施仅提供部分缓解。检索机制继续不加区别地访问敏感数据，这将隐私保护的全部负担转移到了生成器身上。这会造成单点故障，导致当前架构不适合大规模部署。我们的研究结果强调迫切需要结构性、隐私设计保障措施，以确保为每个人提供一个道德和包容的网络。|[2512.24848](http://arxiv.org/abs/2512.24848)|null|\n",
        "2512.24827": "|**2025-12-31**|**Discovering Coordinated Joint Options via Inter-Agent Relative Dynamics**|暂时延长的操作提高了在单代理环境中探索和计划的能力。在多智能体设置中，联合状态空间随着智能体数量的指​​数增长使得协调行为变得更加有价值。然而，同样的指数增长使得多代理选项的设计特别具有挑战性。现有的多智能体选项发现方法通常会产生松散耦合或完全独立的行为，从而牺牲协调性。为了解决这些限制，我们描述了一种多代理选项发现的新方法。具体来说，我们提出了一种联合状态抽象，它压缩状态空间，同时保留发现强协调行为所需的信息。我们的方法建立在归纳偏差的基础上，即代理状态的同步为缺乏明确目标的情况下的协调提供了自然的基础。我们首先近似与团队最大对齐的虚拟状态，即 \\textit{Fermat} 状态，并用它来定义 \\textit{spreadness} 的度量，捕获每个单独状态维度上的团队级别的错位。基于这种表示，我们然后采用神经图拉普拉斯估计器来导出捕获代理之间状态同步模式的选项。我们评估了两个多智能体域中多个场景的结果选项，表明与替代选项发现方法相比，它们产生了更强的下游协调能力。|[2512.24827](http://arxiv.org/abs/2512.24827)|null|\n",
        "2512.24794": "|**2025-12-31**|**Nonlinear Noise2Noise for Efficient Monte Carlo Denoiser Training**|Noise2Noise 方法允许使用成对的输入和目标图像来训练基于机器学习的降噪器，其中输入和目标都可能有噪声。这消除了使用很难获得的干净目标图像进行训练的需要。然而，Noise2Noise 训练有一个主要限制：应用于噪声目标的非线性函数会扭曲结果。出现这种偏差是因为非线性使得噪声目标的期望值与干净的目标图像不同。由于非线性函数在图像处理中很常见，因此避免使用非线性函数会限制可对噪声目标执行的预处理类型。我们的主要见解是，某些非线性函数可以应用于噪声目标，而不会给结果带来明显的偏差。我们开发了一个理论框架来分析这些非线性的影响，并描述一类具有最小偏差的非线性函数。   我们展示了我们对蒙特卡罗渲染生成的高动态范围（HDR）图像进行去噪的方法。 Noise2Noise 训练在处理 HDR 图像时可能会遇到问题，训练过程会被异常值淹没并且表现不佳。我们考虑解决这些训练问题的常用方法：将非线性色调映射函数应用于模型输出和目标图像以减少其动态范围。由于涉及非线性，该方法之前被认为与 Noise2Noise 训练不兼容。我们表明，损失函数和色调映射函数的某些组合可以减少异常值的影响，同时引入最小的偏差。我们将我们的方法应用于现有的基于机器学习的蒙特卡罗降噪器，其中原始实现是使用高样本计数参考图像进行训练的。我们的结果接近原始实现的结果，但仅使用噪声训练数据生成。|[2512.24794](http://arxiv.org/abs/2512.24794)|null|\n",
        "2512.24763": "|**2025-12-31**|**UniC-Lift: Unified 3D Instance Segmentation via Contrastive Learning**|3D 高斯散射 (3DGS) 和神经辐射场 (NeRF) 具有先进的新颖视图合成。最近的方法将多视图 2D 分割扩展到 3D，从而实现实例/语义分割以更好地理解场景。一个关键挑战是跨视图的 2D 实例标签不一致，导致 3D 预测效果不佳。现有方法采用两阶段方法，其中一些方法依赖于超参数敏感聚类的对比学习，而另一些方法则预处理标签以确保一致性。我们提出了一个统一的框架，合并这些步骤，通过引入用于高斯原语分割的可学习特征嵌入来减少训练时间并提高性能。然后，通过新颖的“嵌入到标签”过程，将这种嵌入有效地解码为实例标签，从而有效地集成优化。虽然这个统一的框架提供了巨大的好处，但我们在对象边界观察到了伪影。为了解决对象边界问题，我们提出沿着这些边界进行硬挖掘样本。然而，直接将硬挖掘应用于特征嵌入被证明是不稳定的。因此，我们在计算三元组损失之前对栅格化特征嵌入应用线性层，这可以稳定训练并显着提高性能。我们的方法在 ScanNet、Replica3D 和 Messy-Rooms 数据集上的定性和定量优于基线。|[2512.24763](http://arxiv.org/abs/2512.24763)|null|\n"
    },
    "具生智能&自动驾驶": {
        "2512.23294": "|**2025-12-29**|**Agentic AI-Enhanced Semantic Communications: Foundations, Architecture, and Applications**|语义通信（SemCom）作为6G的关键技术之一，正在将网络从比特传输转向语义信息交换。在此基础上，引入具有感知、记忆、推理、行动能力的代理人工智能（AI），为智能通信提供了一条切实可行的路径。本文从研究基础、系统架构、应用场景等角度系统阐述了智能体AI如何赋能SemCom。我们首先按智能体类型对现有研究进行全面回顾，涵盖嵌入式智能体、大语言模型（LLM）/大视觉模型（LVM）智能体和强化学习（RL）智能体。此外，我们提出了一个统一的代理AI增强SemCom框架，涵盖应用层、语义层和云边协作层，形成从意图到编码到传输到解码到动作到评估的闭环。我们还提出了几个典型场景，包括多车辆协同感知、多机器人协同救援以及智能（智能和简洁）网络的代理操作。此外，我们还介绍了一种基于代理知识库（KB）的联合源通道编码案例研究 AKB-JSCC，其中源 KB 和通道 KB 分别由 LLM/LVM 代理和 RL 代理构建。实验结果表明，AKB-JSCC在不同信道条件下均取得了较高的信息重构质量。最后，我们讨论了未来的演进和研究方向，为Agentic SemCom的可移植、可验证、可控的研究和部署提供参考。|[2512.23294](http://arxiv.org/abs/2512.23294)|null|\n",
        "2512.23292": "|**2025-12-29**|**Agentic Physical AI toward a Domain-Specific Foundation Model for Nuclear Reactor Control**|物理系统人工智能的主流范式是将通用基础模型扩展到通用多模态推理，但在控制界面上遇到了根本障碍。最近的基准测试表明，即使是前沿视觉语言模型在基本定量物理任务上也只能达到 50-53% 的准确度，表现为近似猜测器，在违反物理约束的同时保留了语义的合理性。这种输入不忠实不是规模缺陷，而是结构限制。以感知为中心的架构优化参数空间模拟，而安全关键控制则需要对执行的操作进行结果空间保证。在这里，我们通过引入作为代理物理人工智能运行的紧凑语言模型，提出了一条通往特定领域基础模型的根本不同的途径，其中策略优化是由基于物理的验证而不是感知推理驱动的。我们在合成反应堆控制场景上训练了一个包含 3.6 亿参数的模型，将数据集从 10^3 示例扩展到 10^5 示例。这会引起通用模型中不存在的急剧相变。小规模系统表现出具有灾难性尾部风险的高方差模仿，而大规模模型则经历了超过 500 倍的方差崩溃，从而稳定了执行级别的行为。尽管均衡地暴露于四个驱动系列，但该模型自动拒绝了大约 70% 的训练分布，并将 95% 的运行时执行集中在单组策略上。学习到的表示可以在不同的物理场和连续输入模式之间传输，而无需进行架构修改。|[2512.23292](http://arxiv.org/abs/2512.23292)|null|\n",
        "2512.23220": "|**2025-12-29**|**A Human-Oriented Cooperative Driving Approach: Integrating Driving Intention, State, and Conflict**|人车协同驾驶是实现全自动驾驶的重要桥梁，可以提高驾驶灵活性，逐步建立驾驶员对自动驾驶技术的信任和接受度。为了建立更自然、更有效的人车交互，我们提出了一种以人为本的协作驾驶（HOCD）方法，该方法主要通过优先考虑驾驶员意图和状态来最大限度地减少人机冲突。在实施过程中，我们同时考虑战术和操作层面，以确保无缝的人车合作。在战术层面，我们设计了一种意图感知的轨迹规划方法，以意图一致性成本作为核心指标来评估轨迹并使其与驾驶员意图保持一致。在操作层面，我们制定了基于强化学习的控制权限分配策略，通过设计的奖励函数来优化策略，以实现驾驶员状态和权限分配之间的一致性。仿真和人机交互实验的结果表明，我们提出的方法不仅符合轨迹规划中的驾驶员意图，而且确保了合理的权限分配。与其他协作驾驶方法相比，所提出的 HOCD 方法显着提高了驾驶性能并减轻了人机冲突。代码可在 https://github.com/i-Qin/HOCD 获取。|[2512.23220](http://arxiv.org/abs/2512.23220)|null|\n",
        "2512.23215": "|**2025-12-29**|**AVOID: The Adverse Visual Conditions Dataset with Obstacles for Driving Scene Understanding**|了解道路场景的视觉感知对于智能自动驾驶汽车仍然至关重要。特别是，需要实时可靠地检测意外的小道路危险，尤其是在变化的不利条件下（例如天气和日光）。然而，现有的道路驾驶数据集仅提供在正常或不利情况下获取的大规模图像，并且通常不包含在与其他类别相同的视觉域中捕获的道路障碍物。为了解决这个问题，我们引入了一个名为 AVOID（不良视觉条件数据集）的新数据集，用于在模拟环境中收集的实时障碍物检测。 AVOID 包含在各种天气和时间条件下捕获的沿每条路径的大量意外道路障碍物。每个图像都与相应的语义和深度图、原始和语义 LiDAR 数据以及路径点相结合，从而支持大多数视觉感知任务。我们在障碍物检测任务的高性能实时网络上对结果进行基准测试，并且还提出并使用用于语义分割、深度和航路点预测任务的综合多任务网络进行消融研究。|[2512.23215](http://arxiv.org/abs/2512.23215)|null|\n",
        "2512.23208": "|**2025-12-29**|**Exploring Syn-to-Real Domain Adaptation for Military Target Detection**|物体检测是民用和军事应用中感兴趣的关键目标任务之一。特别是，目标检测方法的实际部署对于军事指挥和侦察过程中的决策过程至关重要。然而，当前的域自适应目标检测算法仅在自然或自动驾驶场景范围内考虑将一个域适应另一个相似的域。由于军事领域经常处理各种混合环境，因此检测来自多个不同目标域的对象提出了更大的挑战。由于合成孔径雷达 (SAR) 数据具有全天候、远距离和高分辨率的特点，因此一些装甲军事目标探测研究都使用了合成孔径雷达 (SAR) 数据。尽管如此，SAR数据采集和处理的成本仍然远高于传统RGB相机，这是一种更实惠的替代方案，并且数据处理时间显着缩短。此外，缺乏军事目标检测数据集限制了这种低成本方法的使用。为了缓解这些问题，我们建议使用逼真的视觉工具虚幻引擎生成基于 RGB 的合成数据，用于跨域设置中的军事目标检测。为此，我们通过训练合成数据集并验证网络收集的真实军事目标数据集来进行合成到真实的传输实验。我们对最先进的域适应方法进行了基准测试，该方法通过对我们提出的训练-验证数据集对的监督程度进行区分，并发现当前使用图像上最小提示（例如对象类）的方法比无监督或半监督 DA 方法取得了实质性改进。从这些观察中，我们认识到当前仍有待克服的挑战。|[2512.23208](http://arxiv.org/abs/2512.23208)|null|\n",
        "2512.23180": "|**2025-12-29**|**GaussianDWM: 3D Gaussian Driving World Model for Unified Scene Understanding and Multi-Modal Generation**|随着生成模型的进步，驾驶世界模型（DWM）一直在快速发展。然而，现有的 DWM 缺乏 3D 场景理解能力，只能根据输入数据生成内容，而无法解释或推理驾驶环境。此外，当前使用点云或 BEV 特征表示 3D 空间信息的方法无法准确地将文本信息与底层 3D 场景对齐。为了解决这些限制，我们提出了一种基于 3D 高斯场景表示的新型统一 DWM 框架，该框架既可以实现 3D 场景理解和多模态场景生成，同时还可以丰富理解和生成任务的上下文。我们的方法通过将丰富的语言特征嵌入到每个高斯基元中，直接将文本信息与 3D 场景对齐，从而实现早期模态对齐。此外，我们设计了一种新颖的任务感知语言引导采样策略，可以消除冗余的 3D 高斯分布，并将准确且紧凑的 3D 标记注入 LLM。此外，我们设计了一种双条件多模态生成模型，其中视觉语言模型捕获的信息被用作高级语言条件与低级图像条件相结合，共同指导多模态生成过程。我们对 nuScenes 和 NuInteract 数据集进行全面研究，以验证我们框架的有效性。我们的方法实现了最先进的性能。我们将在 GitHub https://github.com/dtc111111/GaussianDWM 上公开发布代码。|[2512.23180](http://arxiv.org/abs/2512.23180)|null|\n",
        "2512.23162": "|**2025-12-29**|**SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling**|数据稀缺仍然是实现完全自主手术机器人的根本障碍。虽然大规模视觉语言动作 (VLA) 模型通过利用来自不同领域的配对视频动作数据，在家庭和工业操作中显示出令人印象深刻的通用性，但手术机器人却面临着缺乏包括视觉观察和精确机器人运动学的数据集的问题。相比之下，存在大量的手术视频语料库，但它们缺乏相应的动作标签，阻碍了模仿学习或 VLA 训练的直接应用。在这项工作中，我们的目标是通过学习 SurgWorld 的政策模型来缓解这个问题，SurgWorld 是一个专为外科物理人工智能设计的世界模型。我们专门为手术机器人策划了手术动作文本对齐（SATA）数据集，其中包含详细的动作描述。然后我们基于最先进的物理AI世界模型和SATA构建了SurgeWorld。它能够生成多样化、通用且逼真的手术视频。我们也是第一个使用逆动力学模型从合成手术视频推断伪运动学，生成合成配对视频动作数据的人。我们证明，使用这些增强数据训练的外科 VLA 策略显着优于仅在真实手术机器人平台上进行真实演示训练的模型。我们的方法通过利用大量未标记的手术视频和生成世界建模，为自主手术技能获取提供了一条可扩展的路径，从而为通用和数据高效的手术机器人策略打开了大门。|[2512.23162](http://arxiv.org/abs/2512.23162)|null|\n",
        "2512.23160": "|**2025-12-29**|**A Weak Signal Learning Dataset and Its Baseline Method**|弱信号学习（WSL）是故障诊断、医学成像和自动驾驶等许多领域的常见挑战，其中关键信息经常被噪声和干扰掩盖，导致特征识别变得困难。即使在强信号丰富的任务中，提高模型性能的关键往往在于有效提取弱信号。然而，缺乏专用数据集长期以来限制了研究。为了解决这个问题，我们构建了第一个用于弱信号特征学习的专用数据集，其中包含 13,158 个光谱样本。它具有低信噪比优势（超过 55% 的样本信噪比低于 50）和极端的类不平衡（类比高达 29:1），为弱信号场景下的分类和回归提供了具有挑战性的基准。我们还提出了双视图表示（向量 + 时频图）和针对低 SNR、分布偏斜和对偶不平衡量身定制的 PDVFN 模型。 PDVFN并行提取局部序列特征和全局频域结构，遵循局部增强、序列建模、噪声抑制、多尺度捕获、频率提取和全局感知的原则。这种多源互补性增强了低 SNR 和不平衡数据的表示，为天文光谱学等 WSL 任务提供了新颖的解决方案。实验表明，我们的方法在处理弱信号、高噪声和极端类别不平衡方面实现了更高的准确性和鲁棒性，特别是在低信噪比和不平衡场景下。这项研究提供了专用数据集、基线模型，并为未来的 WSL 研究奠定了基础。|[2512.23160](http://arxiv.org/abs/2512.23160)|null|\n",
        "2512.22973": "|**2025-12-28**|**YOLO-IOD: Towards Real Time Incremental Object Detection**|目前增量目标检测（IOD）的方法主要依赖于 Faster R-CNN 或 DETR 系列检测器；然而，这些方法不适合实时 YOLO 检测框架。在本文中，我们首先确定了在基于 YOLO 的增量检测器中导致灾难性遗忘的三种主要类型的知识冲突：前景-背景混淆、参数干扰和知识提炼失准。随后，我们介绍了 YOLO-IOD，这是一种基于预训练的 YOLO-World 模型构建的实时增量对象检测（IOD）框架，通过分阶段参数高效的微调过程促进增量学习。具体来说，YOLO-IOD 包含三个主要组成部分：1）冲突感知伪标签细化（CPR），它通过利用伪标签的置信度并识别与未来任务相关的潜在对象来减轻前景-背景混乱。 2）基于重要性的核选择（IKS），它在当前学习阶段识别并更新与当前任务相关的关键卷积核。 3）跨阶段不对称知识蒸馏（CAKD），它通过将学生目标检测器的特征传输到先前和当前教师检测器的检测头来解决未对齐的知识蒸馏冲突，从而促进现有类别和新引入类别之间的不对称蒸馏。我们进一步引入了 LoCo COCO，这是一个更现实的基准，可以消除跨阶段的数据泄漏。在传统基准和 LoCo COCO 基准上的实验表明，YOLO-IOD 以最小的遗忘实现了卓越的性能。|[2512.22973](http://arxiv.org/abs/2512.22973)|null|\n",
        "2512.22972": "|**2025-12-28**|**Wavelet-based Multi-View Fusion of 4D Radar Tensor and Camera for Robust 3D Object Detection**|4D毫米波雷达因其低成本和全天候鲁棒性而在自动驾驶和机器人感知领域得到广泛应用。然而，其固有的稀疏性和有限的语义丰富性极大地限制了感知能力。最近，通过利用两种模式的互补优势，将摄像头数据与 4D 雷达融合已成为一种有前途的成本效益解决方案。然而，基于点云的雷达经常遭受多级信号处理带来的信息丢失，而直接利用原始 4D 雷达数据会产生高昂的计算成本。为了应对这些挑战，我们提出了 WRCFormer，这是一种新颖的 3D 对象检测框架，通过解耦雷达立方体的多视图表示将原始雷达立方体与摄像机输入融合在一起。具体来说，我们设计了一个小波注意力模块作为基于小波的特征金字塔网络（FPN）的基本模块，以增强稀疏雷达信号和图像数据的表示。我们进一步引入了一种基于两阶段查询、模态不可知的融合机制，称为几何引导渐进融合，以有效地集成来自两种模态的多视图特征。大量实验表明，WRCFormer 在 K-Radar 基准测试中实现了最先进的性能，在所有场景下均超过最佳模型约 2.4%，在雨夹雪场景下超过最佳模型 1.6%，凸显了其在恶劣天气条件下的稳健性。|[2512.22972](http://arxiv.org/abs/2512.22972)|null|\n",
        "2512.23676": "|**2025-12-29**|**Web World Models**|语言代理越来越需要一个持久的世界，让他们能够在其中行动、记忆和学习。现有方法处于两个极端：传统的 Web 框架提供由数据库支持的可靠但固定的上下文，而完全生成的世界模型旨在以牺牲可控性和实际工程为代价实现无限的环境。在这项工作中，我们介绍了网络世界模型（WWM），这是一个中间地带，世界状态和“物理”在普通网络代码中实现，以确保逻辑一致性，而大型语言模型则在此结构化潜在状态之上生成上下文、叙述和高级决策。我们在现实的网络堆栈上构建了一套 WWM，包括基于真实地理的无限旅行地图集、虚构的星系探险家、网络规模的百科全书和叙事世界，以及模拟和游戏般的环境。在这些系统中，我们确定了 WWM 的实用设计原则：将代码定义的规则与模型驱动的想象分开，将潜在状态表示为类型化的 Web 界面，并利用确定性生成来实现无限但结构化的探索。我们的结果表明，网络堆栈本身可以作为世界模型的可扩展基础，从而实现可控但开放的环境。项目页面：https://github.com/Princeton-AI2-Lab/Web-World-Models。|[2512.23676](http://arxiv.org/abs/2512.23676)|null|\n",
        "2512.23635": "|**2025-12-29**|**Rethinking the Spatio-Temporal Alignment of End-to-End 3D Perception**|时空对齐对于自动驾驶 (AD) 中端到端 (E2E) 感知的时间建模至关重要，可提供有价值的结构和纹理先验信息。现有方法通常依赖于注意力机制来跨帧对齐对象，通过统一的显式物理模型（恒定速度等）简化运动模型。这些方法更喜欢隐式对齐的语义特征，挑战了传统感知范式中显式运动建模的重要性。然而，跨类别和帧的运动状态和对象特征的变化使得这种对齐不是最佳的。为了解决这个问题，我们提出了 HAT，一种时空对齐模块，它允许每个对象在没有直接监督的情况下从多个假设中自适应地解码最佳对齐建议。具体来说，HAT 首先利用多个显式运动模型来生成历史实例的空间锚点和运动感知特征建议。然后，它通过合并嵌入在缓存对象查询中的语义和运动线索来执行多假设解码，最终为目标帧提供最佳对齐建议。在 nuScenes 上，HAT 持续改进跨不同基线的 3D 时间检测器和跟踪器。与 DETR3D 检测器配对时，它在测试集上实现了最先进的跟踪结果，AMOTA 为 46.0%。在以对象为中心的E2E AD方法中，HAT提高了感知精度（+1.3% mAP，+3.1% AMOTA），并将碰撞率降低了32%。当语义被破坏时（nuScenes-C），HAT 增强的运动建模可以在 E2E AD 中实现更稳健的感知和规划。|[2512.23635](http://arxiv.org/abs/2512.23635)|null|\n",
        "2512.23605": "|**2025-12-29**|**Parallelized Code Generation from Simulink Models for Event-driven and Timer-driven ROS 2 Nodes**|近年来，嵌入式系统的复杂性和规模显着增加，特别是在快速发展的自动驾驶系统领域。这导致了机器人操作系统 (ROS) 2 和多核处理器等软件和硬件方法的采用。传统的手动程序并行化面临挑战，包括维护数据完整性和避免死锁等并发问题。虽然基于模型的开发 (MBD) 自动化了这一过程，但在多输入场景中集成 ROS 2 等现代框架时遇到了困难。本文提出了一个 MBD 框架来克服这些问题，将 ROS 2 兼容的 Simulink 模型分类为事件驱动和定时器驱动类型，以实现有针对性的并行化。因此，它扩展了 MBD 的传统并行化，并支持具有多个输入的基于 ROS 2 的模型的并行代码生成。评估结果表明，在使用所提出的框架应用并行化之后，所有模式都显示出执行时间的减少，证实了并行化的有效性。|[2512.23605](http://arxiv.org/abs/2512.23605)|null|\n",
        "2512.23593": "|**2025-12-29**|**A Kalman Filter-Based Disturbance Observer for Steer-by-Wire Systems**|线控转向系统取代了机械连杆，具有减轻重量、设计灵活性以及与自动驾驶兼容等优点。然而，它们很容易受到无意的驾驶员扭矩（称为驾驶员阻抗）的高频干扰，这会降低转向性能。现有的方法要么依赖于直接扭矩传感器，这种传感器成本高昂且不切实际，要么缺乏时间分辨率来捕获快速、高频的驾驶员引起的干扰。我们通过设计一个基于卡尔曼滤波器的干扰观测器来解决这个限制，该观测器仅使用电机状态测量来估计高频驱动器扭矩。我们使用 PT1 滞后近似将驱动器被动扭矩建模为扩展状态，并将其集成到线性和非线性线控转向系统模型中。在本文中，我们介绍了该扰动观测器的设计、实现和仿真，并评估了不同的卡尔曼滤波器变体。我们的研究结果表明，所提出的扰动观测器可以准确地重建驾驶员引起的扰动，最小延迟仅为 14 毫秒。我们表明，非线性扩展卡尔曼滤波器在处理摩擦非线性方面优于其线性对应物，改善了从静态摩擦到动态摩擦过渡期间的估计。鉴于该研究的方法，不可避免地要依赖基于模拟的验证而不是现实世界的实验。需要进一步的研究来调查观察者在现实驾驶条件下的鲁棒性。|[2512.23593](http://arxiv.org/abs/2512.23593)|null|\n",
        "2512.23585": "|**2025-12-29**|**Unsupervised Learning for Detection of Rare Driving Scenarios**|罕见和危险驾驶场景的检测是确保自动驾驶系统安全性和可靠性的关键挑战。本研究探索了一种无监督学习框架，用于使用自然驾驶数据（NDD）检测罕见和极端的驾驶场景。我们利用最近提出的深度隔离森林（DIF），这是一种将基于神经网络的特征表示与隔离森林（IF）相结合的异常检测算法，来识别非线性和复杂的异常。来自感知模块的数据捕获车辆动态和环境条件，并被预处理为从滑动窗口提取的结构化统计特征。该框架结合了用于降维和可视化的 t 分布随机邻域嵌入 (t-SNE)，从而能够更好地解释检测到的异常。使用代理地面实况进行评估，将定量指标与定性视频帧检查相结合。我们的结果表明，所提出的方法可以有效识别罕见和危险的驾驶场景，为自动驾驶系统中的异常检测提供可扩展的解决方案。鉴于该研究的方法，不可避免地要依赖代理地面事实和手动定义的特征组合，而这些组合并不涵盖现实世界驾驶异常的全部范围或其微妙的上下文依赖性。|[2512.23585](http://arxiv.org/abs/2512.23585)|null|\n",
        "2512.23575": "|**2025-12-29**|**Model-based Development for Autonomous Driving Software Considering Parallelization**|近年来，自动驾驶汽车作为解决各种社会问题的解决方案之一而受到关注。然而，自动驾驶软件需要实时性能，因为它考虑了多种功能和复杂的环境。因此，本文提出了一种使用基于模型的开发（MBD）流程的自动驾驶软件并行化方法。该方法扩展了现有的基于模型的并行器（MBP）方法，以方便复杂处理的实现。结果，执行时间减少了。评估结果表明，该方法适用于自动驾驶软件的开发，特别是在实现实时性能方面。|[2512.23575](http://arxiv.org/abs/2512.23575)|null|\n",
        "2512.23541": "|**2025-12-29**|**Act2Goal: From World Model To General Goal-conditioned Policy**|以富有表现力和精确的方式指定机器人操作任务仍然是一个核心挑战。虽然视觉目标提供了紧凑且明确的任务规范，但现有的目标条件策略经常难以进行长期操作，因为它们依赖于单步动作预测，而没有对任务进度进行明确的建模。我们提出了 Act2Goal，一种通用的目标条件操纵策略，它将目标条件视觉世界模型与多尺度时间控制相结合。给定当前观察和目标视觉目标，世界模型会生成一系列合理的中间视觉状态，捕捉长视界结构。为了将这种视觉计划转化为稳健的执行，我们引入了多尺度时间哈希（MSTH），它将想象的轨迹分解为用于细粒度闭环控制的密集近端帧和锚定全局任务一致性的稀疏远端帧。该策略通过端到端交叉注意力将这些表示与运动控制结合起来，从而实现连贯的长视野行为，同时保持对局部干扰的反应。 Act2Goal 对新物体、空间布局和环境实现了强大的零样本泛化。我们通过基于 LoRA 的微调进行事后目标重新标记，进一步实现无奖励在线适应，从而无需外部监督即可快速自主改进。真实的机器人实验表明，Act2Goal 在自主交互的几分钟内将挑战分布外任务的成功率从 30% 提高到 90%，验证了具有多尺度时间控制的目标条件世界模型为稳健的长视野操作提供了必要的结构化指导。项目页面：https://act2goal.github.io/|[2512.23541](http://arxiv.org/abs/2512.23541)|null|\n",
        "2512.23452": "|**2025-12-29**|**Detections of Compact Radio Continuum toward Methanol Maser Rings Using the VLA**|大质量原恒星深深地嵌入其诞生核心的尘埃中，不易被探测到。然而，厘米波长的脉泽发射由于其高亮度，使我们能够研究原恒星星周区域的气体运动学。我们的目标是通过对相关的射电连续谱发射进行灵敏搜索，了解六颗大质量年轻恒星中 6.7 GHz 甲醇脉泽发射所勾勒出的环状结构的起源，并推导其特性。我们在 C 和 K 频段使用 A 配置中的 Karl G. Jansky 甚大阵列，以便对射电连续谱以及 6.7 GHz 甲醇和 22 GHz 水脉泽发射进行成像。我们展示了样本中四个目标的热射流的第一张图像：G23.389+00.185、G23.657-00.127、G28.817+00.365 和 G30.400-00.296。在进一步的目标 G23.207-00.377 中，复杂的 K 波段连续发射使得我们不清楚检测到的峰值是否追踪来自单个年轻原恒星的喷流结或标记多个致密的年轻原恒星。其余源 G31.047+00.356 显示与演化的 H II 区域相关的射电连续谱发射。|[2512.23452](http://arxiv.org/abs/2512.23452)|null|\n",
        "2512.23445": "|**2025-12-29**|**Assessing behaviour coverage in a multi-agent system simulation for autonomous vehicle testing**|随着自动驾驶汽车技术的进步，确保这些系统的安全性和可靠性变得至关重要。因此，全面的测试方法对于评估自动驾驶汽车在各种复杂的现实场景中的性能至关重要。本研究重点关注专为自动驾驶车辆测试而设计的多智能体系统仿真的行为覆盖率分析，并提供一种系统方法来测量和评估仿真环境中的行为覆盖率。通过定义一组驾驶场景和代理交互，我们评估模拟涵盖与自动驾驶相关的广泛行为的程度。   我们的研究结果强调了行为覆盖在验证自动驾驶车辆系统的有效性和稳健性方面的重要性。通过对行为覆盖率指标和基于覆盖率的测试的分析，我们确定了模拟框架中需要改进和优化的关键领域。因此，提出了模型预测控制（MPC）行人代理，其目标函数被制定为鼓励 \\textit{有趣} 测试，同时促进比其他先前研究的行人代理更现实的行为。这项研究通过提供对模拟环境中系统行为的综合评估的见解，有助于推动自动驾驶汽车测试领域的发展。研究结果为通过严格的测试方法提高自动驾驶汽车的安全性、可靠性和性能提供了宝贵的启示。|[2512.23445](http://arxiv.org/abs/2512.23445)|null|\n",
        "2512.23421": "|**2025-12-29**|**DriveLaW:Unifying Planning and Video Generation in a Latent Driving World**|世界模型对于自动驾驶至关重要，因为它们可以了解场景如何随着时间的推移而演变，以解决现实世界的长尾挑战。然而，当前的方法将世界模型限制在有限的角色中：它们在表面上统一的架构中运行，而这些架构仍然将世界预测和运动规划保持为解耦的过程。为了弥补这一差距，我们提出了 DriveLaW，这是一种统一视频生成和运动规划的新颖范例。通过直接将视频生成器中的潜在表示注入规划器中，DriveLaW 确保了高保真未来生成与可靠轨迹规划之间的内在一致性。具体来说，DriveLaW 由两个核心组件组成：DriveLaW-Video，我们强大的世界模型，可通过富有表现力的潜在表示生成高保真度预测；DriveLaW-Act，一种扩散规划器，可从 DriveLaW-Video 的潜在特征生成一致且可靠的轨迹，这两个组件均通过三阶段渐进训练策略进行优化。我们统一范式的力量通过这两项任务的新的最先进的结果得到了证明。 DriveLaW 不仅显着提高了视频预测的性能，在 FID 中超越了最佳表现 33.3%，在 FVD 中超越了 1.8%，而且还在 NAVSIM 规划基准上创造了新记录。|[2512.23421](http://arxiv.org/abs/2512.23421)|null|\n",
        "2512.24712": "|**2025-12-31**|**LSRE: Latent Semantic Rule Encoding for Real-Time Semantic Risk Detection in Autonomous Driving**|现实世界的自动驾驶必须遵守复杂的人类社会规则，这些规则超出了法律规定的交通法规。许多语义约束，例如让给紧急车辆、遵守交通官员的手势或停车等校车，对人类来说是直观的，但难以明确编码。尽管大型视觉语言模型（VLM）可以解释此类语义，但其推理成本使得它们对于实时部署来说不切实际。这项工作提出了 LSRE，一种潜在语义规则编码框架，它将稀疏采样的 VLM 判断转换为循环世界模型的潜在空间内的决策边界。通过将语言定义的安全语义编码到轻量级潜在分类器中，LSRE 能够以 10 Hz 的频率进行实时语义风险评估，而无需每帧 VLM 查询。 CARLA 中六个语义失败场景的实验表明，LSRE 获得了与大型 VLM 基线相当的语义风险检测精度，同时提供了更早的危险预测并保持了较低的计算延迟。 LSRE 进一步推广到罕见的语义相似测试用例，表明语言引导的潜在分类为自动驾驶中的语义安全监控提​​供了一种有效且可部署的机制。|[2512.24712](http://arxiv.org/abs/2512.24712)|null|\n",
        "2512.24673": "|**2025-12-31**|**VLA-RAIL: A Real-Time Asynchronous Inference Linker for VLA Models and Robots**|视觉-语言-动作（VLA）模型在机器人技术领域取得了显着的突破，其中动作块在这些进步中发挥着主导作用。鉴于机器人运动控制的实时性和连续性，融合连续动作块队列的策略对 VLA 模型的整体性能具有深远的影响。现有方法在机器人动作执行中存在抖动、停顿甚至暂停的问题，这不仅限制了可实现的执行速度，而且降低了任务完成的整体成功率。本文介绍了 VLA-RAIL（实时异步推理链接器），这是一种新颖的框架，旨在通过异步进行模型推理和机器人运动控制并保证平滑、连续和高速的动作执行来解决这些问题。该论文的核心贡献有两个方面：轨迹平滑器（Trajectory Smoother）使用多项式拟合有效地滤除一个动作块轨迹中的噪声和抖动；块融合器（Chunk Fuser）无缝对齐当前执行轨迹和新到达的块，确保两个连续动作块之间的位置、速度和加速度连续性。我们在动态模拟任务和几个实际操作任务的基准上验证了 VLA-RAIL 的有效性。实验结果表明，VLA-RAIL显着降低了运动抖动，提高了执行速度，提高了任务成功率，这将成为VLA模型大规模部署的关键基础设施。|[2512.24673](http://arxiv.org/abs/2512.24673)|null|\n",
        "2512.24653": "|**2025-12-31**|**RoboMIND 2.0: A Multimodal, Bimanual Mobile Manipulation Dataset for Generalizable Embodied Intelligence**|虽然数据驱动的模仿学习彻底改变了机器人操作，但目前的方法仍然受到缺乏大规模、多样化的现实世界演示的限制。因此，现有模型在非结构化环境中泛化长期双手任务和移动操作的能力仍然有限。为了弥补这一差距，我们推出了 RoboMIND 2.0，这是一个全面的现实世界数据集，包含在 6 个不同的机器人实施例和 739 个复杂任务中收集的超过 310K 个双臂操作轨迹。至关重要的是，为了支持接触丰富和空间扩展任务的研究，该数据集包含 12K 触觉增强片段和 20K 移动操作轨迹。为了补充这些物理数据，我们构建了现实世界环境的高保真数字孪生，并发布了额外的 20K 轨迹模拟数据集，以促进稳健的模拟到真实的传输。为了充分发挥 RoboMIND 2.0 的潜力，我们提出了 MIND-2 系统，这是一个通过离线强化学习优化的分层双系统框架。 MIND-2 集成了一个高级语义规划器 (MIND-2-VLM)，可将抽象的自然语言指令分解为基础子目标，再加上一个低级视觉-语言-动作执行器 (MIND-2-VLA)，可生成精确的、本体感觉感知的运动动作。|[2512.24653](http://arxiv.org/abs/2512.24653)|null|\n",
        "2512.24619": "|**2025-12-31**|**Decentralized No-Regret Frequency-Time Scheduling for FMCW Radar Interference Avoidance**|汽车 FMCW 雷达对于现代 ADAS 和自动驾驶系统不可或缺，但其不断增加的密度也加剧了相互干扰的风险。现有的缓解技术，包括反应性接收器端抑制、主动波形设计和协作调度，通常面临可扩展性、对侧信道通信的依赖或距离多普勒分辨率下降的限制。基于我们早期关于分散频域无遗憾跳跃的工作，本文引入了一个统一的时频博弈论框架，使雷达能够适应频谱和时间资源。我们将干扰避免问题表述为重复的反协调博弈，其中每个雷达使用遗憾最小化动态自主更新频率子带和线性调频脉冲级时间偏移的混合策略。我们表明，所提出的时频无遗憾跳跃算法实现了外部和交换遗憾的消失，并且诱导的经验游戏收敛到$\\varepsilon$-粗相关均衡或相关均衡。理论分析提供了联合域中的遗憾界限，揭示了时间自适应如何隐式地规范频率选择并增强针对异步干扰的鲁棒性。多雷达场景的数值实验表明，与时频随机跳频和集中式基于纳什的基准相比，SINR、碰撞率和距离多普勒质量有了显着改善。|[2512.24619](http://arxiv.org/abs/2512.24619)|null|\n",
        "2512.24497": "|**2025-12-30**|**What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?**|人工智能领域的一个长期挑战是开发能够解决各种物理任务并泛化到新的、看不见的任务和环境的代理。最近流行的方法涉及从状态动作轨迹训练世界模型，然后将其与规划算法一起使用来解决新任务。规划通常在输入空间中执行，但最近的一系列方法引入了规划算法，可以在世界模型的学习表示空间中进行优化，并承诺抽象不相关的细节会产生更有效的规划。在这项工作中，我们将这个系列的模型描述为 JEPA-WM，并研究使此类算法发挥作用的技术选择。我们建议对几个关键组成部分进行全面研究，目的是找到家庭内的最佳方法。我们使用模拟环境和现实世界的机器人数据进行了实验，并研究了模型架构、训练目标和规划算法如何影响规划的成功。我们结合我们的研究结果提出了一个模型，该模型在导航和操作任务方面均优于两个既定基线 DINO-WM 和 V-JEPA-2-AC。代码、数据和检查点可在 https://github.com/facebookresearch/jepa-wms 获取。|[2512.24497](http://arxiv.org/abs/2512.24497)|null|\n",
        "2512.24470": "|**2025-12-30**|**Foundation models on the bridge: Semantic hazard detection and safety maneuvers for maritime autonomy with vision-language models**|IMO MASS 规则草案要求自主和远程监管的海船检测偏离其操作设计范围的情况，输入通知操作员的预定义后备措施，允许立即人工干预，并避免在未经批准的情况下更改航行计划。在警报接管间隙中履行这些义务需要采取短期的、人类可超越的后备策略。当正确的行动取决于含义时，经典的海上自治堆栈就会陷入困境（例如，潜水员放下旗帜意味着有人在水中，火灾靠近意味着危险）。我们认为（i）视觉语言模型（VLM）为这种分布外的情况提供语义意识，并且（ii）具有短视野、人类可覆盖的回退策略的快慢异常管道使得这在切换窗口中变得实用。我们引入了 Semantic Lookout，这是一种仅使用相机、候选者约束的视觉语言模型 (VLM) 后备机动选择器，它在持续的人类权威下从有效的、世界锚定的轨迹中选择一个谨慎的动作（或定位）。在 40 个港口场景中，我们测量了每次呼叫的场景理解和延迟、与人类共识的一致性（三人多数投票模型）、火灾危险场景的短期风险缓解以及水上警报 -> 后备机动 -> 操作员移交。 Sub-10 s 模型保留了较慢的最先进模型的大部分意识。后备机动选择器的性能优于仅几何基线，并增加了火灾场景中的隔离距离。现场运行验证端到端操作。这些结果支持VLM作为与IMO MASS代码草案兼容的语义回退机动选择器，在实际延迟预算内，并激励未来在域适应、混合自主方面的工作，将基础模型语义与多传感器鸟瞰感知和短视野重新规划相结合。|[2512.24470](http://arxiv.org/abs/2512.24470)|null|\n",
        "2512.24426": "|**2025-12-30**|**Counterfactual VLA: Self-Reflective Vision-Language-Action Model with Adaptive Reasoning**|最近的推理增强视觉-语言-动作（VLA）模型通过生成中间推理轨迹提高了端到端自动驾驶的可解释性。然而，这些模型主要描述他们的感知和打算做什么，很少质疑他们计划的行动是否安全或适当。这项工作引入了 Counterfactual VLA (CF-VLA)，这是一种自我反思的 VLA 框架，使模型能够在执行之前推理并修改其计划的操作。 CF-VLA 首先生成总结驾驶意图的时间分段元动作，然后根据元动作和视觉上下文执行反事实推理。此步骤模拟潜在结果，识别不安全行为，并输出指导最终轨迹生成的纠正元操作。为了有效地获得这种自我反思能力，我们提出了一个 rollout-filter-label 管道，该管道从基础（非反事实）VLA 的 rollout 中挖掘高价值场景，并为后续训练轮次标记反事实推理痕迹。在大规模驾驶数据集上的实验表明，CF-VLA 将轨迹精度提高了 17.6%，将安全指标提高了 20.5%，并表现出自适应思维：它只在具有挑战性的场景中实现反事实推理。通过将推理痕迹从一次性描述转变为因果自我校正信号，CF-VLA 向自我反思的自动驾驶代理迈出了一步，这些代理学会在行动之前思考。|[2512.24426](http://arxiv.org/abs/2512.24426)|null|\n",
        "2512.24385": "|**2025-12-30**|**Forging Spatial Intelligence: A Roadmap of Multi-Modal Data Pre-Training for Autonomous Systems**|包括自动驾驶汽车和无人机在内的自主系统的快速发展，更加迫切地需要从多模式车载传感器数据中打造真正的空间智能。虽然基础模型在单模态环境中表现出色，但将其功能集成到相机和激光雷达等不同传感器中以形成统一的理解仍然是一项艰巨的挑战。本文提出了多模式预训练的综合框架，确定了推动实现这一目标的核心技术集。我们剖析了基本传感器特征和学习策略之间的相互作用，评估了特定于平台的数据集在实现这些进步中的作用。我们的核心贡献是为预训练范式制定统一的分类法：从单模态基线到复杂的统一框架，学习 3D 对象检测和语义占用预测等高级任务的整体表示。此外，我们研究了文本输入和占用表示的整合，以促进开放世界的感知和规划。最后，我们确定了关键瓶颈，例如计算效率和模型可扩展性，并提出了通用多模态基础模型的路线图，该模型能够实现稳健的空间智能以进行实际部署。|[2512.24385](http://arxiv.org/abs/2512.24385)|null|\n",
        "2512.24331": "|**2025-12-30**|**Spatial-aware Vision Language Model for Autonomous Driving**|虽然视觉语言模型 (VLM) 通过利用语言模型中嵌入的常识显示出端到端自动驾驶的重大前景，但它们对 2D 图像线索的复杂场景理解和决策的依赖为安全性和可靠性带来了关键瓶颈。当前基于图像的方法难以实现精确的度量空间推理和几何推理，导致驾驶策略不可靠。为了弥补这一差距，我们提出了 LVLDrive（LiDAR-Vision-Language），这是一种新颖的框架，专门设计用于通过结合 LiDAR 点云作为额外的输入模态来升级现有的 VLM，为自动驾驶提供强大的 3D 度量空间理解。一个关键的挑战在于减轻不同 3D 数据对预训练 VLM 带来的灾难性干扰。为此，我们引入了 Gradual Fusion Q-Former，它可以增量注入 LiDAR 功能，确保 VLM 现有知识库的稳定性和保存。此外，我们开发了一个空间感知问答 (SA-QA) 数据集，以明确地教授模型高级 3D 感知和推理能力。关于驾驶基准的大量实验表明，与仅视觉的同类产品相比，LVLDrive 在场景理解、度量空间感知和可靠的驾驶决策方面实现了卓越的性能。我们的工作强调了显式 3D 度量数据对于构建值得信赖的基于 VLM 的自主系统的必要性。|[2512.24331](http://arxiv.org/abs/2512.24331)|null|\n",
        "2512.24329": "|**2025-12-30**|**World model inspired sarcasm reasoning with large language model agents**|讽刺理解是自然语言处理中的一个具有挑战性的问题，因为它需要捕获话语的表面含义与说话者的意图以及周围的社会背景之间的差异。尽管深度学习和大型语言模型（LLM）的最新进展显着提高了性能，但大多数现有方法仍然依赖于单个模型的黑盒预测，这使得很难从结构上解释讽刺背后的认知因素。此外，虽然讽刺常常表现为语义评估与规范期望或意图之间的不匹配，但明确分解和建模这些组件的框架仍然有限。在这项工作中，我们将讽刺理解重新表述为一种世界模型启发的推理过程，并提出了世界模型启发的 SArcasm 推理（WM-SAR），它将字面意义、上下文、规范期望和意图分解为专门的基于 LLM 的代理。字面评价和规范期望之间的差异被明确量化为确定性不一致分数，并与意图分数一起，通过轻量级逻辑回归模型整合这些信号以推断最终的讽刺概率。该设计利用了法学硕士的推理能力，同时保持了可解释的数值决策结构。对代表性讽刺检测基准的实验表明，WM-SAR 始终优于现有的深度学习和基于 LLM 的方法。消融研究和案例分析进一步表明，整合语义不一致和意图推理对于有效的讽刺检测、实现强大的性能和高可解释性至关重要。|[2512.24329](http://arxiv.org/abs/2512.24329)|null|\n",
        "2512.24922": "|**2025-12-31**|**Semi-Supervised Diversity-Aware Domain Adaptation for 3D Object detection**|3D 物体探测器是自动驾驶车辆感知系统的基本组成部分。虽然这些检测器在标准自动驾驶基准上取得了出色的性能，但它们通常很难在不同领域进行推广 - 例如，在美国训练的模型可能在亚洲或欧洲等地区表现不佳。本文提出了一种基于神经元激活模式的新型激光雷达域适应方法，证明如果正确选择了目标域中的一小部分、具有代表性和多样化的样本子集，则可以通过仅注释它们来实现最先进的性能。所提出的方法需要非常小的注释预算，并且当与受持续学习启发的后训练技术相结合时，可以防止原始模型的权重漂移。经验评估表明，所提出的域自适应方法优于线性探测和最先进的域自适应技术。|[2512.24922](http://arxiv.org/abs/2512.24922)|null|\n",
        "2512.24851": "|**2025-12-31**|**VLN-MME: Diagnosing MLLMs as Language-guided Visual Navigation agents**|多模态大语言模型 (MLLM) 在广泛的视觉语言任务中表现出了卓越的能力。然而，它们作为具体代理的性能需要多轮对话空间推理和顺序动作预测，需要进一步探索。我们的工作通过引入一个统一且可扩展​​的评估框架来探索 MLLM 作为零样本代理，通过将传统导航数据集桥接到一个名为 VLN-MME 的标准化基准，来研究视觉和语言导航 (VLN) 背景下的这种潜力。我们通过高度模块化且易于访问的设计简化了评估。这种灵活性简化了实验，实现了跨不同 MLLM 架构、代理设计和导航任务的结构化比较和组件级消融。至关重要的是，在我们的框架的支持下，我们观察到通过思想链（CoT）推理和自我反思来增强我们的基线代理会导致性能意外下降。这表明 MLLM 在具体导航任务中表现出较差的上下文感知能力；尽管它们可以遵循指令并构建输出，但它们的 3D 空间推理保真度较低。 VLN-MME 为在具体导航设置中系统评估通用 MLLM 奠定了基础，并揭示了其顺序决策能力的局限性。我们相信这些发现为 MLLM 作为具体代理的后期培训提供了重要的指导。|[2512.24851](http://arxiv.org/abs/2512.24851)|null|\n"
    }
}