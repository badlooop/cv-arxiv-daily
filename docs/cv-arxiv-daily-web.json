{
    "Video Diffusion": {
        "2602.20119": "|**2026-02-23**|**NovaPlan: Zero-Shot Long-Horizon Manipulation via Closed-Loop Video Language Planning**|解决长期任务需要机器人将高级语义推理与低级物理交互相结合。虽然视觉语言模型 (VLM) 和视频生成模型可以分解任务并想象结果，但它们通常缺乏现实世界执行所需的物理基础。我们引入了 NovaPlan，这是一个分层框架，它将闭环 VLM 和视频规划与几何接地机器人执行相结合，以实现零样本长视野操作。在高层，VLM 规划器将任务分解为子目标，并在闭环中监控机器人的执行情况，使系统能够通过自主重新规划从单步故障中恢复。为了计算低级机器人动作，我们从生成的视频中提取并利用与任务相关的对象关键点和人手姿势作为运动学先验，并采用切换机制来选择更好的动作作为机器人动作的参考，即使在严重遮挡或深度不准确的情况下也能保持稳定的执行。我们展示了 NovaPlan 在三项长期任务和功能操作基准（FMB）上的有效性。我们的结果表明，NovaPlan 可以执行复杂的组装任务并表现出灵巧的错误恢复行为，而无需任何事先演示或培训。项目页面：https://nova-plan.github.io/|[2602.20119](http://arxiv.org/abs/2602.20119)|null|\n",
        "2602.19623": "|**2026-02-23**|**PedaCo-Gen: Scaffolding Pedagogical Agency in Human-AI Collaborative Video Authoring**|虽然文本到视频 (T2V) 生成式人工智能的进步为内容创作民主化提供了一条充满希望的道路，但当前的模型通常针对视觉保真度而不是教学效果进行优化。本研究介绍了 PedaCo-Gen，这是一种基于教学的人类与人工智能协作视频生成系统，用于根据 Mayer 的多媒体学习认知理论 (CTML) 创作教学视频。 PedaCo-Gen 摆脱了传统的“一次性”生成，引入了中间表示 (IR) 阶段，使教育工作者能够与人工智能审阅者交互地审阅和完善视频蓝图（包括脚本和视觉描述）。我们与 23 名教育专家进行的研究表明，与基线相比，PedaCo-Gen 显着提高了各种主题和 CTML 原则的视频质量。参与者认为人工智能驱动的指导不仅是一组指令，而且是一个元认知支架，可以增强他们的教学设计专业知识，报告高生产效率（M = 4.26）和指南有效性（M = 4.04）。这些发现强调了通过有原则的共同创造来恢复教学机构的重要性，为未来将生成能力与人类专业知识相协调的人工智能创作工具奠定了基础。|[2602.19623](http://arxiv.org/abs/2602.19623)|null|\n",
        "2602.19202": "|**2026-02-22**|**UniE2F: A Unified Diffusion Framework for Event-to-Frame Reconstruction with Video Foundation Models**|事件摄像机擅长高速、低功耗和高动态范围场景感知。然而，由于它们从根本上只记录相对强度变化而不是绝对强度，因此生成的数据流会遭受空间信息和静态纹理细节的显着损失。在本文中，我们通过利用预训练视频扩散模型的生成先验从稀疏事件数据重建高保真视频帧来解决这一限制。具体来说，我们首先通过直接应用事件数据作为合成视频的条件来建立基线模型。然后，基于事件流和视频帧之间的物理相关性，我们进一步引入基于事件的帧间残差引导，以提高视频帧重建的准确性。此外，我们通过调制反向扩散采样过程，以零镜头方式将我们的方法扩展到视频帧插值和预测，从而创建统一的事件到帧重建框架。现实世界和合成数据集的实验结果表明，我们的方法在数量和质量上都显着优于以前的方法。我们还向审稿人推荐视频结果补充材料中包含的视频演示。该代码将在 https://github.com/CS-GangXu/UniE2F 上公开提供。|[2602.19202](http://arxiv.org/abs/2602.19202)|null|\n",
        "2602.19163": "|**2026-02-22**|**JavisDiT++: Unified Modeling and Optimization for Joint Audio-Video Generation**|AIGC 已从文本到图像的生成迅速扩展到跨视频和音频的高质量多模态合成。在此背景下，联合音视频生成（JAVG）已成为一项基本任务，它可以根据文本描述生成同步且语义一致的声音和视觉。然而，与 Veo3 等先进商业模型相比，现有的开源方法在生成质量、时间同步性以及与人类偏好的一致性等方面仍然存在局限性。为了弥补这一差距，本文提出了 JavisDiT++，这是一个简洁而强大的框架，用于 JAVG 的统一建模和优化。首先，我们引入了一种特定模态的专家混合（MS-MoE）设计，该设计可以实现跨模态交互功效，同时提高单模态生成质量。然后，我们提出了一种时间对齐 RoPE (TA-RoPE) 策略来实现音频和视频令牌之间的显式帧级同步。此外，我们开发了一种音视频直接偏好优化（AV-DPO）方法，使模型输出在质量、一致性和同步维度上与人类偏好保持一致。我们的模型基于 Wan2.1-1.3B-T2V 构建，仅通过大约 100 万个公共训练条目就实现了最先进的性能，在定性和定量评估方面都显着优于先前的方法。已经进行了全面的消融研究来验证我们提出的模块的有效性。所有代码、模型和数据集均在 https://JavisVerse.github.io/JavisDiT2-page 发布。|[2602.19163](http://arxiv.org/abs/2602.19163)|null|\n",
        "2602.19161": "|**2026-02-22**|**Flash-VAED: Plug-and-Play VAE Decoders for Efficient Video Generation**|潜在扩散模型已经实现了高质量的视频合成，但其推理仍然成本高昂且耗时。随着扩散变压器变得越来越高效，延迟瓶颈不可避免地转移到 VAE 解码器。为了在保持质量的同时减少延迟，我们提出了一种适用于 VAE 解码器的通用加速框架，该框架保持与原始潜在分布的完全对齐。具体来说，我们提出（1）一种独立感知的通道修剪方法，以有效减轻严重的通道冗余，以及（2）一种分阶段的主导算子优化策略，以解决 VAE 解码器中广泛使用的因果 3D 卷积的高推理成本问题。基于这些创新，我们构建了 Flash-VAED 系列。此外，我们设计了一个三相动态蒸馏框架，可以有效地将原始 VAE 解码器的功能转移到 Flash-VAED。在 Wan 和 LTX-Video VAE 解码器上进行的大量实验表明，我们的方法在质量和速度方面都优于基线，实现了大约 6 倍的加速，同时保持了高达 96.9% 的重建性能。值得注意的是，Flash-VAED 将端到端生成流程加速高达 36%，而 VBench-2.0 上的质量下降可以忽略不计。|[2602.19161](http://arxiv.org/abs/2602.19161)|null|\n",
        "2602.19089": "|**2026-02-22**|**Ani3DHuman: Photorealistic 3D Human Animation with Self-guided Stochastic Sampling**|当前的 3D 人体动画方法很难实现照片级真实感：基于运动学的方法缺乏非刚性动力学（例如服装动力学），而利用视频扩散先验的方法可以合成非刚性运动，但会遭受质量伪影和身份损失。为了克服这些限制，我们提出了 Ani3DHuman，一个将基于运动学的动画与视频扩散先验相结合的框架。我们首先引入分层运动表示，将刚性运动与残余非刚性运动分开。刚性运动是通过运动学方法生成的，然后产生粗略渲染以指导视频扩散模型生成恢复残余非刚性运动的视频序列。然而，这种基于扩散采样的恢复任务非常具有挑战性，因为初始渲染不符合分布，导致标准确定性 ODE 采样器失败。因此，我们提出了一种新颖的自引导随机采样方法，该方法通过将随机采样（用于真实感质量）与自引导（用于身份保真度）相结合，有效地解决了分布外问题。这些恢复的视频提供高质量的监督，从而能够优化残余非刚性运动场。大量实验表明 \\MethodName 可以生成逼真的 3D 人体动画，性能优于现有方法。代码可在 https://github.com/qiisun/ani3d human 中找到。|[2602.19089](http://arxiv.org/abs/2602.19089)|null|\n",
        "2602.21188": "|**2026-02-24**|**Human Video Generation from a Single Image with 3D Pose and View Control**|最近的扩散方法由于其强大的视觉生成能力，在从单个图像生成视频方面取得了重大进展。然而，图像到视频的合成仍然存在挑战，特别是在人类视频生成方面，从单个图像推断视图一致、运动相关的衣服皱纹仍然是一个艰巨的问题。在本文中，我们提出了 4D 人类视频生成 (HVG)，这是一种潜在视频扩散模型，能够从具有 3D 姿势和视图控制的单个图像生成高质量、多视图、时空连贯的人类视频。 HVG 通过三个关键设计实现了这一目标：(i) 关节姿势调制，通过新颖的二维骨图捕获 3D 关节的解剖关系，并通过引入 3D 信息解决跨视图的自遮挡问题； (ii) 视图和时间对齐，确保参考图像和姿势序列之间的多视图一致性和对齐，以实现帧到帧的稳定性； (iii) 渐进式时空采样与时间对齐，以保持长多视图动画中的平滑过渡。对图像到视频任务的大量实验表明，HVG 在从不同的人类图像和姿势输入生成高质量 4D 人类视频方面优于现有方法。|[2602.21188](http://arxiv.org/abs/2602.21188)|null|\n",
        "2602.20999": "|**2026-02-24**|**VII: Visual Instruction Injection for Jailbreaking Image-to-Video Generation Models**|图像到视频 (I2V) 生成模型在参考图像上调节视频生成，已显示出新兴的视觉指令跟踪功能，允许参考图像中的某些视觉提示充当视频生成的隐式控制信号。然而，这种功能也带来了一个以前被忽视的风险：对手可能会利用视觉指令通过图像模态注入恶意意图。在这项工作中，我们通过提出视觉指令注入（VII）来揭示这一风险，这是一种免训练且可转移的越狱框架，有意将不安全文本提示的恶意意图伪装成安全参考图像中的良性视觉指令。具体来说，VII 协调恶意意图重新编程模块，从不安全文本提示中提取恶意意图，同时最大限度地减少其静态危害性，并协调视觉指令接地模块，通过渲染与原始不安全文本提示保持语义一致性的视觉指令，将提取的意图接地到安全输入图像上，从而在 I2V 生成过程中引入有害内容。根据经验，我们对四种最先进的商业 I2V 模型（Kling-v2.5-turbo、Gemini Veo-3.1、Seedance-1.5-pro 和 PixVerse-V5）进行的广泛实验表明，VII 的攻击成功率高达 83.5%，同时将拒绝率降低到接近零，显着优于现有基线。|[2602.20999](http://arxiv.org/abs/2602.20999)|null|\n",
        "2602.20685": "|**2026-02-25**|**RAYNOVA: Scale-Temporal Autoregressive World Modeling in Ray Space**|世界基础模型旨在通过物理上合理的行为来模拟现实世界的演化。与之前分别处理空间和时间相关性的方法不同，我们提出了 RAYNOVA，这是一种采用双因果自回归框架的驾驶场景的几何对抗多视图世界模型。它在自回归过程中遵循尺度和时间拓扑顺序，并利用全局注意力进行统一的 4D 时空推理。与强加强 3D 几何先验的现有作品不同，RAYNOVA 基于相对 Plücker 射线位置编码构建了跨视图、帧和尺度的各向同性时空表示，从而能够对不同的相机设置和自我运动进行稳健的泛化。我们进一步引入了一种循环训练范例，以减轻长视野视频生成中的分布漂移。 RAYNOVA 在 nuScenes 上实现了最先进的多视图视频生成结果，同时在不同的输入条件下提供更高的吞吐量和强大的可控性，推广到新颖的视图和相机配置，而无需明确的 3D 场景表示。我们的代码将在 https://raynova-ai.github.io/ 发布。|[2602.20685](http://arxiv.org/abs/2602.20685)|null|\n",
        "2602.20673": "|**2026-02-24**|**GA-Drive: Geometry-Appearance Decoupled Modeling for Free-viewpoint Driving Scene Generatio**|自由视角、可编辑且高保真的驾驶模拟器对于训练和评估端到端自动驾驶系统至关重要。在本文中，我们提出了 GA-Drive，这是一种新颖的模拟框架，能够通过几何外观解耦和基于扩散的生成沿着用户指定的新颖轨迹生成相机视图。给定沿着记录轨迹捕获的一组图像和相应的场景几何形状，GA-Drive 使用几何信息合成新颖的伪视图。然后使用经过训练的视频扩散模型将这些伪视图转换为逼真的视图。通过这种方式，我们将场景的几何形状和外观解耦。这种解耦的优点是它支持通过最先进的视频到视频编辑技术进行外观编辑，同时保留底层几何形状，从而能够在原始和新颖的轨迹上进行一致的编辑。大量实验表明，GA-Drive 在 NTA-IoU、NTL-IoU 和 FID 分数方面明显优于现有方法。|[2602.20673](http://arxiv.org/abs/2602.20673)|null|\n",
        "2602.20583": "|**2026-02-24**|**PropFly: Learning to Propagate via On-the-Fly Supervision from Pre-trained Video Diffusion Models**|基于传播的视频编辑通过将单个编辑帧传播到后续帧中来实现精确的用户控制，同时保持原始上下文（例如运动和结构）。然而，训练此类模型需要大规模、配对（源和编辑）视频数据集，获取这些数据集成本高昂且复杂。因此，我们提出了 PropFly，一种基于传播的视频编辑的训练管道，依赖于预先训练的视频扩散模型 (VDM) 的即时监督，而不需要现成的或预先计算的配对视频编辑数据集。具体来说，我们的 PropFly 利用具有不同无分类器指导 (CFG) 尺度的中间噪声潜伏的一步干净潜伏估计来动态合成不同的“源”（低 CFG）和“编辑”（高 CFG）潜伏对。源潜在变量充当视频的结构信息，而编辑后的潜在变量提供学习传播的目标转换。我们的管道支持附加到预先训练的 VDM 的附加适配器，以学习通过引导调制流匹配 (GMFM) 损失来传播编辑，从而引导模型复制目标转换。我们的动态监督确保模型能够学习时间一致的动态转换。大量实验表明，我们的 PropFly 在各种视频编辑任务上显着优于最先进的方法，产生高质量的编辑结果。|[2602.20583](http://arxiv.org/abs/2602.20583)|null|\n",
        "2602.20497": "|**2026-02-24**|**LESA: Learnable Stage-Aware Predictors for Diffusion Model Acceleration**|扩散模型在图像和视频生成任务中取得了显着的成功。然而，扩散变压器（DiT）的高计算要求对其实际部署提出了重大挑战。虽然特征缓存是一种很有前途的加速策略，但基于简单重用或免训练预测的现有方法很难适应扩散过程的复杂、阶段相关的动态，通常会导致质量下降，并且无法保持与标准去噪过程的一致性。为了解决这个问题，我们提出了一个基于两阶段训练的 LEarnable Stage-Aware (LESA) 预测器框架。我们的方法利用柯尔莫哥洛夫-阿诺德网络（KAN）来准确地从数据中学习时间特征映射。我们进一步引入了多阶段、多专家架构，将专门的预测器分配给不同的噪声级别阶段，从而实现更精确和稳健的特征预测。大量的实验表明，我们的方法在保持高保真生成的同时实现了显着的加速。实验表明，FLUX.1-dev 上的加速为 5.00 倍，质量下降最小（下降 1.0%）；Qwen-Image 上的加速为 6.25 倍，与之前的 SOTA（TaylorSeer）相比，质量提高了 20.2%；HunyuanVideo 上的加速为 5.00 倍，PSNR 比 TaylorSeer 提高了 24.7%。文本到图像和文本到视频合成的最先进性能验证了我们基于训练的框架在不同模型上的有效性和泛化能力。我们的代码包含在补充材料中，并将在 GitHub 上发布。|[2602.20497](http://arxiv.org/abs/2602.20497)|null|\n",
        "2602.20354": "|**2026-02-23**|**3DSPA: A 3D Semantic Point Autoencoder for Evaluating Video Realism**|人工智能视频生成正在迅速发展。为了使视频生成器能够用于从机器人到电影制作等各种应用，它们必须始终如一地生成逼真的视频。然而，评估生成视频的真实感仍然是一个很大程度上手动的过程——需要人工注释或范围有限的定制评估数据集。在这里，我们开发了一个视频真实感自动评估框架，它可以捕获语义和连贯的 3D 结构，并且不需要访问参考视频。我们的方法 3DSPA 是一种 3D 时空点自动编码器，它将 3D 点轨迹、深度线索和 DINO 语义特征集成到视频评估的统一表示中。 3DSPA 对物体如何移动以及场景中发生的情况进行建模，从而能够对真实性、时间一致性和物理合理性进行可靠的评估。实验表明，3DSPA 能够可靠地识别违反物理定律的视频，对运动伪影更敏感，并且更符合人类对多个数据集的视频质量和真实感的判断。我们的结果表明，利用 3D 语义丰富基于轨迹的表示为基准生成视频模型提供了更坚实的基础，并隐式捕获物理规则违规行为。代码和预训练模型权重将在 https://github.com/TheProParadox/3dspa_code 上提供。|[2602.20354](http://arxiv.org/abs/2602.20354)|null|\n",
        "2602.22208": "|**2026-02-26**|**Solaris: Building a Multiplayer Video World Model in Minecraft**|现有的动作条件视频生成模型（视频世界模型）仅限于单智能体视角，无法捕捉现实世界环境的多智能体交互。我们介绍 Solaris，这是一种模拟一致的多视图观察的多人视频世界模型。为了实现这一目标，我们开发了一个多人数据系统，专为《我的世界》等视频游戏的稳健、连续和自动化数据收集而设计。与之前为单人游戏设置构建的平台不同，我们的系统支持协调的多代理交互和同步视频+动作捕捉。使用该系统，我们收集了 1264 万个多人游戏帧，并提出了多人运动、记忆、接地、构建和视图一致性的评估框架。我们使用分阶段的管道来训练 Solaris，该管道逐渐从单人模式过渡到多人模式，结合了双向、因果和自我强迫训练。在最后阶段，我们引入了检查点自我强迫，这是一种内存高效的自我强迫变体，可以实现更长视野的教师。结果显示我们的架构和培训设计优于现有基线。通过开源我们的系统和模型，我们希望为新一代多智能体世界模型奠定基础。|[2602.22208](http://arxiv.org/abs/2602.22208)|null|\n",
        "2602.21929": "|**2026-02-25**|**Geometry-as-context: Modulating Explicit 3D in Scene-consistent Video Generation to Geometry Context**|场景一致的视频生成旨在创建基于摄像机轨迹探索 3D 场景的视频。以前的方法依赖具有外部存储器的视频生成模型来实现一致性，或者迭代 3D 重建和修复，这会在推理过程中由于不正确的中间输出、不可微分的过程和单独的模型而累积错误。为了克服这些限制，我们引入了“几何即上下文”。它使用自回归相机控制的视频生成模型迭代地完成以下步骤：（1）估计 3D 重建所需的当前视图的几何形状，以及（2）模拟和恢复 3D 场景渲染的新视图图像。在这个多任务框架下，我们开发了相机门控注意力模块，以增强模型有效利用相机姿势的能力。在训练阶段，利用文本上下文为了确定应该生成几何图像还是 RGB 图像，为了确保模型在推理过程中可以生成仅 RGB 的输出，从交错的文本-图像-几何训练序列中随机删除该方法，并在单向和前后轨迹的场景视频生成上进行了测试，结果表明其在保持场景一致性和摄像机控制方面优于以前的方法。|[2602.21929](http://arxiv.org/abs/2602.21929)|null|\n",
        "2602.21835": "|**2026-02-25**|**UniVBench: Towards Unified Evaluation for Video Foundation Models**|视频基础模型旨在将视频理解、生成、编辑和指令跟踪集成在一个框架内，使其成为下一代多模态系统的中心方向。然而，现有的评估基准仍然分散且范围有限，因为它们每个都针对单个任务，依赖于特定于任务的指标，并且通常使用短或简单的视频剪辑。因此，它们无法捕获这些模型旨在提供的统一功能。为了解决这一差距，我们引入了 UniVBench，这是一个专门为评估视频基础模型的四个核心能力而构建的基准：视频理解、视频生成、视频编辑，以及新提出的任务视频重建，该任务评估模型如何忠实地再现其遇到的视频内容。我们的基准测试通过纳入 200 个高质量、多样化的多镜头视频，每个视频都配有详细的标题、多格式编辑说明和参考图像，极大地扩展了评估的复杂性。所有视频均由人工创作并经过仔细验证，提供比之前的基准更丰富的电影信息。此外，我们开发了一个统一的代理评估系统（UniV-Eval），该系统标准化了所有任务的提示、指令解析和评分，从而实现了统一视频模型的公平、可扩展和可重复的比较。通过在基于指令的多镜头视频任务中进行基础评估，UniVBench 提供了第一个用于测量视频基础模型旨在实现的集成功能的框架。广泛的人工注释确保我们的评估与人类判断一致，从而实现严格的评估并加速实现强大的视频智能。|[2602.21835](http://arxiv.org/abs/2602.21835)|null|\n",
        "2602.21818": "|**2026-02-25**|**SkyReels-V4: Multi-modal Video-Audio Generation, Inpainting and Editing model**|SkyReels V4 是一个统一的多模态视频基础模型，用于联合视频音频生成、修复和编辑。该模型采用双流多模态扩散变压器（MMDiT）架构，其中一个分支合成视频，另一个分支生成时间对齐的音频，同时共享基于多模态大语言模型（MMLM）的强大文本编码器。 SkyReels V4 接受丰富的多模式指令，包括文本、图像、视频剪辑、蒙版和音频参考。通过将 MMLM 多模态指令跟随功能与视频分支 MMDiT 中的上下文学习相结合，该模型可以在复杂条件下注入细粒度的视觉指导，而音频分支 MMDiT 同时利用音频参考来指导声音生成。在视频方面，我们采用通道串联公式，将图像到视频、视频扩展和视频编辑等多种修复风格任务统一在一个界面下，并通过多模式提示自然扩展到视觉参考修复和编辑。 SkyReels V4 支持高达 1080p 的分辨率、32 FPS 和 15 秒的持续时间，可生成具有同步音频的高保真、多镜头、影院级视频。为了使这种高分辨率、长时间的生成在计算上可行，我们引入了一种效率策略：联合生成低分辨率全序列和高分辨率关键帧，然后是专用的超分辨率和帧插值模型。据我们所知，SkyReels V4是第一个同时支持多模态输入、联合视频音频生成以及生成、修复和编辑统一处理的视频基础模型，同时在电影分辨率和时长上保持强大的效率和质量。|[2602.21818](http://arxiv.org/abs/2602.21818)|null|\n",
        "2602.21581": "|**2026-02-25**|**MultiAnimate: Pose-Guided Image Animation Made Extensible**|姿势引导的人体图像动画旨在合成由一系列姿势驱动的参考角色的逼真视频。虽然基于扩散的方法取得了显着的成功，但大多数现有方法仅限于单角色动画。我们观察到，天真地将这些方法扩展到多角色场景通常会导致角色之间的身份混乱和令人难以置信的遮挡。为了解决这些挑战，在本文中，我们提出了一种基于现代扩散变压器（DiT）的可扩展多字符图像动画框架，用于视频生成。我们的框架的核心引入了两个新颖的组件——标识符分配器和标识符适配器——它们协作捕获每个人的位置线索和人与人之间的空间关系。这种掩码驱动的方案以及可扩展的训练策略不仅增强了灵活性，而且还能够泛化到比训练期间看到的字符更多的场景。值得注意的是，我们的模型仅在两个字符数据集上进行训练，可推广到多字符动画，同时保持与单字符情况的兼容性。大量的实验表明，我们的方法在多字符图像动画中实现了最先进的性能，超越了现有的基于扩散的基线。|[2602.21581](http://arxiv.org/abs/2602.21581)|null|\n",
        "2602.21365": "|**2026-02-24**|**Towards Controllable Video Synthesis of Routine and Rare OR Events**|目的：整理包含罕见、安全关键或非典型事件的手术室 (OR) 工作流程的大规模数据集，在操作和道德上仍然具有挑战性。这一数据瓶颈使得用于检测、理解和缓解手术室中罕见或安全关键事件的环境智能的开发变得复杂。   方法：这项工作提出了一个 OR 视频扩散框架，可以控制罕见和安全关键事件的合成。该框架集成了几何抽象模块、调节模块和微调扩散模型，首先将 OR 场景转换为抽象几何表示，然后调节合成过程，最后生成逼真的 OR 事件视频。使用这个框架，我们还整理了一个合成数据集来训练和验证人工智能模型，以检测无菌区违规事件的险情。   结果：在合成常规 OR 事件时，我们的方法优于现成的视频扩散基线，在域内和域外数据集中实现了较低的 FVD/LPIPS 和较高的 SSIM/PSNR。通过定性结果，我们说明了其对反事实事件进行受控视频合成的能力。根据生成的合成数据进行训练和验证的 AI 模型在检测临近安全关键事件时实现了 70.13% 的召回率。最后，我们进行了一项消融研究，以量化关键设计选择带来的性能增益。   结论：我们的解决方案能够从抽象几何表示中控制合成常规和罕见的 OR 事件。除了展示其生成罕见和安全关键场景的能力之外，我们还展示了其支持环境智能模型开发的潜力。|[2602.21365](http://arxiv.org/abs/2602.21365)|null|\n",
        "2602.21333": "|**2026-02-24**|**HorizonForge: Driving Scene Editing with Any Trajectories and Any Vehicles**|可控驾驶场景生成对于真实且可扩展的自动驾驶模拟至关重要，但现有方法很难同时实现照片真实感和精确控制。我们推出了 Horizo​​nForge，这是一个统一的框架，可将场景重建为可编辑的高斯图和网格，从而实现细粒度的 3D 操作和语言驱动的车辆插入。编辑是通过噪声感知视频扩散过程进行渲染的，该过程强制执行空间和时间一致性，在单个前馈通道中产生不同的场景变化，而无需每个轨迹优化。为了标准化评估，我们进一步提出了 Horizo​​nSuite，这是一个涵盖自我和代理级别编辑任务（例如轨迹修改和对象操作）的综合基准。大量实验表明，高斯网格表示比其他 3D 表示具有更高的保真度，并且视频扩散的时间先验对于相干合成至关重要。结合这些发现，Horizo​​nForge 建立了一个简单而强大的范例，用于逼真、可控的驾驶模拟，与第二最佳的最先进方法相比，实现了 83.4% 的用户偏好增益和 25.19% 的 FID 改进。项目页面：https://horizo​​nforge.github.io/。|[2602.21333](http://arxiv.org/abs/2602.21333)|null|\n",
        "2602.23203": "|**2026-02-26**|**ColoDiff: Integrating Dynamic Consistency With Content Awareness for Colonoscopy Video Generation**|结肠镜检查视频生成提供动态、信息丰富的数据，这对于诊断肠道疾病至关重要，特别是在数据稀缺的情况下。高质量视频生成需要时间一致性和对临床属性的精确控制，但面临着不规则肠道结构、多样化疾病表现和各种成像方式的挑战。为此，我们提出了 ColoDiff，一种基于扩散的框架，可生成动态一致且内容感知的结肠镜检查视频，旨在缓解数据短缺并协助临床分析。在帧间级别，我们的 TimeStream 模块通过跨帧标记化机制将时间依赖性与视频序列解耦，从而在肠道结构不规则的情况下实现复杂的动态建模。在帧内级别，我们的内容感知模块结合了噪声注入嵌入和可学习原型，以实现对临床属性的精确控制，突破了扩散模型的粗略指导。此外，ColoDiff 采用非马尔可夫采样策略，可将实时生成的步骤减少 90% 以上。 ColoDiff 在三个公共数据集和一个医院数据库中进行评估，基于生成指标和下游任务，包括疾病诊断、模态区分、肠道准备评分和病变分割。大量实验表明 ColoDiff 生成的视频具有平滑的过渡和丰富的动态。 ColoDiff 在可控结肠镜检查视频生成方面做出了努力，揭示了合成视频在补充真实表现和缓解临床环境中数据稀缺方面的潜力。|[2602.23203](http://arxiv.org/abs/2602.23203)|null|\n",
        "2602.23152": "|**2026-02-26**|**The Trinity of Consistency as a Defining Principle for General World Models**|构建能够学习、模拟和推理客观物理定律的世界模型是追求通用人工智能的基本挑战。以 Sora 等视频生成模型为代表的最新进展证明了数据驱动的缩放定律在近似物理动力学方面的潜力，而新兴的统一多模态模型 (UMM) 则为集成感知、语言和推理提供了一种有前途的架构范例。尽管取得了这些进展，该领域仍然缺乏一个原则性的理论框架来定义通用世界模型所需的基本属性。在本文中，我们提出世界模型必须建立在一致性三位一体的基础上：模态一致性作为语义接口，空间一致性作为几何基础，时间一致性作为因果引擎。通过这个三方视角，我们系统地回顾了多模态学习的演变，揭示了从松散耦合的专业模块到统一架构的轨迹，从而实现内部世界模拟器的协同出现。为了补充这个概念框架，我们引入了 CoW-Bench，这是一个以多帧推理和生成场景为中心的基准测试。 CoW-Bench 在统一的评估协议下评估视频生成模型和 UMM。我们的工作建立了通向通用世界模型的原则性途径，阐明了当前系统的局限性和未来进步的架构要求。|[2602.23152](http://arxiv.org/abs/2602.23152)|null|\n",
        "2602.22960": "|**2026-02-26**|**UCM: Unifying Camera Control and Memory with Time-aware Positional Encoding Warping for World Models**|基于视频生成的世界模型在模拟交互环境方面表现出了巨大的潜力，但在两个关键领域面临着持续的困难：重新访问场景时保持长期内容一致性以及通过用户提供的输入实现精确的摄像机控制。基于显式 3D 重建的现有方法通常会损害无界场景和细粒度结构的灵活性。替代方法直接依赖于先前生成的帧，而不建立明确的空间对应关系，从而限制了可控性和一致性。为了解决这些限制，我们提出了 UCM，这是一种新颖的框架，通过时间感知的位置编码扭曲机制将长期记忆和精确的相机控制结合起来。为了减少计算开销，我们设计了一种用于高保真生成的高效双流扩散变压器。此外，我们引入了一种可扩展的数据管理策略，利用基于点云的渲染来模拟场景重访，从而促进对超过 500K 单目视频的训练。对现实世界和综合基准的大量实验表明，UCM 在长期场景一致性方面显着优于最先进的方法，同时在高保真视频生成中实现了精确的摄像机可控性。|[2602.22960](http://arxiv.org/abs/2602.22960)|null|\n",
        "2602.22745": "|**2026-02-26**|**SPATIALALIGN: Aligning Dynamic Spatial Relationships in Video Generation**|大多数文本转视频 (T2V) 生成器优先考虑美观质量，但往往忽略生成视频中的空间限制。在这项工作中，我们提出了 SPATIALALIGN，这是一个自我改进框架，可增强 T2V 模型描述文本提示中指定的动态空间关系 (DSR) 的能力。我们提出了零阶正则化直接偏好优化 (DPO) 来微调 T2V 模型，以更好地与 DSR 保持一致。具体来说，我们设计了 DSR-SCORE，这是一种基于几何的指标，可以定量测量生成的视频与提示中指定的 DSR 之间的对齐情况，这比之前依赖 VLM 进行评估的工作向前迈出了一步。我们还建立了具有不同 DSR 的文本视频对数据集，以促进研究。大量的实验表明，我们的微调模型在空间关系方面的表现显着优于基线。代码将在Link中发布。|[2602.22745](http://arxiv.org/abs/2602.22745)|null|\n",
        "2602.22654": "|**2026-02-26**|**Denoising as Path Planning: Training-Free Acceleration of Diffusion Models with DPCache**|扩散模型在图像和视频生成方面取得了显着的成功，但其实际部署仍然受到多步迭代采样的大量计算开销的阻碍。在加速策略中，基于缓存的方法通过跨时间步重用或预测特征来提供免训练且有效的解决方案。然而，现有方法依赖于固定或局部自适应调度，而不考虑去噪轨迹的全局结构，通常导致误差累积和视觉伪影。为了克服这一限制，我们提出了 DPCache，这是一种新颖的免训练加速框架，它将扩散采样加速表述为全局路径规划问题。 DPCache 从一个小的校准集中构造一个路径感知成本张量，以量化以前面的关键时间步长为条件的跳过时间步长的路径相关误差。利用该张量，DPCache 采用动态编程来选择关键时间步的最佳序列，从而最大限度地降低总路径成本，同时保持轨迹保真度。在推理过程中，模型仅在这些关键时间步执行完整计算，而使用缓存的特征有效地预测中间输出。在 DiT、FLUX 和 HunyuanVideo 上进行的大量实验表明，DPCache 以最小的质量损失实现了强大的加速，在 4.87$\\times$ 加速下比之前的加速方法高出 $+$0.031 ImageReward，甚至在 FLUX 上以 3.54$\\times$ 加速超过全步基线 $+$0.028 ImageReward，验证了我们的路径感知全局调度框架的有效性。代码将在 https://github.com/argsss/DPCache 发布。|[2602.22654](http://arxiv.org/abs/2602.22654)|null|\n",
        "2602.22596": "|**2026-02-26**|**BetterScene: 3D Scene Synthesis with Representation-Aligned Generative Model**|我们提出了 BetterScene，这是一种使用极其稀疏、无约束的照片来增强各种现实世界场景的新颖视图合成 (NVS) 质量的方法。 BetterScene 利用在数十亿帧上预训练的可投入生产的稳定视频扩散 (SVD) 模型作为强大的骨干，旨在减少伪影并在推理时恢复视图一致的细节。传统方法已经开发了类似的基于扩散的解决方案来解决新颖视图合成的这些挑战。尽管有了显着的改进，这些方法通常依赖于现成的预训练扩散先验，并且仅对 UNet 模块进行微调，同时保持其他组件冻结，即使在合并深度或语义条件等几何感知正则化时，这仍然会导致细节和伪影不一致。为了解决这个问题，我们研究了扩散模型的潜在空间，并引入了两个组件：(1) 时间等方差正则化和 (2) 视觉基础模型对齐表示，两者都应用于 SVD 管道内的变分自动编码器 (VAE) 模块。 BetterScene 集成了前馈 3D 高斯泼溅 (3DGS) 模型，将特征渲染为 SVD 增强器的输入，并生成连续、无伪影、一致的新颖视图。我们对具有挑战性的 DL3DV-10K 数据集进行评估，并展示了与最先进的方法相比的卓越性能。|[2602.22596](http://arxiv.org/abs/2602.22596)|null|\n",
        "2602.22486": "|**2026-02-25**|**Flow Matching is Adaptive to Manifold Structures**|流匹配已成为基于扩散的生成建模的免模拟替代方案，通过求解常微分方程来生成样本，该常微分方程的时间相关速度场是通过简单源分布（例如标准正态）和目标数据分布之间的插值来学习的。基于流的方法通常表现出更高的训练稳定性，并且在数据集中在低维流形附近的高维设置中实现了强大的经验性能，例如文本到图像合成、视频生成和分子结构生成。尽管取得了这一成功，现有的流匹配理论分析假设目标分布具有平滑、全维密度，使其在流形支持的设置中的有效性很大程度上无法解释。为此，我们从理论上分析了当目标分布支持在光滑流形上时使用线性插值的流匹配。我们为学习的速度场建立非渐近收敛保证，然后通过 ODE 传播该估计误差，以获得由流匹配目标引起的隐式密度估计器的统计一致性。由此产生的收敛速度接近极小极大最优，仅取决于内在维度，并且反映了流形和目标分布的平滑度。总之，这些结果为流匹配如何适应内在数据几何并规避维数灾难提供了原则性解释。|[2602.22486](http://arxiv.org/abs/2602.22486)|null|\n"
    },
    "3D": {
        "2602.20160": "|**2026-02-23**|**tttLRM: Test-Time Training for Long Context and Autoregressive 3D Reconstruction**|我们提出了 tttLRM，这是一种新颖的大型 3D 重建模型，它利用测试时训练 (TTT) 层来实现具有线性计算复杂性的长上下文、自回归 3D 重建，从而进一步扩展模型的能力。我们的框架有效地将多个图像观测结果压缩为 TTT 层的快速权重，在潜在空间中形成隐式 3D 表示，该表示可以解码为各种显式格式，例如用于下游应用的高斯 Splats (GS)。我们模型的在线学习变体支持通过流观察进行渐进式 3D 重建和细化。我们证明，新视图合成任务的预训练可以有效地转移到显式 3D 建模，从而提高重建质量和更快的收敛速度。大量实验表明，与物体和场景上最先进的方法相比，我们的方法在前馈 3D 高斯重建方面实现了卓越的性能。|[2602.20160](http://arxiv.org/abs/2602.20160)|null|\n",
        "2602.20100": "|**2026-02-23**|**Transcending the Annotation Bottleneck: AI-Powered Discovery in Biology and Medicine**|对专家注释的依赖长期以来一直是人工智能应用于生物医学的主要限制步骤。虽然监督学习推动了临床算法的最初浪潮，但向无监督和自监督学习 (SSL) 的范式转变目前正在释放生物样本库规模数据集的潜在潜力。通过直接学习数据的内在结构——无论是磁共振图像（MRI）中的像素、体积扫描中的体素还是基因组序列中的标记——这些方法有助于发现新的表型、形态学与遗传学的联系以及在没有人为偏见的情况下检测异常。本文综合了“无标签学习”方面的开创性和最新进展，强调了无监督框架如何导出可遗传的心脏特征，预测组织学中的空间基因表达，并以与监督框架相媲美或超过监督框架的性能检测病理。|[2602.20100](http://arxiv.org/abs/2602.20100)|null|\n",
        "2602.20079": "|**2026-02-23**|**SemanticNVS: Improving Semantic Scene Understanding in Generative Novel View Synthesis**|我们提出了 SemanticNVS，一种用于新颖视图合成（NVS）的相机条件多视图扩散模型，它通过集成预先训练的语义特征提取器来提高生成质量和一致性。现有的 NVS 方法对于输入视图附近的视图表现良好，但是，它们往往会在长距离相机运动下生成语义上不可信且扭曲的图像，从而显示出严重的退化。我们推测这种退化是由于当前模型无法完全理解其条件或中间生成的场景内容。在这里，我们建议集成预先训练的语义特征提取器，以合并更强的场景语义作为条件，即使在远处的视点也能实现高质量的生成。我们研究了两种不同的策略，（1）扭曲的语义特征和（2）每个去噪步骤的理解和生成的交替方案。多个数据集的实验结果表明，与最先进的替代方案相比，有明显的定性和定量（FID 中为 4.69%-15.26%）改进。|[2602.20079](http://arxiv.org/abs/2602.20079)|null|\n",
        "2602.20063": "|**2026-02-23**|**Spherical Hermite Maps**|球面函数出现在整个计算机图形学中，从球面谐波照明和预先计算的辐射率传输到神经辐射场和程序行星渲染。高效评估对于实时应用至关重要，但现有方法面临质量与性能的权衡：双线性 LUT 采样速度很快，但会产生分面，而双三次过滤需要 16 个纹理样本。大多数实现对法线使用有限差分，需要额外的样本并引入噪声。本文提出了 Spherical Hermite Maps，这是一种解决这种权衡的导数增强 LUT 表示形式。通过在填充立方体贴图的每个纹理像素处存储函数值和缩放偏导数，只需四个纹理样本（2x2 足迹）即可实现双三次 Hermite 重建，同时提供来自相同样本的连续梯度。关键的见解是 Hermite 插值重建平滑导数作为值重建的副产品，使表面法线有效地自由。在受控实验中，球形 Hermite 贴图比双线性插值将 PSNR 提高了 8-41 dB，并以四分之一的成本匹配 16 抽头双三次质量。分析法线可将复杂表面上的平均角度误差减少 9-13%，同时产生稳定的镜面高光。三个应用程序展示了多功能性：球谐字形可视化、网格细节级别的径向深度图冒名顶替者以及具有球形高度场的程序行星/小行星渲染。|[2602.20063](http://arxiv.org/abs/2602.20063)|null|\n",
        "2602.20039": "|**2026-02-23**|**On the Spatial Consistency of Sub-Terahertz Channel Characteristics for Beyond-6G Systems**|在为超 6G 蜂窝系统设计新机制时，射线追踪是一种用于精确亚太赫兹（亚太赫兹，100-300 GHz）信道建模的通用方法。理论上，无线信道可能会随波长距离而变化。因此，在亚太赫兹频段，接近毫米的波长需要极其大量的计算工作来进行光线追踪建模。然而，在实践中，信道特征可能在更大的距离上保持定量相似，这可以大大减少计算工作量。本研究的目的是通过实验表征亚太赫兹通道特性的空间一致性程度。为此，我们在室内大厅 (InH) 环境中在 140-150 GHz 频段进行了大规模测量活动，并以 2.5 mm 至 1 m 的间隔距离表征了信道。我们的结果表明，包括延迟扩展、角度延迟扩展和 K 因子在内的信道特性在数十厘米距离内仅略有变化。这意味着，在所考虑的 InH 环境中，网格可以沿着稳定的视线 (LoS) 方向处于 10-50 个波长范围内（145 GHz），而在不受 LoS 支配的区域中需要更精细的分辨率。对于较粗糙的网格，需要高级插值来捕获快速变化的分散分量。|[2602.20039](http://arxiv.org/abs/2602.20039)|null|\n",
        "2602.20008": "|**2026-02-23**|**Token-UNet: A New Case for Transformers Integration in Efficient and Interpretable 3D UNets for Brain Imaging Segmentation**|我们提出了 Token-UNet，采用 TokenLearner 和 TokenFuser 模块将 Transformer 封装到 UNet 中。   虽然 Transformer 实现了医学成像中输入元素之间的全局交互，但当前的计算挑战阻碍了它们在通用硬件上的部署。 (Swin)UNETR 等模型通过合并 (Swin)Transformer 编码器来适应 UNet 架构，编码器处理每个表示输入的小子体积（$8^3$ 体素）的标记。   Transformer 注意力机制与 token 数量成二次方缩放，这与 3D 输入分辨率的立方缩放相关。   这项工作重新考虑了卷积和注意力的作用，引入了 Token-UNet，这是一系列 3D 分割模型，可以在受限的计算环境和时间范围内运行。   为了减轻计算需求，我们的方法保留了类似 UNet 模型的卷积编码器，并将 TokenLearner 应用于 3D 特征图。该模块从本地和全局结构中汇集预设数量的代币。   我们的结果表明，这种标记化有效地编码了任务相关信息，产生了自然可解释的注意力图。我们最重模型的内存占用、推理计算时间和参数计数减少到 SwinUNETR 值的 33\\%、10\\% 和 35\\%，具有更好的平均性能（SwinUNETR 的 Dice 得分为 86.75\\% $\\pm 0.19\\%$ 与我们的 87.21\\% $\\pm 0.35\\%$ 相比）。   这项工作为在计算资源有限的环境（例如 3D 医学成像）中进行更有效的培训开辟了道路。在有限的硬件设置中简化模型优化、微调和迁移学习可以加速方法的开发并使其多样化，从而造福研究界。|[2602.20008](http://arxiv.org/abs/2602.20008)|null|\n",
        "2602.19970": "|**2026-02-23**|**Discretization and regularization for the reconstruction of inhomogeneities by scattering measurements**|我们通过在时谐设置中执行有限数量的声学类型的散射测量来考虑重建不均匀性的逆问题。我们将重构设置为具有正则化的完全离散变分问题。这样的问题取决于各种参数，即测量次数、正则化参数和离散化参数，即我们对建模物理系统的亥姆霍兹型方程的未知系数进行离散化的网格的大小。我们通过收敛分析表明，人们可以仔细选择这些参数，使得离散正则化最小值问题的解是所寻找的逆问题解的良好近似。|[2602.19970](http://arxiv.org/abs/2602.19970)|null|\n",
        "2602.19916": "|**2026-02-23**|**Augmented Radiance Field: A General Framework for Enhanced Gaussian Splatting**|由于实时渲染性能，3D 高斯分布 (3DGS) 已成为辐射场重建的领先方法。然而，它对球谐函数进行颜色编码的依赖本质上限制了其分离漫反射和镜面反射分量的能力，使得准确表示复杂反射变得具有挑战性。为了解决这个问题，我们提出了一种新颖的增强高斯内核，它通过依赖于视图的不透明度来显式地模拟镜面反射效果。同时，我们引入了误差驱动补偿策略来提高现有 3DGS 场景中的渲染质量。我们的方法从二维高斯初始化开始，然后自适应地插入和优化增强型高斯核，最终产生增强的辐射场。实验表明，我们的方法不仅在渲染性能上超越了最先进的 NeRF 方法，而且还实现了更高的参数效率。项目页面：https://xiaoxinyyx.github.io/augs。|[2602.19916](http://arxiv.org/abs/2602.19916)|null|\n",
        "2602.19896": "|**2026-02-23**|**Monocular Mesh Recovery and Body Measurement of Female Saanen Goats**|萨能奶山羊以其高产奶量而闻名，其泌乳性能与其体型有着内在的联系，因此准确的 3D 身体测量对于评估产奶潜力至关重要，但现有的重建方法缺乏山羊特有的真实 3D 数据。为了解决这一限制，我们建立了 FemaleSaanenGoat 数据集，其中包含 55 只雌性 Saanen 山羊（6-18 个月）的同步八视图 RGBD 视频。使用多视图 DynamicFusion，我们将噪声、非刚性点云序列融合到高保真 3D 扫描中，克服了不规则表面和快速移动的挑战。基于这些扫描，我们开发了 SaanenGoat，这是一种专为雌性 Saanen 山羊设计的参数化 3D 形状模型。该模型具有一个精致的模板，具有 41 个骨骼关节和增强的乳房表示，并与我们的扫描数据一起注册。由 48 只山羊构建的综合形状空间可以精确呈现不同的个体差异。借助SaanenGoat模型，我们从单视图RGBD输入中获得高精度3D重建，并实现了六个关键身体尺寸的自动测量：身长、身高、胸宽、胸围、臀宽和臀高。实验结果证明了我们的方法在 3D 重建和身体测量方面的卓越准确性，为精准畜牧业中大规模 3D 视觉应用提供了一种新的范例。|[2602.19896](http://arxiv.org/abs/2602.19896)|null|\n",
        "2602.19874": "|**2026-02-23**|**BigMaQ: A Big Macaque Motion and Animation Dataset Bridging Image and 3D Pose Representations**|对动物动态和社会行为的认识是推进行为学、生态学、医学和神经科学的基础。深度学习的最新进展已经实现了视频中的自动行为识别，但三维 (3D) 姿势和形状的准确重建尚未集成到此过程中。特别是对于非人类灵长类动物，基于网格的跟踪工作落后于其他物种，使得姿势描述仅限于稀疏的关键点，无法完全捕捉动作动态的丰富性。为了解决这一差距，我们引入了 $\\textbf{Big Ma}$ca$\\textbf{Q}$ue 3D 运动和动画数据集 ($\\texttt{BigMaQ}$)，这是一个大型数据集，包含 750 多个恒河猴互动场景，并具有详细的 3D 姿势描述。扩展了之前基于表面的动物跟踪方法，我们通过将高质量的猕猴模板网格应用于个体猴子来构建特定于主题的纹理化身。这使我们能够提供比以前最先进的基于表面的动物跟踪方法更准确的姿势描述。从原始数据集中，我们推导出 BigMaQ500，这是一种动作识别基准，它将基于表面的姿势向量链接到多个个体猴子的单个帧。通过将从已建立的图像和视频编码器中提取的特征与姿势描述符进行配对，我们证明了在包含姿势信息时平均精度（mAP）的显着改进。通过这些贡献，$\\texttt{BigMaQ}$ 建立了第一个数据集，该数据集既将动态 3D 姿势形状表示集成到动物动作识别的学习任务中，又为推进非人类灵长类动物的视觉外观、姿势和社交互动的研究提供了丰富的资源。代码和数据可在 https://martinivis.github.io/BigMaQ/ 上公开获取。|[2602.19874](http://arxiv.org/abs/2602.19874)|null|\n",
        "2602.21195": "|**2026-02-24**|**Region of Interest Segmentation and Morphological Analysis for Membranes in Cryo-Electron Tomography**|冷冻电子断层扫描 (cryo-ET) 能够对生物结构（包括膜和膜蛋白）进行高分辨率、三维重建。感兴趣区域 (ROI) 的识别是科学成像的核心，因为它可以对复杂数据集中的特定结构特征进行隔离和定量分析。然而，在实践中，投资回报率通常是通过完整的结构分割和事后分析间接得出的。对于连续且几何复杂的结构（例如被分割为单个实体的膜），这种限制尤其明显。在这里，我们开发了 TomoROIS-SurfORA，这是一个两步框架，用于直接、形状无关的 ROI 分割和形态表面分析。 TomoROIS 执行基于深度学习的 ROI 分割，并且可以使用小型注释数据集从头开始训练，从而实现跨不同成像数据的实际应用。 SurfORA 将分段结构处理为点云和表面网格，以提取定量形态特征，包括膜间距离、曲率和表面粗糙度。它支持封闭和开放表面，并特别考虑开放表面，由于缺少楔形效应，开放表面在冷冻电子断层扫描中很常见。我们展示了两种工具，使用含有复杂几何形状的可变形囊泡的体外重构膜系统，能够自动定量分析膜接触位点和内陷等重塑事件。虽然此处在冷冻 ET 膜数据上进行了演示，但组合方法适用于更广泛的科学成像环境中的 ROI 检测和表面分析。|[2602.21195](http://arxiv.org/abs/2602.21195)|null|\n",
        "2602.21182": "|**2026-02-24**|**Circumventing the CAP Theorem with Open Atomic Ethernet**|CAP 定理通常被视为系统法则：在网络分区下，复制服务必须牺牲一致性或可用性。该定理在其标准异步网络模型中是正确的，但操作实践取决于在哪里可以观察到类似分区的现象，以及较低层如何丢弃或保留有关消息命运的语义信息。本文认为，开放原子以太网 (OAE) 改变了工程机制，使 CAP 权衡变得对应用程序可见，方法是：(i) 用端点状态的有限时间双边协调（我们称之为双同步的属性）取代即发即忘链路语义，以及 (ii) 通过八价网格避免 Clos 漏斗点，其中每个节点都可以充当本地修复的生成树的根。其结果不是消除硬图切割，而是通过在数百纳秒内检测和修复主要结构缺陷，大幅减少应用程序可见的“软分区”的频率和持续时间。我们将此观点与 Brewer 的原始 CAP 框架、Gilbert 和 Lynch 的形式化、Lee 等人的 CAL 定理（用表观延迟的定量度量取代二进制分区容差）以及 Abadi 的 PACELC 扩展联系起来。|[2602.21182](http://arxiv.org/abs/2602.21182)|null|\n",
        "2602.21175": "|**2026-02-24**|**Seeing Through Words: Controlling Visual Retrieval Quality with Language Models**|文本到图像检索是视觉语言学习中的一项基本任务，但在现实场景中，它经常受到简短且不明确的用户查询的挑战。此类查询通常只有一两个单词长，导致语义模糊，容易在不同的视觉解释之间发生冲突，并且缺乏对检索图像质量的明确控制。为了解决这些问题，我们提出了一种新的质量可控检索范例，它用上下文细节丰富了简短的查询，同时结合了图像质量的明确概念。我们的关键思想是利用生成语言模型作为查询完成功能，将未指定的查询扩展到描述性形式，以捕获细粒度的视觉属性，例如姿势、场景和美学。我们引入了一个通用框架，该框架在离散质量级别上条件查询完成，该质量级别源自相关性和美学评分模型，因此查询丰富不仅在语义上有意义，而且具有质量意识。由此产生的系统具有三个关键优势：1）灵活性，无需修改即可与任何预训练的视觉语言模型（VLM）兼容； 2) 透明、丰富的查询可由用户明确解释； 3）可控性，使检索结果能够转向用户偏好的质量水平。大量实验表明，我们提出的方法显着改善了检索结果并提供了有效的质量控制，弥补了现代 VLM 的表达能力与短用户查询的未指定性质之间的差距。我们的代码可在 https://github.com/Jianglin954/QCQC 获取。|[2602.21175](http://arxiv.org/abs/2602.21175)|null|\n",
        "2602.21169": "|**2026-02-24**|**Revisiting CPL with sign-switching density: to cross or not to cross the NECB**|最近的 DESI DR2 BAO 测量结果与 CMB 和 SNeIa 数据相结合，显示出对 CPL 参数化状态方程描述的动态暗能量 (DE) 的 $3.2σ$-$3.4σ$ 偏好。这些重建的一个特别显着的特征是从早期的幻影般的政权到晚期的精髓般的行为的明显转变。对于正定 DE 密度，这种转变通常被表述为在 $w(a)=-1$ 处穿过虚拟分界线 (PDL)。然而，允许 DE 密度变为负值，会使 PDL（在 $w(a)=-1$ 的意义上）作为全局分隔符变得非诊断性：物理上有意义的标准是零能量条件边界 (NECB)，$ρ_{\\rm DE}+p_{\\rm DE}=0$。因此，我们测试一旦承认幻象行为的替代实现，特别是通过符号切换 DE 密度，CPL 重建中对 NECB 交叉的数据驱动偏好是否持续存在。为此，我们引入并约束了 CPL 框架的两个受控现象学扩展，其特征是过去具有负 DE 阶段。在 CPL$\\to-Λ$ 模型中，切换历元与 CPL 推断的 NECB 交叉比例因子相关，产生早期负宇宙常数相位，而切换后的演化遵循 CPL 分支。在sCPL模型中，CPL状态方程始终保持不变，而能量密度的符号切换发生在独立的跃迁红移处。我们发现后期 BAO 和 SNeIa 数据驱动负密度相位超出其有效红移覆盖范围，并且这一要求是推断参数行为的主要驱动因素。虽然相对于基线 CPL，这两种模型在统计上都不受欢迎，但承认负 DE 相位通常会降低与宇宙学常数的偏差的显着性。|[2602.21169](http://arxiv.org/abs/2602.21169)|null|\n",
        "2602.21163": "|**2026-02-24**|**A Light Fixture Color Temperature and Color Rendering Index Measuring Device**|人造光源的相关色温 (CCT) 和显色指数 (CRI) 非常重要，因为它们对人类生物学和专业应用具有影响。尽管商用灯通常可以获得 CCT 信息，但通常不会报告 CRI。此外，测量这些参数的设备很难获得，因为它们需要分光光度计，而分光光度计通常是昂贵的设备。在此背景下，本工作详细设计和构建了一个仪表，从设备的结构部分、与传感器的接口、计算到补偿算法的实现，旨在构建分光光度计的专用功能，其设计不使用光学镜头。除了简化设备之外，这种方法还可以使测量不受光学镜头典型色差引起的色散的影响。所获得的原型被证明是有效的，它捕获了各种光源的光谱功率分布并计算它们的 CCT 和 CRI。|[2602.21163](http://arxiv.org/abs/2602.21163)|null|\n",
        "2602.21153": "|**2026-02-24**|**SPRITETOMESH: Automatic Mesh Generation for 2D Skeletal Animation Using Learned Segmentation and Contour-Aware Vertex Placement**|我们推出了 SPRITETOMESH，这是一个全自动管道，用于将 2D 游戏精灵图像转换为与 Spine2D 等骨骼动画框架兼容的三角形网格。创建动画就绪网格传统上是一个繁琐的手动过程，需要艺术家沿着视觉边界仔细放置顶点，这项任务通常每个精灵需要 15-60 分钟。我们的方法通过混合学习算法方法解决了这个问题。分割网络（带有 U-Net 解码器的 EfficientNet-B0 编码器）在来自 172 个游戏的超过 100,000 个精灵掩码对上进行训练，实现了 0.87 的 IoU，从任意输入图像中提供准确的二进制掩码。从这些掩模中，我们使用 Douglas-Peucker 简化和自适应弧细分提取外部轮廓顶点，并通过双边滤波多通道 Canny 边缘检测和轮廓跟踪放置沿视觉边界检测内部顶点。具有基于掩模的质心过滤的 Delaunay 三角测量产生最终的网格。通过受控实验，我们证明通过神经网络热图回归进行直接顶点位置预测对于此任务来说根本上是不可行的：热图解码器始终无法收敛（损失稳定在 0.061），而分割解码器在相同条件下正常训练。我们将此归因于顶点放置的固有艺术本质 - 相同的精灵可以通过多种不同的方式进行有效的网格划分。这个负面结果验证了我们的混合设计：在地面事实明确的情况下进行学习分割，在领域启发法适用的情况下进行算法放置。完整的管道在 3 秒内处理一个精灵，比手动创建速度提高了 300 倍至 1200 倍。我们向游戏开发社区发布经过训练的模型。|[2602.21153](http://arxiv.org/abs/2602.21153)|null|\n",
        "2602.21147": "|**2026-02-24**|**RAMSES-MCR: A consistent multi-group treatment of cosmic rays physics in momentum-space with the RAMSES code**|众所周知，宇宙射线（CR）在许多天体物理环境中发挥着关键作用：它们可以改变冲击动力学，影响星际介质的热化学和电离，通过驱动银河风来调节星系质量含量，并由活跃星系核的喷流释放。它们还通过γ射线发射、射电同步加速器和二次粒子产生作为重要的观测示踪剂。由于 CR 粒子在跨越数十年能量的动量空间中遵循幂律分布，并且由于扩散和辐射损失进一步塑造了这些光谱，因此在数值模拟中对光谱解析 CR 进行建模并评估该建模对气体动力学和观测特征的影响至关重要。我们在自适应网格细化代码 RAMSES 中提出了一种在动量空间中用于 CR 质子的一致多组谱方法，称为 RAMSES-MCR，该方法基于两矩形式主义，该形式主义在动量空间中演化 CR 能量和数密度及其相关通量。模拟的 CR 过程包括平流、各向异性/各向同性扩散、流动不稳定性、库仑和强子损失、绝热变化以及气体反馈。我们还表明，该方法可以自然地扩展到 CR 电子（例如包括同步加速器损耗）并推广到多种 CR 物种。该实施已根据一套标准多维测试进行了验证。最后，我们将 RAMSES-MCR 应用于超新星遗迹的三维膨胀，包括具有各向异性扩散和能量损失的 CR，并演示 CR 能量如何以动量相关的方式重新分布，并在扫雪阶段改变气体动量。|[2602.21147](http://arxiv.org/abs/2602.21147)|null|\n",
        "2602.21105": "|**2026-02-24**|**BrepGaussian: CAD reconstruction from Multi-View Images with Gaussian Splatting**|边界表示 (B-rep) 将 3D 实体建模为其显式边界：修剪的角、边和面。从非结构化数据中恢复 B-rep 表示是计算机视觉和图形领域一项具有挑战性且有价值的任务。深度学习的最新进展极大地改善了 3D 形状几何的恢复，但仍然依赖于密集和干净的点云，并且很难推广到新的形状。我们提出了 B-rep Gaussian Splatting (BrepGaussian)，这是一种从 2D 图像学习 3D 参数表示的新颖框架。我们采用具有可学习特征的高斯泼溅渲染器，然后采用特定的拟合策略。为了解开几何重建和特征学习，我们引入了一个两阶段学习框架，首先捕获几何和边缘，然后细化补丁特征以实现干净的几何和连贯的实例表示。大量的实验证明了我们的方法具有最先进的方法的卓越性能。我们将在接受后发布我们的代码和数据集。|[2602.21105](http://arxiv.org/abs/2602.21105)|null|\n",
        "2602.21103": "|**2026-02-24**|**Prompt-Level Distillation: A Non-Parametric Alternative to Model Fine-Tuning for Efficient Reasoning**|高级推理通常需要思想链提示，这是准确的，但会产生令人望而却步的延迟和大量的测试时间推理成本。标准的替代方案是对较小的模型进行微调，通常会牺牲可解释性，同时引入大量的资源和运营开销。为了解决这些限制，我们引入了即时级蒸馏 (PLD)。我们从教师模型中提取明确的推理模式，并将它们组织成学生模型系统提示的表达指令的结构化列表。使用 Gemma-3 4B 对 StereoSet 和 Contract-NLI 数据集进行评估，PLD 将 Macro F1 分数分别从 57% 提高到 90.0% 和 67% 提高到 83%，使这个紧凑的模型能够以可忽略的延迟开销匹配前沿性能。这些富有表现力的指令使决策过程变得透明，允许对逻辑进行全面的人工验证，使这种方法成为法律、金融和内容审核等受监管行业以及大容量用例和边缘设备的理想选择。|[2602.21103](http://arxiv.org/abs/2602.21103)|null|\n",
        "2602.21100": "|**2026-02-24**|**Skullptor: High Fidelity 3D Head Reconstruction in Seconds with Multi-View Normal Prediction**|从图像重建高保真 3D 头部几何形状对于广泛的应用至关重要，但现有方法面临根本性的限制。传统摄影测量可实现出色的细节，但需要大量相机阵列（25-200+ 视图）、大量计算以及在面部毛发等具有挑战性的区域进行手动清理。最近的替代方案提出了一个基本的权衡：基础模型可以实现高效的单图像重建，但缺乏精细的几何细节，而基于优化的方法可以实现更高的保真度，但需要密集的视图和昂贵的计算。我们通过结合两种范式优势的混合方法来弥补这一差距。我们的方法引入了多视图表面​​法线预测模型，该模型通过交叉视图注意力扩展单眼基础模型，以在前馈传递中产生几何一致的法线。然后，我们在逆向渲染优化框架中利用这些预测作为强大的几何先验来恢复高频表面细节。我们的方法优于最先进的单图像和多视图方法，实现了与密集视图摄影测量相当的高保真度重建，同时降低了相机要求和计算成本。代码和模型将被发布。|[2602.21100](http://arxiv.org/abs/2602.21100)|null|\n",
        "2602.22194": "|**2026-02-25**|**Electrical coupling of a horizontal dipole antenna to a dielectric half-space: applications to radio astronomy from the lunar surface**|月球的背面不受地面无线电频率干扰，也不受地球电离层的影响，应该为射电天文学和宇宙学实验提供独特的安静环境。 30 MHz 以下的射电天空很大程度上尚未被探索，并且被认为包含早期高红移宇宙中新物理的光谱特征。要在此频段实现精确测量，需要准确了解天线性能和系统学。对于即将到来的月球表面射电天文学任务，这种建模将具有挑战性，因为天线将部署在距离月球风化层上方波长一小部分的高度，天线和表面之间的强耦合会显着改变阻抗、辐射模式和效率。风化层的层状介电结构和介电常数随深度增加的趋势使这一挑战变得更加复杂，这两者都很难在数值模拟中忠实地表示。   在这项工作中，我们回顾了对介电半空间上方的简单水平偶极子（代表月球风化层）行为的理论预测，并将其与使用 Ansys HFSS 积分方程求解器获得的仿真结果进行比较。我们量化了代表性月球表面射电天文学实验的天线阻抗和波束方向图如何与天空耦合。结果表明，即使风化层上方的天线高度适度增加，表面感应效应也会迅速减弱。相反，放置在月球表面或非常靠近月球表面的偶极天线将表现出复杂的光谱响应，如果没有风化层特性的详细信息，系统控制将变得非常困难。|[2602.22194](http://arxiv.org/abs/2602.22194)|null|\n",
        "2602.22021": "|**2026-02-25**|**Budgeted Active Experimentation for Treatment Effect Estimation from Observational and Randomized Data**|估计异质治疗效果是数据驱动决策的核心，但工业应用常常面临有限的随机对照试验 (RCT) 预算与根据历史目标政策收集的丰富但有偏见的观察数据之间的根本紧张关系。尽管观测日志具有规模优势，但它们本质上受到政策引起的严重不平衡和重叠违规的影响，导致独立估计不可靠。我们提出了一个预算主动实验框架，该框架通过主动采样迭代增强因果效应估计的模型训练。通过利用观察先验，我们开发了一个针对提升估计不确定性、重叠赤字和域差异的采集函数，以选择信息最丰富的单元进行随机实验。我们建立有限样本偏差界限、通过鞅中心极限定理 (CLT) 的渐近正态性和极小极大下界来证明信息论最优性。对工业数据集的大量实验表明，我们的方法在成本受限的环境中显着优于标准随机基线。|[2602.22021](http://arxiv.org/abs/2602.22021)|null|\n",
        "2602.21929": "|**2026-02-25**|**Geometry-as-context: Modulating Explicit 3D in Scene-consistent Video Generation to Geometry Context**|场景一致的视频生成旨在创建基于摄像机轨迹探索 3D 场景的视频。以前的方法依赖具有外部存储器的视频生成模型来实现一致性，或者迭代 3D 重建和修复，这会在推理过程中由于不正确的中间输出、不可微分的过程和单独的模型而累积错误。为了克服这些限制，我们引入了“几何即上下文”。它使用自回归相机控制的视频生成模型迭代地完成以下步骤：（1）估计 3D 重建所需的当前视图的几何形状，以及（2）模拟和恢复 3D 场景渲染的新视图图像。在这个多任务框架下，我们开发了相机门控注意力模块，以增强模型有效利用相机姿势的能力。在训练阶段，利用文本上下文为了确定应该生成几何图像还是 RGB 图像，为了确保模型在推理过程中可以生成仅 RGB 的输出，从交错的文本-图像-几何训练序列中随机删除该方法，并在单向和前后轨迹的场景视频生成上进行了测试，结果表明其在保持场景一致性和摄像机控制方面优于以前的方法。|[2602.21929](http://arxiv.org/abs/2602.21929)|null|\n",
        "2602.21826": "|**2026-02-25**|**The Silent Spill: Measuring Sensitive Data Leaks Across Public URL Repositories**|各种平台公开了大量 URL，用于安全分析、存档和粘贴共享，例如 VirusTotal、URLScan.io、Hybrid Analysis、Wayback Machine 和 RedHunt。正如一些新闻文章和博客文章中所报道的那样，这些服务可能会无意中暴露包含敏感信息的链接。然而，还没有大规模的测量来量化此类暴露的程度。我们提出了一个自动化系统，可以检测和分析通过可公开访问的 URL 泄露的潜在敏感信息。该系统结合了词汇 URL 过滤、动态渲染、基于 OCR 的提取和内容分类来识别潜在的泄漏。我们将其应用于从公共扫描平台、粘贴网站和网络档案收集的 6,094,475 个 URL，识别出身份验证、财务、个人和文档相关领域的 12,331 个潜在风险。这些发现表明敏感信息仍然暴露，强调了自动检测以识别意外泄漏的重要性。|[2602.21826](http://arxiv.org/abs/2602.21826)|null|\n",
        "2602.21820": "|**2026-02-25**|**Joint Shadow Generation and Relighting via Light-Geometry Interaction Maps**|我们提出了光几何交互（LGI）图，这是一种从单眼深度编码光感知遮挡的新颖表示。与需要完整 3D 重建的光线追踪不同，LGI 能够可靠、准确地捕获基本的光影交互，并根据现成的 2.5D 深度图预测进行计算。 LGI 明确地将照明方向与几何形状联系起来，提供了一个受物理启发的先验来约束生成模型。如果没有这样的先验，这些模型通常会产生浮动阴影、不一致的照明和不可信的阴影几何形状。在此表示的基础上，我们提出了一个用于联合阴影生成和重新照明的统一管道（与将它们视为不相交任务的先前方法不同），捕获对于建模间接效果至关重要的照明和阴影的内在耦合。通过将 LGI 嵌入到桥匹配生成主干中，我们减少了歧义并强制执行物理上一致的光影推理。为了实现有效的训练，我们策划了第一个用于联合阴影和重新照明的大型基准数据集，涵盖反射、透明度和复杂的相互反射。实验表明，合成图像和真实图像的真实性和一致性有了显着提高。因此，LGI 将几何启发的渲染与生成建模联系起来，实现高效、物理一致的阴影生成和重新照明。|[2602.21820](http://arxiv.org/abs/2602.21820)|null|\n",
        "2602.21819": "|**2026-02-25**|**SemVideo: Reconstructs What You Watch from Brain Activity via Hierarchical Semantic Guidance**|从大脑活动重建动态视觉体验为探索人类视觉感知的神经机制提供了一条引人注目的途径。虽然基于功能磁共振成像的图像重建最近取得了显着的进展，但将这一成功扩展到视频重建仍然是一个重大挑战。当前的功能磁共振成像到视频重建方法始终遇到两个主要缺点：（i）跨帧的显着对象的视觉表示不一致，导致外观不匹配； (ii) 时间相干性差，导致运动错位或突然的帧过渡。为了解决这些限制，我们引入了 SemVideo，一种由分层语义信息引导的新型 fMRI 到视频重建框架。 SemVideo 的核心是 SemMiner，这是一个分层指导模块，它根据原始视频刺激构建三个级别的语义线索：静态锚点描述、面向运动的叙述和整体摘要。利用这种语义指导，SemVideo 包含三个关键组件：语义对齐解码器，将 fMRI 信号与源自 SemMiner 的 CLIP 式嵌入对齐；运动适应解码器，使用新颖的三方注意力融合架构重建动态运动模式；以及条件视频渲染，利用分层语义指导进行视频重建。在 CC2017 和 HCP 数据集上进行的实验表明，SemVideo 在语义对齐和时间一致性方面均实现了卓越的性能，在 fMRI 到视频重建方面树立了新的最先进水平。|[2602.21819](http://arxiv.org/abs/2602.21819)|null|\n",
        "2602.21778": "|**2026-02-25**|**From Statics to Dynamics: Physics-Aware Image Editing with Latent Transition Priors**|基于指令的图像编辑在语义对齐方面取得了显着的成功，但当编辑涉及复杂的因果动态（例如折射或材料变形）时，最先进的模型经常无法呈现物理上合理的结果。我们将此限制归因于主流范式，该范式将编辑视为图像对之间的离散映射，它仅提供边界条件并且未指定过渡动态。为了解决这个问题，我们将物理感知编辑重新表述为预测物理状态转换，并引入了 PhysicTran38K，这是一个基于视频的大型数据集，包含跨五个物理域的 38K 转换轨迹，通过两级过滤和约束感知注释管道构建。在此监督的基础上，我们提出了PhysicEdit，一个配备文本-视觉双重思维机制的端到端框架。它将用于物理基础推理的冻结 Qwen2.5-VL 与可学习的转换查询相结合，为扩散主干提供时间步自适应视觉指导。实验表明，PhysicEdit 在物理真实感方面比 Qwen-Image-Edit 提高了 5.9%，在基于知识的编辑方面提高了 10.1%，为开源方法树立了新的最先进水平，同时保持与领先的专有模型的竞争力。|[2602.21778](http://arxiv.org/abs/2602.21778)|null|\n",
        "2602.21685": "|**2026-02-25**|**Adaptive isogeometric analysis of high-order phase-field fracture based on THB-splines**|近几十年来，固体中断裂扩展的研究越来越依赖于相场模型。最近的一些贡献强调了这种方法在静态和动态框架中的潜力。然而，一个主要限制仍然是高计算成本。已经确定了两种主要策略来缓解这个问题：使用局部细化网格和采用高阶模型。在这项工作中，我们利用截断分层 B 样条（THB 样条）引入了高阶相场公式（AT1 和 AT2）的自适应模拟，主要关注二维断裂问题。|[2602.21685](http://arxiv.org/abs/2602.21685)|null|\n",
        "2602.21668": "|**2026-02-25**|**Space-Time Forecasting of Dynamic Scenes with Motion-aware Gaussian Grouping**|预测动态场景仍然是计算机视觉中的一个基本挑战，因为有限的观测使得捕捉连贯的物体级运动和长期时间演化变得困难。我们提出了运动组感知高斯预测 (MoGaF)，这是一个基于 4D 高斯泼溅表示的长期场景外推框架。 MoGaF 引入了运动感知高斯分组和分组优化，以在刚性和非刚性区域上强制执行物理一致的运动，从而产生空间相干的动态表示。利用这种结构化的时空表示，轻量级预测模块可以预测未来的运动，从而实现现实且时间稳定的场景演化。对合成数据集和真实数据集的实验表明，MoGaF 在渲染质量、运动合理性和长期预测稳定性方面始终优于现有基线。我们的项目页面位于 https://slime0519.github.io/mogaf|[2602.21668](http://arxiv.org/abs/2602.21668)|null|\n",
        "2602.21656": "|**2026-02-25**|**Pure-amplitude holograms for high-efficiency generation of phase radial grating based radial carpet beams: Theory and experiments under plane-wave and Gaussian illumination**|本研究介绍了一种用于生成径向地毯光束 (RCB) 的纯振幅全息图 (PAH)，传统上使用纯相位径向光栅 (PRG) 生成径向地毯光束 (RCB)。全息图是通过将二元 PRG 的传输函数嵌入到幅度线性光栅的余弦项的相位参数中来设计的。当用平面波照射时，该全息图会生成非零衍射级的 RCB，而当用高斯光束照射时，它会在特定的传播距离处生成类似 RCB 的图案。这种方法完全消除了对复杂且昂贵的空间光调制器（SLM）的需求。该研究提出了来自此类全息图的平面光束和高斯光束的衍射理论，包括来自 PRG 的高斯光束衍射的具体理论处理。通过理论分析和实验，我们证明了当照明光束是平面波时，由于衍射级数乘以嵌入式基础PRG的相位幅度所产生的相位幅度增强，如何在不同的衍射级产生不同的RCB。对于高斯光束情况，我们展示了如何出于相同的原因在不同的衍射级生成不同的类似 RCB 的图案，尽管仅在特定的传播距离处。实验和数值结果表明，该技术产生的 RCB 和类似 RCB 的图案的有用功率约为 SLM 生成的同类图案的五倍，显示出显着更高的功率效率。这一优点使得所提出的方法非常适合多重光捕获和自由空间光通信等应用。|[2602.21656](http://arxiv.org/abs/2602.21656)|null|\n",
        "2602.23359": "|**2026-02-26**|**SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation**|我们将遮挡推理视为 3D 布局条件生成的一个基本但被忽视的方面。它对于合成具有深度一致的几何形状和比例的部分遮挡的对象至关重要。虽然现有方法可以生成遵循输入布局的真实场景，但它们通常无法对精确的对象间遮挡进行建模。我们提出了 SeeThrough3D，这是一种用于 3D 布局条件生成的模型，可显式模拟遮挡。我们引入了遮挡感知 3D 场景表示 (OSCR)，其中对象被描绘为放置在虚拟环境中的半透明 3D 框，并从所需的摄像机视角进行渲染。透明度对隐藏对象区域进行编码，使模型能够推理遮挡，而渲染的视点在生成过程中提供显式的相机控制。我们通过引入一组从我们渲染的 3D 表示派生的视觉标记来调节基于预训练流的文本到图像图像生成模型。此外，我们应用屏蔽自注意力将每个对象边界框准确地绑定到其相应的文本描述，从而能够准确生成多个对象而无需对象属性混合。为了训练模型，我们构建了一个包含具有强对象间遮挡的多种多对象场景的合成数据集。 SeeThrough3D 可以有效地推广到看不见的对象类别，并通过逼真的遮挡和一致的相机控制实现精确的 3D 布局控制。|[2602.23359](http://arxiv.org/abs/2602.23359)|null|\n",
        "2602.23311": "|**2026-02-26**|**Data-Efficient Generative Modeling of Non-Gaussian Global Climate Fields via Scalable Composite Transformations**|运行物理气候模型的计算成本过高，阻碍了量化未来气候预测的不确定性，这严重限制了训练数据的可用性。我们提出了一个数据有效的框架，用于模拟全球气候场的内部变化，专门用于克服这些样本大小的限制。受联结建模的启发，我们的方法通过对多元标准正态空间的复合变换构建了高度表达的联合分布。我们将用于空间依赖性建模的非参数贝叶斯传输图与灵活的、空间变化的边际模型相结合，这对于捕获非高斯行为和重尾极值至关重要。这些边际由参数模型定义，然后进行半参数 B 样条校正以捕获复杂的分布特征。使用具有低秩近似的高斯过程先验对边际参数进行空间平滑，使计算成本在空间维度上呈线性。当应用于超过 50,000 个网格位置的全球对数降水率场时，我们的随机替代方法实现了高保真度，准确量化了气候分布的空间依赖性和边际特征（包括尾部）。它仅使用 10 个训练样本，其性能优于使用 80 个样本训练的最先进的竞争对手，有效地将气候研究的计算预算增加了八倍。我们在 https://github.com/jobbrachem/ppptm 提供了 Python 实现。|[2602.23311](http://arxiv.org/abs/2602.23311)|null|\n",
        "2602.23257": "|**2026-02-26**|**Randomization Tests in Switchback Experiments**|当单元级随机化不可行、结果汇总或用户干扰不可避免时，会广泛使用折返实验（随着时间的推移交替处理和控制）。在实践中，实验必须支持快速的产品周期，因此团队经常在有限的时间内进行研究，并使用适度的样本做出决策。与此同时，这些时间索引环境中的结果表现出序列依赖性、季节性和偶尔的重尾冲击，而时间干扰（结转或预期）可能会使标准渐近和朴素随机化检验变得不可靠。在本文中，我们开发了一个随机化测试框架，该框架仅使用已知的分配机制，为几个感兴趣的零假设提供有限样本有效、无分布的 p 值，而不对结果过程进行参数假设。对于利益的因果效应，我们施加两个原始条件——非预期和有限的结转范围 m——并基于事前将设计块汇集到“部分”的基础上构造条件随机化测试（CRT），这产生了易于处理的条件分配法并确保焦点结果的可归责性。我们提供用于学习结转窗口和评估非预期的诊断，并且我们引入了学生化的 CRT，以实现会话弱零值，以渐近有效性适应会话内的季节性。使用 AR(1) 噪声指导设计和分析选择的分布式滞后效应下的功率近似，以及仿真证明了相对于常见替代方案的有利尺寸和功率。我们的框架自然地扩展到其他时间索引设计。|[2602.23257](http://arxiv.org/abs/2602.23257)|null|\n",
        "2602.23172": "|**2026-02-26**|**Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking**|捕捉 4D 时空环境对于机器人在动态环境中安全可靠的运行至关重要。然而，大多数现有方法仅解决问题的一方面：它们要么通过边界框提供粗略的几何跟踪，要么提供详细的 3D 结构，例如缺乏明确时间关联的基于体素的占用。在这项工作中，我们提出了用于 4D 全景占用跟踪 (LaGS) 的潜在高斯泼溅，它在整体方向上推进了时空场景理解。我们的方法将基于相机的端到端跟踪与基于掩模的多视图全景占​​用预测相结合，并解决了通过新颖的潜在高斯泼溅方法将多视图信息有效聚合到 3D 体素网格中的关键挑战。具体来说，我们首先将观察结果融合到 3D 高斯中，作为 3D 场景的稀疏的以点为中心的潜在表示，然后将聚合的特征分布到由基于掩模的分割头解码的 3D 体素网格上。我们在 Occ3D nuScenes 和 Waymo 数据集上评估 LaGS，实现了 4D 全景占用跟踪的最先进性能。我们在 https://lags.cs.uni-freiburg.de/ 提供代​​码。|[2602.23172](http://arxiv.org/abs/2602.23172)|null|\n",
        "2602.23163": "|**2026-02-26**|**A Decision-Theoretic Formalisation of Steganography With Applications to LLM Monitoring**|大型语言模型开始展现隐写能力。这种能力可能会让错位的模型逃避监督机制。然而，缺乏检测和量化此类行为的原则性方法。隐写术的经典定义以及基于它们的检测方法需要已知的非隐写信号的参考分布。对于法学硕士中的隐写推理来说，知道这样的参考分布是不可行的；这使得这些方法不再适用。我们提出了另一种选择，\\textbf{隐写术的决策理论观点}。我们的核心观点是，隐写术在能够和不能解码隐藏内容（存在于隐写信号中）的代理之间造成了可用信息的不对称，而这种潜在的不对称性可以从代理的可观察行为中推断出来。为了形式化这个观点，我们引入了广义的$\\mathcal{V}$-信息：一个用于测量某些输入中可用信息量的实用框架。我们用它来定义\\textbf{隐写间隙}——一种通过将隐写信号的下游效用与能够和不能解码隐藏内容的代理进行比较来量化隐写的度量。我们凭经验验证了我们的形式主义，并表明它可以用于检测、量化和减轻法学硕士中的隐写推理。|[2602.23163](http://arxiv.org/abs/2602.23163)|null|\n",
        "2602.23156": "|**2026-02-26**|**Coupling of the continuum and semiclassical limit. Part I: convergence of eigenvalues**|我们分析连续体 $ \\frac{1}{2} Δ+ λ_N^2 V$ 中的半经典 $d$ 维薛定谔算子，在网格上离散化，间距与 $1/N$ 成比例。半经典参数 $λ_N$ 选择为 $λ_N = N^{1 - γ}$，其中 $γ\\in (-1,1)$，这确保 $N$ 同时控制半经典极限和连续极限。我们证明离散算子的所有特征值都收敛于连续统的特征值，如 $λ_N\\to\\infty$。除了这个半经典域之外，在谐振子的情况下，我们进一步讨论 $γ\\in \\mathbb{R} \\setminus (-1,1)$ 的谱渐近性，从而充分表征 $γ\\in\\mathbb{R}$ 所有可能值的特征值行为。|[2602.23156](http://arxiv.org/abs/2602.23156)|null|\n",
        "2602.23097": "|**2026-02-26**|**HELIOS: A surface integral equation software for light scattering in homogeneous, periodic, and stratified environments**|我们推出了 HELIOS（均质和分层介质光学散射），这是一种开源表面积分方程 (SIE) 软件，旨在对嵌入均匀或分层介质和周期性背景中的粒子进行的光散射进行建模。该代码实现了 Poggio-Miller-Chang-Harrington-Wu-Tsai (PMCHWT) 公式，该公式在解决可穿透物体的散射问题方面表现出了卓越的可靠性。域边界使用三角形网格进行离散化，在此基础上使用 Rao-Wilton-Glisson (RWG) 基函数扩展电磁表面电流密度。对于周期性结构，例如光子晶体和超表面，HELIOS 采用埃瓦尔德变换来有效评估与 2D 晶格相关的无穷级数。关于分层媒体，该代码对分层媒体格林张量采用矩阵友好的方法，计算索末菲积分并通过制表插值方案加速计算。源代码是用 C++ 实现的，而 Python 界面则管理工作流程，包括模拟设置、求解器运行和后处理。 HELIOS 的准确性和多功能性通过涵盖其所有功能的各种示例得到了证明。|[2602.23097](http://arxiv.org/abs/2602.23097)|null|\n",
        "2602.23040": "|**2026-02-26**|**PackUV: Packed Gaussian UV Maps for 4D Volumetric Video**|体积视频提供身临其境的 4D 体验，但仍然难以大规模重建、存储和流式传输。现有的基于高斯分布的方法实现了高质量的重建，但在长序列、时间不一致的情况下会崩溃，并且在大运动和去遮挡下会失败。此外，它们的输出通常与传统的视频编码管道不兼容，从而阻碍了实际应用。   我们引入了 PackUV，这是一种新颖的 4D 高斯表示，可将所有高斯属性映射到一系列结构化、多尺度 UV 图集，从而实现紧凑的图像原生存储。为了拟合多视图视频的这种表示，我们提出了 PackUV-GS，这是一种时间一致的拟合方法，可以直接优化 UV 域中的高斯参数。流引导的高斯标记和视频关键帧模块可以识别动态高斯，稳定静态区域，并即使在大运动和去遮挡的情况下也能保持时间连贯性。由此产生的 UV 图集格式是第一个与标准视频编解码器（例如 FFV1）兼容的统一体积视频表示形式，且不会损失质量，从而能够在现有多媒体基础设施中实现高效流式传输。   为了评估长时间的体积捕获，我们提出了 PackUV-2B，这是迄今为止最大的多视图视频数据集，具有 50 多个同步摄像机、大量运动以及跨 100 个序列和 2B（十亿）帧的频繁遮挡。大量实验表明，我们的方法在渲染保真度方面超越了现有基线，同时可扩展到长达 30 分钟的序列且质量一致。|[2602.23040](http://arxiv.org/abs/2602.23040)|null|\n",
        "2602.23038": "|**2026-02-26**|**Parallelizable Search-Space Decomposition for Large-Scale Combinatorial Optimization Problems Using Ising Machines**|组合优化问题在工业中至关重要。然而，许多 COP 都是 NP 困难的，导致搜索空间随着问题大小呈指数增长，并使大规模实例在计算上变得困难。传统的求解器通常将问题视为整体实体，随着结构复杂性的增加，导致效率显着下降。为了解决这个问题，我们提出了一种新颖的搜索空间分解方法，该方法利用变量的固有结构来系统地减小主问题的规模。我们将变量和单个变量成本之间的交互成本表述为约束最大割问题，并使用惩罚项将其转换为二次无约束二元优化公式。伊辛模型求解器用于将问题快速分解为独立的小规模子问题，随后使用数学优化求解器并行求解。我们在有能力的车辆路径问题上验证了该方法。结果证明了三个显着的好处：可行解率的大幅提高、收敛速度加快、在 1 分钟内达到朴素方法需要 30 分钟才能达到的精度，以及高达 95.32% 的变量减少。这些发现表明搜索空间分解是有效解决大规模组合优化问题的一种有前途的策略。|[2602.23038](http://arxiv.org/abs/2602.23038)|null|\n",
        "2602.23022": "|**2026-02-26**|**DMAligner: Enhancing Image Alignment via Diffusion Model Based View Synthesis**|图像对齐是计算机视觉中的一项基本任务，具有广泛的应用。现有方法主要采用基于光流的图像扭曲。然而，该技术容易受到遮挡和照明变化等常见挑战的影响，导致对齐视觉质量下降并影响下游任务的准确性。在本文中，我们提出了 DMAaligner，这是一种基于扩散的框架，通过面向对齐的视图合成进行图像对齐。 DMAligner 旨在从新的角度应对图像对齐的挑战，采用基于生成的解决方案，展示强大的功能并避免与基于流的图像扭曲相关的问题。具体来说，我们提出了一种动态感知扩散训练方法，用于学习条件图像生成，合成图像对齐的新颖视图。它结合了动态感知掩模生成（DMP）模块，可以自适应地区分动态前景区域和静态背景，使扩散模型能够更有效地应对经典方法难以解决的挑战。此外，我们使用 Blender 开发了动态场景图像对齐 (DSIA) 数据集，其中包括 1,033 个室内和室外场景，以及为图像对齐量身定制的超过 30K 图像对。大量的实验结果证明了所提出的方法在 DSIA 基准以及一系列广泛使用的视频数据集上进行定性比较的优越性。我们的代码可在 https://github.com/boomluo02/DMAligner 获取。|[2602.23022](http://arxiv.org/abs/2602.23022)|null|\n"
    },
    "具生智能&自动驾驶": {
        "2602.20134": "|**2026-02-23**|**Modeling Epidemiological Dynamics Under Adversarial Data and User Deception**|流行病学模型越来越依赖自我报告的行为数据，例如疫苗接种状况、口罩使用情况和社交距离遵守情况，以预测疾病传播并评估非药物干预措施 (NPI) 的影响。虽然这些数据提供了有价值的实时见解，但由于个人为了避免处罚、获得福利或表达对公共卫生当局的不信任而采取的动机，它们往往会受到战略误报的影响。为了解释这种人类行为，在本文中，我们引入了一种博弈论框架，该框架将人口与公共卫生当局之间的互动建模为信号博弈。个人（发送者）选择如何报告他们的行为，而公共卫生当局（接收者）则根据可能扭曲的信号更新他们的流行病学模型。我们重点关注围绕掩蔽和疫苗接种的欺骗行为，分析性地描述博弈均衡结果，并评估在通过政策干预维持流行病控制的同时，欺骗行为的容忍程度。我们的结果表明，随着时间的推移，以最小的欺骗程度实现分离平衡会将感染率降至接近于零。值得注意的是，即使在汇集均衡中普遍存在不诚实的情况下，精心设计的发送者和接收者策略仍然可以保持有效的流行病控制。这项工作增进了对流行病学中对抗性数据的理解，并提供了在存在战略用户行为的情况下设计更强大的公共卫生模型的工具。|[2602.20134](http://arxiv.org/abs/2602.20134)|null|\n",
        "2602.20119": "|**2026-02-23**|**NovaPlan: Zero-Shot Long-Horizon Manipulation via Closed-Loop Video Language Planning**|解决长期任务需要机器人将高级语义推理与低级物理交互相结合。虽然视觉语言模型 (VLM) 和视频生成模型可以分解任务并想象结果，但它们通常缺乏现实世界执行所需的物理基础。我们引入了 NovaPlan，这是一个分层框架，它将闭环 VLM 和视频规划与几何接地机器人执行相结合，以实现零样本长视野操作。在高层，VLM 规划器将任务分解为子目标，并在闭环中监控机器人的执行情况，使系统能够通过自主重新规划从单步故障中恢复。为了计算低级机器人动作，我们从生成的视频中提取并利用与任务相关的对象关键点和人手姿势作为运动学先验，并采用切换机制来选择更好的动作作为机器人动作的参考，即使在严重遮挡或深度不准确的情况下也能保持稳定的执行。我们展示了 NovaPlan 在三项长期任务和功能操作基准（FMB）上的有效性。我们的结果表明，NovaPlan 可以执行复杂的组装任务并表现出灵巧的错误恢复行为，而无需任何事先演示或培训。项目页面：https://nova-plan.github.io/|[2602.20119](http://arxiv.org/abs/2602.20119)|null|\n",
        "2602.20060": "|**2026-02-23**|**MeanFuser: Fast One-Step Multi-Modal Trajectory Generation and Adaptive Reconstruction via MeanFlow for End-to-End Autonomous Driving**|生成模型在轨迹规划方面显示出了巨大的潜力。最近的研究表明，锚引导生成模型可以有效地模拟驾驶行为的不确定性并提高整体性能。然而，这些方法依赖于离散的锚词汇，这些词汇必须在测试期间充分覆盖轨迹分布以确保鲁棒性，从而导致词汇大小和模型性能之间的固有权衡。为了克服这一限制，我们提出了 MeanFuser，一种端到端自动驾驶方法，通过三个关键设计提高效率和鲁棒性。 （1）我们引入高斯混合噪声（GMN）来指导生成采样，实现轨迹空间的连续表示并消除对离散锚词汇的依赖。 （2）我们将“MeanFlow Identity”应用于端到端规划，它对 GMN 和轨迹分布之间的平均速度场进行建模，而不是普通流匹配方法中使用的瞬时速度场，有效消除 ODE 求解器的数值误差并显着加速推理。（3）我们设计了一个轻量级自适应重建模块（ARM），使模型能够从所有采样提案中隐式选择，或者在通过注意力权重没有一个令人满意的情况下重建新轨迹。闭环基准测试表明，MeanFuser 在没有 PDM 分数监督的情况下实现了出色的性能，并且具有出色的推理效率，为端到端自动驾驶提供了强大而高效的解决方案。|[2602.20060](http://arxiv.org/abs/2602.20060)|null|\n",
        "2602.20057": "|**2026-02-23**|**AdaWorldPolicy: World-Model-Driven Diffusion Policy with Online Adaptive Learning for Robotic Manipulation**|有效的机器人操作需要能够预测物理结果并适应现实世界环境的策略。有效的机器人操作需要能够预测物理结果并适应现实世界环境的策略。在这项工作中，我们引入了一个统一的框架，即具有在线自适应学习的世界模型驱动扩散策略（AdaWorldPolicy），以在动态条件下以最少的人类参与增强机器人操作。我们的核心见解是，世界模型提供了强大的监督信号，使得动态环境中的在线自适应学习成为可能，并可以通过力-扭矩反馈来补充，以减轻动态力的变化。我们的 AdaWorldPolicy 集成了世界模型、动作专家和力预测器 - 所有这些都以互连的流量匹配扩散变压器 (DiT) 的形式实现。它们通过多模态自注意力层互连，实现联合学习的深度特征交换，同时保留其独特的模块化特征。我们进一步提出了一种新颖的在线自适应学习（AdaOL）策略，该策略可以在“行动生成”模式和“未来想象”模式之间动态切换，以驱动所有三个模块的反应性更新。这创建了一个强大的闭环机制，可以以最小的开销适应视觉和物理域的变化。在一系列模拟和真实机器人基准测试中，我们的 AdaWorldPolicy 实现了最先进的性能，具有对分布外场景的动态自适应能力。|[2602.20057](http://arxiv.org/abs/2602.20057)|null|\n",
        "2602.19968": "|**2026-02-23**|**Probabilistic Photonic Computing**|概率计算擅长近似组合问题和建模不确定性。然而，将传统的确定性硬件用于概率模型具有挑战性：（伪）随机数生成会引入计算开销和额外的数据混洗，这对于需要低延迟的安全关键应用（例如自动驾驶）尤其不利。因此，迫切需要创新的概率计算架构，以合理的能耗实现低延迟。物理计算提供了一个有前途的解决方案，因为这些系统不依赖于数据的抽象确定性表示，而是直接以物理量对信息进行编码。因此，它们可以与物理熵源无缝集成，从而实现固有的概率架构。由于可用带宽大、数据编码的多个正交自由度以及内存计算和并行数据传输的最佳特性，光子计算是一个突出的变体。在这里，我们重点介绍物理光子计算和光子随机数生成方面的关键进展。我们提供有关概率光子处理器实现的见解，并就其对人工智能系统的影响和未来挑战提供我们的观点。|[2602.19968](http://arxiv.org/abs/2602.19968)|null|\n",
        "2602.19941": "|**2026-02-23**|**Probing Dust in the MWC 480 Disk from Millimeter to Centimeter Wavelengths**|我们对 MWC 480 周围的圆盘进行了深度、高分辨率（$\\sim$100 mas）Karl G. Jansky 甚大阵列 (VLA) Ka 波段 (9.1 毫米) 观测，并通过与档案阿塔卡马大型毫米/亚毫米阵列 (ALMA) 0.87、1.17、1.33 和 3.0 毫米数据的组合分析推断尘埃属性。首次在 9.1 毫米处检测到 95 au (B95) 处突出的尘埃环，而 160 au 处微弱的外环并未显露出来。通过非参数可见度建模，我们确定了两个新的环形特征：所有波长范围内 20-50 au 内的平台，以及 B95 环外部 0.87、1.17 和 1.33 毫米处的肩部，与行星盘相互作用的特征一致。我们发现 B95 环的宽度在整个波长范围内保持恒定，这表明碎片在径向扩散中占主导地位，或者环内存在未解析的子结构。解析光谱模型产生了两类尘埃解决方案，它们同样能很好地再现观测结果：致密颗粒或高度多孔（90％）的颗粒，其中碳质成分分别以难熔有机物或无定形碳为主。推断的最大晶粒尺寸在两个环的位置达到峰值，并在 B95 环内达到厘米。两种灰尘混合物的总灰尘质量为 $860^{+95}_{-78}\\rm~M_\\oplus$/$1500^{+440}_{-330}\\rm~M_\\oplus$（内盘中的大/小颗粒溶液）和 $230^{+14}_{-13}\\rm~M_\\oplus$。仅 B95 环就分别包含 $100^{+5}_{-5}\\rm~M_\\oplus$ 和 $43^{+2}_{-2}\\rm~M_\\oplus$，足以组装巨行星的核心。最后，我们强调了宽带、多波长观测在更好地限制原行星盘中的尘埃成分和孔隙率方面的力量。|[2602.19941](http://arxiv.org/abs/2602.19941)|null|\n",
        "2602.19735": "|**2026-02-23**|**VGGT-MPR: VGGT-Enhanced Multimodal Place Recognition in Autonomous Driving Environments**|在自动驾驶中，强大的位置识别对于全局定位和闭环检测至关重要。虽然多模态位置识别 (MPR) 中相机和 LiDAR 数据的模态间融合在克服单模态对应方法的局限性方面表现出了希望，但现有的 MPR 方法基本上只关注手工制作的融合策略和需要昂贵的再训练的高度参数化的主干网。为了解决这个问题，我们提出了 VGGT-MPR，这是一种多模态地点识别框架，采用视觉几何接地变换器（VGGT）作为统一的几何引擎，用于全局检索和重新排序。在全局检索阶段，VGGT通过先前的深度感知和点图监督提取几何丰富的视觉嵌入，并用预测的深度图致密稀疏的LiDAR点云以改善结构表示。这增强了融合多模态特征的辨别能力，并生成用于快速检索的全局描述符。除了全局检索之外，我们还设计了一种免训练的重新排序机制，该机制利用 VGGT 的跨视图关键点跟踪功能。通过将掩模引导的关键点提取与置信感知对应评分相结合，我们提出的重新排序机制有效地细化了检索结果，而无需额外的参数优化。对大规模自动驾驶基准的大量实验和我们自行收集的数据表明，VGGT-MPR 实现了最先进的性能，对严重的环境变化、视角转换和遮挡表现出强大的鲁棒性。我们的代码和数据将公开。|[2602.19735](http://arxiv.org/abs/2602.19735)|null|\n",
        "2602.19710": "|**2026-02-23**|**Universal Pose Pretraining for Generalizable Vision-Language-Action Policies**|现有的视觉-语言-动作（VLA）模型经常遭受特征崩溃和训练效率低下的困扰，因为它们将高级感知与稀疏的、特定于实施例的动作监督纠缠在一起。由于这些模型通常依赖于针对视觉问答 (VQA) 进行优化的 VLM 主干，因此它们擅长语义识别，但经常忽略决定不同动作模式的微妙 3D 状态变化。   为了解决这些未对准问题，我们提出了 Pose-VLA，这是一种解耦范例，它将 VLA 训练分为预训练阶段，用于在统一的以相机为中心的空间中提取通用 3D 空间先验，以及后训练阶段，用于在机器人特定的动作空间内进行有效的实施例对齐。通过引入离散姿势标记作为通用表示，Pose-VLA 将来自不同 3D 数据集的空间基础与来自机器人演示的几何级轨迹无缝集成。我们的框架遵循两阶段预训练流程，通过姿势建立基本的空间基础，然后通过轨迹监督进行运动对齐。   广泛的评估表明，Pose-VLA 在 RoboTwin 2.0 上取得了最先进的结果，平均成功率为 79.5%，在 LIBERO 上的竞争表现为 96.0%。现实世界的实验进一步展示了跨不同对象的强大泛化能力，每个任务仅使用 100 个演示，验证了我们预训练范例的效率。|[2602.19710](http://arxiv.org/abs/2602.19710)|null|\n",
        "2602.19634": "|**2026-02-23**|**Compositional Planning with Jumpy World Models**|利用时间抽象进行规划的能力是智能决策的核心。我们不是对原始动作进行推理，而是研究将预先训练的策略组成为临时扩展动作的代理，从而能够解决任何一个成员无法单独解决的复杂任务。这种组合规划仍然难以捉摸，因为长期预测中的复合误差使得估计排序策略引起的访问分布变得具有挑战性。在 arXiv:2206.08736 中引入的几何政策组合框架的推动下，我们通过学习多步动态的预测模型（所谓的跳跃世界模型）来应对这些挑战，这些模型以非政策方式捕获跨多个时间尺度的预训练政策引起的状态占用。在时间差异流 (arXiv:2503.09817) 的基础上，我们通过新颖的一致性目标增强了这些模型，该目标可以跨时间尺度调整预测，从而提高长期预测准确性。我们进一步演示了如何结合这些生成预测来估计在不同时间尺度上执行任意策略序列的价值。根据经验，我们发现，在具有挑战性的操作和导航任务上，使用跳跃世界模型进行组合规划可以显着提高各种基本策略的零样本性能，平均比在长视野任务上使用原始操作进行规划相对提高了 200%。|[2602.19634](http://arxiv.org/abs/2602.19634)|null|\n",
        "2602.19571": "|**2026-02-23**|**HOCA-Bench: Beyond Semantic Perception to Predictive World Modeling via Hegelian Ontological-Causal Anomalies**|视频法学硕士在语义感知方面稳步提高，但在预测世界建模方面仍然存在不足，而预测世界建模是物理基础智能的核心。我们推出 HOCA-Bench，这是一个通过黑格尔透镜描述物理异常的基准。 HOCA-Bench 将异常分为两种类型：本体异常（实体违反其自身的定义或持久性）和因果异常（交互违反物理关系）。我们使用最先进的生成视频模型作为对抗模拟器，构建了一个包含 1,439 个视频（3,470 个 QA 对）的测试平台。对 17 个视频法学硕士的评估显示出明显的认知滞后：模型经常识别静态本体论违规（例如形状突变），但与因果机制（例如重力或摩擦）作斗争，因果任务的性能下降超过 20%。 System-2“思维”模式改善了推理，但并没有缩小差距，这表明当前的架构比应用基本物理定律更容易识别视觉模式。|[2602.19571](http://arxiv.org/abs/2602.19571)|null|\n",
        "2602.21172": "|**2026-02-24**|**NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning**|视觉-语言-动作（VLA）模型通过用统一的端到端架构取代模块化管道来推进自动驾驶。然而，当前的 VLA 面临两个昂贵的要求：（1）海量数据集收集，（2）密集推理注释。在这项工作中，我们用 \\modelname 解决了这两个挑战（\\textbf{No} \\textbf{R}easoning for \\textbf{D}riving）。与现有的 VLA 相比，\\modelname 实现了具有竞争力的性能，同时对 $<$60\\% 的数据进行了微调，并且没有推理注释，从而减少了 3$\\times$ 的标记。我们发现，当标准组相对策略优化（GRPO）应用于在如此小的、无推理数据集上训练的策略时，无法产生显着的改进。我们表明，这种限制源于难度偏差，它不成比例地惩罚来自 GRPO 内产生高方差推出的场景的奖励信号。 \\modelname 通过结合 Dr.~GRPO 克服了这个问题，Dr.~GRPO 是一种旨在减轻法学硕士难度偏差的最新算法。因此，\\modelname 只需一小部分训练数据且无需推理开销，即可在 Waymo 和 NAVSIM 上实现具有竞争力的性能，从而实现更高效的自主系统。|[2602.21172](http://arxiv.org/abs/2602.21172)|null|\n",
        "2602.21161": "|**2026-02-24**|**ActionReasoning: Robot Action Reasoning in 3D Space with LLM for Robotic Brick Stacking**|经典的机器人系统通常依赖于为受限环境设计的定制规划器。虽然在有限的环境中有效，但这些系统缺乏泛化能力，限制了具体人工智能和通用机器人的可扩展性。最近的数据驱动的视觉-语言-行动（VLA）方法旨在从大规模模拟和现实世界数据中学习策略。然而，物理世界的连续动作空间显着超过了语言标记的表示能力，这使得人们不清楚仅扩展数据是否可以产生通用的机器人智能。为了解决这一差距，我们提出了 ActionReasoning，这是一个法学硕士驱动的框架，它执行显式的动作推理，为机器人操作生成物理一致的、先验指导的决策。 ActionReasoning 利用大型语言模型 (LLM) 中已编码的物理先验和现实世界知识，并将它们构建在多代理架构中。我们在砖堆垛的易处理案例研究中实例化了该框架，其中假设环境状态已经被准确测量。然后环境状态被序列化并传递到多代理 LLM 框架，该框架生成物理感知行动计划。实验表明，所提出的多代理 LLM 框架可以实现稳定的积木放置，同时将工作量从低级特定领域编码转移到高级工具调用和提示，突出了其更广泛泛化的潜力。这项工作引入了一种有前途的方法，通过将物理推理与法学硕士相结合，在机器人操作中桥接感知和执行。|[2602.21161](http://arxiv.org/abs/2602.21161)|null|\n",
        "2602.21157": "|**2026-02-24**|**HALO: A Unified Vision-Language-Action Model for Embodied Multimodal Chain-of-Thought Reasoning**|视觉-语言-动作（VLA）模型在机器人操作方面表现出了强大的性能，但由于缺乏多模态推理和预测世界在行动下如何演变的明确机制，常常在长期或分布外场景中表现不佳。最近的工作在VLA模型中引入文本思维链或视觉子目标预测来进行推理，但仍然未能为联合文本推理、视觉预见和动作预测提供统一的类人推理框架。为此，我们提出了 HALO，一个统一的 VLA 模型，它通过文本任务推理的顺序过程、细粒度指导的视觉子目标预测和 EM-CoT 增强动作预测来实现体现多模式思想链 (EM-CoT) 推理。我们使用 Mixture-of-Transformers (MoT) 架构实例化 HALO，该架构将语义推理、视觉预见和动作预测解耦给专业专家，同时允许无缝的跨专家协作。为了大规模实现 HALO 学习，我们引入了一个自动化管道来合成 EM-CoT 训练数据以及精心设计的训练方案。大量实验表明：（1）HALO 在模拟和现实环境中均实现了卓越的性能，在 RoboTwin 基准上超出了基线策略 pi_0 34.1%； (2) 训练方案和 EM-CoT 设计的所有建议组件都有助于提高任务成功率； (3) HALO 通过我们提出的 EM-CoT 推理在激进的看不见的环境随机化下表现出强大的泛化能力。|[2602.21157](http://arxiv.org/abs/2602.21157)|null|\n",
        "2602.21015": "|**2026-02-24**|**From Perception to Action: An Interactive Benchmark for Vision Reasoning**|了解物理结构对于现实世界的应用（例如具体代理、交互设计和长视野操作）至关重要。然而，流行的视觉语言模型（VLM）评估仍然集中在与结构无关的单轮设置（例如，VQA）上，无法评估智能体推理几何、接触和支持关系如何共同限制动态环境中可能采取的行动的能力。为了解决这一差距，我们引入了动作和交互的因果层次结构 (CHAIN) 基准，这是一个交互式 3D、物理驱动的测试台，旨在评估模型是否能够理解、规划和执行基于物理约束的结构化动作序列。 CHAIN 将评估从被动感知转变为主动解决问题，涵盖联锁机械谜题以及 3D 堆叠和包装等任务。我们在统一的交互设置下对最先进的 VLM 和基于扩散的模型进行了全面的研究。我们的结果表明，表现最好的模型仍然难以内化物理结构和因果约束，往往无法制定可靠的长期计划，并且无法将感知的结构强有力地转化为有效的行动。该项目可在 https://social-ai-studio.github.io/CHAIN/ 获取。|[2602.21015](http://arxiv.org/abs/2602.21015)|null|\n",
        "2602.21013": "|**2026-02-24**|**Notes-to-Self: Scratchpad Augmented VLAs for Memory Dependent Manipulation Tasks**|许多灵巧的操作任务本质上都是非马尔可夫的，但在最近兴起的视觉-语言-动作（VLA）范式中，这一事实却很少受到关注。尽管它们成功地将互联网规模的语义理解引入机器人技术，但现有的 VLA 主要是“无状态的”，并且难以处理依赖于内存的长期任务。在这项工作中，我们探索了一种通过结合语言暂存器来向 VLA 传递空间和时间记忆的方法。便签本可以记住特定于任务的信息，例如对象位置，并且允许模型跟踪计划以及该计划中子目标的进展情况。我们在 MemoryBench 上对来自 ClevrSkills 环境的内存相关任务的拆分以及具有挑战性的现实世界拾取和放置任务评估了这种方法。我们证明，结合语言暂存器可以显着提高非循环和循环模型的这些任务的泛化能力。|[2602.21013](http://arxiv.org/abs/2602.21013)|null|\n",
        "2602.20979": "|**2026-02-24**|**Toward an Agentic Infused Software Ecosystem**|在软件开发中充分利用人工智能代理的能力需要重新思考软件生态系统本身。为此，本文概述了基于三个支柱的代理注入软件生态系统 (AISE) 的创建。首先，当然是人工智能代理本身，在过去的五年里，人工智能代理已经从简单的代码完成转向复杂的独立开发任务，这一趋势只会持续下去。第二个支柱是这些代理用来完成任务的编程语言和 API（或工具），并且越来越多地充当人类和人工智能代理交互和协作的通信基础。最后一个支柱是代理运行的运行时环境和生态系统，它提供了编程代理用于与外部世界交互（并影响其中的操作）的功能。为了实现 AISE 的愿景，所有三个支柱都必须以整体方式推进，最重要的是，以一种对当前存在的、未来存在的人工智能代理以及与它们一起工作的人类开发人员来说具有协同作用的方式。|[2602.20979](http://arxiv.org/abs/2602.20979)|null|\n",
        "2602.20963": "|**2026-02-24**|**A Robotic Testing Platform for Pipelined Discovery of Resilient Soft Actuators**|高电场下的短寿命阻碍了线性介电弹性体致动器（DEA）在机器人中的广泛应用。由于每个样本测试耗时且高维参数空间影响性能，系统扫描很困难。为了解决这个问题，我们提出了一种由能够扫描 DEA 寿命的新型测试机器人启用的优化管道。该机器人集成了机电性能测量、可编程电压输入和多通道测试能力。使用它，我们扫描了基于 Elastosil 的线性执行器的寿命参数，包括输入电压幅度、频率、电极材料浓度和电连接填料。最佳参数组合将边界操作条件下的使用寿命提高了 100%，并随后按比例扩大以实现更高的力和位移输出。最终产品展示了模块化、可扩展的四足步行机器人的弹性，具有有效负载能力（> 100% 的自由体重，> 700% 的组合执行器重量）。这项工作首次将自动驾驶实验室方法引入机器人执行器设计中。|[2602.20963](http://arxiv.org/abs/2602.20963)|null|\n",
        "2602.20943": "|**2026-02-24**|**UFO: Unifying Feed-Forward and Optimization-based Methods for Large Driving Scene Modeling**|动态驾驶场景重建对于自动驾驶仿真和闭环学习至关重要。虽然最近的前馈方法已显示出 3D 重建的前景，但由于序列长度的二次复杂性以及长时间建模动态对象的挑战，它们在长距离驱动序列方面遇到了困难。我们提出了 UFO，一种新颖的循环范例，它结合了基于优化和前馈方法的优点，可实现高效的远程 4D 重建。我们的方法维护了 4D 场景表示，随着新观察的到来，该表示不断迭代地细化，使用基于可见性的过滤机制来选择信息丰富的场景标记并实现长序列的高效处理。对于动态对象，我们引入了一种对象姿势引导建模方法，支持精确的远程运动捕捉。 Waymo 开放数据集上的实验表明，我们的方法在各种序列长度上显着优于按场景优化和现有的前馈方法。值得注意的是，我们的方法可以在 0.5 秒内重建 16 秒的驾驶日志，同时保持卓越的视觉质量和几何精度。|[2602.20943](http://arxiv.org/abs/2602.20943)|null|\n",
        "2602.20846": "|**2026-02-24**|**Body-Reservoir Governance in Repeated Games: Embodied Decision-Making, Dynamic Sentinel Adaptation, and Complexity-Regularized Optimization**|标准博弈论通过诸如“一报还一报”（TfT）之类的条件策略来解释重复博弈中的合作，但这需要连续计算，从而给实体主体带来物理成本。我们提出了一个三层的身体储存库治理（BRG）架构：（1）一个身体储存库（回声状态网络），其$d$维状态对交互历史进行隐式推理，充当决策者和异常检测器，（2）一个认知过滤器，提供按需激活的昂贵的策略工具，以及（3）一个具有感受性参数$α\\in [0,1]$的元认知治理层。在全身治理（$α=1$）下，闭环动力学满足自洽方程：合作表示为水库的固定点，而不是计算。策略复杂度成本定义为水库状态分布与其习惯基线之间的 KL 散度。主体治理降低了这一成本，维度为 $d$ 的行动方差减少至 $1600\\times$。动态哨兵根据储存库自身状态生成复合不适信号，驱动自适应 $α(t)$：合作期间接近基线，在背叛时迅速下降以激活认知报复。超越身体会产生与内部状态扭曲成比例的热力学成本。哨兵在所有条件下都获得了最高回报，优于静态机构治理、TfT 和 EMA 基线。维度扫描（$d \\in \\{5,\\ldots,100\\}$）显示隐式推理尺度与身体丰富度（$23\\times$ 到 $1600\\times$ 方差减少），归因于储层动态。 $(d, τ_{\\mathrm{env}})$ 空间中的相图揭示了 $d \\approx 20$ 附近的治理制度转变。该框架将合作重新解释为适应动力系统的最小耗散响应——从体现的动态而不是计算的动态中产生。|[2602.20846](http://arxiv.org/abs/2602.20846)|null|\n",
        "2602.20794": "|**2026-02-24**|**VGGDrive: Empowering Vision-Language Models with Cross-View Geometric Grounding for Autonomous Driving**|跨视角3D几何建模能力对于自动驾驶的重要性不言而喻，但现有的视觉语言模型（VLM）本身就缺乏这种能力，导致其性能表现平平。虽然一些有前途的方法试图通过构建用于辅助训练的问答数据来缓解这一问题，但它们仍然无法从根本上使 VLM 具备全面处理不同评估协议的能力。因此，我们制定了一条新路线，主张将成熟 3D 基础模型的交叉视图几何基础注入 VLM，从而缩小自动驾驶中的这一关键能力差距。本着这种精神，我们提出了一种新颖的架构 VGGDrive，它为视觉语言模型提供了跨视图几何基础，以实现自动驾驶。具体来说，为了将冻结视觉 3D 模型中的跨视图 3D 几何特征与 VLM 的 2D 视觉特征连接起来，我们引入了即插即用的跨视图 3D 几何启用器 (CVGE)。 CVGE解耦了基础VLM架构，并通过分层自适应注入机制有效地为VLM提供了3D功能。大量实验表明，VGGDrive 在五个自动驾驶基准测试中增强了基本 VLM 性能，包括跨视图风险感知、运动预测和轨迹规划等任务。我们相信，成熟的 3D 基础模型可以通过有效集成来赋能自动驾驶任务，我们希望我们的初步探索能够向自动驾驶社区展示这种范式的潜力。|[2602.20794](http://arxiv.org/abs/2602.20794)|null|\n",
        "2602.22208": "|**2026-02-25**|**Solaris: Building a Multiplayer Video World Model in Minecraft**|现有的动作条件视频生成模型（视频世界模型）仅限于单智能体视角，无法捕捉现实世界环境的多智能体交互。我们介绍 Solaris，这是一种模拟一致的多视图观察的多人视频世界模型。为了实现这一目标，我们开发了一个多人数据系统，专为《我的世界》等视频游戏的稳健、连续和自动化数据收集而设计。与之前为单人游戏设置构建的平台不同，我们的系统支持协调的多代理交互和同步视频+动作捕捉。使用该系统，我们收集了 1264 万个多人游戏帧，并提出了多人运动、记忆、接地、构建和视图一致性的评估框架。我们使用分阶段的管道来训练 Solaris，该管道逐渐从单人模式过渡到多人模式，结合了双向、因果和自我强迫训练。在最后阶段，我们引入了检查点自我强迫，这是一种内存高效的自我强迫变体，可以实现更长视野的教师。结果显示我们的架构和培训设计优于现有基线。通过开源我们的系统和模型，我们希望为新一代多智能体世界模型奠定基础。|[2602.22208](http://arxiv.org/abs/2602.22208)|null|\n",
        "2602.22198": "|**2026-02-25**|**Thermal activation drives a finite-size crossover from scale-free to runaway avalanches in amorphous solids**|我们使用具有局部激活规则且无外部驱动的弹塑性模型研究非晶固体中的热雪崩动力学。通过持久性测量和相关的四点磁化率 $χ_4$ 量化的动态异质性揭示了随着温度变化而出现的相关时空重排。随着温度升高，雪崩统计数据从具有指数截止的无标度行为演变为由跨系统失控事件主导的状态。我们确定了一个与系统尺寸相关的临界温度$T_c(L)$，它将间歇性雪崩动力学与热辅助流分开，其中自持雪崩使系统瞬时流化。我们表明，$T_c(L)$ 随着系统尺寸的增加而代数减小，这表明在热力学极限下，任意小但有限的温度可能会破坏间歇状态的稳定性。雪崩大小和持续时间之间的关系类似于剪切系统中的关系，而屈服最小距离的统计数据揭示了严格驱动的过阻尼动力学中不存在的温度驱动的边际稳定性重组。我们的结果表明，仅热激活就可以在无序弹性介质中产生有限尺寸控制的不稳定尺度。|[2602.22198](http://arxiv.org/abs/2602.22198)|null|\n",
        "2602.22172": "|**2026-02-25**|**Effects of realistic laser intensity and phase distribution on high-charge laser wakefield acceleration**|激光尾场加速（LWFA）可以在厘米长的等离子体中产生相对论电子束和各种二次粒子，使其成为有价值的粒子源，在许多学科中具有重要应用。在这项工作中，我们通过实验测量和细胞内颗粒模拟研究了激光脉冲的非理想横向强度和相位分布对 LWFA 的影响。与横向高斯激光相比，75 TW 激光脉冲的复杂横向轮廓降低了等离子体中的自聚焦强度。此外，现实激光脉冲激发的非线性等离子体尾流的鞘层结构比高斯激光器的鞘层结构更宽、更复杂。这些阻碍了等离子体电子的注入。当激光脉冲在等离子体中传播时，其强度分布逐渐变成椭圆形，并在主轴方位角附近驱动具有尖锐鞘的等离子体尾流，从而导致注入。当在模拟中使用真实的激光轮廓时，注入电子的电荷和能量与实验结果非常匹配（$\\sim200$ pC 电荷和 $\\sim 200$ MeV 峰值能量），而高斯激光模拟产生更高的电荷（$\\sim500$ pC）。我们的研究结果揭示了由非理想激光脉冲驱动的 LWFA 与由高斯脉冲驱动的 LWFA 之间的注入动力学差异，并且对于需要高电荷电子束的 LWFA 应用非常有用。|[2602.22172](http://arxiv.org/abs/2602.22172)|null|\n",
        "2602.22096": "|**2026-02-25**|**WeatherCity: Urban Scene Reconstruction with Controllable Multi-Weather Transformation**|可编辑的高保真 4D 场景对于自动驾驶至关重要，因为它们可以应用于端到端训练和闭环仿真。然而，现有的重建方法主要局限于复制观测场景，缺乏多样化天气模拟的能力。而图像级天气编辑方法往往会引入场景伪影，并且对天气效果的可控性较差。为了解决这些限制，我们提出了 WeatherCity，这是一种用于 4D 城市场景重建和天气编辑的新颖框架。具体来说，我们利用文本引导的图像编辑模型来实现图像天气背景的灵活编辑。为了应对多天气建模的挑战，我们引入了一种基于共享场景特征和专用天气特定解码器的新型天气高斯表示。通过内容一致性优化进一步增强了这种表示，确保不同天气条件下的连贯建模。此外，我们设计了一个物理驱动的模型，通过粒子和运动模式模拟动态天气效果。对多个数据集和各种场景的大量实验表明，WeatherCity在4D重建和天气编辑方面实现了灵活的可控性、高保真度和时间一致性。我们的框架不仅能够对天气条件（例如小雨和大雪）进行细粒度控制，而且还支持场景内的对象级操作。|[2602.22096](http://arxiv.org/abs/2602.22096)|null|\n",
        "2602.22091": "|**2026-02-25**|**Learning to Drive is a Free Gift: Large-Scale Label-Free Autonomy Pretraining from Unposed In-The-Wild Videos**|在线提供的以自我为中心的驾驶视频为自动驾驶提供了丰富的视觉数据源，但它们缺乏注释使得学习捕获语义结构和 3D 几何的表示变得困难。大型前馈空间模型的最新进展表明，可以在一次前向传递中推断出点图和自我运动，这为可扩展的驾驶感知提供了一个有希望的方向。因此，我们提出了一个无标签、教师指导的框架，用于直接从未摆出的视频中学习自动驾驶表示。与之前主要关注帧间一致性的自我监督方法不同，我们认为安全和反应性驾驶关键取决于时间背景。为此，我们利用配备轻量级自回归模块的前馈架构，使用多模态监督信号进行训练，引导模型联合预测当前和未来的点图、相机姿势、语义分割和运动掩模。多模态教师提供序列级伪监督，使 LFG 能够从原始 YouTube 视频中学习统一的伪 4D 表示，而无需姿势、标签或 LiDAR。由此产生的编码器不仅可以有效地转移到 NAVSIM 基准上的下游自动驾驶规划，超越多摄像头和仅使用单个单目摄像头的 LiDAR 基线，而且在一系列语义、几何和定性运动预测任务上进行评估时也能产生强大的性能。这些几何和运动感知功能使 LFG 成为引人注目的以视频为中心的自动驾驶基础模型。|[2602.22091](http://arxiv.org/abs/2602.22091)|null|\n",
        "2602.22040": "|**2026-02-25**|**IGR J12580+0134: A Candidate for Repeating Partial Tidal Disruption Events Supported by Multi-Wavelength Observations**|重复部分潮汐破坏事件（pTDE）可以直接探测超大质量黑洞周围的恒星轨道和偶发性质量损失，但可靠的识别需要多波段和多纪元的证据。我们使用多历元 Karl G. Jansky VLA 观测以及来自 Swift/XRT 和 NICER 的 X 射线约束，研究 NGC 4845 中核瞬变 IGR J12580+0134 的晚期射电再亮是否可以解释为重复的 pTDE。射电光曲线显示出两个不同的阶段，L 波段峰值相隔 $\\approx1513$ 天。使用马尔可夫链蒙特卡罗拟合的同步加速器余辉框架对第二阶段进行建模有利于非相对论流出 $v\\simeq0.03c$，其各向同性等效动能为 $10^{50}$ erg 在近似恒定密度的核周介质中传播。在 2016 年的射电耀斑期间，Swift/XRT 没有检测到明显的同期增亮，而 2023 年的微弱 NICER 耀斑表明存在间歇性低水平吸积。因此，复发时间尺度和无线电能量学使 IGR J12580+0134 成为重复 pTDE 系统的可能候选者，从而激励持续敏感的无线电和 X 射线监测来测试未来的重新激活。|[2602.22040](http://arxiv.org/abs/2602.22040)|null|\n",
        "2602.22010": "|**2026-02-25**|**World Guidance: World Modeling in Condition Space for Action Generation**|利用未来的观察模型来促进行动生成，为增强视觉-语言-行动（VLA）模型的能力提供了一条有前途的途径。然而，现有的方法很难在保持高效、可预测的未来表示和保留足够的细粒度信息以指导精确的动作生成之间取得平衡。为了解决这个限制，我们提出了 WoG（世界指导），这是一个框架，通过将未来的观察结果注入到动作推理管道中，将它们映射到紧凑的条件中。然后，VLA 经过训练，可以同时预测这些压缩条件和未来的动作，从而在条件空间内实现有效的世界建模以进行动作推理。我们证明，建模和预测这个条件空间不仅有利于细粒度动作的生成，而且还表现出卓越的泛化能力。此外，它还可以从大量的人类操作视频中有效地学习。模拟和现实环境中的大量实验验证了我们的方法显着优于基于未来预测的现有方法。项目页面位于：https://selen-suyue.github.io/WoGNet/|[2602.22010](http://arxiv.org/abs/2602.22010)|null|\n",
        "2602.22001": "|**2026-02-25**|**Are Foundation Models the Route to Full-Stack Transfer in Robotics?**|对于人类和机器人来说，迁移学习发生在不同的抽象层次上，从高级语言迁移到低级运动技能迁移。在本文中，我们概述了基础模型和变压器网络对这些不同级别的影响，使机器人比以往任何时候都更接近“全栈传输”。从机器人迁移学习的角度考虑 LLM、VLM 和 VLA，使我们能够强调除具体实现之外的重复出现的迁移概念。我们还考虑了基础模型时代机器人技术的数据收集和传输基准的挑战。基础模型是机器人全栈传输的途径吗？我们的期望是，他们一定会作为关键技术继续走这条路线。|[2602.22001](http://arxiv.org/abs/2602.22001)|null|\n",
        "2602.21992": "|**2026-02-25**|**PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning**|360 度全景图像越来越多地用于虚拟现实、自动驾驶和机器人技术中，以实现整体场景理解。然而，由于几何失真和有限的 3D 监督，当前的视觉语言模型 (VLM) 难以在等距柱状投影 (ERP) 图像上进行 3D 空间推理。我们推出了 PanoEnv，这是一个从合成 3D 环境构建的大型 VQA 基准测试，包含五个类别（例如相对位置、体积比较）的 14.8K 个问题，这些问题基于准确的 3D 注释，包括深度、分割和边界框。对 14 个最先进的 VLM 进行基准测试揭示了有限的 3D 理解，总体准确率仅为 49.34%，开放式 (OE) 问题的准确率为 8.36%。为了增强 3D 推理，我们提出了一种基于组相对策略优化 (GRPO) 的强化学习后训练框架，该框架具有基于事实指导的奖励，其中结合了距离容差和空间一致性等五种几何感知策略。两阶段课程进一步减轻灾难性遗忘：第一阶段训练结构化任务（真/假和多项选择），第二阶段对混合开放式数据进行微调以提高泛化能力。我们的 7B 模型实现了新的最先进的性能，将整体准确率提高到 52.93% (+3.59%)，将开放式准确率提高到 14.83%，同时保持结构化任务性能。它还取得了最高的语义评估分数（Q-Score 6.24，P-Score 5.95），超越了 32B 模型。这些结果表明，PanoEnv-QA 和我们基于课程的 RL 框架有效地将 3D 空间智能注入 VLM 中，以实现全方位感知。|[2602.21992](http://arxiv.org/abs/2602.21992)|null|\n",
        "2602.21952": "|**2026-02-25**|**MindDriver: Introducing Progressive Multimodal Reasoning for Autonomous Driving**|视觉语言模型（VLM）表现出强大的推理能力，显示出端到端自动驾驶系统的前景。思想链（CoT）作为VLM广泛使用的推理策略，正面临着严峻的挑战。现有的文本CoT在文本语义空间和轨迹物理空间之间存在较大差距。尽管最近的方法利用未来图像代替文本作为 CoT 过程，但它缺乏明确的面向规划的客观指导来生成具有准确场景演化的图像。为了解决这些问题，我们创新性地提出了 MindDriver，这是一种渐进式多模态推理框架，使 VLM 能够模仿人类的渐进式思维进行自动驾驶。 MindDriver 呈现语义理解、语义到物理空间想象以及物理空间轨迹规划。为了在 MindDriver 中实现对齐推理过程，我们开发了一个反馈引导的自动数据注释管道来生成对齐的多模态推理训练数据。此外，我们开发了一种渐进强化微调方法，通过渐进的高水平基于奖励的学习来优化对齐。 MindDriver 在 nuScences 开环和 Bench2Drive 闭环评估中展示了卓越的性能。代码可在 https://github.com/hotdogcheesewhite/MindDriver 获取。|[2602.21952](http://arxiv.org/abs/2602.21952)|null|\n",
        "2602.23259": "|**2026-02-26**|**Risk-Aware World Model Predictive Control for Generalizable End-to-End Autonomous Driving**|随着模仿学习（IL）和大规模驾驶数据集的进步，端到端自动驾驶（E2E-AD）最近取得了巨大进展。目前，基于IL的方法已成为主流范式：模型依赖于专家给出的标准驾驶行为，并学习最小化其行为与专家行为之间的差异。然而，“只像专家一样驾驶”这一目标的泛化能力有限：当遇到专家演示分布之外的罕见或未见的长尾场景时，模型往往会在缺乏先验经验的情况下做出不安全的决策。这就提出了一个基本问题：E2E-AD 系统能否在没有任何专家行动监督的情况下做出可靠的决策？受此启发，我们提出了一个名为风险感知世界模型预测控制（RaWMPC）的统一框架，通过稳健控制来解决这种泛化困境，而不依赖于专家演示。实际上，RaWMPC 利用世界模型来预测多个候选行动的后果，并通过明确的风险评估选择低风险行动。为了赋予世界模型预测危险驾驶行为结果的能力，我们设计了一种风险感知交互策略，系统地将世界模型暴露于危险行为，使灾难性结果可预测，从而可以避免。此外，为了在测试时生成低风险的候选动作，我们引入了一种自我评估蒸馏方法，将风险规避能力从训练有素的世界模型中提取到生成动作提案网络中，而无需任何专家演示。大量实验表明，RaWMPC 在分布内和分布外场景中均优于最先进的方法，同时提供卓越的决策可解释性。|[2602.23259](http://arxiv.org/abs/2602.23259)|null|\n",
        "2602.23164": "|**2026-02-26**|**MetaOthello: A Controlled Study of Multiple World Models in Transformers**|基础模型必须处理多个生成过程，但机械可解释性主要研究孤立的能力；目前尚不清楚单个变压器如何组织多个可能相互冲突的“世界模型”。之前关于黑白棋玩神经网络的实验测试了世界模型学习，但重点关注具有一组规则的单个游戏。我们引入了 MetaOthello，这是一套受控的 Othello 变体套件，具有共享语法但不同的规则或标记化，并在混合变体数据上训练小型 GPT，以研究如何在共享表示空间中组织多个世界模型。我们发现，在混合游戏数据上训练的 Transformer 不会将其容量划分为孤立的子模型；相反，它们集中在一个大部分共享的董事会状态表示上，该表示在变体之间因果转移。在一种变体上训练的线性探针可以干预另一种变体的内部状态，其有效性接近匹配探针。对于具有令牌重新映射的同构游戏，表示相当于跨层泛化的单个正交旋转。当规则部分重叠时，早期层保持与游戏无关的表示，而中间层识别游戏身份，而后面的层则专门化。 MetaOthello 不仅提供了一条了解变形金刚是否学习世界模型的途径，还提供了一条了解它们如何同时组织多个世界模型的途径。|[2602.23164](http://arxiv.org/abs/2602.23164)|null|\n",
        "2602.23152": "|**2026-02-26**|**The Trinity of Consistency as a Defining Principle for General World Models**|构建能够学习、模拟和推理客观物理定律的世界模型是追求通用人工智能的基本挑战。以 Sora 等视频生成模型为代表的最新进展证明了数据驱动的缩放定律在近似物理动力学方面的潜力，而新兴的统一多模态模型 (UMM) 则为集成感知、语言和推理提供了一种有前途的架构范例。尽管取得了这些进展，该领域仍然缺乏一个原则性的理论框架来定义通用世界模型所需的基本属性。在本文中，我们提出世界模型必须建立在一致性三位一体的基础上：模态一致性作为语义接口，空间一致性作为几何基础，时间一致性作为因果引擎。通过这个三方视角，我们系统地回顾了多模态学习的演变，揭示了从松散耦合的专业模块到统一架构的轨迹，从而实现内部世界模拟器的协同出现。为了补充这个概念框架，我们引入了 CoW-Bench，这是一个以多帧推理和生成场景为中心的基准测试。 CoW-Bench 在统一的评估协议下评估视频生成模型和 UMM。我们的工作建立了通向通用世界模型的原则性途径，阐明了当前系统的局限性和未来进步的架构要求。|[2602.23152](http://arxiv.org/abs/2602.23152)|null|\n",
        "2602.23148": "|**2026-02-26**|**On Sample-Efficient Generalized Planning via Learned Transition Models**|广义规划研究解决方案策略的构建，该解决方案策略泛化于共享公共域模型的规划问题系列，由转换函数 $γ 正式定义：S \\times A \\rightarrow S$。经典方法通过符号抽象和对 $γ$ 的显式推理来实现这种泛化。相比之下，最近基于 Transformer 的规划器（例如 PlanGPT 和 Plansformer）在很大程度上将广义规划视为直接动作序列预测，绕过了显式转换建模。虽然对分布内实例有效，但这些方法通常需要大型数据集和模型大小，并且由于缺乏明确的世界状态演化，常常会在长范围设置中遭受状态漂移。在这项工作中，我们将广义规划制定为转换模型学习问题，其中神经模型显式逼近后继状态函数 $\\hatγ \\approx γ$ 并通过推出符号状态轨迹来生成计划。该模型不是直接预测动作，而是自回归预测中间世界状态，从而将域动态学习为隐式世界模型。为了研究大小不变的泛化和样本效率，我们系统地评估了多种状态表示和神经架构，包括关系图编码。我们的结果表明，在多个领域中，学习显式转换模型比直接行动序列预测能产生更高的分布外满足计划成功率，同时通过显着更少的训练实例和更小的模型来实现这些收益。这是 ICAPS 2026 上接受的同名短论文的扩展版本。|[2602.23148](http://arxiv.org/abs/2602.23148)|null|\n",
        "2602.23109": "|**2026-02-26**|**Towards Intelligible Human-Robot Interaction: An Active Inference Approach to Occluded Pedestrian Scenarios**|突然出现的被遮挡行人给自动驾驶带来了严峻的安全挑战。传统的基于规则或纯粹数据驱动的方法难以应对这些长尾场景固有的高度不确定性。为了应对这一挑战，我们提出了一种基于主动推理的新颖框架，该框架赋予智能体类似人类的信念驱动机制。我们的框架利用 Rao-Blackwellized 粒子滤波器 (RBPF) 来有效估计行人的混合状态。为了在不确定性下模拟类人的认知过程，我们引入了条件信念重置机制和假设注入技术，以明确地模拟有关行人多重潜在意图的信念。规划是通过交叉熵方法 (CEM) 增强型模型预测路径积分 (MPPI) 控制器实现的，该控制器将 CEM 的高效迭代搜索与 MPPI 固有的鲁棒性相结合。模拟实验表明，与反应性、基于规则和强化学习 (RL) 基线相比，我们的方法显着降低了碰撞率，同时还表现出可解释的、类人的驾驶行为，反映了智能体的内部信念状态。|[2602.23109](http://arxiv.org/abs/2602.23109)|null|\n",
        "2602.23058": "|**2026-02-26**|**GeoWorld: Geometric World Models**|基于能量的预测世界模型通过推理潜在的能量景观而不是生成像素，为多步骤视觉规划提供了一种强大的方法。然而，现有的方法面临两个主要挑战：（i）它们的潜在表示通常是在欧几里得空间中学习的，忽略了状态之间潜在的几何和层次结构；（ii）它们难以进行长期预测，这导致在扩展部署过程中快速退化。为了解决这些挑战，我们引入了 GeoWorld，这是一种几何世界模型，通过双曲 JEPA 保留几何结构和层次关系，它将欧几里得空间的潜在表示映射到双曲流形。我们进一步引入几何强化学习进行基于能量的优化，从而在双曲潜在空间中实现稳定的多步规划。 CrossTask 和 COIN 上的大量实验表明，与最先进的 V-JEPA 2 相比，3 步规划的 SR 提高了约 3%，4 步规划的 SR 提高了 2%。 项目网站：https://steve-zeyu-zhang.github.io/GeoWorld。|[2602.23058](http://arxiv.org/abs/2602.23058)|null|\n",
        "2602.23046": "|**2026-02-26**|**The LOFAR sub-arcsecond view of the high-redshift radio relic in PSZ2G091.83+26.11**|高红移下增强的逆康普顿 (IC) 损耗使星系团中的漫射射电光谱变得陡峭，从而有利于低频（~100 MHz）观测。然而，低频研究通常缺乏定位粒子加速位点或分离射电星系漫射发射所需的分辨率。在本文中，我们通过解析加速站点并检查下游区域，揭示了遥远星团PSZ2G091.83+26.11（z=0.822）中射电遗迹的属性。我们使用 145 MHz 的欧洲 LOFAR (ILT)，首次在 1 GHz 以下研究了（亚）角秒分辨率的射电遗迹，并辅以更高频率的角秒分辨率 VLA 数据。我们确认漫射发射不是射电星系。朝向簇中心的光谱指数梯度与之前的 5'' 地图相匹配。高分辨率 0.4 英寸和 1.9 英寸图像显示了冲击波之前的发射，将遗迹与射电星系连接起来。 145 MHz 和 3.0 GHz 下游的 1.9'' 剖面遵循对数正态磁场分布。 145 MHz 冲击表面在电子密度、旋转测量和分数极化变化的同一位置显示出明显的不连续性，可能与磁场变化有关。最后，我们发现了无线电功率红移演化与星团质量相关性的迹象。 LOFAR 长基线可实现令人印象深刻的角分辨率，为星系团中的低能等离子体打开了前所未有的视野。这在高红移星团的情况下极其重要，其中低频无线电发射受能量损失的影响较小，但其检测受到分辨率差的严重限制。|[2602.23046](http://arxiv.org/abs/2602.23046)|null|\n",
        "2602.22988": "|**2026-02-26**|**Residual Koopman Spectral Profiling for Predicting and Preventing Transformer Training Instability**|Transformer 中的训练分歧会浪费计算量，但实践者只有在昂贵的运行开始后才发现不稳定。因此，在培训开始之前，他们需要变压器的预期故障概率。我们对残余库普曼光谱分析 (RKSP) 的研究提供了这样的估计。从初始化时的单个前向传递中，RKSP 通过将白化动态模式分解应用于逐层残差快照来提取库普曼谱特征。我们的核心诊断，即近单位光谱质量，量化了集中在单位圆附近的模态分数，从而捕获了不稳定风险。为了预测广泛配置之间的分歧，该估计器实现了 0.995 的 AUROC，优于最佳梯度基线。我们通过库普曼频谱整形（KSS）进一步使这种诊断变得可行，它在训练期间重塑频谱。我们凭经验验证我们的方法在实践中是否有效：RKSP 在初始化时预测发散，当 RKSP 标记高风险时，打开 KSS 成功防止发散。在没有归一化层的具有挑战性的高学习率机制中，KSS 将发散率从 66.7% 降低到 12.5%，并使学习率提高 50% 到 150%。这些发现可推广到 WikiText-103 语言模型、CIFAR-10 上的视觉转换器和预训练语言模型（包括高达 7B 的 GPT-2 和 LLaMA-2），以及新兴架构（例如 MoE、Mamba 风格的 SSM 和 KAN）。|[2602.22988](http://arxiv.org/abs/2602.22988)|null|\n",
        "2602.22960": "|**2026-02-26**|**UCM: Unifying Camera Control and Memory with Time-aware Positional Encoding Warping for World Models**|基于视频生成的世界模型在模拟交互环境方面表现出了巨大的潜力，但在两个关键领域面临着持续的困难：重新访问场景时保持长期内容一致性以及通过用户提供的输入实现精确的摄像机控制。基于显式 3D 重建的现有方法通常会损害无界场景和细粒度结构的灵活性。替代方法直接依赖于先前生成的帧，而不建立明确的空间对应关系，从而限制了可控性和一致性。为了解决这些限制，我们提出了 UCM，这是一种新颖的框架，通过时间感知的位置编码扭曲机制将长期记忆和精确的相机控制结合起来。为了减少计算开销，我们设计了一种用于高保真生成的高效双流扩散变压器。此外，我们引入了一种可扩展的数据管理策略，利用基于点云的渲染来模拟场景重访，从而促进对超过 500K 单目视频的训练。对现实世界和综合基准的大量实验表明，UCM 在长期场景一致性方面显着优于最先进的方法，同时在高保真视频生成中实现了精确的摄像机可控性。|[2602.22960](http://arxiv.org/abs/2602.22960)|null|\n",
        "2602.22940": "|**2026-02-26**|**Considering Perspectives for Automated Driving Ethics: Collective Risk in Vehicular Motion Planning**|最近的自动车辆 (AV) 运动规划策略围绕最大限度地降低道路交通风险而发展。然而，他们只从自动驾驶汽车的角度考虑风险，因此没有考虑其决策对其他道路使用者的道德问题。我们认为，这并不能降低每个道路使用者的风险，因为从每个道路使用者的角度来看，风险可能不同。事实上，从自动驾驶汽车的角度最小化风险可能并不意味着从其他道路使用者的角度来看风险也被最小化；事实上，它甚至可能会增加。为了检验这一假设，我们提出了一种自动驾驶运动规划策略，支持在所有道路使用者视角之间切换风险最小化策略。我们发现，从其他道路使用者的角度来看的风险通常可以被认为与从自动驾驶汽车的角度来看的风险不同。从集体风险的角度来看，即平衡所有道路使用者的风险，我们观察到自动驾驶汽车能够最大限度地降低整体交通风险，同时为了他人的利益而将自己置于稍高的风险，这与人类的驾驶行为是一致的。此外，采用集体风险最小化策略还可以在其他道路使用者对自动驾驶汽车的风险估计较低时采取果断行动，从而有利于自动驾驶汽车的行驶效率。然而，当其他道路使用者难以预测其计划行动（即与高风险相关）时，自动驾驶汽车会保守驾驶。我们认为，这种行为是一种自我反思的形式，也是社会可接受的 AV 行为的自然先决条件。我们的结论是，为了促进包括自动驾驶汽车在内的道路交通的道德规范，在自动驾驶汽车的决策中必须考虑每个道路使用者的风险视角。|[2602.22940](http://arxiv.org/abs/2602.22940)|null|\n"
    }
}