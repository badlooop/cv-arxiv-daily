{
    "Video Diffusion": {
        "2512.24724": "|**2025-12-31**|**FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation**|在这项工作中，我们表明模型容量的影响随时间步长的不同而变化：它对于早期和晚期阶段至关重要，但在中间阶段基本上可以忽略不计。因此，我们提出了 FlowBlending，一种阶段感知的多模型采样策略，分别在容量敏感阶段和中间阶段采用大模型和小模型。我们进一步引入简单的标准来选择阶段边界，并提供速度发散分析作为识别容量敏感区域的有效代理。在 LTX-Video (2B/13B) 和 WAN 2.1 (1.3B/14B) 中，FlowBlending 的推理速度提高了 1.65 倍，失败次数减少了 57.35%，同时保持了大型模型的视觉保真度、时间连贯性和语义对齐。 FlowBlending 还与现有的采样加速技术兼容，可实现高达 2 倍的额外加速。项目页面位于：https://jibin86.github.io/flowblending_project_page。|[2512.24724](http://arxiv.org/abs/2512.24724)|null|\n",
        "2512.24551": "|**2025-12-31**|**PhyGDPO: Physics-Aware Groupwise Direct Preference Optimization for Physically Consistent Text-to-Video Generation**|文本到视频（T2V）生成的最新进展已经实现了良好的视觉质量，但合成忠实遵循物理定律的视频仍然是一个开放的挑战。现有的主要基于图形或提示扩展的方法很难推广到简单的模拟环境之外或学习隐式物理推理。缺乏具有丰富物理相互作用和现象的训练数据也是一个问题。在本文中，我们首先介绍了一种物理增强视频数据构建管道 PhyAugPipe，它利用具有思维链推理的视觉语言模型 (VLM) 来收集大规模训练数据集 PhyVidGen-135K。然后，我们制定了一个有原则的物理感知分组直接偏好优化（PhyGDPO）框架，该框架建立在分组 Plackett-Luce 概率模型的基础上，以捕获超越成对比较的整体偏好。在 PhyGDPO 中，我们设计了一种物理引导奖励 (PGR) 方案，该方案嵌入基于 VLM 的物理奖励，以引导优化实现物理一致性。我们还提出了一种 LoRA-Switch Reference (LoRA-SR) 方案，该方案消除了内存繁重的参考重复，以实现高效训练。实验表明，我们的方法在 PhyGenBench 和 VideoPhy2 上显着优于最先进的开源方法。请查看我们的项目页面 https://caiyuanhao1998.github.io/project/PhyGDPO 以获取更多视频结果。我们的代码、模型和数据将发布在https://github.com/caiyuanhao1998/Open-PhyGDPO|[2512.24551](http://arxiv.org/abs/2512.24551)|null|\n",
        "2512.24271": "|**2025-12-30**|**Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation**|多模态大语言模型（MLLM）在视频理解方面取得了显着进展。然而，它们存在一个严重的弱点：过度依赖语言先验，这可能会导致视觉上的无根据的幻觉，特别是在处理违背常识的反事实视频时。这种限制源于文本和视频之间固有的数据不平衡，由于收集和注释反事实数据的成本高昂，因此很难解决。为了解决这个问题，我们引入了 DualityForge，这是一种新颖的反事实数据合成框架，它采用可控的、基于扩散的视频编辑将现实世界的视频转换为反事实场景。通过将结构化上下文信息嵌入到视频编辑和 QA 生成过程中，该框架会自动生成高质量的 QA 对以及原始编辑的视频对，以进行对比训练。基于此，我们构建了 DualityVidQA，一个旨在减少 MLLM 幻觉的大规模视频数据集。此外，为了充分利用配对数据的对比性质，我们提出了对偶归一化优势训练（DNA-Train），这是一种两阶段 SFT-RL 训练机制，其中 RL 阶段应用成对 $\\ell_1$ 优势归一化，从而实现更稳定、更高效的策略优化。 DualityVidQA-Test 的实验表明，我们的方法大大减少了反事实视频上的模型幻觉，比 Qwen2.5-VL-7B 基线相对提高了 24.0%。此外，我们的方法在幻觉和通用基准方面都取得了显着的进步，表明了强大的泛化能力。我们将开源我们的数据集和代码。|[2512.24271](http://arxiv.org/abs/2512.24271)|null|\n",
        "2512.24227": "|**2025-12-30**|**Mirage: One-Step Video Diffusion for Photorealistic and Coherent Asset Editing in Driving Scenes**|以视觉为中心的自动驾驶系统依靠多样化且可扩展的训练数据来实现稳健的性能。虽然视频对象编辑为数据增强提供了一条有前途的途径，但现有方法通常难以保持高视觉保真度和时间连贯性。在这项工作中，我们提出了 \\textbf{Mirage}，这是一种一步式视频扩散模型，用于驾驶场景中逼真且连贯的资产编辑。 Mirage 建立在文本到视频的扩散之上，以确保跨帧的时间一致性。然而，3D 因果变分自动编码器通常会因压缩而遭受空间保真度下降的影响，并且直接将 3D 编码器特征传递到解码器层会破坏时间因果关系。为了解决这个问题，我们将时间无关的潜在变量从预训练的 2D 编码器注入到 3D 解码器中，以恢复细节，同时保留因果结构。此外，由于场景对象和插入的资产在不同的目标下进行优化，因此它们的高斯表现出分布不匹配，从而导致姿势不对齐。为了缓解这个问题，我们引入了一种两阶段数据对齐策略，将粗略的 3D 对齐和精细的 2D 细化相结合，从而改善对齐并提供更清晰的监督。大量实验表明 Mirage 在不同的编辑场景中实现了高度的真实感和时间一致性。除了资产编辑之外，Mirage 还可以推广到其他视频到视频翻译任务，为未来研究提供可靠的基准。我们的代码可在 https://github.com/wm-research/mirage 获取。|[2512.24227](http://arxiv.org/abs/2512.24227)|null|\n",
        "2512.24086": "|**2025-12-30**|**RainFusion2.0: Temporal-Spatial Awareness and Hardware-Efficient Block-wise Sparse Attention**|在视频和图像生成任务中，扩散变压器（DiT）模型由于注意力机制而产生极高的计算成本，这限制了其实际应用。此外，随着硬件的进步，除图形处理单元（GPU）之外的各种设备，例如专用集成电路（ASIC），已越来越多地用于模型推理。稀疏注意力通过跳过对无关紧要标记的计算来利用注意力固有的稀疏性，是减轻计算成本的有效方法。然而，现有的稀疏注意力方法有两个关键限制：稀疏模式预测的开销和缺乏硬件通用性，因为这些方法大多数都是为 GPU 设计的。为了应对这些挑战，本研究提出了 RainFusion2.0，旨在开发一种在线自适应、硬件高效且低开销的稀疏注意力机制，以加速视频和图像生成模型，并在不同的硬件平台上具有强大的性能。关键技术见解包括：（1）利用逐块平均值作为稀疏掩模预测的代表标记； (2) 实现时空感知的令牌排列； (3)引入专门针对视频生成场景设计的首帧接收机制。实验结果表明，RainFusion2.0可以实现80%的稀疏度，同时在不影响视频质量的情况下实现1.5~1.8倍的端到端加速。此外，RainFusion2.0 展示了跨各种生成模型的有效性，并验证了其跨不同硬件平台的泛化能力。|[2512.24086](http://arxiv.org/abs/2512.24086)|null|\n",
        "2512.23994": "|**2025-12-30**|**PhyAVBench: A Challenging Audio Physics-Sensitivity Benchmark for Physically Grounded Text-to-Audio-Video Generation**|文本转音频视频 (T2AV) 生成支持需要逼真视听内容的广泛应用，包括虚拟现实、世界建模、游戏和电影制作。然而，现有的 T2AV 模型仍然无法产生物理上合理的声音，这主要是由于它们对物理原理的理解有限。为了定位当前的研究进展，我们推出了 PhyAVBench，这是一个具有挑战性的音频物理灵敏度基准测试，旨在系统地评估现有 T2AV 模型的音频物理接地能力。 PhyAVBench 包含 1,000 组配对文本提示以及受控物理变量，这些变量隐含地引起声音变化，从而能够对模型对基础声学条件变化的敏感度进行细粒度评估。我们将这种评估范式称为音频物理灵敏度测试（APST）。与之前主要关注音视频同步的基准测试不同，PhyAVBench 明确评估模型对声音生成物理机制的理解，涵盖 6 个主要音频物理维度、4 个日常场景（音乐、音效、语音及其混合）和 50 个细粒度测试点，范围从声音衍射等基本方面到亥姆霍兹共振等更复杂的现象。每个测试点由多组配对提示组成，其中每个提示都以至少 20 个新录制或收集的真实视频为基础，从而最大限度地降低模型预训练期间数据泄漏的风险。提示和视频都经过严格的人为纠错和质量控制迭代完善，以确保高质量。我们认为，只有真正掌握与音频相关的物理原理的模型才能生成物理上一致的视听内容。我们希望 PhyAVBench 能够促进这一关键但很大程度上尚未探索的领域的未来进展。|[2512.23994](http://arxiv.org/abs/2512.23994)|null|\n",
        "2512.23983": "|**2025-12-30**|**DriveExplorer: Images-Only Decoupled 4D Reconstruction with Progressive Restoration for Driving View Extrapolation**|本文提出了自动驾驶场景中视图外推的有效解决方案。最近的方法侧重于使用扩散模型从给定的视点生成移位的新颖视图图像。然而，这些方法严重依赖于 LiDAR 点云、3D 边界框和车道注释等先验知识，这些先验知识需要昂贵的传感器或劳动密集型标签，限制了在实际部署中的适用性。在这项工作中，仅使用图像和可选的相机姿势，我们首先估计全局静态点云和每帧动态点云，将它们融合成统一的表示。然后，我们采用可变形 4D 高斯框架来重建场景。最初训练的 4D 高斯模型渲染退化图像和伪图像来训练视频扩散模型。随后，通过扩散模型迭代地改进逐渐平移的高斯渲染，并将增强的结果合并回作为 4DGS 的训练数据。这个过程一直持续到外推达到目标视点为止。与基线相比，我们的方法可以在新颖的外推视点生成更高质量的图像。|[2512.23983](http://arxiv.org/abs/2512.23983)|null|\n",
        "2512.23953": "|**2025-12-30**|**T2VAttack: Adversarial Attack on Text-to-Video Diffusion Models**|文本到视频 (T2V) 扩散模型的快速发展推动了从自然语言描述生成高质量、时间连贯的视频方面的显着进步。尽管取得了这些成就，但它们面对对抗性攻击的脆弱性在很大程度上仍未得到探索。在本文中，我们介绍了 T2VAtack，这是一项从语义和时间角度对 T2V 扩散模型的对抗性攻击的综合研究。考虑到视频数据固有的动态性质，我们提出了两个不同的攻击目标：评估视频文本对齐的语义目标和评估时间动态的时间目标。为了实现有效且高效的攻击过程，我们提出了两种对抗性攻击方法：（i）T2VAtack-S，它识别提示中语义或时间上的关键单词，并通过贪婪搜索将其替换为同义词；（ii）T2VAtack-I，它以最小扰动迭代地插入优化单词到提示中。通过结合这些目标和策略，我们对几种最先进的 T2V 模型（包括 ModelScope、CogVideoX、Open-Sora 和 HunyuanVideo）的对抗鲁棒性进行了全面评估。我们的实验表明，即使是微小的即时修改，例如替换或插入单个单词，也可能导致语义保真度和时间动态的大幅下降，凸显了当前 T2V 扩散模型中的关键漏洞。|[2512.23953](http://arxiv.org/abs/2512.23953)|null|\n",
        "2512.25075": "|**2025-12-31**|**SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time**|我们提出了 SpaceTimePilot，这是一种视频扩散模型，可以解开空间和时间以实现可控的生成渲染。给定单目视频，SpaceTimePilot 可以在生成过程中独立改变摄像机视点和运动序列，重新渲染场景，以实现跨空间和时间的连续和任意探索。为了实现这一目标，我们在扩散过程中引入了一种有效的动画时间嵌入机制，允许对输出视频相对于源视频的运动序列进行显式控制。由于没有数据集提供具有连续时间变化的同一动态场景的配对视频，我们提出了一种简单而有效的时间扭曲训练方案，该方案重新利用现有的多视图数据集来模拟时间差异。该策略有效地监督模型学习时间控制并实现鲁棒的时空解缠结。为了进一步提高双重控制的精度，我们引入了两个额外的组件：改进的相机调节机制，允许从第一帧开始改变相机，以及CamxTime，第一个合成时空全覆盖渲染数据集，可在场景内提供完全自由的时空视频轨迹。对时间扭曲方案和 CamxTime 数据集的联合训练可以产生更精确的时间控制。我们在现实世界和合成数据上评估了 SpaceTimePilot，与之前的工作相比，展示了清晰的时空解离和强大的结果。项目页面：https://zheninghuang.github.io/Space-Time-Pilot/ 代码：https://github.com/ZheningHuang/spacetimepilot|[2512.25075](http://arxiv.org/abs/2512.25075)|null|\n",
        "2512.24952": "|**2025-12-31**|**VIPER: Process-aware Evaluation for Generative Video Reasoning**|视频生成领域的最新突破展示了一种称为帧链 (CoF) 推理的新兴功能，其中模型通过生成连续帧来解决复杂的任务。虽然这些模型显示出生成视频推理 (GVR) 的前景，但现有的评估框架通常依赖于单帧评估，这可能会导致结果黑客攻击，即模型通过错误的过程得出正确的结论。为了解决这个问题，我们提出了一种流程感知的评估范式。我们推出了 VIPER，这是一个涵盖时间、结构、符号、空间、物理和规划推理等 16 项任务的综合基准测试。此外，我们提出了过程结果一致性（POC@r），这是一种新的指标，利用带有分层标题的 VLM-as-Judge 来评估中间步骤和最终结果的有效性。我们的实验表明，最先进的视频模型仅实现了约 20% POC@1.0，并且表现出显着的结果黑客攻击。我们进一步探讨了测试时间缩放和采样鲁棒性的影响，强调了当前视频生成和真正的广义视觉推理之间的巨大差距。我们的基准将公开发布。|[2512.24952](http://arxiv.org/abs/2512.24952)|null|\n",
        "2512.24766": "|**2025-12-31**|**Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow**|生成视频建模已成为一种引人注目的工具，可以对开放世界操纵的合理物理交互进行零镜头推理。然而，将这种人类主导的运动转化为机器人系统所需的低级动作仍然是一个挑战。我们观察到，在给定初始图像和任务指令的情况下，这些模型擅长合成合理的物体运动。因此，我们引入了 Dream2Flow，这是一个通过 3D 对象流作为中间表示来桥接视频生成和机器人控制的框架。我们的方法从生成的视频中重建 3D 对象运动，并将操作制定为对象轨迹跟踪。通过将状态变化与实现这些变化的执行器分离，Dream2Flow 克服了实施例差距，并实现了预训练视频模型的零镜头引导，以操纵不同类别的对象，包括刚性、铰接式、可变形和粒状。通过轨迹优化或强化学习，Dream2Flow 将重建的 3D 对象流转换为可执行的低级命令，而无需特定于任务的演示。仿真和现实世界实验强调 3D 对象流作为通用且可扩展的接口，用于使视频生成模型适应开放世界的机器人操作。视频和可视化可在 https://dream2flow.github.io/ 上获取。|[2512.24766](http://arxiv.org/abs/2512.24766)|null|\n",
        "2601.00678": "|**2026-01-02**|**Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians**|人类擅长仅凭一张图像来预测场景的未来动态。能够模仿这种能力的视频生成模型是智能系统的重要组成部分。最近的方法提高了单图像条件视频生成中的时间相干性和 3D 一致性。然而，这些方法通常缺乏强大的用户可控性，例如修改相机路径，限制了它们在实际应用中的适用性。大多数现有的相机控制的图像到视频模型都难以准确建模相机运动、保持时间一致性和保持几何完整性。利用显式中间 3D 表示可实现与给定摄像机轨迹对齐的连贯视频生成，从而提供了一种有前景的解决方案。尽管这些方法通常使用 3D 点云来渲染场景并在后期引入对象运动，但尽管允许精确控制相机运动，但这种两步过程仍然无法实现完全的时间一致性。我们提出了一种新颖的框架，在单次前向传递中给定单个图像的情况下，构建 3D 高斯场景表示并对合理的对象运动进行采样。这使得能够快速生成相机引导的视频，而无需迭代去噪将对象运动注入渲染帧。在 KITTI、Waymo、RealEstate10K 和 DL3DV-10K 数据集上进行的大量实验表明，我们的方法实现了最先进的视频质量和推理效率。该项目页面位于 https://melonienimasha.github.io/Pixel-to-4D-Website。|[2601.00678](http://arxiv.org/abs/2601.00678)|null|\n",
        "2601.00504": "|**2026-01-01**|**MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation**|准确模拟现有 3D 对象和各种材料通常需要专业知识和耗时的物理参数调整才能实现所需的动态行为。我们引入了 MotionPhysics，这是一个端到端的可微分框架，它可以根据用户提供的自然语言提示来推断感兴趣的 3D 场景的合理物理参数，从而无需从地面实况轨迹或带注释的视频中进行指导。我们的方法首先利用多模态大语言模型来估计材料参数值，这些参数值被限制在合理的范围内。我们进一步提出了一种可学习的运动蒸馏损失，它从预训练的视频扩散模型中提取鲁棒的运动先验，同时最小化外观和几何归纳偏差以指导模拟。我们在三十多个场景中评估运动物理，包括现实世界、人工设计和人工智能生成的 3D 对象，涵盖弹性固体、金属、泡沫、沙子以及牛顿和非牛顿流体等多种材料。我们证明 MotionPhysics 在自然语言的指导下产生视觉逼真的动态模拟，超越了现有技术，同时自动确定物理上合理的参数。代码和项目页面位于：https://wangmiaowei.github.io/MotionPhysics.github.io/。|[2601.00504](http://arxiv.org/abs/2601.00504)|null|\n",
        "2601.00393": "|**2026-01-01**|**NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos**|在本文中，我们提出了 NeoVerse，一种多功能的 4D 世界模型，能够进行 4D 重建、新轨迹视频生成和丰富的下游应用。我们首先确定当前 4D 世界建模方法中可扩展性的常见限制，该限制是由昂贵且专门的多视图 4D 数据或繁琐的训练预处理引起的。相比之下，我们的 NeoVerse 建立在一个核心理念之上，该理念使整个管道可扩展至各种野外单目视频。具体来说，NeoVerse 具有无姿态前馈 4D 重建、在线单目退化模式模拟和其他良好对齐的技术。这些设计使 NeoVerse 具有多功能性并可推广到各个领域。同时，NeoVerse 在标准重建和生成基准方面实现了最先进的性能。我们的项目页面位于 https://neoverse-4d.github.io|[2601.00393](http://arxiv.org/abs/2601.00393)|null|\n",
        "2601.00126": "|**2025-12-31**|**Compositional Diffusion with Guided search for Long-Horizon Planning**|生成模型已成为强大的规划工具，组合方法通过组合本地模块化生成模型为长期任务分布建模提供了特别的希望。这种构图范式跨越了不同的领域，从多步骤操作规划到全景图像合成到长视频生成。然而，组合生成模型面临着一个严峻的挑战：当局部分布是多峰时，现有的组合方法平均不兼容的模式，产生的计划既不局部可行，也不全局一致。我们提出了带有引导搜索的组合扩散（CDGS），它通过将搜索直接嵌入扩散去噪过程来解决这个\\emph{模式平均}问题。我们的方法通过基于总体的采样探索局部模式的不同组合，使用基于可能性的过滤修剪不可行的候选者，并通过重叠片段之间的迭代重采样来强制全局一致性。 CDGS 在七项机器人操作任务上与预言机的性能相匹配，优于缺乏组合性或需要长期训练数据的基线。该方法可以跨领域推广，通过有效的本地到全局消息传递实现连贯的文本引导的全景图像和长视频。更多详细信息：https://cdgsearch.github.io/|[2601.00126](http://arxiv.org/abs/2601.00126)|null|\n",
        "2601.00051": "|**2025-12-31**|**TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model**|世界模型旨在赋予人工智能系统以连贯且时间一致的方式表示、生成动态环境并与之交互的能力。虽然最近的视频生成模型表现出了令人印象深刻的视觉质量，但它们在实时交互、长视野一致性和动态场景的持久记忆方面仍然有限，阻碍了它们向实际世界模型的演进。在本报告中，我们介绍了 TeleWorld，这是一种实时多模态 4D 世界建模框架，它将视频生成、动态场景重建和长期世界记忆统一在闭环系统中。 TeleWorld 引入了一种新颖的生成-重构-指导范式，其中生成的视频流被不断重构为动态 4D 时空表示，从而指导后续生成保持空间、时间和物理一致性。为了支持低延迟的长视野生成，我们采用了基于自回归扩散的视频模型，该模型通过宏观微观规划（MMPL）进行了增强，这是一种分层规划方法，可减少从帧级到段级的误差累积，并结合高效的分布匹配蒸馏（DMD），从而在实际计算预算下实现实时合成。我们的方法在统一的 4D 框架内实现了动态对象建模和静态场景表示的无缝集成，将世界模型推进到实用、交互式和计算可访问的系统。大量实验表明，TeleWorld 在静态和动态世界理解、长期一致性和实时生成效率方面均取得了出色的性能，将其定位为迈向交互式、支持记忆的多模式生成和体现智能的世界模型的实用步骤。|[2601.00051](http://arxiv.org/abs/2601.00051)|null|\n"
    },
    "3D": {
        "2512.24742": "|**2025-12-31**|**Splatwizard: A Benchmark Toolkit for 3D Gaussian Splatting Compression**|最近出现的 3D 高斯分布 (3DGS) 标志着实时新颖视图合成的重大突破。然而，基于 3DGS 的算法的快速普及迫切需要标准化和综合的评估工具，尤其是压缩任务。现有的基准测试通常缺乏全面评估不同方法的独特特征所需的具体指标，例如渲染速度、率失真权衡、内存效率和几何精度。为了弥补这一差距，我们推出了 Splatwizard，这是一个专门为 3DGS 压缩模型进行基准测试而设计的统一基准测试工具包。 Splatwizard 提供了一个易于使用的框架来实现新的 3DGS 压缩模型并利用先前工作提出的最先进的技术。此外，框架中还包含一个集成管道，可自动计算关键性能指标，包括基于图像的质量指标、重建网格的倒角距离、渲染帧速率和计算资源消耗。代码可在 https://github.com/splatwizard/splatwizard 获取|[2512.24742](http://arxiv.org/abs/2512.24742)|null|\n",
        "2512.24647": "|**2025-12-31**|**Solving the inverse Source Problems for wave equation with final time measurements by a data driven approach**|本文开发了一种离散数据驱动的方法，用于通过最终时间测量来解决波动方程的逆源问题。重点关注 $L^2$-Tikhonov 正则化方法，我们使用噪声离散空间观测来分析其在两种不同噪声模型下的收敛性。通过利用前向算子的谱分解并将噪声分离技术引入变分框架，我们为重构解 $u$ 和源项 $f$ 建立了误差界限，而不需要经典源条件。此外，源误差的预期收敛速度是在较弱的拓扑中导出的。我们还将分析扩展到具有有限元离散化的完全离散情况，表明总体误差仅取决于噪声水平、正则化参数、时间步长和空间网格大小。这些估计为在没有先验信息的情况下以数据驱动的方式选择最佳正则化参数提供了基础。数值实验验证了理论结果并证明了所提算法的效率。|[2512.24647](http://arxiv.org/abs/2512.24647)|null|\n",
        "2512.24577": "|**2025-12-31**|**QAOA-MaxCut has barren plateaus for almost all graphs**|近年来，QAOA 一直是深入研究的主题，但相对应的动态李代数 (DLA)——VQA 表达性和可训练性的关键指标——除了高度对称的实例之外，仍然知之甚少。指数级缩放的 DLA 维度与优化领域中所谓的贫瘠高原 (BP) 的存在相关，这使得训练变得棘手。在这项工作中，我们研究了应用于规范 MaxCut 的 QAOA 的 DLA，适用于加权图和未加权图。对于加权图，我们表明，当从连续分布中提取权重时，对于除路径和循环之外的所有连通图，DLA 维数几乎肯定会增长为 $θ(4^n)$。在更常见的未加权设置中，我们表明，除指数消失部分之外的所有图都渐近地具有 $ θ(4 ^ n) $ 大 DLA 维度。还确定了相应 DLA 的整个简单李代数分解，从中我们证明损失函数的方差为 $O(1/2^n)$，这意味着这些加权和未加权图上的 QAOA 都受到 BP 的影响。此外，我们还给出了 DLA 具有指数维数的图族的显式构造，包括 MaxCut 在 $\\mathsf P$ 中的情况。我们对未加权情况的证明基于许多分裂引理和 DLA 自由条件，这些条件允许人们将极其复杂的李代数问题转换为合适的图论问题。这些构成了新算法的基础，该算法计算此类 DLA 的速度比以前的方法快几个数量级，从而将标准硬件上的运行时间从几天缩短到几秒钟。我们将此算法应用于 MQLib，这是一个经典的 MaxCut 基准套件，覆盖超过 3,500 个实例，最多 53,130 个顶点，并发现，忽略边权重，至少 75% 的实例拥有维度至少为 $2^{128}$ 的 DLA。|[2512.24577](http://arxiv.org/abs/2512.24577)|null|\n",
        "2512.24564": "|**2025-12-31**|**CPR: Causal Physiological Representation Learning for Robust ECG Analysis under Distribution Shifts**|用于心电图 (ECG) 诊断的深度学习模型已经取得了显着的准确性，但在对抗对抗性扰动方面表现出脆弱性，特别是模仿生物形态的平滑对抗性扰动 (SAP)。现有的防御措施面临着严峻的困境：对抗训练（AT）提供了鲁棒性，但会产生令人望而却步的计算负担，而随机平滑（RS）等经过认证的方法会引入显着的推理延迟，使得它们对于实时临床监测来说不切实际。我们认为这种脆弱性源于模型对非鲁棒虚假相关性的依赖，而不是不变的病理特征。为了解决这个问题，我们提出因果生理表征学习（CPR）。与不受语义限制的标准去噪方法不同，CPR 在因果解开框架内结合了生理结构先验。通过结构因果模型 (SCM) 对心电图生成进行建模，CPR 强制实施结构干预，将不变的病理形态（P-QRS-T 复合波）与非因果伪影严格分开。 PTB-XL 的经验结果表明，CPR 明显优于标准临床预处理方法。具体来说，在 SAP 攻击下，CPR 的 F1 得分为 0.632，超过 Median Smoothing (0.541 F1) 9.1%。至关重要的是，CPR 与随机平滑经过认证的稳健性相匹配，同时保持单遍推理效率，在稳健性、效率和临床可解释性之间提供卓越的权衡。|[2512.24564](http://arxiv.org/abs/2512.24564)|null|\n",
        "2512.24534": "|**2025-12-31**|**BF-APNN: A Low-Memory Method for Accelerating the Solution of Radiative Transfer Equations**|辐射传递方程（RTE）表现出高维和多尺度特征，使得传统数值方法计算量大。现有的深度学习方法在低维或线性 RTE 中表现良好，但在高维或非线性 RTE 中仍然面临许多挑战。为了克服这些挑战，我们提出了基函数渐近保持神经网络（BF-APNN），该框架继承了辐射传递渐近保持神经网络（RT-APNN）的优点并加速了求解过程。通过对微观组件采用基函数扩展（源自微观-宏观分解），BF-APNN 有效减轻了训练期间与评估高维积分相关的计算负担。数值实验涉及具有非线性、不连续性和多尺度行为特征的具有挑战性的 RTE 场景，结果表明，与 RT-APNN 相比，BF-APNN 大大减少了训练时间，同时保持了较高的解精度。此外，BF-APNN 在解决复杂的高维 RTE 问题方面表现出卓越的性能，凸显了其作为辐射传输计算的强大工具的潜力。|[2512.24534](http://arxiv.org/abs/2512.24534)|null|\n",
        "2512.24506": "|**2025-12-30**|**Generalising E-prop to Deep Networks**|循环网络通常通过时间反向传播（BPTT）进行训练。然而，BPTT 需要存储网络中所有状态的历史记录，然后按时间顺序向后回放它们。对于大脑来说，这种计算似乎极不可能实现。实时循环学习 (RTRL) 提出了一种数学上等效的替代方案，其中梯度信息与常规前向传播一起在本地及时向前传播，但它的计算复杂度明显高于 BPTT，这使得它对于大型网络来说不切实际。 E-prop 提出了 RTRL 的近似，将其复杂性降低到 BPTT 的水平，同时保持纯粹的在线前向更新，可以通过每个突触的资格跟踪来实现。然而，RTRL 和 E-prop 上的工作普遍研究具有循环动态的单层学习。然而，大脑中的学习跨越多个层次，由深度和时间的层次动态组成。在这篇数学笔记中，我们扩展了 E-prop 框架来处理任意深度的网络，推导出一种新颖的跨深度递归关系，将 E-prop 的资格痕迹扩展到更深的层。因此，我们的结果表明，在线学习算法可以同时在时间和深度上执行准确的信用分配，从而允许在不随时间反向传播的情况下训练深度循环网络。|[2512.24506](http://arxiv.org/abs/2512.24506)|null|\n",
        "2512.24483": "|**2025-12-30**|**Decentralized Optimization over Time-Varying Row-Stochastic Digraphs**|有向图的分散优化对于机器人群、传感器网络和分布式学习等应用至关重要。在许多实际场景中，底层网络是时变广播网络（TVBN），由于无法访问出度信息，只能构造行随机混合矩阵。在 TVBN 上实现精确收敛仍然是一个长期悬而未决的问题，因为时变行随机混合矩阵的限制分布取决于不可预测的未来图实现，使得标准偏差校正技术不可行。   本文通过开发第一个仅使用时变行随机矩阵实现精确收敛的算法来解决这个悬而未决的问题。我们提出 PULM（Pull-with-Memory），这是一种八卦协议，通过行随机混合和局部调整之间的交替来达到指数收敛的平均共识。在 PULM 的基础上，我们开发了 PULM-DGD，它收敛到 $\\mathcal{O}(\\ln(T)/T)$ 的平稳解，以实现平滑的非凸目标。我们的结果显着地将去中心化优化扩展到高度动态的通信环境。|[2512.24483](http://arxiv.org/abs/2512.24483)|null|\n",
        "2512.24456": "|**2025-12-30**|**Fast high-order spectral solvers for PDEs on triangulated surfaces with applications to deforming surfaces**|在本文中，我们将基于经典四边形的分层庞加莱-斯特克洛夫（HPS）框架扩展到三角几何。传统上，HPS 方法将非结构化高阶四边形网格作为输入，并依赖于每个元素的张量积谱离散化。为了克服这一限制，我们引入了两种互补的三角形元素高阶策略：一种易于实现的简化四边形化方法，以及基于 Dubiner 多项式的基于三角形的谱元素方法。我们以数值方式表明，这些扩展保留了 HPS 框架的光谱精度、效率和快速直接求解器结构。该方法进一步扩展到时间相关和演化的表面，其性能通过反应扩散系统和几何驱动的表面演化的数值实验得到证明。|[2512.24456](http://arxiv.org/abs/2512.24456)|null|\n",
        "2512.24450": "|**2025-12-30**|**Robust reduced rank regression under heavy-tailed noise and missing data via non-convex penalization**|降阶回归 (RRR) 是通过低维潜在结构对多重响应进行建模的基本工具，可在高维设置中提供可解释性和强大的预测性能。然而，经典的 RRR 方法通常依赖于平方损失和高斯噪声假设，这使得它们对重尾误差、异常值和数据污染敏感。此外，缺失数据的存在（在现代应用中很常见）使可靠的低秩估计变得更加复杂。在本文中，我们提出了一个强大的降级回归框架，该框架可同时解决重尾噪声、异常值和缺失数据。我们的方法将稳健的 Huber 损失与非凸谱正则化相结合，特别是极小最大凹罚分 (MCP) 和平滑剪切绝对偏差 (SCAD)。与凸核范数正则化不同，所提出的非凸惩罚减轻了过度收缩，并能够更准确地恢复底层低秩结构。该方法还可以容纳响应矩阵中缺失的数据，而无需插补。我们开发了一种基于交替更新和定制光谱阈值的高效近端梯度算法。广泛的模拟研究表明，在重尾噪声和污染下，所提出的方法大大优于基于核规范和非鲁棒的替代方法。癌细胞系数据集的应用进一步说明了所提出的稳健 RRR 框架的实际优势。   我们的方法是在 R 包 rrpackrobust 中实现的，该包位于 https://github.com/tienmt/rrpackrobust。|[2512.24450](http://arxiv.org/abs/2512.24450)|null|\n",
        "2512.24428": "|**2025-12-30**|**Subsecond 3D Mesh Generation for Robot Manipulation**|3D 网格是计算机科学和工程中广泛使用的基本表示形式。在机器人技术中，它们特别有价值，因为它们捕获物体的形式与机器人与物理世界的交互方式直接一致，从而实现预测稳定抓取、检测碰撞和模拟动力学等核心功能。尽管自动 3D 网格生成方法近年来取得了可喜的进展，有可能为实时机器人感知提供一条途径，但仍然存在两个关键挑战。首先，生成高保真网格对于实时使用来说非常慢，每个对象通常需要数十秒。其次，网格生成本身是不够的。在机器人技术中，网格必须基于上下文，即从场景中正确分割并以正确的比例和姿势进行注册。此外，除非这些背景基础步骤仍然有效，否则它们只会引入新的瓶颈。在这项工作中，我们引入了一个端到端系统来解决这些挑战，在一秒内从单个 RGB-D 图像生成高质量、基于上下文的 3D 网格。我们的管道集成了开放词汇对象分割、加速的基于扩散的网格生成和强大的点云配准，每项都针对速度和准确性进行了优化。我们展示了它在现实世界操纵任务中的有效性，表明它使网格能够用作机器人感知和规划的实用、按需表示。|[2512.24428](http://arxiv.org/abs/2512.24428)|null|\n",
        "2512.25075": "|**2025-12-31**|**SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time**|我们提出了 SpaceTimePilot，这是一种视频扩散模型，可以解开空间和时间以实现可控的生成渲染。给定单目视频，SpaceTimePilot 可以在生成过程中独立改变摄像机视点和运动序列，重新渲染场景，以实现跨空间和时间的连续和任意探索。为了实现这一目标，我们在扩散过程中引入了一种有效的动画时间嵌入机制，允许对输出视频相对于源视频的运动序列进行显式控制。由于没有数据集提供具有连续时间变化的同一动态场景的配对视频，我们提出了一种简单而有效的时间扭曲训练方案，该方案重新利用现有的多视图数据集来模拟时间差异。该策略有效地监督模型学习时间控制并实现鲁棒的时空解缠结。为了进一步提高双重控制的精度，我们引入了两个额外的组件：改进的相机调节机制，允许从第一帧开始改变相机，以及CamxTime，第一个合成时空全覆盖渲染数据集，可在场景内提供完全自由的时空视频轨迹。对时间扭曲方案和 CamxTime 数据集的联合训练可以产生更精确的时间控制。我们在现实世界和合成数据上评估了 SpaceTimePilot，与之前的工作相比，展示了清晰的时空解离和强大的结果。项目页面：https://zheninghuang.github.io/Space-Time-Pilot/ 代码：https://github.com/ZheningHuang/spacetimepilot|[2512.25075](http://arxiv.org/abs/2512.25075)|null|\n",
        "2512.25071": "|**2025-12-31**|**Edit3r: Instant 3D Scene Editing from Sparse Unposed Images**|我们提出了 Edit3r，这是一个前馈框架，可以从未摆姿势、视图不一致、指令编辑的图像中一次性重建和编辑 3D 场景。与之前需要针对场景进行优化的方法不同，Edit3r 直接预测指令对齐的 3D 编辑，从而无需优化或姿态估计即可实现快速且逼真的渲染。训练这种模型的一个关键挑战在于缺乏用于监督的多视图一致编辑图像。我们通过（i）基于 SAM2 的重新着色策略来解决这个问题，该策略生成可靠的、跨视图一致的监督，以及（ii）不对称输入策略，将重新着色的参考视图与原始辅助视图配对，鼓励网络融合和对齐不同的观察结果。据推断，我们的模型可以有效地处理通过 InstructPix2Pix 等 2D 方法编辑的图像，尽管在训练期间没有接触到此类编辑。对于大规模定量评估，我们引入了DL3DV-Edit-Bench，这是一个基于DL3DV测试分割构建的基准测试，具有20个不同的场景、4种编辑类型和总共100个编辑。全面的定量和定性结果表明，与最近的基线相比，Edit3r 实现了卓越的语义对齐和增强的 3D 一致性，同时以显着更高的推理速度运行，使其在实时 3D 编辑应用程序中具有广阔的前景。|[2512.25071](http://arxiv.org/abs/2512.25071)|null|\n",
        "2512.24986": "|**2025-12-31**|**PhysTalk: Language-driven Real-time Physics in 3D Gaussian Scenes**|逼真的视觉模拟无处不在，但它们的创作需要计算时间、渲染和专业的动画知识。从文本输入生成开放词汇视觉效果成为一种有前途的解决方案，可以释放巨大的创造潜力。然而，当前的管道缺乏物理现实性和有效的语言接口，需要缓慢的离线优化。相比之下，PhysTalk 采用 3D 高斯溅射 (3DGS) 场景作为输入，并将任意用户提示转换为实时、基于物理的交互式 4D 动画。大型语言模型 (LLM) 生成可执行代码，通过轻量级代理和粒子动力学直接修改 3DGS 参数。值得注意的是，PhysTalk 是第一个将 3DGS 与物理模拟器直接耦合的框架，无需依赖耗时的网格提取。在保留开放词汇的同时，该设计通过对任意多材质对象的碰撞感知、基于物理的操作来实现交互式 3D 高斯动画。最后，PhysTalk 无需训练且计算量轻：这使得 4D 动画可以广泛使用，并将这些工作流程从“渲染和等待”范式转变为与现代物理信息管道的交互式对话。|[2512.24986](http://arxiv.org/abs/2512.24986)|null|\n",
        "2512.24985": "|**2025-12-31**|**DarkEQA: Benchmarking Vision-Language Models for Embodied Question Answering in Low-Light Indoor Environments**|视觉语言模型（VLM）越来越多地被采用作为实体代理的中央推理模块。现有的基准测试是在理想、光线充足的条件下评估其功能，但强大的 24/7 运行要求在各种视觉退化情况下都具有性能，包括夜间低光条件或黑暗环境中——这是一个在很大程度上被忽视的核心必要条件。为了解决这一尚未充分探索的挑战，我们提出了 DarkEQA，这是一个开源基准，用于在多级低光条件下评估 EQA 相关的感知基元。 DarkEQA 通过在受控降级下评估以自我为中心的观察的问答来隔离感知瓶颈，从而实现归因稳健性分析。 DarkEQA 的一个关键设计特点是其物理保真度：在线性 RAW 空间中对视觉退化进行建模，模拟基于物理的照明下降和传感器噪声，然后采用 ISP 启发的渲染管道。我们通过评估各种最先进的 VLM 和低光图像增强 (LLIE) 模型来展示 DarkEQA 的实用性。我们的分析系统地揭示了 VLM 在这些具有挑战性的视觉条件下运行时的局限性。我们的代码和基准数据集将在接受后发布。|[2512.24985](http://arxiv.org/abs/2512.24985)|null|\n",
        "2512.24970": "|**2025-12-31**|**Random Batch Sum-of-Gaussians Method for Molecular Dynamics of Born-Mayer-Huggins Systems**|玻恩-梅耶-哈金斯 (BMH) 势结合了库仑相互作用、色散和短程指数斥力，广泛用于熔盐等离子材料。然而，BMH 系统的大规模分子动力学模拟通常受到计算、通信和内存成本的限制。我们最近提出了随机批量高斯和（RBSOG）方法，该方法通过使用高斯和（SOG）分解将势分解为短程和长程部分，并在傅里叶空间中对长程部分应用重要性采样，从而加速库仑计算。在这项工作中，我们将 RBSOG 扩展到 BMH 系统，并结合随机批处理列表 (RBL) 方案来进一步加速短程部分，从而产生一个统一的框架，用于具有 BMH 潜力的高效模拟。 SOG 分解和 RBL 的结合能够有效且可扩展地处理 BMH 系统中的长程和短程相互作用，特别是 RBL 可以通过随机批量邻居列表很好地处理中程指数排斥和色散。提供误差估计以显示 RBL 力的理论收敛性。我们在 2048 美元的 CPU 核心上使用高达 5\\times10^6$ 原子的熔融氯化钠和混合碱金属卤化物来评估该框架。与基于 Ewald 的粒子-粒子粒子网格方法和仅 RBSOG 方法相比，我们的方法在使用 $1000$ 核心时分别实现了大约 $4\\sim10\\times$ 和 $2\\times$ 加速，在相同水平的结构和热力学精度下，并且内存使用量减少。这些结果证明了我们的方法在远程交互 MD 模拟的准确性和可扩展性方面具有有吸引力的性能。|[2512.24970](http://arxiv.org/abs/2512.24970)|null|\n",
        "2512.24951": "|**2025-12-31**|**Laser intracavity absorption magnetometry for optical quantum sensing**|腔内吸收光谱 (ICAS) 是一种成熟的技术，用于以超高灵敏度检测微弱吸收信号。在这里，我们将这一概念扩展到使用金刚石中的氮空位（NV）中心的磁力测量。我们引入了激光腔内吸收磁力计（LICAM），这一概念原则上适用于更广泛的光学量子传感器，包括光泵磁力计。使用可自我维持运行的电驱动、边缘发射二极管激光器，我们证明 LICAM 可以实现在环境条件下运行的高灵敏度磁力计。在接近激光阈值时，与传统的单通道几何结构相比，我们的光学对比度提高了 475 倍，磁灵敏度提高了 180 倍。单模二极管激光器的速率方程模型准确地描述了实验结果。根据我们的测量，我们确定了 $\\mathrm{pT}\\,\\mathrm{Hz}^{-1/2}$ 范围内的预计散粒噪声限制灵敏度，并表明，通过实际设备的改进，可以实现低至 $\\mathrm{fT}\\,\\mathrm{Hz}^{-1/2}$ 范围的灵敏度。|[2512.24951](http://arxiv.org/abs/2512.24951)|null|\n",
        "2512.24848": "|**2025-12-31**|**PrivacyBench: A Conversational Benchmark for Evaluating Privacy in Personalized AI**|个性化人工智能代理依赖于对用户数字足迹的访问，其中通常包括来自私人电子邮件、聊天和购买历史记录的敏感数据。然而，这种访问会带来根本性的社会和隐私风险：缺乏社会情境意识的系统可能会无意中泄露用户秘密，从而威胁到数字福祉。我们引入了 PrivacyBench，这是一个基准，具有包含嵌入式秘密的基于社会的数据集和用于衡量秘密保存的多轮对话评估。测试检索增强生成 (RAG) 助手表明，他们在高达 26.56% 的交互中泄露秘密。隐私意识提示可将泄漏率降低至 5.12%，但该措施仅提供部分缓解。检索机制继续不加区别地访问敏感数据，这将隐私保护的全部负担转移到了生成器身上。这会造成单点故障，导致当前架构不适合大规模部署。我们的研究结果强调迫切需要结构性、隐私设计保障措施，以确保为每个人提供一个道德和包容的网络。|[2512.24848](http://arxiv.org/abs/2512.24848)|null|\n",
        "2512.24827": "|**2025-12-31**|**Discovering Coordinated Joint Options via Inter-Agent Relative Dynamics**|暂时延长的操作提高了在单代理环境中探索和计划的能力。在多智能体设置中，联合状态空间随着智能体数量的指​​数增长使得协调行为变得更加有价值。然而，同样的指数增长使得多代理选项的设计特别具有挑战性。现有的多智能体选项发现方法通常会产生松散耦合或完全独立的行为，从而牺牲协调性。为了解决这些限制，我们描述了一种多代理选项发现的新方法。具体来说，我们提出了一种联合状态抽象，它压缩状态空间，同时保留发现强协调行为所需的信息。我们的方法建立在归纳偏差的基础上，即代理状态的同步为缺乏明确目标的情况下的协调提供了自然的基础。我们首先近似与团队最大对齐的虚拟状态，即 \\textit{Fermat} 状态，并用它来定义 \\textit{spreadness} 的度量，捕获每个单独状态维度上的团队级别的错位。基于这种表示，我们然后采用神经图拉普拉斯估计器来导出捕获代理之间状态同步模式的选项。我们评估了两个多智能体域中多个场景的结果选项，表明与替代选项发现方法相比，它们产生了更强的下游协调能力。|[2512.24827](http://arxiv.org/abs/2512.24827)|null|\n",
        "2512.24794": "|**2025-12-31**|**Nonlinear Noise2Noise for Efficient Monte Carlo Denoiser Training**|Noise2Noise 方法允许使用成对的输入和目标图像来训练基于机器学习的降噪器，其中输入和目标都可能有噪声。这消除了使用很难获得的干净目标图像进行训练的需要。然而，Noise2Noise 训练有一个主要限制：应用于噪声目标的非线性函数会扭曲结果。出现这种偏差是因为非线性使得噪声目标的期望值与干净的目标图像不同。由于非线性函数在图像处理中很常见，因此避免使用非线性函数会限制可对噪声目标执行的预处理类型。我们的主要见解是，某些非线性函数可以应用于噪声目标，而不会给结果带来明显的偏差。我们开发了一个理论框架来分析这些非线性的影响，并描述一类具有最小偏差的非线性函数。   我们展示了我们对蒙特卡罗渲染生成的高动态范围（HDR）图像进行去噪的方法。 Noise2Noise 训练在处理 HDR 图像时可能会遇到问题，训练过程会被异常值淹没并且表现不佳。我们考虑解决这些训练问题的常用方法：将非线性色调映射函数应用于模型输出和目标图像以减少其动态范围。由于涉及非线性，该方法之前被认为与 Noise2Noise 训练不兼容。我们表明，损失函数和色调映射函数的某些组合可以减少异常值的影响，同时引入最小的偏差。我们将我们的方法应用于现有的基于机器学习的蒙特卡罗降噪器，其中原始实现是使用高样本计数参考图像进行训练的。我们的结果接近原始实现的结果，但仅使用噪声训练数据生成。|[2512.24794](http://arxiv.org/abs/2512.24794)|null|\n",
        "2512.24763": "|**2025-12-31**|**UniC-Lift: Unified 3D Instance Segmentation via Contrastive Learning**|3D 高斯散射 (3DGS) 和神经辐射场 (NeRF) 具有先进的新颖视图合成。最近的方法将多视图 2D 分割扩展到 3D，从而实现实例/语义分割以更好地理解场景。一个关键挑战是跨视图的 2D 实例标签不一致，导致 3D 预测效果不佳。现有方法采用两阶段方法，其中一些方法依赖于超参数敏感聚类的对比学习，而另一些方法则预处理标签以确保一致性。我们提出了一个统一的框架，合并这些步骤，通过引入用于高斯原语分割的可学习特征嵌入来减少训练时间并提高性能。然后，通过新颖的“嵌入到标签”过程，将这种嵌入有效地解码为实例标签，从而有效地集成优化。虽然这个统一的框架提供了巨大的好处，但我们在对象边界观察到了伪影。为了解决对象边界问题，我们提出沿着这些边界进行硬挖掘样本。然而，直接将硬挖掘应用于特征嵌入被证明是不稳定的。因此，我们在计算三元组损失之前对栅格化特征嵌入应用线性层，这可以稳定训练并显着提高性能。我们的方法在 ScanNet、Replica3D 和 Messy-Rooms 数据集上的定性和定量优于基线。|[2512.24763](http://arxiv.org/abs/2512.24763)|null|\n",
        "2601.00796": "|**2026-01-02**|**AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction**|从单目视频重建动态 3D 场景需要同时捕获高频外观细节和时间连续运动。使用单个高斯原语的现有方法受到其低通滤波性质的限制，而标准 Gabor 函数会引入能量不稳定。此外，缺乏时间连续性约束通常会导致插值期间出现运动伪影。我们提出了 AdaGaR，一个统一的框架，解决显式动态场景建模中的频率自适应性和时间连续性问题。我们引入了自适应 Gabor 表示，通过可学习的频率权重和自适应能量补偿来扩展高斯模型，以平衡细节捕捉和稳定性。为了实现时间连续性，我们采用具有时间曲率正则化的三次 Hermite 样条来确保平滑的运动演化。结合深度估计、点跟踪和前景掩模的自适应初始化机制在早期训练中建立稳定的点云分布。 Tap-Vid DAVIS 上的实验展示了最先进的性能（PSNR 35.49、SSIM 0.9433、LPIPS 0.0723）以及跨帧插值、深度一致性、视频编辑和立体视图合成的强大泛化能力。项目页面：https://jiewenchan.github.io/AdaGaR/|[2601.00796](http://arxiv.org/abs/2601.00796)|null|\n",
        "2601.00702": "|**2026-01-02**|**DefVINS: Visual-Inertial Odometry for Deformable Scenes**|可变形场景违反了支撑经典视觉惯性里程计 (VIO) 的刚性假设，当变形主导视觉视差时，通常会导致局部非刚性运动过度拟合或严重漂移。我们引入了 DefVINS，一种视觉惯性里程计框架，它明确地将刚性、IMU 锚定状态与由嵌入变形图表示的非刚性扭曲分开。该系统使用标准 VIO 程序进行初始化，该程序修复了重力、速度和 IMU 偏差，之后随着估计的条件良好，逐渐激活非刚性自由度。包括可观测性分析，以描述惯性测量如何限制刚性运动，并在存在变形的情况下使其他不可观测的模式变得可识别。该分析促进了 IMU 锚定的使用，并为基于条件的激活策略提供了信息，该策略可防止不良激励下的不适定更新。烧蚀研究证明了将惯性约束与可观察性变形激活相结合的好处，从而提高了非刚性环境下的鲁棒性。|[2601.00702](http://arxiv.org/abs/2601.00702)|null|\n",
        "2601.00678": "|**2026-01-02**|**Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians**|人类擅长仅凭一张图像来预测场景的未来动态。能够模仿这种能力的视频生成模型是智能系统的重要组成部分。最近的方法提高了单图像条件视频生成中的时间相干性和 3D 一致性。然而，这些方法通常缺乏强大的用户可控性，例如修改相机路径，限制了它们在实际应用中的适用性。大多数现有的相机控制的图像到视频模型都难以准确建模相机运动、保持时间一致性和保持几何完整性。利用显式中间 3D 表示可实现与给定摄像机轨迹对齐的连贯视频生成，从而提供了一种有前景的解决方案。尽管这些方法通常使用 3D 点云来渲染场景并在后期引入对象运动，但尽管允许精确控制相机运动，但这种两步过程仍然无法实现完全的时间一致性。我们提出了一种新颖的框架，在单次前向传递中给定单个图像的情况下，构建 3D 高斯场景表示并对合理的对象运动进行采样。这使得能够快速生成相机引导的视频，而无需迭代去噪将对象运动注入渲染帧。在 KITTI、Waymo、RealEstate10K 和 DL3DV-10K 数据集上进行的大量实验表明，我们的方法实现了最先进的视频质量和推理效率。该项目页面位于 https://melonienimasha.github.io/Pixel-to-4D-Website。|[2601.00678](http://arxiv.org/abs/2601.00678)|null|\n",
        "2601.00599": "|**2026-01-02**|**The thermodynamics of pressure activated assembly of supramolecules in isochoric and isobaric systems**|冷冻保存的功效受到难以获得足够高的细胞内冷冻保护溶质浓度而不在加载过程中引起渗透损伤或化学毒性的限制。这项热力学研究引入了一种将冷冻保护剂直接或通过血管灌注输送到细胞中的新概念机制。在此框架中，通过压力激活由冷冻保护剂单体或低聚物组成的膜渗透超分子组装体的分解，原位产生高浓度的细胞内冷冻保护溶质，可以实现有效的冷冻保护。这些超分子最初以低浓度存在，预计通过被动分配或内吞作用以最小的渗透效应进入细胞，并随后在分解时转化为高细胞内浓度的冷冻保护剂。我们提出，在等容（恒定体积）冷冻过程中固有产生的或在等压（恒定压力）条件下外部施加的升高的静水压力可以使超分子组装体不稳定，其解离状态所占的摩尔体积比组装状态的摩尔体积更小。在等容冷冻下，固定体积内的冰形成会产生显着的压力增加，这是相变的热力学结果，使压力成为由亥姆霍兹自由能控制的因变量。在等压条件下，压力通过吉布斯自由能充当外部控制变量。在这两种配方中，压力激活的分解将膜传输与冷冻保护剂的可用性分离，并能够在冷却或冷冻过程中精确地同步溶质生成，而无需预加载渗透活性溶质。|[2601.00599](http://arxiv.org/abs/2601.00599)|null|\n",
        "2601.00583": "|**2026-01-02**|**HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts**|虽然联邦学习 (FL) 可以在不损害数据隐私的情况下对大型语言模型 (LLM) 进行微调，但 LLM 的庞大规模使得设备上培训对于资源受限的客户端（例如移动设备）来说不切实际。因此，专家混合（MoE）模型已成为一种计算高效的解决方案，它在模型训练期间仅激活稀疏的专家子集，以在不牺牲性能的情况下减轻计算负担。尽管将 MoE 集成到 FL 微调中具有巨大的潜力，但它仍然面临三个关键挑战：i）为客户选择合适的专家仍然具有挑战性，因为缺乏可靠的指标来衡量每个专家对本地微调性能的影响，ii）跨客户端的异构计算资源严重阻碍了基于 MoE 的 LLM 微调，因为跨不同输入样本的动态专家激活可能会压垮资源受限的设备，以及 iii）特定于客户端的专家子集和路由偏好会破坏全局聚合，其中未对齐专家更新和不一致的门控网络会产生破坏性干扰。为了应对这些挑战，我们提出了 HFedMoE，这是一种基于 MoE 的异构 FL 微调框架，可为每个客户定制专家子集，以实现计算高效的 LLM 微调。具体来说，HFedMoE 根据专家对微调性能的贡献来识别专家的重要性，然后从信息瓶颈的角度自适应地选择专家子集，以与每个客户端的计算预算保持一致。稀疏感知模型聚合策略还旨在聚合主动微调的专家和具有重要性加权贡献的门控参数。大量实验表明 HFedMoE 在训练精度和收敛速度方面优于最先进的基准。|[2601.00583](http://arxiv.org/abs/2601.00583)|null|\n",
        "2601.00552": "|**2026-01-02**|**Tabletop X-ray ghost video of moving objects**|X射线成像广泛应用于临床医学、工业检测和各种科学研究领域。不幸的是，目前使用的大多数 X 射线二维 (2D) 探测器都存在像素数量和读出时间之间的根本权衡问题，这使得它们不适合快速移动物体成像，并且读出死区时间会导致帧丢失。 X 射线重影成像 (XGI) 提供了一种仅使用高灵敏度单像素探测器对物体进行成像的替代方法。然而，现有 XGI 方法的一个关键限制是所需的总采集时间过长，这使得它对于实际应用来说不切实际。在本文中，我们提出了一种基于编码到快速旋转掩模上的随机二进制模式的快速空间调制方案。以高达每秒 200 帧的成像速率和 225 微米的分辨率展示了移动物体的清晰 X 射线可视化。我们的方法首次大大提高了XGI成像速度，为运动物体的X射线成像应用铺平了道路，例如旋转航空发动机的检查和体内医学成像。|[2601.00552](http://arxiv.org/abs/2601.00552)|null|\n",
        "2601.00541": "|**2026-01-02**|**Asymptotic Distribution-Free Tests for Ultra-high Dimensional Parametric Regressions via Projected Empirical Processes and $p$-value Combination**|本文开发了一种基于预测经验过程和 p 值组合来测试稀疏参数回归模型拟合优度的新颖方法，其中协变量维度可能大大超过样本大小。在这种超高维设置中，传统的基于经验过程的检验常常会失败，因为维数灾难或它们对参数估计量的渐近线性和正态性的依赖——这些属性在超高维场景下可能不成立。为了克服这些挑战，我们首先将经典的鞅变换扩展到温和条件下的超高维设置，并基于对单位球体上的任何投影的鞅变换、投影残差标记经验过程构建 Cramer-von Mises 类型检验。鞅变换使该投影检验渐近无分布，并使我们能够仅使用参数估计器的标准收敛率导出其极限分布。虽然在温和条件下，单位球体上的几乎所有投影的投影测试都是一致的，但它仍然可能会遭受特定投影的功率损失。因此，我们进一步采用强大的 p 值组合程序（例如柯西组合）来聚合多个预测的 p 值，从而增强整体稳健性。此外，认识到基于经验过程的测试擅长检测低频信号，而局部平滑测试通常优于高频信号，因此我们提出了一种新颖的混合测试，使用柯西组合聚合这两种方法。由此产生的混合测试对于低频和高频替代方案都很有效。 $\\cdots$|[2601.00541](http://arxiv.org/abs/2601.00541)|null|\n",
        "2601.00535": "|**2026-01-02**|**FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection**|大规模文本到图像（T2I）扩散模型擅长开放域合成，但在精确文本渲染方面仍然存在困难，特别是对于多行布局、密集排版和中文等长尾脚本。先前的解决方案通常需要昂贵的再培训或严格的外部布局限制，这会降低美观性并限制灵活性。我们提出了 \\textbf{FreeText}，这是一种免训练、即插即用的框架，它通过利用 \\emph{Diffusion Transformer (DiT)} 模型的内在机制来改进文本渲染。 \\textbf{FreeText} 将问题分解为 \\emph{写在哪里} 和 \\emph{写什么}。对于 \\emph{where to write}，我们通过从内生图像到文本注意力中读取标记方式的空间属性来定位写入区域，使用类似接收器的标记作为稳定的空间锚点和拓扑感知的细化来生成高置信度的掩模。对于\\emph{写什么}，我们引入了频谱调制字形注入（SGMI），它通过频域带通调制先注入噪声对齐的字形，以加强字形结构并抑制语义泄漏（呈现概念而不是单词）。在 longText-Benchmark、CVTG 和我们的 CLT-Bench 上对 Qwen-Image、FLUX.1-dev 和 SD3 变体进行的广泛实验表明，文本可读性得到了一致的提高，同时在很大程度上保留了语义对齐和美学质量，并且推理开销适中。|[2601.00535](http://arxiv.org/abs/2601.00535)|null|\n",
        "2601.00491": "|**2026-01-01**|**Transfer-learned Kolosov-Muskhelishvili Informed Neural Networks for Fracture Mechanics**|基于物理的神经网络已广泛应用于固体力学问题。然而，平衡控制偏微分方程和边界条件仍然具有挑战性，特别是在断裂力学中，准确的预测很大程度上取决于裂纹尖端附近的精细采样。为了克服这些限制，本研究开发了具有 Williams 丰富功能的 Kolosov-Muskhelishvili 知情神经网络。得益于全纯表示，控制方程可通过构造得到满足，并且只需要边界点进行训练。在一系列基准问题中，Kolosov-Muskhelishvili 知情神经网络与分析法和有限元方法参考文献表现出极好的一致性，对于模式 I 和模式 II 载荷，平均相对误差低于 1\\%，$R^2$ 高于 0.99。此外，使用迁移学习策略将三个裂纹扩展准则（最大切向应力、最大能量释放率和局部对称原理）集成到框架中来预测裂纹扩展方向。所有标准下的预测路径几乎相同，并且迁移学习策略将所需的训练时间减少了 70% 以上。总体而言，开发的框架提供了一种统一、无网格且物理一致的方法，用于准确、高效的裂纹扩展分析。|[2601.00491](http://arxiv.org/abs/2601.00491)|null|\n",
        "2601.00399": "|**2026-01-01**|**A weak Galerkin least squares finite element method for linear convection equations in non-divergence form**|本文针对非散度形式的一阶线性对流方程开发了一种弱伽辽金最小二乘（WG--LS）有限元方法。该方法是使用不连续有限元函数制定的，不需要对对流矢量或反应系数进行任何矫顽力假设。由此产生的离散问题导致对称和正定线性系统，并且适用于一般的多边形和多面体网格。在系数的最小规律性假设下，在合适的能量范数下为 WG--LS 近似建立最优阶误差估计。数值实验验证了理论收敛结果并证明了该方法的准确性和效率。|[2601.00399](http://arxiv.org/abs/2601.00399)|null|\n"
    },
    "具生智能&自动驾驶": {
        "2512.24712": "|**2025-12-31**|**LSRE: Latent Semantic Rule Encoding for Real-Time Semantic Risk Detection in Autonomous Driving**|现实世界的自动驾驶必须遵守复杂的人类社会规则，这些规则超出了法律规定的交通法规。许多语义约束，例如让给紧急车辆、遵守交通官员的手势或停车等校车，对人类来说是直观的，但难以明确编码。尽管大型视觉语言模型（VLM）可以解释此类语义，但其推理成本使得它们对于实时部署来说不切实际。这项工作提出了 LSRE，一种潜在语义规则编码框架，它将稀疏采样的 VLM 判断转换为循环世界模型的潜在空间内的决策边界。通过将语言定义的安全语义编码到轻量级潜在分类器中，LSRE 能够以 10 Hz 的频率进行实时语义风险评估，而无需每帧 VLM 查询。 CARLA 中六个语义失败场景的实验表明，LSRE 获得了与大型 VLM 基线相当的语义风险检测精度，同时提供了更早的危险预测并保持了较低的计算延迟。 LSRE 进一步推广到罕见的语义相似测试用例，表明语言引导的潜在分类为自动驾驶中的语义安全监控提​​供了一种有效且可部署的机制。|[2512.24712](http://arxiv.org/abs/2512.24712)|null|\n",
        "2512.24673": "|**2025-12-31**|**VLA-RAIL: A Real-Time Asynchronous Inference Linker for VLA Models and Robots**|视觉-语言-动作（VLA）模型在机器人技术领域取得了显着的突破，其中动作块在这些进步中发挥着主导作用。鉴于机器人运动控制的实时性和连续性，融合连续动作块队列的策略对 VLA 模型的整体性能具有深远的影响。现有方法在机器人动作执行中存在抖动、停顿甚至暂停的问题，这不仅限制了可实现的执行速度，而且降低了任务完成的整体成功率。本文介绍了 VLA-RAIL（实时异步推理链接器），这是一种新颖的框架，旨在通过异步进行模型推理和机器人运动控制并保证平滑、连续和高速的动作执行来解决这些问题。该论文的核心贡献有两个方面：轨迹平滑器（Trajectory Smoother）使用多项式拟合有效地滤除一个动作块轨迹中的噪声和抖动；块融合器（Chunk Fuser）无缝对齐当前执行轨迹和新到达的块，确保两个连续动作块之间的位置、速度和加速度连续性。我们在动态模拟任务和几个实际操作任务的基准上验证了 VLA-RAIL 的有效性。实验结果表明，VLA-RAIL显着降低了运动抖动，提高了执行速度，提高了任务成功率，这将成为VLA模型大规模部署的关键基础设施。|[2512.24673](http://arxiv.org/abs/2512.24673)|null|\n",
        "2512.24653": "|**2025-12-31**|**RoboMIND 2.0: A Multimodal, Bimanual Mobile Manipulation Dataset for Generalizable Embodied Intelligence**|虽然数据驱动的模仿学习彻底改变了机器人操作，但目前的方法仍然受到缺乏大规模、多样化的现实世界演示的限制。因此，现有模型在非结构化环境中泛化长期双手任务和移动操作的能力仍然有限。为了弥补这一差距，我们推出了 RoboMIND 2.0，这是一个全面的现实世界数据集，包含在 6 个不同的机器人实施例和 739 个复杂任务中收集的超过 310K 个双臂操作轨迹。至关重要的是，为了支持接触丰富和空间扩展任务的研究，该数据集包含 12K 触觉增强片段和 20K 移动操作轨迹。为了补充这些物理数据，我们构建了现实世界环境的高保真数字孪生，并发布了额外的 20K 轨迹模拟数据集，以促进稳健的模拟到真实的传输。为了充分发挥 RoboMIND 2.0 的潜力，我们提出了 MIND-2 系统，这是一个通过离线强化学习优化的分层双系统框架。 MIND-2 集成了一个高级语义规划器 (MIND-2-VLM)，可将抽象的自然语言指令分解为基础子目标，再加上一个低级视觉-语言-动作执行器 (MIND-2-VLA)，可生成精确的、本体感觉感知的运动动作。|[2512.24653](http://arxiv.org/abs/2512.24653)|null|\n",
        "2512.24619": "|**2025-12-31**|**Decentralized No-Regret Frequency-Time Scheduling for FMCW Radar Interference Avoidance**|汽车 FMCW 雷达对于现代 ADAS 和自动驾驶系统不可或缺，但其不断增加的密度也加剧了相互干扰的风险。现有的缓解技术，包括反应性接收器端抑制、主动波形设计和协作调度，通常面临可扩展性、对侧信道通信的依赖或距离多普勒分辨率下降的限制。基于我们早期关于分散频域无遗憾跳跃的工作，本文引入了一个统一的时频博弈论框架，使雷达能够适应频谱和时间资源。我们将干扰避免问题表述为重复的反协调博弈，其中每个雷达使用遗憾最小化动态自主更新频率子带和线性调频脉冲级时间偏移的混合策略。我们表明，所提出的时频无遗憾跳跃算法实现了外部和交换遗憾的消失，并且诱导的经验游戏收敛到$\\varepsilon$-粗相关均衡或相关均衡。理论分析提供了联合域中的遗憾界限，揭示了时间自适应如何隐式地规范频率选择并增强针对异步干扰的鲁棒性。多雷达场景的数值实验表明，与时频随机跳频和集中式基于纳什的基准相比，SINR、碰撞率和距离多普勒质量有了显着改善。|[2512.24619](http://arxiv.org/abs/2512.24619)|null|\n",
        "2512.24497": "|**2025-12-30**|**What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?**|人工智能领域的一个长期挑战是开发能够解决各种物理任务并泛化到新的、看不见的任务和环境的代理。最近流行的方法涉及从状态动作轨迹训练世界模型，然后将其与规划算法一起使用来解决新任务。规划通常在输入空间中执行，但最近的一系列方法引入了规划算法，可以在世界模型的学习表示空间中进行优化，并承诺抽象不相关的细节会产生更有效的规划。在这项工作中，我们将这个系列的模型描述为 JEPA-WM，并研究使此类算法发挥作用的技术选择。我们建议对几个关键组成部分进行全面研究，目的是找到家庭内的最佳方法。我们使用模拟环境和现实世界的机器人数据进行了实验，并研究了模型架构、训练目标和规划算法如何影响规划的成功。我们结合我们的研究结果提出了一个模型，该模型在导航和操作任务方面均优于两个既定基线 DINO-WM 和 V-JEPA-2-AC。代码、数据和检查点可在 https://github.com/facebookresearch/jepa-wms 获取。|[2512.24497](http://arxiv.org/abs/2512.24497)|null|\n",
        "2512.24470": "|**2025-12-30**|**Foundation models on the bridge: Semantic hazard detection and safety maneuvers for maritime autonomy with vision-language models**|IMO MASS 规则草案要求自主和远程监管的海船检测偏离其操作设计范围的情况，输入通知操作员的预定义后备措施，允许立即人工干预，并避免在未经批准的情况下更改航行计划。在警报接管间隙中履行这些义务需要采取短期的、人类可超越的后备策略。当正确的行动取决于含义时，经典的海上自治堆栈就会陷入困境（例如，潜水员放下旗帜意味着有人在水中，火灾靠近意味着危险）。我们认为（i）视觉语言模型（VLM）为这种分布外的情况提供语义意识，并且（ii）具有短视野、人类可覆盖的回退策略的快慢异常管道使得这在切换窗口中变得实用。我们引入了 Semantic Lookout，这是一种仅使用相机、候选者约束的视觉语言模型 (VLM) 后备机动选择器，它在持续的人类权威下从有效的、世界锚定的轨迹中选择一个谨慎的动作（或定位）。在 40 个港口场景中，我们测量了每次呼叫的场景理解和延迟、与人类共识的一致性（三人多数投票模型）、火灾危险场景的短期风险缓解以及水上警报 -> 后备机动 -> 操作员移交。 Sub-10 s 模型保留了较慢的最先进模型的大部分意识。后备机动选择器的性能优于仅几何基线，并增加了火灾场景中的隔离距离。现场运行验证端到端操作。这些结果支持VLM作为与IMO MASS代码草案兼容的语义回退机动选择器，在实际延迟预算内，并激励未来在域适应、混合自主方面的工作，将基础模型语义与多传感器鸟瞰感知和短视野重新规划相结合。|[2512.24470](http://arxiv.org/abs/2512.24470)|null|\n",
        "2512.24426": "|**2025-12-30**|**Counterfactual VLA: Self-Reflective Vision-Language-Action Model with Adaptive Reasoning**|最近的推理增强视觉-语言-动作（VLA）模型通过生成中间推理轨迹提高了端到端自动驾驶的可解释性。然而，这些模型主要描述他们的感知和打算做什么，很少质疑他们计划的行动是否安全或适当。这项工作引入了 Counterfactual VLA (CF-VLA)，这是一种自我反思的 VLA 框架，使模型能够在执行之前推理并修改其计划的操作。 CF-VLA 首先生成总结驾驶意图的时间分段元动作，然后根据元动作和视觉上下文执行反事实推理。此步骤模拟潜在结果，识别不安全行为，并输出指导最终轨迹生成的纠正元操作。为了有效地获得这种自我反思能力，我们提出了一个 rollout-filter-label 管道，该管道从基础（非反事实）VLA 的 rollout 中挖掘高价值场景，并为后续训练轮次标记反事实推理痕迹。在大规模驾驶数据集上的实验表明，CF-VLA 将轨迹精度提高了 17.6%，将安全指标提高了 20.5%，并表现出自适应思维：它只在具有挑战性的场景中实现反事实推理。通过将推理痕迹从一次性描述转变为因果自我校正信号，CF-VLA 向自我反思的自动驾驶代理迈出了一步，这些代理学会在行动之前思考。|[2512.24426](http://arxiv.org/abs/2512.24426)|null|\n",
        "2512.24385": "|**2025-12-30**|**Forging Spatial Intelligence: A Roadmap of Multi-Modal Data Pre-Training for Autonomous Systems**|包括自动驾驶汽车和无人机在内的自主系统的快速发展，更加迫切地需要从多模式车载传感器数据中打造真正的空间智能。虽然基础模型在单模态环境中表现出色，但将其功能集成到相机和激光雷达等不同传感器中以形成统一的理解仍然是一项艰巨的挑战。本文提出了多模式预训练的综合框架，确定了推动实现这一目标的核心技术集。我们剖析了基本传感器特征和学习策略之间的相互作用，评估了特定于平台的数据集在实现这些进步中的作用。我们的核心贡献是为预训练范式制定统一的分类法：从单模态基线到复杂的统一框架，学习 3D 对象检测和语义占用预测等高级任务的整体表示。此外，我们研究了文本输入和占用表示的整合，以促进开放世界的感知和规划。最后，我们确定了关键瓶颈，例如计算效率和模型可扩展性，并提出了通用多模态基础模型的路线图，该模型能够实现稳健的空间智能以进行实际部署。|[2512.24385](http://arxiv.org/abs/2512.24385)|null|\n",
        "2512.24331": "|**2025-12-30**|**Spatial-aware Vision Language Model for Autonomous Driving**|虽然视觉语言模型 (VLM) 通过利用语言模型中嵌入的常识显示出端到端自动驾驶的重大前景，但它们对 2D 图像线索的复杂场景理解和决策的依赖为安全性和可靠性带来了关键瓶颈。当前基于图像的方法难以实现精确的度量空间推理和几何推理，导致驾驶策略不可靠。为了弥补这一差距，我们提出了 LVLDrive（LiDAR-Vision-Language），这是一种新颖的框架，专门设计用于通过结合 LiDAR 点云作为额外的输入模态来升级现有的 VLM，为自动驾驶提供强大的 3D 度量空间理解。一个关键的挑战在于减轻不同 3D 数据对预训练 VLM 带来的灾难性干扰。为此，我们引入了 Gradual Fusion Q-Former，它可以增量注入 LiDAR 功能，确保 VLM 现有知识库的稳定性和保存。此外，我们开发了一个空间感知问答 (SA-QA) 数据集，以明确地教授模型高级 3D 感知和推理能力。关于驾驶基准的大量实验表明，与仅视觉的同类产品相比，LVLDrive 在场景理解、度量空间感知和可靠的驾驶决策方面实现了卓越的性能。我们的工作强调了显式 3D 度量数据对于构建值得信赖的基于 VLM 的自主系统的必要性。|[2512.24331](http://arxiv.org/abs/2512.24331)|null|\n",
        "2512.24329": "|**2025-12-30**|**World model inspired sarcasm reasoning with large language model agents**|讽刺理解是自然语言处理中的一个具有挑战性的问题，因为它需要捕获话语的表面含义与说话者的意图以及周围的社会背景之间的差异。尽管深度学习和大型语言模型（LLM）的最新进展显着提高了性能，但大多数现有方法仍然依赖于单个模型的黑盒预测，这使得很难从结构上解释讽刺背后的认知因素。此外，虽然讽刺常常表现为语义评估与规范期望或意图之间的不匹配，但明确分解和建模这些组件的框架仍然有限。在这项工作中，我们将讽刺理解重新表述为一种世界模型启发的推理过程，并提出了世界模型启发的 SArcasm 推理（WM-SAR），它将字面意义、上下文、规范期望和意图分解为专门的基于 LLM 的代理。字面评价和规范期望之间的差异被明确量化为确定性不一致分数，并与意图分数一起，通过轻量级逻辑回归模型整合这些信号以推断最终的讽刺概率。该设计利用了法学硕士的推理能力，同时保持了可解释的数值决策结构。对代表性讽刺检测基准的实验表明，WM-SAR 始终优于现有的深度学习和基于 LLM 的方法。消融研究和案例分析进一步表明，整合语义不一致和意图推理对于有效的讽刺检测、实现强大的性能和高可解释性至关重要。|[2512.24329](http://arxiv.org/abs/2512.24329)|null|\n",
        "2512.24922": "|**2025-12-31**|**Semi-Supervised Diversity-Aware Domain Adaptation for 3D Object detection**|3D 物体探测器是自动驾驶车辆感知系统的基本组成部分。虽然这些检测器在标准自动驾驶基准上取得了出色的性能，但它们通常很难在不同领域进行推广 - 例如，在美国训练的模型可能在亚洲或欧洲等地区表现不佳。本文提出了一种基于神经元激活模式的新型激光雷达域适应方法，证明如果正确选择了目标域中的一小部分、具有代表性和多样化的样本子集，则可以通过仅注释它们来实现最先进的性能。所提出的方法需要非常小的注释预算，并且当与受持续学习启发的后训练技术相结合时，可以防止原始模型的权重漂移。经验评估表明，所提出的域自适应方法优于线性探测和最先进的域自适应技术。|[2512.24922](http://arxiv.org/abs/2512.24922)|null|\n",
        "2512.24851": "|**2025-12-31**|**VLN-MME: Diagnosing MLLMs as Language-guided Visual Navigation agents**|多模态大语言模型 (MLLM) 在广泛的视觉语言任务中表现出了卓越的能力。然而，它们作为具体代理的性能需要多轮对话空间推理和顺序动作预测，需要进一步探索。我们的工作通过引入一个统一且可扩展​​的评估框架来探索 MLLM 作为零样本代理，通过将传统导航数据集桥接到一个名为 VLN-MME 的标准化基准，来研究视觉和语言导航 (VLN) 背景下的这种潜力。我们通过高度模块化且易于访问的设计简化了评估。这种灵活性简化了实验，实现了跨不同 MLLM 架构、代理设计和导航任务的结构化比较和组件级消融。至关重要的是，在我们的框架的支持下，我们观察到通过思想链（CoT）推理和自我反思来增强我们的基线代理会导致性能意外下降。这表明 MLLM 在具体导航任务中表现出较差的上下文感知能力；尽管它们可以遵循指令并构建输出，但它们的 3D 空间推理保真度较低。 VLN-MME 为在具体导航设置中系统评估通用 MLLM 奠定了基础，并揭示了其顺序决策能力的局限性。我们相信这些发现为 MLLM 作为具体代理的后期培训提供了重要的指导。|[2512.24851](http://arxiv.org/abs/2512.24851)|null|\n",
        "2601.00755": "|**2026-01-02**|**A formal theory on problem space as a semantic world model in systems engineering**|经典问题空间理论将问题解决建模为通过状态、算子、目标和约束的结构化空间的导航。系统工程（SE）采用类似的构造（功能分析、操作分析、情景、权衡研究），但仍然缺乏问题空间本身的严格系统理论表示。在当前的实践中，推理通常直接从利益相关者的目标进行到规定性的工件。这使得关于操作环境、允许的交互和上下文条件的基本假设隐含或过早地嵌入到架构或需求中。本文通过将问题空间形式化为包含在需求和解决方案承诺之前定义的理论构造的显式语义世界模型来解决这一差距。这些构造与开发的公理、定理和推论一起建立了严格的标准，用于明确的边界语义、成功的利益相关者目标满足的上下文相关交互可追溯性，以及问题空间规范的充分性，在该规范上可以独立于解决方案设计进行有纪律的推理。它清楚地区分了问题领域的真实情况和选择的解决方案。本文最后讨论了该理论对实践者的重要性，并提供了利益相关者和工程师之间基于对话的假设案例研究，展示了该理论如何在设计任何规定性工件之前指导问题框架。|[2601.00755](http://arxiv.org/abs/2601.00755)|null|\n",
        "2601.00742": "|**2026-01-02**|**Materials Informatics: Emergence To Autonomous Discovery In The Age Of AI**|这一视角探讨了材料信息学的演变，从物理学和信息论的基础到通过人工智能 (AI) 的成熟。我们追溯了该领域的发展轨迹，从早期里程碑到材料基因组计划的变革性影响以及最近出现的大型语言模型 (LLM)。我们将材料信息学视为一个不断发展的生态系统，而不仅仅是一个工具包，回顾了推动逆向设计和自主驾驶实验室的关键方法，例如贝叶斯优化、强化学习和 Transformers。我们专门解决法学硕士整合的实际挑战，比较专家模型与通才模型，并讨论不确定性量化的解决方案。展望未来，我们评估人工智能从预测工具到协作研究伙伴的转变。通过利用主动学习和检索增强生成（RAG），该领域正在迈向自主材料科学的新时代，其日益以“人类脱离循环”的发现过程为特征。|[2601.00742](http://arxiv.org/abs/2601.00742)|null|\n",
        "2601.00393": "|**2026-01-01**|**NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos**|在本文中，我们提出了 NeoVerse，一种多功能的 4D 世界模型，能够进行 4D 重建、新轨迹视频生成和丰富的下游应用。我们首先确定当前 4D 世界建模方法中可扩展性的常见限制，该限制是由昂贵且专门的多视图 4D 数据或繁琐的训练预处理引起的。相比之下，我们的 NeoVerse 建立在一个核心理念之上，该理念使整个管道可扩展至各种野外单目视频。具体来说，NeoVerse 具有无姿态前馈 4D 重建、在线单目退化模式模拟和其他良好对齐的技术。这些设计使 NeoVerse 具有多功能性并可推广到各个领域。同时，NeoVerse 在标准重建和生成基准方面实现了最先进的性能。我们的项目页面位于 https://neoverse-4d.github.io|[2601.00393](http://arxiv.org/abs/2601.00393)|null|\n",
        "2601.00367": "|**2026-01-01**|**PatchBlock: A Lightweight Defense Against Adversarial Patches for Embedded EdgeAI Devices**|对抗性攻击对 EdgeAI 应用中机器学习模型的可靠部署构成了重大挑战，例如自动驾驶和监控，这些应用依赖于资源受限的设备进行实时推理。其中，基于补丁的对抗攻击，即向对象应用小的恶意补丁（例如贴纸），可以欺骗神经网络做出错误的预测，从而可能产生严重的后果。在本文中，我们提出了 PatchBlock，这是一个轻量级框架，旨在检测和消除图像中的对抗性补丁。利用异常值检测和降维，PatchBlock 可以识别受对抗性噪声影响的区域并抑制其影响。它作为传感器级别的预处理模块运行，与 GPU 推理并行地在 CPU 上高效运行，从而保持系统吞吐量，同时避免额外的 GPU 开销。该框架遵循三阶段流程：将输入分割成块（分块），通过重新设计的隔离森林检测异常区域，并进行有针对性的切割以实现更快的收敛（分离），并对已识别的异常值应用降维（缓解）。 PatchBlock 与模型和补丁无关，可以对现有管道进行改造，并在传感器输入和下游模型之间无缝集成。对多个神经架构、基准数据集、攻击类型和不同边缘设备的评估表明，PatchBlock 不断提高鲁棒性，在 Google Adversarial Patch 等强补丁攻击下恢复高达 77% 的模型精度，同时保持高可移植性和最小的干净精度损失。此外，PatchBlock 在效率、计算时间和每个样本的能耗方面优于最先进的防御，使其适合 EdgeAI 应用。|[2601.00367](http://arxiv.org/abs/2601.00367)|null|\n",
        "2601.00270": "|**2026-01-01**|**Rectifying Adversarial Examples Using Their Vulnerabilities**|基于深度神经网络的分类器在处理对抗性示例 (AE) 时容易出错。 AE 是人类无法检测到的扰动最小的输入数据，对依赖于安全的应用程序构成重大风险。因此，人们进行了广泛的研究来开发减轻其威胁的防御机制。大多数现有方法主要侧重于根据输入样本特征区分AE，强调AE检测，而没有在攻击前解决样本的正确分类问题。虽然某些任务可能只需要拒绝检测到的 AE，但其他任务则需要识别正确的原始输入类别，例如自动驾驶中的交通标志识别。本研究的目的是提出一种纠正 AE 的方法，以估计其原始输入的正确标签。我们的方法基于重新攻击 AE，将其移出决策边界以进行准确的标签预测，有效解决纠正使用白盒攻击方法创建的最小可感知 AE 的问题。然而，有效纠正距边界一定距离的黑盒攻击所产生的不良事件，或被针对性攻击错误分类为低置信度类别的不良事件，仍然存在挑战。通过采用仅考虑 AE 作为输入的直接方法，所提出的方法可以解决各种攻击，同时避免参数调整或初步训练的要求。结果表明，所提出的方法在纠正通过各种攻击方法（包括定向攻击和黑盒攻击）生成的 AE 方面表现出一致的性能。此外，在对抗各种攻击的稳定性方面，它优于传统的校正和输入转换方法。|[2601.00270](http://arxiv.org/abs/2601.00270)|null|\n",
        "2601.00156": "|**2026-01-01**|**Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions**|在本文中，我们介绍了面部分析中一个尚未探索的问题：针对任意选择的面部区域（称为 FaceFocalDesc）生成和识别多属性自然语言描述，其中包含面部动作单元（AU）、情绪状态和年龄估计。我们认为，系统专注于单个面部区域的能力可以带来更好的理解和控制。为了实现这一能力，我们为任意选择的面部区域构建了一个新的多属性描述数据集，提供丰富的区域级注释和自然语言描述。此外，我们提出了一种基于 Qwen2.5-VL 的微调视觉语言模型，称为 Focal-RegionFace，用于面部状态分析，该模型通过多个逐步微调阶段逐步细化对局部面部特征的关注，从而实现可解释的年龄估计、FAU 和情绪检测。实验结果表明，Focal-RegionFace 在新基准上在传统和广泛使用的指标以及新提出的指标方面均取得了最佳性能。这充分验证了其在细粒度多属性人脸区域焦点分析场景中的有效性和通用性。|[2601.00156](http://arxiv.org/abs/2601.00156)|null|\n",
        "2601.00051": "|**2025-12-31**|**TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model**|世界模型旨在赋予人工智能系统以连贯且时间一致的方式表示、生成动态环境并与之交互的能力。虽然最近的视频生成模型表现出了令人印象深刻的视觉质量，但它们在实时交互、长视野一致性和动态场景的持久记忆方面仍然有限，阻碍了它们向实际世界模型的演进。在本报告中，我们介绍了 TeleWorld，这是一种实时多模态 4D 世界建模框架，它将视频生成、动态场景重建和长期世界记忆统一在闭环系统中。 TeleWorld 引入了一种新颖的生成-重构-指导范式，其中生成的视频流被不断重构为动态 4D 时空表示，从而指导后续生成保持空间、时间和物理一致性。为了支持低延迟的长视野生成，我们采用了基于自回归扩散的视频模型，该模型通过宏观微观规划（MMPL）进行了增强，这是一种分层规划方法，可减少从帧级到段级的误差累积，并结合高效的分布匹配蒸馏（DMD），从而在实际计算预算下实现实时合成。我们的方法在统一的 4D 框架内实现了动态对象建模和静态场景表示的无缝集成，将世界模型推进到实用、交互式和计算可访问的系统。大量实验表明，TeleWorld 在静态和动态世界理解、长期一致性和实时生成效率方面均取得了出色的性能，将其定位为迈向交互式、支持记忆的多模式生成和体现智能的世界模型的实用步骤。|[2601.00051](http://arxiv.org/abs/2601.00051)|null|\n"
    }
}