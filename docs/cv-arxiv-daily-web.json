{
    "Video Diffusion": {
        "2602.21188": "|**2026-02-24**|**Human Video Generation from a Single Image with 3D Pose and View Control**|最近的扩散方法由于其强大的视觉生成能力，在从单个图像生成视频方面取得了重大进展。然而，图像到视频的合成仍然存在挑战，特别是在人类视频生成方面，从单个图像推断视图一致、运动相关的衣服皱纹仍然是一个艰巨的问题。在本文中，我们提出了 4D 人类视频生成 (HVG)，这是一种潜在视频扩散模型，能够从具有 3D 姿势和视图控制的单个图像生成高质量、多视图、时空连贯的人类视频。 HVG 通过三个关键设计实现了这一目标：(i) 关节姿势调制，通过新颖的二维骨图捕获 3D 关节的解剖关系，并通过引入 3D 信息解决跨视图的自遮挡问题； (ii) 视图和时间对齐，确保参考图像和姿势序列之间的多视图一致性和对齐，以实现帧到帧的稳定性； (iii) 渐进式时空采样与时间对齐，以保持长多视图动画中的平滑过渡。对图像到视频任务的大量实验表明，HVG 在从不同的人类图像和姿势输入生成高质量 4D 人类视频方面优于现有方法。|[2602.21188](http://arxiv.org/abs/2602.21188)|null|\n",
        "2602.20999": "|**2026-02-24**|**VII: Visual Instruction Injection for Jailbreaking Image-to-Video Generation Models**|图像到视频 (I2V) 生成模型在参考图像上调节视频生成，已显示出新兴的视觉指令跟踪功能，允许参考图像中的某些视觉提示充当视频生成的隐式控制信号。然而，这种功能也带来了一个以前被忽视的风险：对手可能会利用视觉指令通过图像模态注入恶意意图。在这项工作中，我们通过提出视觉指令注入（VII）来揭示这一风险，这是一种免训练且可转移的越狱框架，有意将不安全文本提示的恶意意图伪装成安全参考图像中的良性视觉指令。具体来说，VII 协调恶意意图重新编程模块，从不安全文本提示中提取恶意意图，同时最大限度地减少其静态危害性，并协调视觉指令接地模块，通过渲染与原始不安全文本提示保持语义一致性的视觉指令，将提取的意图接地到安全输入图像上，从而在 I2V 生成过程中引入有害内容。根据经验，我们对四种最先进的商业 I2V 模型（Kling-v2.5-turbo、Gemini Veo-3.1、Seedance-1.5-pro 和 PixVerse-V5）进行的广泛实验表明，VII 的攻击成功率高达 83.5%，同时将拒绝率降低到接近零，显着优于现有基线。|[2602.20999](http://arxiv.org/abs/2602.20999)|null|\n",
        "2602.20685": "|**2026-02-25**|**RAYNOVA: Scale-Temporal Autoregressive World Modeling in Ray Space**|世界基础模型旨在通过物理上合理的行为来模拟现实世界的演化。与之前分别处理空间和时间相关性的方法不同，我们提出了 RAYNOVA，这是一种采用双因果自回归框架的驾驶场景的几何对抗多视图世界模型。它在自回归过程中遵循尺度和时间拓扑顺序，并利用全局注意力进行统一的 4D 时空推理。与强加强 3D 几何先验的现有作品不同，RAYNOVA 基于相对 Plücker 射线位置编码构建了跨视图、帧和尺度的各向同性时空表示，从而能够对不同的相机设置和自我运动进行稳健的泛化。我们进一步引入了一种循环训练范例，以减轻长视野视频生成中的分布漂移。 RAYNOVA 在 nuScenes 上实现了最先进的多视图视频生成结果，同时在不同的输入条件下提供更高的吞吐量和强大的可控性，推广到新颖的视图和相机配置，而无需明确的 3D 场景表示。我们的代码将在 https://raynova-ai.github.io/ 发布。|[2602.20685](http://arxiv.org/abs/2602.20685)|null|\n",
        "2602.20673": "|**2026-02-24**|**GA-Drive: Geometry-Appearance Decoupled Modeling for Free-viewpoint Driving Scene Generatio**|自由视角、可编辑且高保真的驾驶模拟器对于训练和评估端到端自动驾驶系统至关重要。在本文中，我们提出了 GA-Drive，这是一种新颖的模拟框架，能够通过几何外观解耦和基于扩散的生成沿着用户指定的新颖轨迹生成相机视图。给定沿着记录轨迹捕获的一组图像和相应的场景几何形状，GA-Drive 使用几何信息合成新颖的伪视图。然后使用经过训练的视频扩散模型将这些伪视图转换为逼真的视图。通过这种方式，我们将场景的几何形状和外观解耦。这种解耦的优点是它支持通过最先进的视频到视频编辑技术进行外观编辑，同时保留底层几何形状，从而能够在原始和新颖的轨迹上进行一致的编辑。大量实验表明，GA-Drive 在 NTA-IoU、NTL-IoU 和 FID 分数方面明显优于现有方法。|[2602.20673](http://arxiv.org/abs/2602.20673)|null|\n",
        "2602.20583": "|**2026-02-24**|**PropFly: Learning to Propagate via On-the-Fly Supervision from Pre-trained Video Diffusion Models**|基于传播的视频编辑通过将单个编辑帧传播到后续帧中来实现精确的用户控制，同时保持原始上下文（例如运动和结构）。然而，训练此类模型需要大规模、配对（源和编辑）视频数据集，获取这些数据集成本高昂且复杂。因此，我们提出了 PropFly，一种基于传播的视频编辑的训练管道，依赖于预先训练的视频扩散模型 (VDM) 的即时监督，而不需要现成的或预先计算的配对视频编辑数据集。具体来说，我们的 PropFly 利用具有不同无分类器指导 (CFG) 尺度的中间噪声潜伏的一步干净潜伏估计来动态合成不同的“源”（低 CFG）和“编辑”（高 CFG）潜伏对。源潜在变量充当视频的结构信息，而编辑后的潜在变量提供学习传播的目标转换。我们的管道支持附加到预先训练的 VDM 的附加适配器，以学习通过引导调制流匹配 (GMFM) 损失来传播编辑，从而引导模型复制目标转换。我们的动态监督确保模型能够学习时间一致的动态转换。大量实验表明，我们的 PropFly 在各种视频编辑任务上显着优于最先进的方法，产生高质量的编辑结果。|[2602.20583](http://arxiv.org/abs/2602.20583)|null|\n",
        "2602.20497": "|**2026-02-24**|**LESA: Learnable Stage-Aware Predictors for Diffusion Model Acceleration**|扩散模型在图像和视频生成任务中取得了显着的成功。然而，扩散变压器（DiT）的高计算要求对其实际部署提出了重大挑战。虽然特征缓存是一种很有前途的加速策略，但基于简单重用或免训练预测的现有方法很难适应扩散过程的复杂、阶段相关的动态，通常会导致质量下降，并且无法保持与标准去噪过程的一致性。为了解决这个问题，我们提出了一个基于两阶段训练的 LEarnable Stage-Aware (LESA) 预测器框架。我们的方法利用柯尔莫哥洛夫-阿诺德网络（KAN）来准确地从数据中学习时间特征映射。我们进一步引入了多阶段、多专家架构，将专门的预测器分配给不同的噪声级别阶段，从而实现更精确和稳健的特征预测。大量的实验表明，我们的方法在保持高保真生成的同时实现了显着的加速。实验表明，FLUX.1-dev 上的加速为 5.00 倍，质量下降最小（下降 1.0%）；Qwen-Image 上的加速为 6.25 倍，与之前的 SOTA（TaylorSeer）相比，质量提高了 20.2%；HunyuanVideo 上的加速为 5.00 倍，PSNR 比 TaylorSeer 提高了 24.7%。文本到图像和文本到视频合成的最先进性能验证了我们基于训练的框架在不同模型上的有效性和泛化能力。我们的代码包含在补充材料中，并将在 GitHub 上发布。|[2602.20497](http://arxiv.org/abs/2602.20497)|null|\n",
        "2602.22208": "|**2026-02-26**|**Solaris: Building a Multiplayer Video World Model in Minecraft**|现有的动作条件视频生成模型（视频世界模型）仅限于单智能体视角，无法捕捉现实世界环境的多智能体交互。我们介绍 Solaris，这是一种模拟一致的多视图观察的多人视频世界模型。为了实现这一目标，我们开发了一个多人数据系统，专为《我的世界》等视频游戏的稳健、连续和自动化数据收集而设计。与之前为单人游戏设置构建的平台不同，我们的系统支持协调的多代理交互和同步视频+动作捕捉。使用该系统，我们收集了 1264 万个多人游戏帧，并提出了多人运动、记忆、接地、构建和视图一致性的评估框架。我们使用分阶段的管道来训练 Solaris，该管道逐渐从单人模式过渡到多人模式，结合了双向、因果和自我强迫训练。在最后阶段，我们引入了检查点自我强迫，这是一种内存高效的自我强迫变体，可以实现更长视野的教师。结果显示我们的架构和培训设计优于现有基线。通过开源我们的系统和模型，我们希望为新一代多智能体世界模型奠定基础。|[2602.22208](http://arxiv.org/abs/2602.22208)|null|\n",
        "2602.21929": "|**2026-02-25**|**Geometry-as-context: Modulating Explicit 3D in Scene-consistent Video Generation to Geometry Context**|场景一致的视频生成旨在创建基于摄像机轨迹探索 3D 场景的视频。以前的方法依赖具有外部存储器的视频生成模型来实现一致性，或者迭代 3D 重建和修复，这会在推理过程中由于不正确的中间输出、不可微分的过程和单独的模型而累积错误。为了克服这些限制，我们引入了“几何即上下文”。它使用自回归相机控制的视频生成模型迭代地完成以下步骤：（1）估计 3D 重建所需的当前视图的几何形状，以及（2）模拟和恢复 3D 场景渲染的新视图图像。在这个多任务框架下，我们开发了相机门控注意力模块，以增强模型有效利用相机姿势的能力。在训练阶段，利用文本上下文为了确定应该生成几何图像还是 RGB 图像，为了确保模型在推理过程中可以生成仅 RGB 的输出，从交错的文本-图像-几何训练序列中随机删除该方法，并在单向和前后轨迹的场景视频生成上进行了测试，结果表明其在保持场景一致性和摄像机控制方面优于以前的方法。|[2602.21929](http://arxiv.org/abs/2602.21929)|null|\n",
        "2602.21835": "|**2026-02-25**|**UniVBench: Towards Unified Evaluation for Video Foundation Models**|视频基础模型旨在将视频理解、生成、编辑和指令跟踪集成在一个框架内，使其成为下一代多模态系统的中心方向。然而，现有的评估基准仍然分散且范围有限，因为它们每个都针对单个任务，依赖于特定于任务的指标，并且通常使用短或简单的视频剪辑。因此，它们无法捕获这些模型旨在提供的统一功能。为了解决这一差距，我们引入了 UniVBench，这是一个专门为评估视频基础模型的四个核心能力而构建的基准：视频理解、视频生成、视频编辑，以及新提出的任务视频重建，该任务评估模型如何忠实地再现其遇到的视频内容。我们的基准测试通过纳入 200 个高质量、多样化的多镜头视频，每个视频都配有详细的标题、多格式编辑说明和参考图像，极大地扩展了评估的复杂性。所有视频均由人工创作并经过仔细验证，提供比之前的基准更丰富的电影信息。此外，我们开发了一个统一的代理评估系统（UniV-Eval），该系统标准化了所有任务的提示、指令解析和评分，从而实现了统一视频模型的公平、可扩展和可重复的比较。通过在基于指令的多镜头视频任务中进行基础评估，UniVBench 提供了第一个用于测量视频基础模型旨在实现的集成功能的框架。广泛的人工注释确保我们的评估与人类判断一致，从而实现严格的评估并加速实现强大的视频智能。|[2602.21835](http://arxiv.org/abs/2602.21835)|null|\n",
        "2602.21818": "|**2026-02-25**|**SkyReels-V4: Multi-modal Video-Audio Generation, Inpainting and Editing model**|SkyReels V4 是一个统一的多模态视频基础模型，用于联合视频音频生成、修复和编辑。该模型采用双流多模态扩散变压器（MMDiT）架构，其中一个分支合成视频，另一个分支生成时间对齐的音频，同时共享基于多模态大语言模型（MMLM）的强大文本编码器。 SkyReels V4 接受丰富的多模式指令，包括文本、图像、视频剪辑、蒙版和音频参考。通过将 MMLM 多模态指令跟随功能与视频分支 MMDiT 中的上下文学习相结合，该模型可以在复杂条件下注入细粒度的视觉指导，而音频分支 MMDiT 同时利用音频参考来指导声音生成。在视频方面，我们采用通道串联公式，将图像到视频、视频扩展和视频编辑等多种修复风格任务统一在一个界面下，并通过多模式提示自然扩展到视觉参考修复和编辑。 SkyReels V4 支持高达 1080p 的分辨率、32 FPS 和 15 秒的持续时间，可生成具有同步音频的高保真、多镜头、影院级视频。为了使这种高分辨率、长时间的生成在计算上可行，我们引入了一种效率策略：联合生成低分辨率全序列和高分辨率关键帧，然后是专用的超分辨率和帧插值模型。据我们所知，SkyReels V4是第一个同时支持多模态输入、联合视频音频生成以及生成、修复和编辑统一处理的视频基础模型，同时在电影分辨率和时长上保持强大的效率和质量。|[2602.21818](http://arxiv.org/abs/2602.21818)|null|\n",
        "2602.21581": "|**2026-02-25**|**MultiAnimate: Pose-Guided Image Animation Made Extensible**|姿势引导的人体图像动画旨在合成由一系列姿势驱动的参考角色的逼真视频。虽然基于扩散的方法取得了显着的成功，但大多数现有方法仅限于单角色动画。我们观察到，天真地将这些方法扩展到多角色场景通常会导致角色之间的身份混乱和令人难以置信的遮挡。为了解决这些挑战，在本文中，我们提出了一种基于现代扩散变压器（DiT）的可扩展多字符图像动画框架，用于视频生成。我们的框架的核心引入了两个新颖的组件——标识符分配器和标识符适配器——它们协作捕获每个人的位置线索和人与人之间的空间关系。这种掩码驱动的方案以及可扩展的训练策略不仅增强了灵活性，而且还能够泛化到比训练期间看到的字符更多的场景。值得注意的是，我们的模型仅在两个字符数据集上进行训练，可推广到多字符动画，同时保持与单字符情况的兼容性。大量的实验表明，我们的方法在多字符图像动画中实现了最先进的性能，超越了现有的基于扩散的基线。|[2602.21581](http://arxiv.org/abs/2602.21581)|null|\n",
        "2602.21365": "|**2026-02-24**|**Towards Controllable Video Synthesis of Routine and Rare OR Events**|目的：整理包含罕见、安全关键或非典型事件的手术室 (OR) 工作流程的大规模数据集，在操作和道德上仍然具有挑战性。这一数据瓶颈使得用于检测、理解和缓解手术室中罕见或安全关键事件的环境智能的开发变得复杂。   方法：这项工作提出了一个 OR 视频扩散框架，可以控制罕见和安全关键事件的合成。该框架集成了几何抽象模块、调节模块和微调扩散模型，首先将 OR 场景转换为抽象几何表示，然后调节合成过程，最后生成逼真的 OR 事件视频。使用这个框架，我们还整理了一个合成数据集来训练和验证人工智能模型，以检测无菌区违规事件的险情。   结果：在合成常规 OR 事件时，我们的方法优于现成的视频扩散基线，在域内和域外数据集中实现了较低的 FVD/LPIPS 和较高的 SSIM/PSNR。通过定性结果，我们说明了其对反事实事件进行受控视频合成的能力。根据生成的合成数据进行训练和验证的 AI 模型在检测临近安全关键事件时实现了 70.13% 的召回率。最后，我们进行了一项消融研究，以量化关键设计选择带来的性能增益。   结论：我们的解决方案能够从抽象几何表示中控制合成常规和罕见的 OR 事件。除了展示其生成罕见和安全关键场景的能力之外，我们还展示了其支持环境智能模型开发的潜力。|[2602.21365](http://arxiv.org/abs/2602.21365)|null|\n",
        "2602.21333": "|**2026-02-24**|**HorizonForge: Driving Scene Editing with Any Trajectories and Any Vehicles**|可控驾驶场景生成对于真实且可扩展的自动驾驶模拟至关重要，但现有方法很难同时实现照片真实感和精确控制。我们推出了 Horizo​​nForge，这是一个统一的框架，可将场景重建为可编辑的高斯图和网格，从而实现细粒度的 3D 操作和语言驱动的车辆插入。编辑是通过噪声感知视频扩散过程进行渲染的，该过程强制执行空间和时间一致性，在单个前馈通道中产生不同的场景变化，而无需每个轨迹优化。为了标准化评估，我们进一步提出了 Horizo​​nSuite，这是一个涵盖自我和代理级别编辑任务（例如轨迹修改和对象操作）的综合基准。大量实验表明，高斯网格表示比其他 3D 表示具有更高的保真度，并且视频扩散的时间先验对于相干合成至关重要。结合这些发现，Horizo​​nForge 建立了一个简单而强大的范例，用于逼真、可控的驾驶模拟，与第二最佳的最先进方法相比，实现了 83.4% 的用户偏好增益和 25.19% 的 FID 改进。项目页面：https://horizo​​nforge.github.io/。|[2602.21333](http://arxiv.org/abs/2602.21333)|null|\n",
        "2602.23203": "|**2026-02-26**|**ColoDiff: Integrating Dynamic Consistency With Content Awareness for Colonoscopy Video Generation**|结肠镜检查视频生成提供动态、信息丰富的数据，这对于诊断肠道疾病至关重要，特别是在数据稀缺的情况下。高质量视频生成需要时间一致性和对临床属性的精确控制，但面临着不规则肠道结构、多样化疾病表现和各种成像方式的挑战。为此，我们提出了 ColoDiff，一种基于扩散的框架，可生成动态一致且内容感知的结肠镜检查视频，旨在缓解数据短缺并协助临床分析。在帧间级别，我们的 TimeStream 模块通过跨帧标记化机制将时间依赖性与视频序列解耦，从而在肠道结构不规则的情况下实现复杂的动态建模。在帧内级别，我们的内容感知模块结合了噪声注入嵌入和可学习原型，以实现对临床属性的精确控制，突破了扩散模型的粗略指导。此外，ColoDiff 采用非马尔可夫采样策略，可以将实时生成的步骤减少 90% 以上。 ColoDiff 在三个公共数据集和一个医院数据库中进行评估，基于生成指标和下游任务，包括疾病诊断、模态区分、肠道准备评分和病变分割。大量实验表明 ColoDiff 生成的视频具有平滑的过渡和丰富的动态。 ColoDiff 在可控结肠镜检查视频生成方面做出了努力，揭示了合成视频在补充真实表现和缓解临床环境中数据稀缺方面的潜力。|[2602.23203](http://arxiv.org/abs/2602.23203)|null|\n",
        "2602.23152": "|**2026-02-26**|**The Trinity of Consistency as a Defining Principle for General World Models**|构建能够学习、模拟和推理客观物理定律的世界模型是追求通用人工智能的基本挑战。以 Sora 等视频生成模型为代表的最新进展证明了数据驱动的缩放定律在近似物理动力学方面的潜力，而新兴的统一多模态模型 (UMM) 则为集成感知、语言和推理提供了一种有前途的架构范例。尽管取得了这些进展，该领域仍然缺乏一个原则性的理论框架来定义通用世界模型所需的基本属性。在本文中，我们提出世界模型必须建立在一致性三位一体的基础上：模态一致性作为语义接口，空间一致性作为几何基础，时间一致性作为因果引擎。通过这个三方视角，我们系统地回顾了多模态学习的演变，揭示了从松散耦合的专业模块到统一架构的轨迹，从而实现内部世界模拟器的协同出现。为了补充这个概念框架，我们引入了 CoW-Bench，这是一个以多帧推理和生成场景为中心的基准测试。 CoW-Bench 在统一的评估协议下评估视频生成模型和 UMM。我们的工作建立了通向通用世界模型的原则性途径，阐明了当前系统的局限性和未来进步的架构要求。|[2602.23152](http://arxiv.org/abs/2602.23152)|null|\n",
        "2602.22960": "|**2026-02-26**|**UCM: Unifying Camera Control and Memory with Time-aware Positional Encoding Warping for World Models**|基于视频生成的世界模型在模拟交互环境方面表现出了巨大的潜力，但在两个关键领域面临着持续的困难：重新访问场景时保持长期内容一致性以及通过用户提供的输入实现精确的摄像机控制。基于显式 3D 重建的现有方法通常会损害无界场景和细粒度结构的灵活性。替代方法直接依赖于先前生成的帧，而不建立明确的空间对应关系，从而限制了可控性和一致性。为了解决这些限制，我们提出了 UCM，这是一种新颖的框架，通过时间感知的位置编码扭曲机制将长期记忆和精确的相机控制结合起来。为了减少计算开销，我们设计了一种用于高保真生成的高效双流扩散变压器。此外，我们引入了一种可扩展的数据管理策略，利用基于点云的渲染来模拟场景重访，从而促进对超过 500K 单目视频的训练。对现实世界和综合基准的大量实验表明，UCM 在长期场景一致性方面显着优于最先进的方法，同时在高保真视频生成中实现了精确的摄像机可控性。|[2602.22960](http://arxiv.org/abs/2602.22960)|null|\n",
        "2602.22745": "|**2026-02-27**|**SPATIALALIGN: Aligning Dynamic Spatial Relationships in Video Generation**|大多数文本转视频 (T2V) 生成器优先考虑美观质量，但往往忽略生成视频中的空间限制。在这项工作中，我们提出了 SPATIALALIGN，这是一个自我改进框架，可增强 T2V 模型描述文本提示中指定的动态空间关系 (DSR) 的能力。我们提出了零阶正则化直接偏好优化 (DPO) 来微调 T2V 模型，以更好地与 DSR 保持一致。具体来说，我们设计了 DSR-SCORE，这是一种基于几何的指标，可以定量测量生成的视频与提示中指定的 DSR 之间的对齐情况，这比之前依赖 VLM 进行评估的工作向前迈出了一步。我们还建立了具有不同 DSR 的文本视频对数据集，以促进研究。大量的实验表明，我们的微调模型在空间关系方面的表现显着优于基线。代码将在Link中发布。项目页面：https://fengming001ntu.github.io/SpatialAlign/|[2602.22745](http://arxiv.org/abs/2602.22745)|null|\n",
        "2602.22654": "|**2026-02-26**|**Denoising as Path Planning: Training-Free Acceleration of Diffusion Models with DPCache**|扩散模型在图像和视频生成方面取得了显着的成功，但其实际部署仍然受到多步迭代采样的大量计算开销的阻碍。在加速策略中，基于缓存的方法通过跨时间步重用或预测特征来提供免训练且有效的解决方案。然而，现有方法依赖于固定或局部自适应调度，而不考虑去噪轨迹的全局结构，通常导致误差累积和视觉伪影。为了克服这一限制，我们提出了 DPCache，这是一种新颖的免训练加速框架，它将扩散采样加速表述为全局路径规划问题。 DPCache 从一个小的校准集中构造一个路径感知成本张量，以量化以前面的关键时间步长为条件的跳过时间步长的路径相关误差。利用该张量，DPCache 采用动态编程来选择关键时间步的最佳序列，从而最大限度地降低总路径成本，同时保持轨迹保真度。在推理过程中，模型仅在这些关键时间步执行完整计算，而使用缓存的特征有效地预测中间输出。在 DiT、FLUX 和 HunyuanVideo 上进行的大量实验表明，DPCache 以最小的质量损失实现了强大的加速，在 4.87$\\times$ 加速下比之前的加速方法高出 $+$0.031 ImageReward，甚至在 FLUX 上以 3.54$\\times$ 加速超过全步基线 $+$0.028 ImageReward，验证了我们的路径感知全局调度框架的有效性。代码将在 https://github.com/argsss/DPCache 发布。|[2602.22654](http://arxiv.org/abs/2602.22654)|null|\n",
        "2602.22596": "|**2026-02-26**|**BetterScene: 3D Scene Synthesis with Representation-Aligned Generative Model**|我们提出了 BetterScene，这是一种使用极其稀疏、无约束的照片来增强各种现实世界场景的新颖视图合成 (NVS) 质量的方法。 BetterScene 利用在数十亿帧上预训练的可投入生产的稳定视频扩散 (SVD) 模型作为强大的骨干，旨在减少伪影并在推理时恢复视图一致的细节。传统方法已经开发了类似的基于扩散的解决方案来解决新颖视图合成的这些挑战。尽管有了显着的改进，这些方法通常依赖于现成的预训练扩散先验，并且仅对 UNet 模块进行微调，同时保持其他组件冻结，即使在合并深度或语义条件等几何感知正则化时，这仍然会导致细节和伪影不一致。为了解决这个问题，我们研究了扩散模型的潜在空间，并引入了两个组件：(1) 时间等方差正则化和 (2) 视觉基础模型对齐表示，两者都应用于 SVD 管道内的变分自动编码器 (VAE) 模块。 BetterScene 集成了前馈 3D 高斯泼溅 (3DGS) 模型，将特征渲染为 SVD 增强器的输入，并生成连续、无伪影、一致的新颖视图。我们对具有挑战性的 DL3DV-10K 数据集进行评估，并展示了与最先进的方法相比的卓越性能。|[2602.22596](http://arxiv.org/abs/2602.22596)|null|\n",
        "2602.22486": "|**2026-02-25**|**Flow Matching is Adaptive to Manifold Structures**|流匹配已成为基于扩散的生成建模的免模拟替代方案，通过求解常微分方程来生成样本，该常微分方程的时间相关速度场是通过简单源分布（例如标准正态）和目标数据分布之间的插值来学习的。基于流的方法通常表现出更高的训练稳定性，并且在数据集中在低维流形附近的高维设置中实现了强大的经验性能，例如文本到图像合成、视频生成和分子结构生成。尽管取得了这一成功，现有的流匹配理论分析假设目标分布具有平滑、全维密度，使其在流形支持的设置中的有效性很大程度上无法解释。为此，我们从理论上分析了当目标分布支持在光滑流形上时使用线性插值的流匹配。我们为学习的速度场建立非渐近收敛保证，然后通过 ODE 传播该估计误差，以获得由流匹配目标引起的隐式密度估计器的统计一致性。由此产生的收敛速度接近极小极大最优，仅取决于内在维度，并且反映了流形和目标分布的平滑度。总之，这些结果为流匹配如何适应内在数据几何并规避维数灾难提供了原则性解释。|[2602.22486](http://arxiv.org/abs/2602.22486)|null|\n",
        "2602.24289": "|**2026-02-27**|**Mode Seeking meets Mean Seeking for Fast Long Video Generation**|将视频生成从几秒扩展到几分钟面临着一个关键瓶颈：虽然短视频数据丰富且高保真，但连贯的长格式数据却稀缺且仅限于狭窄的领域。为了解决这个问题，我们提出了一种训练范式，其中模式搜索满足均值搜索，通过解耦扩散变压器基于统一表示将局部保真度与长期一致性解耦。我们的方法利用通过长视频监督学习训练的全局流匹配头来捕获叙事结构，同时采用局部分布匹配头，通过模式搜索反向 KL 散度将滑动窗口与冻结的短视频教师对齐。该策略能够合成分钟尺度的视频，通过监督流匹配从有限的长视频中学习远程连贯性和运动，同时通过将学生的每个滑动窗口片段与冻结的短视频教师对齐来继承局部现实主义，从而产生几步快速的长视频生成器。评估表明，我们的方法通过共同提高局部清晰度、运动和远程一致性，有效地缩小了保真度与视野的差距。项目网站：https://primecai.github.io/mmm/。|[2602.24289](http://arxiv.org/abs/2602.24289)|null|\n",
        "2602.24208": "|**2026-02-27**|**SenCache: Accelerating Diffusion Model Inference via Sensitivity-Aware Caching**|扩散模型实现了最先进的视频生成质量，但由于大量的连续去噪步骤，其推理仍然昂贵。这推动了越来越多关于加速扩散推理的研究。在免训练加速方法中，缓存通过跨时间步重用先前计算的模型输出来减少计算量。现有的缓存方法依赖于启发式标准来选择缓存/重用时间步长，并且需要大量的调整。我们通过原则性的敏感度感知缓存框架来解决这一限制。具体来说，我们通过分析模型输出对去噪输入中的扰动（即噪声潜伏和时间步长）的敏感性来形式化缓存误差，并表明这种敏感性是缓存误差的关键预测因子。基于此分析，我们提出了灵敏度感知缓存（SenCache），这是一种动态缓存策略，可以根据每个样本自适应地选择缓存时间步长。我们的框架为自适应缓存提供了理论基础，解释了为什么先前的经验启发法可以部分有效，并将其扩展到动态的、特定于样本的方法。在 Wan 2.1、CogVideoX 和 LTX-Video 上的实验表明，在类似的计算预算下，SenCache 比现有的缓存方法实现了更好的视觉质量。|[2602.24208](http://arxiv.org/abs/2602.24208)|null|\n",
        "2602.24161": "|**2026-02-27**|**GeoDiff4D: Geometry-Aware Diffusion for 4D Head Avatar Reconstruction**|从单个肖像图像重建逼真且可动画的 4D 头部头像仍然是计算机视觉领域的一项基本挑战。虽然扩散模型在头像重建的图像和视频生成方面取得了显着进展，但现有方法主要依赖于 2D 先验，很难实现一致的 3D 几何形状。我们提出了一种新颖的框架，利用几何感知扩散来学习强大的几何先验，以进行高保真头部头像重建。我们的方法联合合成肖像图像和相应的表面法线，而无姿势表达编码器捕获隐式表达表示。合成图像和潜在表达都被纳入基于高斯的 3D 化身中，从而实现具有精确几何形状的逼真渲染。大量的实验表明，我们的方法在视觉质量、表达保真度和跨身份泛化方面远远优于最先进的方法，同时支持实时渲染。|[2602.24161](http://arxiv.org/abs/2602.24161)|null|\n",
        "2602.24148": "|**2026-02-27**|**HumanOrbit: 3D Human Reconstruction as 360° Orbit Generation**|我们提出了一种从单个输入图像生成围绕人的完整 360° 轨道视频的方法。现有方法通常采用基于图像的扩散模型来进行多视图合成，但会在视图之间和原始身份上产生不一致的结果。相比之下，最近的视频扩散模型已经证明了它们生成与给定提示非常一致的逼真结果的能力。受这些结果的启发，我们提出了 HumanOrbit，一种用于多视图人体图像生成的视频扩散模型。我们的方法使模型能够合成围绕主题的连续相机旋转，产生几何一致的新颖视图，同时保留人的外观和身份。使用生成的多视图帧，我们进一步提出了一种重建管道，可以恢复对象的纹理网格。实验结果验证了 HumanOrbit 在多视图图像生成方面的有效性，并且与最先进的基线相比，重建的 3D 模型表现出卓越的完整性和保真度。|[2602.24148](http://arxiv.org/abs/2602.24148)|null|\n",
        "2602.23969": "|**2026-02-27**|**MSVBench: Towards Human-Level Evaluation of Multi-Shot Video Generation**|视频生成向复杂、多镜头叙事的演变暴露了当前评估方法的严重缺陷。现有的基准仍然以单镜头范式为基础，缺乏评估长篇连贯性和吸引力所需的全面故事资产和交叉镜头指标。为了弥补这一差距，我们推出了 MSVBench，这是第一个综合基准测试，具有为多镜头视频生成量身定制的分层脚本和参考图像。我们提出了一种混合评估框架，它将大型多模态模型（LMM）的高级语义推理与特定领域专家模型的细粒度感知严谨性相结合。通过评估不同范式的 20 种视频生成方法，我们发现当前模型尽管具有很强的视觉保真度，但主要表现为视觉插值器而不是真实世界模型。我们通过展示最先进的 Spearman 排名与人类判断的 94.4% 相关性，进一步验证了基准的可靠性。最后，MSVBench 通过提供可扩展的监控信号来超越评估。在其管道细化的推理轨迹上微调轻量级模型，可产生与 Gemini-2.5-Flash 等商业模型相当的人性化性能。|[2602.23969](http://arxiv.org/abs/2602.23969)|null|\n",
        "2602.23956": "|**2026-02-27**|**SwitchCraft: Training-Free Multi-Event Video Generation with Attention Controls**|文本到视频扩散模型的最新进展使得高保真度和时间连贯的视频合成成为可能。然而，当前的模型主要针对单事件生成进行优化。在处理多事件提示时，如果没有明确的时间基础，此类模型通常会产生混合或折叠的场景，从而破坏预期的叙述。为了解决这个限制，我们提出了 SwitchCraft，这是一种用于多事件视频生成的免训练框架。我们的主要见解是跨时间的统一提示注入忽略了事件和帧之间的对应关系。为此，我们引入了事件对齐查询引导（EAQS），它引导帧级注意力与相关事件提示保持一致。此外，我们提出了自动平衡强度求解器（ABSS），它自适应地平衡转向强度以保持时间一致性和视觉保真度。大量实验表明，与现有基线相比，SwitchCraft 显着提高了提示对齐、事件清晰度和场景一致性，为多事件视频生成提供了简单而有效的解决方案。|[2602.23956](http://arxiv.org/abs/2602.23956)|null|\n"
    },
    "3D": {
        "2602.21195": "|**2026-02-24**|**Region of Interest Segmentation and Morphological Analysis for Membranes in Cryo-Electron Tomography**|冷冻电子断层扫描 (cryo-ET) 能够对生物结构（包括膜和膜蛋白）进行高分辨率、三维重建。感兴趣区域 (ROI) 的识别是科学成像的核心，因为它可以对复杂数据集中的特定结构特征进行隔离和定量分析。然而，在实践中，投资回报率通常是通过完整的结构分割和事后分析间接得出的。对于连续且几何复杂的结构（例如被分割为单个实体的膜），这种限制尤其明显。在这里，我们开发了 TomoROIS-SurfORA，这是一个两步框架，用于直接、形状无关的 ROI 分割和形态表面分析。 TomoROIS 执行基于深度学习的 ROI 分割，并且可以使用小型注释数据集从头开始训练，从而实现跨不同成像数据的实际应用。 SurfORA 将分段结构处理为点云和表面网格，以提取定量形态特征，包括膜间距离、曲率和表面粗糙度。它支持封闭和开放表面，并特别考虑开放表面，由于缺少楔形效应，开放表面在冷冻电子断层扫描中很常见。我们展示了两种工具，使用含有复杂几何形状的可变形囊泡的体外重构膜系统，能够自动定量分析膜接触位点和内陷等重塑事件。虽然此处在冷冻 ET 膜数据上进行了演示，但组合方法适用于更广泛的科学成像环境中的 ROI 检测和表面分析。|[2602.21195](http://arxiv.org/abs/2602.21195)|null|\n",
        "2602.21182": "|**2026-02-24**|**Circumventing the CAP Theorem with Open Atomic Ethernet**|CAP 定理通常被视为系统法则：在网络分区下，复制服务必须牺牲一致性或可用性。该定理在其标准异步网络模型中是正确的，但操作实践取决于在哪里可以观察到类似分区的现象，以及较低层如何丢弃或保留有关消息命运的语义信息。本文认为，开放原子以太网 (OAE) 改变了工程机制，使 CAP 权衡变得对应用程序可见，方法是：(i) 用端点状态的有限时间双边协调（我们称之为双同步的属性）取代即发即忘链路语义，以及 (ii) 通过八价网格避免 Clos 漏斗点，其中每个节点都可以充当本地修复的生成树的根。其结果不是消除硬图切割，而是通过在数百纳秒内检测和修复主要结构缺陷，大幅减少应用程序可见的“软分区”的频率和持续时间。我们将此观点与 Brewer 的原始 CAP 框架、Gilbert 和 Lynch 的形式化、Lee 等人的 CAL 定理（用表观延迟的定量度量取代二进制分区容差）以及 Abadi 的 PACELC 扩展联系起来。|[2602.21182](http://arxiv.org/abs/2602.21182)|null|\n",
        "2602.21175": "|**2026-02-24**|**Seeing Through Words: Controlling Visual Retrieval Quality with Language Models**|文本到图像检索是视觉语言学习中的一项基本任务，但在现实场景中，它经常受到简短且不明确的用户查询的挑战。此类查询通常只有一两个单词长，导致语义模糊，容易在不同的视觉解释之间发生冲突，并且缺乏对检索图像质量的明确控制。为了解决这些问题，我们提出了一种新的质量可控检索范例，它用上下文细节丰富了简短的查询，同时结合了图像质量的明确概念。我们的关键思想是利用生成语言模型作为查询完成功能，将未指定的查询扩展到描述性形式，以捕获细粒度的视觉属性，例如姿势、场景和美学。我们引入了一个通用框架，该框架在离散质量级别上条件查询完成，该质量级别源自相关性和美学评分模型，因此查询丰富不仅在语义上有意义，而且具有质量意识。由此产生的系统具有三个关键优势：1）灵活性，无需修改即可与任何预训练的视觉语言模型（VLM）兼容； 2) 透明、丰富的查询可由用户明确解释； 3）可控性，使检索结果能够转向用户偏好的质量水平。大量实验表明，我们提出的方法显着改善了检索结果并提供了有效的质量控制，弥补了现代 VLM 的表达能力与短用户查询的未指定性质之间的差距。我们的代码可在 https://github.com/Jianglin954/QCQC 获取。|[2602.21175](http://arxiv.org/abs/2602.21175)|null|\n",
        "2602.21169": "|**2026-02-24**|**Revisiting CPL with sign-switching density: to cross or not to cross the NECB**|最近的 DESI DR2 BAO 测量结果与 CMB 和 SNeIa 数据相结合，显示出对 CPL 参数化状态方程描述的动态暗能量 (DE) 的 $3.2σ$-$3.4σ$ 偏好。这些重建的一个特别显着的特征是从早期的幻影般的政权到晚期的精髓般的行为的明显转变。对于正定 DE 密度，这种转变通常被表述为在 $w(a)=-1$ 处穿过虚拟分界线 (PDL)。然而，允许 DE 密度变为负值，会使 PDL（在 $w(a)=-1$ 的意义上）作为全局分隔符变得非诊断性：物理上有意义的标准是零能量条件边界 (NECB)，$ρ_{\\rm DE}+p_{\\rm DE}=0$。因此，我们测试一旦承认幻象行为的替代实现，特别是通过符号切换 DE 密度，CPL 重建中对 NECB 交叉的数据驱动偏好是否持续存在。为此，我们引入并约束了 CPL 框架的两个受控现象学扩展，其特征是过去具有负 DE 阶段。在 CPL$\\to-Λ$ 模型中，切换历元与 CPL 推断的 NECB 交叉比例因子相关，产生早期负宇宙常数相位，而切换后的演化遵循 CPL 分支。在sCPL模型中，CPL状态方程始终保持不变，而能量密度的符号切换发生在独立的跃迁红移处。我们发现后期 BAO 和 SNeIa 数据驱动负密度相位超出其有效红移覆盖范围，并且这一要求是推断参数行为的主要驱动因素。虽然相对于基线 CPL，这两种模型在统计上都不受欢迎，但承认负 DE 相位通常会降低与宇宙学常数的偏差的显着性。|[2602.21169](http://arxiv.org/abs/2602.21169)|null|\n",
        "2602.21163": "|**2026-02-24**|**A Light Fixture Color Temperature and Color Rendering Index Measuring Device**|人造光源的相关色温 (CCT) 和显色指数 (CRI) 非常重要，因为它们对人类生物学和专业应用具有影响。尽管商用灯通常可以获得 CCT 信息，但通常不会报告 CRI。此外，测量这些参数的设备很难获得，因为它们需要分光光度计，而分光光度计通常是昂贵的设备。在此背景下，本工作详细设计和构建了一个仪表，从设备的结构部分、与传感器的接口、计算到补偿算法的实现，旨在构建分光光度计的专用功能，其设计不使用光学镜头。除了简化设备之外，这种方法还可以使测量不受光学镜头典型色差引起的色散的影响。所获得的原型被证明是有效的，它捕获了各种光源的光谱功率分布并计算它们的 CCT 和 CRI。|[2602.21163](http://arxiv.org/abs/2602.21163)|null|\n",
        "2602.21153": "|**2026-02-24**|**SPRITETOMESH: Automatic Mesh Generation for 2D Skeletal Animation Using Learned Segmentation and Contour-Aware Vertex Placement**|我们推出了 SPRITETOMESH，这是一个全自动管道，用于将 2D 游戏精灵图像转换为与 Spine2D 等骨骼动画框架兼容的三角形网格。创建动画就绪网格传统上是一个繁琐的手动过程，需要艺术家沿着视觉边界仔细放置顶点，这项任务通常每个精灵需要 15-60 分钟。我们的方法通过混合学习算法方法解决了这个问题。分割网络（带有 U-Net 解码器的 EfficientNet-B0 编码器）在来自 172 个游戏的超过 100,000 个精灵掩码对上进行训练，实现了 0.87 的 IoU，从任意输入图像中提供准确的二进制掩码。从这些掩模中，我们使用 Douglas-Peucker 简化和自适应弧细分提取外部轮廓顶点，并通过双边滤波多通道 Canny 边缘检测和轮廓跟踪放置沿视觉边界检测内部顶点。具有基于掩模的质心过滤的 Delaunay 三角测量产生最终的网格。通过受控实验，我们证明通过神经网络热图回归进行直接顶点位置预测对于此任务来说根本上是不可行的：热图解码器始终无法收敛（损失稳定在 0.061），而分割解码器在相同条件下正常训练。我们将此归因于顶点放置的固有艺术本质 - 相同的精灵可以通过多种不同的方式进行有效的网格划分。这个负面结果验证了我们的混合设计：在地面事实明确的情况下进行学习分割，在领域启发法适用的情况下进行算法放置。完整的管道在 3 秒内处理一个精灵，比手动创建速度提高了 300 倍至 1200 倍。我们向游戏开发社区发布经过训练的模型。|[2602.21153](http://arxiv.org/abs/2602.21153)|null|\n",
        "2602.21147": "|**2026-02-24**|**RAMSES-MCR: A consistent multi-group treatment of cosmic rays physics in momentum-space with the RAMSES code**|众所周知，宇宙射线（CR）在许多天体物理环境中发挥着关键作用：它们可以改变冲击动力学，影响星际介质的热化学和电离，通过驱动银河风来调节星系质量含量，并由活跃星系核的喷流释放。它们还通过γ射线发射、射电同步加速器和二次粒子产生作为重要的观测示踪剂。由于 CR 粒子在跨越数十年能量的动量空间中遵循幂律分布，并且由于扩散和辐射损失进一步塑造了这些光谱，因此在数值模拟中对光谱解析 CR 进行建模并评估该建模对气体动力学和观测特征的影响至关重要。我们在自适应网格细化代码 RAMSES 中提出了一种在动量空间中用于 CR 质子的一致多组谱方法，称为 RAMSES-MCR，该方法基于两矩形式主义，该形式主义在动量空间中演化 CR 能量和数密度及其相关通量。模拟的 CR 过程包括平流、各向异性/各向同性扩散、流动不稳定性、库仑和强子损失、绝热变化以及气体反馈。我们还表明，该方法可以自然地扩展到 CR 电子（例如包括同步加速器损耗）并推广到多种 CR 物种。该实施已根据一套标准多维测试进行了验证。最后，我们将 RAMSES-MCR 应用于超新星遗迹的三维膨胀，包括具有各向异性扩散和能量损失的 CR，并演示 CR 能量如何以动量相关的方式重新分布，并在扫雪阶段改变气体动量。|[2602.21147](http://arxiv.org/abs/2602.21147)|null|\n",
        "2602.21105": "|**2026-02-24**|**BrepGaussian: CAD reconstruction from Multi-View Images with Gaussian Splatting**|边界表示 (B-rep) 将 3D 实体建模为其显式边界：修剪的角、边和面。从非结构化数据中恢复 B-rep 表示是计算机视觉和图形领域一项具有挑战性且有价值的任务。深度学习的最新进展极大地改善了 3D 形状几何的恢复，但仍然依赖于密集和干净的点云，并且很难推广到新的形状。我们提出了 B-rep Gaussian Splatting (BrepGaussian)，这是一种从 2D 图像学习 3D 参数表示的新颖框架。我们采用具有可学习特征的高斯泼溅渲染器，然后采用特定的拟合策略。为了解开几何重建和特征学习，我们引入了一个两阶段学习框架，首先捕获几何和边缘，然后细化补丁特征以实现干净的几何和连贯的实例表示。大量的实验证明了我们的方法具有最先进的方法的卓越性能。我们将在接受后发布我们的代码和数据集。|[2602.21105](http://arxiv.org/abs/2602.21105)|null|\n",
        "2602.21103": "|**2026-02-24**|**Prompt-Level Distillation: A Non-Parametric Alternative to Model Fine-Tuning for Efficient Reasoning**|高级推理通常需要思想链提示，这是准确的，但会产生令人望而却步的延迟和大量的测试时间推理成本。标准的替代方案是对较小的模型进行微调，通常会牺牲可解释性，同时引入大量的资源和运营开销。为了解决这些限制，我们引入了即时级蒸馏 (PLD)。我们从教师模型中提取明确的推理模式，并将它们组织成学生模型系统提示的表达指令的结构化列表。使用 Gemma-3 4B 对 StereoSet 和 Contract-NLI 数据集进行评估，PLD 将 Macro F1 分数分别从 57% 提高到 90.0% 和 67% 提高到 83%，使这个紧凑的模型能够以可忽略的延迟开销匹配前沿性能。这些富有表现力的指令使决策过程变得透明，允许对逻辑进行全面的人工验证，使这种方法成为法律、金融和内容审核等受监管行业以及大容量用例和边缘设备的理想选择。|[2602.21103](http://arxiv.org/abs/2602.21103)|null|\n",
        "2602.21100": "|**2026-02-24**|**Skullptor: High Fidelity 3D Head Reconstruction in Seconds with Multi-View Normal Prediction**|从图像重建高保真 3D 头部几何形状对于广泛的应用至关重要，但现有方法面临根本性的限制。传统摄影测量可实现出色的细节，但需要大量相机阵列（25-200+ 视图）、大量计算以及在面部毛发等具有挑战性的区域进行手动清理。最近的替代方案提出了一个基本的权衡：基础模型可以实现高效的单图像重建，但缺乏精细的几何细节，而基于优化的方法可以实现更高的保真度，但需要密集的视图和昂贵的计算。我们通过结合两种范式优势的混合方法来弥补这一差距。我们的方法引入了多视图表面​​法线预测模型，该模型通过交叉视图注意力扩展单眼基础模型，以在前馈传递中产生几何一致的法线。然后，我们在逆向渲染优化框架中利用这些预测作为强大的几何先验来恢复高频表面细节。我们的方法优于最先进的单图像和多视图方法，实现了与密集视图摄影测量相当的高保真度重建，同时降低了相机要求和计算成本。代码和模型将被发布。|[2602.21100](http://arxiv.org/abs/2602.21100)|null|\n",
        "2602.22194": "|**2026-02-25**|**Electrical coupling of a horizontal dipole antenna to a dielectric half-space: applications to radio astronomy from the lunar surface**|月球的背面不受地面无线电频率干扰，也不受地球电离层的影响，应该为射电天文学和宇宙学实验提供独特的安静环境。 30 MHz 以下的射电天空很大程度上尚未被探索，并且被认为包含早期高红移宇宙中新物理的光谱特征。要在此频段实现精确测量，需要准确了解天线性能和系统学。对于即将到来的月球表面射电天文学任务，这种建模将具有挑战性，因为天线将部署在距离月球风化层上方波长一小部分的高度，天线和表面之间的强耦合会显着改变阻抗、辐射模式和效率。风化层的层状介电结构和介电常数随深度增加的趋势使这一挑战变得更加复杂，这两者都很难在数值模拟中忠实地表示。   在这项工作中，我们回顾了对介电半空间上方的简单水平偶极子（代表月球风化层）行为的理论预测，并将其与使用 Ansys HFSS 积分方程求解器获得的仿真结果进行比较。我们量化了代表性月球表面射电天文学实验的天线阻抗和波束方向图如何与天空耦合。结果表明，即使风化层上方的天线高度适度增加，表面感应效应也会迅速减弱。相反，放置在月球表面或非常靠近月球表面的偶极天线将表现出复杂的光谱响应，如果没有风化层特性的详细信息，系统控制将变得非常困难。|[2602.22194](http://arxiv.org/abs/2602.22194)|null|\n",
        "2602.22021": "|**2026-02-25**|**Budgeted Active Experimentation for Treatment Effect Estimation from Observational and Randomized Data**|估计异质治疗效果是数据驱动决策的核心，但工业应用常常面临有限的随机对照试验 (RCT) 预算与根据历史目标政策收集的丰富但有偏见的观察数据之间的根本紧张关系。尽管观测日志具有规模优势，但它们本质上受到政策引起的严重不平衡和重叠违规的影响，导致独立估计不可靠。我们提出了一个预算主动实验框架，该框架通过主动采样迭代增强因果效应估计的模型训练。通过利用观察先验，我们开发了一个针对提升估计不确定性、重叠赤字和域差异的采集函数，以选择信息最丰富的单元进行随机实验。我们建立有限样本偏差界限、通过鞅中心极限定理 (CLT) 的渐近正态性和极小极大下界来证明信息论最优性。对工业数据集的大量实验表明，我们的方法在成本受限的环境中显着优于标准随机基线。|[2602.22021](http://arxiv.org/abs/2602.22021)|null|\n",
        "2602.21929": "|**2026-02-25**|**Geometry-as-context: Modulating Explicit 3D in Scene-consistent Video Generation to Geometry Context**|场景一致的视频生成旨在创建基于摄像机轨迹探索 3D 场景的视频。以前的方法依赖具有外部存储器的视频生成模型来实现一致性，或者迭代 3D 重建和修复，这会在推理过程中由于不正确的中间输出、不可微分的过程和单独的模型而累积错误。为了克服这些限制，我们引入了“几何即上下文”。它使用自回归相机控制的视频生成模型迭代地完成以下步骤：（1）估计 3D 重建所需的当前视图的几何形状，以及（2）模拟和恢复 3D 场景渲染的新视图图像。在这个多任务框架下，我们开发了相机门控注意力模块，以增强模型有效利用相机姿势的能力。在训练阶段，利用文本上下文为了确定应该生成几何图像还是 RGB 图像，为了确保模型在推理过程中可以生成仅 RGB 的输出，从交错的文本-图像-几何训练序列中随机删除该方法，并在单向和前后轨迹的场景视频生成上进行了测试，结果表明其在保持场景一致性和摄像机控制方面优于以前的方法。|[2602.21929](http://arxiv.org/abs/2602.21929)|null|\n",
        "2602.21826": "|**2026-02-25**|**The Silent Spill: Measuring Sensitive Data Leaks Across Public URL Repositories**|各种平台公开了大量 URL，用于安全分析、存档和粘贴共享，例如 VirusTotal、URLScan.io、Hybrid Analysis、Wayback Machine 和 RedHunt。正如一些新闻文章和博客文章中所报道的那样，这些服务可能会无意中暴露包含敏感信息的链接。然而，还没有大规模的测量来量化此类暴露的程度。我们提出了一个自动化系统，可以检测和分析通过可公开访问的 URL 泄露的潜在敏感信息。该系统结合了词汇 URL 过滤、动态渲染、基于 OCR 的提取和内容分类来识别潜在的泄漏。我们将其应用于从公共扫描平台、粘贴网站和网络档案收集的 6,094,475 个 URL，识别出身份验证、财务、个人和文档相关领域的 12,331 个潜在风险。这些发现表明敏感信息仍然暴露，强调了自动检测以识别意外泄漏的重要性。|[2602.21826](http://arxiv.org/abs/2602.21826)|null|\n",
        "2602.21820": "|**2026-02-25**|**Joint Shadow Generation and Relighting via Light-Geometry Interaction Maps**|我们提出了光几何交互（LGI）图，这是一种从单眼深度编码光感知遮挡的新颖表示。与需要完整 3D 重建的光线追踪不同，LGI 能够可靠、准确地捕获基本的光影交互，并根据现成的 2.5D 深度图预测进行计算。 LGI 明确地将照明方向与几何形状联系起来，提供了一个受物理启发的先验来约束生成模型。如果没有这样的先验，这些模型通常会产生浮动阴影、不一致的照明和不可信的阴影几何形状。在此表示的基础上，我们提出了一个用于联合阴影生成和重新照明的统一管道（与将它们视为不相交任务的先前方法不同），捕获对于建模间接效果至关重要的照明和阴影的内在耦合。通过将 LGI 嵌入到桥匹配生成主干中，我们减少了歧义并强制执行物理上一致的光影推理。为了实现有效的训练，我们策划了第一个用于联合阴影和重新照明的大型基准数据集，涵盖反射、透明度和复杂的相互反射。实验表明，合成图像和真实图像的真实性和一致性有了显着提高。因此，LGI 将几何启发的渲染与生成建模联系起来，实现高效、物理一致的阴影生成和重新照明。|[2602.21820](http://arxiv.org/abs/2602.21820)|null|\n",
        "2602.21819": "|**2026-02-25**|**SemVideo: Reconstructs What You Watch from Brain Activity via Hierarchical Semantic Guidance**|从大脑活动重建动态视觉体验为探索人类视觉感知的神经机制提供了一条引人注目的途径。虽然基于功能磁共振成像的图像重建最近取得了显着的进展，但将这一成功扩展到视频重建仍然是一个重大挑战。当前的功能磁共振成像到视频重建方法始终遇到两个主要缺点：（i）跨帧的显着对象的视觉表示不一致，导致外观不匹配； (ii) 时间相干性差，导致运动错位或突然的帧过渡。为了解决这些限制，我们引入了 SemVideo，一种由分层语义信息引导的新型 fMRI 到视频重建框架。 SemVideo 的核心是 SemMiner，这是一个分层指导模块，它根据原始视频刺激构建三个级别的语义线索：静态锚点描述、面向运动的叙述和整体摘要。利用这种语义指导，SemVideo 包含三个关键组件：语义对齐解码器，将 fMRI 信号与源自 SemMiner 的 CLIP 式嵌入对齐；运动适应解码器，使用新颖的三方注意力融合架构重建动态运动模式；以及条件视频渲染，利用分层语义指导进行视频重建。在 CC2017 和 HCP 数据集上进行的实验表明，SemVideo 在语义对齐和时间一致性方面均实现了卓越的性能，在 fMRI 到视频重建方面树立了新的最先进水平。|[2602.21819](http://arxiv.org/abs/2602.21819)|null|\n",
        "2602.21778": "|**2026-02-25**|**From Statics to Dynamics: Physics-Aware Image Editing with Latent Transition Priors**|基于指令的图像编辑在语义对齐方面取得了显着的成功，但当编辑涉及复杂的因果动态（例如折射或材料变形）时，最先进的模型经常无法呈现物理上合理的结果。我们将此限制归因于主流范式，该范式将编辑视为图像对之间的离散映射，它仅提供边界条件并且未指定过渡动态。为了解决这个问题，我们将物理感知编辑重新表述为预测物理状态转换，并引入了 PhysicTran38K，这是一个基于视频的大型数据集，包含跨五个物理域的 38K 转换轨迹，通过两级过滤和约束感知注释管道构建。在此监督的基础上，我们提出了PhysicEdit，一个配备文本-视觉双重思维机制的端到端框架。它将用于物理基础推理的冻结 Qwen2.5-VL 与可学习的转换查询相结合，为扩散主干提供时间步自适应视觉指导。实验表明，PhysicEdit 在物理真实感方面比 Qwen-Image-Edit 提高了 5.9%，在基于知识的编辑方面提高了 10.1%，为开源方法树立了新的最先进水平，同时保持与领先的专有模型的竞争力。|[2602.21778](http://arxiv.org/abs/2602.21778)|null|\n",
        "2602.21685": "|**2026-02-25**|**Adaptive isogeometric analysis of high-order phase-field fracture based on THB-splines**|近几十年来，固体中断裂扩展的研究越来越依赖于相场模型。最近的一些贡献强调了这种方法在静态和动态框架中的潜力。然而，一个主要限制仍然是高计算成本。已经确定了两种主要策略来缓解这个问题：使用局部细化网格和采用高阶模型。在这项工作中，我们利用截断分层 B 样条（THB 样条）引入了高阶相场公式（AT1 和 AT2）的自适应模拟，主要关注二维断裂问题。|[2602.21685](http://arxiv.org/abs/2602.21685)|null|\n",
        "2602.21668": "|**2026-02-25**|**Space-Time Forecasting of Dynamic Scenes with Motion-aware Gaussian Grouping**|预测动态场景仍然是计算机视觉中的一个基本挑战，因为有限的观测使得捕捉连贯的物体级运动和长期时间演化变得困难。我们提出了运动组感知高斯预测 (MoGaF)，这是一个基于 4D 高斯泼溅表示的长期场景外推框架。 MoGaF 引入了运动感知高斯分组和分组优化，以在刚性和非刚性区域上强制执行物理一致的运动，从而产生空间相干的动态表示。利用这种结构化的时空表示，轻量级预测模块可以预测未来的运动，从而实现现实且时间稳定的场景演化。对合成数据集和真实数据集的实验表明，MoGaF 在渲染质量、运动合理性和长期预测稳定性方面始终优于现有基线。我们的项目页面位于 https://slime0519.github.io/mogaf|[2602.21668](http://arxiv.org/abs/2602.21668)|null|\n",
        "2602.21656": "|**2026-02-25**|**Pure-amplitude holograms for high-efficiency generation of phase radial grating based radial carpet beams: Theory and experiments under plane-wave and Gaussian illumination**|本研究介绍了一种用于生成径向地毯光束 (RCB) 的纯振幅全息图 (PAH)，传统上使用纯相位径向光栅 (PRG) 生成径向地毯光束 (RCB)。全息图是通过将二元 PRG 的传输函数嵌入到幅度线性光栅的余弦项的相位参数中来设计的。当用平面波照射时，该全息图会生成非零衍射级的 RCB，而当用高斯光束照射时，它会在特定的传播距离处生成类似 RCB 的图案。这种方法完全消除了对复杂且昂贵的空间光调制器（SLM）的需求。该研究提出了来自此类全息图的平面光束和高斯光束的衍射理论，包括来自 PRG 的高斯光束衍射的具体理论处理。通过理论分析和实验，我们证明了当照明光束是平面波时，由于衍射级数乘以嵌入式基础PRG的相位幅度所产生的相位幅度增强，如何在不同的衍射级产生不同的RCB。对于高斯光束情况，我们展示了如何出于相同的原因在不同的衍射级生成不同的类似 RCB 的图案，尽管仅在特定的传播距离处。实验和数值结果表明，该技术产生的 RCB 和类似 RCB 的图案的有用功率约为 SLM 生成的同类图案的五倍，显示出显着更高的功率效率。这一优点使得所提出的方法非常适合多重光捕获和自由空间光通信等应用。|[2602.21656](http://arxiv.org/abs/2602.21656)|null|\n",
        "2602.23359": "|**2026-02-26**|**SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation**|我们将遮挡推理视为 3D 布局条件生成的一个基本但被忽视的方面。它对于合成具有深度一致的几何形状和比例的部分遮挡的对象至关重要。虽然现有方法可以生成遵循输入布局的真实场景，但它们通常无法对精确的对象间遮挡进行建模。我们提出了 SeeThrough3D，这是一种用于 3D 布局条件生成的模型，可显式模拟遮挡。我们引入了遮挡感知 3D 场景表示 (OSCR)，其中对象被描绘为放置在虚拟环境中的半透明 3D 框，并从所需的摄像机视角进行渲染。透明度对隐藏对象区域进行编码，使模型能够推理遮挡，而渲染的视点在生成过程中提供显式的相机控制。我们通过引入一组从我们渲染的 3D 表示派生的视觉标记来调节基于预训练流的文本到图像图像生成模型。此外，我们应用屏蔽自注意力将每个对象边界框准确地绑定到其相应的文本描述，从而能够准确生成多个对象而无需对象属性混合。为了训练模型，我们构建了一个包含具有强对象间遮挡的多种多对象场景的合成数据集。 SeeThrough3D 可以有效地推广到看不见的对象类别，并通过逼真的遮挡和一致的相机控制实现精确的 3D 布局控制。|[2602.23359](http://arxiv.org/abs/2602.23359)|null|\n",
        "2602.23311": "|**2026-02-26**|**Data-Efficient Generative Modeling of Non-Gaussian Global Climate Fields via Scalable Composite Transformations**|运行物理气候模型的计算成本过高，阻碍了量化未来气候预测的不确定性，这严重限制了训练数据的可用性。我们提出了一个数据有效的框架，用于模拟全球气候场的内部变化，专门用于克服这些样本大小的限制。受联结建模的启发，我们的方法通过对多元标准正态空间的复合变换构建了高度表达的联合分布。我们将用于空间依赖性建模的非参数贝叶斯传输图与灵活的、空间变化的边际模型相结合，这对于捕获非高斯行为和重尾极值至关重要。这些边际由参数模型定义，然后进行半参数 B 样条校正以捕获复杂的分布特征。使用具有低秩近似的高斯过程先验对边际参数进行空间平滑，使计算成本在空间维度上呈线性。当应用于超过 50,000 个网格位置的全球对数降水率场时，我们的随机替代方法实现了高保真度，准确量化了气候分布的空间依赖性和边际特征（包括尾部）。它仅使用 10 个训练样本，其性能优于使用 80 个样本训练的最先进的竞争对手，有效地将气候研究的计算预算增加了八倍。我们在 https://github.com/jobbrachem/ppptm 提供了 Python 实现。|[2602.23311](http://arxiv.org/abs/2602.23311)|null|\n",
        "2602.23257": "|**2026-02-26**|**Randomization Tests in Switchback Experiments**|当单元级随机化不可行、结果汇总或用户干扰不可避免时，会广泛使用折返实验（随着时间的推移交替处理和控制）。在实践中，实验必须支持快速的产品周期，因此团队经常在有限的时间内进行研究，并使用适度的样本做出决策。与此同时，这些时间索引环境中的结果表现出序列依赖性、季节性和偶尔的重尾冲击，而时间干扰（结转或预期）可能会使标准渐近和朴素随机化检验变得不可靠。在本文中，我们开发了一个随机化测试框架，该框架仅使用已知的分配机制，为几个感兴趣的零假设提供有限样本有效、无分布的 p 值，而不对结果过程进行参数假设。对于利益的因果效应，我们施加两个原始条件——非预期和有限的结转范围 m——并基于事前将设计块汇集到“部分”的基础上构造条件随机化测试（CRT），这产生了易于处理的条件分配法并确保焦点结果的可归责性。我们提供用于学习结转窗口和评估非预期的诊断，并且我们引入了学生化的 CRT，以实现会话弱零值，以渐近有效性适应会话内的季节性。使用 AR(1) 噪声指导设计和分析选择的分布式滞后效应下的功率近似，以及仿真证明了相对于常见替代方案的有利尺寸和功率。我们的框架自然地扩展到其他时间索引设计。|[2602.23257](http://arxiv.org/abs/2602.23257)|null|\n",
        "2602.23172": "|**2026-02-26**|**Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking**|捕捉 4D 时空环境对于机器人在动态环境中安全可靠的运行至关重要。然而，大多数现有方法仅解决问题的一方面：它们要么通过边界框提供粗略的几何跟踪，要么提供详细的 3D 结构，例如缺乏明确时间关联的基于体素的占用。在这项工作中，我们提出了用于 4D 全景占用跟踪 (LaGS) 的潜在高斯泼溅，它在整体方向上推进了时空场景理解。我们的方法将基于相机的端到端跟踪与基于掩模的多视图全景占​​用预测相结合，并解决了通过新颖的潜在高斯泼溅方法将多视图信息有效聚合到 3D 体素网格中的关键挑战。具体来说，我们首先将观察结果融合到 3D 高斯中，作为 3D 场景的稀疏的以点为中心的潜在表示，然后将聚合的特征分布到由基于掩模的分割头解码的 3D 体素网格上。我们在 Occ3D nuScenes 和 Waymo 数据集上评估 LaGS，实现了 4D 全景占用跟踪的最先进性能。我们在 https://lags.cs.uni-freiburg.de/ 提供代​​码。|[2602.23172](http://arxiv.org/abs/2602.23172)|null|\n",
        "2602.23163": "|**2026-02-26**|**A Decision-Theoretic Formalisation of Steganography With Applications to LLM Monitoring**|大型语言模型开始展现隐写能力。这种能力可能会让错位的模型逃避监督机制。然而，缺乏检测和量化此类行为的原则性方法。隐写术的经典定义以及基于它们的检测方法需要已知的非隐写信号的参考分布。对于法学硕士中的隐写推理来说，知道这样的参考分布是不可行的；这使得这些方法不再适用。我们提出了另一种选择，\\textbf{隐写术的决策理论观点}。我们的核心观点是，隐写术在能够和不能解码隐藏内容（存在于隐写信号中）的代理之间造成了可用信息的不对称，而这种潜在的不对称性可以从代理的可观察行为中推断出来。为了形式化这个观点，我们引入了广义的$\\mathcal{V}$-信息：一个用于测量某些输入中可用信息量的实用框架。我们用它来定义\\textbf{隐写间隙}——一种通过将隐写信号的下游效用与能够和不能解码隐藏内容的代理进行比较来量化隐写的度量。我们凭经验验证了我们的形式主义，并表明它可以用于检测、量化和减轻法学硕士中的隐写推理。|[2602.23163](http://arxiv.org/abs/2602.23163)|null|\n",
        "2602.23156": "|**2026-02-26**|**Coupling of the continuum and semiclassical limit. Part I: convergence of eigenvalues**|我们分析连续体 $ \\frac{1}{2} Δ+ λ_N^2 V$ 中的半经典 $d$ 维薛定谔算子，在网格上离散化，间距与 $1/N$ 成比例。半经典参数 $λ_N$ 选择为 $λ_N = N^{1 - γ}$，其中 $γ\\in (-1,1)$，这确保 $N$ 同时控制半经典极限和连续极限。我们证明离散算子的所有特征值都收敛于连续统的特征值，如 $λ_N\\to\\infty$。除了这个半经典域之外，在谐振子的情况下，我们进一步讨论 $γ\\in \\mathbb{R} \\setminus (-1,1)$ 的谱渐近性，从而充分表征 $γ\\in\\mathbb{R}$ 所有可能值的特征值行为。|[2602.23156](http://arxiv.org/abs/2602.23156)|null|\n",
        "2602.23097": "|**2026-02-26**|**HELIOS: A surface integral equation software for light scattering in homogeneous, periodic, and stratified environments**|我们推出了 HELIOS（均质和分层介质光学散射），这是一种开源表面积分方程 (SIE) 软件，旨在对嵌入均匀或分层介质和周期性背景中的粒子进行的光散射进行建模。该代码实现了 Poggio-Miller-Chang-Harrington-Wu-Tsai (PMCHWT) 公式，该公式在解决可穿透物体的散射问题方面表现出了卓越的可靠性。域边界使用三角形网格进行离散化，在此基础上使用 Rao-Wilton-Glisson (RWG) 基函数扩展电磁表面电流密度。对于光子晶体和超表面等周期性结构，HELIOS 采用埃瓦尔德变换来有效评估与 2D 晶格相关的无穷级数。关于分层媒体，该代码对分层媒体格林张量采用矩阵友好的方法，计算索末菲积分并通过制表插值方案加速计算。源代码是用 C++ 实现的，而 Python 界面则管理工作流程，包括模拟设置、求解器运行和后处理。 HELIOS 的准确性和多功能性通过涵盖其所有功能的各种示例得到了证明。|[2602.23097](http://arxiv.org/abs/2602.23097)|null|\n",
        "2602.23040": "|**2026-02-26**|**PackUV: Packed Gaussian UV Maps for 4D Volumetric Video**|体积视频提供身临其境的 4D 体验，但仍然难以大规模重建、存储和流式传输。现有的基于高斯分布的方法实现了高质量的重建，但在长序列、时间不一致的情况下会崩溃，并且在大运动和去遮挡下会失败。此外，它们的输出通常与传统的视频编码管道不兼容，从而阻碍了实际应用。   我们引入了 PackUV，这是一种新颖的 4D 高斯表示，可将所有高斯属性映射到一系列结构化、多尺度 UV 图集，从而实现紧凑的图像原生存储。为了拟合多视图视频的这种表示，我们提出了 PackUV-GS，这是一种时间一致的拟合方法，可以直接优化 UV 域中的高斯参数。流引导的高斯标记和视频关键帧模块可以识别动态高斯，稳定静态区域，并即使在大运动和去遮挡的情况下也能保持时间连贯性。由此产生的 UV 图集格式是第一个与标准视频编解码器（例如 FFV1）兼容的统一体积视频表示形式，且不会损失质量，从而能够在现有多媒体基础设施中实现高效流式传输。   为了评估长时间的体积捕获，我们提出了 PackUV-2B，这是迄今为止最大的多视图视频数据集，具有 50 多个同步摄像机、大量运动以及跨 100 个序列和 2B（十亿）帧的频繁遮挡。大量实验表明，我们的方法在渲染保真度方面超越了现有基线，同时可扩展到长达 30 分钟的序列且质量一致。|[2602.23040](http://arxiv.org/abs/2602.23040)|null|\n",
        "2602.23038": "|**2026-02-26**|**Parallelizable Search-Space Decomposition for Large-Scale Combinatorial Optimization Problems Using Ising Machines**|组合优化问题在工业中至关重要。然而，许多 COP 都是 NP 困难的，导致搜索空间随着问题大小呈指数增长，并使大规模实例在计算上变得困难。传统的求解器通常将问题视为整体实体，随着结构复杂性的增加，导致效率显着下降。为了解决这个问题，我们提出了一种新颖的搜索空间分解方法，该方法利用变量的固有结构来系统地减小主问题的规模。我们将变量和单个变量成本之间的交互成本表述为约束最大割问题，并使用惩罚项将其转换为二次无约束二元优化公式。伊辛模型求解器用于将问题快速分解为独立的小规模子问题，随后使用数学优化求解器并行求解。我们在有能力的车辆路径问题上验证了该方法。结果证明了三个显着的好处：可行解率的大幅提高、收敛速度加快、在 1 分钟内达到朴素方法需要 30 分钟才能达到的精度，以及高达 95.32% 的变量减少。这些发现表明搜索空间分解是有效解决大规模组合优化问题的一种有前途的策略。|[2602.23038](http://arxiv.org/abs/2602.23038)|null|\n",
        "2602.23022": "|**2026-02-26**|**DMAligner: Enhancing Image Alignment via Diffusion Model Based View Synthesis**|图像对齐是计算机视觉中的一项基本任务，具有广泛的应用。现有方法主要采用基于光流的图像扭曲。然而，该技术容易受到遮挡和照明变化等常见挑战的影响，导致对齐视觉质量下降并影响下游任务的准确性。在本文中，我们提出了 DMAaligner，这是一种基于扩散的框架，通过面向对齐的视图合成进行图像对齐。 DMAligner 旨在从新的角度应对图像对齐的挑战，采用基于生成的解决方案，展示强大的功能并避免与基于流的图像扭曲相关的问题。具体来说，我们提出了一种动态感知扩散训练方法，用于学习条件图像生成，合成图像对齐的新颖视图。它结合了动态感知掩模生成（DMP）模块，可以自适应地区分动态前景区域和静态背景，使扩散模型能够更有效地应对经典方法难以解决的挑战。此外，我们使用 Blender 开发了动态场景图像对齐 (DSIA) 数据集，其中包括 1,033 个室内和室外场景，以及为图像对齐量身定制的超过 30K 图像对。大量的实验结果证明了所提出的方法在 DSIA 基准以及一系列广泛使用的视频数据集上进行定性比较的优越性。我们的代码可在 https://github.com/boomluo02/DMAligner 获取。|[2602.23022](http://arxiv.org/abs/2602.23022)|null|\n",
        "2602.24290": "|**2026-02-27**|**UFO-4D: Unposed Feedforward 4D Reconstruction from Two Images**|从未摆出的图像进行密集 4D 重建仍然是一个严峻的挑战，当前的方法依赖于缓慢的测试时间优化或碎片化的、特定于任务的前馈模型。我们引入了 UFO-4D，这是一个统一的前馈框架，可以仅从一对未摆出的图像中重建密集、明确的 4D 表示。 UFO-4D 直接估计动态 3D 高斯图，从而能够以前馈方式联合一致地估计 3D 几何、3D 运动和相机姿态。我们的核心见解是，从单个动态 3D 高斯表示中差异化地渲染多个信号可提供重大的训练优势。这种方法可以实现自我监督的图像合成损失，同时紧密耦合外观、深度和运动。由于所有模态共享相同的几何基元，因此监督一种模态本质上会规范和改进其他模态。这种协同作用克服了数据稀缺性，使 UFO-4D 在关节几何、运动和相机姿态估计方面的性能比之前的工作高出 3 倍。我们的表示还可以在新颖的视图和时间上进行高保真 4D 插值。请访问我们的项目页面查看视觉结果：https://ufo-4d.github.io/|[2602.24290](http://arxiv.org/abs/2602.24290)|null|\n",
        "2602.24161": "|**2026-02-27**|**GeoDiff4D: Geometry-Aware Diffusion for 4D Head Avatar Reconstruction**|从单个肖像图像重建逼真且可动画的 4D 头部头像仍然是计算机视觉领域的一项基本挑战。虽然扩散模型在头像重建的图像和视频生成方面取得了显着进展，但现有方法主要依赖于 2D 先验，很难实现一致的 3D 几何形状。我们提出了一种新颖的框架，利用几何感知扩散来学习强大的几何先验，以进行高保真头部头像重建。我们的方法联合合成肖像图像和相应的表面法线，而无姿势表达编码器捕获隐式表达表示。合成图像和潜在表达都被纳入基于高斯的 3D 化身中，从而实现具有精确几何形状的逼真渲染。大量的实验表明，我们的方法在视觉质量、表达保真度和跨身份泛化方面远远优于最先进的方法，同时支持实时渲染。|[2602.24161](http://arxiv.org/abs/2602.24161)|null|\n",
        "2602.24148": "|**2026-02-27**|**HumanOrbit: 3D Human Reconstruction as 360° Orbit Generation**|我们提出了一种从单个输入图像生成围绕人的完整 360° 轨道视频的方法。现有方法通常采用基于图像的扩散模型来进行多视图合成，但会在视图之间和原始身份上产生不一致的结果。相比之下，最近的视频扩散模型已经证明了它们生成与给定提示非常一致的逼真结果的能力。受这些结果的启发，我们提出了 HumanOrbit，一种用于多视图人体图像生成的视频扩散模型。我们的方法使模型能够合成围绕主题的连续相机旋转，产生几何一致的新颖视图，同时保留人的外观和身份。使用生成的多视图帧，我们进一步提出了一种重建管道，可以恢复对象的纹理网格。实验结果验证了 HumanOrbit 在多视图图像生成方面的有效性，并且与最先进的基线相比，重建的 3D 模型表现出卓越的完整性和保真度。|[2602.24148](http://arxiv.org/abs/2602.24148)|null|\n",
        "2602.24136": "|**2026-02-27**|**Prune Wisely, Reconstruct Sharply: Compact 3D Gaussian Splatting via Adaptive Pruning and Difference-of-Gaussian Primitives**|3D 高斯溅射 (3DGS) 推动了 3D 场景表示方面的最新重大进展，它实现了具有照片级真实感质量的实时渲染。 3DGS通常需要大量基元来实现高保真度，导致冗余表示和高资源消耗，从而限制了其对于复杂或大规模场景的可扩展性。因此，有效的修剪策略和更具表现力的基元可以减少冗余，同时保持视觉质量对于实际部署至关重要。我们提出了一种高效、集成的重建感知修剪策略，该策略根据重建质量自适应地确定修剪时机和细化间隔，从而减小模型大小，同时提高渲染质量。此外，我们引入了 3D 高斯差分基元，它在单个基元中联合建模正密度和负密度，从而提高了紧凑配置下高斯的表现力。我们的方法显着提高了模型的紧凑性，实现了高斯计数减少高达 90%，同时提供与最先进的方法相似或在某些情况下更好的视觉质量。代码将公开。|[2602.24136](http://arxiv.org/abs/2602.24136)|null|\n",
        "2602.24096": "|**2026-02-27**|**DiffusionHarmonizer: Bridging Neural Reconstruction and Photorealistic Simulation with Online Diffusion Enhancer**|仿真对于自动驾驶汽车等自主机器人的开发和评估至关重要。神经重建正在成为一种有前途的解决方案，因为它能够以自动化和可扩展的方式仅根据真实世界的数据模拟各种场景。然而，虽然 NeRF 和 3D Gaussian Splatting 等方法可以产生视觉上引人注目的结果，但它们经常会出现伪影，特别是在渲染新视图时，并且无法真实地集成插入的动态对象，特别是当它们是从不同场景捕获时。为了克服这些限制，我们引入了 DiffusionHarmonizer，这是一种在线生成增强框架，可将此类不完美场景的渲染转换为时间一致的输出，同时提高其真实感。其核心是一个单步时间条件增强器，它是从预训练的多步图像扩散模型转换而来的，能够在单个 GPU 上的在线模拟器中运行。有效训练它的关键是定制数据管理管道，该管道构建强调外观协调、伪像校正和光照真实感的合成真实对。其结果是一个可扩展的系统，显着提高了研究和生产环境中的模拟保真度。|[2602.24096](http://arxiv.org/abs/2602.24096)|null|\n",
        "2602.24092": "|**2026-02-27**|**An $ε$-Optimal Sequential Approach for Solving zs-POSGs**|虽然最近将零和部分可观察随机博弈 (zs-POSG) 简化为转换无关随机博弈 (TI-SG) 理论上承认动态规划，但实际解决方案仍然受到同时极小极大备份的固有非线性和指数复杂性的阻碍。在这项工作中，我们通过分离原理严格地将同时交互重新构建为顺序决策过程，从而克服了这一计算障碍。我们引入了用于评估和执行的独特的充分统计数据、顺序占用状态和私人占用家庭，它们揭示了最优价值函数中的潜在几何结构。这种结构洞察力使我们能够线性化备份算子，将更新复杂性从指数降低到多项式，同时无需启发式簿记即可直接提取安全策略。实验结果表明，利用这种顺序框架的算法显着优于最先进的方法，有效地使以前难以解决的领域变得可解决。|[2602.24092](http://arxiv.org/abs/2602.24092)|null|\n",
        "2602.24065": "|**2026-02-27**|**EvalMVX: A Unified Benchmarking for Neural 3D Reconstruction under Diverse Multiview Setups**|神经表面重建的最新进展显着增强了 3D 重建。然而，当前的现实世界数据集主要集中于基于 RGB 输入的多视图立体 (MVS) 基准测试。多视图光度立体 (MVPS) 和多视图偏振形状 (MVSfP) 虽然在高保真表面重建和稀疏输入中不可或缺，但尚未与 MVS 一起进行定量评估。为了确定不同 MVX（MVS、MVSfP 和 MVPS）技术的工作范围，我们提出了 EvalMVX，这是一个包含 25 美元对象的真实世界数据集，每个对象均使用偏光相机在 20 美元的不同视图和 17 美元的光照条件（包括 OLAT 和自然照明）下捕获，从而生成 8,500 美元的图像。每个对象都包含对齐的地面实况 3D 网格，有助于同时对 MVX 方法进行定量基准测试。基于我们的 EvalMVX，我们评估了近年来发布的 13 美元的 MVX 方法，记录了性能最佳的方法，并识别了不同几何细节和反射类型下的开放问题。我们希望 EvalMVX 和基准测试结果能够启发未来多视图 3D 重建的研究。|[2602.24065](http://arxiv.org/abs/2602.24065)|null|\n",
        "2602.23959": "|**2026-02-27**|**Thinking with Images as Continuous Actions: Numerical Visual Chain-of-Thought**|最近的多模态大语言模型（MLLM）越来越依赖视觉思维链来对图像进行基于区域的推理。然而，现有的方法通过文本化坐标（导致模态不匹配和语义碎片）或固定粒度补丁来处理地面区域，这两种方式都限制了精确的区域选择，并且通常需要进行重大的架构更改。在本文中，我们提出了数值视觉思想链（NV-CoT），这是一个使 MLLM 能够使用连续数值坐标对图像进行推理的框架。 NV-CoT 将 MLLM 动作空间从离散词汇标记扩展到连续的欧几里德空间，允许模型直接生成边界框坐标作为动作，只需进行最小的架构修改。该框架支持监督微调和强化学习。特别是，我们用坐标上的高斯（或拉普拉斯）策略替换分类令牌策略，并通过重新参数化采样引入随机性，使 NV-CoT 与 GRPO 式策略优化完全兼容。针对八个代表性视觉推理基线的三个基准的广泛实验表明，NV-CoT 显着提高了定位精度和最终答案准确性，同时还加速了训练收敛，验证了 MLLM 中连续动作视觉推理的有效性。代码可在 https://github.com/kesenzhao/NV-CoT 中获取。|[2602.23959](http://arxiv.org/abs/2602.23959)|null|\n",
        "2602.23947": "|**2026-02-27**|**Hierarchical Concept-based Interpretable Models**|现代深度神经网络由于其潜在表示的不透明性而仍然难以解释，阻碍了模型的理解、调试和去偏差。概念嵌入模型（CEM）通过将输入映射到人类可解释的概念表示（可以从中预测任务）来解决这个问题。然而，CEM 无法表示概念间的关系，并且在训练期间需要不同粒度的概念注释，从而限制了其适用性。在本文中，我们介绍了分层概念嵌入模型（HiCEM），这是一个新的 CEM 系列，它通过分层结构显式地建模概念关系。为了在现实环境中启用 HiCEM，我们提出了概念拆分，这是一种从预训练的 CEM 嵌入空间自动发现更细粒度的子概念的方法，无需额外注释。这使得 HiCEM 能够从有限的概念标签生成细粒度的解释，从而减少注释负担。我们对多个数据集进行的评估，包括对 PseudoKitchens（新提出的基于概念的 3D 厨房渲染数据集）的用户研究和实验，表明（1）概念分割发现了训练期间缺少的人类可解释的子概念，可用于训练高度准确的 HiCEM；（2）HiCEM 能够在不同粒度上进行强大的测试时概念干预，从而提高任务准确性。|[2602.23947](http://arxiv.org/abs/2602.23947)|null|\n",
        "2602.23926": "|**2026-02-27**|**Leveraging Geometric Prior Uncertainty and Complementary Constraints for High-Fidelity Neural Indoor Surface Reconstruction**|使用有符号距离函数的神经隐式表面重建已经取得了重大进展，但由于不可靠或有噪声的几何先验，恢复薄结构和复杂几何形状等精细细节仍然具有挑战性。现有的方法依赖于优化过程中产生的隐含不确定性来过滤这些先验，这是间接且低效的，并且掩盖高不确定性区域中的监督进一步导致欠约束的优化。为了解决这些问题，我们提出了 GPU-SDF，这是一种利用几何先验不确定性和互补约束的室内表面重建神经隐式框架。我们引入了一个自监督模块，可以在没有辅助网络的情况下明确估计先验不确定性。基于这种估计，我们设计了一种不确定性引导的损失，它可以调节先前的影响而不是丢弃它，从而保留微弱但信息丰富的线索。为了解决先验不确定性较高的区域，GPU-SDF 进一步结合了两个互补的约束：加强边界监督的边缘距离场和加强几何一致性的多视图一致性正则化。大量实验证实，GPU-SDF 改善了精细细节的重建，并可作为现有框架的即插即用增强功能。源代码可在 https://github.com/IRMVLab/GPU-SDF 获取|[2602.23926](http://arxiv.org/abs/2602.23926)|null|\n"
    },
    "具生智能&自动驾驶": {
        "2602.21172": "|**2026-02-24**|**NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning**|视觉-语言-动作（VLA）模型通过用统一的端到端架构取代模块化管道来推进自动驾驶。然而，当前的 VLA 面临两个昂贵的要求：（1）海量数据集收集，（2）密集推理注释。在这项工作中，我们用 \\modelname 解决了这两个挑战（\\textbf{No} \\textbf{R}easoning for \\textbf{D}riving）。与现有的 VLA 相比，\\modelname 实现了具有竞争力的性能，同时对 $<$60\\% 的数据进行了微调，并且没有推理注释，从而减少了 3$\\times$ 的标记。我们发现，当标准组相对策略优化（GRPO）应用于在如此小的、无推理数据集上训练的策略时，无法产生显着的改进。我们表明，这种限制源于难度偏差，它不成比例地惩罚来自 GRPO 内产生高方差推出的场景的奖励信号。 \\modelname 通过结合 Dr.~GRPO 克服了这个问题，Dr.~GRPO 是一种旨在减轻法学硕士难度偏差的最新算法。因此，\\modelname 只需一小部分训练数据且无需推理开销，即可在 Waymo 和 NAVSIM 上实现具有竞争力的性能，从而实现更高效的自主系统。|[2602.21172](http://arxiv.org/abs/2602.21172)|null|\n",
        "2602.21161": "|**2026-02-24**|**ActionReasoning: Robot Action Reasoning in 3D Space with LLM for Robotic Brick Stacking**|经典的机器人系统通常依赖于为受限环境设计的定制规划器。虽然在有限的环境中有效，但这些系统缺乏泛化能力，限制了具体人工智能和通用机器人的可扩展性。最近的数据驱动的视觉-语言-行动（VLA）方法旨在从大规模模拟和现实世界数据中学习策略。然而，物理世界的连续动作空间显着超过了语言标记的表示能力，这使得人们不清楚仅扩展数据是否可以产生通用的机器人智能。为了解决这一差距，我们提出了 ActionReasoning，这是一个法学硕士驱动的框架，它执行显式的动作推理，为机器人操作生成物理一致的、先验指导的决策。 ActionReasoning 利用大型语言模型 (LLM) 中已编码的物理先验和现实世界知识，并将它们构建在多代理架构中。我们在砖堆垛的易处理案例研究中实例化了该框架，其中假设环境状态已经被准确测量。然后环境状态被序列化并传递到多代理 LLM 框架，该框架生成物理感知行动计划。实验表明，所提出的多代理 LLM 框架可以实现稳定的积木放置，同时将工作量从低级特定领域编码转移到高级工具调用和提示，突出了其更广泛泛化的潜力。这项工作引入了一种有前途的方法，通过将物理推理与法学硕士相结合，在机器人操作中桥接感知和执行。|[2602.21161](http://arxiv.org/abs/2602.21161)|null|\n",
        "2602.21157": "|**2026-02-24**|**HALO: A Unified Vision-Language-Action Model for Embodied Multimodal Chain-of-Thought Reasoning**|视觉-语言-动作（VLA）模型在机器人操作方面表现出了强大的性能，但由于缺乏多模态推理和预测世界在行动下如何演变的明确机制，常常在长期或分布外场景中表现不佳。最近的工作在VLA模型中引入文本思维链或视觉子目标预测来进行推理，但仍然未能为联合文本推理、视觉预见和动作预测提供统一的类人推理框架。为此，我们提出了 HALO，一个统一的 VLA 模型，它通过文本任务推理的顺序过程、细粒度指导的视觉子目标预测和 EM-CoT 增强动作预测来实现体现多模式思想链 (EM-CoT) 推理。我们使用 Mixture-of-Transformers (MoT) 架构实例化 HALO，该架构将语义推理、视觉预见和动作预测解耦给专业专家，同时允许无缝的跨专家协作。为了大规模实现 HALO 学习，我们引入了一个自动化管道来合成 EM-CoT 训练数据以及精心设计的训练方案。大量实验表明：（1）HALO 在模拟和现实环境中均实现了卓越的性能，在 RoboTwin 基准上超出了基线策略 pi_0 34.1%； (2) 训练方案和 EM-CoT 设计的所有建议组件都有助于提高任务成功率； (3) HALO 通过我们提出的 EM-CoT 推理在激进的看不见的环境随机化下表现出强大的泛化能力。|[2602.21157](http://arxiv.org/abs/2602.21157)|null|\n",
        "2602.21015": "|**2026-02-24**|**From Perception to Action: An Interactive Benchmark for Vision Reasoning**|了解物理结构对于现实世界的应用（例如具体代理、交互设计和长视野操作）至关重要。然而，流行的视觉语言模型（VLM）评估仍然集中在与结构无关的单轮设置（例如，VQA）上，无法评估智能体推理几何、接触和支持关系如何共同限制动态环境中可能采取的行动的能力。为了解决这一差距，我们引入了动作和交互的因果层次结构 (CHAIN) 基准，这是一个交互式 3D、物理驱动的测试台，旨在评估模型是否能够理解、规划和执行基于物理约束的结构化动作序列。 CHAIN 将评估从被动感知转变为主动解决问题，涵盖联锁机械谜题以及 3D 堆叠和包装等任务。我们在统一的交互设置下对最先进的 VLM 和基于扩散的模型进行了全面的研究。我们的结果表明，表现最好的模型仍然难以内化物理结构和因果约束，往往无法制定可靠的长期计划，并且无法将感知的结构强有力地转化为有效的行动。该项目可在 https://social-ai-studio.github.io/CHAIN/ 获取。|[2602.21015](http://arxiv.org/abs/2602.21015)|null|\n",
        "2602.21013": "|**2026-02-24**|**Notes-to-Self: Scratchpad Augmented VLAs for Memory Dependent Manipulation Tasks**|许多灵巧的操作任务本质上都是非马尔可夫的，但在最近兴起的视觉-语言-动作（VLA）范式中，这一事实却很少受到关注。尽管它们成功地将互联网规模的语义理解引入机器人技术，但现有的 VLA 主要是“无状态的”，并且难以处理依赖于内存的长期任务。在这项工作中，我们探索了一种通过结合语言暂存器来向 VLA 传递空间和时间记忆的方法。便签本可以记住特定于任务的信息，例如对象位置，并且允许模型跟踪计划以及该计划中子目标的进展情况。我们在 MemoryBench 上对来自 ClevrSkills 环境的内存相关任务的拆分以及具有挑战性的现实世界拾取和放置任务评估了这种方法。我们证明，结合语言暂存器可以显着提高非循环和循环模型的这些任务的泛化能力。|[2602.21013](http://arxiv.org/abs/2602.21013)|null|\n",
        "2602.20979": "|**2026-02-24**|**Toward an Agentic Infused Software Ecosystem**|在软件开发中充分利用人工智能代理的能力需要重新思考软件生态系统本身。为此，本文概述了基于三个支柱的代理注入软件生态系统 (AISE) 的创建。首先，当然是人工智能代理本身，在过去的五年里，人工智能代理已经从简单的代码完成转向复杂的独立开发任务，这一趋势只会持续下去。第二个支柱是这些代理用来完成任务的编程语言和 API（或工具），并且越来越多地充当人类和人工智能代理交互和协作的通信基础。最后一个支柱是代理运行的运行时环境和生态系统，它提供了编程代理用于与外部世界交互（并影响其中的操作）的功能。为了实现 AISE 的愿景，所有三个支柱都必须以整体方式推进，最重要的是，以一种对当前存在的、未来存在的人工智能代理以及与它们一起工作的人类开发人员来说具有协同作用的方式。|[2602.20979](http://arxiv.org/abs/2602.20979)|null|\n",
        "2602.20963": "|**2026-02-24**|**A Robotic Testing Platform for Pipelined Discovery of Resilient Soft Actuators**|高电场下的短寿命阻碍了线性介电弹性体致动器（DEA）在机器人中的广泛应用。由于每个样本测试耗时且高维参数空间影响性能，系统扫描很困难。为了解决这个问题，我们提出了一种由能够扫描 DEA 寿命的新型测试机器人启用的优化管道。该机器人集成了机电性能测量、可编程电压输入和多通道测试能力。使用它，我们扫描了基于 Elastosil 的线性执行器的寿命参数，包括输入电压幅度、频率、电极材料浓度和电连接填料。最佳参数组合将边界操作条件下的使用寿命提高了 100%，并随后按比例扩大以实现更高的力和位移输出。最终产品展示了模块化、可扩展的四足步行机器人的弹性，具有有效负载能力（> 100% 的自由体重，> 700% 的组合执行器重量）。这项工作首次将自动驾驶实验室方法引入机器人执行器设计中。|[2602.20963](http://arxiv.org/abs/2602.20963)|null|\n",
        "2602.20943": "|**2026-02-24**|**UFO: Unifying Feed-Forward and Optimization-based Methods for Large Driving Scene Modeling**|动态驾驶场景重建对于自动驾驶仿真和闭环学习至关重要。虽然最近的前馈方法已显示出 3D 重建的前景，但由于序列长度的二次复杂性以及长时间建模动态对象的挑战，它们在长距离驱动序列方面遇到了困难。我们提出了 UFO，一种新颖的循环范例，它结合了基于优化和前馈方法的优点，可实现高效的远程 4D 重建。我们的方法维护了 4D 场景表示，随着新观察的到来，该表示不断迭代地细化，使用基于可见性的过滤机制来选择信息丰富的场景标记并实现长序列的高效处理。对于动态对象，我们引入了一种对象姿势引导建模方法，支持精确的远程运动捕捉。 Waymo 开放数据集上的实验表明，我们的方法在各种序列长度上显着优于按场景优化和现有的前馈方法。值得注意的是，我们的方法可以在 0.5 秒内重建 16 秒的驾驶日志，同时保持卓越的视觉质量和几何精度。|[2602.20943](http://arxiv.org/abs/2602.20943)|null|\n",
        "2602.20846": "|**2026-02-24**|**Body-Reservoir Governance in Repeated Games: Embodied Decision-Making, Dynamic Sentinel Adaptation, and Complexity-Regularized Optimization**|标准博弈论通过诸如“一报还一报”（TfT）之类的条件策略来解释重复博弈中的合作，但这需要连续计算，从而给实体主体带来物理成本。我们提出了一个三层的身体储存库治理（BRG）架构：（1）一个身体储存库（回声状态网络），其$d$维状态对交互历史进行隐式推理，充当决策者和异常检测器，（2）一个认知过滤器，提供按需激活的昂贵的策略工具，以及（3）一个具有感受性参数$α\\in [0,1]$的元认知治理层。在全身治理（$α=1$）下，闭环动力学满足自洽方程：合作表示为水库的固定点，而不是计算。策略复杂度成本定义为水库状态分布与其习惯基线之间的 KL 散度。主体治理降低了这一成本，维度为 $d$ 的行动方差减少至 $1600\\times$。动态哨兵根据储存库自身状态生成复合不适信号，驱动自适应 $α(t)$：合作期间接近基线，在背叛时迅速下降以激活认知报复。超越身体会产生与内部状态扭曲成比例的热力学成本。哨兵在所有条件下都获得了最高回报，优于静态机构治理、TfT 和 EMA 基线。维度扫描（$d \\in \\{5,\\ldots,100\\}$）显示隐式推理尺度与身体丰富度（$23\\times$ 到 $1600\\times$ 方差减少），归因于储层动态。 $(d, τ_{\\mathrm{env}})$ 空间中的相图揭示了 $d \\approx 20$ 附近的治理制度转变。该框架将合作重新解释为适应动力系统的最小耗散响应——从体现的动态而不是计算的动态中产生。|[2602.20846](http://arxiv.org/abs/2602.20846)|null|\n",
        "2602.20794": "|**2026-02-24**|**VGGDrive: Empowering Vision-Language Models with Cross-View Geometric Grounding for Autonomous Driving**|跨视角3D几何建模能力对于自动驾驶的重要性不言而喻，但现有的视觉语言模型（VLM）本身就缺乏这种能力，导致其性能表现平平。虽然一些有前途的方法试图通过构建用于辅助训练的问答数据来缓解这一问题，但它们仍然无法从根本上使 VLM 具备全面处理不同评估协议的能力。因此，我们制定了一条新路线，主张将成熟 3D 基础模型的交叉视图几何基础注入 VLM，从而缩小自动驾驶中的这一关键能力差距。本着这种精神，我们提出了一种新颖的架构 VGGDrive，它为视觉语言模型提供了跨视图几何基础，以实现自动驾驶。具体来说，为了将冻结视觉 3D 模型中的跨视图 3D 几何特征与 VLM 的 2D 视觉特征连接起来，我们引入了即插即用的跨视图 3D 几何启用器 (CVGE)。 CVGE解耦了基础VLM架构，并通过分层自适应注入机制有效地为VLM提供了3D功能。大量实验表明，VGGDrive 在五个自动驾驶基准测试中增强了基本 VLM 性能，包括跨视图风险感知、运动预测和轨迹规划等任务。我们相信，成熟的 3D 基础模型可以通过有效集成来赋能自动驾驶任务，我们希望我们的初步探索能够向自动驾驶社区展示这种范式的潜力。|[2602.20794](http://arxiv.org/abs/2602.20794)|null|\n",
        "2602.22208": "|**2026-02-25**|**Solaris: Building a Multiplayer Video World Model in Minecraft**|现有的动作条件视频生成模型（视频世界模型）仅限于单智能体视角，无法捕捉现实世界环境的多智能体交互。我们介绍 Solaris，这是一种模拟一致的多视图观察的多人视频世界模型。为了实现这一目标，我们开发了一个多人数据系统，专为《我的世界》等视频游戏的稳健、连续和自动化数据收集而设计。与之前为单人游戏设置构建的平台不同，我们的系统支持协调的多代理交互和同步视频+动作捕捉。使用该系统，我们收集了 1264 万个多人游戏帧，并提出了多人运动、记忆、接地、构建和视图一致性的评估框架。我们使用分阶段的管道来训练 Solaris，该管道逐渐从单人模式过渡到多人模式，结合了双向、因果和自我强迫训练。在最后阶段，我们引入了检查点自我强迫，这是一种内存高效的自我强迫变体，可以实现更长视野的教师。结果显示我们的架构和培训设计优于现有基线。通过开源我们的系统和模型，我们希望为新一代多智能体世界模型奠定基础。|[2602.22208](http://arxiv.org/abs/2602.22208)|null|\n",
        "2602.22198": "|**2026-02-25**|**Thermal activation drives a finite-size crossover from scale-free to runaway avalanches in amorphous solids**|我们使用具有局部激活规则且无外部驱动的弹塑性模型研究非晶固体中的热雪崩动力学。通过持久性测量和相关的四点磁化率 $χ_4$ 量化的动态异质性揭示了随着温度变化而出现的相关时空重排。随着温度升高，雪崩统计数据从具有指数截止的无标度行为演变为由跨系统失控事件主导的状态。我们确定了一个与系统尺寸相关的临界温度$T_c(L)$，它将间歇性雪崩动力学与热辅助流分开，其中自持雪崩使系统瞬时流化。我们表明，$T_c(L)$ 随着系统尺寸的增加而代数减小，这表明在热力学极限下，任意小但有限的温度可能会破坏间歇状态的稳定性。雪崩大小和持续时间之间的关系类似于剪切系统中的关系，而屈服最小距离的统计数据揭示了严格驱动的过阻尼动力学中不存在的温度驱动的边际稳定性重组。我们的结果表明，仅热激活就可以在无序弹性介质中产生有限尺寸控制的不稳定尺度。|[2602.22198](http://arxiv.org/abs/2602.22198)|null|\n",
        "2602.22172": "|**2026-02-25**|**Effects of realistic laser intensity and phase distribution on high-charge laser wakefield acceleration**|激光尾场加速（LWFA）可以在厘米长的等离子体中产生相对论电子束和各种二次粒子，使其成为有价值的粒子源，在许多学科中具有重要应用。在这项工作中，我们通过实验测量和细胞内颗粒模拟研究了激光脉冲的非理想横向强度和相位分布对 LWFA 的影响。与横向高斯激光相比，75 TW 激光脉冲的复杂横向轮廓降低了等离子体中的自聚焦强度。此外，现实激光脉冲激发的非线性等离子体尾流的鞘层结构比高斯激光器的鞘层结构更宽、更复杂。这些阻碍了等离子体电子的注入。当激光脉冲在等离子体中传播时，其强度分布逐渐变成椭圆形，并在主轴方位角附近驱动具有尖锐鞘的等离子体尾流，从而导致注入。当在模拟中使用真实的激光轮廓时，注入电子的电荷和能量与实验结果非常匹配（$\\sim200$ pC 电荷和 $\\sim 200$ MeV 峰值能量），而高斯激光模拟产生更高的电荷（$\\sim500$ pC）。我们的研究结果揭示了由非理想激光脉冲驱动的 LWFA 与由高斯脉冲驱动的 LWFA 之间的注入动力学差异，并且对于需要高电荷电子束的 LWFA 应用非常有用。|[2602.22172](http://arxiv.org/abs/2602.22172)|null|\n",
        "2602.22096": "|**2026-02-25**|**WeatherCity: Urban Scene Reconstruction with Controllable Multi-Weather Transformation**|可编辑的高保真 4D 场景对于自动驾驶至关重要，因为它们可以应用于端到端训练和闭环仿真。然而，现有的重建方法主要局限于复制观测场景，缺乏多样化天气模拟的能力。而图像级天气编辑方法往往会引入场景伪影，并且对天气效果的可控性较差。为了解决这些限制，我们提出了 WeatherCity，这是一种用于 4D 城市场景重建和天气编辑的新颖框架。具体来说，我们利用文本引导的图像编辑模型来实现图像天气背景的灵活编辑。为了应对多天气建模的挑战，我们引入了一种基于共享场景特征和专用天气特定解码器的新型天气高斯表示。通过内容一致性优化进一步增强了这种表示，确保不同天气条件下的连贯建模。此外，我们设计了一个物理驱动的模型，通过粒子和运动模式模拟动态天气效果。对多个数据集和各种场景的大量实验表明，WeatherCity在4D重建和天气编辑方面实现了灵活的可控性、高保真度和时间一致性。我们的框架不仅能够对天气条件（例如小雨和大雪）进行细粒度控制，而且还支持场景内的对象级操作。|[2602.22096](http://arxiv.org/abs/2602.22096)|null|\n",
        "2602.22091": "|**2026-02-25**|**Learning to Drive is a Free Gift: Large-Scale Label-Free Autonomy Pretraining from Unposed In-The-Wild Videos**|在线提供的以自我为中心的驾驶视频为自动驾驶提供了丰富的视觉数据源，但它们缺乏注释使得学习捕获语义结构和 3D 几何的表示变得困难。大型前馈空间模型的最新进展表明，可以在一次前向传递中推断出点图和自我运动，这为可扩展的驾驶感知提供了一个有希望的方向。因此，我们提出了一个无标签、教师指导的框架，用于直接从未摆出的视频中学习自动驾驶表示。与之前主要关注帧间一致性的自我监督方法不同，我们认为安全和反应性驾驶关键取决于时间背景。为此，我们利用配备轻量级自回归模块的前馈架构，使用多模态监督信号进行训练，引导模型联合预测当前和未来的点图、相机姿势、语义分割和运动掩模。多模态教师提供序列级伪监督，使 LFG 能够从原始 YouTube 视频中学习统一的伪 4D 表示，而无需姿势、标签或 LiDAR。由此产生的编码器不仅可以有效地转移到 NAVSIM 基准上的下游自动驾驶规划，超越多摄像头和仅使用单个单目摄像头的 LiDAR 基线，而且在一系列语义、几何和定性运动预测任务上进行评估时也能产生强大的性能。这些几何和运动感知功能使 LFG 成为引人注目的以视频为中心的自动驾驶基础模型。|[2602.22091](http://arxiv.org/abs/2602.22091)|null|\n",
        "2602.22040": "|**2026-02-25**|**IGR J12580+0134: A Candidate for Repeating Partial Tidal Disruption Events Supported by Multi-Wavelength Observations**|重复部分潮汐破坏事件（pTDE）可以直接探测超大质量黑洞周围的恒星轨道和偶发性质量损失，但可靠的识别需要多波段和多纪元的证据。我们使用多历元 Karl G. Jansky VLA 观测以及来自 Swift/XRT 和 NICER 的 X 射线约束，研究 NGC 4845 中核瞬变 IGR J12580+0134 的晚期射电再亮是否可以解释为重复的 pTDE。射电光曲线显示出两个不同的阶段，L 波段峰值相隔 $\\approx1513$ 天。使用马尔可夫链蒙特卡罗拟合的同步加速器余辉框架对第二阶段进行建模有利于非相对论流出 $v\\simeq0.03c$，其各向同性等效动能为 $10^{50}$ erg 在近似恒定密度的核周介质中传播。在 2016 年的射电耀斑期间，Swift/XRT 没有检测到明显的同期增亮，而 2023 年的微弱 NICER 耀斑表明存在间歇性低水平吸积。因此，复发时间尺度和无线电能量学使 IGR J12580+0134 成为重复 pTDE 系统的可能候选者，从而激励持续敏感的无线电和 X 射线监测来测试未来的重新激活。|[2602.22040](http://arxiv.org/abs/2602.22040)|null|\n",
        "2602.22010": "|**2026-02-25**|**World Guidance: World Modeling in Condition Space for Action Generation**|利用未来的观察模型来促进行动生成，为增强视觉-语言-行动（VLA）模型的能力提供了一条有前途的途径。然而，现有的方法很难在保持高效、可预测的未来表示和保留足够的细粒度信息以指导精确的动作生成之间取得平衡。为了解决这个限制，我们提出了 WoG（世界指导），这是一个框架，通过将未来的观察结果注入到动作推理管道中，将它们映射到紧凑的条件中。然后，VLA 经过训练，可以同时预测这些压缩条件和未来的动作，从而在条件空间内实现有效的世界建模以进行动作推理。我们证明，建模和预测这个条件空间不仅有利于细粒度动作的生成，而且还表现出卓越的泛化能力。此外，它还可以从大量的人类操作视频中有效地学习。模拟和现实环境中的大量实验验证了我们的方法显着优于基于未来预测的现有方法。项目页面位于：https://selen-suyue.github.io/WoGNet/|[2602.22010](http://arxiv.org/abs/2602.22010)|null|\n",
        "2602.22001": "|**2026-02-25**|**Are Foundation Models the Route to Full-Stack Transfer in Robotics?**|对于人类和机器人来说，迁移学习发生在不同的抽象层次上，从高级语言迁移到低级运动技能迁移。在本文中，我们概述了基础模型和变压器网络对这些不同级别的影响，使机器人比以往任何时候都更接近“全栈传输”。从机器人迁移学习的角度考虑 LLM、VLM 和 VLA，使我们能够强调除具体实现之外的重复出现的迁移概念。我们还考虑了基础模型时代机器人技术的数据收集和传输基准的挑战。基础模型是机器人全栈传输的途径吗？我们的期望是，他们一定会作为关键技术继续走这条路线。|[2602.22001](http://arxiv.org/abs/2602.22001)|null|\n",
        "2602.21992": "|**2026-02-25**|**PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning**|360 度全景图像越来越多地用于虚拟现实、自动驾驶和机器人技术中，以实现整体场景理解。然而，由于几何失真和有限的 3D 监督，当前的视觉语言模型 (VLM) 难以在等距柱状投影 (ERP) 图像上进行 3D 空间推理。我们推出了 PanoEnv，这是一个从合成 3D 环境构建的大型 VQA 基准测试，包含五个类别（例如相对位置、体积比较）的 14.8K 个问题，这些问题基于准确的 3D 注释，包括深度、分割和边界框。对 14 个最先进的 VLM 进行基准测试揭示了有限的 3D 理解，总体准确率仅为 49.34%，开放式 (OE) 问题的准确率为 8.36%。为了增强 3D 推理，我们提出了一种基于组相对策略优化 (GRPO) 的强化学习后训练框架，该框架具有基于事实指导的奖励，其中结合了距离容差和空间一致性等五种几何感知策略。两阶段课程进一步减轻灾难性遗忘：第一阶段训练结构化任务（真/假和多项选择），第二阶段对混合开放式数据进行微调以提高泛化能力。我们的 7B 模型实现了新的最先进的性能，将整体准确率提高到 52.93% (+3.59%)，将开放式准确率提高到 14.83%，同时保持结构化任务性能。它还取得了最高的语义评估分数（Q-Score 6.24，P-Score 5.95），超越了 32B 模型。这些结果表明，PanoEnv-QA 和我们基于课程的 RL 框架有效地将 3D 空间智能注入 VLM 中，以实现全方位感知。|[2602.21992](http://arxiv.org/abs/2602.21992)|null|\n",
        "2602.21952": "|**2026-02-25**|**MindDriver: Introducing Progressive Multimodal Reasoning for Autonomous Driving**|视觉语言模型（VLM）表现出强大的推理能力，显示出端到端自动驾驶系统的前景。思想链（CoT）作为VLM广泛使用的推理策略，正面临着严峻的挑战。现有的文本CoT在文本语义空间和轨迹物理空间之间存在较大差距。尽管最近的方法利用未来图像代替文本作为 CoT 过程，但它缺乏明确的面向规划的客观指导来生成具有准确场景演化的图像。为了解决这些问题，我们创新性地提出了 MindDriver，这是一种渐进式多模态推理框架，使 VLM 能够模仿人类的渐进式思维进行自动驾驶。 MindDriver 呈现语义理解、语义到物理空间想象以及物理空间轨迹规划。为了在 MindDriver 中实现对齐推理过程，我们开发了一个反馈引导的自动数据注释管道来生成对齐的多模态推理训练数据。此外，我们开发了一种渐进强化微调方法，通过渐进的高水平基于奖励的学习来优化对齐。 MindDriver 在 nuScences 开环和 Bench2Drive 闭环评估中展示了卓越的性能。代码可在 https://github.com/hotdogcheesewhite/MindDriver 获取。|[2602.21952](http://arxiv.org/abs/2602.21952)|null|\n",
        "2602.23259": "|**2026-02-26**|**Risk-Aware World Model Predictive Control for Generalizable End-to-End Autonomous Driving**|随着模仿学习（IL）和大规模驾驶数据集的进步，端到端自动驾驶（E2E-AD）最近取得了巨大进展。目前，基于IL的方法已成为主流范式：模型依赖于专家给出的标准驾驶行为，并学习最小化其行为与专家行为之间的差异。然而，“只像专家一样驾驶”这一目标的泛化能力有限：当遇到专家演示分布之外的罕见或未见的长尾场景时，模型往往会在缺乏先验经验的情况下做出不安全的决策。这就提出了一个基本问题：E2E-AD 系统能否在没有任何专家行动监督的情况下做出可靠的决策？受此启发，我们提出了一个名为风险感知世界模型预测控制（RaWMPC）的统一框架，通过稳健控制来解决这种泛化困境，而不依赖于专家演示。实际上，RaWMPC 利用世界模型来预测多个候选行动的后果，并通过明确的风险评估选择低风险行动。为了赋予世界模型预测危险驾驶行为结果的能力，我们设计了一种风险感知交互策略，系统地将世界模型暴露于危险行为，使灾难性结果可预测，从而可以避免。此外，为了在测试时生成低风险的候选动作，我们引入了一种自我评估蒸馏方法，将风险规避能力从训练有素的世界模型中提取到生成动作提案网络中，而无需任何专家演示。大量实验表明，RaWMPC 在分布内和分布外场景中均优于最先进的方法，同时提供卓越的决策可解释性。|[2602.23259](http://arxiv.org/abs/2602.23259)|null|\n",
        "2602.23164": "|**2026-02-26**|**MetaOthello: A Controlled Study of Multiple World Models in Transformers**|基础模型必须处理多个生成过程，但机械可解释性主要研究孤立的能力；目前尚不清楚单个变压器如何组织多个可能相互冲突的“世界模型”。之前关于黑白棋玩神经网络的实验测试了世界模型学习，但重点关注具有一组规则的单个游戏。我们引入了 MetaOthello，这是一套受控的 Othello 变体套件，具有共享语法但不同的规则或标记化，并在混合变体数据上训练小型 GPT，以研究如何在共享表示空间中组织多个世界模型。我们发现，在混合游戏数据上训练的 Transformer 不会将其容量划分为孤立的子模型；相反，它们集中在一个大部分共享的董事会状态表示上，该表示在变体之间因果转移。在一种变体上训练的线性探针可以干预另一种变体的内部状态，其有效性接近匹配探针。对于具有令牌重新映射的同构游戏，表示相当于跨层泛化的单个正交旋转。当规则部分重叠时，早期层保持与游戏无关的表示，而中间层识别游戏身份，而后面的层则专门化。 MetaOthello 不仅提供了一条了解变形金刚是否学习世界模型的途径，还提供了一条了解它们如何同时组织多个世界模型的途径。|[2602.23164](http://arxiv.org/abs/2602.23164)|null|\n",
        "2602.23152": "|**2026-02-26**|**The Trinity of Consistency as a Defining Principle for General World Models**|构建能够学习、模拟和推理客观物理定律的世界模型是追求通用人工智能的基本挑战。以 Sora 等视频生成模型为代表的最新进展证明了数据驱动的缩放定律在近似物理动力学方面的潜力，而新兴的统一多模态模型 (UMM) 则为集成感知、语言和推理提供了一种有前途的架构范例。尽管取得了这些进展，该领域仍然缺乏一个原则性的理论框架来定义通用世界模型所需的基本属性。在本文中，我们提出世界模型必须建立在一致性三位一体的基础上：模态一致性作为语义接口，空间一致性作为几何基础，时间一致性作为因果引擎。通过这个三方视角，我们系统地回顾了多模态学习的演变，揭示了从松散耦合的专业模块到统一架构的轨迹，从而实现内部世界模拟器的协同出现。为了补充这个概念框架，我们引入了 CoW-Bench，这是一个以多帧推理和生成场景为中心的基准测试。 CoW-Bench 在统一的评估协议下评估视频生成模型和 UMM。我们的工作建立了通向通用世界模型的原则性途径，阐明了当前系统的局限性和未来进步的架构要求。|[2602.23152](http://arxiv.org/abs/2602.23152)|null|\n",
        "2602.23148": "|**2026-02-26**|**On Sample-Efficient Generalized Planning via Learned Transition Models**|广义规划研究解决方案策略的构建，该解决方案策略泛化于共享公共域模型的规划问题系列，由转换函数 $γ 正式定义：S \\times A \\rightarrow S$。经典方法通过符号抽象和对 $γ$ 的显式推理来实现这种泛化。相比之下，最近基于 Transformer 的规划器（例如 PlanGPT 和 Plansformer）在很大程度上将广义规划视为直接动作序列预测，绕过了显式转换建模。虽然对分布内实例有效，但这些方法通常需要大型数据集和模型大小，并且由于缺乏明确的世界状态演化，常常会在长范围设置中遭受状态漂移。在这项工作中，我们将广义规划制定为转换模型学习问题，其中神经模型显式逼近后继状态函数 $\\hatγ \\approx γ$ 并通过推出符号状态轨迹来生成计划。该模型不是直接预测动作，而是自回归预测中间世界状态，从而将域动态学习为隐式世界模型。为了研究大小不变的泛化和样本效率，我们系统地评估了多种状态表示和神经架构，包括关系图编码。我们的结果表明，在多个领域中，学习显式转换模型比直接行动序列预测能产生更高的分布外满足计划成功率，同时通过显着更少的训练实例和更小的模型来实现这些收益。这是 ICAPS 2026 上接受的同名短论文的扩展版本。|[2602.23148](http://arxiv.org/abs/2602.23148)|null|\n",
        "2602.23109": "|**2026-02-26**|**Towards Intelligible Human-Robot Interaction: An Active Inference Approach to Occluded Pedestrian Scenarios**|突然出现的被遮挡行人给自动驾驶带来了严峻的安全挑战。传统的基于规则或纯粹数据驱动的方法难以应对这些长尾场景固有的高度不确定性。为了应对这一挑战，我们提出了一种基于主动推理的新颖框架，该框架赋予智能体类似人类的信念驱动机制。我们的框架利用 Rao-Blackwellized 粒子滤波器 (RBPF) 来有效估计行人的混合状态。为了在不确定性下模拟类人的认知过程，我们引入了条件信念重置机制和假设注入技术，以明确地模拟有关行人多重潜在意图的信念。规划是通过交叉熵方法 (CEM) 增强型模型预测路径积分 (MPPI) 控制器实现的，该控制器将 CEM 的高效迭代搜索与 MPPI 固有的鲁棒性相结合。模拟实验表明，与反应性、基于规则和强化学习 (RL) 基线相比，我们的方法显着降低了碰撞率，同时还表现出可解释的、类人的驾驶行为，反映了智能体的内部信念状态。|[2602.23109](http://arxiv.org/abs/2602.23109)|null|\n",
        "2602.23058": "|**2026-02-26**|**GeoWorld: Geometric World Models**|基于能量的预测世界模型通过推理潜在的能量景观而不是生成像素，为多步骤视觉规划提供了一种强大的方法。然而，现有的方法面临两个主要挑战：（i）它们的潜在表示通常是在欧几里得空间中学习的，忽略了状态之间潜在的几何和层次结构；（ii）它们难以进行长期预测，这导致在扩展部署过程中快速退化。为了解决这些挑战，我们引入了 GeoWorld，这是一种几何世界模型，通过双曲 JEPA 保留几何结构和层次关系，它将欧几里得空间的潜在表示映射到双曲流形。我们进一步引入几何强化学习进行基于能量的优化，从而在双曲潜在空间中实现稳定的多步规划。 CrossTask 和 COIN 上的大量实验表明，与最先进的 V-JEPA 2 相比，3 步规划的 SR 提高了约 3%，4 步规划的 SR 提高了 2%。 项目网站：https://steve-zeyu-zhang.github.io/GeoWorld。|[2602.23058](http://arxiv.org/abs/2602.23058)|null|\n",
        "2602.23046": "|**2026-02-26**|**The LOFAR sub-arcsecond view of the high-redshift radio relic in PSZ2G091.83+26.11**|高红移下增强的逆康普顿 (IC) 损耗使星系团中的漫射射电光谱变得陡峭，从而有利于低频（~100 MHz）观测。然而，低频研究通常缺乏定位粒子加速位点或分离射电星系漫射发射所需的分辨率。在本文中，我们通过解析加速站点并检查下游区域，揭示了遥远星团PSZ2G091.83+26.11（z=0.822）中射电遗迹的属性。我们使用 145 MHz 的欧洲 LOFAR (ILT)，首次在 1 GHz 以下研究了（亚）角秒分辨率的射电遗迹，并辅以更高频率的角秒分辨率 VLA 数据。我们确认漫射发射不是射电星系。朝向簇中心的光谱指数梯度与之前的 5'' 地图相匹配。高分辨率 0.4 英寸和 1.9 英寸图像显示了冲击波之前的发射，将遗迹与射电星系连接起来。 145 MHz 和 3.0 GHz 下游的 1.9'' 剖面遵循对数正态磁场分布。 145 MHz 冲击表面在电子密度、旋转测量和分数极化变化的同一位置显示出明显的不连续性，可能与磁场变化有关。最后，我们发现了无线电功率红移演化与星团质量相关性的暗示。 LOFAR 长基线可实现令人印象深刻的角分辨率，为星系团中的低能等离子体打开了前所未有的视野。这在高红移星团的情况下极其重要，其中低频无线电发射受能量损失的影响较小，但其检测受到分辨率差的严重限制。|[2602.23046](http://arxiv.org/abs/2602.23046)|null|\n",
        "2602.22988": "|**2026-02-26**|**Residual Koopman Spectral Profiling for Predicting and Preventing Transformer Training Instability**|Transformer 中的训练分歧会浪费计算量，但实践者只有在昂贵的运行开始后才发现不稳定。因此，在培训开始之前，他们需要变压器的预期故障概率。我们对残余库普曼光谱分析 (RKSP) 的研究提供了这样的估计。从初始化时的单个前向传递中，RKSP 通过将白化动态模式分解应用于逐层残差快照来提取库普曼谱特征。我们的核心诊断，即近单位光谱质量，量化了集中在单位圆附近的模态分数，从而捕获了不稳定风险。为了预测广泛配置之间的分歧，该估计器实现了 0.995 的 AUROC，优于最佳梯度基线。我们通过库普曼频谱整形（KSS）进一步使这种诊断变得可行，它在训练期间重塑频谱。我们凭经验验证我们的方法在实践中是否有效：RKSP 在初始化时预测发散，当 RKSP 标记高风险时，打开 KSS 成功防止发散。在没有归一化层的具有挑战性的高学习率机制中，KSS 将发散率从 66.7% 降低到 12.5%，并使学习率提高 50% 到 150%。这些发现可推广到 WikiText-103 语言模型、CIFAR-10 上的视觉转换器和预训练语言模型（包括高达 7B 的 GPT-2 和 LLaMA-2），以及新兴架构（例如 MoE、Mamba 风格的 SSM 和 KAN）。|[2602.22988](http://arxiv.org/abs/2602.22988)|null|\n",
        "2602.22960": "|**2026-02-26**|**UCM: Unifying Camera Control and Memory with Time-aware Positional Encoding Warping for World Models**|基于视频生成的世界模型在模拟交互环境方面表现出了巨大的潜力，但在两个关键领域面临着持续的困难：重新访问场景时保持长期内容一致性以及通过用户提供的输入实现精确的摄像机控制。基于显式 3D 重建的现有方法通常会损害无界场景和细粒度结构的灵活性。替代方法直接依赖于先前生成的帧，而不建立明确的空间对应关系，从而限制了可控性和一致性。为了解决这些限制，我们提出了 UCM，这是一种新颖的框架，通过时间感知的位置编码扭曲机制将长期记忆和精确的相机控制结合起来。为了减少计算开销，我们设计了一种用于高保真生成的高效双流扩散变压器。此外，我们引入了一种可扩展的数据管理策略，利用基于点云的渲染来模拟场景重访，从而促进对超过 500K 单目视频的训练。对现实世界和综合基准的大量实验表明，UCM 在长期场景一致性方面显着优于最先进的方法，同时在高保真视频生成中实现了精确的摄像机可控性。|[2602.22960](http://arxiv.org/abs/2602.22960)|null|\n",
        "2602.22940": "|**2026-02-26**|**Considering Perspectives for Automated Driving Ethics: Collective Risk in Vehicular Motion Planning**|最近的自动车辆 (AV) 运动规划策略围绕最大限度地降低道路交通风险而发展。然而，他们只从自动驾驶汽车的角度考虑风险，因此没有考虑其决策对其他道路使用者的道德问题。我们认为，这并不能降低每个道路使用者的风险，因为从每个道路使用者的角度来看，风险可能不同。事实上，从自动驾驶汽车的角度最小化风险可能并不意味着从其他道路使用者的角度来看风险也被最小化；事实上，它甚至可能会增加。为了检验这一假设，我们提出了一种自动驾驶运动规划策略，支持在所有道路使用者视角之间切换风险最小化策略。我们发现，从其他道路使用者的角度来看的风险通常可以被认为与从自动驾驶汽车的角度来看的风险不同。从集体风险的角度来看，即平衡所有道路使用者的风险，我们观察到自动驾驶汽车能够最大限度地降低整体交通风险，同时为了他人的利益而将自己置于稍高的风险，这与人类的驾驶行为是一致的。此外，采用集体风险最小化策略还可以在其他道路使用者对自动驾驶汽车的风险估计较低时采取果断行动，从而有利于自动驾驶汽车的行驶效率。然而，当其他道路使用者难以预测其计划行动（即与高风险相关）时，自动驾驶汽车会保守驾驶。我们认为，这种行为是一种自我反思的形式，也是社会可接受的 AV 行为的自然先决条件。我们的结论是，为了促进包括自动驾驶汽车在内的道路交通的道德规范，在自动驾驶汽车的决策中必须考虑每个道路使用者的风险视角。|[2602.22940](http://arxiv.org/abs/2602.22940)|null|\n",
        "2602.24143": "|**2026-02-27**|**Robust Skills, Brittle Grounding: Diagnosing Restricted Generalization in Vision-Language Action Policies via Multi-Object Picking**|视觉语言动作（VLA）策略通常会在相对较少的演示下报告强大的操纵基准性能，但目前尚不清楚这是否反映了强大的语言到对象基础或对不会转移到训练分布之外的对象位置相关性的依赖。我们提出了一项受控的多对象拾取研究，该研究逐渐增加对象放置的可变性直至完全工作空间随机化，并评估保留的对象-位置配对，这些配对打破了熟悉的关联而不增加空间难度。通过这些压力测试和数据扩展，我们发现对于代表性的 VLA 策略，包括 SmolVLA 和 $π_{0.5}$，在更困难的情况下，操作原语的执行仍然比指令条件任务的成功更可靠，这表明操作技能的获取与指令遵循脱钩。我们建议使用任务阶梯和分解指标来增强操作基准，这些指标分别测量原始执行和指令条件成功，以更好地诊断基于指令的泛化。|[2602.24143](http://arxiv.org/abs/2602.24143)|null|\n",
        "2602.24121": "|**2026-02-27**|**Planning from Observation and Interaction**|观察学习要求代理仅通过参考对所执行任务的观察来学习执行任务。这项工作研究了现实世界机器人学习中的等效设置，其中不假设可以获得手工设计的奖励和演示动作。为了解决这种数据受限的环境，这项工作提出了一种基于规划的逆强化学习（IRL）算法，用于仅通过观察和交互进行世界建模。完全在现实世界中进行的实验表明，这种范例对于在一小时内从头开始学习基于图像的操作任务是有效的，无需假设先验知识、预训练或任务观察之外的任何类型的数据。此外，这项工作表明，学习到的世界模型表示能够从头开始在现实世界中进行在线迁移学习。与具有更多限制性假设的现有方法（包括 IRL、RL 和行为克隆 (BC)）相比，所提出的方法表现出显着更高的样本效率和成功率，为通过观察和交互进行在线世界建模和规划提供了一条实用的道路。视频及更多内容请访问：https://uwrobotlearning.github.io/mpail2/。|[2602.24121](http://arxiv.org/abs/2602.24121)|null|\n",
        "2602.24096": "|**2026-02-27**|**DiffusionHarmonizer: Bridging Neural Reconstruction and Photorealistic Simulation with Online Diffusion Enhancer**|仿真对于自动驾驶汽车等自主机器人的开发和评估至关重要。神经重建正在成为一种有前途的解决方案，因为它能够以自动化和可扩展的方式仅根据真实世界的数据模拟各种场景。然而，虽然 NeRF 和 3D Gaussian Splatting 等方法可以产生视觉上引人注目的结果，但它们经常会出现伪影，特别是在渲染新视图时，并且无法真实地集成插入的动态对象，特别是当它们是从不同场景捕获时。为了克服这些限制，我们引入了 DiffusionHarmonizer，这是一种在线生成增强框架，可将此类不完美场景的渲染转换为时间一致的输出，同时提高其真实感。其核心是一个单步时间条件增强器，它是从预训练的多步图像扩散模型转换而来的，能够在单个 GPU 上的在线模拟器中运行。有效训练它的关键是定制数据管理管道，该管道构建强调外观协调、伪像校正和光照真实感的合成真实对。其结果是一个可扩展的系统，显着提高了研究和生产环境中的模拟保真度。|[2602.24096](http://arxiv.org/abs/2602.24096)|null|\n",
        "2602.23997": "|**2026-02-27**|**Foundation World Models for Agents that Learn, Verify, and Adapt Reliably Beyond Static Environments**|下一代自主智能体不仅必须高效学习，而且必须可靠地行动并在开放世界中调整自己的行为。标准方法通常假设固定的任务和环境，很少或没有新颖性，这限制了世界模型支持代理的能力，代理必须随着条件的变化而发展其策略。本文概述了基础世界模型的愿景：统一强化学习、反应/程序合成和抽象机制的持久组合表示。我们提出了一个围绕四个组成部分构建的议程：（i）来自规范的可学习奖励模型，以支持具有明确目标的优化； (ii) 将自适应形式验证融入整个学习过程； (iii) 在线抽象校准，以量化模型预测的可靠性； (iv) 由验证者指导的测试时综合和世界模型生成。这些组件共同使代理能够综合可验证的程序，从少量的交互中得出新的策略，并在适应新颖性的同时保持正确性。由此产生的框架将基础世界模型定位为学习、推理和适应的基础，为智能体奠定了基础，这些智能体不仅表现良好，而且可以解释和证明他们所采取的行为。|[2602.23997](http://arxiv.org/abs/2602.23997)|null|\n",
        "2602.23969": "|**2026-02-27**|**MSVBench: Towards Human-Level Evaluation of Multi-Shot Video Generation**|视频生成向复杂、多镜头叙事的演变暴露了当前评估方法的严重缺陷。现有的基准仍然以单镜头范式为基础，缺乏评估长篇连贯性和吸引力所需的全面故事资产和交叉镜头指标。为了弥补这一差距，我们推出了 MSVBench，这是第一个综合基准测试，具有为多镜头视频生成量身定制的分层脚本和参考图像。我们提出了一种混合评估框架，它将大型多模态模型（LMM）的高级语义推理与特定领域专家模型的细粒度感知严谨性相结合。通过评估不同范式的 20 种视频生成方法，我们发现当前模型尽管具有很强的视觉保真度，但主要表现为视觉插值器而不是真实世界模型。我们通过展示最先进的 Spearman 排名与人类判断的 94.4% 相关性，进一步验证了基准的可靠性。最后，MSVBench 通过提供可扩展的监控信号来超越评估。在其管道细化的推理轨迹上微调轻量级模型，可产生与 Gemini-2.5-Flash 等商业模型相当的人性化性能。|[2602.23969](http://arxiv.org/abs/2602.23969)|null|\n",
        "2602.23937": "|**2026-02-27**|**Enhancing Vision-Language Navigation with Multimodal Event Knowledge from Real-World Indoor Tour Videos**|视觉语言导航（VLN）代理经常在看不见的环境中进行长视野推理，特别是在面对模糊的、粗粒度的指令时。虽然最近的进展使用知识图来增强推理，但受人类情景记忆启发的多模态事件知识的潜力仍未得到充分探索。在这项工作中，我们提出了一种以事件为中心的知识增强策略，用于自动化流程知识挖掘和特征融合，以解决 VLN 任务中的粗粒度指令和长范围推理问题。首先，我们构建了 YE-KG，这是第一个大规模多模态时空知识图，具有超过 86k 个节点和 83k 个边，源自真实世界的室内视频。通过利用多模态大语言模型（即 LLaVa、GPT4），我们将非结构化视频流提取为结构化语义-动作-效果事件，作为显式情景记忆。其次，我们介绍STE-VLN，它通过从粗到细的层次检索机制将上述图集成到VLN模型中。这使得智能体能够检索因果事件序列，并将它们与以自我为中心的视觉观察动态融合。 REVERIE、R2R 和 R2R-CE 基准测试证明了我们以事件为中心的策略的效率，在不同的行动空间中优于最先进的方法。我们的数据和代码可在项目网站 https://sites.google.com/view/y-event-kg/ 上找到。|[2602.23937](http://arxiv.org/abs/2602.23937)|null|\n",
        "2602.23896": "|**2026-02-27**|**TSC: Topology-Conditioned Stackelberg Coordination for Multi-Agent Reinforcement Learning in Interactive Driving**|密集交通中安全高效的自动驾驶从根本上来说是一个去中心化的多智能体协调问题，其中合并、编织等冲突点的交互必须在部分可观测性下可靠地解决。由于只有局部和不完整的线索，交互模式可能会迅速变化，通常会导致不稳定的行为，例如振荡屈服或不安全的承诺。现有的多智能体强化学习（MARL）方法要么采用同步决策，这加剧了非平稳性，要么依赖集中式排序机制，随着流量密度的增加，该机制扩展性较差。为了解决这些限制，我们提出了拓扑条件Stackelberg协调（TSC），这是一种在无通信执行下的去中心化交互式驱动的学习框架，它从轨迹之间受辫子启发的编织关系中提取时变有向优先级图，从而定义本地领导者-跟随者依赖关系，而无需构建全局游戏顺序。以此图为条件，TSC 将密集交互内生地分解为图本地 Stackelberg 子博弈，并在集中训练和分散执行 (CTDE) 下学习顺序协调策略，通过行动预测预测领导者，并通过行动条件价值学习训练追随者以近似局部最佳响应，从而提高密集交通中的训练稳定性和安全性。四种密集交通场景的实验表明，TSC 在关键指标上实现了优于代表性 MARL 基线的性能，最显着的是减少碰撞，同时保持有竞争力的交通效率和控制平滑性。|[2602.23896](http://arxiv.org/abs/2602.23896)|null|\n",
        "2602.23894": "|**2026-02-27**|**SelfOccFlow: Towards end-to-end self-supervised 3D Occupancy Flow prediction**|估计车辆周围环境的 3D 占用和运动对于自动驾驶、实现动态环境中的态势感知至关重要。现有方法联合学习几何和运动，但依赖于昂贵的 3D 占用和流注释、边界框的速度标签或预训练的光流模型。我们提出了一种用于 3D 占用流量估计的自监督方法，无需人工生成注释或外部流量监督。我们的方法将场景分解为单独的静态和动态符号距离场，并通过时间聚合隐式学习运动。此外，我们引入了源自特征余弦相似性的强大自监督流程提示。我们在 SemanticKITTI、KITTI-MOT 和 nuScenes 上展示了 3D 占用流方法的有效性。|[2602.23894](http://arxiv.org/abs/2602.23894)|null|\n",
        "2602.23871": "|**2026-02-27**|**Bandwidth-adaptive Cloud-Assisted 360-Degree 3D Perception for Autonomous Vehicles**|自动驾驶的一个关键挑战在于在严格的延迟限制下保持对周围障碍物的实时态势感知。高处理要求加上有限的机载计算资源可能会导致延迟问题，特别是在复杂的城市环境中。为了解决这个问题，我们建议利用车辆到一切（V2X）通信将处理部分卸载到计算资源丰富的云端，从而减少整体延迟。我们的方法利用基于 Transformer 的模型将多摄像头传感器数据融合到全面的鸟瞰图 (BEV) 表示中，从而实现准确的 360 度 3D 物体检测。根据本地处理的层数和特征的量化级别，计算在车辆和云端之间动态分配。为了进一步减少网络负载，我们在传输之前应用特征向量裁剪和压缩。在现实世界的实验评估中，与传统的板载解决方案相比，我们的混合策略实现了 72% 的端到端延迟减少。为了适应波动的网络条件，我们引入了一种动态优化算法，该算法选择分割点和量化级别以最大限度地提高检测精度，同时满足实时延迟约束。实际带宽变化下基于轨迹的评估表明，在相同的延迟性能下，这种自适应方法比静态参数化的精度提高了 20%。|[2602.23871](http://arxiv.org/abs/2602.23871)|null|\n",
        "2602.23787": "|**2026-02-27**|**FPPS: An FPGA-Based Point Cloud Processing System**|点云处理是自动驾驶系统的计算瓶颈，特别是对于实时应用程序，而能源效率仍然是一个关键的系统约束。这项工作提出了 FPPS，这是一种 FPGA 加速的点云处理系统，旨在优化迭代最近点 (ICP) 算法，这是 3D 定位和感知管道的经典基石。在广泛使用的 KITTI 基准数据集上进行评估，所提出的系统比最先进的 CPU 基准实现了高达 35$\\times$（运行时加权平均值为 15.95 倍）的加速，同时保持同等的配准精度。值得注意的是，该设计将平均功率效率提高了 8.58 倍，在性能和能耗之间实现了令人信服的平衡。这些结果使 FPPS 成为资源受限的嵌入式自主平台的可行解决方案，其中延迟和功耗都是关键的设计优先事项。|[2602.23787](http://arxiv.org/abs/2602.23787)|null|\n"
    }
}