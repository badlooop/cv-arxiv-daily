{
    "Video Diffusion": {
        "2511.21579": "|**2025-11-26**|**Harmony: Harmonizing Audio and Video Generation through Cross-Task Synergy**|同步视听内容的合成是生成人工智能的一个关键挑战，开源模型面临着稳健的视听对齐的挑战。我们的分析表明，这个问题根源于联合扩散过程的三个基本挑战：（1）对应漂移，同时演化的噪声潜伏阻碍了对齐的稳定学习； (2) 低效的全局注意力机制，无法捕捉细粒度的时间线索； （3）传统无分类器指导（CFG）的模态内偏差，它增强了条件性，但没有增强跨模态同步。为了克服这些挑战，我们引入了 Harmony，这是一种新颖的框架，可以机械地强制执行视听同步。我们首先提出了一种跨任务协同训练范例，通过利用来自音频驱动视频和视频驱动音频生成任务的强大监督信号来减轻漂移。然后，我们设计了一个全局-局部解耦交互模块，以实现高效、精确的时间式对齐。最后，我们提出了一种新颖的同步增强型 CFG (SyncCFG)，它可以在推理过程中显式地隔离和放大对齐信号。大量实验表明，Harmony 建立了一种新的最先进技术，在生成保真度以及最重要的是实现细粒度视听同步方面都显着优于现有方法。|[2511.21579](http://arxiv.org/abs/2511.21579)|null|\n",
        "2511.21541": "|**2025-11-26**|**Video Generation Models Are Good Latent Reward Models**|事实证明，奖励反馈学习（ReFL）对于使图像生成与人类偏好保持一致是有效的。然而，其扩展到视频生成面临着重大挑战。现有的视频奖励模型依赖于为像素空间输入设计的视觉语言模型，将 ReFL 优化限制在计算成本高昂的 VAE 解码后接近完成的去噪步骤。这种像素空间方法会产生大量的内存开销和增加的训练时间，并且其后期优化缺乏早期监督，仅改进视觉质量，而不是基本的运动动力学和结构连贯性。在这项工作中，我们表明预训练的视频生成模型自然适合在噪声潜在空间中进行奖励建模，因为它们被明确设计为在任意时间步处理噪声潜在表示，并通过其顺序建模功能本质上保留时间信息。因此，我们提出了过程奖励反馈学习（PRFL），这是一个完全在潜在空间中进行偏好优化的框架，无需 VAE 解码即可在整个去噪链中实现高效的梯度反向传播。大量实验表明，与 RGB ReFL 相比，PRFL 显着提高了与人类偏好的一致性，同时显着减少了内存消耗和训练时间。|[2511.21541](http://arxiv.org/abs/2511.21541)|null|\n",
        "2511.21475": "|**2025-11-26**|**MobileI2V: Fast and High-Resolution Image-to-Video on Mobile Devices**|最近，视频生成取得了快速发展，引起了人们对移动设备上图像到视频（I2V）合成的越来越多的关注。然而，扩散模型的巨大计算复杂性和缓慢的生成速度对资源受限的移动设备上的实时、高分辨率视频生成提出了重大挑战。在这项工作中，我们提出了 MobileI2V，这是一种 270M 轻量级扩散模型，用于在移动设备上实时生成图像到视频。核心在于：（1）我们分析了线性注意力模块和softmax注意力模块在移动设备上的性能，提出了一种平衡生成效率和质量的线性混合架构降噪器。 (2) 我们设计了一种时间步蒸馏策略，将 I2V 采样步骤从 20 多个压缩到只有 2 个，而没有显着的质量损失，从而使生成速度提高了 10 倍。 (3) 我们应用了针对移动设备的注意力优化，使设备上推理期间的注意力操作速度提高了 2 倍。 MobileI2V 首次能够在移动设备上快速生成 720p 图像到视频，其质量可与现有型号相媲美。在一步条件下，720p视频每一帧的生成速度小于100ms。我们的代码位于：https://github.com/hustvl/MobileI2V。|[2511.21475](http://arxiv.org/abs/2511.21475)|null|\n",
        "2511.21375": "|**2025-11-26**|**Thinking With Bounding Boxes: Enhancing Spatio-Temporal Video Grounding via Reinforcement Fine-Tuning**|时空视频基础（STVG）需要根据自然语言描述在时间和空间上定位未修剪视频中的目标对象。尽管多模态大语言模型 (MLLM) 具有很强的语言理解能力，但由于标准视觉编码器中的训练目标不一致和细粒度区域词对齐较弱，因此在 STVG 上表现不佳。为了解决这个问题，我们提出了 STVG-o1，这是第一个使现成的 MLLM 无需任何架构修改即可实现最先进的 STVG 性能的框架。我们的方法引入了一种边界框思想链机制，该机制在产生最终预测之前的中间步骤中明确推理时空位置。我们进一步设计了一个由格式、一致性、时间、空间和思维奖励组成的多维强化奖励函数，它通过强化微调提供几何感知监督。在 HCSTVG-v1/v2 和 VidSTG 上进行评估，STVG-o1 在 HCSTVG 上设置了新的最先进结果，在 HCSTVG-v1 上比最佳特定任务方法高出 7.3\\% m\\_tIoU，匹配 VidSTG 上的专用模型，并大幅超越所有现有的基于 MLLM 的方法。它还展示了跨数据集的强大开放词汇泛化能力，将 MLLM 建立为精确时空基础的可行且强大的支柱。我们的代码和模型将被发布。|[2511.21375](http://arxiv.org/abs/2511.21375)|null|\n",
        "2511.21251": "|**2025-11-26**|**AVFakeBench: A Comprehensive Audio-Video Forgery Detection Benchmark for AV-LMMs**|音频视频 (AV) 伪造的威胁正在迅速演变，超越以人类为中心的深度伪造，包括跨复杂自然场景的更多样化的操作。然而，现有的基准仍然局限于基于 DeepFake 的伪造和单粒度注释，因此无法捕捉现实世界伪造场景的多样性和复杂性。为了解决这个问题，我们推出了 AVFakeBench，这是第一个全面的音频-视频伪造检测基准，涵盖了人类主体和一般主体的丰富伪造语义。 AVFakeBench 包含 12K 个精心策划的音频视频问题，涵盖七种伪造类型和四个级别的注释。为了确保高质量和多样化的伪造，我们提出了一个多阶段混合伪造框架，该框架将用于任务规划的专有模型与用于精确操作的专家生成模型集成在一起。该基准建立了一个涵盖二元判断、伪造类型分类、伪造细节选择和解释推理的多任务评估框架。我们在 AVFakeBench 上评估了 11 种音频视频大语言模型 (AV-LMM) 和 2 种流行的检测方法，展示了 AV-LMM 作为新兴伪造检测器的潜力，同时揭示了它们在细粒度感知和推理方面的显着弱点。|[2511.21251](http://arxiv.org/abs/2511.21251)|null|\n",
        "2511.21146": "|**2025-11-26**|**AV-Edit: Multimodal Generative Sound Effect Editing via Audio-Visual Semantic Joint Control**|音效编辑（通过添加、删除或替换元素来修改音频）仍然受到仅依赖于低级信号处理或粗略文本提示的现有方法的限制，通常会导致灵活性有限和音频质量不佳。为了解决这个问题，我们提出了 AV-Edit，这是一种生成音效编辑框架，可以通过联合利用视觉、音频和文本语义来对视频中现有的音轨进行细粒度编辑。具体来说，所提出的方法采用专门设计的对比视听掩蔽自动编码器（CAV-MAE-Edit）进行多模态预训练，学习对齐的跨模态表示。然后，使用这些表示来训练编辑多模态扩散变压器 (MM-DiT)，该模型能够消除视觉上不相关的声音，并通过基于相关性的特征门控训练策略生成与视频内容一致的缺失音频元素。此外，我们构建了一个专用的基于视频的声音编辑数据集作为评估基准。实验表明，所提出的AV-Edit可以根据视觉内容生成经过精确修改的高质量音频，在音效编辑领域实现了最先进的性能，并在音频生成领域表现出强大的竞争力。|[2511.21146](http://arxiv.org/abs/2511.21146)|null|\n",
        "2511.21145": "|**2025-11-26**|**TEAR: Temporal-aware Automated Red-teaming for Text-to-Video Models**|文本到视频 (T2V) 模型能够合成高质量、时间连贯的动态视频内容，但多样化的生成也固有地带来了关键的安全挑战。现有的安全评估方法侧重于静态图像和文本生成，不足以捕获视频生成中复杂的时间动态。为了解决这个问题，我们提出了一个 TEmporal 感知的自动化红队框架，名为 TEAR，这是一个自动化框架，旨在发现与 T2V 模型的动态时间排序特别相关的安全风险。 TEAR 采用通过两阶段方法优化的时间感知测试生成器：初始生成器训练和时间感知在线偏好学习，以制作文本无害的提示，利用时间动态来引发违反策略的视频输出。并采用细化模型来循环提高即时隐身性和对抗有效性。广泛的实验评估证明了 TEAR 在开源和商业 T2V 系统中的有效性，攻击成功率超过 80%，比之前 57% 的最佳结果有了显着提升。|[2511.21145](http://arxiv.org/abs/2511.21145)|null|\n",
        "2511.21139": "|**2025-11-26**|**Referring Video Object Segmentation with Cross-Modality Proxy Queries**|引用视频对象分割（RVOS）是一种新兴的跨模态任务，旨在生成给定文本表达式引用的目标对象的像素级图。主要概念涉及学习语义空间内视觉元素和语言表达的准确对齐。最近的方法通过条件查询解决跨模态对齐问题，使用基于变压器结构的查询响应机制跟踪目标对象。然而，它们表现出两个局限性：（1）这些条件查询缺乏帧间依赖性和变化建模，使得在帧与帧之间存在显着变化的情况下准确的目标跟踪具有挑战性； (2)它们较晚地集成了文本约束，这可能导致视频特征潜在地集中在未引用的对象上。因此，我们提出了一种名为 ProxyFormer 的新型 RVOS 架构，它引入了一组代理查询来集成视觉和文本语义，并促进它们之间的语义流动。通过在视频特征编码器的多个阶段逐步更新和传播代理查询，ProxyFormer 确保视频特征集中在感兴趣的对象上。这种动态演化还能够建立帧间依赖关系，从而提高对象跟踪的准确性和连贯性。为了减轻高计算成本，我们将跨模态交互解耦到时间和空间维度。此外，我们设计了联合语义一致性（JSC）训练策略，以协调代理查询和组合视频文本对之间的语义共识。对四个广泛使用的 RVOS 基准的综合实验证明了我们的 ProxyFormer 相对于最先进方法的优越性。|[2511.21139](http://arxiv.org/abs/2511.21139)|null|\n",
        "2511.21136": "|**2025-11-26**|**Efficient Training for Human Video Generation with Entropy-Guided Prioritized Progressive Learning**|随着扩散模型的发展，人类视频生成迅速发展，但在高分辨率、多帧数据上训练这些模型所需的高计算成本和大量内存消耗带来了重大挑战。在本文中，我们提出了熵引导优先级渐进学习（Ent-Prog），这是一种专为人类视频生成扩散模型量身定制的高效训练框架。首先，我们引入条件熵膨胀（CEI）来评估不同模型组件对目标条件生成任务的重要性，从而实现对最关键组件的优先训练。其次，我们引入了一种自适应渐进式调度，它通过测量收敛效率来自适应地增加训练期间的计算复杂性。 Ent-Prog 减少了训练时间和 GPU 内存消耗，同时保持了模型性能。跨三个数据集的广泛实验证明了 Ent-Prog 的有效性，在不影响生成性能的情况下实现了高达 2.2$\\times$ 的训练加速和 2.4$\\times$ GPU 内存减少。|[2511.21136](http://arxiv.org/abs/2511.21136)|null|\n",
        "2511.21135": "|**2025-11-26**|**SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation**|遵守社会规范的具体导航仍然是一个开放的研究挑战。我们的 \\textbf{SocialNav} 是具有分层“大脑行动”架构的社交意识导航的基础模型，能够理解高级社会规范并生成低级的、符合社会规范的轨迹。为了实现这种双重功能，我们构建了 SocNav 数据集，这是一个包含 700 万个样本的大规模集合，包括 (1) 认知激活数据集，提供社交推理信号，例如思想链解释和社交可遍历性预测，以及 (2) 专家轨迹金字塔，聚合来自互联网视频、模拟环境和现实世界机器人的各种导航演示。提出了一个多阶段训练管道来逐步注入和完善导航智能：我们首先通过模仿学习将一般导航技能和社会规范理解注入到模型中，然后通过精心设计的社交感知流探索GRPO（SAFE-GRPO）来完善这些技能，这是第一个基于流的实体导航强化学习框架，明确奖励符合社会规范的行为。与最先进的方法相比，SocialNav 实现了 +38% 的成功率和 +46% 的社会合规率，显示出导航性能和社会合规性方面的巨大进步。我们的项目页面：https://amap-eai.github.io/SocialNav/|[2511.21135](http://arxiv.org/abs/2511.21135)|null|\n",
        "2511.21690": "|**2025-11-26**|**TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos**|仅通过少数演示来在新平台和新场景中学习新的机器人任务仍然具有挑战性。虽然其他实施例（人类和不同机器人）的视频很丰富，但实施例、相机和环境的差异阻碍了它们的直接使用。我们通过引入统一的符号表示（场景级轨迹的紧凑 3D“轨迹空间”）来解决小数据问题，从而能够从跨实施例、跨环境和跨任务视频中进行学习。我们提出了 TraceGen，这是一种世界模型，可以预测轨迹空间而不是像素空间中的未来运动，抽象出外观，同时保留操作所需的几何结构。为了大规模训练 TraceGen，我们开发了 TraceForge，这是一种数据管道，可将异构人类和机器人视频转换为一致的 3D 轨迹，生成包含 123K 视频和 180 万个观察轨迹语言三元组的语料库。对该语料库的预训练产生了可有效适应的可转移 3D 运动：仅用五个目标机器人视频，TraceGen 在四项任务中就获得了 80% 的成功，同时提供比最先进的基于视频的世界模型快 50-600 倍的推理速度。在更具挑战性的情况下，只有五个在手持电话上捕获的未校准的人体演示视频可用，它在真实机器人上仍然达到 67.5% 的成功率，这突显了 TraceGen 在不依赖对象探测器或大量像素空间生成的情况下适应不同实施例的能力。|[2511.21690](http://arxiv.org/abs/2511.21690)|null|\n",
        "2511.21592": "|**2025-11-26**|**MoGAN: Improving Motion Quality in Video Diffusion via Few-Step Motion Adversarial Post-Training**|视频扩散模型实现了强大的帧级保真度，但仍难以实现运动连贯性、动态性和真实性，经常产生抖动、重影或令人难以置信的动态。一个关键的限制是标准去噪 MSE 目标不提供对时间一致性的直接监督，从而允许模型实现低损失，同时仍然产生较差的运动。我们提出了 MoGAN，一种以运动为中心的后训练框架，无需奖励模型或人类偏好数据即可提高运动真实感。我们构建在三步蒸馏视频扩散模型之上，训练基于 DiT 的光流鉴别器来区分真实运动和生成运动，并结合分布匹配正则器来保持视觉保真度。通过在 Wan2.1-T2V-1.3B 上进行实验，MoGAN 显着提高了基准测试中的运动质量。在 VBench 上，MoGAN 的运动得分比 50 步教师模型提高了 7.3%，比 3 步 DMD 模型提高了 13.3%。在 VideoJAM-Bench 上，MoGAN 的运动得分比老师提高了 7.4%，比 DMD 提高了 8.8%，同时保持了相当甚至更好的美学和图像质量得分。一项人类研究进一步证实，MoGAN 在运动质量方面更受青睐（教师为 52% vs. 38%；DMD 为 56% vs. 29%）。总体而言，MoGAN 在不牺牲视觉保真度或效率的情况下提供了更加真实的运动，为快速、高质量视频生成提供了一条实用途径。项目网页为：https://xavihart.github.io/mogan。|[2511.21592](http://arxiv.org/abs/2511.21592)|null|\n",
        "2511.22715": "|**2025-11-27**|**ReAG: Reasoning-Augmented Generation for Knowledge-based Visual Question Answering**|多模态大语言模型 (MLLM) 在共同理解文本、图像和视频方面表现出了令人印象深刻的能力，通常通过视觉问答 (VQA) 进行评估。然而，即使是最先进的 MLLM 也难以应对特定领域或知识密集型查询，其中相关信息在预训练数据中的代表性不足。基于知识的 VQA (KB-VQA) 通过检索外部文档来条件回答生成来解决这个问题，但当前的检索增强方法存在精度低、段落噪音大和推理有限的问题。为了解决这个问题，我们提出了 ReAG，这是一种新颖的推理增强多模态 RAG 方法，它将粗粒度和细粒度检索与过滤不相关段落的批评模型相结合，确保高质量的附加上下文。该模型遵循多阶段训练策略，利用强化学习来增强对检索内容的推理，而监督微调仅作为冷启动。 Encyclopedic-VQA 和 InfoSeek 的大量实验表明，ReAG 显着优于先前的方法，提高了答案准确性并提供基于检索到的证据的可解释推理。我们的源代码可公开获取：https://github.com/aimagelab/ReAG。|[2511.22715](http://arxiv.org/abs/2511.22715)|null|\n",
        "2511.22533": "|**2025-11-27**|**Fast3Dcache: Training-free 3D Geometry Synthesis Acceleration**|扩散模型在 2D 图像、视频和 3D 形状等模态中取得了令人印象深刻的生成质量，但由于迭代去噪过程，其推理的计算成本仍然很高。虽然最近基于缓存的方法有效地重用冗余计算来加速 2D 和视频生成，但将这些技术直接应用于 3D 扩散模型可能会严重破坏几何一致性。在 3D 合成中，即使缓存的潜在特征中的微小数值错误也会累积，导致结构伪影和拓扑不一致。为了克服这一限制，我们提出了 Fast3Dcache，这是一种免训练的几何感知缓存框架，可以加速 3D 扩散推理，同时保持几何保真度。我们的方法引入了预测缓存调度器约束（PCSC）来根据体素稳定模式动态确定缓存配额，并引入时空稳定性标准（SSC）来根据速度大小和加速度标准选择稳定特征以供重用。综合实验表明，Fast3Dcache 显着加速了推理，实现了 27.12% 的加速和 54.8% 的 FLOP 减少，并且通过 Chamfer Distance (2.48%) 和 F-Score (1.95%) 衡量的几何质量下降最小。|[2511.22533](http://arxiv.org/abs/2511.22533)|null|\n",
        "2511.22488": "|**2025-11-27**|**AI killed the video star. Audio-driven diffusion model for expressive talking head generation**|我们提出了 Dimitra++，这是一种用于音频驱动头部说话生成的新颖框架，经过简化可以学习嘴唇运动、面部表情以及头部姿势运动。具体来说，我们提出了一种条件运动扩散变换器 (cMDT)，采用 3D 表示来建模面部运动序列。 cMDT 以两个输入为条件：确定外观的参考面部图像，以及驱动运动的音频序列。定量和定性实验以及对两个广泛使用的数据集（即 VoxCeleb2 和 CelebV-HQ）的用户研究表明，Dimitra++ 在生成赋予嘴唇运动、面部表情和头部姿势的真实说话头像方面能够优于现有方法。|[2511.22488](http://arxiv.org/abs/2511.22488)|null|\n",
        "2511.22455": "|**2025-11-27**|**Beyond Real versus Fake Towards Intent-Aware Video Analysis**|生成模型的快速发展导致了越来越真实的深度伪造视频，带来了重大的社会和安全风险。虽然现有的检测方法侧重于区分真视频和假视频，但这些方法无法解决一个基本问题：被操纵的视频背后的意图是什么？为了解决这个问题，我们引入了 IntentHQ：一个以人为中心的意图分析的新基准，将范式从真实性验证转变为视频的上下文理解。 IntentHQ 由 5168 个视频组成，这些视频经过精心收集并注释了 23 个细粒度的意图类别，包括“金融欺诈”、“间接营销”、“政治宣传”以及“散布恐惧”。我们使用监督和自监督的多模态模型进行意图识别，这些模型集成了时空视频特征、音频处理和文本分析，以推断视频背后的潜在动机和目标。我们提出的模型经过简化，可以区分各种意图类别。|[2511.22455](http://arxiv.org/abs/2511.22455)|null|\n",
        "2511.22443": "|**2025-11-27**|**Do You See What I Say? Generalizable Deepfake Detection based on Visual Speech Recognition**|Deepfake 一代已经取得了显着的进步，有助于生成高度逼真的图像、视频和音频。虽然技术上很有趣，但这种进展引起了对滥用受操纵媒体的严重担忧。为了减少这种滥用，迫切需要强大且可靠的深度伪造检测。为此，我们提出了一种新颖的网络 FauxNet，它基于预先训练的视觉语音识别（VSR）功能。通过从视频中提取时间 VSR 特征，我们可以识别真实视频并将其与经过处理的视频分开。在这种情况下，圣杯与零样本检测有关，即可泛化检测，这是我们在这项工作中关注的重点。 FauxNet 在此设置中始终优于最先进的技术。此外，FauxNet 能够区分视频的生成技术。最后，我们提出了新的数据集，称为 Authentica-Vox 和 Authentica-HDTF，总共包含约 38,000 个真实和虚假视频，后者是使用六种最新的 Deepfake 生成技术创建的。我们对 Authentica 数据集和 FaceForensics++ 提供了广泛的分析和结果，证明了 FauxNet 的优越性。 Authentica 数据集将公开。|[2511.22443](http://arxiv.org/abs/2511.22443)|null|\n",
        "2511.22330": "|**2025-11-27**|**Prompt-based Consistent Video Colorization**|现有的视频着色方法难以应对时间闪烁或需要大量的手动输入。我们提出了一种新颖的方法，使用从语言和分割衍生的丰富语义指导来自动进行高保真视频着色。我们采用语言条件扩散模型来对灰度帧进行着色。通过自动生成的对象蒙版和文本提示提供指导；我们的主要自动方法使用通用提示，无需输入特定颜色即可实现最先进的结果。时间稳定性是通过使用光流 (RAFT) 扭曲先前帧的颜色信息来实现的；校正步骤检测并修复由扭曲引起的不一致。对标准基准（DAVIS30、VIDEVO20）的评估表明，我们的方法在着色精度（PSNR）和视觉真实感（色彩度、CDC）方面实现了最先进的性能，证明了基于自动提示的指导对一致视频着色的有效性。|[2511.22330](http://arxiv.org/abs/2511.22330)|null|\n",
        "2511.22287": "|**2025-11-27**|**Match-and-Fuse: Consistent Generation from Unstructured Image Sets**|我们提出了 Match-and-Fuse - 一种零样本、免训练的方法，用于一致控制生成非结构化图像集 - 共享共同视觉元素的集合，但在视点、捕获时间和周围内容方面有所不同。与对单个图像或密集采样视频进行操作的现有方法不同，我们的框架执行集合到集合的生成：给定源集和用户提示，它会生成一个新集合，以保留共享内容的跨图像一致性。我们的关键思想是将任务建模为一个图，其中每个节点对应一个图像，每个边触发图像对的联合生成。这种表述将所有成对的世代整合到一个统一的框架中，增强它们的局部一致性，同时确保整个集合的全局一致性。这是通过在密集输入对应的指导下融合图像对的内部特征来实现的，无需掩模或手动监督。它还允许我们利用文本到图像模型中的新兴先验，当多个视图共享单个画布时，鼓励连贯的生成。 Match-and-Fuse 实现了最先进的一致性和视觉质量，并解锁了从图像集合创建内容的新功能。|[2511.22287](http://arxiv.org/abs/2511.22287)|null|\n",
        "2511.22229": "|**2025-11-27**|**VSpeechLM: A Visual Speech Language Model for Visual Text-to-Speech Task**|视觉文本转语音（VisualTTS）的任务，也称为视频配音，旨在生成与输入视频中的嘴唇运动同步的语音，此外还与输入文本的内容保持一致并克隆参考语音的音色。现有的VisualTTS模型通常采用轻量级架构并设计专门的模块来分别实现上述目标，但由于模型容量和VisualTTS数据有限，语音质量并不令人满意。最近，语音大语言模型（SpeechLLM）显示出生成高质量语音的强大能力。但在如何充分利用视频输入的时间线索来生成口型同步语音方面，还没有做多少工作。为了在 VisualTTS 任务中生成高质量且口型同步的语音，我们提出了一种基于 SpeechLLM 的新型视觉语音语言模型，称为 VSpeechLM。为了捕获文本和视频之间的同步关系，我们提出了一种文本视频对齐器。它首先学习音素和嘴唇运动之间的细粒度对齐，然后输出包含嘴唇同步线索的扩展音素序列。接下来，我们提出的基于 SpeechLLM 的解码器将扩展的音素序列作为输入，并学习生成唇同步语音。大量实验表明，我们的 VSpeechLM 在整体质量、说话者相似度和同步指标方面明显优于以前的 VisualTTS 方法。|[2511.22229](http://arxiv.org/abs/2511.22229)|null|\n",
        "2511.22228": "|**2025-11-27**|**3D-Consistent Multi-View Editing by Diffusion Guidance**|扩散模型的最新进展极大地改进了基于文本的图像编辑，但独立编辑图像的方法通常会在同一场景的不同视图中产生几何和光度不一致的结果。这种不一致对于编辑 NeRF 或 Gaussian Splat 模型等 3D 表示尤其成问题。我们提出了一种免训练的扩散框架，可以在图像编辑过程中强制执行多视图一致性。关键假设是未编辑图像中的对应点在编辑后应该经历类似的变换。为了实现这一目标，我们引入了一致性损失，引导扩散采样进行连贯编辑。该框架非常灵活，可以与广泛不同的图像编辑方法相结合，支持密集和稀疏的多视图编辑设置。实验结果表明，与现有的多视图编辑方法相比，我们的方法显着提高了 3D 一致性。我们还表明，这种增强的一致性可以实现高质量的高斯 Splat 编辑，具有清晰的细节和对用户指定的文本提示的高度保真度。视频结果请参阅我们的项目页面：https://3d-consistent-editing.github.io/|[2511.22228](http://arxiv.org/abs/2511.22228)|null|\n",
        "2511.22189": "|**2025-11-27**|**Department-Specific Security Awareness Campaigns: A Cross-Organizational Study of HR and Accounting**|许多网络攻击之所以成功，是因为它们利用了人类层面的缺陷。为了解决这个问题，组织依靠安全意识计划，旨在提高员工抵御社会工程的能力。虽然一些著作建议此类计划应考虑情境相关性，但研究中的常见做法是采用“一般”观点。例如，之前的用户研究不是关注特定部门的问题，而是寻求提供组织范围内的结论。这样的协议可能会导致忽视仅影响组织的特定子集的漏洞。   在本文中，我们解决了这种疏忽。首先，通过系统的文献综述，我们提供的证据表明，先前的文献未能充分考虑部门的特定需求。然后，我们开展了一项多公司和混合方法的研究，重点关注两个关键部门：人力资源（HR）和会计。我们探讨三个维度：这些部门面临的威胁；向这些部门开展的安全意识活动涵盖的主题；以及最大限度地提高此类活动有效性的交付方法。我们首先采访了一家跨国企业的 16 名员工，然后以这些结果为基础设计了一项结构化调查，通过该调查收集了 9 个组织的 90 多名人力资源/会计成员的回答。我们发现，人力资源部门通过包含恶意软件和高管冒充的求职申请成为攻击目标，而会计部门则面临发票欺诈、凭证盗窃和勒索软件的威胁。目前的培训通常被认为过于通用，员工更喜欢较短的、基于场景的格式，如视频和模拟。这些偏好与年度会议的常见行业惯例相矛盾。根据这些见解，我们提出了设计适合部门需求和工作流程的意识计划的建议。|[2511.22189](http://arxiv.org/abs/2511.22189)|null|\n",
        "2511.23478": "|**2025-11-28**|**Video-R2: Reinforcing Consistent and Grounded Reasoning in Multimodal Language Models**|对动态视觉内容的推理仍然是多模态大语言模型的核心挑战。最近的思维模型为可解释性生成了明确的推理痕迹；然而，他们的推理往往看似令人信服，但逻辑上不一致或缺乏视觉证据。我们通过两个诊断指标来识别和形式化这些问题：思考答案一致性（TAC），它衡量推理和答案之间的一致性，以及视频注意力分数（VAS），它捕捉推理对视觉线索和文本线索的依赖程度。对 11 个视频推理基准的分析表明，当前模型严重依赖语言先验而不是视觉内容。为了解决这个问题，我们提出了一种强化学习方法，可以提高时间精度和推理一致性。我们的方法将时间戳感知监督微调与由新颖的时间对齐奖励（TAR）引导的组相对策略优化（GRPO）相结合。这种双步骤的训练后阶段鼓励时间对齐和因果连贯的视频推理。由此产生的模型 Video R2 在多个基准测试中始终实现了更高的 TAC、VAS 和准确性，这表明时间对齐和推理一致性的改进可以带来更准确、更值得信赖的视频理解。我们的代码、数据集和模型将开源。|[2511.23478](http://arxiv.org/abs/2511.23478)|null|\n",
        "2511.23475": "|**2025-11-28**|**AnyTalker: Scaling Multi-Person Talking Video Generation with Interactivity Refinement**|最近，多人视频生成开始受到重视。虽然一些初步工作已经探索了音频驱动的多人谈话视频生成，但由于多样化多人数据收集的高成本以及通过连贯的交互性驱动多个身份的困难，它们经常面临挑战。为了应对这些挑战，我们提出了 AnyTalker，一个多人生成框架，具有可扩展的多流处理架构。具体来说，我们用一种新颖的身份感知注意力机制扩展了 Diffusion Transformer 的注意力模块，该机制迭代地处理身份音频对，从而允许任意缩放可驾驶的身份。此外，训练多人生成模型需要大量多人数据。我们提出的训练流程仅依赖于单人视频来学习多人说话模式，并仅通过一些真实的多人剪辑来改进交互性。此外，我们提供了一个有针对性的指标和数据集，旨在评估生成的多人视频的自然度和交互性。大量实验表明，AnyTalker 实现了卓越的唇形同步、视觉质量和自然交互性，在数据成本和身份可扩展性之间取得了良好的平衡。|[2511.23475](http://arxiv.org/abs/2511.23475)|null|\n",
        "2511.23429": "|**2025-11-28**|**Hunyuan-GameCraft-2: Instruction-following Interactive Game World Model**|生成世界模型的最新进展在创建开放式游戏环境方面取得了显着进展，从静态场景合成发展到动态交互式模拟。然而，当前的方法仍然受到严格的动作模式和高注释成本的限制，限制了它们对不同的游戏内交互和玩家驱动的动态进行建模的能力。为了应对这些挑战，我们引入了Hunyuan-GameCraft-2，这是一种用于生成游戏世界建模的指令驱动交互的新范式。我们的模型不依赖固定的键盘输入，而是允许用户通过自然语言提示、键盘或鼠标信号来控制游戏视频内容，从而在生成的世界中实现灵活且语义丰富的交互。我们正式定义了交互式视频数据的概念，并开发了一个自动化流程，将大规模、非结构化的文本视频对转换为因果对齐的交互式数据集。我们的模型建立在 14B 图像到视频专家混合 (MoE) 基础模型的基础上，结合了文本驱动的交互注入机制，可对摄像机运动、角色行为和环境动态进行细粒度控制。我们引入了一个以交互为中心的基准测试InterBench，来全面评估交互性能。大量的实验表明，我们的模型生成了时间连贯且有因果关系的交互式游戏视频，这些视频忠实地响应各种自由形式的用户指令，例如“开门”、“拔火把”或“触发爆炸”。|[2511.23429](http://arxiv.org/abs/2511.23429)|null|\n",
        "2511.23428": "|**2025-11-28**|**DisMo: Disentangled Motion Representations for Open-World Motion Transfer**|文本到视频 (T2V) 和图像到视频 (I2V) 模型的最新进展使得能够从简单的文本描述或初始帧创建视觉上引人注目的动态视频。然而，这些模型通常无法提供与内容分离的运动的明确表示，从而限制了它们对内容创建者的适用性。为了解决这一差距，我们提出了 DisMo，这是一种通过图像空间重建目标直接从原始视频数据学习抽象运动表示的新颖范例。我们的表示是通用的并且独立于静态信息，例如外观、对象身份或姿势。这使得开放世界的运动传输成为可能，允许运动在语义上不相关的实体之间传输，而不需要对象对应，甚至在截然不同的类别之间也是如此。与之前的方法不同，之前的方法会权衡运动保真度和即时依从性，过度拟合源结构或偏离所描述的动作，我们的方法将运动语义与外观分离，从而实现准确的传输和忠实的调节。此外，我们的运动表示可以通过轻量级适配器与任何现有的视频生成器相结合，使我们能够轻松地从视频模型的未来进步中受益。我们通过一系列不同的运动转移任务证明了我们方法的有效性。最后，我们表明，学习到的表示非常适合下游运动理解任务，在 Something-Something v2 和 Jester 等基准上的零样本动作分类中，始终优于最先进的视频表示模型（例如 V-JEPA）。项目页面：https://compvis.github.io/DisMo|[2511.23428](http://arxiv.org/abs/2511.23428)|null|\n",
        "2511.23311": "|**2025-11-28**|**Toward Automatic Safe Driving Instruction: A Large-Scale Vision Language Model Approach**|大规模视觉语言模型 (LVLM) 在需要视觉信息的任务（包括对象检测）中展现出先进的功能。这些能力在自动驾驶等各个工业领域具有广阔的应用前景。例如，LVLM 可以对面向道路的摄像机捕获的视频生成面向安全的描述。然而，确保全面的安全需要监控驾驶员所面对的视图以及检测危险事件，例如驾驶时使用手机。因此，处理面向驾驶员和面向道路的摄像头的同步输入的能力是必要的。在本研究中，我们通过构建数据集并评估其在该数据集上的性能来开发模型并研究 LVLM 的功能。我们的实验结果表明，虽然预先训练的 LVLM 的有效性有限，但经过微调的 LVLM 可以生成准确且具有安全意识的驾驶指令。尽管如此，仍然存在一些挑战，特别是在检测视频中微妙或复杂的事件方面。我们的研究结果和错误分析提供了宝贵的见解，有助于改进该领域基于 LVLM 的系统。|[2511.23311](http://arxiv.org/abs/2511.23311)|null|\n",
        "2511.23199": "|**2025-11-28**|**Vision Bridge Transformer at Scale**|我们推出 Vision Bridge Transformer (ViBT)，它是专为条件生成而设计的布朗桥模型的大规模实例。与将噪声转换为数据的传统扩散模型不同，桥模型直接对输入和输出之间的轨迹进行建模，从而创建有效的数据到数据的转换范例。通过将这些模型扩展到 20B 和 1.3B 参数，我们展示了它们在图像和视频翻译任务中的有效性。为了支持这种规模，我们采用了 Transformer 架构，并提出了用于稳健训练的方差稳定速度匹配目标。这些进步共同凸显了扩展桥接模型在基于指令的图像编辑和复杂视频翻译方面的强大功能。|[2511.23199](http://arxiv.org/abs/2511.23199)|null|\n",
        "2511.23191": "|**2025-11-28**|**GeoWorld: Unlocking the Potential of Geometry Models to Facilitate High-Fidelity 3D Scene Generation**|之前利用视频模型生成图像到 3D 场景的作品往往会遇到几何失真和内容模糊的问题。在本文中，我们通过释放几何模型的潜力来革新图像到 3D 场景生成的流程，并展示我们的 GeoWorld。我们建议首先生成连续的视频帧，然后利用几何模型提供全帧几何特征，而不是利用从单帧输入获得的几何信息，该特征包含比先前方法中使用的单帧深度图或相机嵌入更丰富的信息，并使用这些几何特征作为几何条件来辅助视频生成模型。为了增强几何结构的一致性，我们进一步提出了几何对齐损失，为模型提供现实世界的几何约束和几何适应模块，以确保几何特征的有效利用。大量实验表明，我们的 GeoWorld 可以从单个图像和给定的相机轨迹生成高保真 3D 场景，在质量和数量上都优于现有方法。项目页面：https://peaes.github.io/GeoWorld/。|[2511.23191](http://arxiv.org/abs/2511.23191)|null|\n",
        "2511.23172": "|**2025-11-28**|**Fast Multi-view Consistent 3D Editing with Video Priors**|文本驱动的 3D 编辑支持使用文本指令进行用户友好的 3D 对象或场景编辑。由于缺乏多视图一致性先验，现有方法通常采用 2D 生成或编辑模型来单独处理每个视图，然后迭代 2D-3D-2D 更新。然而，这些方法不仅耗时，而且容易产生过度平滑的结果，因为从不同视图收集的不同编辑信号在迭代过程中被平均。在本文中，我们提出基于生成视频先验的 3D 编辑 (ViP3DE)，以利用预训练视频生成模型的时间一致性先验，在单次前向传递中实现多视图一致 3D 编辑。我们的主要见解是在单个编辑视图上调节视频生成模型，以生成其他一致的编辑视图以直接进行 3D 更新，从而绕过迭代编辑范例。由于 3D 更新需要将编辑的视图与特定的相机姿势配对，因此我们建议视频模型进行运动保留噪声混合，以在预定义的相机姿势下生成编辑的视图。此外，我们引入了几何感知去噪，通过将 3D 几何先验集成到视频模型中来进一步增强多视图一致性。大量实验表明，我们提出的 ViP3DE 即使在单次前向传递中也能实现高质量的 3D 编辑结果，在编辑质量和速度方面都显着优于现有方法。|[2511.23172](http://arxiv.org/abs/2511.23172)|null|\n",
        "2511.23146": "|**2025-11-28**|**InstanceV: Instance-Level Video Generation**|文本到视频扩散模型的最新进展使得能够生成以文本描述为条件的高质量视频。然而，大多数现有的文本到视频模型仅依赖于文本条件，缺乏对视频生成的一般细粒度可控性。为了应对这一挑战，我们提出了 InstanceV，这是一种视频生成框架，可实现 i) 实例级控制和 ii) 全局语义一致性。具体来说，借助所提出的实例感知屏蔽交叉注意机制，InstanceV 最大限度地利用额外的实例级基础信息，在指定的空间位置生成正确归因的实例。为了提高整体一致性，我们引入了共享时间步长自适应提示增强模块，该模块以参数有效的方式将本地实例与全局语义连接起来。此外，我们在训练和推理过程中加入了空间感知无条件指导，以减轻小实例的消失。最后，我们提出了一个名为 InstanceBench 的新基准，它将通用视频质量指标与实例感知指标相结合，以便对实例级视频生成进行更全面的评估。大量实验表明，InstanceV 不仅在视频生成方面实现了卓越的实例级可控性，而且在定性和定量评估中的一般质量和实例感知指标方面均优于现有的最先进模型。|[2511.23146](http://arxiv.org/abs/2511.23146)|null|\n",
        "2511.23127": "|**2025-11-28**|**DualCamCtrl: Dual-Branch Diffusion Model for Geometry-Aware Camera-Controlled Video Generation**|本文提出了 DualCamCtrl，一种用于摄像机控制视频生成的新颖的端到端扩散模型。最近的工作通过将相机姿势表示为基于光线的条件来推进这一领域，但它们往往缺乏足够的场景理解和几何意识。 DualCamCtrl 通过引入双分支框架专门针对这一限制，该框架可相互生成相机一致的 RGB 和深度序列。为了协调这两种模式，我们进一步提出了语义引导相互对齐（SIGMA）机制，该机制以语义引导和相互增强的方式执行 RGB 深度融合。这些设计共同使 DualCamCtrl 能够更好地理清外观和几何建模，生成更忠实地遵循指定摄像机轨迹的视频。此外，我们分析并揭示了深度和相机姿势在去噪阶段的独特影响，并进一步证明早期和后期在形成全局结构和细化局部细节方面发挥着互补作用。大量实验表明，DualCamCtrl 实现了更一致的摄像机控制视频生成，与之前的方法相比，摄像机运动误差减少了 40% 以上。我们的项目页面：https://soyouthinkyoucantell.github.io/dualcamctrl\\-page/|[2511.23127](http://arxiv.org/abs/2511.23127)|null|\n",
        "2512.01095": "|**2025-11-30**|**CycliST: A Video Language Model Benchmark for Reasoning on Cyclical State Transitions**|我们提出了 CycliST，这是一个新颖的基准数据集，旨在评估视频语言模型 (VLM) 在循环状态转换上的文本推理能力。 CycliST 通过生成具有对象运动和视觉属性周期性模式的合成的、结构丰富的视频序列来捕获现实世界过程的基本方面。 CycliST 采用分层评估系统，通过循环物体数量、场景杂乱和照明条件的变化逐步增加难度，挑战最先进的时空认知模型。我们对当前最先进的 VLM（开源和专有）进行了广泛的实验，并揭示了它们在推广到线性和轨道运动等循环动力学以及颜色和比例等视觉属性随时间变化的局限性。我们的结果表明，当今的 VLM 很难可靠地检测和利用循环模式，缺乏时间理解的概念，并且无法从场景中提取定量见解，例如运动物体的数量，这凸显了需要解决的重大技术差距。更具体地说，我们发现没有单一模型在性能上始终领先：规模和架构都与结果没有很强的相关性，并且没有模型在所有任务上都取得同样的成功。通过提供有针对性的挑战和全面的评估框架，CycliST 为视觉推理模型铺平了道路，在理解周期模式方面超越了最先进的技术。|[2512.01095](http://arxiv.org/abs/2512.01095)|null|\n",
        "2512.01045": "|**2025-11-30**|**Med-CRAFT: Automated Construction of Interpretable and Multi-Hop Video Workloads via Knowledge Graph Traversal**|高质量、有逻辑注释的视频数据集的稀缺仍然是医学领域推进多模态大型语言模型 (MLLM) 的主要瓶颈。传统的手动注释非常昂贵且不可扩展，而现有的合成方法经常遭受随机幻觉和缺乏逻辑可解释性的困扰。为了应对这些挑战，我们引入了 \\textbf{\\PipelineName}，这是一种新颖的神经符号数据工程框架，它将基准综合形式化为确定性图遍历过程。与黑盒生成方法不同，Med-CRAFT 从原始视频流中提取结构化视觉基元（例如手术器械、解剖边界），并将其实例化为动态时空知识图。通过将查询生成锚定到该图中的有效路径，我们为每个合成的基准项目强制执行严格的思想链 (CoT) 来源。我们实例化该管道以生成 M3-Med-Auto，这是一个大规模医学视频推理基准，展示了细粒度的时间选择性和多跳逻辑复杂性。综合评估表明，我们的自动化管道生成的查询工作负载的复杂性与专家管理的数据集相当。此外，逻辑对齐分析揭示了规定的图形拓扑与最先进的 MLLM 的推理步骤之间的高度相关性，验证了系统将可验证逻辑编码为视觉语言基准的能力。这项工作为关键领域中可扩展、低成本构建稳健的评估协议铺平了道路。|[2512.01045](http://arxiv.org/abs/2512.01045)|null|\n",
        "2512.01031": "|**2025-11-30**|**VLASH: Real-Time VLAs via Future-State-Aware Asynchronous Inference**|视觉-语言-动作模型（VLA）在处理各种机器人任务方面的能力越来越强。然而，它们在现实世界中的部署仍然缓慢且低效：演示视频通常会加速 5-10 倍才能显得流畅，但会出现明显的动作停顿和对环境变化的延迟反应。异步推理提供了一种有前途的解决方案，通过使机器人能够同时执行动作和执行推理来实现连续和低延迟的控制。然而，由于机器人和环境在推理过程中不断发展，预测和执行间隔之间会出现时间错位。这会导致严重的操作不稳定，而现有方法要么会降低准确性，要么会引入运行时开销来缓解这种不稳定。我们提出了 VLASH，这是一种用于 VLA 的通用异步推理框架，可以提供平滑、准确和快速的反应控制，而无需额外的开销或架构更改。 VLASH 通过使用先前生成的动作块向前滚动机器人状态来估计未来的执行时间状态，从而弥合预测和执行之间的差距。实验表明，与同步推理相比，VLASH 实现了高达 2.03 倍的加速，并减少了高达 17.4 倍的反应延迟，同时完全保留了原始精度。此外，它使 VLA 能够处理快速反应、高精度的任务，例如打乒乓球和打地鼠，而传统同步推理无法解决这些问题。代码可在 https://github.com/mit-han-lab/vlash 获取|[2512.01031](http://arxiv.org/abs/2512.01031)|null|\n",
        "2512.00961": "|**2025-11-30**|**Goal-Driven Reward by Video Diffusion Models for Reinforcement Learning**|强化学习（RL）在各个领域取得了显着的成功，但它通常依赖于精心设计的程序奖励函数来指导代理行为。设计这样的奖励函数可能具有挑战性，并且可能无法很好地概括不同的任务。为了解决这一限制，我们利用预训练视频扩散模型中包含的丰富的世界知识为 RL 代理提供目标驱动的奖励信号，而无需专门设计奖励。我们的关键想法是利用在大规模视频数据集上预训练的现成视频扩散模型作为视频级和帧级目标的信息奖励函数。对于视频级奖励，我们首先在特定领域的数据集上微调预训练的视频扩散模型，然后使用其视频编码器来评估代理轨迹的潜在表示与生成的目标视频之间的对齐情况。为了实现更细粒度的目标，我们通过使用 CLIP 从生成的视频中识别最相关的帧（作为目标状态）来得出帧级目标。然后，我们采用学习的前向-后向表示来表示从给定的状态-动作对访问目标状态的概率作为帧级奖励，从而促进更加连贯和目标驱动的轨迹。对各种元世界任务的实验证明了我们方法的有效性。|[2512.00961](http://arxiv.org/abs/2512.00961)|null|\n",
        "2512.00960": "|**2025-11-30**|**Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction**|通用机器人必须从多样化的大规模人机交互（HOI）中学习，才能在现实世界中稳健运行。单目互联网视频提供了几乎无限且随时可用的数据源，捕获了人类活动、物体和环境的无与伦比的多样性。然而，从这些野外视频中准确且可扩展地提取 4D 交互数据仍然是一个重大且尚未解决的挑战。因此，在这项工作中，我们引入了 4DHOISolver，这是一种新颖且高效的优化框架，它通过利用稀疏的人机循环接触点注释来约束不适定的 4D HOI 重建问题，同时保持高时空一致性和物理合理性。利用这个框架，我们引入了 Open4DHOI，这是一个新的大规模 4D HOI 数据集，具有包含 144 个对象类型和 103 个动作的多样化目录。此外，我们通过使基于强化学习的代理能够模仿恢复的运动来证明重建的有效性。然而，现有 3D 基础模型的综合基准表明，自动预测精确的人与物体接触对应关系仍然是一个未解决的问题，这强调了我们的人机循环策略的迫切必要性，同时对社区提出了公开的挑战。数据和代码将在 https://wenboran2002.github.io/open4dhoi/ 公开提供|[2512.00960](http://arxiv.org/abs/2512.00960)|null|\n",
        "2512.00909": "|**2025-11-30**|**TalkingPose: Efficient Face and Gesture Animation with Feedback-guided Diffusion Model**|扩散模型的最新进展显着提高了角色驱动动画的真实性和通用性，使得仅从单个 RGB 图像和一组驾驶姿势即可合成高质量的运动。然而，生成时间连贯的长格式内容仍然具有挑战性。现有方法受到计算和内存限制，因为它们通常在短视频片段上进行训练，因此只能在有限的帧长度上有效执行，并阻碍了它们扩展相干生成的潜力。为了解决这些限制，我们提出了 TalkingPose，这是一种新颖的基于扩散的框架，专门设计用于制作长格式、时间一致的人体上半身动画。 TalkingPose 利用驱动帧精确捕捉富有表现力的面部和手部动作，通过稳定的扩散骨干将这些动作无缝地传输给目标演员。为了确保连续运动并增强时间一致性，我们引入了一种基于图像扩散模型的反馈驱动机制。值得注意的是，这种机制不会产生额外的计算成本或需要二次训练阶段，从而能够生成无限持续时间的动画。此外，我们引入了一个全面的大规模数据集，作为人体上半身动画的新基准。|[2512.00909](http://arxiv.org/abs/2512.00909)|null|\n",
        "2512.00832": "|**2025-11-30**|**PanFlow: Decoupled Motion Control for Panoramic Video Generation**|全景视频生成因其在虚拟现实和沉浸式媒体中的应用而受到越来越多的关注。然而，现有的方法缺乏明确的运动控制，并且难以生成具有大而复杂运动的场景。我们提出了 PanFlow，这是一种利用全景图的球形性质将高动态相机旋转与输入光流条件解耦的新颖方法，从而能够更精确地控制大型动态运动。我们进一步引入球形噪声扭曲策略来促进跨全景边界运动的循环一致性。为了支持有效的训练，我们策划了一个具有帧级姿态和流注释的大规模、运动丰富的全景视频数据集。我们还展示了我们的方法在各种应用中的有效性，包括运动传输和视频编辑。大量实验表明，PanFlow 在运动保真度、视觉质量和时间连贯性方面显着优于现有方法。我们的代码、数据集和模型可在 https://github.com/hengzag/PanFlow 获取。|[2512.00832](http://arxiv.org/abs/2512.00832)|null|\n",
        "2512.00762": "|**2025-11-30**|**Seeing the Wind from a Falling Leaf**|计算机视觉的一个长期目标是对视频中的运动进行建模，而运动背后的表示，即导致物体变形和移动的不可见的物理交互，在很大程度上仍未被探索。在本文中，我们研究如何从视觉观察中恢复看不见的力，例如，通过观察掉落到地面的叶子来估计风场。我们的关键创新是端到端可微逆图形框架，该框架直接对视频中的对象几何形状、物理属性和交互进行联合建模。通过反向传播，我们的方法能够从物体运动中恢复力的表示。我们在合成场景和现实场景中验证了我们的方法，结果证明了其从视频推断合理力场的能力。此外，我们展示了我们的方法的潜在应用，包括基于物理的视频生成和编辑。我们希望我们的方法有助于理解和建模像素背后的物理过程，弥合视觉和物理之间的差距。请在我们的\\href{https://chaoren2357.github.io/seeingthewind/}{项目页面}中查看更多视频结果。|[2512.00762](http://arxiv.org/abs/2512.00762)|null|\n",
        "2512.00677": "|**2025-11-30**|**Dynamic-eDiTor: Training-Free Text-Driven 4D Scene Editing with Multimodal Diffusion Transformer**|4D 表示方面的最新进展，例如 Dynamic NeRF 和 4D Gaussian Splatting (4DGS)，已经实现了动态 4D 场景重建。然而，由于在编辑过程中确保跨空间和时间的多视图和时间一致性的挑战，文本驱动的 4D 场景编辑仍未得到充分探索。现有的研究依赖于独立编辑帧的 2D 扩散模型，通常会导致运动失真、几何漂移和不完整的编辑。我们推出 Dynamic-eDiTor，这是一种利用多模态扩散变压器 (MM-DiT) 和 4DGS 的免训练文本驱动 4D 编辑框架。该机制由用于局部一致的跨视图和时间融合的时空子网格注意（STGA）和用于通过令牌继承和光流引导令牌替换进行全局传播的上下文令牌传播（CTP）组成。这些组件共同使 Dynamic-eDiTor 能够执行无缝、全局一致的多视图视频，无需额外训练，并直接优化预训练的源 4DGS。对多视图视频数据集 DyNeRF 的大量实验表明，我们的方法实现了卓越的编辑保真度以及多视图和时间一致性的先验方法。结果和代码的项目页面：https://di-lee.github.io/dynamic-eDiTor/|[2512.00677](http://arxiv.org/abs/2512.00677)|null|\n",
        "2512.00532": "|**2025-11-29**|**Image Generation as a Visual Planner for Robotic Manipulation**|生成逼真的机器人操作视频是统一具体代理的感知、规划和行动的重要一步。虽然现有的视频扩散模型需要大量特定领域的数据集并且难以泛化，但最近在语言图像语料库上训练的图像生成模型表现出很强的组合性，包括合成时间相干网格图像的能力。这表明即使没有明确的时间建模，也具有类似视频生成的潜在能力。   我们探索这些模型在使用 LoRA 微调进行轻微调整后是否可以充当机器人的视觉规划器。我们提出了一个由两部分组成的框架，其中包括：(1) 文本条件生成，它使用语言指令和第一帧；(2) 轨迹条件生成，它使用 2D 轨迹叠加和相同的初始帧。 Jaco Play 数据集、Bridge V2 和 RT1 数据集上的实验表明，两种模式都能生成与其各自条件相符的平滑、连贯的机器人视频。   我们的研究结果表明，预训练的图像生成器对可转移的时间先验进行编码，并且可以在最少的监督下充当类似视频的机器人规划器。代码发布于\\href{https://github.com/pangye202264690373/Image-Generation-as-a-Visual-Planner-for-Robotic-Manipulation}{https://github.com/pangye202264690373/Image-Generation-as-a-Visual-Planner-for-Robotic-Manipulation}。|[2512.00532](http://arxiv.org/abs/2512.00532)|null|\n"
    },
    "3D": {
        "2511.21564": "|**2025-11-26**|**Large data global well-posedness for the modified Novikov-Veselov system**|修正的诺维科夫-维谢洛夫系统（mNV）是二维空间维度的立方三阶色散演化。它也是完全可集成的，与散焦 Davey-Stewartson II (DS II) 系统属于同一层次结构。   mNV 系统至关重要 $L^2$。前段时间，Schottdorf证明了对于小$L^2$初始数据，mNV方程是全局适定的。在本文中，我们使用逆散射方法来考虑大数据问题。我们的主要结果表明，mNV 系统对于大型 $L^2$ 数据具有全局良好的定位，随着时间的推移，解决方案会分散到 $\\pm \\infty$。证明中具有独立意义的一个关键要素是相关散射变换的新非线性 Gagliardo-Nirenberg 不等式。   作为我们主要结果的副产品，我们还能够在关键的 $\\dot H^{-1} + L^1$ 水平上证明密切相关的 Novikov-Veselov 问题的全局适定性结果，对于一系列可以启发式描述为无孤子的数据。这里我们使用关联的 Miura 图来连接 mNV 和 NV 流。为了表征 Miura 映射的范围，我们证明了另一个独立兴趣的结果，即在二维空间维度的临界情况下 Agmon-Allegretto-Piepenbrink 原理的尖锐、尺度不变形式。|[2511.21564](http://arxiv.org/abs/2511.21564)|null|\n",
        "2511.21508": "|**2025-11-26**|**Metastability in the Dissipative Quantum Rabi Model**|耗散量子拉比模型表现出丰富的非平衡物理特性，包括从正常相到超辐射相的耗散相变。在这项工作中，我们研究了弱自旋弛豫情况下超辐射相的稳定性。我们发现，即使是弱的自旋弛豫也可以将超辐射相转变为超辐射亚稳态相，其中对称破缺态仅在有限时间内稳定。出现这种情况是因为弛豫引起的每次自旋跳跃都会对系统产生强烈的扰动，可能会以有限的概率将系统从对称破缺状态驱动到对称保持鞍点，然后最终弛豫回到对称破缺状态。这种动态过程导致对称破缺态的寿命有限，并恢复稳态的对称性。为了证实这些结果，我们将平均场和累积量展开分析与精确的数值模拟相结合。在有限尺寸系统中分析对称破缺态的寿命，并通过有限尺寸缩放将结论外推到热力学极限。我们的研究结果确立了耗散量子拉比模型中对称破缺态的亚稳态性质，并揭示了耗散相变超出其平衡状态的复杂性。这里揭示的机制可以推广到一类广泛的开放量子系统，突出了平衡相变和稳态相变之间的基本区别。|[2511.21508](http://arxiv.org/abs/2511.21508)|null|\n",
        "2511.21459": "|**2025-11-26**|**Resolution Where It Counts: Hash-based GPU-Accelerated 3D Reconstruction via Variance-Adaptive Voxel Grids**|根据范围数据进行高效且可扩展的 3D 表面重建仍然是计算机图形和视觉领域的核心挑战，特别是在实时和资源受限的场景中。基于固定分辨率体素网格或八叉树等分层结构的传统体积方法常常面临内存效率低下、计算开销大和缺乏 GPU 支持的问题。我们提出了一种新颖的方差自适应、多分辨率体素网格，它根据有符号距离场（SDF）观测值的局部方差动态调整体素大小。与之前依赖递归八叉树结构的多分辨率方法不同，我们的方法利用平面空间哈希表来存储所有体素块，支持恒定时间访问和完全 GPU 并行性。这种设计可实现高内存效率和实时可扩展性。我们进一步演示了我们的表示如何通过高斯泼溅的并行四叉树结构支持 GPU 加速渲染，从而能够有效控制泼溅密度。与固定分辨率基线相比，我们的开源 CUDA/C++ 实现实现了高达 13 倍的加速和 4 倍的内存使用率降低，同时在重建精度方面保持了同等结果，为高性能 3D 重建提供了实用且可扩展的解决方案。|[2511.21459](http://arxiv.org/abs/2511.21459)|null|\n",
        "2511.21439": "|**2025-11-26**|**EvRainDrop: HyperGraph-guided Completion for Effective Frame and Event Stream Aggregation**|事件相机产生空间稀疏但时间密集的异步事件流。主流事件表示学习算法通常使用事件框架、体素或张量作为输入。尽管这些方法取得了显着的进展，但它们难以解决空间稀疏引起的欠采样问题。在本文中，我们提出了一种新颖的超图引导的时空事件流完成机制，该机制通过超图连接不同时间和空间位置的事件标记，并利用上下文信息消息传递来完成这些稀疏事件。所提出的方法可以灵活地将 RGB 标记作为该补全框架内超图中的节点，从而实现基于多模态超图的信息补全。随后，我们通过自注意力聚合不同时间步长的超图节点信息，从而实现多模态特征的有效学习和融合。对单标签和多标签事件分类任务的大量实验充分验证了我们提出的框架的有效性。本文的源代码将在 https://github.com/Event-AHU/EvRainDrop 上发布。|[2511.21439](http://arxiv.org/abs/2511.21439)|null|\n",
        "2511.21409": "|**2025-11-26**|**Knowledge Distillation for Continual Learning of Biomedical Neural Fields**|神经场越来越多地用作（生物）医学成像中的轻量级、连续且可微分的信号表示。然而，与体素网格等离散信号表示不同，神经场不能轻易扩展。由于神经场本质上是神经网络，因此当向模型提供新数据时，由于灾难性遗忘，神经场中表示的先前信号将会退化。这项工作研究了不同神经场方法遭受灾难性遗忘的程度，并提出了缓解这一问题的策略。我们考虑数据逐渐可用的场景，只有最新的数据可用于神经场拟合。在一系列关于心脏电影 MRI 数据的实验中，我们演示了当时空域扩大或表示信号的维度增加时，知识蒸馏如何减轻灾难性遗忘。我们发现灾难性遗忘的数量在很大程度上取决于所使用的神经场模型，而蒸馏可以使神经场中的持续学习成为可能。|[2511.21409](http://arxiv.org/abs/2511.21409)|null|\n",
        "2511.21393": "|**2025-11-26**|**Lopsided HSS Iterative Method and Preconditioner for a class of Complex Symmetric Linear System**|在本研究中，我们提出了不平衡 HSS（LHSS）迭代方法来求解一类复杂对称不定线性方程组。该方法采用交替迭代方案，其中每次迭代都需要求解两个具有对称实系数矩阵的方程组。这种设计旨在减少与复杂算术相关的高计算成本。理论分析表明，收敛速度的上限仅取决于实对称矩阵的最大和最小特征值以及迭代参数。当特征值满足一定条件时，该方法保证任何正迭代参数的收敛性。基于这一见解，我们开发了预处理不平衡 HSS 迭代方法 (PLHSS)。理论结果表明，与原始方法相比，PLHSS 表现出优越的收敛特性。此外，我们还得出了新方法的最佳参数和相应的最佳收敛速度。此外，我们在迭代方法的基础上推导了PLHSS预处理器。预处理矩阵的特征值聚类良好，并且特征向量与特定内积正交。数值实验证明了预处理 GMRES 和 COCG 方法的效率。 LHSS 迭代方法和相关预处理器显示了测试数值示例的网格大小无关和参数不敏感的收敛行为。|[2511.21393](http://arxiv.org/abs/2511.21393)|null|\n",
        "2511.21647": "|**2025-11-26**|**Fast 3D Ultrasound Localization Microscopy via Projection-based Processing Framework**|三维超声定位显微镜 (ULM) 可实现脉管系统的全面可视化，从而提高诊断可靠性。然而，其临床转化仍然具有挑战性，因为全 3D 重建的体素数量呈指数增长，带来了大量的计算需求和大量的后处理时间。在这项基于行列阵列 (RCA) 的 3D 体内猪肾 ULM 研究中，我们重新制定了完整 3D ULM 流程的每个步骤，包括波束形成、杂波过滤、运动估计、微泡分离和定位到一系列计算高效的 2D 操作中，大大减少了要处理的体素数量，同时保持了相当的精度。所提出的框架在单个 RTX A6000 Ada GPU 上在 0.52 秒（采集时间的 70%）内重建以 400 Hz 帧速率采集的每个 0.75 秒整体，覆盖 25*27.4*27.4 mm3 体积，同时保持与传统 3D 处理相当的 ULM 图像质量。从数量上讲，它在密度图之间实现了 0.93 的结构相似性指数 (SSIM)，斜率为 0.93 且 R2 = 0.88 的体素速度一致性，与传统 3D 结果紧密匹配，并首次展示了扫描过程中实时反馈的潜力，这可以提高鲁棒性，减少操作员依赖性并加速临床工作流程。|[2511.21647](http://arxiv.org/abs/2511.21647)|null|\n",
        "2511.21634": "|**2025-11-26**|**Cosmological Probes of Lepton Parity Freeze-in Dark Matter: $ΔN_{\\rm eff}$ & Gravitational Waves**|在中微子质量的规范 I 型跷跷板机制中，称为轻子宇称的剩余对称性：$(-1)^L$ 仍然保留。引入具有均匀轻子宇称的马约拉纳费米子 $S$ 使其自然稳定，使其成为可行的暗物质 (DM) 候选者。轻子宇称奇数单重态标量 $σ$ 的添加允许耦合 $N S σ$，其中 $N$ 是右手中微子。如果$S$没有热化，那么DM遗迹可以通过两种不同的方式产生：(i)对于再加热温度，$T_{\\rm rh}>m_{N}$，主要通过$N$的衰变($N\\rightarrow Sσ$)，以及(ii)对于$T_{\\rm EW}<T_{\\rm rh}\\ll m_{N}$，通过标准模型希格斯($h$)衰变($h\\rightarrow) SS$ 一次循环）。如果$σ-h$四次耦合很大，那么即使$\\langleσ\\rangle=0$，它也可以导致强的一阶电弱相变。或者，如果 $σ-h$ 耦合很小，那么 $σ$ 可以以更大的丰度冻结，因此它在晚期的衰变 ($σ\\rightarrow Sν$) 可以产生额外的相对论自由度 ($Δ{N}_{\\rm eff}$)。因此，该框架提供了一种质量范围从 MeV 到 TeV 不等的可行 DM，并通过引力波和 $Δ{N}_{\\rm eff}$ 留下可观察的印记，这提供了互补的探针，有可能在未来的引力波和 CMB 实验中检测到。|[2511.21634](http://arxiv.org/abs/2511.21634)|null|\n",
        "2511.21633": "|**2025-11-26**|**Bang-Bang Evasion: Its Stochastic Optimality and a Terminal-Set-Based Implementation**|我们解决了平面残局交战中的最佳规避问题，其中具有有限横向加速度的目标试图避免被线性反馈定律引导的导弹拦截。与假设完美信息或在随机设置中使用启发式操作模型的现有方法相反，我们在涉及不完美信息和有界控制的固有随机框架中制定问题。遵循广义分离定理，控制律影响状态的后验分布。将确定性环境中众所周知的爆炸式规避策略的最优性扩展到现实的随机规避场景领域，我们首先证明最优规避策略始终存在，并且最优解集至少包含一个爆炸式策略，从而使所得最优控制问题成为有限维。利用这种结构，我们其次提出了基于闭环终端集的规避（TSE）策略，并证明了其在针对比例导航追踪器的模拟中的有效性。蒙特卡罗模拟表明，TSE 策略优于基于随机电报、Singer 和编织模型的传统随机规避策略。|[2511.21633](http://arxiv.org/abs/2511.21633)|null|\n",
        "2511.21565": "|**2025-11-26**|**UAVLight: A Benchmark for Illumination-Robust 3D Reconstruction in Unmanned Aerial Vehicle (UAV) Scenes**|照明不一致是多视图 3D 重建中的一个基本挑战。阳光方向、云层和阴影的变化打破了经典多视图立体 (MVS) 和运动结构 (SfM) 管道以及最新神经渲染方法背后的恒定照明假设，导致几何漂移、颜色不一致和阴影印记。这个问题在基于无人机的重建中尤其重要，因为长时间的飞行时间和室外环境使得照明变化不可避免。然而，现有的数据集要么将捕获限制在短时间窗口内，因此缺乏有意义的照明多样性，要么跨越数月和季节，其中几何和语义的变化混淆了照明鲁棒性的孤立研究。我们推出了 UAVLight，这是一种用于光照鲁棒 3D 重建的受控但真实的基准。每个场景都是在一天中的多个固定时间沿着可重复的、地理参考的飞行路径捕获的，在一致的几何形状、校准和视点下产生自然光照变化。通过跨照明条件的标准化评估协议，UAVLight 为开发和基准测试重建方法提供了可靠的基础，这些重建方法在真实的室外环境中是一致的、忠实的和可重新照明的。|[2511.21565](http://arxiv.org/abs/2511.21565)|null|\n",
        "2511.22704": "|**2025-11-27**|**Splat-SAP: Feed-Forward Gaussian Splatting for Human-Centered Scene with Scale-Aware Point Map Reconstruction**|我们提出了 Splat-SAP，这是一种前馈方法，可以从具有大稀疏性的双目相机中渲染以人为中心的场景的新颖视图。高斯泼溅在渲染任务中显示出了其巨大的潜力，但它通常需要使用密集的输入视图进行每个场景的优化。尽管最近的一些方法通过多视图立体获得的几何先验实现了前馈高斯泼溅渲染，但这些方法仍然需要大量重叠的输入视图来建立几何先验。为了弥补这一差距，我们利用像素级点图重建来表示几何形状，该几何形状对于独立视图建模的大稀疏性具有鲁棒性。一般来说，我们提出一个两阶段的学习策略。在第一阶段，我们通过迭代亲和力学习过程将点图转换为真实空间，这有利于接下来的相机控制。在第 2 阶段，我们将两个输入视图的点图投影到目标视图平面上，并通过立体匹配细化此类几何形状。此外，我们将高斯基元锚定在这个精致的平面上，以渲染高质量的图像。作为度量表示，第 1 阶段中的比例感知点图以自监督方式进行训练，无需 3D 监督，第 2 阶段则通过光度损失进行监督。我们收集了以人为中心的多视图数据，并证明我们的方法提高了点图重建的稳定性和自由视点渲染的视觉质量。|[2511.22704](http://arxiv.org/abs/2511.22704)|null|\n",
        "2511.22699": "|**2025-11-27**|**Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer**|高性能图像生成模型目前由 Nano Banana Pro 和 Seedream 4.0 等专有系统主导。领先的开源替代方案，包括 Qwen-Image、Hunyuan-Image-3.0 和 FLUX.2，其特点是参数数量庞大（20B 到 80B），这使得它们对于消费级硬件的推理和微调来说不切实际。为了解决这一差距，我们提出了 Z-Image，这是一种基于可扩展单流扩散变压器 (S3-DiT) 架构的高效 6B 参数基础生成模型，挑战了“不惜一切代价扩展”范式。通过系统地优化整个模型生命周期（从精心策划的数据基础设施到简化的培训课程），我们仅用 314K H800 GPU 小时（约 63 万美元）就完成了完整的培训工作流程。我们的带有奖励后训练的几步蒸馏方案进一步产生了 Z-Image-Turbo，在企业级 H800 GPU 上提供亚秒级推理延迟，并与消费级硬件（<16GB VRAM）兼容。此外，我们的全方位预训练范例还可以对 Z-Image-Edit 进行高效训练，Z-Image-Edit 是一种具有令人印象深刻的指令跟踪功能的编辑模型。定性和定量实验都表明，我们的模型在各个方面都达到了与领先竞争对手相当或超过的性能。最值得注意的是，Z-Image 在真实感图像生成和双语文本渲染方面表现出卓越的能力，提供的结果可与顶级商业模型相媲美，从而证明可以在显着降低计算开销的情况下实现最先进的结果。我们公开发布我们的代码、权重和在线演示，以促进可访问、预算友好且最先进的生成模型的开发。|[2511.22699](http://arxiv.org/abs/2511.22699)|null|\n",
        "2511.22690": "|**2025-11-27**|**Ar2Can: An Architect and an Artist Leveraging a Canvas for Multi-Human Generation**|尽管最近在文本到图像生成方面取得了进展，但现有模型始终无法生成可靠的多人场景，经常会复制面孔、合并身份或错误计数个体。我们提出了 Ar2Can，这是一个新颖的两阶段框架，它将空间规划与多人生成的身份渲染分开。架构师模块预测结构化布局，指定每个人应该出现的位置。然后，Artist 模块在结合了匈牙利空间对齐和 ArcFace 身份相似性的基于空间的人脸匹配奖励的指导下，合成逼真的图像。这种方法确保面部在正确的位置渲染并忠实地保留参考身份。我们开发了两种 Architect 变体，与基于扩散的 Artist 模型无缝集成，并通过组相对策略优化 (GRPO) 进行优化，使用组合奖励来实现计数准确性、图像质量和身份匹配。在 MultiHuman-Testbench 上进行评估，Ar2Can 在计数准确性和身份保存方面取得了显着改进，同时保持了较高的感知质量。值得注意的是，我们的方法主要使用合成数据来实现这些结果，而不需要真实的多人图像。|[2511.22690](http://arxiv.org/abs/2511.22690)|null|\n",
        "2511.22680": "|**2025-11-27**|**Integrated polarization-entangled photon source for wavelength-multiplexed quantum networks**|纠缠光子是量子通信、计算和网络的基本资源。其中，偏振纠缠光子对因其直接的状态操纵和直接用于量子密钥分发、隐形传态和网络协议而发挥着重要作用。然而，实现紧凑、高效、可扩展且满足实际部署要求的偏振纠缠源仍然是一个重大挑战。在这里，我们提出了一种简单但高性能的薄膜铌酸锂（TFLN）片上偏振纠缠光子对源。我们的器件采用双准相位匹配 (D-QPM)，可在单个纳米光子波导中顺序支持 0 型和 I 型自发参数下转换，从而无需干涉仪、偏振旋转器或其他复杂电路。该源直接产生高保真贝尔态，具有宽带宽、高亮度、低噪声。利用这个集成平台，我们在部署在长达 50 公里的城域光纤链路上的四用户量子网络中实现了波长复用纠缠分布。这些结果为基于集成光子学的实用量子通信系统和多用户量子网状网络建立了一条稳健且可扩展的途径。|[2511.22680](http://arxiv.org/abs/2511.22680)|null|\n",
        "2511.22628": "|**2025-11-27**|**Piecewise polynomial approximation on non-Lipschitz domains**|我们证明了非 Lipschitz 域的非 Lipschitz 网格上分数 Sobolev 空间中不连续分段多项式逼近的最佳逼近误差估计。特别地，域的边界和网格元素的边界可以是分形的。|[2511.22628](http://arxiv.org/abs/2511.22628)|null|\n",
        "2511.22578": "|**2025-11-27**|**Text Condition Embedded Regression Network for Automated Dental Abutment Design**|基台是人工种植牙的重要组成部分，其设计过程耗时耗力。长期使用不合适的牙种植体基台可能会导致种植体并发症，包括种植体周围炎。利用人工智能辅助种植牙基台设计，可以快速提高基台设计效率，增强基台适应性。在本文中，我们提出了一种文本条件嵌入式基台设计框架（TCEAD），这是文献中可用的新颖的自动化基台设计解决方案。该研究通过引入文本引导定位（TGL）模块来促进邻接区域定位，从而扩展了网格掩模自动编码器（MeshMAE）的自监督学习框架。由于基台的参数确定很大程度上依赖于局部细粒度特征（种植体的宽度和高度以及到对牙的距离），因此我们使用口腔扫描数据对编码器进行预训练，以提高模型的特征提取能力。此外，考虑到基台区域仅占口腔扫描数据的一小部分，我们设计了TGL模块，通过对比语言-图像预训练（CLIP）的文本编码器引入基台区域的描述，使网络能够快速定位基台区域。我们在大型基台设计数据集上验证了 TCEAD 的性能。大量实验表明，与其他主流方法相比，TCEAD 的交并比 (IoU) 提高了 0.8%-12.85%，凸显了其在自动化牙基台设计中的潜力。|[2511.22578](http://arxiv.org/abs/2511.22578)|null|\n",
        "2511.22562": "|**2025-11-27**|**Making an oriented graph acyclic using inversions of bounded or prescribed size**|给定一个有向图 $D$，顶点子集 $X$ 的反转包括反转两个端点都在 $X$ 中的所有弧的方向。当子集 $X$ 的大小为 $p$（或至多 $p$）时，此操作称为 $(=p)$-inversion（或 $(\\leq p)$-inversion）。那么，如果一个有向图可以通过一系列 $p$-反转而变成非循环，那么它就是 $(=p)$-可逆的。我们观察到，对于 $n=|V(D)|$，判断 $D$ 是否是 $(=n-1)$ 可逆相当于判断 $D$ 是否是非循环可推的，因此是 NP 完全的。在所有其他情况下，当 $p \\neq n-1$ 时，我们构造一个多项式时间算法来决定 $(=p)$-可逆性。   然后，我们考虑$(= p)$-反转数，$\\text{inv}^{= p}(D)$（分别为$(\\leq p)$-反转数，$\\text{inv}^{\\leq p}(D)$），定义为$(=p)$-反转数（分别为$(\\leq p)$-反转数），呈现$D$非循环。我们证明，对于每个整数 $p\\geq 2$，每个 $(=p)$ 可逆有向图 $D$ 都满足 $\\text{inv}^{= p}(D) \\leq |A(D)|$。当 $p$ 为偶数时，我们将 $\\text{inv}^{= p}$ 通过反馈弧集数的（线性）函数绑定，并排除奇数 $p$ 的任何绑定函数的存在。   最后，我们研究了确定给定有向图的 $(= p)$ 反转数或 $(\\leq p)$ 反转数是否至多为给定整数 $k$ 的复杂性。对于任何固定正整数 $p \\geq 2$，当 $k$ 是输入的一部分时，我们表明即使在锦标赛中，这两个问题也是 NP 困难的。在一般面向图中，当由 $p$ 参数化时，我们证明了两个问题的 $W[1]$ 硬度，即使 $k=1$ 也是如此。相比之下，我们在锦标赛中的两个问题上都展示了 $p + k$ 中的多项式内核。|[2511.22562](http://arxiv.org/abs/2511.22562)|null|\n",
        "2511.22553": "|**2025-11-27**|**Bringing Your Portrait to 3D Presence**|我们提出了一个统一的框架，用于根据头部、半身和全身输入的单个肖像重建可动画的 3D 人体化身。我们的方法解决了三个瓶颈：姿势和帧敏感的特征表示、有限的可扩展数据和不可靠的代理网格估计。我们引入了双 UV 表示，通过 Core-UV 和 Shell-UV 分支将图像特征映射到规范 UV 空间，从而消除姿势和框架引起的标记偏移。我们还构建了一个分解的合成数据流形，将 2D 生成多样性与几何一致的 3D 渲染相结合，并由提高真实性和身份一致性的训练方案支持。强大的代理网格跟踪器可在部分可见性下保持稳定性。这些组件共同实现了强大的野外泛化能力。我们的模型仅在半身合成数据上进行训练，实现了最先进的头部和上半身重建以及具有竞争力的全身结果。大量的实验和分析进一步验证了我们方法的有效性。|[2511.22553](http://arxiv.org/abs/2511.22553)|null|\n",
        "2511.22533": "|**2025-11-27**|**Fast3Dcache: Training-free 3D Geometry Synthesis Acceleration**|扩散模型在 2D 图像、视频和 3D 形状等模态中取得了令人印象深刻的生成质量，但由于迭代去噪过程，其推理的计算成本仍然很高。虽然最近基于缓存的方法有效地重用冗余计算来加速 2D 和视频生成，但将这些技术直接应用于 3D 扩散模型可能会严重破坏几何一致性。在 3D 合成中，即使缓存的潜在特征中的微小数值错误也会累积，导致结构伪影和拓扑不一致。为了克服这一限制，我们提出了 Fast3Dcache，这是一种免训练的几何感知缓存框架，可以加速 3D 扩散推理，同时保持几何保真度。我们的方法引入了预测缓存调度器约束（PCSC）来根据体素稳定模式动态确定缓存配额，并引入时空稳定性标准（SSC）来根据速度大小和加速度标准选择稳定特征以供重用。综合实验表明，Fast3Dcache 显着加速了推理，实现了 27.12% 的加速和 54.8% 的 FLOP 减少，并且通过 Chamfer Distance (2.48%) 和 F-Score (1.95%) 衡量的几何质量下降最小。|[2511.22533](http://arxiv.org/abs/2511.22533)|null|\n",
        "2511.22474": "|**2025-11-27**|**Day in the Life of RIPE Atlas: Operational Insights and Applications in Network Measurements**|网络测量平台因其分布式特性而越来越受到研究人员和运营商的欢迎，简化了互联网远程部分的测量。 RIPE Atlas 在全球 178 个国家/地区拥有超过 12,900 个有利位置，是分析选播部署、网络延迟和拓扑等的重要工具。尽管每天生成超过 TB 的测量结果，但对底层过程的了解仍然有限。本文深入研究了 RIPE Atlas 生命周期中的一天，包含 50,900 个独特的测量结果和超过 13 亿个结果。虽然大多数日常测量都是用户定义的，但内置和锚定网格占据了生成结果的 89%。我们广泛研究不同的探测和测量如何影响 RIPE Atlas 的日常运营，并考虑它们可能引入的任何偏差。此外，我们还演示了如何利用现有测量来调查审查、跟踪路由对称性以及保留地址块的使用等。最后，我们为使用 RIPE Atlas 平台的研究人员提出了一系列建议，以提高透明度、可重复性和道德规范。|[2511.22474](http://arxiv.org/abs/2511.22474)|null|\n",
        "2511.23278": "|**2025-11-28**|**RetryGuard: Preventing Self-Inflicted Retry Storms in Cloud Microservices Applications**|现代云应用程序构建在独立、多样化的微服务之上，提供可扩展性、灵活性和基于使用情况的计费。然而，这些不同服务的结构设计，以及它们对动态互联网流量的自动缩放器的依赖，带来了重大的协调挑战。正如我们在本文中所演示的，不一致的服务之间使用的常见默认重试模式可能会变成重试风暴，从而提高资源使用率和成本，从而导致自我造成的拒绝钱包 (DoW) 场景。为了克服这些问题，我们引入了 RetryGuard，这是一个分布式框架，用于跨相互依赖的微服务对重试模式进行高效控制。通过按服务管理重试策略并做出并行决策，RetryGuard 可防止重试风暴、抑制资源争用并降低不断上升的运营成本。 RetryGuard 根据分析模型做出决策，该模型捕获重试、吞吐量（拒绝）、延迟和成本之间的关系。实验结果表明，与 AWS 标准和高级重试策略相比，RetryGuard 显着降低了资源使用量和成本。我们通过 Istio 服务网格在更复杂的 Kubernetes 部署中进一步展示了其可扩展性和卓越性能，并实现了实质性改进。|[2511.23278](http://arxiv.org/abs/2511.23278)|null|\n",
        "2511.23252": "|**2025-11-28**|**One-Shot Secure Aggregation: A Hybrid Cryptographic Protocol for Private Federated Learning in IoT**|联邦学习 (FL) 提供了一种很有前途的方法来协作训练机器学习模型，而无需集中原始数据，但其可扩展性往往受到过多通信开销的限制。这一挑战在物联网 (IoT) 环境中更加严重，其中设备面临严格的带宽、延迟和能源限制。传统的安全聚合协议虽然对于保护模型更新至关重要，但经常需要多次交互、较大的有效负载大小以及每个客户端的成本，这使得它们对于许多边缘部署来说不切实际。   在这项工作中，我们提出了 Hyb-Agg，一种轻量级且通信高效的安全聚合协议，它将多密钥 CKKS (MK-CKKS) 同态加密与基于椭圆曲线 Diffie-Hellman (ECDH) 的附加掩码集成在一起。 Hyb-Agg 将安全聚合过程简化为每轮一次、非交互式客户端到服务器传输，确保每个客户端通信保持恒定，无论参与者数量如何。这种设计消除了部分解密交换，在 RLWE、CDH 和随机预言机假设下保留了强大的隐私性，并保持了针对服务器和最多 $N-2$ 客户端串通的鲁棒性。   我们在高性能和资源受限的设备（包括 Raspberry Pi 4）上实施和评估 Hyb-Agg，证明它可以提供亚秒级执行时间，同时实现比明文大小约 12 倍的恒定通信扩展系数。通过直接解决通信瓶颈，Hyb-Agg 实现了可扩展、保护隐私的联合学习，这对于现实世界的物联网部署来说是实用的。|[2511.23252](http://arxiv.org/abs/2511.23252)|null|\n",
        "2511.23241": "|**2025-11-28**|**Synthetic Industrial Object Detection: GenAI vs. Feature-Based Methods**|减少数据生成和注释的负担仍然是在工业和机器人环境中经济高效地部署机器学习的主要挑战。虽然合成渲染是一种很有前途的解决方案，但弥合模拟与真实之间的差距通常需要专家干预。在这项工作中，我们对一系列域随机化 (DR) 和域适应 (DA) 技术进行了基准测试，包括基于特征的方法、生成式 AI (GenAI) 和经典渲染方法，用于创建上下文化的合成数据，而无需手动注释。我们的评估重点是低级和高级特征对齐的有效性和效率，以及由现实世界环境生成的提示引导的基于受控扩散的 DA 方法。我们在两个数据集上验证我们的方法：专有工业数据集（汽车和物流）和公共机器人数据集。结果表明，如果具有足够可变性的基于渲染的数据可用作种子，则基于更简单的特征的方法（例如基于亮度和感知哈希过滤）在准确性和资源效率方面都优于更复杂的基于 GenAI 的方法。感知哈希始终实现最高性能，在工业和机器人数据集上的 mAP50 分数分别为 98% 和 67%。此外，与更简单的方法相比，GenAI 方法在数据生成方面存在大量时间开销，但模拟到真实 mAP 值没有明显改善。我们的研究结果提供了可操作的见解，可以有效地弥合模拟与真实的差距，从而使专门基于合成数据训练的模型能够在现实世界中获得较高的性能。|[2511.23241](http://arxiv.org/abs/2511.23241)|null|\n",
        "2511.23227": "|**2025-11-28**|**PointCNN++: Performant Convolution on Native Points**|现有的 3D 点云数据卷积学习方法分为两种范式：基于点的方法，可以保留几何精度，但经常面临性能挑战；基于体素的方法，通过量化来实现高效率，但以几何保真度为代价。这种精度损失是点云配准等任务的关键瓶颈。我们提出了 PointCNN++，这是一种新颖的架构设计，可以从根本上缓解这种精度与性能之间的权衡。它将稀疏卷积从体素推广到点}，将基于体素的卷积视为我们更通用的基于点的卷积的一种特殊的、退化的情况。首先，我们引入以点为中心的卷积，其中感受野以原始的高精度点坐标为中心。其次，为了使这种高保真操作具有高性能，我们设计了一种在点上本地操作 \\textbf{native} 的计算策略。我们将本机点上的卷积表述为矩阵向量乘法和约简 (MVMR) 问题，为此我们开发了专用的、高度优化的 GPU 内核。实验表明，PointCNN++ \\textbf{使用的内存少一个数量级，并且速度比代表性的基于点的方法快几倍}。此外，当用作其概括的基于体素的主干的简单替代时，它 \\textbf{显着提高了点云配准精度，同时证明更节省内存且速度更快}。 PointCNN++ 表明，保留几何细节和实现高性能并不相互排斥，这为新型高保真度和高效的 3D 学习铺平了道路。我们的代码将开源。|[2511.23227](http://arxiv.org/abs/2511.23227)|null|\n",
        "2511.23221": "|**2025-11-28**|**Robust 3DGS-based SLAM via Adaptive Kernel Smoothing**|在本文中，我们挑战了 3DGS-SLAM 中的传统观念，即渲染质量是跟踪精度的主要决定因素。我们认为，与仅仅追求完美的场景表示相比，增强光栅化过程对参数错误的鲁棒性以确保稳定的相机姿态跟踪更为重要。为了应对这一挑战，我们提出了一种新颖的方法，利用平滑的内核策略来增强基于 3DGS 的 SLAM 的鲁棒性。与仅专注于最小化渲染错误的传统方法不同，我们的核心见解是使光栅化过程更能适应 3DGS 参数中的缺陷。我们假设，通过允许每个高斯在渲染过程中影响更平滑、更广泛的像素分布，我们可以减轻异常高斯参数噪声的有害影响。这种方法有意向渲染图像引入受控模糊，充当正则化项，稳定后续的姿态优化。虽然完全重新设计光栅化管道是一种理想的解决方案，但我们提出了一种实用且有效的替代方案，可以轻松集成到现有的 3DGS 框架中。我们的方法称为校正模糊 KNN (CB-KNN)，自适应修改局部区域内 K 最近邻高斯的 RGB 值和位置。这种动态调整会产生更平滑的局部渲染，减少错误的 GS 参数对整体图像的影响。实验结果表明，我们的方法在保持场景重建（映射）整体质量的同时，显着提高了相机姿态跟踪的鲁棒性和准确性。|[2511.23221](http://arxiv.org/abs/2511.23221)|null|\n",
        "2511.23450": "|**2025-11-28**|**Object-Centric Data Synthesis for Category-level Object Detection**|对象检测的深度学习方法已经实现了图像中特定对象类别的可靠检测。然而，将模型的检测能力扩展到新的对象类需要大量带注释的训练数据，获取这些数据既昂贵又耗时，特别是对于现有数据集中表示不足的长尾类。在这里，我们介绍了以对象为中心的数据设置，当以对象为中心的数据（多视图图像或3D模型）的形式提供有限的数据时，并系统地评估四种不同的数据合成方法的性能，以在此设置中微调新对象类别的对象检测模型。这些方法基于简单的图像处理技术、3D 渲染和图像扩散模型，并使用以对象为中心的数据来合成具有不同上下文连贯性和复杂性的真实、杂乱的图像。我们评估这些方法如何使模型能够在现实世界数据中实现类别级泛化，并在数据受限的实验环境中展示显着的性能提升。|[2511.23450](http://arxiv.org/abs/2511.23450)|null|\n",
        "2511.23412": "|**2025-11-28**|**LR B-spline perspective for RM B-splines: construction and effortless refinements**|最近引入了可达最小支持 (RM) B 样条作为一种新颖的类 B 样条基础。它们具有局部线性独立性，并采用类似 de Boor 的快速评估算法。这些特性使它们对于等几何分析的应用特别有吸引力。在本文中，我们表明，通过观察 RM B 样条是局部细化 (LR) B 样条的特殊情况，可以轻松建立自动网格细化程序。|[2511.23412](http://arxiv.org/abs/2511.23412)|null|\n",
        "2511.23369": "|**2025-11-28**|**SimScale: Learning to Drive via Real-World Simulation at Scale**|实现完全自动驾驶系统需要在各种场景中学习理性决策，包括安全关键场景和非分布场景。然而，此类案例在人类专家收集的现实世界语料库中代表性不足。为了弥补数据多样性的不足，我们引入了一种新颖且可扩展的模拟框架，能够根据现有的驾驶日志合成大量未见的状态。我们的管道利用先进的神经渲染和反应环境来生成由扰动的自我轨迹控制的高保真多视图观察。此外，我们为这些新模拟的状态开发了一种伪专家轨迹生成机制，以提供动作监督。根据合成数据，我们发现对现实世界和模拟样本的简单协同训练策略可以显着提高各种规划方法在具有挑战性的现实世界基准上的鲁棒性和泛化性，在 navhard 上高达 +6.8 EPDMS，在 navtest 上高达 +2.9。更重要的是，即使没有额外的现实世界数据流，这种策略改进也可以通过仅增加模拟数据来顺利扩展。我们进一步揭示了这种模拟真实学习系统（我们称之为 SimScale）的几个关键发现，包括伪专家的设计和不同策略架构的扩展属性。我们的模拟数据和代码将被发布。|[2511.23369](http://arxiv.org/abs/2511.23369)|null|\n",
        "2511.23331": "|**2025-11-28**|**Optimization and application of ultra-high field preclinical high-resolution and 3D 1H-MRSI using compressed sensing**|超高场质子磁共振波谱成像 (1H-MRSI) 在临床前领域的使用有所增加。与啮齿动物大脑中采集时间长和脑代谢物浓度低相关的挑战导致了 3D-1H-MRSI 加速方案的开发和应用，例如欠采样技术压缩感知 (CS)。本研究旨在在临床前体内应用的背景下探索 CS 工具，以便在平面内增加的 2D 和通过平面的 3D/多切片采集中实现高分辨率 MRSI 采集。我们对参数进行了探索，以实现尽可能最高的加速度，从而使 3D 尽可能节省时间。参数研究的结果表明，如果 k 空间中心的核心采样尺寸正确，则加速因子 (AF) 可以达到 4。通过这个特定的集合，使用 2D-FID-MRSI 探索了导致亚 1 μL 标称体素大小的更高矩阵尺寸，并添加了 9 个补充相位编码/切片以实现 3D-FID-MRSI。与感兴趣切片内的非加速 2D-FID-MRSI 相比，光谱质量和代谢图足够准确。在 CS 的不同使用过程中，我们注意到与点扩散函数 (PSF) 相关的问题。我们的工作提出了一种强大而有效的协议，可以使用 CS 实现 3D-1H-MRSI，从而以最小的技术限制和高质量的采集达到低于 30 分钟的采集时间。|[2511.23331](http://arxiv.org/abs/2511.23331)|null|\n",
        "2511.23292": "|**2025-11-28**|**FACT-GS: Frequency-Aligned Complexity-Aware Texture Reparameterization for 2D Gaussian Splatting**|高斯泼溅技术使逼真的场景外观建模得到了迅速发展，从而实现了实时、高质量的渲染。最近的进展引入了每基元纹理，将空间颜色变化纳入每个高斯，提高了它们的表现力。然而，基于纹理的高斯使用统一的每高斯采样网格对外观进行参数化，无论局部视觉复杂性如何，都分配相等的采样密度。这导致纹理空间利用率低下，高频区域采样不足，平滑区域浪费容量，导致外观模糊并丢失精细结构细节。我们介绍 FACT-GS，一种频率对齐复杂性感知纹理高斯分布框架，可根据局部视觉频率分配纹理采样密度。基于自适应采样理论，FACT-GS 将纹理参数化重新表述为可微的采样密度分配问题，用可学习的频率感知分配策略取代均匀纹理，该策略通过雅可比行列式调制局部采样密度的变形场实现。 FACT-GS 基于 2D 高斯分布，在固定分辨率纹理网格上执行非均匀采样，在保持实时性能的同时，在相同的参数预算下恢复更清晰的高频细节。|[2511.23292](http://arxiv.org/abs/2511.23292)|null|\n",
        "2512.01103": "|**2025-11-30**|**Learning Eigenstructures of Unstructured Data Manifolds**|我们引入了一种新颖的框架，可以直接从非结构化数据中学习形状和流形分析的谱基础，从而消除了对传统算子选择、离散化和特征求解器的需要。基于最优逼近理论，我们训练一个网络，通过在选定的探测函数分布上最小化学习基础中的重构误差来分解隐式逼近算子。对于合适的分布，它们可以被视为拉普拉斯算子及其特征分解的近似，这是几何处理的基础。此外，我们的方法不仅以统一的方式恢复谱基础，而且还恢复隐式度量的采样密度和基础算子的特征值。值得注意的是，我们的无监督方法不对数据流形做出任何假设，例如网格划分或流形维度，从而使其能够扩展到任何维度的任意数据集。在 3D 和高维图像流形表面上的点云上，我们的方法产生有意义的光谱基础，可以类似于拉普拉斯算子的光谱基础，而无需显式构造算子。通过用基于学习的方法取代传统的算子选择、构造和特征分解，我们的框架为传统管道提供了一种有原则的、数据驱动的替代方案。这为非结构化数据的几何处理开辟了新的可能性，特别是在高维空间中。|[2512.01103](http://arxiv.org/abs/2512.01103)|null|\n",
        "2512.01011": "|**2025-11-30**|**An Adaptive Physics-Driven Deep Learning Framework for a Two-Phase Stefan Problem**|使用相变材料 (PCM) 的热能存储 (TES) 是可持续能源管理和电网稳定性的关键技术。本研究提出了一种新颖的物理驱动深度学习 (PDDL) 框架，用于对与翅片式换热器集成的基于 PCM 的二维 TES 系统中的复杂固液相变进行建模。该系统在冷却空气瞬态强制对流下运行，提出了具有挑战性的移动边界问题（MBP），其特点是复杂的相界面动力学和强烈的几何依赖性。由于不断变化的界面处需要重复的网格划分，解决此类 Stefan 问题的传统数值方法面临着巨大的计算负担。为了克服这些限制，我们开发了一种多网络 PDDL 方法，可以同时预测固相温度场、翅片温度分布和移动相边界位置。该架构采用三个并行运行的专用深度神经网络，受到能量守恒和界面条件的物理定律的约束。针对已建立的分析基准的全面验证表明，该框架在预测不同纵横比的界面演化和温度分布方面具有卓越的准确性。该模型成功捕获了几何参数对凝固速率和热性能的参数影响，而无需网格再生。我们的方法为优化基于 PCM 的 TES 系统提供了有效的计算范例，并提供了三维配置和多材料复合材料的可扩展性，为先进的热能系统设计提供了巨大的潜力。|[2512.01011](http://arxiv.org/abs/2512.01011)|null|\n",
        "2512.01008": "|**2025-11-30**|**LISA-3D: Lifting Language-Image Segmentation to 3D via Multi-View Consistency**|文本驱动的 3D 重建需要一个掩模生成器，该生成器能够同时理解开放词汇指令并在各个视点之间保持一致。我们提出了 LISA-3D，这是一个两阶段框架，通过使用几何感知低阶适应 (LoRA) 层改造指令跟踪模型 LISA 并重用冻结的 SAM-3D 重建器，将语言图像分割提升为 3D。在训练过程中，我们利用现成的 RGB-D 序列及其相机姿势来构建可微分的重投影损失，从而强制执行跨视图协议，而不需要任何额外的 3D 文本监督。生成的蒙版与 RGB 图像连接起来，形成 SAM-3D 的 RGBA 提示，无需重新训练即可输出高斯图或纹理网格。在 ScanRefer 和 Nr3D 中，LISA-3D 将语言到 3D 的准确性比单视图基线提高了 15.6 个点，同时仅适应 1160 万个参数。该系统是模块化的、数据高效的，并支持在未见过的类别上进行零样本部署，为语言引导的 3D 内容创建提供了实用的方法。我们的代码将在 https://github.com/binisalegend/LISA-3D 上提供。|[2512.01008](http://arxiv.org/abs/2512.01008)|null|\n",
        "2512.00952": "|**2025-11-30**|**Charge state equilibration of nitrogen-vacancy center ensembles in diamond: The role of electron tunneling**|氮空位（NV）中心的电荷态稳定性严重影响其作为量子传感器和量子位的应用。了解电荷态转换和平衡不仅对于金刚石的 NV 中心至关重要，而且对于一般宽带隙材料中的缺陷和杂质也至关重要。这些中心在不存在移动载流子的情况下在光学或电子激发下改变电荷状态的机制仍不清楚，可能会影响从荧光粉到电力电子器件等应用的性能。在这里，我们以 NV 中心系综的光电离为例阐明了这个问题。使用泵浦探针光谱，我们电离带负电的 NV 中心，并在长达几秒的时间尺度上监测 $\\NVm$ 的恢复。我们发现回收率很大程度上取决于周围氮供体的浓度。值得注意的是，平衡动力学没有表现出对温度的明显依赖性，排除了热激活过程。由密度泛函计算支持的多声子辅助电子隧道模型解释了测量结果并将隧道效应识别为平衡机制。|[2512.00952](http://arxiv.org/abs/2512.00952)|null|\n",
        "2512.00944": "|**2025-11-30**|**Binary-Gaussian: Compact and Progressive Representation for 3D Gaussian Segmentation**|3D 高斯分布 (3D-GS) 已成为一种高效的 3D 表示形式，并为分割等语义任务奠定了有前途的基础。然而，现有的基于 3D-GS 的分割方法通常依赖于高维类别特征，这会带来大量的内存开销。此外，由于标签空间拥塞和缺乏稳定的多粒度控制机制，细粒度分割仍然具有挑战性。为了解决这些限制，我们提出了一种用于每高斯类别表示的从粗到细的二进制编码方案，该方案通过二进制到十进制的映射将每个特征压缩为单个整数，从而大大减少了内存使用。我们进一步设计了一种渐进式训练策略，将全景分割分解为一系列独立的子任务，减少类间冲突，从而增强细粒度分割能力。此外，我们在分割训练期间微调不透明度，以解决光度渲染和语义分割之间的不兼容问题，这通常会导致前景-背景混乱。对多个基准的大量实验表明，我们的方法实现了最先进的分割性能，同时显着减少内存消耗并加速推理。|[2512.00944](http://arxiv.org/abs/2512.00944)|null|\n",
        "2512.00892": "|**2025-11-30**|**Accurately modeling long-term storage with minimum representative hours in large-scale renewable energy systems**|能源系统优化通常依赖于时间序列聚合来确保计算的易处理性。聚合通常会丢失时间步骤的时间顺序，这使得存储级别表示具有挑战性。通常，通过使用代表性日 (RD) 来利用日内时间顺序来解决这一挑战，尽管代表性小时 (RH) 可以比 RD 更少的代表性时间步长更准确地描述输入时间序列。然而，到目前为止，RH 存储表示方法的使用受到计算复杂度高、聚类和存储表示精度差或适用性受限等限制。在这里，我们提出了一种基于 RH 的新型存储表示方法，它将 RH 时间序列聚合的高精度与基于 RD 的方法的高计算效率结合起来。通过在欧洲净零能源系统模型上对四种最成熟的存储表示方法进行基准测试，我们发现与最成熟的 RD 和 RH 方法相比，对于相同的目标值，所提出的方法可以减少 95% 以上的求解时间。所提出的方法在每年约 100 至 500 个代表性小时的强聚合中表现出特殊的优势，使得该方法特别适用于大规模和部门耦合的过渡路径模型。所开发的用于准确建模短期和长期存储的方法以及所提出的发现对于能源系统建模者具有实际意义，他们在大规模应用中寻求计算易处理性，同时避免存储和转换容量的错误分配。|[2512.00892](http://arxiv.org/abs/2512.00892)|null|\n",
        "2512.00850": "|**2025-11-30**|**Smol-GS: Compact Representations for Abstract 3D Gaussian Splatting**|我们提出了 Smol-GS，一种学习 3D 高斯分布 (3DGS) 紧凑表示的新方法。我们的方法学习 3D 空间中集成空间和语义信息的高效编码。该模型通过递归体素层次结构捕获图块的坐标，而图块特征存储抽象的线索，包括颜色、不透明度、变换和材料属性。这种设计允许模型将 3D 场景压缩几个数量级，而不会损失灵活性。 Smol-GS 在标准基准上实现了最先进的压缩，同时保持了高渲染质量。除了视觉保真度之外，离散表示还可以作为下游任务的基础，例如导航、规划和更广泛的 3D 场景理解。|[2512.00850](http://arxiv.org/abs/2512.00850)|null|\n",
        "2512.00790": "|**2025-11-30**|**Observation of individual vortex penetration in a coplanar superconducting resonator**|我们演示了超导微波谐振器中单个阿布里科索夫涡旋的检测和控制。在毫开尔文温度下使用微波传输光谱法制造并研究了 $λ/4$ 谐振器，该谐振器在接地端附近有一个狭窄区域，充当涡流陷阱。共振频率的急剧逐步下降被检测为外部磁场增加的函数，这归因于单个阿布里科索夫涡旋进入狭窄区域。 NV 中心磁力测量证实了这种解释，揭示了磁场增加时的离散涡旋进入事件。我们的结果建立了一种用微波研究和操纵阿布里科索夫涡旋状态的方法。|[2512.00790](http://arxiv.org/abs/2512.00790)|null|\n",
        "2512.00765": "|**2025-11-30**|**The Outline of Deception: Physical Adversarial Attacks on Traffic Signs Using Edge Patches**|智能驾驶系统很容易受到交通标志的物理对抗性攻击。这些攻击可能会导致错误分类，从而导致错误的驾驶决策，从而危及道路安全。此外，在 V2X 网络内，此类误解可能会传播，引发级联故障，从而破坏整体流量和系统稳定性。然而，当前物理攻击的一个关键限制是缺乏隐形性。大多数方法对标志的中心区域施加扰动，从而产生人类观察者很容易察觉的视觉显着模式，从而限制了它们在现实世界中的实用性。本研究提出了 TESP-Attack，这是一种用于交通标志分类的新型隐形感知对抗补丁方法。基于人类视觉注意力主要集中在交通标志的中心区域的观察，我们采用实例分割来生成符合标志形状特征的边缘对齐掩模。利用 U-Net 生成器制作对抗性补丁，然后通过颜色和纹理约束以及频域分析对其进行优化，以实现与背景环境的无缝集成，从而实现高效的视觉隐藏。所提出的方法在具有不同架构的交通标志分类模型中展示了出色的攻击成功率，在有限的查询预算下实现了 90% 以上的攻击成功率。它还表现出强大的跨模型可移植性，并保持强大的现实世界性能，在不同角度和距离下保持稳定。|[2512.00765](http://arxiv.org/abs/2512.00765)|null|\n",
        "2512.00753": "|**2025-11-30**|**Boosting Gaussian Boson Sampling using Optical Parametric Amplification Networks**|高斯玻色子采样（GBS）提供了展示量子计算优势的途径。然而，光损耗减少了系统中的纠缠，可以使 GBS 结果经典地可模拟。我们提出了一种基于干涉仪网络中排列的光学参量放大器（OPA）的非线性光子架构。这种主动配置放大了电路内的量子相关性，同时保留了输出概率的#P-hard哈夫尼结构。使用对数负性，我们在数值上表明，在无损极限下，纠缠与 OPA 增益和网络深度呈线性比例关系，并且在实际损失率下与模式数量保持线性比例关系。这些缩放行为表明有损场景中的经典模拟在计算上仍然难以处理。我们的结果表明，OPA 增强的 GBS 在噪声环境中保持了计算硬度，为近期光子量子计算机提供了更有效的实现。|[2512.00753](http://arxiv.org/abs/2512.00753)|null|\n"
    },
    "具生智能&自动驾驶": {
        "2511.23476": "|**2025-11-28**|**Thinking by Doing: Building Efficient World Model Reasoning in LLMs via Multi-turn Interaction**|开发强大的世界模型推理对于大型语言模型 (LLM) 代理在复杂环境中进行规划和交互至关重要。虽然多轮交互通过真实的反馈提供了对环境动态的更好理解，但当前的方法通常会强加严格的推理过程，这限制了模型的主动学习，最终阻碍了有效的世界模型推理。为了解决这些问题，我们通过高效交互和主动推理探索世界模型内化（WMAct），它将模型从结构化推理中解放出来，让模型直接通过实践来塑造思维，并通过两个关键机制实现有效和高效的世界模型推理：（1）奖励重新调整机制，根据行动效能调整结果奖励，以激励减少冗余和有目的的交互； （2）交互频率退火策略，逐步减少允许的最大交互次数，这迫使模型压缩其学习并内化环境动态，而不是过度依赖环境线索。我们在 Sokoban、Maze 和 Taxi 上的实验表明，WMAct 产生有效的世界模型推理，能够在一个回合中解决以前需要多次交互的任务，并促进对复杂环境的强大可迁移性，从而提高一系列推理基准的性能。|[2511.23476](http://arxiv.org/abs/2511.23476)|null|\n",
        "2511.23465": "|**2025-11-28**|**SmallWorlds: Assessing Dynamics Understanding of World Models in Isolated Environments**|当前的世界模型缺乏用于系统评估的统一且受控的环境，因此很难评估它们是否真正捕捉到了管理环境动态的基本规则。在这项工作中，我们通过引入 SmallWorld Benchmark 来应对这一开放性挑战，这是一个测试平台，旨在评估孤立且精确控制的动态条件下的世界模型能力，而不依赖于手工制作的奖励信号。使用这个基准，我们在完全可观察的状态空间中对代表性架构（包括循环状态空间模型、变压器、扩散模型和神经常微分方程）进行全面的实验，检查它们在六个不同领域的行为。实验结果揭示了这些模型如何有效地捕获环境结构以及它们的预测如何随着扩展的推出而恶化，突出了当前建模范式的优点和局限性，并为表示学习和动态建模的未来改进方向提供了见解。|[2511.23465](http://arxiv.org/abs/2511.23465)|null|\n",
        "2511.23455": "|**2025-11-28**|**The Price of Progress: Algorithmic Efficiency and the Falling Cost of AI Inference**|近年来，语言模型在高级基准测试上取得了巨大进步，但其中大部分进步只有通过使用更昂贵的模型才能实现。因此，基准可能会呈现出每美元实际能力进步的扭曲景象。为了解决这个问题，我们使用人工分析和 Epoch AI 的数据来形成当前和历史价格的最大数据集，以运行迄今为止的基准。我们发现，对于知识、推理、数学和软件工程基准的前沿模型，给定基准性能水平的价格下降得非常快，大约每年 5 美元到 10 美元。 AI推理成本的降低得益于经济力量、硬件效率的提高和算法效率的提高。隔离开放模型来控制竞争效应并除以硬件价格下降，我们估计算法效率的进步约为每年 3 美元。最后，我们建议评估者公开并考虑基准测试的价格，作为衡量人工智能现实世界影响的重要组成部分。|[2511.23455](http://arxiv.org/abs/2511.23455)|null|\n",
        "2511.23450": "|**2025-11-28**|**Object-Centric Data Synthesis for Category-level Object Detection**|对象检测的深度学习方法已经实现了图像中特定对象类别的可靠检测。然而，将模型的检测能力扩展到新的对象类需要大量带注释的训练数据，获取这些数据既昂贵又耗时，特别是对于现有数据集中表示不足的长尾类。在这里，我们介绍了以对象为中心的数据设置，当以对象为中心的数据（多视图图像或3D模型）的形式提供有限的数据时，并系统地评估四种不同的数据合成方法的性能，以在此设置中微调新对象类别的对象检测模型。这些方法基于简单的图像处理技术、3D 渲染和图像扩散模型，并使用以对象为中心的数据来合成具有不同上下文连贯性和复杂性的真实、杂乱的图像。我们评估这些方法如何使模型能够在现实世界数据中实现类别级泛化，并在数据受限的实验环境中展示显着的性能提升。|[2511.23450](http://arxiv.org/abs/2511.23450)|null|\n",
        "2511.23440": "|**2025-11-28**|**Accelerated Execution of Bayesian Neural Networks using a Single Probabilistic Forward Pass and Code Generation**|机器学习模型在诊断、天气预报、自然语言处理和自动驾驶等领域表现良好，但其有限的不确定性处理限制了在安全关键环境中的使用。传统的神经网络通常无法检测域外（OOD）数据，并且可能输出自信但不正确的预测。贝叶斯神经网络 (BNN) 通过提供概率估计来解决这个问题，但会产生较高的计算成本，因为预测需要采样权重分布和多次前向传递。概率前向传递 (PFP​​) 通过假设高斯分布权重和激活，为随机变分推理 (SVI) 提供高效近似，从而实现完全分析的不确定性传播并用单个确定性前向传递取代采样。我们提出了一个端到端的管道，用于在嵌入式 ARM CPU 上训练、编译、优化和部署基于 PFP 的 BNN。使用 TVM 深度学习编译器，我们结合手动和自动调整策略，实现了用于多层感知器和卷积神经网络的专用高斯传播算子库。消融研究表明，PFP 在计算效率方面始终优于 SVI，小批量的加速速度高达 4200 倍。 PFP-BNN 在准确性、不确定性估计和 OOD 检测方面与 Dirty-MNIST 上的 SVI-BNN 相匹配，同时大大降低了计算成本。这些结果凸显了将贝叶斯近似与代码生成相结合的潜力，可以在资源受限的系统上实现高效的 BNN 部署。|[2511.23440](http://arxiv.org/abs/2511.23440)|null|\n",
        "2511.23436": "|**2025-11-28**|**Towards Continuous Intelligence Growth: Self-Training, Continual Learning, and Dual-Scale Memory in SuperIntelliAgent**|我们引入了 SuperIntelliAgent，这是一个代理学习框架，它将可训练的小型扩散模型（学习者）与冻结的大型语言模型（验证者）结合起来，通过自我监督的交互实现持续的智力增长。与传统的监督微调不同，SuperIntelliAgent 无需注释即可自主学习：学习器生成候选输出，验证器通过逐步推理对其进行评估，它们的交互产生用于直接偏好优化 (DPO) 的选择/拒绝对。这会将每个输入转换为伪训练信号以进行持续改进。该框架集成了双尺度记忆：短期上下文记忆可在细化周期中保留推理痕迹，而长期记忆可通过轻量级即时微调来巩固所获得的知识。重播缓冲区保留显示可验证进度的样本，并将它们作为辅助监督重播，在形成适应性课程的同时加强最近的学习。 SuperIntelliAgent 与基础设施无关，可以插入现有的代理框架，同时将普通的推理循环转变为终身优化过程。我们认为，将可训练的学习者与具有推理能力的验证者配对形成了智力增长的最小可靠单元，因为配对反馈和部分历史重播会产生更丰富的学习课程和更强的偏好一致性。通过少量自动生成的 DPO 对，学习器在所有基准测试中都有所提高，这表明该机制为持续的情报积累和实际部署提供了有希望的方向。|[2511.23436](http://arxiv.org/abs/2511.23436)|null|\n",
        "2511.23429": "|**2025-11-28**|**Hunyuan-GameCraft-2: Instruction-following Interactive Game World Model**|生成世界模型的最新进展在创建开放式游戏环境方面取得了显着进展，从静态场景合成发展到动态交互式模拟。然而，当前的方法仍然受到严格的动作模式和高注释成本的限制，限制了它们对不同的游戏内交互和玩家驱动的动态进行建模的能力。为了应对这些挑战，我们引入了Hunyuan-GameCraft-2，这是一种用于生成游戏世界建模的指令驱动交互的新范式。我们的模型不依赖固定的键盘输入，而是允许用户通过自然语言提示、键盘或鼠标信号来控制游戏视频内容，从而在生成的世界中实现灵活且语义丰富的交互。我们正式定义了交互式视频数据的概念，并开发了一个自动化流程，将大规模、非结构化的文本视频对转换为因果对齐的交互式数据集。我们的模型建立在 14B 图像到视频专家混合 (MoE) 基础模型的基础上，结合了文本驱动的交互注入机制，可对摄像机运动、角色行为和环境动态进行细粒度控制。我们引入了一个以交互为中心的基准测试InterBench，来全面评估交互性能。大量的实验表明，我们的模型生成了时间连贯且有因果关系的交互式游戏视频，这些视频忠实地响应各种自由形式的用户指令，例如“开门”、“拔火把”或“触发爆炸”。|[2511.23429](http://arxiv.org/abs/2511.23429)|null|\n",
        "2511.23428": "|**2025-11-28**|**DisMo: Disentangled Motion Representations for Open-World Motion Transfer**|文本到视频 (T2V) 和图像到视频 (I2V) 模型的最新进展使得能够从简单的文本描述或初始帧创建视觉上引人注目的动态视频。然而，这些模型通常无法提供与内容分离的运动的明确表示，从而限制了它们对内容创建者的适用性。为了解决这一差距，我们提出了 DisMo，这是一种通过图像空间重建目标直接从原始视频数据学习抽象运动表示的新颖范例。我们的表示是通用的并且独立于静态信息，例如外观、对象身份或姿势。这使得开放世界的运动传输成为可能，允许运动在语义上不相关的实体之间传输，而不需要对象对应，甚至在截然不同的类别之间也是如此。与之前的方法不同，之前的方法会权衡运动保真度和即时依从性，过度拟合源结构或偏离所描述的动作，我们的方法将运动语义与外观分离，从而实现准确的传输和忠实的调节。此外，我们的运动表示可以通过轻量级适配器与任何现有的视频生成器相结合，使我们能够轻松地从视频模型的未来进步中受益。我们通过一系列不同的运动转移任务证明了我们方法的有效性。最后，我们表明，学习到的表示非常适合下游运动理解任务，在 Something-Something v2 和 Jester 等基准上的零样本动作分类中，始终优于最先进的视频表示模型（例如 V-JEPA）。项目页面：https://compvis.github.io/DisMo|[2511.23428](http://arxiv.org/abs/2511.23428)|null|\n",
        "2511.23371": "|**2025-11-28**|**Multilayer network science: theory, methods, and applications**|多层网络科学已成为分析互连和相互依赖的复杂系统的中心框架。随着丰富的异构数据的可用性不断增加，它的相关性大幅增长，这使得揭示和利用许多现实世界网络固有的多层组织成为可能。在这篇评论中，我们总结了该领域的最新发展。在理论和方法论方面，我们概述了核心概念并调查了社区检测、动态过程、时间网络、高阶交互和基于机器学习的方法的进展。在应用方面，我们讨论不同领域的进展，包括相互依赖的基础设施、传播动力学、计算社会科学、经济和金融系统、生态和气候网络、科学研究、网络医学和网络神经科学。我们以前瞻性的观点作为结论，强调对标准化数据集和软件、时态和高阶结构的更深层次集成的需求，以及向复杂系统的真正预测模型的过渡。|[2511.23371](http://arxiv.org/abs/2511.23371)|null|\n",
        "2511.23369": "|**2025-11-28**|**SimScale: Learning to Drive via Real-World Simulation at Scale**|实现完全自动驾驶系统需要在各种场景中学习理性决策，包括安全关键场景和非分布场景。然而，此类案例在人类专家收集的现实世界语料库中代表性不足。为了弥补数据多样性的不足，我们引入了一种新颖且可扩展的模拟框架，能够根据现有的驾驶日志合成大量未见的状态。我们的管道利用先进的神经渲染和反应环境来生成由扰动的自我轨迹控制的高保真多视图观察。此外，我们为这些新模拟的状态开发了一种伪专家轨迹生成机制，以提供动作监督。根据合成数据，我们发现对现实世界和模拟样本的简单协同训练策略可以显着提高各种规划方法在具有挑战性的现实世界基准上的鲁棒性和泛化性，在 navhard 上高达 +6.8 EPDMS，在 navtest 上高达 +2.9。更重要的是，即使没有额外的现实世界数据流，这种策略改进也可以通过仅增加模拟数据来顺利扩展。我们进一步揭示了这种模拟真实学习系统（我们称之为 SimScale）的几个关键发现，包括伪专家的设计和不同策略架构的扩展属性。我们的模拟数据和代码将被发布。|[2511.23369](http://arxiv.org/abs/2511.23369)|null|\n",
        "2512.01102": "|**2025-11-30**|**Semantic Communications for Vehicle-Based Mission-Critical Services: Challenges and Solutions**|随着基于无人机（UAV）的应急通信和车联网（IoV）自动驾驶等关键任务（MC）业务的出现，传统的通信框架已无法满足人们对更高可靠性、更低时延和日益增长的传输负载的需求。语义通信 (SemCom) 是一种新兴的通信范式，它将重点从位级数据转移到接收器的上下文和预期任务（即语义级），预计将成为第六代 (6G) 网络的一场关键革命。然而，专门针对基于车辆的MC（VbMC）服务定制的明确且系统的SemCom框架尚未提出，这主要是由于其复杂性和缺乏对其MC特性的分析。在本文中，我们首先介绍 SemCom 框架内的关键信息关键型和基础设施关键型车辆服务。然后我们分析 MC 服务的独特特征以及它们给 SemCom 带来的相应挑战。在此基础上，我们提出了一种新颖的 SemCom 框架，旨在满足车辆系统中 MC 服务的特定需求，为现有挑战提供潜在的解决方案。最后，我们提出了一个基于无人机的快速拥堵缓解案例研究，利用 eXplainable AI (XAI) 来验证所提出的 SemCom 框架的有效性。|[2512.01102](http://arxiv.org/abs/2512.01102)|null|\n",
        "2512.01095": "|**2025-11-30**|**CycliST: A Video Language Model Benchmark for Reasoning on Cyclical State Transitions**|我们提出了 CycliST，这是一个新颖的基准数据集，旨在评估视频语言模型 (VLM) 在循环状态转换上的文本推理能力。 CycliST 通过生成具有对象运动和视觉属性周期性模式的合成的、结构丰富的视频序列来捕获现实世界过程的基本方面。 CycliST 采用分层评估系统，通过循环物体数量、场景杂乱和照明条件的变化逐步增加难度，挑战最先进的时空认知模型。我们对当前最先进的 VLM（开源和专有）进行了广泛的实验，并揭示了它们在推广到线性和轨道运动等循环动力学以及颜色和比例等视觉属性随时间变化的局限性。我们的结果表明，当今的 VLM 很难可靠地检测和利用循环模式，缺乏时间理解的概念，并且无法从场景中提取定量见解，例如运动物体的数量，这凸显了需要解决的重大技术差距。更具体地说，我们发现没有单一模型在性能上始终领先：规模和架构都与结果没有很强的相关性，并且没有模型在所有任务上都取得同样的成功。通过提供有针对性的挑战和全面的评估框架，CycliST 为视觉推理模型铺平了道路，在理解周期模式方面超越了最先进的技术。|[2512.01095](http://arxiv.org/abs/2512.01095)|null|\n",
        "2512.01081": "|**2025-11-30**|**Testing the Machine Consciousness Hypothesis**|机器意识假说指出，意识是具有二阶感知能力的计算系统的无基底功能属性。我提出了一个研究计划，通过研究集体自我模型（连贯的、自我参照的表征）如何从嵌入通用自组织环境中的分布式学习系统中出现，来通过计算机模拟来研究这个想法。这里概述的理论始于这样的假设：意识是集体智能系统的一个新兴属性，通过通信进行预测同步。它不是个体建模的附带现象，而是系统进化以内部描述自身的语言的属性。对于基本现实的模型，我从一个最小但通用的计算世界开始：一个元胞自动机，它表现出计算不可约性和局部可约性。在这个计算基础之上，我引入了一个能够通信和适应的本地、预测、代表性（神经）模型网络。我使用这个分层模型来研究集体智慧如何作为主体间协调的直接结果而产生自我表征。我认为意识并不是来自建模本身，而是来自沟通。它源于本地观察者组之间嘈杂、有损的预测消息交换，描述了底层计算基质（基本现实）中的持久模式。正是通过这种代表性对话，出现了一种共享模型，协调了许多对世界的片面看法。更广泛的目标是通过研究内部自我模型如何在没有集中控制的分布式系统中形成，来开发可实证检验的机器意识理论。|[2512.01081](http://arxiv.org/abs/2512.01081)|null|\n",
        "2512.01078": "|**2025-11-30**|**SimWorld: An Open-ended Realistic Simulator for Autonomous Agents in Physical and Social Worlds**|虽然 LLM/VLM 支持的人工智能代理在数学、编码和计算机使用方面取得了快速进步，但它们在复杂的物理和社会环境中的应用仍然具有挑战性。构建能够在现实世界中生存和发展的代理（例如，通过自主赚取收入或经营业务）需要跨不同具体场景的大规模交互、推理、培训和评估。然而，用于此类开发的现有世界模拟器存在不足：它们通常依赖于有限的手工制作环境，模拟简化的类似游戏的物理和社会规则，并且缺乏对 LLM/VLM 代理的本机支持。我们推出 SimWorld，这是一款基于虚幻引擎 5 构建的新模拟器，旨在在丰富的、类似真实世界的设置中开发和评估 LLM/VLM 代理。 SimWorld 提供三大核心功能：（1）真实、开放式的世界模拟，包括准确的物理和社会动态以及语言驱动的程序环境生成； (2) LLM/VLM 代理的丰富接口，具有多模式世界输入和不同抽象级别的开放词汇操作； (3)用户可以轻松定制的多样化且可扩展的物理和社会推理场景。我们通过在涉及战略合作和竞争的长期多智能体交付任务上部署前沿 LLM 智能体（例如 GPT-4o、Gemini-2.5-Flash、Claude-3.5 和 DeepSeek-Prover-V2）来演示 SimWorld。结果揭示了不同模型的不同推理模式和局限性。我们开源 SimWorld，并希望它成为跨学科推进现实世界代理智能的基础平台：https://simworld.org。|[2512.01078](http://arxiv.org/abs/2512.01078)|null|\n",
        "2512.01073": "|**2025-11-30**|**The Modeler Schema Theory of Consciousness, with a Falsifiable Experiment**|我们认为意识源自单一控制代理，即建模者模式。当大脑的建模器系统构建和更新内部世界模型时，它会监视该系统。作为监控的一部分，建模者模式通过对建模者的输出应用基于品质的一致性检查来生成经验。人类代理由三个协作代理组成：建模者、控制器和目标者，每个代理与相关的监管“模式”代理配对。我们还描述了快速建模器和快速控制器；进化的捷径，其快速行动将先于意识。我们的核心预测是，建模器模式在扫视期间执行基于品质的一致性检查，并在发现差异时发出自下而上的目标。为了测试这个预测，我们提出了一个扫视变化检测实验，该实验可以区分 Modeler 生成的目标和 Modeler 模式生成的目标。在建模者模式中定位感受性将经验与内部表征的调节和细化联系起来，阐明了意识如何从模型控制中产生，并提出了一条通往经验证伪的道路，从而为解决意识难题提供了一个具体的、可测试的建议。|[2512.01073](http://arxiv.org/abs/2512.01073)|null|\n",
        "2512.01048": "|**2025-11-30**|**TRoVe: Discovering Error-Inducing Static Feature Biases in Temporal Vision-Language Models**|视觉语言模型（VLM）在处理时间理解任务方面取得了长足的进步，这些任务涉及表征图像序列中的视觉变化。然而，最近的研究表明，在进行预测时，VLM 可能依赖于静态特征偏差，例如背景或对象特征，而不是动态视觉变化。静态特征偏差是一种捷径，可能会导致下游任务的系统预测错误；因此，在实际模型部署之前识别和描述导致错误的静态特征偏差至关重要。在这项工作中，我们介绍了 TRoVe，一种自动方法，用于发现由时态 VLM 学习到的导致错误的静态特征偏差。给定经过训练的 VLM 和与下游分类任务相关的带注释的验证数据集，TRoVe 从数据集中提取候选静态特征，并通过 (i) 特征对分类错误的影响以及 (ii) VLM 在进行预测时依赖该特征的程度对每个特征进行评分。为了定量评估 TRoVe，我们引入了一个评估框架，该框架由 101 个经过训练的时间 VLM 与学习到的静态特征偏差的真实注释配对组成。我们使用这个框架来证明 TRoVe 可以准确识别 VLM 中导致错误的静态特征偏差，与最接近的基线相比实现了 28.6% 的改进。最后，我们将 TRoVe 应用于 7 个现成的 VLM 和 2 个时间理解任务，揭示以前未知的静态特征偏差，并证明学习偏差的知识可以帮助提高测试时的模型性能。我们的代码可在 https://github.com/Stanford-AIMI/TRoVe 获取。|[2512.01048](http://arxiv.org/abs/2512.01048)|null|\n",
        "2512.01039": "|**2025-11-30**|**Joint Partitioning and Placement of Foundation Models for Real-Time Edge AI**|在异构边缘环境中对大规模基础模型进行推理需要一个从根本上可重新配置的编排底层。模型层的静态分区假定计算和网络资源之间的时间稳定性，这与现实世界部署的波动性不一致。我们引入了一个框架，其中基础模型的空间放置和内部分割都被提升为运行时解析的构造。编排问题被形式化为对分层分配的约束优化，受到不断变化的延迟、利用率和隐私梯度的影响。该框架通过将模型感知容量分析与动态图重新分区和重新分配相结合，实现响应基础设施波动的反应式推理组合。我们介绍架构和算法组件，以及 6G 多接入边缘计算中的代表性用例。|[2512.01039](http://arxiv.org/abs/2512.01039)|null|\n",
        "2512.01031": "|**2025-11-30**|**VLASH: Real-Time VLAs via Future-State-Aware Asynchronous Inference**|视觉-语言-动作模型（VLA）在处理各种机器人任务方面的能力越来越强。然而，它们在现实世界中的部署仍然缓慢且低效：演示视频通常会加速 5-10 倍才能显得流畅，但会出现明显的动作停顿和对环境变化的延迟反应。异步推理提供了一种有前途的解决方案，通过使机器人能够同时执行动作和执行推理来实现连续和低延迟的控制。然而，由于机器人和环境在推理过程中不断发展，预测和执行间隔之间会出现时间错位。这会导致严重的操作不稳定，而现有方法要么会降低准确性，要么会引入运行时开销来缓解这种不稳定。我们提出了 VLASH，这是一种用于 VLA 的通用异步推理框架，可以提供平滑、准确和快速的反应控制，而无需额外的开销或架构更改。 VLASH 通过使用先前生成的动作块向前滚动机器人状态来估计未来的执行时间状态，从而弥合预测和执行之间的差距。实验表明，与同步推理相比，VLASH 实现了高达 2.03 倍的加速，并减少了高达 17.4 倍的反应延迟，同时完全保留了原始精度。此外，它使 VLA 能够处理快速反应、高精度的任务，例如打乒乓球和打地鼠，而传统同步推理无法解决这些问题。代码可在 https://github.com/mit-han-lab/vlash 获取|[2512.01031](http://arxiv.org/abs/2512.01031)|null|\n",
        "2512.01030": "|**2025-11-30**|**Lotus-2: Advancing Geometric Dense Prediction with Powerful Image Generative Model**|由于 2D 观察和 3D 结构之间的外观模糊性和非内射映射，从单个图像中恢复像素级几何属性从根本上来说是不适定的。虽然判别回归模型通过大规模监督实现了强大的性能，但其成功受到可用数据的规模、质量和多样性以及有限的物理推理的限制。最近的扩散模型展示了强大的世界先验，对从大量图像文本数据中学习到的几何和语义进行编码，但直接重用其随机生成公式对于确定性几何推理来说并不是最优的：前者针对多样化和高保真图像生成进行了优化，而后者则需要稳定且准确的预测。在这项工作中，我们提出了 Lotus-2，一个用于稳定、准确和细粒度几何密集预测的两阶段确定性框架，旨在提供最佳适应协议以充分利用预先训练的生成先验。具体来说，在第一阶段，核心预测器采用具有干净数据目标的单步确定性公式和轻量级局部连续性模块（LCM）来生成没有网格伪影的全局相干结构。在第二阶段，细节锐化器在核心预测器定义的流形内执行约束多步整流流细化，通过无噪声的确定性流匹配增强细粒度几何形状。 Lotus-2 仅使用 59K 训练样本（不到现有大型数据集的 1%），在单目深度估计和极具竞争力的表面法线预测方面建立了新的最先进结果。这些结果表明，扩散模型可以作为确定性的世界先验，从而实现超越传统判别和生成范式的高质量几何推理。|[2512.01030](http://arxiv.org/abs/2512.01030)|null|\n",
        "2512.01023": "|**2025-11-30**|**Approximating Analytically-Intractable Likelihood Densities with Deterministic Arithmetic for Optimal Particle Filtering**|粒子滤波算法已经为自主机器人（自动驾驶汽车、无人机、仓库机器人）、目标跟踪和计量经济学中的问题提供了实用的解决方案，并在语音处理和医学（患者监护）中得到了进一步的应用。然而，对于高频和资源受限的系统来说，它们在表示观测可能性方面的固有弱点（这通常会导致粒子简并）仍然没有得到解决。最佳建议和辅助粒子过滤器等改进在特定情况下缓解了这个问题，并增加了计算成本。这项工作提出了一种新的粒子滤波方法及其实现，它使得任意似然密度的可调近似表示成为参数分布的程序变换。我们的方法利用最新的计算平台，可以在不依赖随机方法的情况下对概率分布表示（UxHw）执行确定性计算。对于非高斯非线性系统和具有最佳辅助粒子滤波器的情况，我们对总共 294840 个评估点的似然评估误差和速度进行了基准测试。对于此类模型，结果表明，与蒙特卡洛替代方案相比，UxHw 方法的加速速度高达 37.7 倍。对于窄均匀观测噪声，粒子滤波器错误地分配零似然率高达 81.89%，而 UxHw 实现了 1.52% 的错误零率。与蒙特卡罗替代方案相比，UxHw 方法的滤波器 RMSE 提高了 18.9%（平均 3.3%）。|[2512.01023](http://arxiv.org/abs/2512.01023)|null|\n"
    }
}