{
    "Video Diffusion": {
        "2601.00678": "|**2026-01-02**|**Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians**|人类擅长仅凭一张图像来预测场景的未来动态。能够模仿这种能力的视频生成模型是智能系统的重要组成部分。最近的方法提高了单图像条件视频生成中的时间相干性和 3D 一致性。然而，这些方法通常缺乏强大的用户可控性，例如修改相机路径，限制了它们在实际应用中的适用性。大多数现有的相机控制的图像到视频模型都难以准确建模相机运动、保持时间一致性和保持几何完整性。利用显式中间 3D 表示可实现与给定摄像机轨迹对齐的连贯视频生成，从而提供了一种有前景的解决方案。尽管这些方法通常使用 3D 点云来渲染场景并在后期引入对象运动，但尽管允许精确控制相机运动，但这种两步过程仍然无法实现完全的时间一致性。我们提出了一种新颖的框架，在单次前向传递中给定单个图像的情况下，构建 3D 高斯场景表示并对合理的对象运动进行采样。这使得能够快速生成相机引导的视频，而无需迭代去噪将对象运动注入渲染帧。在 KITTI、Waymo、RealEstate10K 和 DL3DV-10K 数据集上进行的大量实验表明，我们的方法实现了最先进的视频质量和推理效率。该项目页面位于 https://melonienimasha.github.io/Pixel-to-4D-Website。|[2601.00678](http://arxiv.org/abs/2601.00678)|null|\n",
        "2601.01568": "|**2026-01-04**|**MM-Sonate: Multimodal Controllable Audio-Video Generation with Zero-Shot Voice Cloning**|联合音频-视频生成旨在合成同步的多感官内容，但当前的统一模型难以实现细粒度的声学控制，特别是对于身份保留语音。现有方法要么因级联生成而遭受时间错位，要么缺乏在联合合成框架内执行零样本语音克隆的能力。在这项工作中，我们提出了 MM-Sonate，一种多模态流匹配框架，它将可控音频-视频联合生成与零样本语音克隆功能相结合。与依赖于粗略语义描述的先前作品不同，MM-Sonate 利用统一的指令音素输入来强制执行严格的语言和时间对齐。为了实现零样本语音克隆，我们引入了一种音色注入机制，可以有效地将说话者身份与语言内容分离。此外，为了解决多模态设置中标准无分类器引导的局限性，我们提出了一种基于噪声的负调节策略，该策略利用自然噪声先验来显着增强声保真度。实证评估表明，MM-Sonate 在联合生成基准中建立了新的最先进的性能，在唇形同步和语音清晰度方面显着优于基线，同时实现了与专门的文本到语音系统相当的语音克隆保真度。|[2601.01568](http://arxiv.org/abs/2601.01568)|null|\n",
        "2601.01528": "|**2026-01-04**|**DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving**|视频生成模型作为世界模型的一种形式，已成为人工智能领域最令人兴奋的前沿之一，它让智能体能够通过对复杂场景的时间演化进行建模来想象未来。在自动驾驶中，这一愿景催生了驾驶世界模型：想象自我和代理未来的生成模拟器，实现可扩展的模拟、极端情况的安全测试以及丰富的合成数据生成。然而，尽管研究活动快速增长，但该领域缺乏严格的基准来衡量进展和指导优先事项。现有的评估仍然有限：通用视频指标忽视了安全关键的成像因素；轨迹的合理性很少被量化；时间和代理级别的一致性被忽略；自我调节的可控性被忽略。此外，当前的数据集无法涵盖现实世界部署所需的条件的多样性。为了解决这些差距，我们推出了 DrivingGen，这是第一个生成驾驶世界模型的综合基准测试。 DrivingGen 将来自驾驶数据集和互联网规模视频源的多样化评估数据集（涵盖不同的天气、一天中的时间、地理区域和复杂的操作）与一套新指标相结合，共同评估视觉真实性、轨迹合理性、时间一致性和可控性。对 14 个最先进模型进行基准测试揭示了明显的权衡：通用模型看起来更好，但违反物理原理，而驾驶专用模型可以真实地捕捉运动，但视觉质量落后。 DrivingGen 提供统一的评估框架，以培育可靠、可控和可部署的驾驶世界模型，从而实现可扩展的模拟、规划和数据驱动的决策。|[2601.01528](http://arxiv.org/abs/2601.01528)|null|\n",
        "2601.01352": "|**2026-01-04**|**Slot-ID: Identity-Preserving Video Generation from Reference Videos via Slot-Based Temporal Identity Encoding**|制作保留用户指定身份的即时忠实视频仍然具有挑战性：模型需要从稀疏参考中推断面部动态，同时平衡身份保留和运动自然度之间的紧张关系。对单个图像进行调节完全忽略了时间特征，这会导致姿势锁定运动、不自然的扭曲以及当视点和表情发生变化时出现“平均”面孔。为此，我们引入了扩散变换器视频生成器的身份条件变体，它使用短参考视频而不是单个肖像。我们的关键想法是将动态纳入参考文献中。一个短片揭示了特定主题的模式，例如微笑如何形成、姿势和灯光。从这个片段中，Sinkhorn 路由编码器学习紧凑的身份令牌，捕获特征动态，同时保持预训练的骨干网兼容。尽管仅添加了轻量级调节，但该方法始终可以提高大姿势变化和富有表现力的面部行为下的身份保留，同时在不同的主题和提示中保持即时的忠实性和视觉真实感。|[2601.01352](http://arxiv.org/abs/2601.01352)|null|\n",
        "2601.00996": "|**2026-01-02**|**VEAT Quantifies Implicit Associations in Text-to-Video Generator Sora and Reveals Challenges in Bias Mitigation**|Sora 等文本转视频 (T2V) 生成器引发了人们对生成的内容是否反映社会偏见的担忧。我们通过引入视频嵌入关联测试 (VEAT) 和单类别 VEAT (SC-VEAT)，将嵌入关联测试从文字和图像扩展到视频。我们通过从广泛使用的基线（包括隐式关联测试（IAT）场景和 OASIS 图像类别）重现关联的方向和大小来验证这些方法。然后，我们对 17 个职业和 7 个奖项中的种族（非洲裔美国人与欧洲裔美国人）和性别（女性与男性）与效价（愉快与不愉快）的关联进行了量化。 Sora 视频将欧洲裔美国人和女性更多地与愉悦联系在一起（d>0.8）。效应大小与现实世界的人口分布相关：职业中男性和白人的百分比（r=0.93，r=0.83）以及获奖者中男性和非黑人的百分比（r=0.88，r=0.99）。应用明确的去偏见提示通常会降低效应大小的大小，但可能会适得其反：两种与黑人相关的职业（看门人、邮政服务）在去偏见后变得更加与黑人相关。总之，这些结果表明，如果不严格评估和负责任地部署，易于访问的 T2V 发生器实际上可能会放大代表性危害。|[2601.00996](http://arxiv.org/abs/2601.00996)|null|\n",
        "2601.00943": "|**2026-01-02**|**PhyEduVideo: A Benchmark for Evaluating Text-to-Video Models for Physics Education**|生成式人工智能模型，特别是文本到视频（T2V）系统，通过自动创建引人入胜且直观的视觉解释，为改变科学教育提供了一条有前途的途径。在这项工作中，我们通过引入解释性视频生成的专用基准，迈出了评估其在物理教育中的潜力的第一步。该基准旨在评估 T2V 模型通过视觉插图传达核心物理概念的能力。我们基准测试中的每个物理概念都被分解为细粒度的教学点，每个点都附有精心设计的提示，旨在对教学点进行视觉解释。 T2V 模型根据其根据这些提示生成准确视频的能力进行评估。我们的目标是系统地探索使用 T2V 模型生成高质量、符合课程的教育内容的可行性，为实现由人工智能驱动的可扩展、可访问和个性化的学习体验铺平道路。我们的评估表明，当前的模型可以生成视觉上连贯的视频，具有平滑的运动和最小的闪烁，但其概念准确性不太可靠。力学、流体和光学等领域的表现令人鼓舞，但模型在电磁学和热力学方面遇到了困难，这些领域的抽象相互作用很难描述。这些发现强调了教育视频生成中视觉质量和概念正确性之间的差距。我们希望这个基准测试能够帮助社区缩小这一差距，并转向能够大规模提供准确、符合课程的物理内容的 T2V 系统。基准测试和随附的代码库可在 https://github.com/meghamariamkm/PhyEduVideo 上公开获取。|[2601.00943](http://arxiv.org/abs/2601.00943)|null|\n",
        "2601.02358": "|**2026-01-05**|**VINO: A Unified Visual Generator with Interleaved OmniModal Context**|我们推出了 VINO，一个统一的视觉生成器，可以在单个框架内执行图像和视频生成和编辑。 VINO 不依赖特定于任务的模型或每种模态的独立模块，而是使用以文本、图像和视频为条件的共享扩散主干，从而在一个模型下实现广泛的视觉创建和编辑任务。具体来说，VINO 将视觉语言模型 (VLM) 与多模态扩散变压器 (MMDiT) 结合起来，其中多模态输入被编码为交错条件标记，然后用于指导扩散过程。该设计支持多参考基础、长格式指令遵循以及跨静态和动态内容的一致身份保留，同时避免特定于模态的架构组件。为了训练这样一个统一的系统，我们引入了一个多阶段训练管道，该管道逐步将视频生成基础模型扩展为能够进行图像和视频输入和输出的统一的多任务生成器。在不同的生成和编辑基准中，VINO 展示了强大的视觉质量、忠实的指令遵循、改进的参考和属性保留以及更可控的多身份编辑。我们的结果强调了实现可扩展的统一视觉生成的实用路径，以及交错的上下文计算作为通用视觉创建基础的前景。|[2601.02358](http://arxiv.org/abs/2601.02358)|null|\n",
        "2601.02204": "|**2026-01-05**|**NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation**|我们提出了 NextFlow，一个统一的仅解码器自回归变压器，在 6 万亿个交错的文本图像离散标记上进行训练。通过利用统一自回归架构中的统一视觉表示，NextFlow 原生激活多模态理解和生成功能，解锁图像编辑、交错内容和视频生成的能力。受模态独特性质的启发（其中文本是严格顺序的，而图像本质上是分层的），我们保留文本的下一个标记预测，但采用下一个尺度预测进行视觉生成。这与传统的光栅扫描方法不同，只需 5 秒即可生成 1024x1024 图像，比同类 AR 模型快几个数量级。我们通过强大的训练方法解决多尺度生成的不稳定性。此外，我们引入了强化学习的前缀调整策略。实验表明，NextFlow 在统一模型中实现了最先进的性能，并且在视觉质量方面可与专门的扩散基线相媲美。|[2601.02204](http://arxiv.org/abs/2601.02204)|null|\n",
        "2601.02125": "|**2026-01-05**|**SingingBot: An Avatar-Driven System for Robotic Face Singing Performance**|为机器人面孔配备唱歌功能对于具有同理心的人机交互至关重要。然而，现有的机器人面部驾驶研究主要集中在对话或模仿静态表情上，难以满足持续的情感表达和歌唱连贯性的高要求。为了解决这个问题，我们提出了一种新颖的化身驱动框架来吸引机器人唱歌。我们首先利用嵌入广泛人类先验的肖像视频生成模型来合成生动的歌唱化身，提供可靠的表达和情感引导。随后，这些面部特征通过跨越广泛表达空间的面向语义的映射功能转移到机器人。此外，为了定量评估机器人歌唱的情感丰富度，我们提出了情感动态范围指标来衡量效价-唤醒空间内的情感宽度，揭示了广泛的情感范围对于吸引人的表演至关重要。综合实验证明，我们的方法在保持唇音同步的同时实现了丰富的情感表达，显着优于现有方法。|[2601.02125](http://arxiv.org/abs/2601.02125)|null|\n",
        "2601.02107": "|**2026-01-05**|**MagicFight: Personalized Martial Arts Combat Video Generation**|在通用文本到视频生成的激增中，个性化人类视频生成领域取得了显着的进步，主要集中在单人场景上。然而，据我们所知，两人互动的领域，特别是在武术格斗的背景下，仍然是未知的。我们发现了一个重大差距：现有的单人舞蹈生成模型不足以捕捉两名交战战士的微妙性和复杂性，从而导致身份混乱、肢体异常和动作不匹配等挑战。为了解决这个问题，我们引入了一项开创性的新任务：个性化武术战斗视频生成。我们的方法 MagicFight 是专门为克服这些障碍而设计的。鉴于这项开创性任务，我们面临着缺乏适当的数据集的问题。因此，我们使用游戏物理引擎 Unity 生成定制数据集，精心制作大量 3D 角色、武术动作和场景，旨在表现战斗的多样性。 MagicFight 改进并调整了现有的模型和策略，以生成高保真两人战斗视频，保持个人身份并确保无缝、连贯的动作序列，从而为交互式视频内容创建领域的未来创新奠定基础。   网站：https://MingfuYAN.github.io/MagicFight/ 数据集：https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta|[2601.02107](http://arxiv.org/abs/2601.02107)|null|\n",
        "2601.03233": "|**2026-01-06**|**LTX-2: Efficient Joint Audio-Visual Foundation Model**|最近的文本到视频扩散模型可以生成引人注目的视频序列，但它们仍然保持沉默——缺少音频提供的语义、情感和氛围线索。我们引入了 LTX-2，这是一种开源基础模型，能够以统一的方式生成高质量、时间同步的视听内容。 LTX-2 由具有 14B 参数视频流和 5B 参数音频流的非对称双流变压器组成，通过具有时间位置嵌入的双向音频-视频交叉注意层和用于共享时间步调节的跨模态 AdaLN 进行耦合。该架构可以实现统一视听模型的高效训练和推理，同时为视频生成分配比音频生成更多的容量。我们采用多语言文本编码器来实现更广泛的及时理解，并引入模态感知的无分类器指导（模态-CFG）机制来改进视听对齐和可控性。除了生成语音之外，LTX-2 还可以生成丰富、连贯的音轨，遵循每个场景的人物、环境、风格和情感，并配有自然背景和拟音元素。在我们的评估中，该模型实现了最先进的视听质量并迅速遵守开源系统，同时以专有模型的一小部分计算成本和推理时间提供与专有模型相当的结果。所有模型权重和代码均公开发布。|[2601.03233](http://arxiv.org/abs/2601.03233)|null|\n",
        "2601.03178": "|**2026-01-06**|**DiffBench Meets DiffAgent: End-to-End LLM-Driven Diffusion Acceleration Code Generation**|扩散模型在图像和视频生成方面取得了显着的成功。然而，它们固有的多步骤推理过程会带来大量的计算开销，阻碍了现实世界的部署。因此，加速扩散模型至关重要，但确定如何结合多种模型加速技术仍然是一个重大挑战。为了解决这个问题，我们引入了一个由大型语言模型（LLM）驱动的框架，用于自动加速代码生成和评估。首先，我们介绍 DiffBench，这是一个综合基准测试，它跨不同的扩散架构、优化组合和部署场景实现了三阶段自动评估管道。其次，我们提出了 DiffAgent，一种为任意扩散模型生成最佳加速策略和代码的代理。 DiffAgent 采用闭环工作流程，其中规划组件和调试组件迭代地细化代码生成组件的输出，而遗传算法从执行环境中提取性能反馈以指导后续代码细化。我们详细解释了 DiffBench 的构造以及 DiffAgent 的设计原理。大量实验表明，DiffBench 可以对生成的代码进行全面评估，并且 DiffAgent 在生成有效的扩散加速策略方面显着优于现有的 LLM。|[2601.03178](http://arxiv.org/abs/2601.03178)|null|\n",
        "2601.02785": "|**2026-01-06**|**DreamStyle: A Unified Framework for Video Stylization**|视频风格化是视频生成模型的重要下游任务，尚未得到彻底探索。其输入样式条件通常包括文本、样式图像和样式化的第一帧。每种条件都有其独特的优势：文本更灵活，风格图像提供更准确的视觉锚点，风格化的第一帧使长视频风格化变得可行。然而，现有方法很大程度上局限于单一类型的样式条件，这限制了它们的应用范围。此外，缺乏高质量的数据集会导致风格不一致和时间闪烁。为了解决这些限制，我们引入了 DreamStyle，一个统一的视频风格化框架，支持 (1) 文本引导、(2) 风格图像引导和 (3) 第一帧引导视频风格化，并配有精心设计的数据管理管道来获取高质量的配对视频数据。 DreamStyle 基于普通图像到视频 (I2V) 模型构建，并使用低秩适应 (LoRA) 和特定于令牌的向上矩阵进行训练，以减少不同条件令牌之间的混淆。定性和定量评估都表明，DreamStyle 能够胜任所有三项视频风格化任务，并且在风格一致性和视频质量方面优于竞争对手。|[2601.02785](http://arxiv.org/abs/2601.02785)|null|\n",
        "2601.02646": "|**2026-01-06**|**DreamLoop: Controllable Cinemagraph Generation from a Single Photograph**|动态照片将静态照片与选择性循环运动相结合，具有独特的艺术吸引力。以可控的方式从单张照片生成它们尤其具有挑战性。现有的图像动画技术仅限于简单的低频运动，并且只能在具有重复纹理（例如水和烟雾）的狭窄区域中运行。相比之下，大规模视频扩散模型并非针对电影图像限制而定制，并且缺乏生成无缝、受控循环所需的专门数据。我们推出了 DreamLoop，这是一种可控视频合成框架，专用于从单张照片生成电影图片，而不需要任何电影图片训练数据。我们的关键思想是通过针对两个目标进行训练来适应通用视频扩散模型：时间桥接和运动调节。这种策略可以实现灵活的电影图像生成。在推理过程中，通过使用输入图像作为第一帧和最后一帧条件，我们强制执行无缝循环。通过调节静态轨道，我们保持静态背景。最后，通过为目标对象提供用户指定的运动路径，我们的方法提供了对动画轨迹和时间的直观控制。据我们所知，DreamLoop 是第一种通过灵活直观的控制为一般场景生成电影图像的方法。我们证明，我们的方法可以生成符合用户意图的高质量、复杂的电影图像，其性能优于现有方法。|[2601.02646](http://arxiv.org/abs/2601.02646)|null|\n",
        "2601.04194": "|**2026-01-07**|**Choreographing a World of Dynamic Objects**|物理 4D（3D + 时间）世界中的动态对象不断演化、变形并与其他对象交互，从而产生多样化的 4D 场景动态。在本文中，我们提出了一种通用生成管道 CHORD，用于 CHOReographing 动态对象和场景并合成此类现象。用于创建这些动态的传统基于规则的图形管道基于特定类别的启发式方法，但属于劳动密集型且不可扩展。最近基于学习的方法通常需要大规模数据集，这可能无法涵盖所有​​感兴趣的对象类别。相反，我们的方法通过提出基于蒸馏的管道来提取隐藏在 2D 视频的欧拉表示中的丰富拉格朗日运动信息，从而继承了视频生成模型的普遍性。我们的方法是通用的、通用的并且与类别无关。我们通过实验生成各种多体 4D 动力学来证明其有效性，展示其与现有方法相比的优势，并证明其在生成机器人操纵策略方面的适用性。项目页面：https://yanzhelyu.github.io/chord|[2601.04194](http://arxiv.org/abs/2601.04194)|null|\n",
        "2601.04153": "|**2026-01-07**|**Diffusion-DRF: Differentiable Reward Flow for Video Diffusion Fine-Tuning**|直接偏好优化 (DPO) 最近通过增强视觉保真度和文本对齐来改进文本到视频 (T2V) 的生成。然而，当前的方法依赖于来自人类注释或学习奖励模型的不可微偏好信号。这种依赖使得训练标签密集、容易出现偏差且易于博弈，这通常会引发奖励黑客攻击和不稳定的训练。我们提出了 Diffusion-DRF，这是一种可微分奖励流，用于使用冻结的现成视觉语言模型（VLM）作为免训练批评家来微调视频扩散模型。 Diffusion-DRF 通过扩散去噪链直接反向传播 VLM 反馈，将 logit 级响应转换为令牌感知梯度以进行优化。我们提出了一个自动化的、方面结构的提示管道来获得可靠的多维 VLM 反馈，而梯度检查点可以通过最终的去噪步骤实现高效的更新。 Diffusion-DRF 提高了视频质量和语义对齐，同时减轻奖励黑客攻击和崩溃——无需额外的奖励模型或偏好数据集。它与模型无关，并且很容易推广到其他基于扩散的生成任务。|[2601.04153](http://arxiv.org/abs/2601.04153)|null|\n",
        "2601.04090": "|**2026-01-07**|**Gen3R: 3D Scene Generation Meets Feed-Forward Reconstruction**|我们提出了 Gen3R，一种将基础重建模型和视频扩散模型的强大先验联系起来的方法，用于场景级 3D 生成。我们重新调整 VGGT 重建模型的用途，通过在其标记上训练适配器来产生几何潜在特征，这些标记被正则化以与预训练视频扩散模型的外观潜在特征保持一致。通过联合生成这些解开但对齐的潜在变量，Gen3R 可以生成 RGB 视频和相应的 3D 几何图形，包括相机姿势、深度图和全局点云。实验表明，我们的方法在单图像和多图像条件 3D 场景生成方面取得了最先进的结果。此外，我们的方法可以通过利用生成先验来增强重建的鲁棒性，证明了重建和生成模型紧密耦合的互惠互利。|[2601.04090](http://arxiv.org/abs/2601.04090)|null|\n",
        "2601.04068": "|**2026-01-07**|**Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models**|将文本到视频的扩散模型与人类偏好保持一致对于生成高质量视频至关重要。现有的直接偏好优化（DPO）方法依赖于多样本排序和特定于任务的批评模型，这种方法效率低下，并且经常产生模糊的全局监督。为了解决这些限制，我们提出了 LocalDPO，这是一种新颖的后训练框架，它从真实视频构建本地化偏好对并优化时空区域级别的对齐。我们设计了一个自动化管道来有效地收集偏好对数据，该数据通过每个提示进行一次推理来生成偏好对，从而消除了对外部批评家模型或手动注释的需要。具体来说，我们将高质量的真实视频视为正样本，并通过使用随机时空掩模局部破坏它们并使用冻结的基础模型仅恢复掩模区域来生成相应的负样本。在训练过程中，我们引入了区域感知 DPO 损失，将偏好学习限制在损坏区域以实现快速收敛。 Wan2.1 和 CogVideoX 上的实验表明，与其他训练后方法相比，LocalDPO 持续提高了视频保真度、时间一致性和人类偏好分数，为视频生成器对齐建立了更高效、更细粒度的范例。|[2601.04068](http://arxiv.org/abs/2601.04068)|null|\n",
        "2601.03665": "|**2026-01-07**|**PhysVideoGenerator: Towards Physically Aware Video Generation via Latent Physics Guidance**|当前的视频生成模型可以生成高质量的美学视频，但通常很难学习现实世界物理动力学的表示，从而导致诸如不自然的物体碰撞、不一致的重力和时间闪烁等伪影。在这项工作中，我们提出了 PhysVideoGenerator，这是一个概念验证框架，它将可学习的物理学先验嵌入到视频生成过程中。我们引入了一种轻量级预测器网络 PredictorP，它直接从噪声扩散潜伏中回归从预训练视频联合嵌入预测架构（V-JEPA 2）中提取的高级物理特征。这些预测的物理标记通过专用的交叉注意力机制注入到基于 DiT 的生成器 (Latte) 的时间注意力层中。我们的主要贡献是证明了这种联合训练范例的技术可行性：我们证明扩散潜伏包含足够的信息来恢复 V-JEPA 2 物理表示，并且多任务优化在训练过程中保持稳定。该报告记录了架构设计、技术挑战和训练稳定性验证，为未来大规模评估物理感知生成模型奠定了基础。|[2601.03665](http://arxiv.org/abs/2601.03665)|null|\n",
        "2601.03655": "|**2026-01-07**|**VideoMemory: Toward Consistent Video Generation via Memory Integration**|在多个镜头中保持一致的角色、道具和环境是叙事视频生成的主要挑战。现有模型可以生成高质量的短片，但当场景发生变化或实体在长时间间隔后重新出现时，通常无法保留实体的身份和外观。我们提出了 VideoMemory，一个以实体为中心的框架，通过动态内存库将叙事规划与视觉生成集成在一起。给定结构化脚本，多智能体系统将叙述分解为镜头，从内存中检索实体表示，并根据这些检索到的状态合成关键帧和视频。动态内存库存储角色、道具和背景的明确视觉和语义描述符，并在每次拍摄后进行更新，以反映故事驱动的变化，同时保留身份。这种检索更新机制可以对远处镜头中的实体进行一致的描绘，并支持连贯的长格式生成。为了评估此设置，我们构建了一个 54 例多镜头一致性基准，涵盖角色、道具和背景持续场景。大量实验表明，VideoMemory 在不同的叙事序列中实现了强大的实体级连贯性和高感知质量。|[2601.03655](http://arxiv.org/abs/2601.03655)|null|\n"
    },
    "3D": {
        "2601.00796": "|**2026-01-02**|**AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction**|从单目视频重建动态 3D 场景需要同时捕获高频外观细节和时间连续运动。使用单个高斯原语的现有方法受到其低通滤波性质的限制，而标准 Gabor 函数会引入能量不稳定。此外，缺乏时间连续性约束通常会导致插值期间出现运动伪影。我们提出了 AdaGaR，一个统一的框架，解决显式动态场景建模中的频率自适应性和时间连续性问题。我们引入了自适应 Gabor 表示，通过可学习的频率权重和自适应能量补偿来扩展高斯模型，以平衡细节捕捉和稳定性。为了实现时间连续性，我们采用具有时间曲率正则化的三次 Hermite 样条来确保平滑的运动演化。结合深度估计、点跟踪和前景掩模的自适应初始化机制在早期训练中建立稳定的点云分布。 Tap-Vid DAVIS 上的实验展示了最先进的性能（PSNR 35.49、SSIM 0.9433、LPIPS 0.0723）以及跨帧插值、深度一致性、视频编辑和立体视图合成的强大泛化能力。项目页面：https://jiewenchan.github.io/AdaGaR/|[2601.00796](http://arxiv.org/abs/2601.00796)|null|\n",
        "2601.00702": "|**2026-01-02**|**DefVINS: Visual-Inertial Odometry for Deformable Scenes**|可变形场景违反了支撑经典视觉惯性里程计 (VIO) 的刚性假设，当变形主导视觉视差时，通常会导致局部非刚性运动过度拟合或严重漂移。我们引入了 DefVINS，一种视觉惯性里程计框架，它明确地将刚性、IMU 锚定状态与由嵌入变形图表示的非刚性扭曲分开。该系统使用标准 VIO 程序进行初始化，该程序修复了重力、速度和 IMU 偏差，之后随着估计的条件良好，逐渐激活非刚性自由度。包括可观测性分析，以描述惯性测量如何限制刚性运动，并在存在变形的情况下使其他不可观测的模式变得可识别。该分析促进了 IMU 锚定的使用，并为基于条件的激活策略提供了信息，该策略可防止不良激励下的不适定更新。烧蚀研究证明了将惯性约束与可观察性变形激活相结合的好处，从而提高了非刚性环境下的鲁棒性。|[2601.00702](http://arxiv.org/abs/2601.00702)|null|\n",
        "2601.00678": "|**2026-01-02**|**Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians**|人类擅长仅凭一张图像来预测场景的未来动态。能够模仿这种能力的视频生成模型是智能系统的重要组成部分。最近的方法提高了单图像条件视频生成中的时间相干性和 3D 一致性。然而，这些方法通常缺乏强大的用户可控性，例如修改相机路径，限制了它们在实际应用中的适用性。大多数现有的相机控制的图像到视频模型都难以准确建模相机运动、保持时间一致性和保持几何完整性。利用显式中间 3D 表示可实现与给定摄像机轨迹对齐的连贯视频生成，从而提供了一种有前景的解决方案。尽管这些方法通常使用 3D 点云来渲染场景并在后期引入对象运动，但尽管允许精确控制相机运动，但这种两步过程仍然无法实现完全的时间一致性。我们提出了一种新颖的框架，在单次前向传递中给定单个图像的情况下，构建 3D 高斯场景表示并对合理的对象运动进行采样。这使得能够快速生成相机引导的视频，而无需迭代去噪将对象运动注入渲染帧。在 KITTI、Waymo、RealEstate10K 和 DL3DV-10K 数据集上进行的大量实验表明，我们的方法实现了最先进的视频质量和推理效率。该项目页面位于 https://melonienimasha.github.io/Pixel-to-4D-Website。|[2601.00678](http://arxiv.org/abs/2601.00678)|null|\n",
        "2601.00599": "|**2026-01-02**|**The thermodynamics of pressure activated assembly of supramolecules in isochoric and isobaric systems**|冷冻保存的功效受到难以获得足够高的细胞内冷冻保护溶质浓度而不在加载过程中引起渗透损伤或化学毒性的限制。这项热力学研究引入了一种将冷冻保护剂直接或通过血管灌注输送到细胞中的新概念机制。在此框架中，通过压力激活由冷冻保护剂单体或低聚物组成的膜渗透超分子组装体的分解，原位产生高浓度的细胞内冷冻保护溶质，可以实现有效的冷冻保护。这些超分子最初以低浓度存在，预计通过被动分配或内吞作用以最小的渗透效应进入细胞，并随后在分解时转化为高细胞内浓度的冷冻保护剂。我们提出，在等容（恒定体积）冷冻过程中固有产生的或在等压（恒定压力）条件下外部施加的升高的静水压力可以使超分子组装体不稳定，其解离状态所占的摩尔体积比组装状态的摩尔体积更小。在等容冷冻下，固定体积内的冰形成会产生显着的压力增加，这是相变的热力学结果，使压力成为由亥姆霍兹自由能控制的因变量。在等压条件下，压力通过吉布斯自由能充当外部控制变量。在这两种配方中，压力激活的分解将膜传输与冷冻保护剂的可用性分离，并能够在冷却或冷冻过程中精确地同步溶质生成，而无需预加载渗透活性溶质。|[2601.00599](http://arxiv.org/abs/2601.00599)|null|\n",
        "2601.00583": "|**2026-01-02**|**HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts**|虽然联邦学习 (FL) 可以在不损害数据隐私的情况下对大型语言模型 (LLM) 进行微调，但 LLM 的庞大规模使得设备上培训对于资源受限的客户端（例如移动设备）来说不切实际。因此，专家混合（MoE）模型已成为一种计算高效的解决方案，它在模型训练期间仅激活稀疏的专家子集，以在不牺牲性能的情况下减轻计算负担。尽管将 MoE 集成到 FL 微调中具有巨大的潜力，但它仍然面临三个关键挑战：i）为客户选择合适的专家仍然具有挑战性，因为缺乏可靠的指标来衡量每个专家对本地微调性能的影响，ii）跨客户端的异构计算资源严重阻碍了基于 MoE 的 LLM 微调，因为跨不同输入样本的动态专家激活可能会压垮资源受限的设备，以及 iii）特定于客户端的专家子集和路由偏好会破坏全局聚合，其中未对齐专家更新和不一致的门控网络会产生破坏性干扰。为了应对这些挑战，我们提出了 HFedMoE，这是一种基于 MoE 的异构 FL 微调框架，可为每个客户定制专家子集，以实现计算高效的 LLM 微调。具体来说，HFedMoE 根据专家对微调性能的贡献来识别专家的重要性，然后从信息瓶颈的角度自适应地选择专家子集，以与每个客户端的计算预算保持一致。稀疏感知模型聚合策略还旨在聚合主动微调的专家和具有重要性加权贡献的门控参数。大量实验表明 HFedMoE 在训练精度和收敛速度方面优于最先进的基准。|[2601.00583](http://arxiv.org/abs/2601.00583)|null|\n",
        "2601.00552": "|**2026-01-02**|**Tabletop X-ray ghost video of moving objects**|X射线成像广泛应用于临床医学、工业检测和各种科学研究领域。不幸的是，目前使用的大多数 X 射线二维 (2D) 探测器都存在像素数量和读出时间之间的根本权衡问题，这使得它们不适合快速移动物体成像，并且读出死区时间会导致帧丢失。 X 射线重影成像 (XGI) 提供了一种仅使用高灵敏度单像素探测器对物体进行成像的替代方法。然而，现有 XGI 方法的一个关键限制是所需的总采集时间过长，这使得它对于实际应用来说不切实际。在本文中，我们提出了一种基于编码到快速旋转掩模上的随机二进制模式的快速空间调制方案。以高达每秒 200 帧的成像速率和 225 微米的分辨率展示了移动物体的清晰 X 射线可视化。我们的方法首次大大提高了XGI成像速度，为运动物体的X射线成像应用铺平了道路，例如旋转航空发动机的检查和体内医学成像。|[2601.00552](http://arxiv.org/abs/2601.00552)|null|\n",
        "2601.00541": "|**2026-01-02**|**Asymptotic Distribution-Free Tests for Ultra-high Dimensional Parametric Regressions via Projected Empirical Processes and $p$-value Combination**|本文开发了一种基于预测经验过程和 p 值组合来测试稀疏参数回归模型拟合优度的新颖方法，其中协变量维度可能大大超过样本大小。在这种超高维设置中，传统的基于经验过程的检验常常会失败，因为维数灾难或它们对参数估计量的渐近线性和正态性的依赖——这些属性在超高维场景下可能不成立。为了克服这些挑战，我们首先将经典的鞅变换扩展到温和条件下的超高维设置，并基于对单位球体上的任何投影的鞅变换、投影残差标记经验过程构建 Cramer-von Mises 类型检验。鞅变换使该投影检验渐近无分布，并使我们能够仅使用参数估计器的标准收敛率导出其极限分布。虽然在温和条件下，单位球体上的几乎所有投影的投影测试都是一致的，但它仍然可能会遭受特定投影的功率损失。因此，我们进一步采用强大的 p 值组合程序（例如柯西组合）来聚合多个预测的 p 值，从而增强整体稳健性。此外，认识到基于经验过程的测试擅长检测低频信号，而局部平滑测试通常优于高频信号，因此我们提出了一种新颖的混合测试，使用柯西组合聚合这两种方法。由此产生的混合测试对于低频和高频替代方案都很有效。 $\\cdots$|[2601.00541](http://arxiv.org/abs/2601.00541)|null|\n",
        "2601.00535": "|**2026-01-02**|**FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection**|大规模文本到图像（T2I）扩散模型擅长开放域合成，但在精确文本渲染方面仍然存在困难，特别是对于多行布局、密集排版和中文等长尾脚本。先前的解决方案通常需要昂贵的再培训或严格的外部布局限制，这会降低美观性并限制灵活性。我们提出了 \\textbf{FreeText}，这是一种免训练、即插即用的框架，它通过利用 \\emph{Diffusion Transformer (DiT)} 模型的内在机制来改进文本渲染。 \\textbf{FreeText} 将问题分解为 \\emph{写在哪里} 和 \\emph{写什么}。对于 \\emph{where to write}，我们通过从内生图像到文本注意力中读取标记方式的空间属性来定位写入区域，使用类似接收器的标记作为稳定的空间锚点和拓扑感知的细化来生成高置信度的掩模。对于\\emph{写什么}，我们引入了频谱调制字形注入（SGMI），它通过频域带通调制先注入噪声对齐的字形，以加强字形结构并抑制语义泄漏（呈现概念而不是单词）。在 longText-Benchmark、CVTG 和我们的 CLT-Bench 上对 Qwen-Image、FLUX.1-dev 和 SD3 变体进行的广泛实验表明，文本可读性得到了一致的提高，同时在很大程度上保留了语义对齐和美学质量，并且推理开销适中。|[2601.00535](http://arxiv.org/abs/2601.00535)|null|\n",
        "2601.01800": "|**2026-01-05**|**Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving**|强化学习 (RL) 在自动驾驶 (AD) 领域显示出巨大的潜力，但其易受扰动的影响仍然是现实世界部署的关键障碍。作为主要对策，对抗性训练通过在对手故意引入扰动的情况下训练 AD 代理来提高策略的稳健性。现有方法通常将交互建模为具有连续攻击的零和游戏。然而，此类设计忽视了代理和对手之间固有的不对称性，无法反映安全关键风险的稀疏性，导致所实现的鲁棒性不足以满足实际的 AD 场景。为了解决这些限制，我们引入了关键性感知的鲁棒强化学习（CARRL），这是一种新颖的对抗性训练方法，用于处理自动驾驶中稀疏的、安全关键的风险。 CARRL 由两个相互作用的部分组成：风险暴露对手 (REA) 和风险目标稳健代理 (RTRA)。我们将 REA 和 RTRA 之间的交互建模为一般和游戏，使 REA 能够专注于暴露安全关键型故障（例如碰撞），而 RTRA 则学会平衡安全性与驾驶效率。 REA 采用解耦优化机制，在预算有限的情况下更好地识别和利用稀疏的安全关键时刻。然而，这种集中攻击不可避免地导致对抗性数据的缺乏。 RTRA 通过双重重放缓冲区共同利用良性和对抗性体验来应对这种稀缺性，并在扰动下强制执行政策一致性以稳定行为。实验结果表明，与最先进的基线方法相比，我们的方法在所有情况下将碰撞率降低了至少 22.66%。|[2601.01800](http://arxiv.org/abs/2601.01800)|null|\n",
        "2601.01784": "|**2026-01-05**|**DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization**|AIGC 技术的快速发展可以通过篡改视频中的小片段来误导观众，从而导致视频级检测不准确且缺乏说服力。因此，旨在精确定位被篡改片段的时间伪造定位（TFL）变得至关重要。然而，现有的方法往往受到\\emph{局部视图}的限制，无法捕获全局异常。为了解决这个问题，我们提出了一个用于时间伪造定位的 \\underline{d} 双流图学习和 \\underline{d}isentanglement 框架（DDNet）。通过协调局部工件的\\emph{时间距离流}和用于远程连接的\\emph{语义内容流}，DDNet 可以防止全局线索被局部平滑性淹没。此外，我们引入了跟踪解缠结和适应（TDA）来隔离通用伪造指纹，并引入跨级特征嵌入（CLFE）来通过层次特征的深度融合构建强大的特征基础。 ForgeryNet 和 TVIL 基准测试表明，我们的方法在 AP@0.95 中比最先进的方法性能高出约 9%，并且跨域鲁棒性显着提高。|[2601.01784](http://arxiv.org/abs/2601.01784)|null|\n",
        "2601.01749": "|**2026-01-05**|**MANGO:Natural Multi-speaker 3D Talking Head Generation via 2D-Lifted Enhancement**|目前音频驱动的3D头部生成方法主要针对单扬声器场景，缺乏自然、双向的听和说交互。实现无缝对话行为（即说和听状态的流畅转换）仍然是一个关键挑战。现有的 3D 对话化身方法依赖于容易出错的伪 3D 标签，无法捕捉细粒度的面部动态。为了解决这些限制，我们引入了一种新颖的两阶段框架 MANGO，它通过交替训练来利用纯图像级监督来减轻伪 3D 标签引入的噪声，从而实现与现实世界对话行为的更好对齐。具体来说，在第一阶段，带有双音频交互模块的基于扩散的变压器对多扬声器音频的自然 3D 运动进行建模。在第二阶段，我们使用快速 3D 高斯渲染器生成高保真图像，并通过交替训练为 3D 运动提供 2D 级光度监控。此外，我们还推出了 MANGO-Dialog，这是一个高质量的数据集，包含 500 多个身份的超过 50 小时的对齐 2D-3D 对话数据。大量实验表明，我们的方法在模拟两人 3D 对话运动方面实现了卓越的准确性和真实性，显着提高了音频驱动头部说话的保真度和可控性。|[2601.01749](http://arxiv.org/abs/2601.01749)|null|\n",
        "2601.01731": "|**2026-01-05**|**A generalized Scharfetter-Gummel scheme for nonlocal cross-diffusion systems**|分析了多维环面上非局域交叉扩散系统的隐式欧拉有限体积格式。这些方程描述了具有排斥或吸引相互作用的种群物种的动态。该数值方案基于非局部通量项的广义 Scharfetter-Gummel 离散化。对于仅可积的核函数，该方案保留了正性、总质量和熵结构。当网格尺寸趋于零时，显示了离散解的存在性及其对连续问题解的收敛性。一个关键的困难是 Scharfetter-Gummel 近似中广义伯努利函数的简并性。这个问题可以通过证明离散费舍尔信息的统一估计来克服，这需要玻尔兹曼和拉奥熵不等式。数值模拟在一维和二维空间维度上说明了该方案的特征。|[2601.01731](http://arxiv.org/abs/2601.01731)|null|\n",
        "2601.01660": "|**2026-01-04**|**Animated 3DGS Avatars in Diverse Scenes with Consistent Lighting and Shadows**|我们提出了一种在动画 3D 高斯泼溅 (3DGS) 头像与 3DGS 场景或与插入静态场景中的动态对象交互时实现一致光照和阴影的方法。我们的主要贡献是深度高斯阴影贴图 (DGSM)，它是经典阴影贴图算法的现代模拟，专为体积 3DGS 表示而定制。基于经典的深度阴影映射思想，我们证明 3DGS 允许沿着光线进行封闭形式的光累积，从而无需网格化即可实现体积阴影计算。对于每个估计的光，我们将同心径向壳上的透射率制成表格，并将其存储在八面体图集中，现代 GPU 可以根据查询实时采样，以减弱受影响的场景高斯分布，从而一致地投射和接收阴影。为了重新照亮移动的头像，我们使用以球谐函数 (SH) 为基础表示的 HDRI 探针来近似局部环境照明，并应用快速每高斯辐射率传输，避免显式 BRDF 估计或离线优化。我们演示了来自 AvatarX 和 ActorsHQ 的化身的环境一致照明，合成到 ScanNet++、DL3DV 和 SuperSplat 场景中，并展示了与插入对象的交互。在单个和多个头像设置中，DGSM 和 SH 重新照明完全在体积 3DGS 表示中运行，产生连贯的阴影和重新照明，同时避免网格化。|[2601.01660](http://arxiv.org/abs/2601.01660)|null|\n",
        "2601.01618": "|**2026-01-04**|**Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation**|长视距机器人操作对于现实世界的部署越来越重要，需要复杂布局中的空间消歧和动态交互下的时间弹性。然而，现有的端到端和分层的视觉-语言-行动（VLA）策略通常依赖于纯文本线索，同时保持计划意图的潜在性，这破坏了杂乱或未指定场景中的参考基础，阻碍了通过闭环交互对长期目标进行有效的任务分解，并通过模糊行动选择背后的基本原理来限制因果解释。为了解决这些问题，我们首先引入 Visual Sketch，这是一种令人难以置信的视觉中间体，可以在机器人当前视图中渲染点、框、箭头和类型化关系，以外部化空间意图，将语言与场景几何连接起来。在 Visual Sketch 的基础上，我们提出了 Action-Sketcher，这是一个 VLA 框架，它在循环的 See-Think-Sketch-Act 工作流程中运行，并通过自适应令牌门控策略进行协调，用于推理触发器、草图修订和动作发布，从而支持反应性校正和人类交互，同时保留实时动作预测。为了实现可扩展的训练和评估，我们利用交错的图像、文本、视觉草图监督和动作序列来策划不同的语料库，并使用多阶段课程方案来训练 Action-Sketcher，该课程方案结合了用于模态统一的交错序列对齐、用于精确语言基础的语言到草图的一致性、以及通过草图到动作强化来增强鲁棒性的模仿学习。对杂乱场景和多对象任务、模拟和现实世界任务进行的大量实验表明，长期成功率有所提高，对动态场景变化的鲁棒性更强，并且通过可编辑草图和逐步计划增强了可解释性。项目网站：https://action-sketcher.github.io|[2601.01618](http://arxiv.org/abs/2601.01618)|null|\n",
        "2601.01433": "|**2026-01-04**|**Adaptive finite difference methods for the Willmore flow: mesh redistribution algorithm and tangential velocity approach**|我们开发了两种自适应有限差分方法用于威尔莫尔流的数值模拟，采用 k 阶后向微分公式 (BDFk) 进行时间离散化，并结合沿演化界面进行动态网格自适应的监控函数。第一种方法基于由监控函数驱动的加权弧长均匀分布策略，以自适应地重新分布网格点。由曲率及其变化构建的自适应监视器选择机制增强了几何复杂性较强的区域的空间分辨率，同时保留了网格规律性。第二种方法通过将切向速度合并到威尔莫尔流中来消除显式重新参数化，并将网格重新分布固有地嵌入到几何演化中。我们进一步为第二种方法开发了能量稳定校正算法，以在理论层面保证离散能量稳定性。在这两种方法中，监控功能都是自适应框架的核心组件，对基本的几何信息（例如曲率和曲率变化）进行编码，以指导网格细化和重新分布。大量数值实验表明，所提出的基于 BDFk 的自适应方案能够准确捕获 Willmore 流的几何演化，并对涉及复杂界面几何形状的问题表现出出色的鲁棒性和计算效率。|[2601.01433](http://arxiv.org/abs/2601.01433)|null|\n",
        "2601.00939": "|**2026-01-04**|**ShadowGS: Shadow-Aware 3D Gaussian Splatting for Satellite Imagery**|3D 高斯分布 (3DGS) 已成为卫星图像 3D 重建的一种新颖范例。然而，在多时相卫星图像中，由于光照条件的变化，普遍存在的阴影表现出明显的不一致。为了解决这个问题，我们提出了 ShadowGS，一种基于 3DGS 的新颖框架。它利用遥感基于物理的渲染方程，结合高效的光线行进技术，精确建模几何一致的阴影，同时保持高效的渲染。此外，它还可以有效地分解场景中的不同照明组件和明显属性。此外，我们引入了阴影一致性约束，显着提高了 3D 重建的几何精度。我们还结合了一种新颖的阴影贴图，以提高稀疏视图输入的性能。大量实验表明，ShadowGS 只需几分钟的训练，就在阴影解耦精度、3D 重建精度和新颖的视图合成质量方面优于当前最先进的方法。 ShadowGS 在各种设置下表现出强大的性能，包括 RGB、全色锐化和稀疏视图卫星输入。|[2601.00939](http://arxiv.org/abs/2601.00939)|null|\n",
        "2601.01298": "|**2026-01-03**|**Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware**|当前的多智能体大型语言模型 (LLM) 框架受到线性内存扩展的影响，导致“系统 2”并行推理在消费类硬件上不切实际。我们提出了 Warp Cortex，这是一种异步架构，理论上可以通过将代理逻辑与物理内存解耦来实现百万代理认知扩展。通过单例权重共享和新颖的拓扑突触（受到拓扑数据分析 (TDA) 的混合标志技术的启发），我们将权重的内存复杂度从 O(N * L) 降低到 O(1)，上下文的 O(N * k)，其中 k << L。通过将 KV 缓存视为潜在空间中的点云，我们应用见证复合体启发的稀疏化来保留上下文流形的持久同源特征。在单个 NVIDIA RTX 4090 上，我们凭经验演示了 2.2 GB 总 VRAM 下的 100 个并发代理，在计算延迟成为瓶颈之前理论容量超过 1,000 个代理。我们进一步介绍了引用注入，这是一种非侵入式 KV 缓存更新机制，允许异步子代理在不中断流的情况下影响主生成。|[2601.01298](http://arxiv.org/abs/2601.01298)|null|\n",
        "2601.01288": "|**2026-01-03**|**PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS**|基于像素的强化学习通常受到 3D 渲染环境的性能和复杂性的瓶颈。研究人员面临着高速、低级引擎和速度较慢、更易于访问的 Python 框架之间的权衡。为了解决这个问题，我们引入了 PyBatchRender，这是一个用于高吞吐量、批量 3D 渲染的 Python 库，可在简单场景上实现超过 100 万帧每秒 (FPS)。它基于 Panda3D 游戏引擎构建，利用其成熟的生态系统，同时通过优化的批量渲染来提高性能，加速速度高达 1000 倍。 PyBatchRender 被设计为与物理无关的渲染器，用于从像素进行强化学习，比专用库提供更大的灵活性，比典型游戏引擎包装器更简单的设置，并且速度可与 Madrona 等最先进的 C++ 引擎相媲美。用户可以使用数十行代码完全使用 Python 创建自定义场景，从而实现可扩展 AI 训练的快速原型设计。它开源且易于集成，有助于研究人员和开发人员实现高性能 3D 仿真的民主化。该库位于 https://github.com/dolphin-in-a-coma/PyBatchRender。|[2601.01288](http://arxiv.org/abs/2601.01288)|null|\n",
        "2601.02352": "|**2026-01-05**|**On the temperature of the quantum black hole**|广义相对论的一个重要特点是，当黑洞的视界区域变得无害时，其外部就会加倍，从而产生一个因果上不相连的平行宇宙。这种复杂性在特霍夫特的统一性论证中发挥着核心作用，强调物理宇宙与其在地平线另一边的复制品之间的精确识别。然而，这导致了另一种张力，即霍金温度的两倍校正。这种差异令人担忧，因为林德勒温度是通用的并且符合贝肯斯坦-霍金熵。我们证明，如果形成相应密度矩阵的状态采用广义热场双结构，则玻尔兹曼因子的失配得到修复。这为一些有趣的讨论留下了空间。|[2601.02352](http://arxiv.org/abs/2601.02352)|null|\n",
        "2601.02339": "|**2026-01-05**|**Joint Semantic and Rendering Enhancements in 3D Gaussian Modeling with Anisotropic Local Encoding**|最近的工作提出使用语义特征向量扩展 3DGS，以实现同步语义分割和图像渲染。然而，这些方法通常单独处理语义和渲染分支，仅依赖 2D 监督而忽略 3D 高斯几何。此外，当前的自适应策略仅根据渲染梯度来调整高斯集，这在微妙或无纹理区域中可能是不够的。在这项工作中，我们提出了一个用于 3D 语义高斯建模的联合增强框架，该框架可以协同语义和渲染分支。首先，与传统的点云形状编码不同，我们引入了使用 Laplace-Beltrami 算子的各向异性 3D 高斯切比雪夫描述符来捕获细粒度的 3D 形状细节，从而区分具有相似外观的对象并减少对潜在噪声 2D 引导的依赖。此外，我们不只依赖渲染梯度，而是利用局部语义和形状信号自适应地调整高斯分配和球谐函数，通过选择性资源分配来提高渲染效率。最后，我们采用跨场景知识转移模块来持续更新学习的形状模式，从而实现更快的收敛和稳健的表示，而无需从头开始为每个新场景重新学习形状信息。对多个数据集的实验表明，在保持高渲染帧速率的同时，分割精度和渲染质量有所提高。|[2601.02339](http://arxiv.org/abs/2601.02339)|null|\n",
        "2601.02305": "|**2026-01-05**|**On Statistical Inference for Rates of Change in Spatial Processes over Riemannian Manifolds**|从部分实现或分散的数据进行空间过程的统计推断已经在从环境科学到商业和经济学的各个领域取得了巨大的发展。对相关变化率的推断最近取得了一些进展。文献仅限于欧几里得领域，其中寻求对任意位置的方向导数、沿着选定的感兴趣方向的速率进行推断。事实证明，在这些设置中，高阶率（特别是方向曲率）的推断也很有用。现代空间数据通常来自非欧几里得领域。这份手稿特别考虑了在紧凑黎曼流形上定义的空间过程。我们为矢量场上此类过程的空间变化率开发了一个全面的推理框架。在此过程中，我们形式化了过程实现的平滑性并构造了微分过程——导数和曲率过程。我们推导出确保这些过程存在的核条件，并建立由流形上的“父”高斯过程（GP）和相关微分过程组成的联合多元过程的有效性。对这些速率的预测推断是根据流形上的实现过程设计的。在实践中，流形以多面体网格的形式出现。我们的模拟实验成功地评估了在此类网格上观察到的过程的导数，验证了我们的理论发现。通过增强我们对流形上的 GP 的理解，这份手稿解锁了 GP 广泛使用的机器学习和统计学中的各种潜在应用。我们提出了一种完全基于模型的方法，用于根据流形上分散位置的部分观察或实现的数据来推断空间过程所产生的微分过程。|[2601.02305](http://arxiv.org/abs/2601.02305)|null|\n",
        "2601.02281": "|**2026-01-05**|**InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams**|实现持久、大规模 3D 视觉几何理解的宏伟愿景受到可扩展性和长期稳定性的不可调和的需求的束缚。虽然像 VGGT 这样的离线模型实现了鼓舞人心的几何功能，但它们基于批处理的性质使它们与实时系统无关。流媒体架构虽然是实时操作的预期解决方案，但已被证明是不够的。现有方法要么无法支持真正的无限范围输入，要么遭受长序列的灾难性漂移。我们用 InfiniteVGGT 打破了这个长期存在的困境，InfiniteVGGT 是一种因果视觉几何变换器，通过有界但自适应且永久表达的 KV 缓存来操作滚动内存的概念。利用这一点，我们设计了一种无需训练、与注意力无关的修剪策略，可以智能地丢弃过时的信息，有效地在每个新帧中“滚动”记忆。 InfiniteVGGT 与 FlashAttention 完全兼容，最终缓解了这种妥协，实现了无限范围的流式传输，同时在长期稳定性方面优于现有的流式传输方法。对这样一个系统的最终测试是其在真正无限范围内的性能，由于缺乏极其长期、连续的基准，这种能力不可能得到严格验证。为了解决这一关键差距，我们引入了 Long3D 基准，该基准首次能够对大约 10,000 帧的序列进行连续 3D 几何估计的严格评估。这为长期 3D 几何理解的未来研究提供了明确的评估平台。代码位于：https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT|[2601.02281](http://arxiv.org/abs/2601.02281)|null|\n",
        "2601.02267": "|**2026-01-05**|**DiffProxy: Multi-View Human Mesh Recovery via Diffusion-Generated Dense Proxies**|从多视图图像中恢复人体网格面临着一个根本性的挑战：现实世界的数据集包含不完美的真实注释，这会影响模型的训练，而具有精确监督的合成数据则受到域差距的影响。在本文中，我们提出了 DiffProxy，这是一种新颖的框架，可以生成用于网格恢复的多视图一致的人类代理。 DiffProxy 的核心是利用基于扩散的生成先验来连接综合训练和现实世界的泛化。其主要创新包括：（1）用于生成多视图一致、像素对齐的人体代理的多条件机制； （2）手部细化模块，结合灵活的视觉提示，增强局部细节； (3) 一种不确定性感知测试时间缩放方法，可提高优化过程中对挑战性情况的鲁棒性。这些设计确保网格恢复过程有效地受益于基于扩散的管道的精确合成地面实况和生成优势。 DiffProxy 完全基于合成数据进行训练，在五个现实世界基准测试中实现了最先进的性能，展示了强大的零样本泛化能力，特别是在具有遮挡和部分视图的挑战性场景上。项目页面：https://wrk226.github.io/DiffProxy.html|[2601.02267](http://arxiv.org/abs/2601.02267)|null|\n",
        "2601.02211": "|**2026-01-05**|**Unraveling MMDiT Blocks: Training-free Analysis and Enhancement of Text-conditioned Diffusion**|基于变压器的扩散模型的最新突破，特别是多模态扩散变压器 (MMDiT) 驱动的模型（如 FLUX 和 Qwen Image），促进了文本到图像生成和编辑方面令人兴奋的体验。为了理解基于 MMDiT 的模型的内部机制，现有方法试图分析位置编码和注意力层等特定组件的效果。然而，对不同块及其与文本条件的相互作用如何促进合成过程的全面理解仍然难以实现。在本文中，我们首先开发一个系统管道，通过删除、禁用和增强相应块的文本隐藏状态来全面研究每个块的功能。我们的分析表明，1）语义信息出现在较早的块中，更精细的细节在后面的块中呈现，2）删除特定块通常比禁用文本条件的破坏性更小，3）增强选择性块中的文本条件可以改善语义属性。基于这些观察，我们进一步提出了新颖的免训练策略，以改进文本对齐、精确编辑和加速。大量的实验表明，我们的方法优于各种基线，并且在文本到图像生成、图像编辑和推理加速方面保持灵活性。我们的方法在 SD3.5 上将 T2I-Combench++ 从 56.92% 提高到 63.00%，将 GenEval 从 66.42% 提高到 71.63%，而不会牺牲合成质量。这些结果促进了对 MMDiT 模型的理解，并提供了宝贵的见解，以释放进一步改进的新可能性。|[2601.02211](http://arxiv.org/abs/2601.02211)|null|\n",
        "2601.02202": "|**2026-01-05**|**Density-based topology optimization for turbulent fluid flow using the standard k-epsilon RANS model with wall-functions imposed through an implicit wall penalty formulation**|湍流对边界附近的网格要求很高，以保证精度。在拓扑优化 (TO) 的背景下，如此精细的网格变得不切实际，并且通用方法因精度低和边界层厚度高估而受到阻碍。壁函数是缓解计算要求的自然方法，但由于分散的设计参数化，它们并不是自然地强加在基于密度的 TO 中。我们提出了雷诺平均纳维斯托克斯 (RANS) 的隐式壁函数公式，这是标准 k-epsilon 模型，直接从设计变量的梯度中提取壁法线信息，并启用基于惩罚的公式，将壁函数强加到 RANS 方程中，而不需要贴体网格。该方法为高雷诺数湍流拓扑优化提供了可靠的途径，提供了与显式壁体拟合分析相当的边界层精度，同时保留了基于密度的 TO 的灵活性。此外，由于壁效应是使用壁函数建模的，因此可以在较粗糙的网格上获得准确的解，从而显着降低计算成本。该方法在雷诺数高达 Re = 2e5 的三个规范基准上进行了验证：弯管； U 形弯头；和特斯拉阀门。在所有情况下，所提出的方法都能准确地恢复近壁速度剖面，与具有显式壁函数的贴体网格的验证模拟紧密匹配。相比之下，传统的湍流 TO 公式如果没有建议的壁函数处理，会错误地预测边界层的发展并产生次优结果。|[2601.02202](http://arxiv.org/abs/2601.02202)|null|\n",
        "2601.02144": "|**2026-01-05**|**Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts**|专家混合 (MoE) 架构通过使用参数“路由器”将令牌分派给稀疏的专家子集，有效地扩展大型语言模型。通常，该路由器经过一次训练，然后就被冻结，导致路由决策在分布变化时变得脆弱。我们通过引入 kNN-MoE 来解决这一限制，kNN-MoE 是一种检索增强的路由框架，可重用来自过去类似案例记忆的最佳专家分配。该内存是通过直接优化 token-wise 路由 logits 来离线构建的，以最大化参考集的可能性。至关重要的是，我们使用检索到的邻居的聚合相似度作为置信驱动的混合系数，从而允许该方法在没有找到相关情况时回退到冻结路由器。实验表明 kNN-MoE 的性能优于零样本基线，并且可以与计算成本高昂的监督微调相媲美。|[2601.02144](http://arxiv.org/abs/2601.02144)|null|\n",
        "2601.02103": "|**2026-01-05**|**HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures**|最近基于 3D Gaussian Splatting 的 3D 感知头部生成模型实现了实时、真实感和视图一致的头部合成。然而，一个根本的限制仍然存在：照明和内在外观的深度纠缠阻碍了可控的重新照明。现有的解缠结方法依赖于强假设来实现弱监督学习，这限制了它们复杂照明的能力。为了应对这一挑战，我们引入了 HeadLighter，这是一种新颖的监督框架，可以学习头部生成模型中外观和照明的物理合理分解。具体来说，我们设计了一个双分支架构，分别对光照不变的头部属性和物理接地的渲染组件进行建模。采用渐进式解缠结训练将头部外观先验逐渐注入生成架构中，并通过在受控光照条件下使用光舞台设置捕获的多视图图像进行监督。我们进一步引入了一种蒸馏策略来生成用于真实渲染的高质量法线。实验表明，我们的方法保留了高质量的生成和实时渲染，同时支持显式照明和视点编辑。我们将公开发布我们的代码和数据集。|[2601.02103](http://arxiv.org/abs/2601.02103)|null|\n",
        "2601.02102": "|**2026-01-05**|**360-GeoGS: Geometrically Consistent Feed-Forward 3D Gaussian Splatting Reconstruction for 360 Images**|3D 场景重建是 AR、机器人和数字孪生等空间智能应用的基础。传统的多视图立体与稀疏视点或低纹理区域作斗争，而神经渲染方法虽然能够产生高质量的结果，但需要每个场景的优化并且缺乏实时效率。显式 3D 高斯分布 (3DGS) 可实现高效渲染，但大多数前馈变体侧重于视觉质量而不是几何一致性，从而限制了空间感知任务中准确的表面重建和整体可靠性。本文提出了一种新颖的 360 度图像前馈 3DGS 框架，能够生成几何一致的高斯图元，同时保持高渲染质量。引入深度法线几何正则化，将渲染的深度梯度与法线信息结合起来，监督高斯旋转、缩放和位置，以提高点云和表面精度。实验结果表明，该方法在保持较高渲染质量的同时显着提高了几何一致性，为空间感知任务中的3D重建提供了有效的解决方案。|[2601.02102](http://arxiv.org/abs/2601.02102)|null|\n",
        "2601.03256": "|**2026-01-06**|**Muses: Designing, Composing, Generating Nonexistent Fantasy 3D Creatures without Training**|我们推出了 Muses，这是第一个无需训练的方法，可以在前馈范式中生成奇妙的 3D 生物。以前的方法依赖于零件感知优化、手动组装或 2D 图像生成，由于复杂的零件级操作和有限的域外生成的挑战，通常会产生不切实际或不连贯的 3D 资产。相比之下，Muses 利用 3D 骨架（生物形态的基本表示）来明确、合理地组成不同的元素。这个骨架基础将 3D 内容创建形式化为设计、合成和生成的结构感知管道。 Muses 首先通过图形约束推理构建一个具有连贯布局和比例的创意组合 3D 骨架。然后，该骨架在结构化潜在空间内引导基于体素的组装过程，整合来自不同对象的区域。最后，应用骨骼条件下的图像引导外观建模，为组装后的形状生成风格一致且和谐的纹理。大量的实验确立了 Muses 在视觉保真度、与文本描述的一致性以及灵活 3D 对象编辑潜力方面的最先进性能。项目页面：https://luhexiao.github.io/Muses.github.io/。|[2601.03256](http://arxiv.org/abs/2601.03256)|null|\n",
        "2601.03252": "|**2026-01-06**|**InfiniDepth: Arbitrary-Resolution and Fine-Grained Depth Estimation with Neural Implicit Fields**|现有的深度估计方法从根本上仅限于预测离散图像网格上的深度。这种表示将其可扩展性限制为任意输出分辨率并阻碍几何细节恢复。本文介绍了 InfiniDepth，它将深度表示为神经隐式场。通过简单而有效的局部隐式解码器，我们可以查询连续二维坐标的深度，从而实现任意分辨率和细粒度的深度估计。为了更好地评估我们方法的能力，我们从五种不同的游戏中策划了高质量的 4K 合成基准，涵盖具有丰富几何和外观细节的不同场景。大量实验表明，InfiniDepth 在相对和度量深度估计任务的合成基准和现实基准上均实现了最先进的性能，尤其是在精细细节区域中表现出色。它还有利于在大视点变化下进行新颖的视图合成任务，从而产生具有更少孔洞和伪影的高质量结果。|[2601.03252](http://arxiv.org/abs/2601.03252)|null|\n",
        "2601.03240": "|**2026-01-06**|**The Squeezed Bispectrum from CHIME HI Emission and Planck CMB Lensing: Current Sensitivity and Forecasts**|如果信号能够成功地从极其明亮的无线电前景发射中分离出来，那么使用原子氢 (HI) 进行线强度映射就有可能有效地绘制大面积的宇宙图。这激发了互相关性，以确定测量的 HI 波动的宇宙学性质，并研究它们与星系和底层物质密度场的联系。然而，这些相同的前景使得与投影场（例如宇宙微波背景（CMB）的透镜效应）的互相关变得困难。事实上，相关的傅里​​叶模式沿着视线缓慢变化，因此最容易受到平滑频谱无线电连续谱前景的污染。在本文中，我们实施了一种避免此问题的方法，尝试使用大规模普朗克 CMB 透镜来测量加拿大氢强度测绘实验 (CHIME) 的小规模 21cm 功率的非线性引力耦合。该测量是位置相关的功率谱，即压缩积分双谱。使用 94 个夜晚 1.0 < z < 1.3$ 之间的 CHIME 数据以及积极的前景过滤，我们发现预期信号比当前噪声小五倍。我们预测，合并已收集的额外夜晚的 CHIME 数据将使信噪比达到 3，而无需进一步改进前景清理的过滤。|[2601.03240](http://arxiv.org/abs/2601.03240)|null|\n",
        "2601.03160": "|**2026-01-06**|**Stability, convergence, and geometric properties of second-order-in-time space-time discretizations for linear and semilinear wave equations**|我们通过建立与时间一阶公式的精确等价，重新审视线性和半线性波动方程的二阶时空离散。重点关注使用时间连续分段多项式试验函数的方案，我们分析了它们的稳定性、收敛性和几何特性。我们首先考虑弱时空公式，其中测试函数投影到时间上低一级的不连续多项式上，表明它等效于线性情况下 [French, Peterson 1996] 中提出的方案，并在 [Karakashian, Makridakis 2005] 中扩展到半线性情况。特别是，这种等价表明该方法在网格节点处能量守恒，但不是辛的。然后，我们引入通过高斯-勒让德和高斯-洛巴托时间求积获得的两个辛变体，并表明它们对应于特定的龙格-库塔时间积分器。这些联系阐明了所考虑的时空方法的几何结构。|[2601.03160](http://arxiv.org/abs/2601.03160)|null|\n",
        "2601.03114": "|**2026-01-06**|**Stroke Patches: Customizable Artistic Image Styling Using Regression**|我们提出了一种新颖的、基于回归的方法来对图像进行艺术造型。与最近的神经风格转移或基于扩散的方法不同，我们的方法允许通过使用一组可扩展的笔画补丁来显式控制渲染图像中的笔画组成和细节级别。笔划补丁集是由小程序按程序生成的，这些程序控制各个补丁中笔划的形状、大小、方向、密度、颜色和噪声级别。一旦在一组笔划补丁上进行训练，基于 U-Net 的回归模型就可以以各种不同的、令人回味的和可定制的风格渲染任何输入图像。|[2601.03114](http://arxiv.org/abs/2601.03114)|null|\n",
        "2601.03030": "|**2026-01-06**|**Flow Matching and Diffusion Models via PointNet for Generating Fluid Fields on Irregular Geometries**|我们提出了两种新颖的生成几何深度学习框架，称为 Flow Matching PointNet 和 Diffusion PointNet，用于通过将 PointNet 分别纳入流匹配和扩散模型来预测不规则几何形状上的流体流动变量。在这些框架中，反向生成过程根据看不见的几何形状的标准高斯噪声重建物理场。所提出的方法直接对计算域的点云表示（例如，有限体积网格的网格顶点）进行操作，因此避免了用于将几何形状投影到均匀晶格上的像素化​​的限制。与基于图神经网络的扩散模型相比，Flow Matching PointNet 和 Diffusion PointNet 在预测场中不会表现出高频噪声伪影。此外，与需要辅助中间网络来调节几何形状的方法不同，所提出的框架仅依赖于 PointNet，从而形成简单且统一的架构。所提出的框架的性能是在通过圆柱体的稳定不可压缩流上进行评估的，使用通过改变圆柱体的横截面形状和跨样本的方向构建的几何数据集。结果表明，与具有相同数量可训练参数的普通 PointNet 相比，Flow Matching PointNet 和 Diffusion PointNet 可以更准确地预测速度和压力场以及升力和阻力，并且对不完整的几何形状表现出更高的鲁棒性。|[2601.03030](http://arxiv.org/abs/2601.03030)|null|\n",
        "2601.02906": "|**2026-01-06**|**Linear Script Representations in Speech Foundation Models Enable Zero-Shot Transliteration**|Whisper 等多语言语音基础模型是在网络规模数据上进行训练的，其中每种语言的数据由无数的区域变体组成。然而，不同的地区品种常常采用不同的文字来书写相同的语言，使得语音识别输出也受到输出文字的非确定性的影响。为了缓解这个问题，我们证明脚本在多语言语音模型的激活空间中进行线性编码，并且在推理时修改激活可以直接控制输出脚本。我们发现，即使在非常规的语言-脚本配对中（例如西里尔字母中的意大利语和拉丁字母中的日语），在测试时将此类脚本向量添加到激活中也可以引起脚本更改。我们应用这种方法来诱导对语音识别输出脚本的事后控制，我们观察 Whisper 所有模型大小的竞争性能。|[2601.02906](http://arxiv.org/abs/2601.02906)|null|\n",
        "2601.02829": "|**2026-01-06**|**Resolution deficits drive simulator sickness and compromise reading performance in virtual environments**|扩展现实 (XR) 正在发展成为通用计算平台，但其在生产力方面的采用却因视觉疲劳和模拟器眩晕症而受到阻碍。虽然这些症状通常归因于延迟或运动冲突，但文本清晰度对生理舒适度的确切影响仍不清楚。在这里，我们表明，在虚拟现实和视频透视环境中的阅读任务期间，次优的有效分辨率（即在完整的显示光学渲染管道之后到达眼睛的清晰度）是导致模拟器晕眩的主要驱动因素。通过在统一的 logMAR 量表上系统地操纵端到端有效分辨率，我们在一项受控的受试者内研究中测量了阅读心理物理学和疾病症状。我们发现，当分辨率降至 0 logMAR（正常视力）以下时，阅读性能和用户舒适度呈指数下降。值得注意的是，我们的结果表明 0 logMAR 是一个关键的生理临界点：优于该阈值的分辨率可产生肉眼水平的性能，同时将不适感降至最低，而较差的分辨率会引发恶心和动眼神经紧张的快速、非线性增加。这些发现表明，解决模糊文本所需的认知和感知工作直接损害了用户的舒适度，从而将人眼分辨率确立为未来人体工学 XR 系统设计的关键基线。|[2601.02829](http://arxiv.org/abs/2601.02829)|null|\n",
        "2601.02759": "|**2026-01-06**|**Towards Zero-Shot Point Cloud Registration Across Diverse Scales, Scenes, and Sensor Setups**|一些基于深度学习的点云配准方法难以实现零样本泛化，通常需要针对新环境进行特定于数据集的超参数调整或重新训练。我们确定了三个关键限制：（a）固定的用户定义参数（例如体素大小、搜索半径）无法在不同尺度上泛化，（b）学习的关键点检测器表现出较差的跨域可转移性，以及（c）绝对坐标放大了数据集之间的尺度不匹配。为了解决这三个问题，我们提出了 BUFFER-X，这是一种免训练的配准框架，它通过以下方式实现零样本泛化：（a）用于自动超参数估计的几何引导，（b）分布感知的最远点采样来替换学习检测器，以及（c）补丁级坐标归一化以确保尺度一致性。我们的方法采用分层多尺度匹配来提取局部、中间和全局感受野的对应关系，从而在不同的环境中实现稳健的配准。对于效率关键型应用，我们引入了 BUFFER-X-Lite，它通过早期退出策略和快速位姿求解器在保持精度的同时将总计算时间减少了 43%（相对于 BUFFER-X）。我们对一个综合基准进行评估，该基准包含 12 个涵盖物体尺度、室内和室外场景的数据集，包括异构 LiDAR 配置之间的跨传感器配准。结果表明，我们的方法可以有效地推广，无需手动调整或测试领域的先验知识。代码：https://github.com/MIT-SPARK/BUFFER-X。|[2601.02759](http://arxiv.org/abs/2601.02759)|null|\n",
        "2601.02721": "|**2026-01-06**|**Robust Mesh Saliency GT Acquisition in VR via View Cone Sampling and Geometric Smoothing**|可靠的 3D 网格显着性地面实况 (GT) 对于虚拟现实 (VR) 中以人为中心的视觉建模至关重要。然而，当前的3D网格显着性GT获取方法总体上与2D图像方法一致，忽略了3D几何拓扑和2D图像阵列之间的差异。当前的 VR 眼球追踪管道依赖于单光线采样和欧几里得平滑，触发纹理注意力和跨间隙的信号泄漏。本文提出了一个强大的框架来解决这些限制。我们首先引入视锥采样（VCS）策略，该策略通过高斯分布射线束模拟人类中央凹感受野，以提高复杂拓扑的采样鲁棒性。此外，还开发了混合流形-欧几里德约束扩散（HCD）算法，将流形测地线约束与欧几里德尺度融合，以确保拓扑一致的显着性传播。通过减轻“拓扑短路”和混叠，我们的框架提供了与人类自然感知相一致的高保真 3D 注意力获取范例，为 3D 网格显着性研究提供了更准确、更稳健的基线。|[2601.02721](http://arxiv.org/abs/2601.02721)|null|\n",
        "2601.04120": "|**2026-01-07**|**A Single-Loop Bilevel Deep Learning Method for Optimal Control of Obstacle Problems**|障碍问题的最优控制出现在广泛的应用中，并且由于其非平滑性、非线性和双层结构而在计算上具有挑战性。经典数值方法依赖于基于网格的离散化，通常需要解决一系列代价高昂的子问题。在这项工作中，我们提出了一种单循环双层深度学习方法，该方法是无网格的，可扩展到高维和复杂领域，并避免重复求解离散子问题。该方法采用约束嵌入神经网络来近似状态并控制并保留双层结构。为了有效地训练神经网络，我们提出了一种单循环随机一阶双层算法（S2-FOBA），该算法消除了嵌套优化，并且不依赖于限制性的较低级别唯一性假设。我们在温和的假设下分析了 S2-FOBA 的收敛行为。对基准示例（包括复杂域上规则和不规则障碍物的分布式障碍控制问题）的数值实验表明，与经典数值方法相比，该方法取得了令人满意的精度，同时降低了计算成本。|[2601.04120](http://arxiv.org/abs/2601.04120)|null|\n",
        "2601.04099": "|**2026-01-07**|**A constrained-transport embedded boundary method for compressible resistive magnetohydrodynamics**|近年来人们对脉冲功率磁惯性聚变装置的兴趣日益浓厚，我们提出了一种在笛卡尔网格上实现任意形状的嵌入边界，同时求解可压缩电阻磁流体动力学方程的方法。该方法是围绕方程的有限体积公式构建的，其中黎曼求解器用于计算网格单元之间的面上的通量，以及归纳方程的面心约束输运公式。通过始终计算笛卡尔网格的面和边缘上的通量，可以避免与切割单元相关的小时间步长问题。我们扩展了该方法，使用幻影流体方法来模拟两种具有不同属性的材料之间的移动界面，并展示了一些初步结果，包括磁流体静力学平衡的冲击波驱动和磁驱动动态压缩。我们对该方法进行了彻底的验证，并表明它在没有不连续性的情况下以二阶收敛，在材料属性不连续的情况下以一阶收敛。|[2601.04099](http://arxiv.org/abs/2601.04099)|null|\n",
        "2601.04075": "|**2026-01-07**|**A higher order sparse grid combination technique**|我们证明了一种广义稀疏网格组合技术，它将有限差分解的多元外推与标准组合公式相结合，将规则网格上的二阶精确方案提升为四阶组合稀疏网格解。在分析中，在一般维度上工作，我们将方案的多元误差展开中的所有项表征为一系列半离散问题的解。首先在对方案的截断误差、解的稳定性和规律性的适当假设下正式进行。然后，我们用平滑数据验证泊松问题示例的假设，并说明最多七个维度的实际收敛。|[2601.04075](http://arxiv.org/abs/2601.04075)|null|\n",
        "2601.04054": "|**2026-01-07**|**LinkD: AutoRegressive Diffusion Model for Mechanical Linkage Synthesis**|由于连续节点放置、离散拓扑配置和非线性运动学约束之间的复杂耦合，设计机械连杆以实现目标末端执行器轨迹提出了根本性挑战。高度非线性的运动与配置关系意味着关节位置的小扰动会极大地改变轨迹，而组合扩展的设计空间使得传统的优化和启发式方法在计算上变得难以处理。我们引入了一种自回归扩散框架，该框架通过将机制表示为顺序构造的图来利用连杆组装的二元性质，其中节点对应于关节，边缘对应于刚性连杆。我们的方法将因果变换器与去噪扩散概率模型（DDPM）相结合，两者都以通过变换器编码器编码的目标轨迹为条件。因果变换器自回归逐节点预测离散拓扑，而 DDPM 则细化每个节点的空间坐标和与先前生成的节点的边缘连接。这种顺序生成实现了自适应试错综合，其中表现出运动锁定或碰撞的有问题的节点可以选择性地重新生成，从而允许在设计期间自主纠正简并配置。我们基于图形的数据驱动方法超越了传统的优化方法，实现了可扩展的逆向设计，可推广到具有任意节点数的机制。我们展示了包含多达 20 个节点的链接系统的成功综合，并且可扩展至 N 节点架构。这项工作推进了自回归图生成方法和计算运动学综合，为复杂机械系统的可扩展逆向设计建立了新的范例。|[2601.04054](http://arxiv.org/abs/2601.04054)|null|\n",
        "2601.04013": "|**2026-01-07**|**Effects of Horizontal Discretization on Triangular and Hexagonal Grids on Linear Baroclinic and Symmetric Instabilities**|由于全球海洋环流模型是在允许涡流的分辨率下运行的，因此在选择运动方程的离散化时，准确再现斜压不稳定性的增长率是一个主要问题。从这个角度来看，我们分析了几种海洋环流模型中使用的具有不同类型变量交错的三角形和六边形网格上的离散化。通过将 Eady 配置中的线性斜压不稳定性分析扩展到更复杂网格上的离散化，揭示了一些数值上的微妙之处。与四边形网格上的离散化相比，分析的离散化对于不稳定的杂散模式（部分由网格几何形状产生）的鲁棒性较差。一些微妙之处的出现是因为交错三角形和六边形网格上的杂散模式不遵守伽利略不变性。因此，它们的增长率表现出对背景流和网格之间的对齐以及均匀背景流的强度的依赖性。与寄生模式的相互作用在对称不稳定性轴上变得更加重要，其中不稳定的物理分支和寄生分支在波数空间中更难以分离。我们的分析表明，在大多数情况下，适度的双调和粘度和扩散会抑制虚假分支。然而，为了实现这一目标，需要仔细校准每个考虑的离散化的粘度和扩散率参数。|[2601.04013](http://arxiv.org/abs/2601.04013)|null|\n",
        "2601.03993": "|**2026-01-07**|**PosterVerse: A Full-Workflow Framework for Commercial-Grade Poster Generation with HTML-Based Scalable Typography**|商业级海报设计需要将审美吸引力与精确、信息丰富的内容传递无缝结合。当前的自动海报生成系统面临着重大限制，包括不完整的设计工作流程、文本渲染精度差以及商业应用灵活性不足。为了应对这些挑战，我们提出了 PosterVerse，这是一种完整工作流程的商业级海报生成方法，可以无缝地自动化整个设计过程，同时提供高密度和可扩展的文本渲染。 PosterVerse 通过三个关键阶段复制专业设计：(1) 使用微调的 LLM 创建蓝图，从用户需求中提取关键设计元素，(2) 通过定制的扩散模型生成图形背景，以创建视觉上吸引人的图像，以及 (3) 使用 MLLM 支持的 HTML 引擎进行统一的布局文本渲染，以保证高文本准确性和灵活的定制。此外，我们还推出了 PosterDNA，这是一个商业级的、基于 HTML 的数据集，专为训练和验证海报设计模型而定制。据我们所知，PosterDNA是第一个引入HTML排版文件的中文海报生成数据集，实现可扩展的文本渲染，从根本上解决渲染小而高密度文本的挑战。实验结果表明，PosterVerse 始终能够生成具有吸引人的视觉效果、准确的文本对齐和可定制布局的商业级海报，使其成为自动化商业海报设计的有前途的解决方案。代码和模型可在 https://github.com/wuhaer/PosterVerse 获取。|[2601.03993](http://arxiv.org/abs/2601.03993)|null|\n",
        "2601.03975": "|**2026-01-07**|**Cavity-Driven Multispectral Gain for High-Sensitivity NV Center Magnetometers**|我们报告了一种基于 NV 系综与介电腔耦合的腔式固态磁力计，实现了 12 pT/$\\sqrt{\\rm{Hz}}$ 灵敏度和多光谱特征近三倍的增益。这些特征源于腔引起的 NV 超精细能级分裂，并利用系统双修饰状态中强大的量子相干性来实现高灵敏度。我们预测模拟的近期灵敏度接近 100 fT/$\\sqrt{\\rm{Hz}}$，接近约翰逊-奈奎斯特极限。我们的结果将频率复用确立为一种新的操作范例，为环境条件下的计量提供强大且可扩展的量子资源。|[2601.03975](http://arxiv.org/abs/2601.03975)|null|\n",
        "2601.03954": "|**2026-01-07**|**Computing the Intrinsic Delaunay Triangulation of a Closed Polyhedral Surface**|每个本质上是多面体的表面都可以用门户边形来表示：欧几里得平面中的多边形集合，并抽象地标识出一些对等长的边。虽然这种表示形式可以说比网格（R3 中的平面多边形形成表面）更简单，但它具有无限的快乐：表面中的最短路径可以任意多次访问同一个多边形。这种病态行为是高效算法的障碍。另一方面，Löffler、Ophelders、Staals 和 Silveira (SoCG 2023) 最近证明，（内在的）Delaunay 三角剖分具有有限的幸福感。   在本文中，给定一个由三角形入口边 T 表示的闭合多面体曲面 S，我们提供了一种算法来计算 S 的 Delaunay 三角剖分，其顶点是 S 的奇点（包围角不同于 2pi 的点）。我们算法的时间复杂度是三角形数量和 T 的纵横比 r 对数的多项式。在我们的计算模型中，我们表明 log(r) 中的依赖性是不可避免的。我们的算法可用于在计算三角形门户网站表面上的最短路径之前对其进行预处理，并确定两个三角形门户网站的表面是否等距。|[2601.03954](http://arxiv.org/abs/2601.03954)|null|\n",
        "2601.03943": "|**2026-01-07**|**A laser plasma soliton fusion scheme**|我们引入了一种由激光等离子体孤子实现的新型聚变方案，该方案有望克服达到盈亏平衡条件的几个基本障碍。具体而言，我们使用氘氚（DT）作为燃料。孤立子内部的强电磁场显着增强了 DT 聚变截面，其有质动力势能疏散电子，并将 D/T 加速到适合聚变反应的动能。虽然电子几乎立即被排出，但更重的 D/T 以皮秒时间尺度移动。这种时间尺度的差异为DT聚变在无电子环境中有效发生提供了时间窗口。我们注入两个连续的激光，其中第一个将激发等离子体孤子，第二个更强烈且具有匹配的较低频率，将共振地增强孤子电磁场。我们施加等离子体密度梯度来诱导孤子运动。在其生命周期内被移动孤子扫过的等离子体柱内的所有 D/T 都将参与这种聚变机制。我们证明盈亏平衡条件是可以实现的。利用光纤激光器和 iCAN 激光器技术进行高重复率和高强度操作，千兆瓦输出也许是可以想象的。|[2601.03943](http://arxiv.org/abs/2601.03943)|null|\n",
        "2601.03935": "|**2026-01-07**|**Accelerated simulation of multiscale gas-radiation coupling flows via a general synthetic iterative scheme**|气体-辐射耦合严重影响高超声速再入流，其中极端温度会导致明显的非平衡气体和辐射热传输。因此，准确有效的辐射气体动力学模拟对于大气进入车辆热防护系统的可靠设计是必不可少的。在这项研究中，使用通用合成迭代方案（GSIS）在广泛的流动和辐射传输范围内求解了辐射气流的玻尔兹曼型动力学模型。该方法将非结构化有限体积离散速度方法与一组宏观综合方程相结合。在此框架内，动力学模型为合成方程中的本构关系提供了高阶闭包。同时，宏观综合方程驱动介观动力学系统的演化，显着加速近连续体系的稳态收敛，线性傅里叶稳定性分析证实了这一点。至关重要的是，该算法被证明是渐进保持的，可以正确恢复连续谱和光学厚度极限，由辐射纳维-斯托克斯-傅里叶方程表示，在独立于平均自由程的粗网格上控制不同的平移、旋转、振动和辐射温度。对具有挑战性的基准（包括阿波罗再入舱上的三维高超音速流）的数值模拟表明，GSIS 在辐射气流的多尺度模拟中比传统迭代方案实现了数量级的加速，同时准确捕获高超音速环境中的非平衡效应和辐射传热。|[2601.03935](http://arxiv.org/abs/2601.03935)|null|\n"
    },
    "具生智能&自动驾驶": {
        "2601.00755": "|**2026-01-02**|**A formal theory on problem space as a semantic world model in systems engineering**|经典问题空间理论将问题解决建模为通过状态、算子、目标和约束的结构化空间的导航。系统工程（SE）采用类似的构造（功能分析、操作分析、情景、权衡研究），但仍然缺乏问题空间本身的严格系统理论表示。在当前的实践中，推理通常直接从利益相关者的目标进行到规定性的工件。这使得关于操作环境、允许的交互和上下文条件的基本假设隐含或过早地嵌入到架构或需求中。本文通过将问题空间形式化为包含在需求和解决方案承诺之前定义的理论构造的显式语义世界模型来解决这一差距。这些构造与开发的公理、定理和推论一起建立了严格的标准，用于明确的边界语义、成功的利益相关者目标满足的上下文相关交互可追溯性，以及问题空间规范的充分性，在该规范上可以独立于解决方案设计进行有纪律的推理。它清楚地区分了问题领域的真实情况和选择的解决方案。本文最后讨论了该理论对实践者的重要性，并提供了利益相关者和工程师之间基于对话的假设案例研究，展示了该理论如何在设计任何规定性工件之前指导问题框架。|[2601.00755](http://arxiv.org/abs/2601.00755)|null|\n",
        "2601.00742": "|**2026-01-02**|**Materials Informatics: Emergence To Autonomous Discovery In The Age Of AI**|这一视角探讨了材料信息学的演变，从物理学和信息论的基础到通过人工智能 (AI) 的成熟。我们追溯了该领域的发展轨迹，从早期里程碑到材料基因组计划的变革性影响以及最近出现的大型语言模型 (LLM)。我们将材料信息学视为一个不断发展的生态系统，而不仅仅是一个工具包，回顾了推动逆向设计和自主驾驶实验室的关键方法，例如贝叶斯优化、强化学习和 Transformers。我们专门解决法学硕士整合的实际挑战，比较专家模型与通才模型，并讨论不确定性量化的解决方案。展望未来，我们评估人工智能从预测工具到协作研究伙伴的转变。通过利用主动学习和检索增强生成（RAG），该领域正在迈向自主材料科学的新时代，其日益以“人类脱离循环”的发现过程为特征。|[2601.00742](http://arxiv.org/abs/2601.00742)|null|\n",
        "2601.01800": "|**2026-01-05**|**Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving**|强化学习 (RL) 在自动驾驶 (AD) 领域显示出巨大的潜力，但其易受扰动的影响仍然是现实世界部署的关键障碍。作为主要对策，对抗性训练通过在对手故意引入扰动的情况下训练 AD 代理来提高策略的稳健性。现有方法通常将交互建模为具有连续攻击的零和游戏。然而，此类设计忽视了代理和对手之间固有的不对称性，无法反映安全关键风险的稀疏性，导致所实现的鲁棒性不足以满足实际的 AD 场景。为了解决这些限制，我们引入了关键性感知的鲁棒强化学习（CARRL），这是一种新颖的对抗性训练方法，用于处理自动驾驶中稀疏的、安全关键的风险。 CARRL 由两个相互作用的部分组成：风险暴露对手 (REA) 和风险目标稳健代理 (RTRA)。我们将 REA 和 RTRA 之间的交互建模为一般和游戏，使 REA 能够专注于暴露安全关键型故障（例如碰撞），而 RTRA 则学会平衡安全性与驾驶效率。 REA 采用解耦优化机制，在预算有限的情况下更好地识别和利用稀疏的安全关键时刻。然而，这种集中攻击不可避免地导致对抗性数据的缺乏。 RTRA 通过双重重放缓冲区共同利用良性和对抗性体验来应对这种稀缺性，并在扰动下强制执行政策一致性以稳定行为。实验结果表明，与最先进的基线方法相比，我们的方法在所有情况下将碰撞率降低了至少 22.66%。|[2601.01800](http://arxiv.org/abs/2601.01800)|null|\n",
        "2601.01762": "|**2026-01-05**|**AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving**|端到端自动驾驶快速发展，实现了复杂环境下的联合感知和规划。在规划阶段，最先进的（SOTA）端到端自动驾驶模型将规划分解为并行的横向和纵向预测。虽然有效，但这种并行设计可能会导致 i) 规划路径和速度之间的协调失败，以及 ii) 未充分利用驾驶路径作为纵向规划的先验，从而冗余地编码静态信息。为了解决这个问题，我们提出了一种新颖的级联框架，该框架明确规定了行驶路径上的纵向规划，从而实现协调和碰撞感知的横向和纵向规划。具体来说，我们引入了一种路径条件公式，该公式明确地将行驶路径纳入纵向规划中。在此基础上，该模型预测沿行驶路径的纵向位移，而不是完整的 2D 轨迹路点。这种设计简化了纵向推理，并将其与横向规划更紧密地结合在一起。此外，我们引入了一种面向规划的数据增强策略，通过添加代理和重新标记纵向目标以避免碰撞来模拟罕见的安全关键事件，例如车辆切入。在具有挑战性的 Bench2Drive 基准上进行评估，我们的方法设定了新的 SOTA，驾驶得分为 89.07，成功率为 73.18%，这表明协调性和安全性显着提高|[2601.01762](http://arxiv.org/abs/2601.01762)|null|\n",
        "2601.01743": "|**2026-01-05**|**AI Agent Systems: Architectures, Applications, and Evaluation**|人工智能代理——将基础模型与推理、规划、记忆和工具使用相结合的系统——正在迅速成为自然语言意图和现实世界计算之间的实用接口。这项调查综合了人工智能代理架构的新兴前景：(i) 审议和推理（例如，思想链式分解、自我反思和验证以及约束感知决策），(ii) 规划和控制（从反应性策略到分层和多步骤规划器），以及 (iii) 工具调用和环境交互（检索、代码执行、API 和多模式感知）。我们将之前的工作组织成一个统一的分类法，涵盖代理组件（策略/LLM核心、内存、世界模型、规划器、工具路由器和评论家）、编排模式（单代理与\\多代理；集中与\\分散协调）和部署设置（离线分析与\\在线交互协助；安全关键与\\开放式任务）。我们讨论了关键的设计权衡——延迟与准确性、自主性与可控性、能力与可靠性——并强调了评估如何因非确定性、长期信用分配、工具和环境可变性以及重试和上下文增长等隐性成本而变得复杂。最后，我们总结了测量和基准测试实践（任务套件、人类偏好和效用指标、约束下的成功、稳健性和安全性），并确定了开放的挑战，包括工具操作的验证和护栏、可扩展的内存和上下文管理、代理决策的可解释性以及实际工作负载下的可重复评估。|[2601.01743](http://arxiv.org/abs/2601.01743)|null|\n",
        "2601.01705": "|**2026-01-05**|**Explicit World Models for Reliable Human-Robot Collaboration**|本文讨论了传感噪声、模糊指令和人机交互下的鲁棒性主题。我们对可靠的实体人工智能问题采取了截然不同的策略：我们不关注旨在实现模型可预测性和鲁棒性的形式验证方法，而是强调人机交互​​的动态性、模糊性和主观性，这需要实体人工智能系统以一致、可理解和符合人类期望的方式感知、解释和响应人类意图。我们认为，当实体主体在本质上是社交的、多模式的和流动的人类环境中运行时，可靠性是根据上下文确定的，并且仅对参与交互的人类的目标和期望才有意义。这就需要一种根本不同的方法来实现可靠的嵌入式人工智能，其核心是构建和更新一个可访问的“显式世界模型”，代表人类和人工智能之间的共同点，用于使机器人行为与人类期望保持一致。|[2601.01705](http://arxiv.org/abs/2601.01705)|null|\n",
        "2601.01676": "|**2026-01-04**|**LabelAny3D: Label Any Object 3D in the Wild**|从单眼输入检测 3D 空间中的物体对于从机器人到场景理解等应用至关重要。尽管在室内和自动驾驶领域具有先进的性能，但由于缺乏 3D 野外数据集以及 3D 注释的挑战，现有的单目 3D 检测模型在处理野外图像方面遇到了困难。我们引入了 LabelAny3D，这是一个 \\emph{综合分析} 框架，它可以从 2D 图像重建整体 3D 场景，以有效地生成高质量的 3D 边界框注释。在此基础上，我们提出了 COCO3D，这是开放词汇单目 3D 检测的新基准，源自 MS-COCO 数据集，涵盖了现有 3D 数据集中缺少的广泛对象类别。实验表明，LabelAny3D 生成的注释提高了多个基准中的单目 3D 检测性能，在质量上优于先前的自动标记方法。这些结果证明了基础模型驱动注释在现实、开放世界环境中扩展 3D 识别的前景。|[2601.01676](http://arxiv.org/abs/2601.01676)|null|\n",
        "2601.01618": "|**2026-01-04**|**Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation**|长视距机器人操作对于现实世界的部署越来越重要，需要复杂布局中的空间消歧和动态交互下的时间弹性。然而，现有的端到端和分层的视觉-语言-行动（VLA）策略通常依赖于纯文本线索，同时保持计划意图的潜在性，这破坏了杂乱或未指定场景中的参考基础，阻碍了通过闭环交互对长期目标进行有效的任务分解，并通过模糊行动选择背后的基本原理来限制因果解释。为了解决这些问题，我们首先引入 Visual Sketch，这是一种令人难以置信的视觉中间体，可以在机器人当前视图中渲染点、框、箭头和类型化关系，以外部化空间意图，将语言与场景几何连接起来。在 Visual Sketch 的基础上，我们提出了 Action-Sketcher，这是一个 VLA 框架，它在循环的 See-Think-Sketch-Act 工作流程中运行，并通过自适应令牌门控策略进行协调，用于推理触发器、草图修订和动作发布，从而支持反应性校正和人类交互，同时保留实时动作预测。为了实现可扩展的训练和评估，我们利用交错的图像、文本、视觉草图监督和动作序列来策划不同的语料库，并使用多阶段课程方案来训练 Action-Sketcher，该课程方案结合了用于模态统一的交错序列对齐、用于精确语言基础的语言到草图的一致性、以及通过草图到动作强化来增强鲁棒性的模仿学习。对杂乱场景和多对象任务、模拟和现实世界任务进行的大量实验表明，长期成功率有所提高，对动态场景变化的鲁棒性更强，并且通过可编辑草图和逐步计划增强了可解释性。项目网站：https://action-sketcher.github.io|[2601.01618](http://arxiv.org/abs/2601.01618)|null|\n",
        "2601.01577": "|**2026-01-04**|**HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller**|当前自主控制器强化学习的尝试对数据要求较高，但结果表现不佳、不稳定，无法把握和锚定安全概念，并且由于像素重建的性质而过度关注噪声特征。虽然当前的自我监督学习方法通​​过利用联合嵌入预测架构（JEPA）来学习高维表示是有趣且有效的替代方案，因为该想法模仿了人脑使用想象力和最小观察样本获取新技能的自然能力。本研究介绍了 Hanoi-World，这是一种基于 JEPA 的世界模型，使用循环神经网络 (RNN) 进行具有有效推理时间的长期水平规划。在不同环境下的 Highway-Env 包上进行的实验展示了在安全意识的同时制定驾驶计划的有效能力，与 SOTA 基线相比具有相当大的碰撞率|[2601.01577](http://arxiv.org/abs/2601.01577)|null|\n",
        "2601.01551": "|**2026-01-04**|**Optically Transparent Meta-Grating Embedded in Rear Windshields for Automotive Radar Detection**|雷达通过实现可靠的物体检测，从而为驾驶员提供帮助，并在未来成为自动驾驶的主要传感器之一，在汽车安全中发挥着至关重要的作用。道路参与者的雷达能见度取决于其雷达截面 (RCS)。虽然 RCS 是一种固有属性，但增强它，类似于使用反光背心实现光学可见性，可以通过协作目标设计显着改善雷达探测。然而，现代车辆并不是为此目的而设计的，并且由于行业的保守方法和车辆外部可用空间有限，没有使用嵌入式反射器。后挡风玻璃提供了广阔的未使用区域，但它们仍然必须发挥其主要功能并保持透明。我们建议通过嵌入一个反射面来利用该区域，该反射面考虑了询问场景的几何形状和后挡风玻璃的角度倾斜，确保波被回反射回雷达。该表面被实现为具有周期性的细导线阵列，为设计入射角提供同相激励。鉴于汽车雷达在毫米波范围 (77-81 GHz) 下运行，因此需要具有亚毫米制造精度的大尺寸表面。这是通过将由银纳米粒子和粘合剂组成的导电墨水压印到玻璃的凹槽中来实现的。制造的 10x10 平方米。样品的光学透明度约为 90%，其 RCS 为 8 平方米，超过了汽车的典型 RCS。将这种性能外推到带有嵌入式元光栅的整个后窗，典型的 RCS 为 1000 平方米。可以实现，从而将可检测范围提高了近一个数量级。智能窗户支持无线通信中的高级应用，例如汽车场景、物联网等。|[2601.01551](http://arxiv.org/abs/2601.01551)|null|\n",
        "2601.01528": "|**2026-01-04**|**DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving**|视频生成模型作为世界模型的一种形式，已成为人工智能领域最令人兴奋的前沿之一，它让智能体能够通过对复杂场景的时间演化进行建模来想象未来。在自动驾驶中，这一愿景催生了驾驶世界模型：想象自我和代理未来的生成模拟器，实现可扩展的模拟、极端情况的安全测试以及丰富的合成数据生成。然而，尽管研究活动快速增长，但该领域缺乏严格的基准来衡量进展和指导优先事项。现有的评估仍然有限：通用视频指标忽视了安全关键的成像因素；轨迹的合理性很少被量化；时间和代理级别的一致性被忽略；自我调节的可控性被忽略。此外，当前的数据集无法涵盖现实世界部署所需的条件的多样性。为了解决这些差距，我们推出了 DrivingGen，这是第一个生成驾驶世界模型的综合基准测试。 DrivingGen 将来自驾驶数据集和互联网规模视频源的多样化评估数据集（涵盖不同的天气、一天中的时间、地理区域和复杂的操作）与一套新指标相结合，共同评估视觉真实性、轨迹合理性、时间一致性和可控性。对 14 个最先进模型进行基准测试揭示了明显的权衡：通用模型看起来更好，但违反物理原理，而驾驶专用模型可以真实地捕捉运动，但视觉质量落后。 DrivingGen 提供统一的评估框架，以培育可靠、可控和可部署的驾驶世界模型，从而实现可扩展的模拟、规划和数据驱动的决策。|[2601.01528](http://arxiv.org/abs/2601.01528)|null|\n",
        "2601.01386": "|**2026-01-04**|**ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking**|停车是自动驾驶系统 (ADS) 的一项关键任务，在拥挤的停车位和 GPS 无法识别的环境中面临着独特的挑战。然而，现有的工作重点是 2D 停车位感知、映射和定位，而 3D 重建仍有待探索，这对于捕获停车场景中的复杂空间几何形状至关重要。单纯地提高重建停车场景的视觉质量并不能直接使自动停车受益，因为停车的关键入口是车位感知模块。为了解决这些限制，我们策划了第一个名为 ParkRecon3D 的基准测试，专门为停车场景重建而设计。它包括来自四个环视鱼眼摄像头的传感器数据，以及经过校准的外部参数和密集的停车位注释。然后，我们提出了 ParkGaussian，这是第一个集成 3D 高斯分布 (3DGS) 进行停车场景重建的框架。为了进一步提高重建和下游停车位检测之间的一致性，我们引入了一种槽位感知重建策略，该策略利用现有的停车感知方法来提高槽位区域的合成质量。 ParkRecon3D 上的实验表明，ParkGaussian 实现了最先进的重建质量，并更好地保持了下游任务的感知一致性。代码和数据集将发布在：https://github.com/wm-research/ParkGaussian|[2601.01386](http://arxiv.org/abs/2601.01386)|null|\n",
        "2601.02297": "|**2026-01-05**|**The Polarization and Magnetic Field of the Radio Arc as Observed by ALMA at 100 GHz**|40 多年来，独特的银河中心非热丝 (NTF) 一直是研究的焦点。 NTF 最突出的表现是一束平行的细丝，称为射电弧。使用甚大阵列 (VLA) 在 10 GHz 下进行的射电极化观测揭示了射电弧中的交变磁场模式，这可能是沿视线遇到多个场系统的结果，也可能是射电弧的固有特征。由于对源头进行了较大的旋转测量，这些 VLA 观测结果无法区分这些可能性。我们展示了 ALMA 100 GHz 射电弧观测结果，不受显着法拉第效应的影响。这里报告的观测结果既是 ALMA 首次用于研究 NTF，也是首次对射电弧进行 100 GHz 极化观测。我们发现相对于 NTF 细丝方向均匀旋转的磁场，旋转角度沿每根细丝的长度恒定。然而，我们发现不同的射电弧灯丝中存在系统不同的磁场方向。我们使用这种场模式来更新我们对射电弧局部视线结构的理解。我们发现从 ALMA 观测推断出的磁场可能是多个磁场系统混淆的结果，或者是因为极化集中在 NTF 细丝内。|[2601.02297](http://arxiv.org/abs/2601.02297)|null|\n",
        "2601.02295": "|**2026-01-05**|**CycleVLA: Proactive Self-Correcting Vision-Language-Action Models via Subtask Backtracking and Minimum Bayes Risk Decoding**|目前机器人故障检测和纠正的工作通常以事后方式进行，仅在故障发生后分析错误并应用纠正。这项工作引入了 CycleVLA，这是一个为视觉-语言-动作模型 (VLA) 配备主动自我纠正功能的系统，能够预测初期故障并在执行过程中完全显现之前进行恢复。 CycleVLA 通过集成一个进度感知 VLA（标记最常发生故障的关键子任务转换点）、一个基于 VLM 的故障预测器和规划器（在预测故障时触发子任务回溯）以及一个基于最小贝叶斯风险 (MBR) 解码的测试时间扩展策略来实现这一目标，以提高回溯后的重试成功率。大量实验表明，CycleVLA 可以提高训练有素和训练不足的 VLA 的性能，并且 MBR 可以作为 VLA 的有效零样本测试时间扩展策略。项目页面：https://dannymcy.github.io/cyclevla/|[2601.02295](http://arxiv.org/abs/2601.02295)|null|\n",
        "2601.02046": "|**2026-01-05**|**Agentic Retoucher for Text-To-Image Generation**|SDXL 和 FLUX 等文本到图像 (T2I) 扩散模型已经实现了令人印象深刻的照片级真实感，但四肢、面部、文本等中仍然普遍存在小规模扭曲。现有的细化方法要么执行成本高昂的迭代重新生成，要么依赖空间基础薄弱的视觉语言模型（VLM），导致语义漂移和不可靠的本地编辑。为了缩小这一差距，我们提出了 Agentic Retoucher，这是一种分层决策驱动框架，它将生成后校正重新表述为类人感知-推理-行动循环。具体来说，我们设计了（1）一个感知代理，它在文本图像一致性提示下学习上下文显着性，以实现细粒度的失真定位；（2）一个推理代理，通过渐进式偏好对齐执行与人类一致的推理诊断；（3）一个动作代理，根据用户偏好指导自适应地规划局部修复。这种设计将感知证据、语言推理和可控纠正整合到一个统一的、自我纠正的决策过程中。为了实现细粒度监督和定量评估，我们进一步构建了 GenBlemish-27K，这是一个 6K T2I 图像的数据集，其中包含 12 个类别的 27K 个带注释的伪影区域。大量实验表明，Agentic Retoucher 在感知质量、失真定位和人类偏好调整方面始终优于最先进的方法，为自我校正和感知可靠的 T2I 生成建立了新的范例。|[2601.02046](http://arxiv.org/abs/2601.02046)|null|\n",
        "2601.01989": "|**2026-01-05**|**VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis**|行人意图预测是3级自动驾驶向4级自动驾驶过渡的关键技术之一。为了了解行人过路处的行为，应考虑几个要素和特征，以使未来的道路对每个人来说都更安全。我们引入了一种基于 Transformer/视频视觉 Transformer 的不同大小的算法，该算法使用不同的数据模态。我们在流行的行人行为数据集 JAAD 上评估了我们的算法，并达到了 SOTA 性能，并在准确度、AUC 和 F1 分数等指标上通过了 SOTA。通过广泛的消融研究，研究了不同模型设计选择带来的优势。|[2601.01989](http://arxiv.org/abs/2601.01989)|null|\n",
        "2601.01948": "|**2026-01-05**|**Learning Diffusion Policy from Primitive Skills for Robot Manipulation**|扩散策略（DP）最近显示出在机器人操作中产生动作的巨大前景。然而，现有的方法通常依赖于全局指令来产生短期控制信号，这可能导致动作生成中的失调。我们推测，被称为细粒度、短视野操作的原始技能，例如“向上移动”和“打开夹具”，为机器人学习提供了更直观、更有效的界面。为了弥补这一差距，我们提出了 SDP，这是一种将可解释的技能学习与条件行动计划相结合的技能条件 DP。 SDP 抽象了跨任务的八种可重用的原始技能，并采用视觉语言模型从视觉观察和语言指令中提取离散表示。基于它们，设计了一个轻量级路由器网络，为每个状态分配所需的原始技能，这有助于构建单一技能策略来生成与技能一致的操作。通过将复杂任务分解为一系列原始技能并选择单一技能策略，SDP 可确保不同任务之间的技能行为一致。对两个具有挑战性的模拟基准和现实世界的机器人部署进行的大量实验表明，SDP 始终优于 SOTA 方法，为具有扩散策略的基于技能的机器人学习提供了新的范例。|[2601.01948](http://arxiv.org/abs/2601.01948)|null|\n",
        "2601.03231": "|**2026-01-06**|**Standard Model Higgs Peaks: a Note on the Vacuum Instability during Inflation**|在标准模型中，当四次自耦合为负时，希格斯势在高场值下会变得不稳定。宇宙暴胀期间的大量子涨落可能会使希格斯场超出势垒，从而产生对我们可观测宇宙来说将是灾难性的区域。我们指出，描述希格斯值的峰值（最大值）的极值统计量是推断避免真空不稳定的条件的正确统计量。即使这一统计数据在暴涨期间对哈勃率给出了一个界限，仅比文献中普遍采用的系数强$\\sqrt{2}$，但它在质量上是不同的，我们认为值得传达它。|[2601.03231](http://arxiv.org/abs/2601.03231)|null|\n",
        "2601.03218": "|**2026-01-06**|**Enhancing Safety in Automated Ports: A Virtual Reality Study of Pedestrian-Autonomous Vehicle Interactions under Time Pressure, Visual Constraints, and Varying Vehicle Size**|自动驾驶提高了交通效率，但在复杂的港口环境中也带来了安全挑战。本研究调查环境因素、交通因素和行人特征如何影响港口自动驾驶车辆和行人之间的交互安全。通过对典型港口场景的虚拟现实 (VR) 模拟，33 名参与者在不同的能见度、车辆尺寸和时间压力条件下完成了人行横道任务。结果表明，低能见度条件、部分遮挡和较大的车辆尺寸会显着增加感知风险，促使行人等待更长时间并接受更大的间隙。具体来说，行人在与大型自动驾驶卡车排互动时往往会接受更大的间隙并等待更长的时间，这反映出由于他们感知到的威胁而更加谨慎。然而，局部障碍物也会缩短入侵后的时间，从而压缩安全裕度。年龄、性别和驾驶经验等个人属性进一步影响决策，而时间压力会破坏补偿行为并增加风险。基于这些发现，提出了安全策略，包括在多个视点安装广角摄像头、实现车辆与基础设施的实时通信、增强港口照明和标牌以及加强行人安全培训。这项研究为提高港口环境中基于视觉的自主系统的安全性和部署提供了实用的建议。|[2601.03218](http://arxiv.org/abs/2601.03218)|null|\n",
        "2601.03136": "|**2026-01-06**|**Limited Linguistic Diversity in Embodied AI Datasets**|语言在视觉-语言-动作（VLA）模型中起着至关重要的作用，但用于训练和评估这些系统的数据集的语言特征仍然缺乏记录。在这项工作中，我们对几个广泛使用的 VLA 语料库进行了系统的数据集审核，旨在描述这些数据集实际包含哪些类型的指令以及它们提供了多少语言多样性。我们沿着互补的维度量化教学语言，包括词汇多样性、重复和重叠、语义相似性和句法复杂性。我们的分析表明，许多数据集依赖于高度重复、类似模板的命令，结构变化有限，从而产生了狭窄的指令形式分布。我们将这些发现定位为当前 VLA 训练和评估数据中可用的语言信号的描述性文档，旨在支持更详细的数据集报告、更有原则的数据集选择以及扩大语言覆盖范围的有针对性的管理或增强策略。|[2601.03136](http://arxiv.org/abs/2601.03136)|null|\n",
        "2601.03044": "|**2026-01-06**|**SOP: A Scalable Online Post-Training System for Vision-Language-Action Models**|视觉-语言-动作（VLA）模型通过大规模预训练实现了很强的泛化性，但现实世界的部署除了广泛的泛用性之外还需要专家级的任务熟练程度。现有的 VLA 模型的后训练方法通常是离线的、单个机器人的或特定于任务的，限制了有效的策略适应和现实世界交互中的可扩展学习。我们引入了可扩展在线后训练（SOP）系统，该系统可以直接在物理世界中对通用 VLA 模型进行在线、分布式、多任务后训练。 SOP 通过闭环架构将执行和学习紧密结合在一起，其中一组机器人不断地将策略经验和人工干预信号传输到集中式云学习器，并异步接收更新的策略。这种设计支持及时的策略修正，通过并行部署扩展经验收集，并在适应过程中保留通用性。 SOP 与训练后算法的选择无关；我们用交互式模仿学习（HG-DAgger）和强化学习（RECAP）来实例化它。在一系列现实世界的操作任务中，包括布料折叠、盒子组装和杂货补货，我们表明 SOP 显着提高了大型预训练 VLA 模型的性能，同时保持跨任务的单一共享策略。有效的后期培训可以在现实世界交互的数小时内实现，并且性能与车队中的机器人数量几乎呈线性关系。这些结果表明，将在线学习与车队规模部署紧密结合，有助于在物理世界中实现高效、可靠和可扩展的通用机器人策略的后期培训。|[2601.03044](http://arxiv.org/abs/2601.03044)|null|\n",
        "2601.03001": "|**2026-01-06**|**Towards Efficient 3D Object Detection for Vehicle-Infrastructure Collaboration via Risk-Intent Selection**|车辆基础设施协同感知（VICP）对于解决自动驾驶中的遮挡问题至关重要，但通信带宽和特征冗余之间的权衡仍然是一个关键瓶颈。虽然与原始共享相比，中间融合减少了数据量，但现有框架通常依赖于空间压缩或静态置信图，这会低效地传输来自非关键背景区域的空间冗余特征。为了解决这个问题，我们提出了风险意图选择性检测（RiSe），这是一种交互感知框架，它将范式从识别可见区域转变为优先考虑风险关键区域。具体来说，我们引入了基于势场理论的势场轨迹相关模型（PTCM）来定量评估运动风险。作为补充，意图驱动区域预测模块 (IDAPM) 利用自我运动先验来主动预测和过滤对决策至关重要的关键鸟瞰 (BEV) 区域。通过集成这些组件，RiSe 实现了语义选择性融合方案，仅从高交互区域传输高保真特征，有效地充当特征降噪器。对 DeepAccident 数据集的大量实验表明，我们的方法将通信量减少到完整特征共享的 0.71%，同时保持最先进的检测精度，在带宽效率和感知性能之间建立了竞争性的帕累托前沿。|[2601.03001](http://arxiv.org/abs/2601.03001)|null|\n",
        "2601.02907": "|**2026-01-06**|**Beyond the Black Box: Theory and Mechanism of Large Language Models**|大型语言模型 (LLM) 的迅速出现引发了人工智能领域的深刻范式转变，带来了巨大的工程成功，对现代社会的影响日益增大。然而，当前领域中仍然存在一个关键的悖论：尽管具有实证效力，但我们对法学硕士的理论理解仍然处于不成比例的新生阶段，迫使这些系统在很大程度上被视为“黑匣子”。为了解决这种理论碎片化问题，本次调查提出了一种基于生命周期的统一分类法，将研究领域分为六个不同的阶段：数据准备、模型准备、训练、对齐、推理和评估。在此框架内，我们对驱动法学硕士绩效的基础理论和内部机制进行了系统回顾。具体来说，我们分析了核心理论问题，例如数据混合的数学合理性、各种架构的表示限制以及对齐算法的优化动态。超越当前的最佳实践，我们确定了关键的前沿挑战，包括合成数据自我改进的理论限制、安全保证的数学界限以及新兴智能的机械起源。通过将经验观察与严格的科学探究联系起来，这项工作为将法学硕士发展从工程启发法转向有原则的科学学科提供了一个结构化的路线图。|[2601.02907](http://arxiv.org/abs/2601.02907)|null|\n",
        "2601.02730": "|**2026-01-06**|**HOLO: Homography-Guided Pose Estimator Network for Fine-Grained Visual Localization on SD Maps**|标准清晰度 (SD) 地图上的视觉定位已成为一种有前途的低成本且可扩展的自动驾驶解决方案。然而，现有的基于回归的方法经常忽略固有的几何先验，导致训练效率不佳和定位精度有限。在本文中，我们提出了一种新颖的单应性引导姿态估计器网络，用于多视图图像和标准清晰度（SD）地图之间的细粒度视觉定位。我们通过将地面视图特征投影到 BEV 域并强制与地图特征进行语义对齐来构造满足单应性约束的输入对。然后，我们利用单应性关系来指导特征融合，并将姿势输出限制在有效的可行区域，与依赖基于注意力的融合和直接 3-DoF 姿势回归的现有方法相比，这显着提高了训练效率和定位精度。据我们所知，这是第一个将 BEV 语义推理与单应性学习相结合以进行图像到地图定位的工作。此外，通过显式地对单应性变换进行建模，所提出的框架自然地支持跨分辨率输入，从而增强了模型的灵活性。对 nuScenes 数据集的大量实验表明，我们的方法明显优于现有的最先进的视觉定位方法。代码和预训练模型将公开发布，以促进未来的研究。|[2601.02730](http://arxiv.org/abs/2601.02730)|null|\n",
        "2601.02714": "|**2026-01-06**|**Time-Scaling Is What Agents Need Now**|早期的人工智能范式表现出分离的认知功能：神经网络专注于“感知表征”，强化学习专注于“决策行为”，而符号人工智能则专注于“知识推理”。通过基于 Transformer 的大型模型和世界模型，这些范式正在汇聚成具有闭环“感知-决策-行动”能力的认知代理。   人类通过时间化顺序推理在有限的认知资源下解决复杂的问题。语言依赖于问题空间搜索来进行深层语义推理。虽然早期的大型语言模型（LLM）可以生成流畅的文本，但它们缺乏强大的语义推理能力。思想链 (CoT) 和思想树 (ToT) 等提示技术通过明确中间步骤来扩展推理路径。 DeepSeek-R1 等最新模型通过显式推理轨迹增强了性能。然而，这些方法在搜索完整性和效率方面存在局限性。   这凸显了对“时间缩放”的需求——随着时间的推移，系统地扩展和优化智能体展开推理的能力。时间缩放是指利用扩展时间路径的架构设计，能够实现更深入的问题空间探索、动态策略调整和增强的元认知控制，与认知约束下的人类顺序推理并行。它代表了在不成比例增加静态模型参数的情况下增强深度推理和解决问题的关键前沿。提高智能代理的能力需要将时间缩放原则放在首位，将显式时间推理管理作为基础。|[2601.02714](http://arxiv.org/abs/2601.02714)|null|\n",
        "2601.02584": "|**2026-01-05**|**Dynamic Synchronization of Driven Self-Oscillators: Modeling and Experiment**|在固定频率和振幅强迫下自持振荡器的同步已被很好地理解，但时变强迫如何破坏锁相的研究却少之又少。理论预测，驱动幅度或频率的缓慢、确定性调制可以导致一种特殊的同步机制，其特征是振荡相位间歇性锁定，超出与固定谐波强迫相关的阿诺德舌边界。我们在可控气动声学自振荡器（即哨子）中测试这些预测，该振荡器表现出强大的极限环，并受到具有可编程频率和幅度调制的外部声学强迫的影响。在缓慢变化的频率或强迫幅度下，观察到三种状态：（i）严格同步（ii）间歇同步，其特征是交替锁相和短暂的相滑事件，以及（iii）无同步，具有规则的相滑。特别是在严格的同步机制中，振荡器的相位将遵循任意缓慢变化的驱动相位，并且在幅度调制下，其幅度波动被强烈抑制。|[2601.02584](http://arxiv.org/abs/2601.02584)|null|\n",
        "2601.02456": "|**2026-01-05**|**InternVLA-A1: Unifying Understanding, Generation and Action for Robotic Manipulation**|流行的视觉-语言-动作 (VLA) 模型通常基于多模态大型语言模型 (MLLM) 构建，并在语义理解方面表现出卓越的熟练程度，但它们本质上缺乏推断物理世界动态的能力。因此，最近的方法已经转向世界模型，通常通过视频预测来制定；然而，这些方法常常缺乏语义基础，并且在处理预测错误时表现出脆弱性。为了协同语义理解与动态预测功能，我们提出了 InternVLA-A1。该模型采用统一的 Mixture-of-Transformers 架构，协调三位专家进行场景理解、视觉预见生成和动作执行。这些组件通过统一的屏蔽自注意力机制无缝交互。在 InternVL3 和 Qwen3-VL 的基础上，我们在 2B 和 3B 参数尺度上实例化 InternVLA-A1。我们在跨越 InternData-A1 和 Agibot-World 的混合合成真实数据集上预训练这些模型，覆盖超过 5.33 亿帧。这种混合训练策略有效地利用了合成模拟数据的多样性，同时最大限度地减少了模拟与真实的差距。我们通过 12 个现实世界的机器人任务和模拟基准评估了 InternVLA-A1。它的性能显着优于 pi0 和 GR00T N1.5 等领先模型，在日常任务方面实现了 14.5% 的提升，在动态设置（例如传送带分拣）方面实现了 40%-73.3% 的提升。|[2601.02456](http://arxiv.org/abs/2601.02456)|null|\n",
        "2601.04158": "|**2026-01-07**|**Radio Activity from the Rapidly Rotating T dwarf 2MASS 2228-4310**|我们使用 Karl G. Jansky 甚大阵列 (VLA) 档案数据在 C 波段 (4-8 GHz) 观测了两个观测时期（$2\\times96$ 分钟），展示了对 2MASS J22282889-4310262 (2M2228)（一颗 T6/T6.5 褐矮星）的探测。检测到 2M2228 的时间和频率平均斯托克斯 I 和 V 峰值通量密度为 $67.3\\pm4.9\\ μ \\rm{Jy beam}^{-1}$ 和 $14.4\\pm3.0\\ μ\\text{Jy beam}^{-1}$（第一个历元）和 $107.2\\pm5.2\\ μ\\rm{Jy\\ beam}^{-1}$ 和第二个时期的$-20.7\\pm1.2\\ μ\\text{Jy beam}^{-1}$。这一发现构成了迄今为止在射电波长下检测到的第八个、尤其是旋转速度最快的 T 型矮星。我们的观察揭示了分数偏振比 $f_\\text{c}>50$% 的高度偏振爆发。使用斯托克斯 I 光曲线，我们分别测量两个观测时期 $\\sim47$ 和 $\\sim58$ 分钟的发生间隔，其中第一次爆发在先前测量的中红外光度周期 $85.8\\pm0.32$ 分钟的半个周期时间尺度内对齐。我们将发射归因于电子回旋脉泽发射（ECME），并将磁场强度限制为 $B\\gtrsim1.4$ kG。我们强调，考虑到观测持续时间较短，推断的周期是临时的。先前证明的大气稳定性和2M2228中新检测到的射电发射相结合，使其成为一个有前途的实验室，用于测试磁层流驱动的极光模型，并指导未来协调詹姆斯·韦伯太空望远镜（JWST）和射电观测，以探索极光活动与T型褐矮星大气动力学之间的联系。|[2601.04158](http://arxiv.org/abs/2601.04158)|null|\n",
        "2601.04137": "|**2026-01-07**|**Wow, wo, val! A Comprehensive Embodied World Model Evaluation Turing Test**|随着世界模型在 Embodied AI 中的发展势头，越来越多的作品探索使用视频基础模型作为下游具体任务（如 3D 预测或交互式生成）的预测世界模型。然而，在探索这些下游任务之前，视频基础模型仍然有两个关键问题没有得到解答：（1）它们的生成泛化是否足以维持人类观察者眼中的感知保真度，以及（2）它们是否足够强大，可以作为现实世界具体代理的普遍先验。为了提供回答这些问题的标准化框架，我们引入了体现图灵测试基准：WoW-World-Eval (Wow,wo,val)。 Wow-wo-val 基于 609 个机器人操作数据，检查了五种核心能力，包括感知、规划、预测、泛化和执行。我们提出了一个包含 22 个指标的综合评估协议来评估模型的生成能力，其总体得分与人类偏好之间实现了较高的皮尔逊相关性（>0.93），为人类图灵测试奠定了可靠的基础。在 Wow-wo-val 上，模型在长期规划方面仅达到 17.27，在物理一致性方面最多达到 68.02，表明时空一致性和物理推理有限。对于逆动态模型图灵测试，我们首先使用 IDM 来评估视频基础模型在现实世界中的执行准确性。然而，大多数模型的成功率都下降到约 0%，而《魔兽世界》则保持了 40.74% 的成功率。这些发现表明生成的视频与现实世界之间存在明显差距，凸显了在具体人工智能中对世界模型进行基准测试的紧迫性和必要性。|[2601.04137](http://arxiv.org/abs/2601.04137)|null|\n",
        "2601.04061": "|**2026-01-07**|**CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos**|与丰富的人类视频演示相比，通用视觉-语言-动作模型目前受到机器人数据稀缺的阻碍。现有的潜在动作模型试图利用视频数据，但经常遭受视觉纠缠，捕捉噪音而不是操纵技能。为了解决这个问题，我们提出了对比潜在动作预训练（CLAP），这是一个将视频中的视觉潜在空间与机器人轨迹中的本体感受潜在空间对齐的框架。通过采用对比学习，CLAP 将视频转换映射到量化的、物理可执行的码本上。在此表示的基础上，我们引入了一种双公式 VLA 框架，该框架提供 CLAP-NTP（一种擅长指令跟踪和对象泛化的自回归模型）和 CLAP-RF（一种基于整流流的策略，专为高频、精确操作而设计）。此外，我们提出了一种知识匹配（KM）正则化策略，以减轻微调期间的灾难性遗忘。大量实验表明，CLAP 的性能显着优于强大的基线，能够将技能从人类视频有效转移到机器人执行。项目页面：https://lin-shan.com/CLAP/。|[2601.04061](http://arxiv.org/abs/2601.04061)|null|\n",
        "2601.04052": "|**2026-01-07**|**Stable Language Guidance for Vision-Language-Action Models**|视觉-语言-动作（VLA）模型在广义机器人控制方面展示了令人印象深刻的能力；然而，众所周知，它们仍然容易受到语言扰动的影响。我们发现了一种关键的“模态崩溃”现象，即强烈的视觉先验压倒了稀疏的语言信号，导致代理过度适应特定的指令短语，同时忽略了潜在的语义意图。为了解决这个问题，我们提出了 \\textbf{Residual Semantic Steering (RSS)}，这是一个将物理可供性与语义执行分开的概率框架。 RSS 引入了两项理论创新：(1) \\textbf{蒙特卡罗句法集成}，它通过密集的、LLM 驱动的分布扩展来近似真实的语义后验；(2) \\textbf{Residual Affordance Steering}，一种双流解码机制，通过减去先验的视觉可供性来明确隔离语言的因果影响。理论分析表明，RSS 有效地最大化了行动和意图之间的相互信息，同时抑制了视觉干扰。不同操作基准的实证结果表明，RSS 实现了最先进的鲁棒性，即使在对抗性语言扰动下也能保持性能。|[2601.04052](http://arxiv.org/abs/2601.04052)|null|\n",
        "2601.04035": "|**2026-01-07**|**MobileDreamer: Generative Sketch World Model for GUI Agent**|移动 GUI 代理在现实世界的自动化和实际应用中显示出强大的潜力。然而，大多数现有代理仍然处于反应状态，主要根据当前屏幕做出决策，这限制了它们在长期任务中的性能。通过重复交互构建世界模型可以预测行动结果并支持移动 GUI 代理更好的决策。这是具有挑战性的，因为模型必须具有空间意识来预测动作后状态，同时保持足够的效率以进行实际部署。在本文中，我们提出了 MobileDreamer，这是一种基于世界模型的高效前瞻框架，用于根据世界模型提供的未来想象来装备 GUI 代理。它由文本草图世界模型和GUI代理的展开想象组成。文本草图世界模型通过学习过程预测动作后状态，将数字图像转换为与关键任务相关的草图，并设计一种新颖的顺序不变学习策略来保留 GUI 元素的空间信息。 GUI代理的推出想象策略通过利用世界模型的预测能力来优化动作选择过程。 Android World 上的实验表明，MobileDreamer 实现了最先进的性能，并将任务成功率提高了 5.25%。世界模型评估进一步验证了我们的文本草图建模能够准确预测关键 GUI 元素。|[2601.04035](http://arxiv.org/abs/2601.04035)|null|\n",
        "2601.03905": "|**2026-01-07**|**Current Agents Fail to Leverage World Model as Tool for Foresight**|基于视觉语言模型构建的智能体越来越多地面临需要预测未来状态而不是依赖短期推理的任务。生成世界模型提供了一种有希望的补救措施：智能体可以将它们用作外部模拟器，以在采取行动之前预见结果。本文实证检验了当前的智能体是否可以利用此类世界模型作为工具来增强他们的认知。在不同的代理和视觉问答任务中，我们观察到一些代理很少调用模拟（低于 1%），经常误用预测的推出（大约 15%），并且在模拟可用或强制执行时经常表现出不一致甚至性能下降（高达 5%）。归因分析进一步表明，主要瓶颈在于智能体决定何时进行模拟、如何解释预测结果以及如何将预见性融入下游推理的能力。这些发现强调需要一种机制来促进与世界模型的校准、战略交互，为未来代理系统中更可靠的预期认知铺平道路。|[2601.03905](http://arxiv.org/abs/2601.03905)|null|\n",
        "2601.03904": "|**2026-01-07**|**Towards Safe Autonomous Driving: A Real-Time Motion Planning Algorithm on Embedded Hardware**|确保自动驾驶车辆 (AV) 的功能安全需要运动规划模块，该模块不仅要在严格的实时约束下运行，还要在系统故障时保持可控性。现有的防护概念，例如在线验证（OV），提供了检测不可行的规划输出的安全层。然而，它们缺乏主动机制来确保在主规划器发生故障时安全运行。本文提出了针对故障操作自动驾驶（AD）的主动安全扩展的第一步。我们在运行实时操作系统 (RTOS) 的汽车级嵌入式平台上部署了基于采样的轻量级轨迹规划器。规划器在计算资源有限的情况下不断计算轨迹，为未来的应急规划架构奠定了基础。实验结果证明了具有有限延迟和最小抖动的确定性定时行为，验证了在安全认证硬件上进行轨迹规划的可行性。该研究强调了将主动后备机制整合为下一代保障框架的一个组成部分的潜力和仍然存在的挑战。代码位于：https://github.com/TUM-AVS/real-time-motion-planning|[2601.03904](http://arxiv.org/abs/2601.03904)|null|\n",
        "2601.03789": "|**2026-01-07**|**CSI-MAE: A Masked Autoencoder-based Channel Foundation Model**|自监督学习 (SSL) 已成为机器学习中的一项关键技术，可解决有限的标记数据、高注释成本和可变的无线信道条件等挑战。它对于开发信道基础模型 (CFM) 至关重要，该模型从信道状态信息 (CSI) 中提取潜在特征并适应不同的无线设置。然而，现有的 CFM 存在明显的缺点：严重依赖场景特定数据阻碍泛化，它们专注于单/双任务，缺乏零样本学习能力。在本文中，我们提出了 CSI-MAE，一种利用屏蔽自动编码器进行跨场景泛化的泛化 CFM。它经过 3GPP 信道模型数据集的训练，通过 CSI 感知和生成集成了传感和通信，并在不同的任务中被证明是有效的。轻量级解码器微调策略可以降低训练成本，同时保持有竞争力的性能。在这种方法下，CSI-MAE 匹配或超越了监督模型。通过全参数微调，实现了最先进的性能。其卓越的零样本可转移性也可与跨场景应用中的监督技术相媲美，从而推动无线通信创新。|[2601.03789](http://arxiv.org/abs/2601.03789)|null|\n",
        "2601.03782": "|**2026-01-07**|**PointWorld: Scaling 3D World Models for In-The-Wild Robotic Manipulation**|人类通过目光和身体的预期动作来预测 3D 世界将如何响应，这种能力对于机器人操作同样重要。我们引入了 PointWorld，一种大型预训练 3D 世界模型，它将共享 3D 空间中的状态和动作统一为 3D 点流：给定一个或几个 RGB-D 图像和一系列低级机器人动作命令，PointWorld 预测 3D 中响应给定动作的每像素位移。通过将动作表示为 3D 点流而不是具体实施例的动作空间（例如关节位置），该公式直接以机器人的物理几何形状为条件，同时无缝集成跨实施例的学习。为了训练我们的 3D 世界模型，我们在 3D 视觉和模拟环境的最新进展的支持下，在开放世界环境中构建了一个涵盖真实和模拟机器人操作的大型数据集，单臂 Franka 和双手类人机器人总计约 200 万条轨迹和 500 小时。通过对主干、动作表示、学习目标、部分可观察性、数据混合、域传输和缩放进行严格的大规模实证研究，我们提炼出大规模 3D 世界建模的设计原则。凭借实时（0.1秒）的推理速度，PointWorld可以有效地集成到模型预测控制（MPC）框架中进行操作。我们证明，单个预训练检查点使现实世界的 Franka 机器人能够执行刚体推动、可变形和铰接物体操作以及工具使用，无需任何演示或后期训练，所有这些都来自在野外捕获的单个图像。项目网站：https://point-world.github.io/。|[2601.03782](http://arxiv.org/abs/2601.03782)|null|\n",
        "2601.03741": "|**2026-01-07**|**I2E: From Image Pixels to Actionable Interactive Environments for Text-Guided Image Editing**|现有的文本引导图像编辑方法主要依赖于端到端像素级修复范例。尽管它在简单的场景中取得了成功，但这种范例在需要精确的局部控制和复杂的多对象空间推理的合成编辑任务方面仍然存在很大的困难。这种范例受到以下因素的严重限制：1) 规划和执行的隐式耦合，2) 缺乏对象级控制粒度，以及 3) 对非结构化、以像素为中心的建模的依赖。为了解决这些限制，我们提出了 I2E，一种新颖的“分解然后行动”范例，它将图像编辑重新视为结构化环境中的可操作交互过程。 I2E 利用分解器将非结构化图像转换为离散的、可操作的对象层，然后引入物理感知的视觉语言动作代理，通过思想链推理将复杂的指令解析为一系列原子动作。此外，我们还构建了I2E-Bench，这是一个专为多实例空间推理和高精度编辑而设计的基准。 I2E-Bench 和多个公共基准测试的实验结果表明，I2E 在处理复杂的组合指令、保持物理合理性和确保多轮编辑稳定性方面显着优于最先进的方法。|[2601.03741](http://arxiv.org/abs/2601.03741)|null|\n"
    }
}