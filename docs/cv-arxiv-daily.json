{
    "Video Diffusion": {
        "2512.17907": "|**2025-12-19**|**Dexterous World Models**|3D 重建领域的最新进展使得从日常环境中创建逼真的数字孪生变得容易。然而，当前的数字孪生在很大程度上仍然是静态的，并且仅限于导航和视图合成，没有具体的交互性。为了弥补这一差距，我们引入了灵巧世界模型 (DWM)，这是一种场景动作条件视频扩散框架，用于模拟灵巧的人类动作如何引起静态 3D 场景的动态变化。   给定静态 3D 场景渲染和以自我为中心的手部运动序列，DWM 会生成时间连贯的视频，描绘合理的人景交互。我们的方法将视频生成条件限制为（1）遵循指定摄像机轨迹的静态场景渲染，以确保空间一致性，以及（2）以自我为中心的手部网格渲染，对几何和运动线索进行编码，以直接对动作条件动态进行建模。为了训练 DWM，我们构建了一个混合交互视频数据集。合成的以自我为中心的交互为关节运动和操作学习提供了完全一致的监督，而固定摄像头的真实世界视频则提供了多样化和真实的对象动态。   实验表明，DWM 可实现真实且物理上合理的交互，例如抓取、打开和移动对象，同时保持相机和场景的一致性。该框架代表了迈向基于视频传播的交互式数字孪生的第一步，并实现了以自我为中心的行为的具体模拟。|[2512.17907](http://arxiv.org/abs/2512.17907)|null|\n",
        "2512.17883": "|**2025-12-19**|**Map2Video: Street View Imagery Driven AI Video Generation**|人工智能视频生成降低了视频创作的门槛，但当前的工具仍然存在不一致的问题。电影制作人经常发现剪辑与角色和背景不匹配，因此很难构建连贯的序列。与电影制片人进行的一项形成性研究强调了镜头构图、角色动作和摄像机控制方面的挑战。我们推出了 Map2Video，这是一种基于现实世界地理的街景图像驱动的人工智能视频生成工具。该系统将 Unity 和 ComfyUI 与 VACE 视频生成模型以及用于街景图像的 OpenStreetMap 和 Mapillary 集成。借鉴熟悉的电影制作实践（例如位置搜寻和排练），Map2Video 使用户能够选择地图位置、在街景图像中定位演员和摄像机、绘制移动路径、完善摄像机运动并生成空间一致的视频。我们与 12 名电影制作人一起评估了 Map2Video。与图像到视频的基线相比，它实现了更高的空间精度，需要更少的认知工作，并为场景复制和开放式创意探索提供了更强的可控性。|[2512.17883](http://arxiv.org/abs/2512.17883)|null|\n",
        "2512.17661": "|**2025-12-19**|**Vidarc: Embodied Video Diffusion Model for Closed-loop Control**|由于复杂的实施例动态和多样化的环境，在数据稀缺的环境中操纵机械臂是一项极具挑战性的任务。最近基于视频的方法通过对互联网规模的视频数据进行预训练，在捕获和传输时间和物理交互方面显示出了巨大的前景。然而，这样的方法通常没有针对特定于实施例的闭环控制进行优化，通常遭受高延迟和接地不足的困扰。在本文中，我们提出了 Vidarc（用于动作推理和闭环控制的视频扩散），这是一种通过掩蔽逆动力学模型增强的新型自回归具体视频扩散方法。通过使用与动作相关的掩模来进行视频预测，并通过缓存的自回归生成结合实时反馈，Vidarc 实现了快速、准确的闭环控制。 Vidarc 经过 100 万次跨实施例的预训练，超越了最先进的基线，在实际部署中实现了至少 15% 的成功率提高和 91% 的延迟减少。我们还强调了其在以前未见过的机器人平台上强大的泛化和纠错能力。|[2512.17661](http://arxiv.org/abs/2512.17661)|null|\n",
        "2512.17650": "|**2025-12-19**|**Region-Constraint In-Context Generation for Instructional Video Editing**|最近，上下文生成范式在教学图像编辑方面在数据效率和合成质量方面表现出了强大的力量。然而，为基于指令的视频编辑塑造这种情境学习并非易事。在不指定编辑区域的情况下，去噪时结果会出现编辑区域不准确、编辑区域与非编辑区域之间的标记干扰等问题。为了解决这些问题，我们提出了 ReCo，一种新的教学视频编辑范例，它新颖地深入研究了上下文生成过程中编辑和非编辑区域之间的约束建模。从技术上讲，ReCo 宽度方向连接源视频和目标视频以进行联合去噪。为了校准视频扩散学习，ReCo 利用两个正则化项，即潜在正则化和注意力正则化，分别在一步后向去噪潜伏和注意力图上进行。前者增加了源视频和目标视频之间编辑区域的潜在差异，同时减少了非编辑区域的潜在差异，强调了编辑区域的修改，减轻了外部意外内容的生成。后者抑制了编辑区域中的标记对源视频对应部分中的标记的注意，从而减轻了它们在目标视频中的新对象生成期间的干扰。此外，我们提出了一个大规模、高质量的视频编辑数据集，即 ReCo-Data，包含 50 万个指令视频对，有利于模型训练。对四个主要的基于指令的视频编辑任务进行的广泛实验证明了我们建议的优越性。|[2512.17650](http://arxiv.org/abs/2512.17650)|null|\n",
        "2512.17504": "|**2025-12-19**|**InsertAnywhere: Bridging 4D Scene Geometry and Diffusion Models for Realistic Video Object Insertion**|基于扩散的视频生成的最新进展为可控视频编辑开辟了新的可能性，但由于 4D 场景理解有限以及对遮挡和照明效果的处理不足，逼真的视频对象插入 (VOI) 仍然具有挑战性。我们推出了 InsertAnywhere，这是一种新的 VOI 框架，可实现几何一致的对象放置和外观忠实的视频合成。我们的方法从 4D 感知掩模生成模块开始，该模块重建场景几何形状并跨帧传播用户指定的对象放置，同时保持时间连贯性和遮挡一致性。在此空间基础上，我们扩展了基于扩散的视频生成模型，以联合合成插入的对象及其周围的局部变化，例如照明和阴影。为了实现监督训练，我们引入了 ROSE++，这是一种照明感知合成数据集，通过将 ROSE 对象删除数据集转换为对象删除视频、对象存在视频和 VLM 生成的参考图像的三元组而构建。通过大量的实验，我们证明我们的框架可以在不同的现实世界场景中产生几何上合理且视觉上连贯的对象插入，显着优于现有的研究和商业模型。|[2512.17504](http://arxiv.org/abs/2512.17504)|null|\n",
        "2512.17445": "|**2025-12-19**|**LangDriveCTRL: Natural Language Controllable Driving Scene Editing with Multi-modal Agents**|LangDriveCTRL 是一个自然语言可控框架，用于编辑现实世界的驾驶视频以合成不同的交通场景。它利用显式 3D 场景分解将驾驶视频表示为场景图，包含静态背景和动态对象。为了实现细粒度的编辑和真实感，它集成了一个代理管道，其中 Orchestrator 将用户指令转换为协调专用代理和工具的执行图。具体来说，对象接地代理在自由格式文本描述和场景图中的目标对象节点之间建立对应关系；行为编辑代理根据语言指令生成多对象轨迹；行为审查代理迭代地审查和细化生成的轨迹。渲染编辑后的场景图，然后使用视频扩散工具对其进行细化，以解决由对象插入和显着视图变化引入的伪像。 LangDriveCTRL 支持通过单个自然语言指令进行对象节点编辑（删除、插入和替换）和多对象行为编辑。从数量上讲，它比以前的 SoTA 实现了近 2 倍的指令对齐，并具有出色的结构保留、照片真实感和交通真实感。项目页面位于：https://yunhe24.github.io/langdrivectrl/。|[2512.17445](http://arxiv.org/abs/2512.17445)|null|\n",
        "2512.17253": "|**2025-12-19**|**Mitty: Diffusion-based Human-to-Robot Video Generation**|直接从人类演示视频中学习是迈向可扩展和通用机器人学习的一个重要里程碑。然而，现有方法依赖于关键点或轨迹等中间表示，从而引入信息丢失和累积错误，从而损害时间和视觉一致性。我们推出了 Mitty，一种扩散变压器，可实现视频情境学习以实现端到端 Human2Robot 视频生成。 Mitty 基于预训练的视频扩散模型构建，利用强大的视觉时间先验将人类演示转换为机器人执行视频，而无需动作标签或中间抽象。演示视频被压缩为条件标记，并通过扩散过程中的双向注意力与机器人去噪标记融合。为了缓解配对数据的稀缺性，我们还开发了一种自动合成管道，可以从大型以自我为中心的数据集中生成高质量的人机对。 Human2Robot 和 EPIC-Kitchens 上的实验表明，Mitty 提供了最先进的结果、对未见过的环境的强大泛化能力，以及从人类观察中进行可扩展机器人学习的新见解。|[2512.17253](http://arxiv.org/abs/2512.17253)|null|\n",
        "2512.17152": "|**2025-12-19**|**PhysFire-WM: A Physics-Informed World Model for Emulating Fire Spread Dynamics**|细粒度的火灾预测在应急响应中发挥着至关重要的作用。红外图像和火灾掩模提供了互补的热和边界信息，但当前的方法主要限于具有固有信号稀疏性的二元掩模建模，无法捕获火灾的复杂动态。虽然世界模型在视频生成方面显示出良好的前景，但它们的物理不一致给火灾预报带来了重大挑战。本文介绍了 PhysFire-WM，这是一种用于模拟火灾蔓延动力学的物理世界模型。我们的方法通过对物理模拟器的结构化先验进行编码来纠正物理差异，并结合跨任务协作训练策略（CC-Train）来内部化燃烧动力学，从而缓解基于掩模的建模中信息有限的问题。通过参数共享和梯度协调，CC-Train有效地整合了热辐射动力学和空间边界描绘，增强了物理真实感和几何精度。对细粒度多模式火灾数据集的大量实验证明了 PhysFire-WM 在火灾蔓延预测方面的卓越准确性。验证强调了物理先验和跨任务协作的重要性，为将基于物理的世界模型应用于灾害预测提供了新的见解。|[2512.17152](http://arxiv.org/abs/2512.17152)|null|\n",
        "2512.19678": "|**2025-12-22**|**WorldWarp: Propagating 3D Geometry with Asynchronous Video Diffusion**|生成长距离、几何一致的视频提出了一个基本的困境：虽然一致性要求严格遵守像素空间中的 3D 几何，但最先进的生成模型在相机调节的潜在空间中运行最有效。这种脱节导致当前的方法难以应对遮挡区域和复杂的相机轨迹。为了弥补这一差距，我们提出了 WorldWarp，这是一个将 3D 结构锚与 2D 生成细化器结合起来的框架。为了建立几何基础，WorldWarp 维护了一个通过高斯溅射 (3DGS) 构建的在线 3D 几何缓存。通过明确地将历史内容扭曲成新的视图，该缓存充当结构脚手架，确保每个新框架尊重先前的几何形状。然而，静态扭曲不可避免地会因遮挡而留下孔洞和伪影。我们使用专为“填充和修改”目标而设计的时空扩散（ST-Diff）模型来解决这个问题。我们的关键创新是时空变化的噪声计划：空白区域接收全部噪声以触发生成，而扭曲区域接收部分噪声以实现细化。通过在每一步动态更新 3D 缓存，WorldWarp 可以保持视频块之间的一致性。因此，它通过确保 3D 逻辑引导结构而扩散逻辑完善纹理来实现最先进的保真度。项目页面：\\href{https://hyokong.github.io/worldwarp-page/}{https://hyokong.github.io/worldwarp-page/}。|[2512.19678](http://arxiv.org/abs/2512.19678)|null|\n",
        "2512.19661": "|**2025-12-22**|**Over++: Generative Video Compositing for Layer Interaction Effects**|在专业视频合成工作流程中，艺术家必须在前景主体和背景图层之间手动创建环境交互，例如阴影、反射、灰尘和飞溅。现有的视频生成模型在添加此类效果的同时很难保留输入视频，而当前的视频修复方法要么需要昂贵的每帧掩模，要么会产生令人难以置信的结果。我们引入了增强合成，这是一项新任务，可以根据文本提示和输入视频层合成逼真的半透明环境效果，同时保留原始场景。为了解决这个任务，我们提出了 Over++，一个视频效果生成框架，它不对相机姿势、场景平稳性或深度监督做出任何假设。我们构建了一个专为该任务定制的配对效果数据集，并引入了一种不配对的增强策略，以保留文本驱动的可编辑性。我们的方法还支持可选的蒙版控制和关键帧指导，而不需要密集的注释。尽管训练数据有限，但 Over++ 仍能产生多样化且真实的环境效果，并且在效果生成和场景保存方面均优于现有基线。|[2512.19661](http://arxiv.org/abs/2512.19661)|null|\n",
        "2512.19539": "|**2025-12-22**|**StoryMem: Multi-shot Long Video Storytelling with Memory**|视觉叙事需要生成具有电影质量和远程一致性的多镜头视频。受人类记忆的启发，我们提出了 StoryMem，这是一种将长视频叙事重新表述为以显式视觉记忆为条件的迭代镜头合成的范例，将预先训练的单镜头视频扩散模型转变为多镜头叙事者。这是通过新颖的内存到视频 (M2V) 设计实现的，该设计维护了历史生成镜头中关键帧的紧凑且动态更新的内存库。然后，仅通过 LoRA 微调，通过潜在串联和负 RoPE 移位将存储的内存注入单次视频扩散模型。语义关键帧选择策略与审美偏好过滤一起，进一步确保了整个世代的信息丰富且稳定的记忆。此外，所提出的框架自然地适应平滑的镜头过渡和定制的故事生成应用程序。为了便于评估，我们引入了 ST-Bench，这是一个用于多镜头视频叙事的多样化基准。大量实验表明，StoryMem 比以前的方法实现了卓越的交叉镜头一致性，同时保持了高美感质量和及时的一致性，标志着向连贯的一分钟长视频叙事迈出了重要一步。|[2512.19539](http://arxiv.org/abs/2512.19539)|null|\n",
        "2512.19402": "|**2025-12-22**|**Real2Edit2Real: Generating Robotic Demonstrations via a 3D Control Interface**|机器人学习的最新进展是由大规模数据集和强大的视觉运动策略架构推动的，但策略的稳健性仍然受到收集不同演示的巨大成本的限制，特别是对于操作任务中的空间泛化。为了减少重复的数据收集，我们提出了 Real2Edit2Real，这是一个框架，通过 3D 控制界面将 3D 可编辑性与 2D 可视数据桥接起来，生成新的演示。我们的方法首先使用公制尺度 3D 重建模型从多视图 RGB 观察中重建场景几何形状。基于重建的几何结构，我们对点云进行深度可靠的3D编辑以生成新的操纵轨迹，同时对机器人姿势进行几何校正以恢复物理一致的深度，这是合成新演示的可靠条件。最后，我们提出了一种以深度为主要控制信号的多条件视频生成模型，以及动作、边缘和光线图，以合成空间增强的多视图操作视频。对四个现实世界操作任务的实验表明，仅根据 1-5 个源演示生成的数据训练的策略可以匹配或优于 50 个现实世界演示训练的策略，从而将数据效率提高高达 10-50 倍。此外，高度和纹理编辑的实验结果证明了该框架的灵活性和可扩展性，表明其作为统一数据生成框架的潜力。|[2512.19402](http://arxiv.org/abs/2512.19402)|null|\n",
        "2512.19048": "|**2025-12-22**|**WaTeRFlow: Watermark Temporal Robustness via Flow Consistency**|图像水印支持真实性和来源，但许多方案仍然很容易通过各种扭曲和强大的生成编辑来绕过。基于深度学习的水印提高了基于扩散的图像编辑的鲁棒性，但当通过图像到视频（I2V）将水印图像转换为视频时，仍然存在差距，其中每帧水印检测减弱。 I2V 已从简短、不稳定的剪辑迅速发展为多秒、时间连贯的场景，现在它不仅服务于内容创建，还服务于世界建模和模拟工作流程，这使得跨模式水印恢复变得至关重要。我们推出了 WaTeRFlow，这是一个专为 I2V 下的鲁棒性而定制的框架。它由 (i) FUSE（流引导统一合成引擎）组成，它在训练期间通过指令驱动的编辑和快速视频扩散代理使编码器-解码器暴露于真实的失真，(ii) 具有稳定每帧预测的时间一致性损失 (TCL) 的光流扭曲，以及 (iii) 维持调节信号的语义保留损失。跨代表性 I2V 模型的实验表明，在视频生成之前或之后应用各种失真时，从帧中准确恢复水印，具有更高的首帧和每帧比特精度和弹性。|[2512.19048](http://arxiv.org/abs/2512.19048)|null|\n",
        "2512.19020": "|**2025-12-22**|**CETCAM: Camera-Controllable Video Generation via Consistent and Extensible Tokenization**|在视频生成中实现精确的摄像机控制仍然具有挑战性，因为现有方法通常依赖于摄像机姿态注释，而这些注释难以扩展到大型动态数据集，并且经常与深度估计不一致，从而导致训练测试差异。我们引入了 CETCAM，这是一种摄像机可控的视频生成框架，它通过一致且可扩展的标记化方案消除了对摄像机注释的需要。 CETCAM 利用几何基础模型（例如 VGGT）的最新进展来估计深度和相机参数，并将它们转换为统一的、几何感知的标记。这些令牌通过轻量级上下文块无缝集成到预训练的视频传播主干中。经过两个渐进阶段的训练，CETCAM 首先从不同的原始视频数据中学习强大的摄像机可控性，然后使用精心策划的高保真数据集细化细粒度的视觉质量。跨多个基准的大量实验证明了最先进的几何一致性、时间稳定性和视觉真实感。此外，CETCAM 对其他控制模式（包括修复和布局控制）表现出强大的适应性，突出了其超越相机控制的灵活性。项目页面位于 https://sjtuytc.github.io/CETCam_project_page.github.io/。|[2512.19020](http://arxiv.org/abs/2512.19020)|null|\n",
        "2512.18814": "|**2025-12-21**|**EchoMotion: Unified Human Video and Motion Generation via Dual-Modality Diffusion Transformer**|视频生成模型已经取得了显着进步，但由于人类发音的高度自由度，它们仍然难以合成复杂的人类运动。这种限制源于仅像素训练目标的内在限制，该目标本质上使模型偏向于外观保真度，而牺牲了学习基础运动学原理的代价。为了解决这个问题，我们引入了 EchoMotion，这是一个旨在对外观和人体运动的联合分布进行建模的框架，从而提高复杂人体动作视频生成的质量。 EchoMotion 使用双分支架构扩展了 DiT（扩散变压器）框架，该架构联合处理来自不同模态的令牌。此外，我们提出了 MVS-RoPE（运动视频同步 RoPE），它为视频和运动令牌提供统一的 3D 位置编码。通过为双模态潜在序列提供同步坐标系，MVS-RoPE 建立了一种归纳偏差，促进两种模态之间的时间对齐。我们还提出了运动视频两阶段训练策略。该策略使模型能够执行复杂人类动作视频及其相应运动序列的联合生成，以及多功能的跨模态条件生成任务。为了促进具有这些功能的模型的训练，我们构建了 HuMoVe，这是一个包含大约 80,000 个高质量、以人为中心的视频运动对的大型数据集。我们的研究结果表明，明确表示人体运动与外观是互补的，显着提高了以人为中心的视频生成的连贯性和合理性。|[2512.18814](http://arxiv.org/abs/2512.18814)|null|\n",
        "2512.18772": "|**2025-12-21**|**In-Context Audio Control of Video Diffusion Transformers**|视频生成领域的最新进展已经转向统一的、基于变压器的基础模型，该模型可以处理上下文中的多个条件输入。然而，这些模型主要关注文本、图像和深度图等模态，而对音频等严格时间同步信号的探索还不够。本文介绍了视频扩散变压器 (ICAC) 的上下文音频控制，这是一个框架，研究在统一的全注意力架构（类似于 FullDiT）中集成语音驱动视频生成的音频信号。我们系统地探索了注入音频条件的三种不同机制：标准交叉注意力、2D 自注意力和统一 3D 自注意力。我们的研究结果表明，虽然 3D 注意力在捕捉时空视听相关性方面具有最大潜力，但它也带来了巨大的训练挑战。为了克服这个问题，我们提出了一种 Masked 3D Attention 机制，该机制限制注意力模式以强制时间对齐，从而实现稳定的训练和卓越的性能。我们的实验表明，这种方法以音频流和参考图像为条件，实现了强大的唇形同步和视频质量。|[2512.18772](http://arxiv.org/abs/2512.18772)|null|\n",
        "2512.18741": "|**2025-12-21**|**Memorize-and-Generate: Towards Long-Term Consistency in Real-Time Video Generation**|帧级自回归（frame-AR）模型取得了重大进展，实现了与双向扩散模型相当的实时视频生成，并成为交互式世界模型和游戏引擎的基础。然而，目前长视频生成的方法通常依赖于窗口注意力，它天真地丢弃窗口外的历史上下文，导致灾难性的遗忘和场景不一致；相反，保留完整的历史记录会产生高昂的内存成本。为了解决这种权衡问题，我们提出了 \\textbf{Memorize-and-Generate (MAG)}，这是一个将内存压缩和帧生成解耦为不同任务的框架。具体来说，我们训练一个内存模型来将历史信息压缩到一个紧凑的 KV 缓存中，并训练一个单独的生成器模型来利用这种压缩表示来合成后续帧。此外，我们引入 \\textbf{MAG-Bench} 来严格评估历史内存保留。大量实验表明，MAG 实现了卓越的历史场景一致性，同时在标准视频生成基准上保持了具有竞争力的性能。|[2512.18741](http://arxiv.org/abs/2512.18741)|null|\n",
        "2512.18614": "|**2025-12-21**|**PTTA: A Pure Text-to-Animation Framework for High-Quality Creation**|传统动画制作流程复杂，人工成本高。虽然最近的视频生成模型（例如 Sora、Kling 和 CogVideoX）在自然视频合成方面取得了令人印象深刻的结果，但它们在应用于动画生成时表现出明显的局限性。最近的工作，例如 AniSora，通过针对动画风格微调图像到视频模型，展示了有希望的性能，但在文本到视频设置中的类似探索仍然有限。   在这项工作中，我们提出了 PTTA，一个用于高质量动画创作的纯文本到动画框架。我们首先构建一个小规模但高质量的动画视频和文本描述配对数据集。基于预训练的文本到视频模型 HunyuanVideo，我们进行微调以使其适应动画风格的生成。跨多个维度的广泛视觉评估表明，所提出的方法始终优于动画视频合成中的可比基线。|[2512.18614](http://arxiv.org/abs/2512.18614)|null|\n",
        "2512.20619": "|**2025-12-24**|**SemanticGen: Video Generation in Semantic Space**|最先进的视频生成模型通常会学习 VAE 空间中视频潜伏的分布，并使用 VAE 解码器将它们映射到像素。虽然这种方法可以生成高质量的视频，但它的收敛速度较慢，并且在生成长视频时计算成本较高。在本文中，我们介绍了 SemanticGen，这是一种通过在语义空间中生成视频来解决这些限制的新颖解决方案。我们的主要见解是，由于视频固有的冗余性，生成过程应该从紧凑的高级语义空间开始进行全局规划，然后添加高频细节，而不是使用双向注意力直接对大量低级视频标记进行建模。 SemanticGen 采用两阶段生成过程。在第一阶段，扩散模型生成紧凑的语义视频特征，定义视频的全局布局。在第二阶段，另一个扩散模型根据这些语义特征生成 VAE 潜伏，以产生最终输出。我们观察到，与 VAE 潜在空间相比，语义空间中的生成会导致更快的收敛。当扩展到长视频生成时，我们的方法也是有效且计算效率高的。大量的实验表明，SemanticGen 可以生成高质量的视频，并且性能优于最先进的方法和强大的基线。|[2512.20619](http://arxiv.org/abs/2512.20619)|null|\n",
        "2512.20606": "|**2025-12-23**|**Repurposing Video Diffusion Transformers for Robust Point Tracking**|点跟踪旨在跨视频帧定位对应点，作为 4D 重建、机器人和视频编辑的基本任务。现有方法通常依赖于 ResNet 等浅层卷积主干，独立处理帧，缺乏时间一致性，并在具有挑战性的条件下产生不可靠的匹配成本。通过系统分析，我们发现视频扩散变压器（DiT）在具有时空注意力的大规模现实世界视频上进行预训练，本质上表现出强大的点跟踪能力，并能稳健地处理动态运动和频繁遮挡。我们提出了 DiTracker，它通过以下方式调整视频 DiT：(1) 查询键注意力匹配，(2) 轻量级 LoRA 调整，以及 (3) 与 ResNet 主干的成本融合。尽管使用小 8 倍的批量大小进行训练，DiTracker 在具有挑战性的 ITTO 基准上仍实现了最先进的性能，并且在 TAP-Vid 基准上匹配或优于最先进的模型。我们的工作验证了视频 DiT 功能作为点跟踪的有效且高效的基础。|[2512.20606](http://arxiv.org/abs/2512.20606)|null|\n",
        "2512.20052": "|**2025-12-23**|**Learning Skills from Action-Free Videos**|从视频中学习通过提供超出真实机器人数据集包含的丰富视觉和时间先验，为通才机器人提供了一条有前途的道路。虽然现有的视频生成模型可以产生令人印象深刻的视觉预测，但它们很难转化为低级动作。相反，潜在动作模型可以更好地将视频与动作结合起来，但它们通常在单步级别上运行，缺乏高级规划能力。我们通过引入光流技能抽象（SOF）来弥补这一差距，这是一个从大量无动作视频中学习潜在技能的框架。我们的关键想法是通过基于光流的中间表示来学习潜在技能空间，该中间表示捕获与视频动力学和机器人动作一致的运动信息。通过在基于流的潜在空间中学习技能，SOF 可以对视频衍生技能进行高级规划，并可以更轻松地将这些技能转化为行动。实验表明，我们的方法持续提高了多任务和长视野设置中的性能，展示了直接从原始视觉数据获取和组合技能的能力。|[2512.20052](http://arxiv.org/abs/2512.20052)|null|\n",
        "2512.20000": "|**2025-12-23**|**Few-Shot-Based Modular Image-to-Video Adapter for Diffusion Models**|扩散模型 (DM) 最近在图像和视频生成方面取得了令人印象深刻的照片级真实感。然而，即使在大规模数据集上进行训练，它们在图像动画中的应用仍然有限。造成这种情况的两个主要挑战是：视频信号的高维性导致训练数据的稀缺，导致 DM 在生成运动时更倾向于记忆而不是迅速遵守；此外，DM 很难推广到训练集中不存在的新颖运动模式，并且对它们进行微调以学习这些模式，特别是使用有限的训练数据，仍然有待探索。为了解决这些限制，我们提出了模块化图像到视频适配器（MIVA），这是一种可附加到预先训练的 DM 的轻量级子网络，每个子网络都旨在捕获单个运动模式并通过并行化进行扩展。使用单个消费级 GPU 可以对大约 10 个样本进行有效的 MIVA 训练。在推理时，用户可以通过选择一个或多个 MIVA 来指定运动，从而无需进行即时工程。大量实验表明，MIVA 可以实现更精确的运动控制，同时保持甚至超越在更大的数据集上训练的模型的生成质量。|[2512.20000](http://arxiv.org/abs/2512.20000)|null|\n",
        "2512.19949": "|**2025-12-23**|**How Much 3D Do Video Foundation Models Encode?**|视频是 3D 世界的连续 2D 投影。经过大视频数据的训练后，全局 3D 理解会自然出现吗？我们通过量化对大量视频数据预训练的现有视频基础模型 (VidFM) 的 3D 理解来研究这一问题。我们提出了第一个与模型无关的框架，通过浅读出从其特征估计多个 3D 属性，来测量各种 VidFM 的 3D 感知。我们的研究提出了有关 VidFM 多轴 3D 感知的有意义的发现。特别是，我们表明，最先进的视频生成模型表现出对 3D 对象和场景的深刻理解，尽管没有接受任何 3D 数据的训练。这种理解甚至可以超越专门针对 3D 任务训练的大型专家模型。我们的研究结果以及主要 VidFM 的 3D 基准测试为构建可扩展的 3D 模型提供了宝贵的观察结果。|[2512.19949](http://arxiv.org/abs/2512.19949)|null|\n",
        "2512.19823": "|**2025-12-24**|**Learning to Refocus with Video Diffusion Models**|对焦是摄影的基石，但自动对焦系统常常无法捕捉到预期的拍摄对象，并且用户经常希望在捕捉后调整焦点。我们引入了一种使用视频扩散模型进行真实捕获后重新聚焦的新颖方法。我们的方法从单个散焦图像生成一个感知准确的焦点堆栈，表示为视频序列，从而实现交互式重新聚焦并解锁一系列下游应用程序。我们发布了在不同的现实世界智能手机条件下获取的大规模焦点堆栈数据集，以支持这项工作和未来的研究。我们的方法在感知质量和跨挑战性场景的鲁棒性方面始终优于现有方法，为日常摄影中更先进的焦点编辑功能铺平了道路。代码和数据可在 https://learn2refocus.github.io 获取|[2512.19823](http://arxiv.org/abs/2512.19823)|null|\n",
        "2512.19817": "|**2025-12-22**|**Generating the Past, Present and Future from a Motion-Blurred Image**|我们试图回答这个问题：运动模糊图像可以揭示场景的过去、现在和未来的哪些内容？尽管运动模糊会模糊图像细节并降低视觉质量，但它也会对曝光期间的场景和相机运动信息进行编码。以前的技术利用这些信息从输入的模糊图像中估计出清晰的图像，或者预测一系列视频帧，显示图像捕获时可能发生的情况。然而，他们依靠手工设计的先验或网络架构来解决这个逆问题中的歧义，并且不将图像和视频先验纳入大规模数据集。因此，现有的方法很难再现复杂的场景动态，并且不尝试恢复图像拍摄之前或之后发生的情况。在这里，我们介绍了一种新技术，该技术重新利用在互联网规模数据集上训练的预先训练的视频传播模型来恢复视频，以揭示捕捉时的复杂场景动态以及过去或未来可能发生的情况。我们的方法稳健且通用；它在该任务上优于以前的方法，可推广到具有挑战性的野外图像，并支持下游任务，例如恢复相机轨迹、物体运动和动态 3D 场景结构。代码和数据可在 https://blur2vid.github.io 获取|[2512.19817](http://arxiv.org/abs/2512.19817)|null|\n",
        "2512.21338": "|**2025-12-24**|**HiStream: Efficient High-Resolution Video Generation via Redundancy-Eliminated Streaming**|高分辨率视频生成虽然对数字媒体和电影至关重要，但由于扩散模型的二次复杂性而成为计算瓶颈，使得实际推理变得不可行。为了解决这个问题，我们引入了 HiStream，一种高效的自回归框架，可以系统地减少三个轴上的冗余： i) 空间压缩：在低分辨率下进行去噪，然后使用缓存特征以高分辨率进行细化； ii) 时间压缩：采用逐块策略，固定大小的锚点缓存，保证稳定的推理速度； iii) 时间步长压缩：对后续的缓存条件块应用更少的去噪步骤。在 1080p 基准测试中，我们的主要 HiStream 模型 (i+ii) 实现了最先进的视觉质量，同时与 Wan2.1 基准相比，去噪速度提高了 76.2 倍，并且质量损失可以忽略不计。我们的更快变体 HiStream+ 应用了所有三种优化 (i+ii+iii)，实现了基线 107.5 倍的加速，在速度和质量之间提供了令人信服的权衡，从而使高分辨率视频生成既实用又可扩展。|[2512.21338](http://arxiv.org/abs/2512.21338)|null|\n",
        "2512.21268": "|**2025-12-24**|**ACD: Direct Conditional Control for Video Diffusion Models via Attention Supervision**|可控性是视频合成的基本要求，其中与调节信号的精确对准至关重要。现有的无分类器引导方法通常通过对数据和条件的联合分布进行建模来间接实现调节，这通常会导致对指定条件的可控性有限。基于分类器的指导通过外部分类器强制执行条件，但模型可能会利用这种机制来提高分类器分数，而没有真正满足预期条件，从而导致对抗性伪影和有限的有效可控性。在本文中，我们提出了注意力条件扩散（ACD），这是一种通过注意力监督在视频扩散模型中进行直接条件控制的新颖框架。通过将模型的注意力图与外部控制信号对齐，ACD 实现了更好的可控性。为了支持这一点，我们引入了稀疏 3D 感知对象布局作为有效的调节信号，以及专用的布局 ControlNet 和用于可扩展布局集成的自动注释管道。对基准视频生成数据集的大量实验表明，ACD 可以与条件输入实现出色的对齐，同时保持时间连贯性和视觉保真度，从而为条件视频合成建立了有效的范例。|[2512.21268](http://arxiv.org/abs/2512.21268)|null|\n",
        "2512.21252": "|**2025-12-24**|**DreaMontage: Arbitrary Frame-Guided One-Shot Video Generation**|“一次性”技术代表了电影制作中独特而复杂的美学。然而，其实际实现往往受到高昂的成本和复杂的现实限制的阻碍。尽管新兴的视频生成模型提供了虚拟替代方案，但现有方法通常依赖于简单的剪辑串联，这常常无法保持视觉平滑度和时间连贯性。在本文中，我们介绍了DreaMontage，这是一种专为任意帧引导生成而设计的综合框架，能够从不同的用户提供的输入中合成无缝、富有表现力和长时间的一次性视频。为了实现这一目标，我们通过三个主要维度应对挑战。 (i) 我们将轻量级中间调节机制集成到 DiT 架构中。通过采用有效利用基础训练数据的自适应调整策略，我们解锁了强大的任意帧控制功能。 (ii) 为了增强视觉保真度和电影表现力，我们策划了高质量的数据集并实现了视觉表达 SFT 阶段。在解决主体运动合理性和过渡平滑性等关键问题时，我们采用了定制的DPO方案，显着提高了生成内容的成功率和可用性。 （iii）为了促进扩展序列的生成，我们设计了一种以内存高效方式运行的分段自回归（SAR）推理策略。大量的实验表明，我们的方法实现了视觉冲击力和无缝连贯的一次性效果，同时保持计算效率，使用户能够将碎片化的视觉材料转化为生动、有凝聚力的一次性电影体验。|[2512.21252](http://arxiv.org/abs/2512.21252)|null|\n",
        "2512.21094": "|**2025-12-24**|**T2AV-Compass: Towards Unified Evaluation for Text-to-Audio-Video Generation**|文本到音频视频（T2AV）生成旨在从自然语言合成时间连贯的视频和语义同步的音频，但其评估仍然支离破碎，通常依赖于单模态指标或范围狭窄的基准，无法捕获复杂提示下的跨模态对齐、指令遵循和感知现实主义。为了解决这一限制，我们提出了 T2AV-Compass，这是一个用于全面评估 T2AV 系统的统一基准，由通过分类驱动的管道构建的 500 个多样化且复杂的提示组成，以确保语义丰富性和物理合理性。此外，T2AV-Compass 引入了一个双级评估框架，该框架将视频质量、音频质量和跨模式对齐的客观信号级指标与用于指令跟踪和真实性评估的主观 MLLM-as-a-Judge 协议集成在一起。对 11 个代表性 T2AVsystems 的广泛评估表明，即使是最强大的模型也远远达不到人类水平的真实感和跨模态一致性，在音频真实感、细粒度同步、指令遵循等方面持续失败。这些结果表明未来模型有显着的改进空间，并凸显了 T2AV-Compass 作为推进文本到音频视频生成的具有挑战性和诊断性的测试平台的价值。|[2512.21094](http://arxiv.org/abs/2512.21094)|null|\n"
    },
    "3D": {
        "2512.17907": "|**2025-12-19**|**Dexterous World Models**|3D 重建领域的最新进展使得从日常环境中创建逼真的数字孪生变得容易。然而，当前的数字孪生在很大程度上仍然是静态的，并且仅限于导航和视图合成，没有具体的交互性。为了弥补这一差距，我们引入了灵巧世界模型 (DWM)，这是一种场景动作条件视频扩散框架，用于模拟灵巧的人类动作如何引起静态 3D 场景的动态变化。   给定静态 3D 场景渲染和以自我为中心的手部运动序列，DWM 会生成时间连贯的视频，描绘合理的人景交互。我们的方法将视频生成条件限制为（1）遵循指定摄像机轨迹的静态场景渲染，以确保空间一致性，以及（2）以自我为中心的手部网格渲染，对几何和运动线索进行编码，以直接对动作条件动态进行建模。为了训练 DWM，我们构建了一个混合交互视频数据集。合成的以自我为中心的交互为关节运动和操作学习提供了完全一致的监督，而固定摄像头的真实世界视频则提供了多样化和真实的对象动态。   实验表明，DWM 可实现真实且物理上合理的交互，例如抓取、打开和移动对象，同时保持相机和场景的一致性。该框架代表了迈向基于视频传播的交互式数字孪生的第一步，并实现了以自我为中心的行为的具体模拟。|[2512.17907](http://arxiv.org/abs/2512.17907)|null|\n",
        "2512.17895": "|**2025-12-19**|**Visualization of The Content of Surah al Fiil using Marker-Based Augmented Reality**|本研究介绍了基于标记的增强现实 (AR) 应用程序的开发，旨在将 Surah al-Fil 的内容可视化，作为伊斯兰教育的交互式和上下文丰富的媒介。该系统采用研发方法，通过结构化阶段进行开发，包括数据收集、用户需求分析、界面设计、使用 Blender 创建 3D 资产以及 Unity 3D 与 Vuforia SDK 的集成。该应用程序具有大象军队、天房和阿巴比勒鸟等关键视觉元素，这些元素经过详细建模并链接到高对比度图像标记，以确保准确和稳定的 AR 跟踪。功能测试展示了强大的技术性能，在 30-40 厘米的最佳距离下实现了 95% 的标记检测精度，并在多个 Android 设备上实现了一致的实时渲染。学生和伊斯兰教育教师的用户评价表明接受度很高，在可用性、视觉吸引力、互动性和学习效果方面的总体满意度为 4.7 分（满分 5 分）。这些发现表明，基于 AR 的学习媒体可以提高学习者的参与度，加深对古兰经叙述的理解，并提供对历史和精神背景的身临其境的见解。总体而言，这项研究表明，基于标记的 AR 技术具有巨大的潜力，可以通过交互式和视觉直观的体验丰富传统学习，从而支持数字伊斯兰教育的创新。|[2512.17895](http://arxiv.org/abs/2512.17895)|null|\n",
        "2512.17820": "|**2025-12-19**|**Exploiting ID-Text Complementarity via Ensembling for Sequential Recommendation**|现代顺序推荐（SR）模型通常利用模态特征来表示项目，这在很大程度上受到语言和视觉建模的最新进展的推动。为此，一些工作用模态嵌入完全取代了 ID 嵌入，声称模态嵌入使 ID 嵌入变得不必要，因为它们可以匹配甚至超过 ID 嵌入性能。另一方面，许多工作联合利用 ID 和模态特征，但假设复杂的融合策略，例如多阶段训练和/或复杂的对齐架构，对于这种联合利用是必要的。然而，这两项工作的根本原因是缺乏对 ID 和模态特征的互补性的理解。在这项工作中，我们通过研究基于 ID 和基于文本的 SR 模型的互补性来解决这一差距。我们证明这些模型确实学习了互补信号，这意味着当与另一个模型一起正确使用时，任何一个模型都应该提供性能增益。受此启发，我们提出了一种新的 SR 方法，通过独立的模型训练保留 ID-文本互补性，然后通过简单的集成策略来利用它。尽管这种方法很简单，但我们证明它优于几个竞争性的 SR 基线，这意味着 ID 和文本特征对于实现最先进的 SR 性能是必要的，但复杂的融合架构则不然。|[2512.17820](http://arxiv.org/abs/2512.17820)|null|\n",
        "2512.17817": "|**2025-12-19**|**Chorus: Multi-Teacher Pretraining for Holistic 3D Gaussian Scene Encoding**|虽然 3DGS 已成为一种高保真场景表示，但直接从其基元编码丰富的通用特征仍然尚未得到充分探索。我们通过引入 Chorus 来解决这一差距，Chorus 是一个多教师预训练框架，通过从 2D 基础模型中提取互补信号来学习整体前馈 3D 高斯 Splatting (3DGS) 场景编码器。 Chorus 采用共享 3D 编码器和教师专用投影仪，向语言一致、通才和对象感知的教师学习，鼓励共享嵌入空间，捕获从高级语义到细粒度结构的信号。   我们在广泛的任务上评估 Chorus：开放词汇语义和实例分割、线性和解码器探测以及数据高效监督。除了 3DGS 之外，我们还在几个仅支持点云的基准上测试 Chorus，方法是仅使用高斯中心、颜色、估计法线作为输入来预训练变体。有趣的是，该编码器显示出强大的传输能力，并且优于点云基线，同时使用的训练场景减少了 39.9 倍。最后，我们提出了一种渲染和提取的适应方法，以促进域外微调。我们的代码和模型将在发布后发布。|[2512.17817](http://arxiv.org/abs/2512.17817)|null|\n",
        "2512.17781": "|**2025-12-19**|**LiteGE: Lightweight Geodesic Embedding for Efficient Geodesics Computation and Non-Isometric Shape Correspondence**|计算 3D 表面上的测地距离是 3D 视觉和几何处理中许多任务的基础，与形状对应等任务有着深刻的联系。最近基于学习的方法实现了强大的性能，但依赖于大型 3D 主干，导致内存使用率和延迟较高，这限制了它们在交互式或资源受限设置中的使用。我们引入了 LiteGE，这是一种轻量级方法，通过将 PCA 应用于信息体素的无符号距离场 (UDF) 样本来构造紧凑的、类别感知的形状描述符。该描述符的计算效率很高，并且无需高容量网络。 LiteGE 在稀疏点云上仍然保持鲁棒性，支持少至 300 个点的输入，而之前的方法则无法做到这一点。大量实验表明，与现有神经方法相比，LiteGE 可将内存使用量和推理时间减少高达 300$\\times$。此外，通过利用测地距离和形状对应之间的内在关系，LiteGE 能够实现快速、准确的形状匹配。与最先进的基于网格的方法相比，我们的方法可实现高达 1000 美元\\倍的加速，同时在非等距形状对上保持相当的精度，包括对点云输入的评估。|[2512.17781](http://arxiv.org/abs/2512.17781)|null|\n",
        "2512.17773": "|**2025-12-19**|**Pix2NPHM: Learning to Regress NPHM Reconstructions From a Single Image**|神经参数化头部模型 (NPHM) 是相对于基于网格的 3D 可变形模型 (3DMM) 的最新进展，可促进高保真几何细节。然而，由于 NPHM 潜在空间的表达性质，将 NPHM 与视觉输入相匹配是出了名的具有挑战性。为此，我们提出了 Pix2NPHM，一种视觉变换器（ViT）网络，在给定单个图像作为输入的情况下，直接回归 NPHM 参数。与现有方法相比，神经参数空间使我们的方法能够重建更可识别的面部几何形状和准确的面部表情。为了广泛推广，我们利用特定领域的 ViT 作为主干，这些主干在几何预测任务上进行了预训练。我们在 3D 数据的混合上训练 Pix2NPHM，包括总共超过 100K 的 NPHM 配准，可以在 SDF 空间中进行直接监督，以及大规模 2D 视频数据集，其中法线估计用作伪地面实况几何。 Pix2NPHM 不仅允许以交互帧速率进行 3D 重建，还可以通过针对估计表面法线和规范点图的后续推理时间优化来提高几何保真度。因此，我们实现了前所未有的面部重建质量，可以在野外数据上大规模运行。|[2512.17773](http://arxiv.org/abs/2512.17773)|null|\n",
        "2512.17757": "|**2025-12-19**|**Spectral finite-element formulation of the optimized effective potential method for atomic structure in the random phase approximation**|我们提出了优化有效势（OEP）方法的谱有限元公式，用于随机相位近似（RPA）中的原子结构计算。特别是，我们开发了一个有限元框架，该框架采用多项式网格，其元素节点根据 Chebyshev-Gauss-Lobatto 方案放置，高阶 $\\mathcal{C}^0$-连续拉格朗日多项式基函数以及用于空间积分的高斯-勒让德求积。我们对轨道、Hartree 势和 RPA-OEP 交换相关势采用不同的多项式次数。通过代表性的例子，我们验证了所开发框架的准确性，评估了用 RPA 相关性构建的单参数双混合泛函的保真度，并基于核方法和线性回归，在广义梯度近似水平上开发了 RPA-OEP 交换相关势的机器学习模型。|[2512.17757](http://arxiv.org/abs/2512.17757)|null|\n",
        "2512.17732": "|**2025-12-19**|**Design, Testing and Numerical Modelling of a Low-Speed Wind Tunnel Gust Generator**|理解并准确再现阵风引起的非定常空气动力学对于改进飞机、无人机和风力涡轮机的负载预测、气动弹性分析和控制策略至关重要，特别是在非线性流动现象占主导地位的情况下。在这项工作中，通过实验和数值研究相结合，设计、制造了一种基于振荡叶片的低速风洞阵风发生器，并进行了表征。该系统旨在重现与飞机、无人机和风力涡轮机应用相关的确定性阵风剖面，这些阵风剖面在高度不稳定的空气动力学状态下运行。使用热线风速计进行实验测量，以量化在一定范围的自由流速度、振幅和强迫频率下生成的阵风场。同时，使用变形网格方法进行时间精确的 CFD 模拟，以验证测量结果并分析与阵风形成和传播相关的流动物理现象。特别注意经典“1-cos”阵风剖面固有的负速度峰值。提出了一种改进的叶片运动协议，并证明可以显着降低负峰值系数，同时保持相当大的阵风比。数值结果表明，二次流角变化是由相邻叶片脱落的涡流之间的非线性相互作用引起的。|[2512.17732](http://arxiv.org/abs/2512.17732)|null|\n",
        "2512.17696": "|**2025-12-19**|**Spatially-informed transformers: Injecting geostatistical covariance biases into self-attention for spatio-temporal forecasting**|高维时空过程的建模呈现出经典地质统计学的概率严谨性与深度学习的灵活、高容量表示之间的基本二分法。虽然高斯过程提供了理论一致性和精确的不确定性量化，但其令人望而却步的计算规模使得它们对于大规模传感器网络来说不切实际。相反，现代变压器架构擅长序列建模，但本质上缺乏几何归纳偏差，将空间传感器视为排列不变的标记，而没有对距离的本机理解。在这项工作中，我们提出了一种空间信息变压器，一种混合​​架构，通过可学习的协方差内核将地统计归纳偏差直接注入自注意力机制中。通过将注意力结构正式分解为静态物理先验和非静态数据驱动残差，我们施加了软拓扑约束，有利于空间邻近交互，同时保留对复杂动态进行建模的能力。我们演示了“深度变异”现象，其中网络通过反向传播成功地端到端地恢复了底层过程的真实空间衰减参数。对合成高斯随机场和现实世界流量基准的大量实验证实，我们的方法优于最先进的图神经网络。此外，严格的统计验证证实，所提出的方法不仅能够提供卓越的预测准确性，而且能够提供经过良好校准的概率预测，有效地弥合了物理感知建模和数据驱动学习之间的差距。|[2512.17696](http://arxiv.org/abs/2512.17696)|null|\n",
        "2512.17666": "|**2025-12-19**|**Local h-, p-, and k-Refinement Strategies for the Isogeometric Shifted Boundary Method Using THB-Splines**|近年来，将几何图形修剪、嵌入或浸没到计算背景网格中的概念引起了相当大的关注，特别是在等几何分析 (IGA) 中。在这种方法中，物理域的表示独立于计算网格，与贴体网格相比，可以更轻松地生成后者。虽然这有利于复杂几何形状的处理，但它也带来了挑战，例如小切割单元引起的刚度矩阵病态以及精确执行边界条件的困难。最近提出的解决这些问题的技术是移位边界法（SBM），它仅通过未切割元素表示计算域，并通过从代理边界到真实边界的泰勒展开来强制边界条件。先前的研究表明，对于诺依曼边界条件，通量评估需要在泰勒展开式中附加导数，有效地将收敛阶数降低一阶。在这项工作中，我们首次研究了 SBM 与截断分层 B 样条（THB 样条）相结合在各种局部细化策略下的性能。特别是，我们提出了 THB 样条的局部 p 和 k 细化方案，并将它们与局部 h 细化和未修改的 SBM 进行比较。此外，与标准运算符相比，我们提出了一种增强的移位运算符，它包含混合偏导数。该研究评估了修剪域上基准问题的准确性、稳定性和计算效率。结果强调了不同的细化策略如何影响使用 SBM 修剪的 IGA 公式的收敛行为，并证明目标度提升可以减轻标准方法的诺依曼边界限制。|[2512.17666](http://arxiv.org/abs/2512.17666)|null|\n",
        "2512.19684": "|**2025-12-22**|**Zero-shot Reconstruction of In-Scene Object Manipulation from Video**|我们构建了第一个系统来解决从单目 RGB 视频重建场景内对象操作的问题。由于不恰当的场景重建、模糊的手部物体深度以及物理上合理的交互的需要，这具有挑战性。现有方法以手为中心的坐标进行操作，忽略了场景，阻碍了测量精度和实际使用。在我们的方法中，我们首先使用数据驱动的基础模型来初始化核心组件，包括对象网格和姿势、场景点云和手部姿势。然后，我们应用两阶段优化来恢复从抓取到交互的完整手部物体运动，这与输入视频中观察到的场景信息保持一致。|[2512.19684](http://arxiv.org/abs/2512.19684)|null|\n",
        "2512.19648": "|**2025-12-22**|**4D Gaussian Splatting as a Learned Dynamical System**|我们将 4D 高斯泼溅重新解释为连续时间动态系统，其中场景运动是通过集成学习的神经动态场而不是应用每帧变形而产生的。这个公式，我们称之为 EvoGS，将高斯表示视为一个不断演化的物理系统，其状态在学习的运动定律下不断演化。这解锁了基于变形的方法所缺乏的功能：（1）通过对底层运动规律进行建模，从稀疏时间监督中进行样本有效学习； (2) 时间外推能够实现超出观测时间范围的前向和后向预测； (3) 合成动力学，允许局部动力学注入以实现可控场景合成。动态场景基准测试表明，与变形场基线相比，EvoGS 在保持实时渲染的同时实现了更好的运动连贯性和时间一致性|[2512.19648](http://arxiv.org/abs/2512.19648)|null|\n",
        "2512.19616": "|**2025-12-22**|**Thermodynamics of large-scale chemical reaction networks**|化学和生物网络可以描述从基因调控网络到生化振荡的各种过程。这些过程通过化学主方程建模，本质上是随机的，因为波动在介观尺度上主导着确定性秩序。这些经典的多体过程遭受所谓的高维诅咒，这使得精确的数学描述的计算成本呈指数级增长。指数成本使得对此类不平衡系统的热力学性质的研究变得棘手，并迫使系统噪声的近似值或连续粒子数的假设。在这里，我们使用张量网络通过以高效（次指数）计算成本直接求解化学主方程的系综解来数值探索化学过程的热力学。我们提供对熵产率、热通量、化学功和非平衡热力学势的准确估计，没有采样误差或平均场近似。我们通过耗散自组装模型来说明我们的结果。通过这种方式，我们展示了张量网络如何为以前无法​​实现的方案中的高效化学过程的设计提供信息。|[2512.19616](http://arxiv.org/abs/2512.19616)|null|\n",
        "2512.19584": "|**2025-12-22**|**Patlak Parametric Image Estimation from Dynamic PET Using Diffusion Model Prior**|动态 PET 能够定量估计生理相关参数，广泛应用于研究，并越来越多地应用于临床。动态 PET 中的参数成像需要动力学建模，以根据特定的动力学模型估计体素生理参数。然而，由于拟合过程固有的不适定性质以及全身 PET 中多个床位置的非连续数据采集导致的有限计数，通过动力学模型拟合估计的参数图像通常图像质量较低。在这项工作中，我们以 Patlak 模型为例，提出了一种基于扩散模型的动力学建模框架，用于参数图像估计。扩散模型的评分函数是在静态全身 PET 图像上进行预训练的，并通过利用 Patlak 斜率和截距图像的块状相似性作为先验。在推理过程中，将动力学模型作为数据一致性约束来指导参数图像估计。所提出的框架在不同剂量水平的全身动态 PET 数据集上进行了评估，证明了所提出的框架在提高参数图像质量方面的可行性和良好的性能。|[2512.19584](http://arxiv.org/abs/2512.19584)|null|\n",
        "2512.19522": "|**2025-12-22**|**A Convolutional Neural Deferred Shader for Physics Based Rendering**|通过使用多层感知器 (MLP) 作为回归模型从真实数据集中学习渲染方程，神经渲染领域的最新进展在真实感着色和重新照明方面取得了令人印象深刻的结果。这种方法有望以照片般真实的方式重新照亮现实世界的物体，这对于经典渲染来说是困难的，因为没有容易获得的物质基础事实。然而，重大挑战仍然存在，MLP 中的密集连接导致大量参数，需要大量计算资源，使训练复杂化，并降低渲染过程中的性能。数据驱动的方法需要大量的训练数据来进行泛化；不平衡的数据可能会使模型产生偏差，从而忽略不寻常的照明条件，例如黑暗的场景。本文介绍了 pbnds+：一种新颖的基于物理的神经延迟着色管道，利用卷积神经网络来减少参数并提高着色和重新照明任务的性能；还提出了能量正则化来限制暗照明期间的模型反射。大量的实验表明，我们的方法优于经典基线、最先进的神经着色模型和基于扩散的方法。|[2512.19522](http://arxiv.org/abs/2512.19522)|null|\n",
        "2512.19390": "|**2025-12-22**|**TwinAligner: Visual-Dynamic Alignment Empowers Physics-aware Real2Sim2Real for Robotic Manipulation**|受多模式大型模型的启发，机器人领域正在向数据驱动的端到端学习发展。然而，对昂贵的现实世界数据的依赖限制了进展。模拟器提供了具有成本效益的替代方案，但模拟与现实之间的差距挑战了有效的政策转移。本文介绍了 TwinAligner，这是一种新颖的 Real2Sim2Real 系统，可解决视觉和动态间隙问题。视觉对准模块通过SDF重建和可编辑的3DGS渲染实现像素级对准，而动态对准模块通过识别机器人与物体交互中的刚性物理来确保动态一致性。 TwinAligner 通过提供可扩展的数据收集和建立值得信赖的迭代周期来改进机器人学习，从而加速算法开发。定量评估凸显了 TwinAligner 在视觉和动态实模拟对准方面的强大能力。该系统使经过模拟训练的策略能够实现对现实世界的强大的零样本泛化。现实世界和模拟策略性能之间的高度一致性凸显了 TwinAligner 推进可扩展机器人学习的潜力。代码和数据将在 https://twin-aligner.github.io 上发布|[2512.19390](http://arxiv.org/abs/2512.19390)|null|\n",
        "2512.19321": "|**2025-12-22**|**Learning-Assisted Multi-Operator Variable Neighborhood Search for Urban Cable Routing**|城市地下电缆建设对于提高城市电网的可靠性至关重要，但其高昂的建设成本使得规划成为一项值得优化的任务。在城市环境中，道路布局严格限制电缆布线。一方面，这使得先前工作中使用的纯关系模型（即没有显式路径的模型）过于简单化，另一方面，极大地扩大了组合搜索空间，从而对算法设计提出了更高的要求。在本研究中，我们将城市电缆路由制定为连通路径协同优化问题，并提出了一种学习辅助的多算子变量邻域搜索（L-MVNS）算法。该框架首先引入了一个辅助任务来生成高质量的可行初始解决方案。混合遗传搜索 (HGS) 和 A* 分别充当连接优化器和路线规划优化器。在此基础上，多算子变量邻域搜索 (MVNS) 通过三个互补的破坏算子、改进的 A* 修复算子和自适应邻域大小调整机制，迭代地共同优化变电站间的连接性和详细路线。进一步嵌入多智能体深度强化学习模块，以优先考虑有前途的社区。我们还构建了标准化且可扩展的评估基准套件。在这些案例中，全面的实验证明了有效性和稳定性：相对于代表性方法，MVNS 和 L-MVNS 将总构建成本降低了大约 30-50%，L-MVNS 在更大的实例上提供了额外的收益，并始终保持更高的稳定性。|[2512.19321](http://arxiv.org/abs/2512.19321)|null|\n",
        "2512.19316": "|**2025-12-22**|**Neural Implicit Heart Coordinates: 3D cardiac shape reconstruction from sparse segmentations**|从稀疏的临床图像准确重建心脏解剖结构仍然是患者特异性建模的主要挑战。虽然神经隐式函数之前已应用于此任务，但它们在绘制受试者之间的解剖一致性方面的应用受到限制。在这项工作中，我们介绍了神经隐式心脏坐标（NIHC），这是一种基于通用心室坐标的标准化隐式坐标系，为人类心脏提供了通用的解剖参考系。我们的方法直接从有限数量的 2D 分割（稀疏采集）预测 NIHC，然后将它们解码为任意输出分辨率的密集 3D 分割和高分辨率网格。该模型在包含 5,000 个心脏网格的大型数据集上进行训练，在临床轮廓上实现了较高的重建精度，患病队列 (n=4549) 中的平均欧几里得表面误差为 2.51$\\pm$0.33 mm，健康队列 (n=5576) 中的平均欧几里得表面误差为 2.3$\\pm$0.36 mm。即使在严重的切片稀疏和分割噪声下，NIHC 表示也能实现解剖学上的连贯重建，忠实地恢复瓣膜平面等复杂结构。与传统管道相比，推理时间从60多秒缩短至5-15秒。这些结果表明，NIHC 为根据最少输入数据进行患者特异性 3D 心脏重建提供了稳健且有效的解剖学表示。|[2512.19316](http://arxiv.org/abs/2512.19316)|null|\n",
        "2512.19273": "|**2025-12-22**|**Scale-Invariant Robust Estimation of High-Dimensional Kronecker-Structured Matrices**|高维克罗内克结构估计面临着非凸尺度模糊性和统计鲁棒性之间的冲突。任意因子缩放会扭曲梯度幅度，导致标准固定阈值鲁棒方法无效。我们通过缩放稳健梯度下降（SRGD）解决了这个问题，它通过在截断之前对梯度进行去缩放来稳定优化。为了进一步增强可解释性，我们引入了缩放硬阈值（SHT）来进行不变变量选择。针对典型矩阵问题（例如迹回归、矩阵 GLM 和双线性模型），提出了一种基于鲁棒初始化和 SRGD--SHT 迭代更新的两步估计过程。为重尾预测变量和噪声建立收敛速率，识别相变，其中最佳收敛速率在有限噪声方差下恢复，并针对较重尾部最优退化。模拟数据和两个实际应用的实验证实了所提出的程序具有卓越的鲁棒性和效率。|[2512.19273](http://arxiv.org/abs/2512.19273)|null|\n",
        "2512.19241": "|**2025-12-22**|**Formation of external particle jets on a spherical particle bed subjected to strong explosive loading**|我们报告了在承受强爆炸载荷的球形颗粒床上形成外部颗粒射流的机制，揭示了对颗粒尺寸的关键依赖性。在强爆炸载荷下，外部粒子射流的形成主要由阻力耦合机制驱动。我们针对小颗粒和大颗粒情况进行了欧拉-拉格朗日模拟，在自适应网格上使用高达 2048^3$ 的有效单元和 180 万美元的跟踪地块。仅在小颗粒的情况下观察到明显的射流，同时床层加速增厚。通过定义特征内半径和外半径，颗粒床厚度演变被量化，显示出初始线性增长，随后是非线性减速。粒子动力学分析表明，在非线性阶段，阻力主导着粒子运动和射流形成。颗粒床的初始角度不均匀性导致气体径向速度不均匀。通过阻力耦合，这种流动不对称性在小颗粒中产生径向速度差，从而促进明显的射流形成，而大颗粒则抵抗这种阻力引起的效应。较小颗粒上较大的阻力引起的减速度导致整个颗粒床的速度差增加，这解释了加速增稠。建立了将线性阶段的 Gurney 模型与非线性阶段的阻力主导减速模型相结合的特征半径模型，该模型与不同颗粒尺寸的数值结果表现出良好的一致性。|[2512.19241](http://arxiv.org/abs/2512.19241)|null|\n",
        "2512.20562": "|**2025-12-23**|**Shallow Neural Networks Learn Low-Degree Spherical Polynomials with Learnable Channel Attention**|在本文中，我们通过训练具有通道注意力的超参数化两层神经网络（NN）来研究学习在 $\\RR^d$ 中的单位球上定义的度数 $\\ell_0 = θ(1) \\ge 1$ 的低次球多项式的问题。我们的主要结果是显着提高了学习此类低次多项式的样本复杂性。我们表明，对于任何回归风险 $\\eps \\in (0,1)$，精心设计的具有通道注意力和有限宽度 $m \\ge θ({n^4 \\log (2n/δ)}/{d^{2\\ell_0}})$ 的两层神经网络，通过普通梯度下降 (GD) 训练，需要最低的样本复杂度 $n \\asymp θ(d^{\\ell_0}/\\eps)$，概率为 $1-δ$每个 $δ\\in (0,1)$，与代表性样本复杂度 $θ\\pth{d^{\\ell_0} \\max\\set{\\eps^{-2},\\log d}}$ 形成对比，其中 $n$ 是训练数据大小。此外，这样的样本复杂性是无法改善的，因为经过训练的网络会以至少 $1-δ$ 的概率呈现 $θ(d^{\\ell_0}/{n})$ 阶的非参数回归风险的尖锐比率。另一方面，秩为$θ(d^{\\ell_0})$的回归风险的最小最大最优率为$θ(d^{\\ell_0}/{n})$，因此GD训练的网络的非参数回归风险的率为最小最大最优。具有通道注意力的两层神经网络的训练由两个阶段组成。在第 1 阶段，可证明的可学习通道选择算法以高概率从第一层激活中的初始 $L \\ge \\ell_0$ 通道中识别出真实通道号 $\\ell_0$。这种可学习的选择是通过在两层上进行高效的一步 GD 更新来实现的，从而实现低次多项式目标的特征学习。在第 2 阶段，第二层由标准 GD 使用选定通道的激活函数进行训练。|[2512.20562](http://arxiv.org/abs/2512.20562)|null|\n",
        "2512.20538": "|**2025-12-23**|**AlignPose: Generalizable 6D Pose Estimation via Multi-view Feature-metric Alignment**|基于单视图 RGB 模型的物体姿态估计方法具有很强的泛化性，但从根本上受到深度模糊、杂波和遮挡的限制。多视图姿态估计方法有可能解决这些问题，但现有的工作依赖于精确的单视图姿态估计或缺乏对不可见物体的泛化。我们通过以下三个贡献来应对这些挑战。首先，我们介绍 AlignPose，这是一种 6D 物体姿态估计方法，它聚合来自多个外部校准 RGB 视图的信息，并且不需要任何特定于物体的训练或对称性注释。其次，该方法的关键组成部分是专门为对象姿势设计的新的多视图特征度量细化。它优化了单个一致的世界框架对象姿态，最大限度地减少了动态渲染的对象特征与同时在所有视图中观察到的图像特征之间的特征差异。第三，我们报告了使用 BOP 基准评估对四个数据集（YCB-V、T-LESS、ITODD-MV、HouseCat6D）进行的广泛实验，并表明 AlignPose 优于其他已发布的方法，特别是在实践中容易获得多个视图的具有挑战性的工业数据集上。|[2512.20538](http://arxiv.org/abs/2512.20538)|null|\n",
        "2512.20506": "|**2025-12-23**|**Ultrasonic metamaterial at MHz frequencies using microstructured glass**|声学超材料通过微结构工程增强传统材料特性，为从生物医学成像、临床治疗到无损检测等应用中塑造声场提供了新的机会。然而，在 MHz 频率范围内，仅存在少数超材料架构。它们通常衰减很大或难以制造，并且通常对声音传播提供有限的 3D 控制。在这里，我们介绍一种基于激光雕刻玻璃的兆赫频率超声波超材料。通过构建具有不同雕刻图案的元体素，我们定义了一种全 3D 各向异性超材料，与非结构化玻璃相比，声速局部变化高达 20%，损耗比同类 3D 打印超材料低 100 倍。我们使用这种超材料来定义标准元素库，这些元素可以模块化组合以创建和塑造复杂图案的超声波场。我们的实验得到了理论模型的支持，该模型为超材料行为的微观结构起源提供了额外的见解，并为设计定制的超声场和响应打开了大门。|[2512.20506](http://arxiv.org/abs/2512.20506)|null|\n",
        "2512.20495": "|**2025-12-23**|**Nebula: Enable City-Scale 3D Gaussian Splatting in Virtual Reality via Collaborative Rendering and Accelerated Stereo Rasterization**|3D 高斯溅射 (3DGS) 最近引起了建筑界的广泛关注。然而，当前的架构设计经常忽视 3DGS 可扩展性，这使得它们对于超大规模 3DGS 来说很脆弱。同时，VR带宽要求使得无法从云端传输高保真、流畅的VR内容。   我们推出 Nebula，一个用于大规模 3DGS 协作渲染的连贯加速框架。 Nebula 不是流式传输视频，而是在 LoD 搜索后流式传输中间结果，从而减少了云和客户端之间 1925% 的数据通信。为了进一步增强运动到光子的体验，我们在云中引入了时间感知的 LoD 搜索，通过利用帧间的时间一致性来驯服不规则的内存访问并减少冗余数据访问。在客户端，我们提出了一种新颖的立体光栅化，使两只眼睛能够在立体渲染过程中以位精确的质量共享大部分计算。通过最少的硬件增强，Nebula 实现了 2.7$\\times$ 的运动到光子加速，并比有损视频流减少了 1925% 的带宽。|[2512.20495](http://arxiv.org/abs/2512.20495)|null|\n",
        "2512.20479": "|**2025-12-23**|**UTDesign: A Unified Framework for Stylized Text Editing and Generation in Graphic Design Images**|人工智能辅助图形设计已成为自动创建和编辑海报、横幅和广告等设计元素的强大工具。虽然基于扩散的文本到图像模型在视觉内容生成方面表现出了强大的能力，但它们的文本渲染性能，特别是对于小规模排版和非拉丁文字，仍然有限。在本文中，我们提出了UTDesign，一个用于设计图像中高精度风格化文本编辑和条件文本生成的统一框架，支持英文和中文脚本。我们的框架引入了一种新颖的基于 DiT 的文本样式传输模型，该模型在合成数据集上从头开始训练，能够生成透明的 RGBA 文本前景，从而保留参考字形的样式。我们通过在具有详细文本注释的精选数据集上训练多模式条件编码器，进一步将该模型扩展到条件文本生成框架，从而实现以背景图像、提示和布局规范为条件的准确、风格一致的文本合成。最后，我们通过结合预先训练的文本到图像 (T2I) 模型和基于 MLLM 的布局规划器，将我们的方法集成到完全自动化的文本到设计 (T2D) 管道中。大量实验表明，UTDesign 在文体一致性和文本准确性方面实现了开源方法中最先进的性能，并且与专有商业方法相比还表现出独特的优势。本文的代码和数据可在 https://github.com/ZYM-PKU/UTDesign 获取。|[2512.20479](http://arxiv.org/abs/2512.20479)|null|\n",
        "2512.20414": "|**2025-12-23**|**Topological resolution of conical intersection seams and the coupled cluster bifurcation via mixed Hodge modules**|对圆锥相交（CI）的严格描述仍然是非绝热量子化学的核心挑战。虽然“Yarkony 接缝”——$(3N-8)$维简并流形——在几何上已被很好地理解，但其通过高级电子结构方法的准确表征却受到数值不稳定性的困扰。具体来说，标准耦合簇 (CC) 理论在基态 CI 附近存在根分叉，使得化学的“黄金标准”在最需要的地方不适用。在这里，我们提出 \\textbf{QuMorpheus}，一个开源计算包，它通过实现基于耗散混合 Hodge 模块（DMHM）的拓扑框架来解决这些奇点 [P. Saurabh，arXiv：2512.19487 (2025)]。通过算法将 CC 多项式方程映射到谱束，我们计算交集的精确 Monodromy ($μ$) 不变量。我们证明，这种自动化代数几何方法可以正确识别 Köhn-Tajti 模型中的物理基态拓扑，并解决现实化学系统的交叉缝，包括乙烯和氯离子 ($\\mathrm{H_2Cl^+}$)。此外，我们将 QuMorpheus 应用于 Previtamin D 的光异构化，证明实验观察到的 Woodward-Hoffmann 选择规则是拓扑“Monodromy Wall”（$μ=1，γ=π$）的直接结果，而不是纯粹的能量障碍。这为“Yarkony 问题”建立了通用软件解决方案，从而能够对复杂分子系统中的全局交叉接缝进行稳健、自动的映射。这些交叉点的​​拓扑稳定性允许参考文献[P.11]中讨论的控制协议。 Saurabh，提交给物理学。修订版 X (2025)]。|[2512.20414](http://arxiv.org/abs/2512.20414)|null|\n",
        "2512.20362": "|**2025-12-23**|**CRAFT: Continuous Reasoning and Agentic Feedback Tuning for Multimodal Text-to-Image Generation**|最近的工作表明，推理时间推理和反射可以改进文本到图像的生成，而无需重新训练。然而，现有的方法通常依赖于隐含的、整体的批评或不受约束的即时重写，使得它们的行为难以可靠地解释、控制或停止。相比之下，大型语言模型受益于基于验证、有针对性的纠正和提前停止的明确、结构化的**思维**形式。   我们引入了 CRAFT（连续推理和代理反馈调整），这是一种免训练、与模型无关的框架，它将这种结构化推理范式引入多模态图像生成中。 CRAFT 将提示分解为依赖结构的视觉问题，使用视觉语言模型验证生成的图像，并仅在约束失败时通过 LLM 代理应用有针对性的提示编辑。一旦满足所有约束，该过程就会使用显式停止标准进行迭代，从而产生可解释且可控的推理时间细化循环。   在多个模型系列和具有挑战性的基准中，CRAFT 不断提高构图准确性、文本渲染和基于偏好的评估，尤其是轻量级生成器的收益尤其强劲。重要的是，这些改进只产生可以忽略不计的推理时间开销，允许更小或更便宜的模型接近更昂贵的系统的质量。我们的结果表明，明确结构化、约束驱动的推理时间推理是提高多模态生成模型可靠性的关键因素。|[2512.20362](http://arxiv.org/abs/2512.20362)|null|\n",
        "2512.20347": "|**2025-12-23**|**Three-dimensional mesh adaptation in PFEM**|混沌自由表面流是数值模拟的挑战性问题，主要是由于几何形状的显着变化和频繁的拓扑变化。跟踪拉格朗日公式中流体演化的方法是自然的选择。其中一种方法是粒子有限元法 (PFEM)。作为一种基于粒子和基于网格的混合方法，PFEM 充分利用了这两种方法的优点。使用有限元方法在网格上求解运动方程，并使用获得的速度场来移动该网格的节点，将其视为携带跨时间步长的所有相关信息的粒子。为了避免单元变形，经常重新生成网格。这带来了一些挑战：如何检测域的新形状？如何保持元件的质量可以接受？自适应网格细化能否提高求解器的精度和效率？ PFEM 模拟可以在存在复杂边界几何形状的情况下执行吗？在这项工作中，介绍了 PFEM 的几何形状和网格组件的三个贡献，用于三维自由表面流模拟。首先，我们提出了一种与传统使用的 alpha 形状过程不同的域重建方法，即通过使用前一时间步的平流边界作为谓词来表示域的新形状。其次，提出了分两步的自适应细化过程：细化边界表面，然后批量插入基于质量的节点。第三，提出了一种管理复杂几何形状边界的方法。一系列的应用展示了该方法的兴趣。|[2512.20347](http://arxiv.org/abs/2512.20347)|null|\n",
        "2512.20268": "|**2025-12-23**|**DeepONet-accelerated Bayesian inversion for moving boundary problems**|这项工作表明，神经算子学习提供了一个强大而灵活的框架，用于构建快速、准确的移动边界系统模拟器，使其能够集成到数字孪生平台中。为此，采用深度算子网络（DeepONet）架构来构建有效的代理模型，用于解决多孔介质单相达西流中的移动边界问题。该代理能够快速、准确地近似复杂的流动动力学，并与集成卡尔曼反演 (EKI) 算法相结合来解决贝叶斯反演问题。   通过估计通过树脂传递模塑（RTM）工艺制造的复合材料的纤维增强材料的渗透性和孔隙率来证明所提出的反演框架。使用合成和实验过程中的数据，与全模型 EKI 相比，DeepONet 代理将反演速度加快了几个数量级。这种计算效率能够实时、准确、高分辨率地估计渗透率、孔隙度和其他参数的局部变化，从而支持 RTM 过程的有效监测和控制，以及涉及移动边界流的其他应用。与之前学习依赖于网格的映射的 RTM 反演方法不同，所提出的神经算子在空间和时间域上进行泛化，无需重新训练即可对任意传感器配置进行评估，这代表着数字孪生的实际工业部署迈出了重要一步。|[2512.20268](http://arxiv.org/abs/2512.20268)|null|\n",
        "2512.20253": "|**2025-12-23**|**Quantum Geometric Tensor in the Wild: Resolving Stokes Phenomena via Floquet-Monodromy Spectroscopy**|标准拓扑不变量，例如陈数和贝里相，构成了现代量子物质分类的基石。然而，我们证明了这个框架在存在本质奇点的情况下经历了 \\textbf{灾难性失败}——在开放、驱动和非厄米系统（“狂野”体系）中普遍存在。在这些设置中，局部几何张量发散，导致标准不变量定义不明确，并导致扰动预测与阶次统一 ($\\sim 100\\%$) 偏离现实。我们通过引入\\textbf{Floquet-Monodromy Spectroscopy (FMS)}协议来解决这一危机，这是一种脉冲级控制序列，它通过实验提取隐藏的\\textit{Stokes现象}——完成拓扑描述的“缺失”几何数据。通过将奇点的斯托克斯乘数映射到时域可观测量，FMS 为 \\textbf{复兴理论} 提供了严格的实验桥梁，允许从发散渐近级数精确重建非微扰物理。我们在超导量子模型上验证了这个框架，证明“斯托克斯不变量”可以作为下一代量子数，用于对超出传统拓扑范围的物质相进行分类。|[2512.20253](http://arxiv.org/abs/2512.20253)|null|\n",
        "2512.21311": "|**2025-12-24**|**Learning to Solve PDEs on Neural Shape Representations**|求解形状的偏微分方程 (PDE) 是许多形状分析和工程任务的基础；然而，流行的 PDE 求解器在多边形/三角形网格上运行，而现代 3D 资产越来越多地以神经表示形式存在。这种不匹配使得没有合适的方法可以直接在神经域内求解表面偏微分方程，从而强制显式网格提取或每个实例的残差训练，从而阻碍了端到端的工作流程。我们提出了一种新颖的无网格公式，可以学习以神经（局部）形状属性为条件的局部更新算子，从而能够在（神经）数据所在的位置直接求解表面偏微分方程。该算子自然地与流行的神经表面表示集成，在单个代表性形状上进行一次训练，并概括形状和拓扑变化，从而无需显式网格划分或每个实例优化即可实现准确、快速的推理，同时保留可微分性。跨分析基准（球体上的热方程和泊松求解）和不同表示的真实神经资产，我们的方法略优于 CPM，同时保持相当接近 FEM，并且据我们所知，提供了第一个端到端管道，可在神经和经典表面表示上求解表面偏微分方程。代码将在接受后发布。|[2512.21311](http://arxiv.org/abs/2512.21311)|null|\n",
        "2512.21185": "|**2025-12-24**|**UltraShape 1.0: High-Fidelity 3D Shape Generation via Scalable Geometric Refinement**|在本报告中，我们介绍了 UltraShape 1.0，这是一种用于高保真 3D 几何生成的可扩展 3D 扩散框架。所提出的方法采用两阶段生成流程：首先合成粗略的全局结构，然后细化以产生详细的高质量几何结构。为了支持可靠的 3D 生成，我们开发了全面的数据处理管道，其中包括新颖的无懈可击的处理方法和高质量的数据过滤。该流程通过删除低质量样本、填充孔洞和加厚薄结构来提高公开可用 3D 数据集的几何质量，同时保留细粒度的几何细节。为了实现细粒度的几何细化，我们将扩散过程中的空间定位与几何细节合成解耦。我们通过在固定空间位置执行基于体素的细化来实现这一点，其中从粗几何导出的体素查询提供通过 RoPE 编码的显式位置锚，允许扩散模型专注于在简化的结构化解决方案空间内合成局部几何细节。我们的模型专门在公开的 3D 数据集上进行训练，尽管训练资源有限，但仍能实现强大的几何质量。广泛的评估表明，UltraShape 1.0 在数据处理质量和几何生成方面与现有开源方法相比具有竞争力。所有代码和训练模型都将发布以支持未来的研究。|[2512.21185](http://arxiv.org/abs/2512.21185)|null|\n",
        "2512.21099": "|**2025-12-24**|**TexAvatars : Hybrid Texel-3D Representations for Stable Rigging of Photorealistic Gaussian Head Avatars**|构建可驾驶且逼真的 3D 头部头像已成为 AR/XR 的核心任务，从而实现身临其境且富有表现力的用户体验。随着 3D 高斯等高保真和高效表示的出现，最近的作品已经向超详细的头部头像发展。现有方法通常分为两类：基于规则的分析绑定或基于神经网络的变形场。虽然在受限环境中有效，但这两种方法通常无法推广到看不见的表情和姿势，特别是在极端的重演场景中。其他方法将高斯约束到 3DMM 的全局纹理元素空间，以降低渲染复杂性。然而，这些基于纹理元素的化身往往没有充分利用底层的网格结构。它们应用最小的分析变形，并严重依赖 UV 空间中的神经回归器和启发式正则化，这削弱了几何一致性并限制了对复杂的、不符合分布的变形的外推。为了解决这些限制，我们引入了 TexAvatars，这是一种混合化身表示形式，它将分析绑定的显式几何基础与纹素空间的空间连续性相结合。我们的方法通过 CNN 预测 UV 空间中的局部几何属性，但通过网格感知雅克比行列式驱动 3D 变形，从而实现跨越三角形边界的平滑且语义上有意义的过渡。这种混合设计将语义建模与几何控制分开，从而提高了泛化性、可解释性和稳定性。此外，TexAvatars 还能以高保真度捕捉细粒度的表情效果，包括肌肉引起的皱纹、眉间纹和真实的口腔几何形状。我们的方法在极端的姿势和表情变化下实现了最先进的性能，在具有挑战性的头部重现设置中展示了强大的泛化能力。|[2512.21099](http://arxiv.org/abs/2512.21099)|null|\n",
        "2512.21003": "|**2025-12-24**|**MVInverse: Feed-forward Multi-view Inverse Rendering in Seconds**|多视图逆渲染旨在跨多个视点一致地恢复几何、材质和照明。当应用于多视图图像时，现有的单视图方法经常忽略跨视图关系，导致结果不一致。相比之下，多视图优化方法依赖于缓慢的可微分渲染和每个场景的细化，这使得它们的计算成本昂贵且难以扩展。为了解决这些限制，我们引入了前馈多视图逆渲染框架，该框架可以直接预测 RGB 图像序列中空间变化的反照率、金属性、粗糙度、漫反射着色和表面法线。通过跨视图交替关注，我们的模型捕获了视图内的远程照明交互和视图间材质的一致性，从而在单个前向传递中实现连贯的场景级推理。由于现实世界训练数据的稀缺，在现有合成数据集上训练的模型通常很难推广到现实世界场景。为了克服这一限制，我们提出了一种基于一致性的微调策略，该策略利用未标记的真实世界视频来增强野外条件下的多视图一致性和鲁棒性。对基准数据集的大量实验表明，我们的方法在多视图一致性、材质和法线估计质量以及对现实世界图像的泛化方面实现了最先进的性能。|[2512.21003](http://arxiv.org/abs/2512.21003)|null|\n",
        "2512.20976": "|**2025-12-24**|**XGrid-Mapping: Explicit Implicit Hybrid Grid Submaps for Efficient Incremental Neural LiDAR Mapping**|大规模增量测绘是开发强大而可靠的自主系统的基础，因为它通过导航和决策的顺序输入支持增量环境理解。激光雷达因其准确性和鲁棒性而被广泛用于此目的。最近，神经激光雷达测绘表现出了令人印象深刻的性能；然而，大多数方法依赖于密集的隐式表示并且未充分利用几何结构，而现有的体素引导方法难以实现实时性能。为了应对这些挑战，我们提出了 XGrid-Mapping，这是一种混合网格框架，它联合利用显式和隐式表示来实现高效的神经 LiDAR 映射。具体来说，该策略将提供几何先验和结构指导的稀疏网格与丰富场景表示的隐式密集网格相结合。通过将 VDB 结构与基于子图的组织相结合，该框架减少了计算负载，并实现了大规模的高效增量映射。为了减轻子图之间的不连续性，我们引入了基于蒸馏的重叠对齐策略，其中前面的子图监督后续子图以确保重叠区域的一致性。为了进一步提高鲁棒性和采样效率，我们采用了动态去除模块。大量的实验表明，我们的方法提供了卓越的映射质量，同时克服了体素引导方法的效率限制，从而优于现有的最先进的映射方法。|[2512.20976](http://arxiv.org/abs/2512.20976)|null|\n",
        "2512.20968": "|**2025-12-24**|**Mesh-Attention: A New Communication-Efficient Distributed Attention with Improved Data Locality**|分布式注意力是扩展大型语言模型（LLM）上下文窗口的一个基本问题。最先进的方法 Ring-Attention 由于通信流量过多而受到可扩展性的限制。本文通过使用新的基于矩阵的模型重新思考分布式注意力的设计空间，提出了一种新的分布式注意力算法Mesh-Attention。我们的方法将计算块的二维图块（而不是一维行或列）分配给每个 GPU，以通过降低通信计算 (CommCom) 比率来实现更高的效率。一般方法将 Ring-Attention 作为一种特殊情况，并允许使用不同的图块形状调整 CommCom 比率。重要的是，我们提出了一种贪婪算法，可以有效地搜索瓦片内的调度空间，并具有确保 GPU 之间有效通信的限制。理论分析表明，与现有的其他算法相比，Mesh-Attention 的通信复杂度要低得多，并且具有良好的可扩展性。   我们大量的实验结果表明，Mesh-Attention 在 256 个 GPU 上可以实现高达 3.4 倍的加速（平均 2.9 倍），并减少高达 85.4%（平均 79.0%）的通信量。我们的可扩展性结果进一步证明，随着系统扩展，Mesh-Attention 可以保持卓越的性能，从而大大减少大规模部署中的开销。结果令人信服地证实了 Mesh-Attention 的优势。|[2512.20968](http://arxiv.org/abs/2512.20968)|null|\n",
        "2512.20943": "|**2025-12-24**|**AirGS: Real-Time 4D Gaussian Streaming for Free-Viewpoint Video Experiences**|自由视点视频 (FVV) 允许用户从任意角度观看场景，从而实现身临其境的观看体验。作为 FVV 生成的重要重建技术，4D 高斯泼溅 (4DGS) 使用时变 3D 高斯椭球体对动态场景进行建模，并通过快速光栅化实现高质量渲染。然而，现有的 4DGS 方法在长序列上会出现质量下降的问题，并会带来大量的带宽和存储开销，限制了它们在实时和大规模部署中的适用性。因此，我们推出了 AirGS，这是一种流优化的 4DGS 框架，它重新架构了训练和交付管道，以实现高质量、低延迟的 FVV 体验。 AirGS将高斯视频流转换为多通道2D格式，并智能识别关键帧以提高帧重建质量。它进一步将时间相干性与通货膨胀损失结合起来，以减少训练时间和表示大小。为了支持高效的通信传输，AirGS 将 4DGS 传输建模为整数线性规划问题，并设计了轻量级修剪级别选择算法来自适应修剪要传输的高斯更新，平衡重建质量和带宽消耗。大量实验表明，与 SOTA 4DGS 方法相比，AirGS 在场景变化时可将 PSNR 质量偏差降低 20% 以上，将帧级 PSNR 始终保持在 30 以上，将训练速度提高 6 倍，将每帧传输大小减少近 50%。|[2512.20943](http://arxiv.org/abs/2512.20943)|null|\n",
        "2512.20927": "|**2025-12-24**|**Quantile Rendering: Efficiently Embedding High-dimensional Feature on 3D Gaussian Splatting**|计算机视觉领域的最新进展利用 3D 高斯分布 (3D-GS) 成功地将开放词汇分割 (OVS) 扩展到 3D 领域。尽管取得了这些进展，但有效呈现开放词汇表查询所需的高维特征仍面临重大挑战。现有方法采用码本或特征压缩，导致信息丢失，从而降低分割质量。为了解决这个限制，我们引入了分位数渲染（Q-Render），这是一种新颖的 3D 高斯渲染策略，可以有效处理高维特征，同时保持高保真度。传统的体积渲染对与每条射线相交的所有 3D 高斯进行密集采样，而 Q-Render 则与此不同，它仅对沿射线具有主导影响的那些进行稀疏采样。通过将 Q-Render 集成到可泛化的 3D 神经网络中，我们还提出了高斯分布网络 (GS-Net)，它以可泛化的方式预测高斯特征。 ScanNet 和 LeRF 上的大量实验表明，我们的框架优于最先进的方法，同时能够在 512 维特征图上实现实时渲染，加速大约约 43.7 倍。代码将公开。|[2512.20927](http://arxiv.org/abs/2512.20927)|null|\n",
        "2512.20907": "|**2025-12-24**|**PanoGrounder: Bridging 2D and 3D with Panoramic Scene Representations for VLM-based 3D Visual Grounding**|3D 视觉基础 (3DVG) 是从视觉语言感知到机器人技术的关键桥梁，需要语言理解和 3D 场景推理。传统的监督模型利用显式 3D 几何，但由于 3D 视觉语言数据集的稀缺性以及与现代视觉语言模型 (VLM) 相比推理能力的有限，其泛化能力有限。我们提出了 PanoGrounder，这是一个通用的 3DVG 框架，它将多模态全景表示与预训练的 2D VLM 结合起来，以实现强大的视觉语言推理。全景渲染增强了 3D 语义和几何特征，可作为 2D 和 3D 之间的中间表示，并具有两大优势：(i) 它们可以直接馈送到 VLM，只需极少的调整；(ii) 由于其 360 度视场，它们保留了远程对象到对象的关系。我们设计了一个三阶段管道，考虑场景布局和几何形状，放置一组紧凑的全景视点，使用 VLM 对每个全景渲染进行文本查询，并通过提升将每个视图的预测融合到单个 3D 边界框中。我们的方法在 ScanRefer 和 Nr3D 上取得了最先进的结果，并展示了对未见过的 3D 数据集和文本改写的卓越泛化能力。|[2512.20907](http://arxiv.org/abs/2512.20907)|null|\n",
        "2512.20894": "|**2025-12-24**|**Geese achieve stationary takeoff via synergistic wing kinematics and enhanced aerodynamics**|静止起飞，没有跑动启动或升高下降，需要很大的空气动力来克服重量，特别是对于体重超过 2 公斤的鹅等大型鸟类。然而，复杂的机翼运动和高雷诺数（Re $\\approx$$10^5$）流动动力学挑战了鸟类飞行空气动力学的传统期望，使得这种机制难以捉摸。通过分析 7 只雁 (\\textit{Anser cygnoides}) 的 578 次固定起飞并应用主成分分析 (PCA)，我们揭示了复杂的机翼运动学塌陷到由两个协同作用主导的低维流形上：负责基本节律性行程的行程协同作用和控制展向几何形状的变形协同作用。这种模块化控制策略协调了定型的机翼运动学，具有加速平移下冲程和快速尖端反转上冲程。通过将机翼运动学分析与鹅的质量分布相结合，我们量化了空气动力，发现在整个运动周期中产生了完全正的升力和推力。大雁起飞时空气动力学性能的增强源于三个主要机制。在下冲程期间，准稳态框架预测机翼加速度产生的显着升力。流动可视化表明，尾流捕获通过定向尾流涡流的位置进一步增强了下冲程中的升力产生。在上冲程中，远端机翼执行快速的俯仰运动并产生很大的推力，其垂直分量对重量支撑有很大贡献。|[2512.20894](http://arxiv.org/abs/2512.20894)|null|\n"
    },
    "具生智能&自动驾驶": {
        "2512.17907": "|**2025-12-19**|**Dexterous World Models**|3D 重建领域的最新进展使得从日常环境中创建逼真的数字孪生变得容易。然而，当前的数字孪生在很大程度上仍然是静态的，并且仅限于导航和视图合成，没有具体的交互性。为了弥补这一差距，我们引入了灵巧世界模型 (DWM)，这是一种场景动作条件视频扩散框架，用于模拟灵巧的人类动作如何引起静态 3D 场景的动态变化。   给定静态 3D 场景渲染和以自我为中心的手部运动序列，DWM 会生成时间连贯的视频，描绘合理的人景交互。我们的方法将视频生成条件限制为（1）遵循指定摄像机轨迹的静态场景渲染，以确保空间一致性，以及（2）以自我为中心的手部网格渲染，对几何和运动线索进行编码，以直接对动作条件动态进行建模。为了训练 DWM，我们构建了一个混合交互视频数据集。合成的以自我为中心的交互为关节运动和操作学习提供了完全一致的监督，而固定摄像头的真实世界视频则提供了多样化和真实的对象动态。   实验表明，DWM 可实现真实且物理上合理的交互，例如抓取、打开和移动对象，同时保持相机和场景的一致性。该框架代表了迈向基于视频传播的交互式数字孪生的第一步，并实现了以自我为中心的行为的具体模拟。|[2512.17907](http://arxiv.org/abs/2512.17907)|null|\n",
        "2512.17880": "|**2025-12-19**|**On the complex nature of coronal heating**|热日冕的很大一部分由磁约束的明亮等离子体环组成。这些观察到的环又被构造成明亮的线。我们借助对植根于自洽对流区层的日冕环进行 3D 电阻 MHD 模拟，研究了磁场几何形状、等离子体特性和亮链之间的关系。我们发现不可能将环识别为与温度和密度几乎均匀的等离子体一致的简单相干磁通量管。明亮结构的位置是由加热、冷却和蒸发时间尺度之间复杂的相互作用决定的。电流片优先在不同来源的磁通量的界面处形成。它们也可能在磁场线束内形成，因为磁集中内的运动在一系列时间尺度上驱动等离子体流，这提供了进一步的子结构并可以局部增强磁场梯度，从而促进磁重联。因此，数值实验具有通量管构造和通量编织模型的两个方面。虽然将观测到的日冕环建模为圆柱形通量管有助于理解孤立的特定加热机制的物理原理，但它并不能很好地描述植根于自洽演化的对流区的日冕环的结构。|[2512.17880](http://arxiv.org/abs/2512.17880)|null|\n",
        "2512.17716": "|**2025-12-19**|**Non-perturbative effects of short-range spatial correlations at the two-particle level**|通过细胞动力学平均场理论（CDMFT），我们研究短程相关性如何驱动二维系统中自洽微扰理论的崩溃以及与之相关的最相关的物理后果。为此，我们首先以结构化且一致的方式推导所有物理通道中 CDMFT 级别的 Bethe-Salpeter 方程 (BSE) 形式主义，明确解决相关 Ward 恒等式的重要方面。在这种情况下，我们对二维 Hubbard 模型在中间耦合半填充时的 BSE 进行系统计算。我们的研究说明了电荷通道中 BSE 基本构件（两粒子不可约顶点）的发散是如何由于短程反铁磁波动而在比（纯局部）DMFT 情况更低的相互作用下系统地发生的。此外，与顶点散度相关的广义电荷磁化率特征值的符号变化被认为是在较大相互作用值下驱动二维莫特转变物理以及相邻相分离不稳定性的基本先决条件。|[2512.17716](http://arxiv.org/abs/2512.17716)|null|\n",
        "2512.17698": "|**2025-12-19**|**A VLA search for compact radio sources in the explosive molecular outflows DR 21 and G5.89**|我们提出了对两个爆炸性分子外流 (EMO) DR 21 和 G5.89 的高角分辨率 ($\\sim0\\rlap{.}''1$) VLA Ku 波段 (12--18 GHz) 观测，以寻找与这些爆炸事件相关的失控恒星。在 DR 21 中，我们确定了 13 个紧凑型射电源 (CRS)，其中 9 个位于 DR 21 核心并靠近 CO 流光喷射区域。 CRS 的无线电特性表明，其中三个是非热射电发射体，可能是磁活跃恒星，而其余 CRS 的性质无法最终确定。所有检测到的 CRS 都是后续自行研究的良好候选者，以确认它们是否是失控恒星。我们还确定了多个电离弧形结构，可以拟合抛物线，其对称轴会聚到与 CRS #11 重合的位置，从而提高了该源是主要电离星的可能性。对 18 个分子流出流光的重新分析细化了爆炸事件的中心，该中心与弧收敛点指示的位置紧密对齐，支持 EMO 和 HII 区域的共同恒星起源。在 G5.89 中，观察结果显示了一个具有方形形态的贝壳。该 HII 区域的强扩展发射阻止了壳体内微弱紧凑型无线电源的检测；仅在壳外发现了两个，并且在该区域内安装了一个抛物线弧。总体而言，电离区域中的电弧结构似乎是电离源起源的良好示踪剂。|[2512.17698](http://arxiv.org/abs/2512.17698)|null|\n",
        "2512.17620": "|**2025-12-19**|**StereoMV2D: A Sparse Temporal Stereo-Enhanced Framework for Robust Multi-View 3D Object Detection**|多视角 3D 物体检测是自动驾驶感知中的一项基本任务，其中实现检测精度和计算效率之间的平衡仍然至关重要。基于稀疏查询的 3D 检测器通过一组可学习的查询有效地聚合来自多视图图像的对象相关特征，提供简洁的端到端检测范例。在此基础上，MV2D 利用 2D 检测结果为查询初始化提供高质量的对象先验，从而实现更高的精度和召回率。然而，单帧 2D 检测中固有的深度模糊性仍然限制了 3D 查询生成的准确性。为了解决这个问题，我们提出了 StereoMV2D，这是一个将时间立体建模集成到 2D 检测引导的多视图 3D 检测器中的统一框架。通过利用相邻帧中同一对象的跨时间差异，StereoMV2D 增强了深度感知并细化了查询先验，同时在 2D 感兴趣区域 (RoIs) 内高效执行所有计算。此外，动态置信门机制通过学习从帧间匹配矩阵导出的统计模式以及外观一致性，自适应地评估时间立体线索的可靠性，确保在对象外观和遮挡下进行鲁棒检测。在 nuScenes 和 Argoverse 2 数据集上进行的大量实验表明，StereoMV2D 在不产生大量计算开销的情况下实现了卓越的检测性能。代码可在 https://github.com/Uddd821/StereoMV2D 获取。|[2512.17620](http://arxiv.org/abs/2512.17620)|null|\n",
        "2512.17586": "|**2025-12-19**|**Learning Safe Autonomous Driving Policies Using Predictive Safety Representations**|安全强化学习（SafeRL）是自动驾驶的一个重要范例，其中智能体需要在严格的安全要求下优化性能。这种双重目标造成了根本性的紧张，因为过于保守的政策限制了驾驶效率，而激进的勘探则面临着安全违规的风险。更安全策略学习的安全表示 (SRPL) 框架通过为代理配备未来约束违规的预测模型来解决这一挑战，并在受控环境中显示出前景。本文研究了 SRPL 是否可以扩展到现实世界的自动驾驶场景。 Waymo 开放运动数据集 (WOMD) 和 NuPlan 上的系统实验表明，SRPL 可以改善奖励与安全的权衡，在成功率（效应大小 r = 0.65-0.86）和成本降低（效应大小 r = 0.70-0.83）方面实现统计上显着的改进，观察到的改进 p < 0.05。然而，其有效性取决于底层策略优化器和数据集分布。结果进一步表明，预测安全表示在提高观测噪声的鲁棒性方面发挥着关键作用。此外，在零样本跨数据集评估中，与非 SRPL 方法相比，SRPL 增强代理表现出更好的泛化能力。这些发现共同证明了预测安全表示在增强自动驾驶 SafeRL 方面的潜力。|[2512.17586](http://arxiv.org/abs/2512.17586)|null|\n",
        "2512.17582": "|**2025-12-19**|**Investigating methods to solve large windfarm optimization problems with a minimum number of qubits using circuit-based quantum computers**|本研究研究了用于解决风电场布局优化（WFLO）问题的量子计算方法，该问题被表述为二次无约束二元优化（QUBO）问题。我们研究了两种每个网格点需要少于一个量子位的编码方法：先前开发的泡利相关编码（PCE）和一种新颖的单量子位算子编码（SQOE）。这些方法在三个风电场配置上进行了测试，其中两个来自之前的 WFLO 规模研究，另一个基于威尔士现有风电场的新现实模型。改进的编码方法使我们能够在量子计算机模拟器上使用多达 20 个量子位来解决 $9\\times 9$ 网格上的 WFLO 问题。结果表明，两种编码方法的性能都具有竞争力，并且在测试系统中表现出良好的缩放特性。|[2512.17582](http://arxiv.org/abs/2512.17582)|null|\n",
        "2512.17370": "|**2025-12-19**|**TakeAD: Preference-based Post-optimization for End-to-end Autonomous Driving with Expert Takeover Data**|现有的端到端自动驾驶方法通常依赖于模仿学习（IL），但面临着一个关键挑战：开环训练和闭环部署之间的不一致。这种错位通常会在闭环执行期间触发驾驶员发起的接管和系统脱离。如何利用脱离场景中的专家接管数据并有效扩展IL政策的能力提出了一个有价值但尚未探索的挑战。在本文中，我们提出了 TakeAD，这是一种新颖的基于偏好的后优化框架，可利用脱离数据微调预先训练的 IL 策略，以增强闭环驾驶性能。首先，我们受现实世界自动驾驶系统中人类接管机制的启发，设计了一个高效的专家接管数据收集管道。然后，该后优化框架将用于模仿学习的迭代数据集聚合 (DAgger) 与用于偏好对齐的直接偏好优化 (DPO) 集成在一起。 DAgger 阶段为政策提供了通过直接模仿专家干预来处理脱离状态的基本能力。随后，DPO 阶段会完善策略的行为，以更好地符合脱离场景中的专家偏好。通过多次迭代，该策略逐步学习脱离状态的恢复策略，从而减轻开环差距。闭环 Bench2Drive 基准测试的实验证明了我们的方法与纯 IL 方法相比的有效性，并通过全面的消融确认了每个组件的贡献。|[2512.17370](http://arxiv.org/abs/2512.17370)|null|\n",
        "2512.17287": "|**2025-12-19**|**In-operando dipole orientation for bipolar injection from air-stable electrodes into organic semiconductors**|从空气稳定电极到有机半导体（OSC）的有效载流子注入对于在环境条件下制造溶液处理的有机光电器件至关重要。如今，这通常是通过掺入掺杂 OSC 中间层、引入自组装偶极单层或向活性材料 (AM) 添加移动离子来实现的。在这里，我们展示了一种替代方法，无需额外的注入层或离子添加剂。我们通过将偶极化合物 TMPE-OH 混合到电致发光聚合物超级黄 (SY) 中，并将这种唯一的 AM 沉积在两个空气稳定电极之间，形成单层偶极掺杂 OLED (D-OLED) 来实现这一目标。通过跟踪其瞬态电压-亮度响应、进行阻抗谱分析，并将这些特性与其他两种单层器件概念（即不含偶极化合物的纯 SY OLED 和包含移动离子的发光电化学电池 (LEC)）进行比较，我们可以确定 D-OLED 中的辅助偶极子在施加的驱动电压下重新定向，从而能够立即开启亮度并降低两个电极的注入势垒。最后，我们证明 D-OLED 的电流效率可与采用专用注入层或 LEC 的 SY OLED 相媲美。我们的研究将偶极掺杂确立为一种实用策略，可在溶液处理的有机半导体器件中从空气稳定电极进行有效的双极电荷注入。|[2512.17287](http://arxiv.org/abs/2512.17287)|null|\n",
        "2512.17250": "|**2025-12-19**|**Accelerating Multi-modal LLM Gaming Performance via Input Prediction and Mishit Correction**|实时顺序控制代理通常会受到推理延迟的瓶颈。即使是适度的每步计划延迟也会破坏控制的稳定性并降低整体性能。我们提出了一种推测和校正框架，该框架将推测执行的预测然后验证原理应用于 TD-MPC2 基于模型的控制。在每一步中，预训练的世界模型和潜在空间 MPC 规划器都会生成一个短视野操作队列以及预测的潜在推出，从而允许代理执行多个计划的操作，而无需立即重新规划。当新的观察到达时，系统测量编码的真实潜在状态和排队的预测潜在状态之间的不匹配。对于小到中度的不匹配，轻量级学习校正器会对推测动作应用残差更新，该更新是从重新规划教师离线提取的。对于较大的不匹配，代理可以安全地退回到完全重新规划并清除陈旧的操作队列。我们研究了门控双塔 MLP 校正器和时间 Transformer 校正器来解决局部误差和系统漂移。 DMC Humanoid-Walk 任务的实验表明，我们的方法将规划推理的数量从 500 个减少到 282 个，将端到端步骤延迟提高了 25%，并保持了强大的控制性能，而回报仅减少了 7.1%。消融结果表明，在较长的时间范围内，未经校正的推测执行是不可靠的，这凸显了错配感知校正对于稳健减少延迟的必要性。|[2512.17250](http://arxiv.org/abs/2512.17250)|null|\n",
        "2512.19562": "|**2025-12-22**|**REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation**|视觉-语言-动作（VLA）模型使机器人能够理解和执行自然​​语言指令描述的任务。然而，一个关键的挑战在于它们的泛化能力超出了他们所接受训练的特定环境和条件，而目前在现实世界中评估这一点既困难又昂贵。为了解决这一差距，我们推出了 REALM，这是一种新的模拟环境和基准，旨在评估 VLA 模型的泛化能力，特别强调通过高保真视觉效果和对齐的机器人控制在模拟和现实世界性能之间建立强大的相关性。我们的环境提供了一套 15 个扰动因素、7 种操作技能和超过 3,500 个对象。最后，我们建立了两个任务集来构成我们的基准并评估 π_{0}、π_{0}-FAST 和 GR00T N1.5 VLA 模型，这表明泛化性和鲁棒性仍然是一个开放的挑战。更广泛地说，我们还表明，模拟为我们提供了现实世界的宝贵代理，使我们能够系统地探索和量化 VLA 的弱点和故障模式。项目页面：https://martin-sedlacek.com/realm|[2512.19562](http://arxiv.org/abs/2512.19562)|null|\n",
        "2512.19471": "|**2025-12-22**|**Revealing the intricacies of radio galaxies and filaments in the merging galaxy cluster Abell 2255. II. Properties of filaments using multi-frequency radio data**|在本文中，我们的目标是结合 LOFAR 数据与 uGMRT (1260 MHz) 和 VLA (1520 MHz) 数据进一步分析 Abell 2255 中的灯丝，以约束灯丝的光谱形状。这使得能够以前所未有的高分辨率（~2.3 kpc）研究它们的形态特性，以了解它们的起源，这对于解开原始 TRG 中不同的宇宙射线成分至关重要。我们使用宽视场技术进行了 56 小时的观测，制作了分辨率为 1.5\" 的 LOFAR-VLBI 图。这是该技术首次用于星系团，特别是对于如此深的观测。uGMRT 和 VLA 数据已经过校准和成像，以生成光谱索引图，并应用进一步的技术来提取附加信息，例如细丝的辐射年龄或其均分磁场。还通过旋转测量合成技术使用 VLA 获得了偏振信息。谢谢在 144 MHz 的 LOFAR-VLBI 宽视场图像中，我们发现了超出射电星系附加的非常陡峭 ($α> 2$) 的细丝，延伸约 250 kpc，以前称为 Trail，将 LOFAR-VLBI 与 uGMRT 和 VLA 相结合，我们发现细丝的综合光谱值在 1.1-1.7 之间。光谱分析还表明，原始 TRG 具有复杂的结构，显示出具有不同光谱指数的重叠特征。延伸到整个尾部的偏振发射仅从尾部和灯丝最亮的部分出现，其值高达 22\\%$。|[2512.19471](http://arxiv.org/abs/2512.19471)|null|\n",
        "2512.19453": "|**2025-12-22**|**MaP-AVR: A Meta-Action Planner for Agents Leveraging Vision Language Models and Retrieval-Augmented Generation**|旨在管理复杂日常任务的具体机器人人工智能系统依靠任务规划器来理解和分解高级任务。虽然大多数研究侧重于通过微调或思维链提示来增强 LLM/VLM 的任务理解能力，但本文认为，定义计划的技能组合同样重要。为了应对日常环境的复杂性，技能组合应具有高度的泛化能力。根据经验，更抽象的表达往往更具有普遍性。因此，我们建议将计划结果抽象为一组元操作。每个元动作包含三个组成部分：{移动/旋转、末端执行器状态变化、与环境的关系}。这种抽象用机器人的固有功能取代了以人为中心的概念，例如抓取或推动。因此，计划的结果与机器人能够执行的全部动作无缝结合。此外，为了确保 LLM/VLM 准确地生成所需的元操作格式，我们采用检索增强生成（RAG）技术，该技术利用人工注释的规划演示数据库来促进上下文学习。随着系统成功完成更多任务，数据库将自我扩充以继续支持多样性。元动作集及其与 RAG 的集成是我们规划器的两个新颖贡献，表示为 MaP-AVR，即由 VLM 和 RAG 组成的代理的元动作规划器。为了验证其功效，我们使用 GPT-4o 作为预训练的 LLM/VLM 模型和 OmniGibson 作为我们的机器人平台来设计实验。与当前最先进的方法相比，我们的方法表现出了有希望的性能。项目页面：https://map-avr.github.io/。|[2512.19453](http://arxiv.org/abs/2512.19453)|null|\n",
        "2512.19447": "|**2025-12-22**|**A Gauss-Newton-Induced Structure-Exploiting Algorithm for Differentiable Optimal Control**|可微最优控制，特别是可微非线性模型预测控制（NMPC），提供了一个强大的框架，具有机器学习和控制理论的互补优势。可微最优控制的关键推动因素是计算最优轨迹相对于问题参数的导数，即轨迹导数。先前的工作通过求解微分Karush-Kuhn-Tucker（KKT）系统来计算轨迹导数，并通过构造等效辅助系统有效地实现这一点。然而，我们发现直接利用差分 KKT 系统中的矩阵结构可以显着提高计算速度。受这种见解的启发，我们提出了 FastDOC，它应用 Hessian 的高斯-牛顿近似，并利用所产生的块稀疏性和所涉及矩阵的正半定属性。这些结构特性使我们能够加速计算成本高昂的矩阵分解步骤，从而使理论计算复杂性加快两倍，并且在综合基准测试中，与基线方法相比，FastDOC 实现了高达 180% 的时间减少。最后，我们在类人自动驾驶的模仿学习任务上验证了该方法，结果证明了所提出的 FastDOC 在实际应用中的有效性。|[2512.19447](http://arxiv.org/abs/2512.19447)|null|\n",
        "2512.19396": "|**2025-12-22**|**EchoTrail-GUI: Building Actionable Memory for GUI Agents via Critic-Guided Self-Exploration**|当代 GUI 智能体虽然由于大型视觉语言模型 (VLM) 的进步而能力日益增强，但在运行时却常常面临一个严重的限制：它们孤立地处理每项任务，缺乏系统地从过去的成功经验中学习的机制。这种数字“失忆症”会导致表现不佳、重复错误以及对新挑战的概括能力较差。为了弥补这一差距，我们引入了 EchoTrail-GUI，这是一种新颖的框架，旨在通过为代理配备动态的、可访问的内存来模仿类人的体验式学习。我们的框架分三个不同的阶段运行。首先，在体验探索期间，代理自动与 GUI 环境交互，构建成功任务轨迹的精选数据库，并通过奖励模型进行验证。至关重要的是，整个知识库构建是完全自动化的，不需要人工监督。其次，在记忆注入阶段，在收到新任务后，我们的系统会有效地检索最相关的过去轨迹，作为可操作的“记忆”。最后，在 GUI 任务推理过程中，这些记忆被注入作为上下文指导，以告知代理的推理和决策过程。我们在 Android World 和 AndroidLab 等基准测试中展示了我们方法的有效性。结果表明，EchoTrail-GUI 显着提高了基线代理的任务成功率和运行效率，验证了结构化内存在创建更强大、更智能的 GUI 自动化方面的能力。|[2512.19396](http://arxiv.org/abs/2512.19396)|null|\n",
        "2512.19302": "|**2025-12-22**|**Bridging Semantics and Geometry: A Decoupled LVLM-SAM Framework for Reasoning Segmentation in Remote Sensing**|大型视觉语言模型 (LVLM) 为推进遥感 (RS) 分析带来了巨大希望，但现有的推理分割框架通过端到端监督微调将语言推理和像素预测结合起来，导致几何基础薄弱，跨任务泛化能力有限。为了解决这个问题，我们开发了 Think2Seg-RS，这是一个解耦框架，可训练 LVLM 提示器通过结构化几何提示来控制冻结的分段任意模型 (SAM)。通过仅掩模强化学习目标，LVLM 学会将抽象语义推理转化为基于空间的动作，从而在 EarthReason 数据集上实现最先进的性能。值得注意的是，学习到的提示策略将零样本推广到多个引用分割基准，暴露了语义级和实例级基础之间的明显鸿沟。我们进一步发现，在语义级监督下，紧凑的分割器优于较大的分割器，并且负面提示在异构空中背景中无效。总之，这些发现将语义级推理分割确立为地理空间理解的新范式，为统一、可解释的 LVLM 驱动的地球观测开辟了道路。我们的代码和模型可在 https://github.com/Ricardo-XZ/Think2Seg-RS 上获取。|[2512.19302](http://arxiv.org/abs/2512.19302)|null|\n",
        "2512.19277": "|**2025-12-22**|**Active diffusing crystals in a 2D non-equilibrium system**|我们研究了单分散盘的二维动态吸收态模型，其中丰富的相行为源于仅由重叠粒子之间的排斥位移组成的相互作用。相图揭示了几个非常规的特征，包括无序和静态吸收构型，其中没有颗粒重叠，通过二级相变分隔成具有集体环扩散的连续演化的活性六方晶体，该晶体又经历一级相变成活性各向同性液体。唯一的驱动参数是 $ε$，即随机排斥踢的最大尺寸。小的 $ε$ 有助于自组织进入有序状态，但大的 $ε$ 会阻止这种组织的发生。这与典型的有序-无序转变非常不同，在典型的有序-无序转变中，有两种相互竞争的影响，即能量和熵，驱动着这种转变。|[2512.19277](http://arxiv.org/abs/2512.19277)|null|\n",
        "2512.19270": "|**2025-12-22**|**Are All Data Necessary? Efficient Data Pruning for Large-scale Autonomous Driving Dataset via Trajectory Entropy Maximization**|收集大规模的自然驾驶数据对于训练强大的自动驾驶规划者至关重要。然而，现实世界的数据集往往包含大量重复和低价值的样本，这导致存储成本过高，给政策学习带来的好处有限。为了解决这个问题，我们提出了一种信息论数据修剪方法，可以在不影响模型性能的情况下有效减少训练数据量。我们的方法评估驾驶数据的轨迹分布信息熵，并迭代选择高价值样本，以与模型无关的方式保留原始数据集的统计特征。从理论角度来看，我们表明最大化轨迹熵可以有效限制剪枝子集与原始数据分布之间的 Kullback-Leibler 散度，从而保持泛化能力。使用大规模模仿学习框架在 NuPlan 基准上进行的综合实验表明，所提出的方法可以在保持闭环性能的同时将数据集大小减少多达 40%。这项工作为自动驾驶系统中的可扩展数据管理和高效策略学习提供了一种轻量级且有理论依据的方法。|[2512.19270](http://arxiv.org/abs/2512.19270)|null|\n",
        "2512.19210": "|**2025-12-22**|**Observer, Not Player: Simulating Theory of Mind in LLMs through Game Observation**|我们提出了一个交互式框架，用于评估大型语言模型（LLM）是否在简单但具有战略意义的环境中表现出真正的“理解”。作为一个正在运行的例子，我们关注石头剪刀布（RPS），尽管它看起来很简单，但它需要顺序推理、适应和策略识别。我们的系统将法学硕士定位为观察员，其任务是识别正在采取的策略并阐明这一判断背后的推理。目的不是测试石头剪刀布本身的知识，而是探讨该模型是否能够表现出关于顺序行为的类似心灵的推理。为了支持系统评估，我们提供了一个由静态策略和由良好提示的规则指定的轻量级动态策略组成的基准。我们使用三个互补信号来量化观察者的预测与实际策略对引起的真实分布之间的一致性：交叉熵、Brier 得分和期望值 (EV) 差异。这些指标进一步整合到一个统一的分数中，即联合损失，它平衡了校准、敏感性和收益一致性。与策略识别率（SIR）指标一起，我们的框架不仅可以捕获预测准确性，还可以捕获模型是否能够稳定地识别正在发挥作用的潜在策略。该演示强调交互性、透明度和可重复性。用户可以实时调整 LLM 分布，可视化损失的演变，并直接检查推理片段以识别失败发生的位置和原因。在此过程中，我们的系统为顺序游戏中的类心智推理提供了实用且可解释的代理，提供了对当前法学硕士推理的优势和局限性的见解。|[2512.19210](http://arxiv.org/abs/2512.19210)|null|\n",
        "2512.19150": "|**2025-12-22**|**AMap: Distilling Future Priors for Ahead-Aware Online HD Map Construction**|在线高清地图构建对于自动驾驶至关重要。虽然最近的方法利用历史时间融合来提高性能，但我们在这种范式中发现了一个关键的安全缺陷：它本质上是“空间向后看”。这些方法主要增强了遍历区域的地图重建，对前方看不见的道路提供了最小的改进。至关重要的是，我们对下游规划任务的分析揭示了严重的不对称性：虽然向后感知错误通常是可以容忍的，但前方区域的不准确直接导致了危险的驾驶操作。为了弥补这一安全差距，我们提出了 AMap，一种新的框架我们开创了一种“从未来提炼”的范例，其中具有对未来时间上下文的特权访问权限的教师模型指导仅限于当前框架的轻量级学生模型。这个过程隐式地将前瞻性知识压缩到学生模型中，赋予其零推理时间成本的“前瞻”功能。从技术上讲，我们引入了具有空间屏蔽和非对称查询适应模块的多级 BEV 蒸馏策略，以有效地将未来感知表示转移到学生的静态查询中。nuScenes 和 Argoverse 2 基准的大量实验表明，AMap 显着增强了当前帧感知。最值得注意的是，它在关键前向区域中优于最先进的时间模型，同时保持单个当前帧推理的效率。|[2512.19150](http://arxiv.org/abs/2512.19150)|null|\n",
        "2512.20615": "|**2025-12-23**|**Active Intelligence in Video Avatars via Closed-loop World Modeling**|当前的视频头像生成方法擅长身份保存和运动对齐，但缺乏真正的代理，它们无法通过自适应环境交互自主地追求长期目标。我们通过引入 L-IVA（长视野交互式视觉化身）和 ORCA（在线推理和认知架构）来解决这个问题，L-IVA 是一种在随机生成环境中评估目标导向规划的任务和基准，ORCA 是第一个在视频化身中实现主动智能的框架。 ORCA 通过两项关键创新体现了内部世界模型 (IWM) 功能：(1) 闭环 OTAR 循环（观察-思考-行动-反思），通过不断验证实际生成的预测结​​果，在生成不确定性下保持强大的状态跟踪；(2) 分层双系统架构，其中系统 2 通过状态预测进行战略推理，而系统 1 将抽象计划转换为精确的、特定于模型的动作说明。通过将化身控制制定为 POMDP 并通过结果验证实现持续信念更新，ORCA 能够在开放域场景中自主完成多步骤任务。大量实验表明，ORCA 在任务成功率和行为一致性方面显着优于开环和非反射基线，验证了我们受 IWM 启发的设计，可将视频头像智能从被动动画提升为主动、目标导向的行为。|[2512.20615](http://arxiv.org/abs/2512.20615)|null|\n",
        "2512.20480": "|**2025-12-23**|**Optoelectronically Directed Self-Assembly of Active and Passive Particles into Programmable and Reconfigurable Colloidal Structures**|主动-被动胶体混合物的受控组装为可重构微型机器提供了一条途径，但它们的自组装途径仍然知之甚少。我们使用光电可重构​​交流场图案研究金属介电 Janus 颗粒 (JP) 和被动聚苯乙烯 (PS) 珠的定向组装，这可以精确控制颗粒组成和结合序列。通过实验、分析建模和模拟，我们表明偶极相互作用驱动稳健的 JP-JP 和 JP-PS 二聚体形成，并具有频率依赖性稳定性。在中频和高频下，JP-PS 结合具有很强的吸引力，而在低频下，由于金属半球的电双层屏蔽和电流体动力学流动，它变得有效排斥。在多粒子系统中，PS 珠充当协作中心，分层招募 JP，产生更高阶的混合结构。我们识别结构异构体 - 例如，3JP + 1PS 簇可以根据组装顺序形成链状或三角形构型。模拟证实两者都处于平衡状态，其中三角形异构体稍微更稳定。类似的多态性出现在较大的簇（4JP）中。总体而言，我们建立了一个受控主动-被动胶体组装框架，展示了频率可调相互作用和结构多态性如何实现可重构胶体机器的设计，以应用于微型机器人、靶向输送和自适应材料。|[2512.20480](http://arxiv.org/abs/2512.20480)|null|\n",
        "2512.20299": "|**2025-12-23**|**KnowVal: A Knowledge-Augmented and Value-Guided Autonomous Driving System**|视觉语言推理、驾驶知识和价值调整对于先进的自动驾驶系统至关重要。然而，现有的方法很大程度上依赖于数据驱动的学习，因此很难通过模仿或有限的强化奖励来捕获决策背后的复杂逻辑。为了解决这个问题，我们提出了 KnowVal，一种新的自动驾驶系统，它通过开放世界感知和知识检索的协同集成来实现视觉语言推理。具体来说，我们构建了一个全面的驾驶知识图谱，其中编码了交通法规、防御性驾驶原则和道德规范，并辅以针对驾驶场景定制的高效的基于法学硕士的检索机制。此外，我们开发了人类偏好数据集并训练价值模型来指导可解释的、价值一致的轨迹评估。实验结果表明，我们的方法大大提高了规划性能，同时保持与现有架构的兼容性。值得注意的是，KnowVal 在 nuScenes 上实现了最低的碰撞率，在 Bench2Drive 上实现了最先进的结果。|[2512.20299](http://arxiv.org/abs/2512.20299)|null|\n",
        "2512.20276": "|**2025-12-23**|**ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge**|视觉-语言-动作（VLA）模型已成为机器人感知和控制的统一范例，可实现紧急泛化和长期任务执行。然而，它们在动态的现实环境中的部署受到高推理延迟的严重阻碍。虽然流畅的机器人交互需要 20 至 30 Hz 的控制频率，但由于自回归解码的内存限制性质，当前的 VLA 模型在边缘设备上通常仅以 3-5 Hz 的频率运行。现有的优化通常需要大量的重新训练或妥协模型的准确性。为了弥补这一差距，我们引入了 ActionFlow，这是一个专为资源受限的边缘平台量身定制的系统级推理框架。 ActionFlow 的核心是跨请求管道策略，这是一种新颖的调度程序，它将 VLA 推理重新定义为微请求的宏管道。该策略在连续的时间步长内智能地将内存限制的解码阶段与计算限制的预填充阶段进行批处理，以最大限度地提高硬件利用率。此外，为了支持这种调度，我们提出了一个交叉请求状态打包前向运算符和一个统一的 KV 环形缓冲区，它将碎片内存操作融合到高效的密集计算中。实验结果表明，ActionFlow 在 OpenVLA-7B 模型上无需重新训练即可将 FPS 提高 2.55 倍，从而实现边缘硬件上的实时动态操作。我们的工作可在 https://anonymous.4open.science/r/ActionFlow-1D47 获取。|[2512.20276](http://arxiv.org/abs/2512.20276)|null|\n",
        "2512.20224": "|**2025-12-23**|**UrbanV2X: A Multisensory Vehicle-Infrastructure Dataset for Cooperative Navigation in Urban Areas**|由于单一自动驾驶汽车的局限性，蜂窝车联网（C-V2X）技术为通过传感器信息共享实现完全自动驾驶打开了新的窗口。然而，支持复杂城市环境中车辆与基础设施协同导航的现实数据集仍然很少。为了解决这一差距，我们推出了 UrbanV2X，这是一个从香港 C-V2X 测试台的车辆和路边基础设施收集的综合多感官数据集，旨在支持密集城市地区智能移动应用的研究。我们的机载平台提供来自多个工业相机、LiDAR、4D 雷达、超宽带 (UWB)、IMU 和高精度 GNSS-RTK/INS 导航系统的同步数据。同时，我们的路边基础设施提供 LiDAR、GNSS 和 UWB 测量。整个车辆基础设施平台使用精确时间协议（PTP）进行同步，并提供传感器校准数据。我们还对各种导航算法进行基准测试来评估收集的协作数据。该数据集可在 https://polyu-taslab.github.io/UrbanV2X/ 上公开获取。|[2512.20224](http://arxiv.org/abs/2512.20224)|null|\n",
        "2512.20188": "|**2025-12-23**|**Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation**|大多数视觉语言动作（VLA）系统集成了用于语义推理的视觉语言模型（VLM）和生成连续动作信号的动作专家，但两者通常以单一统一频率运行。因此，策略性能受到大型 VLM 的低推理速度的限制。这种强制同步执行严重限制了全身机器人操作的控制稳定性和实时性，因为全身机器人操作涉及更多的关节、更大的运动空间和动态变化的视图。我们引入了真正的异步快-慢VLA框架（DuoCore-FS），将系统组织成用于高频动作生成的快速路径和用于丰富VLM推理的慢速路径。该系统有两个主要特点。首先，潜在表示缓冲区桥接了慢系统和快系统。它存储与场景指令上下文一致的指令语义和动作推理表示，为快速路径提供高级指导。其次，全身动作标记器提供了全身动作的紧凑、统一的表示。重要的是，VLM 和行动专家仍然接受端到端联合训练，在实现异步执行的同时保留统一的策略学习。 DuoCore-FS 支持 3B 参数 VLM，同时实现 30 Hz 全身动作块生成，速度大约是具有类似模型尺寸的先前 VLA 模型的三倍。真实世界的全身操作实验表明，与同步快-慢 VLA 基线相比，任务成功率有所提高，响应能力也显着增强。 DuoCore-FS 的实现（包括训练、推理和部署）由 Astribot 作为 Astribot 机器人平台的一部分向商业用户提供。|[2512.20188](http://arxiv.org/abs/2512.20188)|null|\n",
        "2512.20179": "|**2025-12-23**|**RESPOND: Risk-Enhanced Structured Pattern for LLM-driven Online Node-level Decision-making**|当前基于法学硕士的驾驶代理依赖于非结构化纯文本内存，其场景检索精度低且反射效率低。为了解决这一限制，我们提出了 RESPOND，这是一个基于明确风险模式的 LLM 驱动代理的结构化决策框架。 RESPOND 使用统一的 5 x 3 矩阵来表示每个以自我为中心的场景，该矩阵对空间拓扑和道路约束进行编码，从而能够一致且可靠地检索空间风险配置。基于这种表示，使用两层内存机制开发了混合规则和LLM决策管道。在高风险环境中，精确的模式匹配可以快速、安全地重用经过验证的操作，而在低风险环境中，子模式匹配支持个性化的驾驶风格适应。此外，模式感知反射机制从崩溃和未遂帧中提取战术修正，以更新结构化记忆，实现一次崩溃即可泛化的学习。大量实验证明了 RESPOND 的有效性。在高速公路环境中，RESPOND 的性能优于最先进的基于 LLM 和强化学习的驾驶代理，同时产生的碰撞大大减少。通过逐步的人类反馈，智能体通过子模式抽象在大约 20 个决策步骤内获得运动驾驶风格。对于现实世界的验证，RESPOND 在从 HighD 数据集中提取的 53 个高风险切入场景进行评估。对于每个事件，在切入前立即进行干预，并通过 RESPOND 重新决定驾驶操作。与记录的人类行为相比，RESPOND 在 84.9% 的场景中降低了后续风险，证明了其在现实驾驶条件下的实际可行性。这些结果凸显了 RESPOND 在自动驾驶、个性化驾驶辅助和主动缓解危险方面的潜力。|[2512.20179](http://arxiv.org/abs/2512.20179)|null|\n",
        "2512.20166": "|**2025-12-23**|**LoLA: Long Horizon Latent Action Learning for General Robot Manipulation**|执行长期、语言引导的机器人操作任务的能力关键依赖于利用历史信息和生成连贯的动作序列。然而，现有的视觉-语言-动作（VLA）模型经常忽视这些功能。为了解决这一挑战，我们提出了 LoLA（长视野潜在动作学习），这是一种专为机器人操作而设计的框架，它集成了长期多视图观察和机器人本体感觉，以实现多步骤推理和动作生成。我们首先使用视觉语言模型来编码来自历史序列和多视图观察的丰富上下文特征。我们进一步介绍了一个关键模块，即状态感知潜在重新表示，它将视觉输入和语言命令转换为可操作的机器人运动空间。与仅将机器人本体感觉（例如关节角度）与 VL 嵌入连接起来的现有 VLA 方法不同，该模块利用此类机器人状态，通过可学习的“实施例锚定”潜在空间在物理尺度上显式地构建 VL 表示。我们在不同的机器人预训练数据集上训练 LoLA，并对模拟基准（SIMPLER 和 LIBERO）以及 Franka 和 Bi-Manual Aloha 机器人的两项现实任务进行了广泛的评估。结果表明，LoLA 显着优于先前最先进的方法（例如 pi0），特别是在长视野操作任务中。|[2512.20166](http://arxiv.org/abs/2512.20166)|null|\n",
        "2512.20105": "|**2025-12-23**|**LiDARDraft: Generating LiDAR Point Cloud from Versatile Inputs**|生成真实且多样化的激光雷达点云对于自动驾驶仿真至关重要。尽管以前的方法可以根据用户输入实现激光雷达点云生成，但由于激光雷达点云的复杂分布与简单的控制信号之间的不平衡，它们很难在实现多功能可控性的同时获得高质量的结果。为了解决这一限制，我们提出了 LiDARDraft，它利用 3D 布局在多功能条件信号和 LiDAR 点云之间建立桥梁。 3D 布局可以根据各种用户输入（例如文本描述和图像）轻松生成。具体来说，我们将文本、图像和点云表示为统一的 3D 布局，并进一步转换为语义和深度控制信号。然后，我们采用基于范围图的 ControlNet 来指导 LiDAR 点云生成。这种像素级对齐方法在可控 LiDAR 点云生成方面展示了出色的性能，实现了“从头开始模拟”，允许从任意文本描述、图像和草图创建自动驾驶环境。|[2512.20105](http://arxiv.org/abs/2512.20105)|null|\n",
        "2512.20014": "|**2025-12-23**|**Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting**|虽然视觉-语言-动作（VLA）模型可以很好地概括通用指令，但它们很难处理诸如“拿来我的杯子”之类的个性化命令，其中机器人必须对视觉上相似的物体中的一个特定实例采取行动。我们研究了这种操纵个人物体的设置，其中 VLA 必须仅使用一些参考图像来识别和控制在训练期间看不见的特定于用户的物体。为了应对这一挑战，我们提出了视觉注意提示（VAP），这是一种简单而有效的免训练感知适配器，为冻结的 VLA 提供自上而下的选择性注意。 VAP 将参考图像视为非参数视觉记忆，通过开放词汇检测和基于嵌入的匹配来为场景中的个人对象奠定基础，然后通过突出显示对象并重写指令将这种基础作为视觉提示注入。我们构建了两个模拟基准：Personalized-SIMPLER 和 Personalized-VLABench，以及一个真实世界的桌面基准来评估跨多个机器人和任务的个性化操作。实验表明，VAP 在成功率和正确对象操作方面始终优于通用策略和令牌学习基线，有助于弥合语义理解和实例级控制之间的差距。|[2512.20014](http://arxiv.org/abs/2512.20014)|null|\n",
        "2512.21220": "|**2025-12-24**|**RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic**|由视觉语言模型（VLM）驱动的实体代理越来越有能力执行复杂的现实世界任务，但它们仍然容易受到可能引发不安全行为的危险指令的影响。运行时安全护栏可以拦截任务执行期间的危险行为，由于其灵活性而提供了一种有前景的解决方案。然而，现有的防御措施通常依赖于静态规则过滤器或提示级别控制，这很难解决动态、时间依赖和上下文丰富的环境中出现的隐含风险。为了解决这个问题，我们提出了 RoboSafe，这是一种通过可执行的基于谓词的安全逻辑为实体代理提供混合推理运行时保护的方法。 RoboSafe 在混合长短安全存储器上集成了两个互补的推理过程。我们首先提出了一个向后反射推理模块，该模块不断地重新访问短期记忆中的最近轨迹，以推断时间安全谓词，并在检测到违规时主动触发重新计划。然后，我们提出了一个前向预测推理模块，该模块通过从长期安全记忆和代理的多模态观察中生成上下文感知的安全谓词来预测即将到来的风险。这些组件共同形成了一个自适应的、可验证的安全逻辑，该逻辑既可解释又可作为代码执行。跨多个代理的广泛实验表明，与领先基线相比，RoboSafe 大幅减少了危险行为（-36.8% 风险发生），同时保持接近原始的任务性能。对物理机械臂的现实评估进一步证实了其实用性。代码将在接受后发布。|[2512.21220](http://arxiv.org/abs/2512.21220)|null|\n",
        "2512.21201": "|**2025-12-24**|**Schrödinger's Navigator: Imagining an Ensemble of Futures for Zero-Shot Object Navigation**|零射击物体导航（ZSON）要求机器人在以前未见过的环境中定位目标物体，而不依赖于预先构建的地图或特定于任务的训练。然而，现有的 ZSON 方法通常在现实和混乱的环境中陷入困境，特别是当场景包含严重遮挡、未知风险或动态移动的目标对象时。为了应对这些挑战，我们提出了 \\textbf{薛定谔导航器}，这是一个受薛定谔关于不确定性的思想实验启发的导航框架。该框架将未观测到的空间视为一组可能的未来世界，并在采取行动之前对它们进行推理。以自我为中心的视觉输入和三个候选轨迹为条件，轨迹条件 3D 世界模型可以想象沿每条路径的未来观察结果。这使得智能体能够超越遮挡并预测看不见区域的风险，而不需要额外的弯路或密集的全局映射。想象的 3D 观察结果被融合到导航地图中并用于更新价值地图。这些更新引导策略走向避免遮挡、减少暴露于不确定空间并更好地跟踪移动目标的轨迹。在 Go2 四足机器人上进行的三个具有挑战性的场景（包括严重的静态遮挡、未知风险和动态移动目标）的实验表明，薛定谔的导航器在自定位、对象定位和遮挡严重环境中的总体成功率方面始终优于强大的 ZSON 基线。这些结果证明了轨迹条件 3D 想象力在实现稳健的零样本对象导航方面的有效性。|[2512.21201](http://arxiv.org/abs/2512.21201)|null|\n",
        "2512.21133": "|**2025-12-24**|**SparScene: Efficient Traffic Scene Representation via Sparse Graph Learning for Large-Scale Trajectory Generation**|多智能体轨迹生成是自动驾驶和智能交通系统的核心问题。然而，在复杂场景中对众多道路使用者和基础设施之间的动态交互进行有效建模仍然是一个悬而未决的问题。现有方法通常采用基于距离或全连接的密集图结构来捕获交互信息，这不仅引入了大量冗余边，而且需要复杂且参数化程度高的网络进行编码，从而导致训练和推理效率低，限制了对大型复杂交通场景的可扩展性。为了克服现有方法的局限性，我们提出了 SparScene，一种稀疏图学习框架，专为高效且可扩展的交通场景表示而设计。 SparScene 不依赖距离阈值，而是利用车道图拓扑在代理和车道之间构建结构感知的稀疏连接，从而实现高效且信息丰富的场景图表示。 SparScene 采用轻量级图形编码器，可有效聚合智能体-地图和智能体-智能体交互，产生紧凑的场景表示，并显着提高效率和可扩展性。在 Waymo 开放运动数据集 (WOMD) 的运动预测基准上，SparScene 以卓越的效率实现了具有竞争力的性能。它可以在 5 毫秒内生成场景中 200 多个智能体的轨迹，并可扩展到超过 5,000 个智能体和 17,000 条车道，推理时间仅为 54 毫秒，GPU 内存为 2.9 GB，凸显了其针对大规模交通场景的卓越可扩展性。|[2512.21133](http://arxiv.org/abs/2512.21133)|null|\n",
        "2512.21129": "|**2025-12-24**|**Active inference and artificial reasoning**|本技术说明考虑了提供有关底层世界模型结构的最大量信息的结果抽样。这种概括提供了一种在一组合理的生成模型或假设下构建学习的原则性方法。在主动推理中，策略（即行动组合）是根据其预期的自由能（包括预期的信息增益和价值）来选择的。信息增益对应于有或没有行动后果的预测后验之间的 KL 散度。基于累积的关于模型参数的后验信念，可以使用贝叶斯模型归约快速有效地评估模型的后验。然后，本着最佳实验设计的精神，随后的信息增益可用于选择消除替代模型中歧义的操作。我们使用部分观察的离散模型来说明这种主动选择或推理；即，“三球”范式以前用于描述通过（综合）内省或睡眠进行的人工洞察和“顿悟时刻”。我们关注的是通过寻求解决世界模型（在该模型下生成结果）的最大不确定性的结果所提供的样本效率。|[2512.21129](http://arxiv.org/abs/2512.21129)|null|\n",
        "2512.20940": "|**2025-12-24**|**ETP-R1: Evolving Topological Planning with Reinforcement Fine-tuning for Vision-Language Navigation in Continuous Environments**|连续环境中的视觉语言导航（VLN-CE）需要一个实体代理按照自然语言指令在连续环境中导航到目标。虽然当前基于图的方法通过将环境抽象为拓扑图并将动作空间简化为航路点选择来提供有效的结构化方法，但它们在利用大规模数据和高级训练范例方面落后于基于大型视觉语言模型（LVLM）的方法。在本文中，我们试图通过引入 ETP-R1 来弥补这一差距，该框架将数据扩展和强化微调（RFT）范式应用于基于图的 VLN-CE 模型。为了打下坚实的基础，我们首先使用 Gemini API 构建高质量、大规模的预训练数据集。该数据集由拓扑轨迹的多样化、低幻觉指令组成，为我们基于图的策略将语言映射到拓扑路径提供了丰富的监督。通过统一 R2R 和 RxR 任务的数据进行联合预训练，这一基础得到进一步加强。在此基础上，我们引入了一个三阶段训练范例，最终首次将闭环在线 RFT 应用于基于图的 VLN-CE 模型，该模型由组相对策略优化 (GRPO) 算法提供支持。大量实验表明，我们的方法非常有效，在 R2R-CE 和 RxR-CE 基准测试的所有主要指标上都建立了新的最先进的性能。我们的代码可在 https://github.com/Cepillar/ETP-R1 获取。|[2512.20940](http://arxiv.org/abs/2512.20940)|null|\n",
        "2512.20884": "|**2025-12-24**|**The Silent Scholar Problem: A Probabilistic Framework for Breaking Epistemic Asymmetry in LLM Agents**|由法学硕士和检索增强生成（RAG）支持的自主代理是数字内容的熟练消费者，但仍然是单向的，我们称之为认知不对称的限制。这种孤立会导致冗余推理并阻碍集体智慧。当前的自我反思框架在很大程度上仍然是启发式和私密性的，缺乏量化确定性或证明外部交互合理性的概率基础。为了弥补这一差距，我们提出了一个正式的概率框架，为代理提供了双向知识交换的非利他动机。我们使用带有遗忘因子 ($γ$) 的 Beta-Bernoulli 分布来模拟代理人对某个命题的信念。这使我们能够将认知不确定性隔离为信念的方差，建立互动的双重驱动力：稳态动机：需要保持确定性以防止 $γ$ 引入的时间衰减。最佳学习策略：定位最大模糊点（$\\mathbb{E}[θ]=0.5$）以最大化信息增益。在此框架下，公共贡献被重新定义为最佳主动学习：共享解决方案以引发反馈是代理减少自身不确定性的最有效方法。为了确保可扩展性，我们引入了认知缓存，它利用遗忘因子来动态地为非平稳知识分布的主动头分配资源的优先级。最后，我们演示了这些积累的信念状态如何充当人类反馈强化学习（RLHF）的可验证奖励信号和监督微调（SFT）的高质量数据过滤器。仿真结果验证了这种不确定性驱动的策略在异构 (Zipfian) 环境中显着优于随机基线，保持了对概念漂移的高度适应性。|[2512.20884](http://arxiv.org/abs/2512.20884)|null|\n",
        "2512.20868": "|**2025-12-24**|**Early warning signals for loss of control**|从飞机和自主机器人到生物和生理系统，维持反馈系统的稳定性依赖于监控它们的行为并不断调整它们的输入。渐进的损害会使这种控制变得脆弱。这往往会被忽视，直到一个小的扰动导致不稳定（即失去控制）。工程领域的传统方法依赖于准确的系统模型来计算一组安全的操作指令，当可能损坏的系统偏离其模型时，这些指令就会变得无效。在这里，我们证明，这种反馈系统对不稳定性的处理方法仍然可以通过弹性的动态指标来监控。这种整体系统安全监控器不依赖于系统模型，而是基于临界减速的一般现象，这种现象已被证明发生在气候、生物和其他接近临界的复杂非线性系统中。我们对工程设备的研究结果开辟了广泛的应用，涉及实时预警系统以及弹性系统设计探索或“修补”的经验指导。虽然我们使用无人机证明了有效性，但基本原理的通用性质表明这些指标可以适用于更广泛的受控系统，包括反应堆、飞机和自动驾驶汽车。|[2512.20868](http://arxiv.org/abs/2512.20868)|null|\n",
        "2512.20815": "|**2025-12-23**|**Learning to Sense for Driving: Joint Optics-Sensor-Model Co-Design for Semantic Segmentation**|传统的自动驾驶流程将摄像头设计与下游感知分离，依靠固定光学器件和手工制作的 ISP，优先考虑人类可见图像而不是机器语义。这种分离会在去马赛克、去噪或量化过程中丢弃信息，同时迫使模型适应传感器伪影。我们提出了一个任务驱动的协同设计框架，它将光学、传感器建模和轻量级语义分割网络统一到单个端到端 RAW 到任务管道中。我们的系统以 DeepLens[19] 为基础，集成了真实的手机级镜头模型、可学习的滤色器阵列、泊松高斯噪声处理和量化，所有这些都直接针对分割目标进行了优化。对 KITTI-360 的评估显示，与固定管道相比，mIoU 得到了一致的改进，其中光学建模和 CFA 学习提供了最大的增益，特别是对于薄或低光敏感类别。重要的是，这些稳健性增益是通过以约 28 FPS 运行的紧凑型约 1M 参数模型实现的，展示了边缘可部署性。视觉和定量分析进一步强调了共同设计的传感器如何使采集适应语义结构、锐化边界并在模糊、噪声和低位深度下保持准确性。这些发现共同确立了光学、传感器和网络的全栈协同优化，作为在自主系统中实现高效、可靠和可部署感知的原则路径。|[2512.20815](http://arxiv.org/abs/2512.20815)|null|\n",
        "2512.20786": "|**2025-12-23**|**Simultaneous JWST, NuSTAR, and VLA Monitoring of Sgr A*: A Unified Picture of the Variable IR, X-ray and Radio Emission**|通量变化是 Sgr A* 信息的基本通道，因为它直接探测强重力下吸积盘内发生的过程。我们展示了 2024 年 4 月 5 日使用 JWST、NuSTAR 和 VLA 对人马座 A* 进行的同步红外、X 射线和射电观测。我们报告检测到光度为 $\\sim5.2x10^{35}$ erg/s 的强烈 X 射线耀斑，与明亮的近红外耀斑一致，并且大约一小时后无线电中出现增亮。我们研究了 X 射线耀斑发射的候选物理机制，并得出结论，这可以通过近红外耀斑辐射的逆康普顿散射得到最好的解释。我们提出了一种类似于日冕物质抛射的动态场景，其中磁通量绳从 Sgr A* 的内部吸积流中喷出，电流片从磁绳向下延伸到吸积流的主体。片内的重新连接产生相反方向的加速粒子流，这些加速粒子流向上朝向绳索移动并且向下朝向吸积流移动。来自接近的高能电子的红外辐射通过射束增强，并被吸积流中的热电子向上散射，从而产生强烈的 X 射线耀斑。与此同时，沿相反方向移动远离磁盘的相对论电子会经历较弱的磁场，因此通过馈入磁通管并在随后的膨胀过程中绝热冷却，以较长的波长辐射。这张物理图片试图统一人马座 A* 在红外、X 射线和射电/亚毫米波长下的可变发射的起源。|[2512.20786](http://arxiv.org/abs/2512.20786)|null|\n",
        "2512.20770": "|**2025-12-23**|**OccuFly: A 3D Vision Benchmark for Semantic Scene Completion from the Aerial Perspective**|语义场景完成 (SSC) 对于移动机器人中的 3D 感知至关重要，因为它通过联合估计密集体积占用率和每体素语义来实现整体场景理解。尽管SSC已在自动驾驶等地面领域得到广泛研究，但自动飞行等空中场景在很大程度上仍未被探索，从而限制了下游应用的进展。此外，LiDAR 传感器代表了 SSC 数据生成的主要方式，由于飞行法规、质量和能量限制以及从高视角看基于 LiDAR 的点云的稀疏性，这对大多数无人驾驶飞行器 (UAV) 提出了挑战。为了解决这些限制，我们推出了 OccuFly，这是第一个现实世界中基于相机的航空 SSC 基准测试，在春季、夏季、秋季和冬季在 50m、40m 和 30m 的高度捕获。 OccuFly覆盖城市、工业和农村场景，提供22个语义类别，数据格式遵循既定惯例，便于与现有研究无缝集成。至关重要的是，我们提出了一种基于相机模态的无激光雷达数据生成框架，该框架在现代无人机上无处不在。通过利用传统的 3D 重建，我们的框架通过将带注释的 2D 掩模的子集提升到重建的点云中来自动化标签传输，从而大大减少手动 3D 注释工作。最后，我们对 OccuFly 的最新技术进行了基准测试，并强调了特定于高视角的挑战，从而为整体航空 3D 场景理解提供了全面的视觉基准。|[2512.20770](http://arxiv.org/abs/2512.20770)|null|\n"
    }
}