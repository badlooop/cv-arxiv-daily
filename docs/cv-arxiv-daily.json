{
    "Video Diffusion": {
        "2601.14255": "|**2026-01-20**|**VideoMaMa: Mask-Guided Video Matting via Generative Prior**|由于标记数据的稀缺，将视频抠图模型推广到现实世界的视频仍然是一个重大挑战。为了解决这个问题，我们提出了视频遮罩到遮罩模型 (VideoMaMa)，它利用预训练的视频扩散模型将粗分割遮罩转换为像素精确的 alpha 遮罩。 VideoMaMa 展示了对现实世界镜头的强大的零镜头泛化能力，尽管它仅基于合成数据进行训练。在此功能的基础上，我们开发了一个用于大规模视频抠图的可扩展伪标签管道，并构建了视频抠图（MA-V）数据集，该数据集为超过 50K 个跨越不同场景和动作的真实视频提供了高质量的抠图注释。为了验证该数据集的有效性，我们在 MA-V 上微调 SAM2 模型以获得 SAM2-Matte，就野外视频的鲁棒性而言，该模型优于在现有抠图数据集上训练的相同模型。这些发现强调了大规模伪标记视频抠图的重要性，并展示了生成先验和可访问的分割线索如何推动视频抠图研究的可扩展进展。|[2601.14255](http://arxiv.org/abs/2601.14255)|null|\n",
        "2601.14250": "|**2026-01-20**|**OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer**|视频比图像或文本传达更丰富的信息，捕捉空间和时间动态。然而，大多数现有的视频定制方法依赖于参考图像或特定于任务的时间先验，未能充分利用视频固有的丰富的时空信息，从而限制了视频生成的灵活性和泛化性。为了解决这些限制，我们提出了 OmniTransfer，一个用于时空视频传输的统一框架。它利用跨帧的多视图信息来增强外观一致性，并利用时间线索来实现细粒度的时间控制。为了统一各种视频传输任务，OmniTransfer 采用了三个关键设计： 任务感知位置偏差，自适应地利用参考视频信息来提高时间对齐或外观一致性；参考解耦因果学习将参考分支和目标分支分开，以实现精确的参考传输，同时提高效率；任务自适应多模态对齐使用多模态语义指导来动态区分和处理不同的任务。大量实验表明，OmniTransfer 在外观（ID 和风格）和时间传输（相机运动和视频效果）方面优于现有方法，同时在不使用姿势的运动传输中匹配姿势引导方法，为灵活、高保真视频生成建立了新范例。|[2601.14250](http://arxiv.org/abs/2601.14250)|null|\n",
        "2601.15221": "|**2026-01-21**|**ScenDi: 3D-to-2D Scene Diffusion Cascades for Urban Generation**|使用扩散模型生成 3D 对象的最新进展取得了显着的成功，但生成逼真的 3D 城市场景仍然具有挑战性。仅依赖 3D 扩散模型的现有方法往往会导致外观细节的退化，而仅使用 2D 扩散模型的方法通常会损害相机的可控性。为了克服这一限制，我们提出了 ScenDi，一种集成了 3D 和 2D 扩散模型的城市场景生成方法。我们首先训练 3D 潜在扩散模型来生成 3D 高斯，从而能够以相对较低的分辨率渲染图像。为了实现可控合成，可以通过指定 3D 边界框、路线图或文本提示等输入来选择性地调节此 3DGS 生成过程。然后，我们训练 2D 视频扩散模型，以增强基于 3D 高斯渲染图像的外观细节。通过利用粗略 3D 场景作为 2D 视频扩散的指导，ScenDi 根据输入条件生成所需的场景，并成功遵循准确的摄像机轨迹。在两个具有挑战性的现实世界数据集 Waymo 和 KITTI-360 上进行的实验证明了我们方法的有效性。|[2601.15221](http://arxiv.org/abs/2601.15221)|null|\n",
        "2601.14674": "|**2026-01-21**|**LaVR: Scene Latent Conditioned Generative Video Trajectory Re-Rendering using Large 4D Reconstruction Models**|给定单目视频，视频重新渲染的目标是从新颖的摄像机轨迹生成场景视图。现有方法面临两个不同的挑战。无几何条件的模型缺乏空间意识，导致视点变化时的漂移和变形。另一方面，几何条件模型依赖于估计深度和显式重建，这使得它们容易受到深度误差和校准误差的影响。   我们建议通过使用嵌入大型 4D 重建模型潜在空间中的隐式几何知识来调节视频生成过程来解决这些挑战。这些潜伏捕获连续空间中的场景结构，无需显式重建。因此，它们提供了一种灵活的表示，允许在更有效地正则化误差之前进行预训练扩散。通过联合调节这些潜在的和源相机的姿势，我们证明我们的模型在视频重新渲染任务上取得了最先进的结果。项目网页为 https://lavr-4d-scene-rerender.github.io/|[2601.14674](http://arxiv.org/abs/2601.14674)|null|\n",
        "2601.15284": "|**2026-01-21**|**Walk through Paintings: Egocentric World Models from Internet Priors**|如果视频生成模型不仅能够想象一个合理的未来，而且能够想象出正确的未来，准确地反映世界如何随着每一个动作而变化，结果会怎样呢？我们通过提出自我中心世界模型（EgoWM）来解决这个问题，这是一种简单的、与架构无关的方法，可以将任何预训练的视频扩散模型转换为动作条件的世界模型，从而实现可控的未来预测。我们不是从头开始训练，而是重新利用互联网规模视频模型的丰富世界先验，并通过轻量级调节层注入运动命令。这使得模型能够忠实地遵循行为，同时保持现实性和强泛化性。我们的方法可以自然地跨实施例和动作空间扩展，从 3-DoF 移动机器人到 25-DoF 类人机器人，其中预测以自我为中心的关节角度驱动的动力学更具挑战性。该模型为导航和操作任务提供连贯的推出，只需要适度的微调。为了独立于视觉外观来评估物理正确性，我们引入了结构一致性评分（SCS），它衡量稳定的场景元素是否与所提供的动作一致地演变。与之前最先进的导航世界模型相比，EgoWM 将 SCS 提高了 80%，同时将推理延迟降低了六倍，并对不可见的环境（包括绘画内的导航）进行了强大的泛化。|[2601.15284](http://arxiv.org/abs/2601.15284)|null|\n",
        "2601.15282": "|**2026-01-21**|**Rethinking Video Generation Model for the Embodied World**|视频生成模型具有显着先进的体现智能，为生成捕获物理世界中的感知、推理和行动的各种机器人数据释放了新的可能性。然而，合成准确反映现实世界机器人交互的高质量视频仍然具有挑战性，并且缺乏标准化基准限制了公平比较和进步。为了解决这一差距，我们引入了一个全面的机器人基准测试 RBench，旨在评估跨五个任务域和四个不同实施例的面向机器人的视频生成。它通过可重复的子指标评估任务级别的正确性和视觉保真度，包括结构一致性、物理合理性和动作完整性。对 25 个代表性模型的评估凸显了在生成物理真实机器人行为方面的重大缺陷。此外，该基准与人类评估的 Spearman 相关系数达到 0.96，验证了其有效性。虽然 RBench 提供了识别这些缺陷的必要视角，但实现物理真实感需要超越评估，以解决高质量训练数据的严重短缺问题。在这些见解的驱动下，我们引入了一个完善的四阶段数据管道，从而产生了 RoVid-X，这是最大的视频生成开源机器人数据集，包含 400 万个带注释的视频剪辑，涵盖数千个任务，并丰富了全面的物理属性注释。总的来说，这个评估和数据的协同生态系统为视频模型的严格评估和可扩展训练奠定了坚实的基础，加速了嵌入式人工智能向通用智能的发展。|[2601.15282](http://arxiv.org/abs/2601.15282)|null|\n",
        "2601.15281": "|**2026-01-21**|**StableWorld: Towards Stable and Consistent Long Interactive Video Generation**|在本文中，我们探讨了交互式视频生成中被忽视的稳定性和时间一致性的挑战，它通过相机移动和文本提示等交互行为合成动态且可控的视频世界。尽管世界建模取得了显着进展，但当前的方法仍然存在严重的不稳定性和时间退化，常常导致长视域交互过程中的空间漂移和场景崩溃。为了更好地理解这个问题，我们首先调查了不稳定的根本原因，并确定错误累积的主要来源源于同一场景，其中生成的帧逐渐偏离初始干净状态并将错误传播到后续帧。基于这一观察，我们提出了一种简单而有效的方法，\\textbf{StableWorld}，一种动态帧驱逐机制。通过不断过滤掉退化的帧，同时保留几何一致的帧，StableWorld 有效地从源头防止累积漂移，从而使交互生成更加稳定和时间一致性。在多个交互式视频模型（例如 Matrix-Game、Open-Oasis 和 Hunyuan-GameCraft）上取得的有希望的结果表明，StableWorld 是模型无关的，可以应用于不同的交互式视频生成框架，以显着提高稳定性、时间一致性和跨不同交互场景的泛化性。|[2601.15281](http://arxiv.org/abs/2601.15281)|null|\n",
        "2601.16214": "|**2026-01-22**|**CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback**|摄像机控制的视频扩散模型的最新进展显着改善了摄像机对准。然而，相机的可控性仍然有限。在这项工作中，我们以奖励反馈学习为基础，旨在进一步提高相机的可控性。然而，直接借用现有的 ReFL 方法面临着一些挑战。首先，当前的奖励模型缺乏评估摄像机对齐的能力。其次，将潜在视频解码为 RGB 视频以进行奖励计算会带来大量的计算开销。第三，3D 几何信息在视频解码过程中通常被忽略。为了解决这些限制，我们引入了一种高效的相机感知 3D 解码器，可将视频潜在解码为 3D 表示以进行奖励量化。具体来说，视频潜伏与相机姿势一起被解码为 3D 高斯。在这个过程中，相机位姿不仅作为输入，还作为投影参数。视频潜伏和相机姿势之间的不对准将导致 3D 结构中的几何扭曲，从而导致渲染模糊。基于这个属性，我们明确优化了渲染的新颖视图和真实视图之间的像素级一致性作为奖励。为了适应随机性，我们进一步引入了一个可见性项，它有选择地仅监督通过几何扭曲导出的确定性区域。在 RealEstate10K 和 WorldScore 基准上进行的大量实验证明了我们提出的方法的有效性。项目页面：\\href{https://a-bigbao.github.io/CamPilot/}{CamPilot 页面}。|[2601.16214](http://arxiv.org/abs/2601.16214)|null|\n",
        "2601.16210": "|**2026-01-22**|**PyraTok: Language-Aligned Pyramidal Tokenizer for Video Understanding and Generation**|离散视频 VAE 是现代文本到视频生成和视频理解系统的基础，但现有的分词器通常在单一尺度上学习视觉码本，词汇量有限，语言监督浅层，导致跨模态对齐和零样本传输较差。我们引入了 PyraTok，一种与语言对齐的金字塔分词器，可以跨多个时空分辨率学习语义结构的离散潜在变量。 PyraTok 建立在预训练视频 VAE 和新颖的语言对齐金字塔量化 (LaPQ) 模块的基础上，该模块使用共享的大型二进制码本在多个深度上离散化编码器特征，从而产生紧凑但富有表现力的视频标记序列。为了将视觉标记与语言紧密结合，PyraTok 联合优化了标记层次结构上的多尺度文本引导量化和全局自回归目标。在十个基准测试中，PyraTok 提供了最先进的 (SOTA) 视频重建，持续提高文本到视频的质量，并在视频分割、时间动作定位和视频理解方面设置了新的 SOTA 零镜头性能，稳健地扩展到高达 4K/8K 分辨率。|[2601.16210](http://arxiv.org/abs/2601.16210)|null|\n",
        "2601.16163": "|**2026-01-22**|**Cosmos Policy: Fine-Tuning Video Models for Visuomotor Control and Planning**|最近的视频生成模型展示了捕捉复杂的物理交互和场景随时间演变的卓越能力。为了利用其时空先验，机器人研究采用了用于策略学习的视频模型，但由于需要多个阶段的后训练和新的架构组件来生成动作，从而引入了复杂性。在这项工作中，我们介绍了 Cosmos Policy，这是一种简单的方法，通过对目标平台上收集的机器人演示数据进行单阶段的后训练，将大型预训练视频模型 (Cosmos-Predict2) 调整为有效的机器人策略，无需进行架构修改。 Cosmos Policy 学习在视频模型的潜在扩散过程中直接生成编码为潜在帧的机器人动作，利用模型的预训练先验和核心学习算法来捕获复杂的动作分布。此外，Cosmos 策略会生成未来的状态图像和值（预期累积奖励），这些图像和值类似地被编码为潜在框架，从而能够以更高的成功可能性对行动轨迹进行测试时规划。在我们的评估中，Cosmos Policy 在 LIBERO 和 RoboCasa 模拟基准上实现了最先进的性能（平均成功率分别为 98.5% 和 67.1%），并且在具有挑战性的现实世界双手操作任务中获得了最高的平均得分，优于从头开始训练的强大扩散策略、基于视频模型的策略以及在相同机器人演示上微调的最先进的视觉语言动作模型。此外，根据政策推出数据，Cosmos Policy 可以从经验中学习，以完善其世界模型和价值函数，并利用基于模型的规划在具有挑战性的任务中实现更高的成功率。我们在 https://research.nvidia.com/labs/dir/cosmos-policy/ 发布代码、模型和训练数据|[2601.16163](http://arxiv.org/abs/2601.16163)|null|\n",
        "2601.16007": "|**2026-01-22**|**PhysicsMind: Sim and Real Mechanics Benchmarking for Physical Reasoning and Prediction in Foundational VLMs and World Models**|现代基础多模态大语言模型 (MLLM) 和视频世界模型在数学、常识和视觉推理方面取得了显着进步，但它们对底层物理的掌握仍然有待探索。试图衡量这个问题的现有基准依赖于合成的视觉问答模板或关注感知视频质量，这与衡量视频遵守物理定律的程度无关。为了解决这种碎片化问题，我们引入了PhysicsMind，这是一个具有真实和模拟环境的统一基准，可根据三个规范原理（质心、杠杆平衡和牛顿第一定律）评估规律一致的推理和生成。 PhysicsMind 包括两个主要任务：i）VQA 任务，测试模型是否可以推理并确定图像或短视频中的物理量和值；ii）视频生成（VG）任务，评估预测的运动轨迹是否遵循与地面真实情况相同的质心、扭矩和惯性约束。在PhysicsMind 上评估了一系列最新的模型和视频生成模型，发现它们依赖于外观启发法，同时经常违反基本力学。这些差距表明，当前的扩展和训练仍然不足以实现强大的物理理解，这凸显了PhysicsMind作为物理感知多模态模型的重点测试平台。我们的数据将在接受后发布。|[2601.16007](http://arxiv.org/abs/2601.16007)|null|\n",
        "2601.15533": "|**2026-01-21**|**From Generative Engines to Actionable Simulators: The Imperative of Physical Grounding in World Models**|世界模型是一种人工智能系统，它模拟环境在行动中如何演变，从而能够通过想象的未来而不是反应性感知来进行规划。然而，当前的世界模型存在视觉混淆：错误地假设高保真视频生成意味着对物理和因果动力学的理解。我们表明，虽然现代模型擅长预测像素，但它们经常违反不变约束，在干预下失败，并在安全关键决策中崩溃。这项调查认为，视觉现实主义是世界理解的不可靠代表。相反，有效的世界模型必须编码因果结构，尊重特定领域的约束，并在长期范围内保持稳定。我们建议将世界模型重新构建为可操作的模拟器而不是视觉引擎，强调结构化 4D 界面、约束感知动力学和闭环评估。将医学决策作为认知压力测试，其中试错是不可能的，错误是不可逆转的，我们证明世界模型的价值不是取决于其推出的现实程度，而是取决于其支持反事实推理、干预计划和强大的长期远见的能力。|[2601.15533](http://arxiv.org/abs/2601.15533)|null|\n",
        "2601.16982": "|**2026-01-23**|**AnyView: Synthesizing Any Novel View in Dynamic Scenes**|现代生成视频模型擅长产生令人信服的高质量输出，但难以在高度动态的现实环境中保持多视图和时空一致性。在这项工作中，我们介绍了 \\textbf{AnyView}，一种基于扩散的视频生成框架，用于具有最小归纳偏差或几何假设的 \\emph{动态视图合成}。我们利用具有不同监督级别的多个数据源，包括单目（2D）、多视图静态（3D）和多视图动态（4D）数据集，来训练通用时空隐式表示，能够从任意相机位置和轨迹生成零样本新颖视频。我们在标准基准上评估 AnyView，显示出与当前最先进水平具有竞争力的结果，并提出 \\textbf{AnyViewBench}，这是一个具有挑战性的新基准，专为各种现实场景中的 \\emph{extreme} 动态视图合成而定制。在这种更戏剧性的设置中，我们发现大多数基线的性能都会急剧下降，因为它们需要视点之间存在显着重叠，而 AnyView 在从 \\emph{any} 视点提示时保持了生成真实、合理且时空一致的视频的能力。结果、数据、代码和模型可以在以下位置查看：https://tri-ml.github.io/AnyView/|[2601.16982](http://arxiv.org/abs/2601.16982)|null|\n",
        "2601.16933": "|**2026-01-23**|**Reward-Forcing: Autoregressive Video Generation with Reward Feedback**|虽然视频生成方面的大多数先前工作依赖于双向架构，但最近的努力试图将这些模型适应自回归变体以支持近实时生成。然而，这种适应通常严重依赖于教师模型，这可能会限制性能，特别是在没有强大的自回归教师的情况下，导致输出质量通常落后于双向模型。在本文中，我们探索了一种使用奖励信号来指导生成过程的替代方法，从而实现更高效和可扩展的自回归生成。通过使用奖励信号来指导模型，我们的方法简化了训练，同时保持了高视觉保真度和时间一致性。通过对标准基准的广泛实验，我们发现我们的方法的性能与现有的自回归模型相当，并且在某些情况下，通过避免教师架构施加的约束，超越了类似大小的双向模型。例如，在 VBench 上，我们的方法获得了 84.92 的总分，与得分 84.31 但需要显着异质蒸馏的最先进的自回归方法非常接近。|[2601.16933](http://arxiv.org/abs/2601.16933)|null|\n",
        "2601.16914": "|**2026-01-23**|**LoL: Longer than Longer, Scaling Video Generation to Hour**|最近对长格式视频生成的研究已经从双向模型转向自回归模型，但这些方法通常会遭受错误积累和长期一致性丧失的困扰。虽然引入注意力接收器帧来减轻这种性能下降，但它们通常会引发一种严重的故障模式，我们称之为接收器崩溃：生成的内容反复恢复到接收器帧，导致突然的场景重置和循环运动模式。我们的分析表明，汇崩溃源于旋转位置嵌入（RoPE）的周期结构与当前生成模型中普遍存在的多头注意力机制之间的固有冲突。为了解决这个问题，我们提出了一种轻量级、免训练的方法，通过引入多头 RoPE 抖动来有效抑制这种行为，打破头间注意力均匀化并减轻长期崩溃。大量的实验表明，我们的方法成功地缓解了汇崩溃，同时保持了发电质量。据我们所知，这项工作首次实现了实时、流媒体和无限长度视频生成的演示，并且质量几乎没有下降。为了说明这种鲁棒性，我们生成了长达 12 小时的连续视频，据我们所知，这是流媒体视频生成中公开展示的最长的结果之一。|[2601.16914](http://arxiv.org/abs/2601.16914)|null|\n",
        "2601.16515": "|**2026-01-23**|**SALAD: Achieve High-Sparsity Attention via Efficient Linear Attention Tuning for Video Diffusion Transformer**|Diffusion Transformers 最近在视频生成方面表现出了卓越的性能。然而，由于完全注意力的二次复杂度，长输入序列会导致高计算延迟。人们提出了各种稀疏注意力机制。免训练稀疏注意力受到有限稀疏性的限制，因此提供了适度的加速，而基于训练的方法可以达到更高的稀疏性，但需要大量数据和计算来进行训练。在这项工作中，我们提出了 SALAD，引入了与稀疏注意力并行的轻量级线性注意力分支。通过结合输入相关的门控机制来精细平衡两个分支，我们的方法实现了 90% 的稀疏性和 1.72 倍的推理加速，同时保持与完全注意力基线相当的生成质量。此外，我们的微调过程非常高效，仅需要 2,000 个视频样本和 1,600 个训练步骤，批量大小为 8。|[2601.16515](http://arxiv.org/abs/2601.16515)|null|\n",
        "2601.16296": "|**2026-01-22**|**Memory-V2V: Augmenting Video-to-Video Diffusion Models with Memory**|最近的基础视频到视频扩散模型在通过修改外观、运动或相机运动来编辑用户提供的视频方面取得了令人印象深刻的结果。然而，现实世界的视频编辑通常是一个迭代过程，用户通过多轮交互来完善结果。在这种多轮设置中，当前的视频编辑器很难在顺序编辑之间保持交叉一致性。在这项工作中，我们首次解决了多轮视频编辑中的交叉一致性问题，并引入了 Memory-V2V，这是一个简单而有效的框架，可以通过显式内存增强现有的视频到视频模型。给定先前编辑的视频的外部缓存，Memory-V2V 采用准确的检索和动态标记化策略来根据先前的结果调整当前的编辑步骤。为了进一步减少冗余和计算开销，我们在 DiT 主干中提出了一个可学习的令牌压缩器，它可以压缩冗余的条件令牌，同时保留基本的视觉线索，从而实现 30% 的整体加速。我们在具有挑战性的任务上验证 Memory-V2V，包括视频小说视图合成和文本调节的长视频编辑。大量实验表明，Memory-V2V 生成的视频在最小计算开销的情况下显着提高了交叉一致性，同时在最先进的基线上保持甚至提高了特定任务的性能。项目页面：https://dohunlee1.github.io/MemoryV2V|[2601.16296](http://arxiv.org/abs/2601.16296)|null|\n",
        "2601.16272": "|**2026-01-22**|**GR3EN: Generative Relighting for 3D Environments**|我们提出了一种重新照亮大型房间规模环境 3D 重建的方法。现有的 3D 场景重新照明解决方案通常需要解决不确定或病态的逆渲染问题，因此无法在复杂的现实场景上产生高质量的结果。尽管最近在使用生成图像和视频扩散模型进行重新照明方面取得了很大的进展，但这些技术要么仅限于 2D 图像和视频重新照明，要么仅限于单个对象的 3D 重新照明。我们的方法通过将视频到视频重新照明扩散模型的输出提炼为 3D 重建，实现房间规模场景的可控 3D 重新照明。这回避了解决困难的逆渲染问题的需要，并产生了一个灵活的系统，可以重新照亮复杂现实世界场景的 3D 重建。我们在合成数据集和真实数据集上验证了我们的方法，以表明它可以在新的照明条件下忠实地渲染场景的新颖视图。|[2601.16272](http://arxiv.org/abs/2601.16272)|null|\n"
    },
    "3D": {
        "2601.14253": "|**2026-01-20**|**Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis**|我们提出了 Motion 3-to-4，这是一个前馈框架，用于从单个单目视频和可选的 3D 参考网格合成高质量的 4D 动态对象。虽然最近的进展显着改进了 2D、视频和 3D 内容生成，但由于训练数据有限以及从单目角度恢复几何和运动的固有模糊性，4D 合成仍然很困难。 Motion 3-to-4 通过将 4D 合成分解为静态 3D 形状生成和运动重建来解决这些挑战。使用规范参考网格，我们的模型学习紧凑的运动潜在表示并预测每帧顶点轨迹以恢复完整的、时间相干的几何形状。可扩展的逐帧变换器进一步实现了对不同序列长度的鲁棒性。对标准基准和具有精确地面实况几何的新数据集的评估表明，与之前的工作相比，Motion 3-to-4 提供了卓越的保真度和空间一致性。项目页面位于 https://motion3-to-4.github.io/。|[2601.14253](http://arxiv.org/abs/2601.14253)|null|\n",
        "2601.14208": "|**2026-01-20**|**Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting**|检查二手车的底盘是一项劳动密集型任务，需要检查人员蹲下或爬到每辆车下方进行彻底检查。此外，网上买家很少看到底盘照片。我们提出了一个端到端的管道，它利用三摄像头装置来捕获车辆行驶在起落架上时的起落架视频，并生成起落架的交互式 3D 模型。 3D 模型使检查员和客户能够旋转、缩放和剖切起落架，使他们能够在几秒钟内检测到生锈、泄漏或冲击损坏，从而提高工作场所安全和买家信心。我们的主要贡献是一个装备感知的运动结构 (SfM) 管道，专门设计用于克服广角镜头畸变和低视差场景的挑战。我们的方法通过集成精确的相机校准、同步视频流和相机装备的强大几何先验，克服了广角镜头畸变和低视差场景的挑战。我们使用带有学习组件的约束匹配策略、DISK 特征提取器和基于注意力的 LightGlue 匹配器来生成高质量的稀疏点云，而这通常是标准 SfM 管道无法实现的。这些点云为高斯喷射过程提供种子，以生成实时渲染的逼真的起落架模型。我们的实验和消融研究表明，我们的设计选择对于实现最先进的质量至关重要。|[2601.14208](http://arxiv.org/abs/2601.14208)|null|\n",
        "2601.14207": "|**2026-01-20**|**Copy-Trasform-Paste: Zero-Shot Object-Object Alignment Guided by Vision-Language and Geometric Constraints**|我们研究两个给定网格的零镜头 3D 对齐，使用描述其空间关系的文本提示——这是内容创建和场景组装的基本功能。早期的方法主要依赖于几何对齐程序，而最近的工作利用预训练的二维扩散模型来建模语言条件的对象-对象空间关系。相比之下，我们在测试时直接优化相对姿态，通过可微分渲染器使用 CLIP 驱动的梯度更新平移、旋转和各向同性尺度，而无需训练新模型。我们的框架通过几何感知目标增强了语言监督：软迭代最近点（ICP）术语的变体鼓励表面附着和渗透损失以阻止相互渗透。分阶段的时间表随着时间的推移加强了接触约束，而摄像机控制则将优化集中在交互区域。为了进行评估，我们策划了一个包含不同类别和关系的基准，并与基线进行比较。我们的方法优于所有替代方法，产生语义上忠实且物理上合理的对齐。|[2601.14207](http://arxiv.org/abs/2601.14207)|null|\n",
        "2601.14183": "|**2026-01-20**|**Gradient-based optimization of exact stochastic kinetic models**|随机动力学模型描述了生物学、化学和物理学领域的系统，其中离散事件和小群体使得确定性近似不充分。这些系统中的参数推断和逆向设计需要对随机模拟算法生成的轨迹进行优化，但所涉及的离散反应事件本质上是不可微分的。我们提出了一种基于直通 Gumbel-Softmax 估计的方法，该方法在前向传递中保持精确的随机模拟，同时通过仅在后向传递中应用的连续松弛来近似梯度。我们展示了随机基因表达中参数推断的稳健性能，从矩统计和跨不同且具有挑战性的参数范围的完整稳态分布准确地恢复了电报启动子模型的动力学速率。我们进一步证明了该方法对随机热力学逆设计问题的适用性，描述了非平衡电流和熵产生之间的帕累托最优权衡。通过精确的随机模拟有效区分的能力为连续时间马尔可夫动力学控制的许多领域的系统推理和理性设计奠定了基础。|[2601.14183](http://arxiv.org/abs/2601.14183)|null|\n",
        "2601.14173": "|**2026-01-20**|**Penalizing Localized Dirichlet Energies in Low Rank Tensor Products**|我们研究用于回归任务的低秩张量积 B 样条 (TPBS) 模型，并研究狄利克雷能量作为平滑度的度量。我们证明 TPBS 模型承认狄利克雷能量的封闭式表达式，并揭示了使用指数级小的狄利克雷能量可以实现完美插值的场景。这使得基于狄利克雷能量的全局正则化无效。为了解决这个限制，我们提出了一种基于在以训练点为中心的小超立方体上定义的局部狄利克雷能量的新颖正则化策略。利用预训练的 TPBS 模型，我们还引入了两个估计器来从不完整的样本中进行推断。与神经网络的比较实验表明，对于大多数数据集，TPBS 模型在过拟合情况下优于神经网络，并且在其他方​​面保持有竞争力的性能。总体而言，TPBS 模型对过度拟合表现出更强的鲁棒性，并且始终受益于正则化，而神经网络对过度拟合更敏感，并且在利用正则化方面效果较差。|[2601.14173](http://arxiv.org/abs/2601.14173)|null|\n",
        "2601.14161": "|**2026-01-20**|**One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion**|我们提出了一种从稀疏图像进行高保真新颖视图合成 (NVS) 的新颖框架，解决了最近基于 Vision Transformer (ViT) 主干的前馈 3D 高斯分布 (3DGS) 方法的关键限制。虽然基于 ViT 的管道提供了强大的几何先验，但由于计算成本，它们通常受到低分辨率输入的限制。此外，现有的生成增强方法往往与 3D 无关，导致视图之间的结构不一致，尤其是在看不见的区域。为了克服这些挑战，我们设计了一个双域细节感知模块，它能够处理高分辨率图像而不受ViT主干的限制，并赋予高斯额外的功能来存储高频细节。我们开发了一个特征引导的扩散网络，它可以在恢复过程中保留高频细节。我们引入了统一的训练策略，可以联合优化基于 ViT 的几何主干和基于扩散的细化模块。实验表明，我们的方法可以在多个数据集上保持卓越的生成质量。|[2601.14161](http://arxiv.org/abs/2601.14161)|null|\n",
        "2601.14148": "|**2026-01-20**|**The Quest for Reliable AI Accelerators: Cross-Layer Evaluation and Design Optimization**|随着CMOS技术向纳米尺度发展，老化效应和工艺变化变得越来越明显，给AI加速器带来了巨大的可靠性挑战。传统的基于保护带的设计方法依赖于悲观的时序余量，显着牺牲了性能和计算效率，使其不足以满足高性能人工智能计算需求。当前的可靠性感知人工智能加速器设计面临两个核心挑战：（1）缺乏系统的跨层分析工具来捕获跨器件、电路、架构和应用层的耦合可靠性影响； (2)传统可靠性优化和计算效率之间的基本权衡。为了应对这些挑战，本文系统地提出了一系列可靠性感知加速器设计，包括（1）老化和变化感知动态时序分析器，（2）使用关键输入模式减少的加速器数据流优化，以及（3）大型语言模型（LLM）的弹性表征和新颖架构设计。这些协同优化方法通过紧密结合跨层可靠性建模和AI工作负载特征，有效实现可靠、高效的AI加速。|[2601.14148](http://arxiv.org/abs/2601.14148)|null|\n",
        "2601.14079": "|**2026-01-20**|**VENI: Variational Encoder for Natural Illumination**|逆渲染是一个不适定问题，但是像照明先验这样的先验可以简化它。现有的工作要么忽视照明环境的球形和旋转等变性质，要么不提供表现良好的潜在空间。我们提出了一种旋转等变变分自动编码器，可以在不依赖 2D 投影的情况下对球体上的自然照明进行建模。为了保持环境图的 SO(2) 等变性，我们使用新颖的矢量神经元视觉变换器 (VN-ViT) 作为编码器，使用旋转等变条件神经场作为解码器。在编码器中，我们使用新颖的 SO(2) 等变全连接层（矢量神经元的扩展）将等方差从 SO(3) 减少到 SO(2)。我们证明，当我们的 SO(2) 等变模型中使用时，我们的 SO(2) 等变全连接层的性能优于标准矢量神经元。与以前的方法相比，我们的变分自动编码器可以在潜在空间中实现更平滑的插值，并提供表现更良好的潜在空间。|[2601.14079](http://arxiv.org/abs/2601.14079)|null|\n",
        "2601.14055": "|**2026-01-20**|**Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI**|用于 3D 医学成像的现代视觉主干通常通过参数密集的编码器-解码器结构处理密集的体素网格，这种设计将其参数的很大一部分分配给空间重建而不是特征学习。我们的方法引入了 SVGFormer，这是一个建立在内容感知分组阶段之上的无解码器管道，该阶段将体积划分为超体素的语义图。其分层编码器通过将补丁级 Transformer 与超体素级图注意网络相结合来学习丰富的节点表示，联合建模细粒度的区域内特征和更广泛的区域间依赖性。该设计将所有可学习能力集中在特征编码上，并提供从补丁到区域级别的固有的双尺度可解释性。为了验证该框架的灵活性，我们在 BraTS 数据集上训练了两种专门的模型：一种用于节点级分类，一种用于肿瘤比例回归。两个模型都取得了强劲的性能，分类模型的 F1 分数为 0.875，回归模型的 MAE 为 0.028，证实了编码器学习判别性和局部性特征的能力。我们的结果表明，基于图形、仅编码器的范式为 3D 医学图像表示提供了准确且本质上可解释的替代方案。|[2601.14055](http://arxiv.org/abs/2601.14055)|null|\n",
        "2601.14033": "|**2026-01-20**|**PAC-Private Responses with Adversarial Composition**|现代机器学习模型越来越多地部署在 API 后面。这使得标准权重私有化方法（例如 DP-SGD）产生不必要的噪音，以牺牲效用为代价。虽然模型权重在训练数据集中可能会有很大差异，但模型对特定输入的响应维度要低得多且更稳定。这促使直接对模型输出执行隐私保证。   我们在 PAC 隐私下解决这个问题，它通过控制互信息 (MI) 为任意黑盒函数提供基于实例的隐私保证。重要的是，PAC 隐私明确奖励输出稳定性和降低噪音水平。然而，一个核心挑战仍然存在：响应隐私需要组合大量由不可信用户发出的自适应选择的、潜在对抗性的查询，而现有的 PAC 隐私组合结果是不够的。我们引入了一种新算法，通过自适应噪声校准实现对抗性组合，并证明互信息保证在自适应和对抗性查询下线性累积。   表格、视觉和 NLP 任务的实验表明，我们的方法以极小的每次查询隐私预算实现了高实用性。在 CIFAR-10 上，我们实现了 87.79% 的准确率，每步 MI 预算为 2^{-32}$。这使得能够服务一百万个查询，同时可证明将成员推理攻击 (MIA) 成功率限制在 51.08%——与 $(0.04, 10^{-5})$-DP 的保证相同。此外，我们表明私人响应可用于标记公共数据，以提炼可发布的隐私保护模型；使用 ImageNet 子集作为公共数据集，我们的模型从 210,000 个响应中提取，在 CIFAR-10 上实现了 91.86% 的准确率，MIA 成功上限为 50.49%，与 $(0.02,10^{-5})$-DP 相当。|[2601.14033](http://arxiv.org/abs/2601.14033)|null|\n",
        "2601.15275": "|**2026-01-21**|**RayRoPE: Projective Ray Positional Encoding for Multi-view Attention**|我们研究了多视图变换器的位置编码，该变换器处理来自一组姿势输入图像的标记，并寻求一种独特地编码补丁的机制，允许具有多频率相似性的 SE(3) 不变注意，并且可以适应底层场景的几何形状。我们发现先前的（绝对或相对）多视图注意力编码方案不能满足上述要求，并提出 RayRoPE 来解决这一差距。 RayRoPE 基于相关光线表示补丁位置，但利用沿光线的预测点而不是几何感知编码的方向。为了实现 SE(3) 不变性，RayRoPE 计算查询帧投影坐标以计算多频率相似性。最后，由于沿着射线的“预测”3D 点可能不精确，RayRoPE 提出了一种在不确定性下分析计算预期位置编码的机制。我们在新颖视图合成和立体深度估计任务上验证了 RayRoPE，并表明它比替代位置编码方案持续改进（例如，CO3D 中的 LPIPS 相对改进了 15%）。我们还表明，RayRoPE 可以无缝合并 RGB-D 输入，从而比无法对该信息进行位置编码的替代方案获得更大的收益。|[2601.15275](http://arxiv.org/abs/2601.15275)|null|\n",
        "2601.15251": "|**2026-01-21**|**The Effect of Scripts and Formats on LLM Numeracy**|大型语言模型 (LLM) 在基本算术方面取得了令人印象深刻的熟练程度，在标准数值任务上的表现可与人类水平相媲美。然而，当数值表达式偏离训练语料库中的普遍惯例时，很少有人关注这些模型的表现。在这项工作中，我们研究了各种数字脚本和格式的数字推理。我们表明，当数字输入以代表性不足的脚本或格式呈现时，LLM 的准确性会大幅下降，尽管潜在的数学推理是相同的。我们进一步证明，有针对性的提示策略，例如几次提示和明确的数字映射，可以大大缩小这一差距。我们的研究结果强调了多语言数字推理中被忽视的挑战，并为与法学硕士合作提供了可行的见解，以跨不同的数字脚本和格式样式可靠地解释、操作和生成数字。|[2601.15251](http://arxiv.org/abs/2601.15251)|null|\n",
        "2601.15250": "|**2026-01-21**|**FlowSSC: Universal Generative Monocular Semantic Scene Completion via One-Step Latent Diffusion**|由于从单个视图推断被遮挡的 3D 几何图形固有的模糊性，单目 RGB 图像的语义场景完成 (SSC) 是一项基本但具有挑战性的任务。虽然前馈方法取得了进展，但它们常常难以在遮挡区域中生成合理的细节并保留对象的基本空间关系。这种针对整个 3D 空间的准确生成推理能力在现实应用中至关重要。在本文中，我们提出了 FlowSSC，这是第一个直接应用于单目语义场景完成的生成框架。 FlowSSC将SSC任务视为条件生成问题，并且可以与现有的前馈SSC方法无缝集成，以显着提高其性能。为了在不影响质量的情况下实现实时推理，我们引入了在紧凑的三平面潜在空间中运行的快捷流匹配。与需要数百个步骤的标准扩散模型不同，我们的方法利用快捷机制在一步中实现高保真生成，从而能够在自治系统中实际部署。 SemanticKITTI 上的大量实验表明 FlowSSC 实现了最先进的性能，显着优于现有基准。|[2601.15250](http://arxiv.org/abs/2601.15250)|null|\n",
        "2601.15234": "|**2026-01-21**|**Cosmic strings, domain walls and environment-dependent clustering**|最近的宇宙学数据有利于幻影穿越暗能量，激发具有非最小耦合的模型，从而在结构形成中引入第五种力。将这些模型与本地测试相协调通常需要严格的筛选，从而导致依赖于环境的聚类。我们通过非最小耦合标量场驱动的后期结构诱导相变来研究这种效应。为此，我们引入了 Norns，一种完全相对论的宇宙粒子网格代码，它自洽地演化出一个复杂的标量场——对称子的泛化，产生全局 U(1) 弦而不是畴壁。通过模拟，我们比较了弦和墙形成模型，量化了对物质功率谱、晕质量函数和缺陷动力学的影响。强烈的环境依赖性效应可能会在低密度区域产生与 LCDM 的显着偏差，同时保持总体功率谱变化适度（k~0.3-0.5 h Mpc^-1 时约 4-15%，z > 0.2 的亚百分比）。我们发现，有吸引力的第五力可以局部抑制空隙中的结构生长，同时通过驱动空隙的流出来增强周围过密区域的结构生长。这些效应在物质密度概率密度函数和标记的晕功率谱中留下了独特的特征，这些特征很可能在低红移数据中被检测到。|[2601.15234](http://arxiv.org/abs/2601.15234)|null|\n",
        "2601.15221": "|**2026-01-21**|**ScenDi: 3D-to-2D Scene Diffusion Cascades for Urban Generation**|使用扩散模型生成 3D 对象的最新进展取得了显着的成功，但生成逼真的 3D 城市场景仍然具有挑战性。仅依赖 3D 扩散模型的现有方法往往会导致外观细节的退化，而仅使用 2D 扩散模型的方法通常会损害相机的可控性。为了克服这一限制，我们提出了 ScenDi，一种集成了 3D 和 2D 扩散模型的城市场景生成方法。我们首先训练 3D 潜在扩散模型来生成 3D 高斯，从而能够以相对较低的分辨率渲染图像。为了实现可控合成，可以通过指定 3D 边界框、路线图或文本提示等输入来选择性地调节此 3DGS 生成过程。然后，我们训练 2D 视频扩散模型，以增强基于 3D 高斯渲染图像的外观细节。通过利用粗略 3D 场景作为 2D 视频扩散的指导，ScenDi 根据输入条件生成所需的场景，并成功遵循准确的摄像机轨迹。在两个具有挑战性的现实世界数据集 Waymo 和 KITTI-360 上进行的实验证明了我们方法的有效性。|[2601.15221](http://arxiv.org/abs/2601.15221)|null|\n",
        "2601.15209": "|**2026-01-21**|**Deaf and Hard of Hearing Access to Intelligent Personal Assistants: Comparison of Voice-Based Options with an LLM-Powered Touch Interface**|我们调查了耳聋和听力障碍 (DHH) 人士的智能个人助理 (IPA) 的可及性，他们可以在日常交流中使用语音。 IPA 无法理解包括聋人语音在内的多种口音，这使得非手语和会说话的 DHH 个人基本上无法理解它们。使用 Echo Show，我们比较了通过英语口语进行自然语言输入的可用性；在混合方法研究中，使用 Alexa 的自动语音识别和绿野仙踪设置，由训练有素的辅导员根据大语言模型 (LLM) 辅助的触摸界面重述命令。触摸方法是通过法学硕士支持的“任务提示器”进行导航，该提示器集成了用户的历史记录和智能环境，以建议适合上下文的命令。定量结果显示，英语口语条件与法学硕士辅助触摸条件之间没有显着差异。定性结果显示对每种方法可用性的看法存在差异。最终，IPA 需要能够本地识别强大的聋人口音语音。|[2601.15209](http://arxiv.org/abs/2601.15209)|null|\n",
        "2601.15196": "|**2026-01-21**|**TTCBF: A Truncated Taylor Control Barrier Function for High-Order Safety Constraints**|控制屏障函数 (CBF) 通过使规定的安全集前向不变性来增强安全性。然而，标准 CBF 仅限于相对度数为 1 的安全约束，而高阶 CBF (HOCBF) 方法则以引入一系列辅助函数和多个 K 类函数为代价来解决更高的相对度数，这些函数的调整随相对度数进行调整。在本文中，我们引入了一种截断泰勒控制屏障函数（TTCBF），它推广了标准离散时间 CBF 以考虑高阶安全约束，并且只需要一个 K 类函数，与相对度无关。我们还提出了一种自适应变体，自适应 TTCBF (aTTCBF)，它优化 K 类函数的在线增益以提高适应性，同时比现有的自适应 HOCBF 变体需要更少的控制设计参数。相对六度弹簧质量系统和杂乱走廊导航的数值实验验证了上述理论发现。|[2601.15196](http://arxiv.org/abs/2601.15196)|null|\n",
        "2601.15110": "|**2026-01-21**|**Pb4U-GNet: Resolution-Adaptive Garment Simulation via Propagation-before-Update Graph Network**|服装模拟是计算机视觉和图形领域各种应用（从虚拟试穿到数字人体建模）的基础。然而，传统的基于物理的方法在计算上仍然昂贵，阻碍了它们在时间敏感场景中的应用。虽然图神经网络（GNN）提供了有前途的加速，但现有方法表现出较差的跨分辨率泛化能力，表明超出训练分布的更高分辨率网格的性能显着下降。这源于两个关键因素：（1）现有的 GNN 采用固定的消息传递深度，无法使信息聚合适应网格密度变化；（2）在服装模拟中，顶点位移量本质上依赖于分辨率。为了解决这些问题，我们引入了更新前传播图网络（Pb4U-GNet），这是一种分辨率自适应框架，可将消息传播与功能更新解耦。 Pb4U-GNet 包含两个关键机制：（1）动态传播深度控制，根据网格分辨率调整消息传递迭代，以及（2）几何感知更新缩放，根据局部网格特征缩放预测。大量实验表明，即使仅在低分辨率网格上进行训练，Pb4U-GNet 在不同网格分辨率下也表现出很强的通用性，解决了神经服装模拟中的基本挑战。|[2601.15110](http://arxiv.org/abs/2601.15110)|null|\n",
        "2601.15098": "|**2026-01-21**|**Three-dimensional visualization of X-ray micro-CT with large-scale datasets: Efficiency and accuracy for real-time interaction**|随着Micro-CT技术不断完善其对材料微观结构的表征，工业CT超精密检测正在生成越来越大的数据集，需要解决超精密检测过程中缺陷3D表征的准确性和效率之间的权衡问题。本文以独特的视角介绍了使用 Micro-CT 进行准确、高效的 3D 可视化的最新进展，追踪其从医学成像到工业无损检测 (NDT) 的演变。在众多的CT重建和体绘制方法中，本文选择性地回顾和分析了平衡精度和效率的方法，提供全面的分析，以帮助研究人员快速掌握高效、准确的微观特征3D重建方法。通过比较计算机断层扫描原理与微观结构技术的进步，本文探讨了 CT 重建算法从分析方法到深度学习技术的演变，以及体绘制算法、加速和数据缩减方面的改进。此外，它还探索了先进的照明模型，以实现高精度、逼真且高效的体积渲染。此外，本文展望了 CT 重建和体绘制的潜在方向。旨在指导未来研究快速选择高效、精确的方法，开发通过虚拟-物理交互实时在线监测内部材料缺陷的新思路和新方法，将数字孪生模型应用于结构健康监测（SHM）。|[2601.15098](http://arxiv.org/abs/2601.15098)|null|\n",
        "2601.15078": "|**2026-01-21**|**Computable Structuralism: A Categorical Rewrite Calculus of Mythic Variants**|神话和叙事的结构性方法在仔细阅读时很引人注目，但很难在传统、媒体和规模之间进行比较。我们提出了一个正式的框架，将列维-斯特劳斯变换呈现为数学，同时保持叙事分析的可读性。变体、超级英雄连续性和特许经营弧被建模为耦合的两个寄存器状态 $(X,Y)$ 上的类型化重写程序，抽象出日常/社交渠道和符号/合法化渠道。规范公式变成了一致性数据：更新endofunctors之间的自然变换$η:U\\Rightarrow V$，其中$U$就地更新每个寄存器，$V$执行交换+反转。上下文通过操作员的选择内化，将自然性转变为面向语料库的类型检查：失败诊断错误指定的反对或非法运输；成功见证了连贯的结构模型。顺序效应由五值不变量（Key）来概括。我们将该方法应用于 80 个叙述（20 个民间故事、20 个宗教神话、20 个超级英雄、20 个特许经营权），每个叙述都用密钥编码为 $(a,b,x,y)$。 59/80 (74\\%) 明确命名 $y$ 中的规范约束（法律、禁忌、合同、预言），支持双寄存器抽象。结果是结构人类学和文化分析之间架起了一座可测试的桥梁：故事仍然是可解释的，但又成为可运输的对象，用于计算、比较和对转型的可证伪的约束。|[2601.15078](http://arxiv.org/abs/2601.15078)|null|\n",
        "2601.16214": "|**2026-01-22**|**CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback**|摄像机控制的视频扩散模型的最新进展显着改善了摄像机对准。然而，相机的可控性仍然有限。在这项工作中，我们以奖励反馈学习为基础，旨在进一步提高相机的可控性。然而，直接借用现有的 ReFL 方法面临着一些挑战。首先，当前的奖励模型缺乏评估摄像机对齐的能力。其次，将潜在视频解码为 RGB 视频以进行奖励计算会带来大量的计算开销。第三，3D 几何信息在视频解码过程中通常被忽略。为了解决这些限制，我们引入了一种高效的相机感知 3D 解码器，可将视频潜在解码为 3D 表示以进行奖励量化。具体来说，视频潜伏与相机姿势一起被解码为 3D 高斯。在这个过程中，相机位姿不仅作为输入，还作为投影参数。视频潜伏和相机姿势之间的不对准将导致 3D 结构中的几何扭曲，从而导致渲染模糊。基于这个属性，我们明确优化了渲染的新颖视图和真实视图之间的像素级一致性作为奖励。为了适应随机性，我们进一步引入了一个可见性项，它有选择地仅监督通过几何扭曲导出的确定性区域。在 RealEstate10K 和 WorldScore 基准上进行的大量实验证明了我们提出的方法的有效性。项目页面：\\href{https://a-bigbao.github.io/CamPilot/}{CamPilot 页面}。|[2601.16214](http://arxiv.org/abs/2601.16214)|null|\n",
        "2601.16208": "|**2026-01-22**|**Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders**|通过在高维语义潜在空间中进行训练，表示自动编码器 (RAE) 在 ImageNet 上的扩散建模中显示出明显的优势。在这项工作中，我们研究了该框架是否可以扩展到大规模、自由格式的文本到图像（T2I）生成。我们首先通过对网络、合成和文本渲染数据进行训练，将冻结表示编码器 (SigLIP-2) 上的 RAE 解码器扩展到 ImageNet 之外，发现虽然规模提高了总体保真度，但有针对性的数据组合对于文本等特定领域至关重要。然后，我们对最初为 ImageNet 提出的 RAE 设计选择进行严格的压力测试。我们的分析表明，扩展简化了框架：虽然与维度相关的噪声调度仍然至关重要，但诸如宽扩散头和噪声增强解码之类的架构复杂性在规模上提供的优势可以忽略不计。在这个简化的框架上构建，我们对扩散变压器从 0.5B 到 9.8B 参数范围内的 RAE 与最先进的 FLUX VAE 进行了受控比较。在所有模型规模的预训练过程中，RAE 的表现始终优于 VAE。此外，在对高质量数据集进行微调期间，基于 VAE 的模型在 64 个 epoch 后出现灾难性的过拟合，而 RAE 模型在 256 个 epoch 中保持稳定，并始终获得更好的性能。在所有实验中，基于 RAE 的扩散模型表现出更快的收敛速度和更好的生成质量，使 RAE 成为比 VAE 更简单、更强大的基础，可用于大规模 T2I 生成。此外，由于视觉理解和生成都可以在共享表示空间中运行，因此多模态模型可以直接对生成的潜在变量进行推理，为统一模型开辟了新的可能性。|[2601.16208](http://arxiv.org/abs/2601.16208)|null|\n",
        "2601.16148": "|**2026-01-22**|**ActionMesh: Animated 3D Mesh Generation with Temporal 3D Diffusion**|生成动画 3D 对象是许多应用程序的核心，但大多数先进的作品通常难以在实践中应用，因为它们的设置有限、运行时间长或质量有限。我们引入了 ActionMesh，这是一种生成模型，可以前馈方式预测“正在运行”的可用于生产的 3D 网格。从早期视频模型中汲取灵感，我们的主要见解是修改现有的 3D 扩散模型以包含时间轴，从而形成我们称为“时间 3D 扩散”的框架。具体来说，我们首先调整 3D 扩散阶段来生成一系列代表时变且独立的 3D 形状的同步潜在变量。其次，我们设计了一个时间 3D 自动编码器，它将一系列独立形状转换为预定义参考形状的相应变形，从而使我们能够构建动画。将这两个组件结合起来，ActionMesh 可根据不同的输入生成动画 3D 网格，例如单目视频、文本描述，甚至带有描述其动画的文本提示的 3D 网格。此外，与以前的方法相比，我们的方法速度很快，并且产生的结果是无装备且拓扑一致的，因此可以实现快速迭代和无缝应用，例如纹理和重定向。我们在标准视频到 4D 基准（Consistent4D、Objaverse）上评估我们的模型，并报告几何精度和时间一致性方面的最先进性能，证明我们的模型可以以前所未有的速度和质量提供动画 3D 网格。|[2601.16148](http://arxiv.org/abs/2601.16148)|null|\n",
        "2601.16118": "|**2026-01-22**|**A Case for Hypergraphs to Model and Map SNNs on Neuromorphic Hardware**|在神经形态硬件上执行尖峰神经网络 (SNN) 会带来将神经元映射到核心的问题。 SNN 的工作原理是在神经元之间传播尖峰，并通过突触形成图形。神经形态硬件通过片上网络、传输尖峰和核心网格来模仿它们，每个核心管理多个神经元。其运营成本与尖峰移动和活跃核心有关。映射包括两个任务：对 SNN 的图进行分区以适合内部核心以及将每个分区放置在硬件网格上。两者都是 NP 难题，并且随着 SNN 和硬件扩展到数十亿个神经元，它们变得越来越难以有效解决。在这项工作中，我们建议将 SNN 的抽象从图提升到超图，并相应地重新设计映射技术。由此产生的模型通过揭示神经元之间超边缘共同成员关系的概念，忠实地捕获了核心内部尖峰的复制。我们进一步表明，超边的重叠和局部性与高质量映射密切相关，使这些属性有助于设计映射算法。通过直接利用它们，通过共享超边缘对神经元进行分组，可以减少通信流量和硬件资源的使用，而不仅仅是收缩单个连接所达到的效果。为了证实这一见解，我们考虑了几种分区和放置算法，其中一些是新设计的，另一些是根据文献改编的，并将它们与逐渐更大且生物合理的 SNN 进行比较。我们的结果表明，基于超图的技术可以在几种执行时间制度下实现比最先进的技术更好的映射。基于这些观察，我们确定了一些有前途的算法选择，以实现任何规模的有效映射。|[2601.16118](http://arxiv.org/abs/2601.16118)|null|\n",
        "2601.16113": "|**2026-01-22**|**synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier**|由于缺乏大规模带注释的训练数据集，低资源语言的光学字符识别 (OCR) 仍然是一个重大挑战。克什米尔语等语言拥有大约 700 万使用者，其复杂的波斯阿拉伯语文字具有独特的变音符号，目前缺乏 Tesseract、TrOCR 和 PaddleOCR 等主要 OCR 系统的支持。为此类语言手动创建数据集非常昂贵、耗时且容易出错，通常需要逐字转录打印或手写文本。   我们推出 SynthOCR-Gen，这是一款专为低资源语言设计的开源合成 OCR 数据集生成器。我们的工具通过将数字 Unicode 文本语料库转换为即用型训练数据集，解决了 OCR 开发的根本瓶颈。该系统实现了一个全面的管道，包括文本分段（字符、单词、n-gram、句子和行级别）、具有脚本纯度强制的 Unicode 规范化、具有可配置分布的多字体渲染，以及模拟真实世界文档降级（包括旋转、模糊、噪声和扫描仪伪影）的 25 多种数据增强技术。   我们通过生成包含 600,000 个样本的分词克什米尔 OCR 数据集来展示我们方法的有效性，该数据集已在 HuggingFace 上公开发布。这项工作为将资源匮乏的语言带入视觉语言人工智能模型时代提供了一条实用途径，并且该工具可供全球使用服务不足的书写系统的研究人员和从业者公开使用。|[2601.16113](http://arxiv.org/abs/2601.16113)|null|\n",
        "2601.16096": "|**2026-01-22**|**Neural Particle Automata: Learning Self-Organizing Particle Dynamics**|我们介绍神经粒子自动机（NPA），这是神经元胞自动机（NCA）从静态晶格到动态粒子系统的拉格朗日推广。与细胞固定在像素或体素的经典欧拉 NCA 不同，NPA 将每个细胞建模为具有连续位置和内部状态的粒子，两者都通过共享的、可学习的神经规则进行更新。这种基于粒子的配方产生了清晰的细胞个体化，允许异质动力学，并且仅将计算集中在存在活动的区域。与此同时，粒子系统提出了挑战：邻域是动态的，局部相互作用的简单实现与粒子数量呈二次方缩放。我们通过使用由内存高效、CUDA 加速内核支持的可微分平滑粒子流体动力学 (SPH) 算子取代基于网格的邻域感知来解决这些挑战，从而实现可扩展的端到端训练。在形态发生、点云分类和基于粒子的纹理合成等任务中，我们表明 NPA 保留了关键的 NCA 行为，例如鲁棒性和自我再生，同时实现了特定于粒子系统的新行为。总之，这些结果将 NPA 定位为学习自组织粒子动力学的紧凑神经模型。|[2601.16096](http://arxiv.org/abs/2601.16096)|null|\n",
        "2601.15982": "|**2026-01-22**|**Real-Time Inviscid Fluid Dynamics and Aero-acoustics on a Sphere**|复杂表面上的实时流体和气动声学模拟可以具有交互式应用程序 - 从基于全球的天气可视化到具有物理精确的风和声音的沉浸式计算机游戏。然而，传统的基于网格的求解器难以解决表面奇点附近的数值不稳定问题，而基于网格的方法缺乏以稳定、高阶精度求解偏微分方程 (PDE) 的直接路径。   我们的模型结合了最近点法 (CPM)、基于投影的纳维-斯托克斯求解器和 Ffowcs Williams-Hawkings (FWH) 类比，为实时无粘流体模拟和带有嵌入式障碍物的球面气动声学提供了一个统一的框架。通过将计算限制在球体周围的窄带内，CPM 可以在笛卡尔嵌入中求解表面偏微分方程，而无需参数化。每个带点都映射到其最近的表面位置，带算子将结果投影到局部切线空间上。表面障碍物使用有符号距离函数 (SDF) 进行建模，强制执行无滑移速度约束和基于伯努利的压力调整，以实现一致的现实世界边界相互作用。气动声源直接根据表面压力导数计算，并通过频率和幅度调制以及抑制伪影的滞后平滑映射到实时音频。   我们从该模型中得到的结果模拟了球形表面上无粘性流体的行为，同时利用在表面上流动的流体的压力产生声音。这种方法提供的结果具有稳定性、几何一致性，并支持科学可视化、虚拟现实和教育工具中的应用。|[2601.15982](http://arxiv.org/abs/2601.15982)|null|\n",
        "2601.15951": "|**2026-01-22**|**EVolSplat4D: Efficient Volume-based Gaussian Splatting for 4D Urban Scene Synthesis**|静态和动态城市场景的新颖视图合成（NVS）对于自动驾驶模拟至关重要，但现有方法往往难以平衡重建时间和质量。虽然最先进的神经辐射场和 3D 高斯喷射方法可以实现照片级真实感，但它们通常依赖于耗时的每个场景优化。相反，新兴的前馈方法经常采用每像素高斯表示，这会导致在复杂、动态环境中聚合多视图预测时出现 3D 不一致。我们提出了 EvolSplat4D，这是一种前馈框架，通过统一三个专门分支中基于体积和基于像素的高斯预测，超越了现有的每像素范式。对于近距离静态区域，我们直接从 3D 特征体积预测多个帧上 3D 高斯的一致几何形状，并辅以语义增强的基于图像的渲染模块来预测其外观。对于动态演员，我们利用以对象为中心的规范空间和运动调整渲染模块来聚合时间特征，确保稳定的 4D 重建，尽管运动先验存在噪声。远场场景由高效的每像素高斯分支处理，以确保全场景覆盖。 KITTI-360、KITTI、Waymo 和 PandaSet 数据集上的实验结果表明，EvolSplat4D 能够以卓越的准确性和一致性重建静态和动态环境，优于按场景优化和最先进的前馈基线。|[2601.15951](http://arxiv.org/abs/2601.15951)|null|\n",
        "2601.15936": "|**2026-01-22**|**Detecting interpolation errors in infant mortality counts in 20th Century England and Wales**|了解地方政府地区的历史数据集（例如英格兰和威尔士的婴儿死亡率数据）可以为我们不断变化的社会提供有价值的见解。由于收集记录的地方政府辖区的边界经常发生变化，此类分析在实践中可能具有挑战性。文献中为克服此类实际挑战而采用的一种解决方案是使用面积插值来预处理数据，以使单位在聚焦时间段内保持一致。然而，这样的方法很容易出错。在本文中，我们介绍了一种新颖的变点方法来检测插值表现不佳的实例。我们证明了我们的方法在原始数据上的实用性，并且还证明了校正插值误差如何影响婴儿死亡率曲线的聚类。|[2601.15936](http://arxiv.org/abs/2601.15936)|null|\n",
        "2601.15929": "|**2026-01-22**|**NeuroMamba: Multi-Perspective Feature Interaction with Visual Mamba for Neuron Segmentation**|神经元分割是重建全面神经元连接组的基石，这对于破译大脑的功能组织至关重要。神经元的不规则形态和密集交织的结构使这项任务特别具有挑战性。由于缺乏远程上下文，流行的基于 CNN 的方法通常无法解决模糊边界，而基于 Transformer 的方法则因块分割过程中体素级细节的丢失而导致边界不精确。为了解决这些限制，我们提出了 NeuroMamba，这是一个多视角框架，它利用 Mamba 的线性复杂性来实现无补丁全局建模，并将其与互补的局部特征建模相结合，从而有效地捕获远程依赖性，同时精心保留细粒度的体素细节。具体来说，我们设计了一个通道门控边界判别特征提取器（BDFE）来增强局部形态线索。作为补充，我们引入了空间连续特征提取器 (SCFE)，它将分辨率感知扫描机制集成到 Visual Mamba 架构中，以自适应地对不同数据分辨率的全局依赖关系进行建模。最后，交叉调制机制协同融合这些多视角特征。我们的方法在四个公共 EM 数据集上展示了最先进的性能，验证了其对各向异性和各向同性分辨率的卓越适应性。源代码将公开。|[2601.15929](http://arxiv.org/abs/2601.15929)|null|\n",
        "2601.16982": "|**2026-01-23**|**AnyView: Synthesizing Any Novel View in Dynamic Scenes**|现代生成视频模型擅长产生令人信服的高质量输出，但难以在高度动态的现实环境中保持多视图和时空一致性。在这项工作中，我们介绍了 \\textbf{AnyView}，一种基于扩散的视频生成框架，用于具有最小归纳偏差或几何假设的 \\emph{动态视图合成}。我们利用具有不同监督级别的多个数据源，包括单目（2D）、多视图静态（3D）和多视图动态（4D）数据集，来训练通用时空隐式表示，能够从任意相机位置和轨迹生成零样本新颖视频。我们在标准基准上评估 AnyView，显示出与当前最先进水平具有竞争力的结果，并提出 \\textbf{AnyViewBench}，这是一个具有挑战性的新基准，专为各种现实场景中的 \\emph{extreme} 动态视图合成而定制。在这种更戏剧性的设置中，我们发现大多数基线的性能都会急剧下降，因为它们需要视点之间存在显着重叠，而 AnyView 在从 \\emph{any} 视点提示时保持了生成真实、合理且时空一致的视频的能力。结果、数据、代码和模型可以在以下位置查看：https://tri-ml.github.io/AnyView/|[2601.16982](http://arxiv.org/abs/2601.16982)|null|\n",
        "2601.16973": "|**2026-01-23**|**VisGym: Diverse, Customizable, Scalable Environments for Multimodal Agents**|现代视觉语言模型（VLM）在多步骤视觉交互中的特征仍然很差，特别是在它们如何整合长期视野中的感知、记忆和行动方面。我们推出 VisGym，这是一个拥有 17 个环境的体育馆，用于评估和训练 VLM。该套件涵盖符号谜题、真实图像理解、导航和操作，并提供对难度、输入表示、规划范围和反馈的灵活控制。我们还提供多步求解器来生成结构化演示，从而实现监督微调。我们的评估表明，所有前沿模型都在交互设置中陷入困境，在简单（46.6％）和困难（26.0％）配置中的成功率都很低。我们的实验揭示了显着的局限性：模型难以有效地利用长上下文，在无限历史记录中的表现比在截断窗口中的表现更差。此外，我们发现一些基于文本的符号任务一旦以视觉方式呈现就会变得更加困难。然而，明确的目标观察、文本反馈和在部分可观察或未知动态设置中进行监督微调的探索性演示会产生一致的收益，突出显示具体的故障模式和改进多步骤视觉决策的途径。代码、数据和模型可以在：https://visgym.github.io/ 找到。|[2601.16973](http://arxiv.org/abs/2601.16973)|null|\n",
        "2601.16935": "|**2026-01-23**|**AERO: Adaptive and Efficient Runtime-Aware OTA Updates for Energy-Harvesting IoT**|能量收集 (EH) 物联网 (IoT) 设备在间歇性能源可用性下运行，这会扰乱任务执行并使能源密集型无线 (OTA) 更新变得特别具有挑战性。传统的 OTA 更新机制依赖于重新启动并产生大量开销，因此不适合间歇供电的系统。最近的实时 OTA 更新技术减少了重启开销，但仍然缺乏确保更新与运行时执行交互时的一致性的机制。本文介绍了 AERO，一种自适应且高效的运行时感知 OTA 更新机制，它将更新任务集成到设备的有向无环图 (DAG) 中，并在能量和时间限制下将它们与常规任务一起调度。通过识别受更新影响的执行区域并动态调整依赖关系，AERO 确保一致的更新集成，同时适应间歇性的能源可用性。对代表性工作负载的实验表明，与现有的实时更新方法相比，更新可靠性和效率得到了提高。|[2601.16935](http://arxiv.org/abs/2601.16935)|null|\n",
        "2601.16930": "|**2026-01-23**|**In Quest of an Extensible Multi-Level Harm Taxonomy for Adversarial AI: Heart of Security, Ethical Risk Scoring and Resilience Analytics**|从网络安全、道德、风险分析到对抗性人工智能，伤害无处不在，但不存在系统的或商定的伤害清单，而且这个概念本身也很少按照认真分析所需的精确度进行定义。当前的讨论依赖于模糊的、特定的伤害概念，使得细致入微、结构化和定性的评估实际上变得不可能。本文直接挑战了这一差距。我们引入了一种结构化且可扩展的伤害分类法，该分类法以当代伦理理论的集合为基础，使伤害变得明确、可枚举且易于分析处理。拟议的框架确定了 66 多种不同的伤害类型，系统地分为人类和非人类两个总体领域以及 11 个主要类别，每个类别都明确与 11 种主导伦理理论保持一致。虽然设计上可扩展，但上层有意保持稳定。除了分类之外，我们还引入了一种受害实体的理论意识分类法，并将规范性伤害属性正式化，包括实质上改变道德严重性的可逆性和持续时间。总之，这些贡献将伤害从修辞占位符转变为可操作的分析对象，从而能够对人工智能系统和其他社会技术领域进行严格的道德推理和长期安全评估，其中伤害是首要关注的问题。|[2601.16930](http://arxiv.org/abs/2601.16930)|null|\n",
        "2601.16911": "|**2026-01-23**|**Cell-vertex WENO schemes with shock-capturing quadrature for high-order finite element discretizations of hyperbolic problems**|我们提出了一种新的局部激波捕获方法，用于双曲守恒定律的连续（CG）和不连续伽辽金（DG）离散化。我们之前的工作中介绍了高阶 CG 和 DG 近似的基于耗散的加权基本非振荡 (WENO) 稳定的基本框架。在此总体框架中，Hermite WENO (HWENO) 重建用于计算局部平滑度传感器，从而确定每个细胞的适当人工粘度量。在原始版本中，WENO 平均的候选多项式是使用冯诺依曼邻居的导数数据构建的。我们通过使用与网格顶点相关的 WENO 多项式作为基于单元的 WENO 平均的候选多项式来升级这个标准的“单元-单元”重建过程。各个单元的 Hermite 数据被发送到这些单元的顶点，之后顶点平均 HWENO 数据被发送回包含顶点的单元。新的“单元顶点”平均过程包括顶点邻居的数据，而无需将它们显式添加到重建模板中。它减轻了网格印记，也可用于 DG 方法的经典 HWENO 限制器。该方法的第二个主要新颖之处是高阶有限元内人工粘度的正交驱动分布。用非线性 WENO 型对应物代替线性正交权重，我们将冲击捕获耗散集中在不连续性附近，同时将问题单元的平滑部分中的耗散最小化。这种 WENO 稳定性的重新分布保留了每个单元内的总耗散率，并提高了局部冲击分辨率，而无需依赖子单元分解技术。一维和二维数值实验表明，高阶元素的准确性和鲁棒性有了显着提高。|[2601.16911](http://arxiv.org/abs/2601.16911)|null|\n",
        "2601.16860": "|**2026-01-23**|**Hidden Zeros in Massive Theories**|我们研究了无质量色序振幅中发现的隐藏零点和相关分解在大规模变形下是否持续存在。使用运动学网格结构，我们表明隐藏的零点仅在对称控制的质量生成中存在。对于具有均匀质量的大规模 $\\text{Tr} Φ^3$，零点及其因式分解模式在平面变量的大规模移位后继承，并且类似的陈述适用于 Kaluza-Klein 约简，其中相关非平面变量由守恒模数修改。对于非线性 sigma 模型 (NLSM)，朴素 π 介子质量项通常会破坏隐藏的零点，而杂散诱导势则可恢复它们。这允许在零附近进行因式分解，包括由适当质量变形的 NLSM + $φ^3$ 理论描述的奇点通道，并导致针对大量 NLSM 振幅的基于隐藏零的基于壳递归。对于自旋一，简单的大规模杨-米尔斯理论无法表现出隐藏的零点，而自发破缺的规范理论却保留了它们。|[2601.16860](http://arxiv.org/abs/2601.16860)|null|\n",
        "2601.16767": "|**2026-01-23**|**Tactile Rendering Using Three Basic Stimulus Components in Ultrasound Midair Haptics**|超声波空中触觉 (UMH) 可以使用聚焦超声波呈现非接触式触觉刺激，而不会限制用户的移动。最近，UMH 已被证明不仅可以呈现传统的振动触觉，还可以通过以几赫兹的速度局部旋转超声波焦点来呈现静态压力感觉。通过这些压力和振动感觉，UMH 涵盖了触觉感知所依赖的三种机械感受器：SA-I、FA-I 和 FA-II。本研究提出了一种基于这些受体特征的 UMH 纹理渲染方法。设计了与每个机械感受器相对应的三种基本超声波刺激，并通过它们的组合呈现触觉纹理。对于 SA-I，采用压力刺激。对于 FA-I 和 FA-II，分别采用 30 Hz 和 150 Hz 的振动刺激。实验结果表明，所提出的方法可以渲染至少六种具有不同粗糙度和摩擦感的可辨别纹理。值得注意的是，通过与真实物理物体的比较，我们发现仅压力刺激被认为是光滑的。其光滑度类似于玻璃大理石。当合成振动刺激时，感知的粗糙度和摩擦力显着增加。粗糙度达到100目砂纸的水平。|[2601.16767](http://arxiv.org/abs/2601.16767)|null|\n",
        "2601.16736": "|**2026-01-23**|**A Step to Decouple Optimization in 3DGS**|3D 高斯分布 (3DGS) 已成为实时新颖视图合成的强大技术。作为通过基元之间的梯度传播进行优化的显式表示，在深度神经网络（DNN）中广泛接受的优化实际上在 3DGS 中得到了采用，例如同步权重更新和具有自适应梯度的 Adam。然而，考虑到 3DGS 中的物理意义和具体设计，3DGS 的优化中有两个被忽视的细节：（i）更新步骤耦合，它会导致优化器状态重新缩放和视点之外昂贵的属性更新，以及（ii）当前的梯度耦合，这可能导致正则化效果不足或过于有效。然而，这种复杂的耦合尚未得到充分探索。在重新审视 3DGS 的优化之后，我们采取了一个步骤将其解耦，并将该过程重构为：稀疏 Adam、重新状态正则化和解耦属性正则化。通过在 3DGS 和 3DGS-MCMC 框架下进行大量实验，我们的工作提供了对这些组件的更深入的了解。最后，基于实证分析，我们重新设计优化，通过重新耦合有益成分提出AdamW-GS，同时获得更好的优化效率和表示有效性。|[2601.16736](http://arxiv.org/abs/2601.16736)|null|\n",
        "2601.16728": "|**2026-01-23**|**A locking-free nodal-based polytopal method for linear elasticity**|这项工作提出了一种离散德拉姆（DDR）数值方案，用于解决一般多面体网格上的线性弹性问题，重点是防止准不可压缩状态下的体积锁定。该方法被表述为基于节点的方法，使用 DDR 复合体的最低阶梯度空间，富含标量面气泡自由度，可有效捕获跨单元面的法向通量。这种面气泡富集对于确保发散场有足够的近似灵活性至关重要，从而消除了当拉梅参数$λ$接近无穷大时通常发生的{体积锁定}现象。我们建立独立于 $λ\\ge 0$ 的 $H^1$ 误差估计，并且仅依赖于 $μ$ 的下限，保证从可压缩到几乎不可压缩状态的整个范围内的鲁棒性。我们还展示了如何使我们的方案适应无摩擦接触力学模型，保持对原始变量（位移）的无锁定估计。数值实验证实，即使材料表现为不可压缩介质，所提出的{无锁定}方法也可以对一般多面体离散化提供准确且稳定的近似。这种方法的灵活性和稳健性使其成为涉及几乎不可压缩弹性材料的工程应用中混合配方的实用替代方案。|[2601.16728](http://arxiv.org/abs/2601.16728)|null|\n",
        "2601.16672": "|**2026-01-23**|**ReWeaver: Towards Simulation-Ready and Topology-Accurate Garment Reconstruction**|高质量 3D 服装重建在缩小数字化身、虚拟试穿和机器人操作等应用中的模拟与真实差距方面发挥着至关重要的作用。然而，现有的服装重建方法通常依赖于非结构化表示，例如 3D 高斯 Splats，难以提供服装拓扑和缝纫结构的准确重建。因此，重建的输出通常不适合高保真物理模拟。我们提出了 ReWeaver，这是一种新颖的框架，用于从稀疏多视图 RGB 图像中进行拓扑精确的 3D 服装和缝纫图案重建。只需四个输入视图，ReWeaver 即可预测接缝和面板以及它们在 2D UV 空间和 3D 空间中的连接性。预测的接缝和面板与多视图图像精确对齐，产生适合 3D 感知、高保真物理模拟和机器人操作的结构化 2D--3D 服装表示。为了实现有效的训练，我们构建了一个大规模数据集 GCD-TS，包括多视图 RGB 图像、3D 服装几何形状、纹理人体网格和带注释的缝纫图案。该数据集包含超过 100,000 个合成样本，涵盖各种复杂的几何形状和拓扑。大量实验表明，ReWeaver 在拓扑精度、几何对齐和接缝板一致性方面始终优于现有方法。|[2601.16672](http://arxiv.org/abs/2601.16672)|null|\n"
    },
    "具生智能&自动驾驶": {
        "2601.14135": "|**2026-01-20**|**Multi-Tongue Frequency Fractal Dynamics in Hodgkin-Huxley Neurons Induced by Temporal Interference Stimulation**|我们研究了霍奇金-赫胥黎模型在先前未探索的亚赫兹共振状态下的时间干扰（TI）刺激下的神经元兴奋性，并发现了一种惊人的非线性响应，我们称之为“多舌频率分形”。与产生平滑谐振谷的单频驱动不同，双频激励将这种响应分割成一系列急剧调制的舌，其数量和结构随着观察时间的推移而增长，揭示了清晰的自相似结构。这些特征是随着失谐变化而在非级联和级联高次谐波和次谐波生成之间的转变中出现的，并且在 omega ~ 0.2 rad/s 的本征离子时间尺度附近最大化。参数扫描表明，钾电导越高，钠电导越低，漏电导越低，分形计数越高。这些结果表明，即使在经典的可兴奋膜中，TI 刺激也可以引发丰富的、分层组织的频率响应，揭示 Hodgkin-Huxley 动力学中的分形组织。|[2601.14135](http://arxiv.org/abs/2601.14135)|null|\n",
        "2601.14133": "|**2026-01-20**|**TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers**|标准视觉语言动作 (VLA) 模型通常会针对机器人控制明确调整整体视觉语言模型 (VLM) 主干。然而，这种方法在维持高水平的一般语义理解和学习低水平、细粒度的感觉运动技能之间造成了严重的紧张关系，常常导致模型的开放世界能力的“灾难性遗忘”。为了解决这一冲突，我们引入了 TwinBrainVLA，这是一种新颖的架构，它协调保留通用语义理解的通用 VLM 和致力于联合机器人控制的具体本体感觉的专业 VLM。 TwinBrainVLA 通过一种新颖的非对称混合变形金刚 (AsyMoT) 机制，将冻结的“左脑”（保留了强大的一般视觉推理功能）与可训练的“右脑”（专门用于具体感知）进行了协同作用。这种设计允许右脑从冻结的左脑动态查询语义知识，并将其与本体感受状态融合，为流程匹配动作专家提供丰富的调节，以生成精确的连续控制。在 SimplerEnv 和 RoboCasa 基准上进行的大量实验表明，与最先进的基线相比，TwinBrainVLA 实现了卓越的操作性能，同时明确保留了预训练 VLM 的全面视觉理解能力，为构建同时实现高级语义理解和低级物理灵活性的通用机器人提供了一个有前途的方向。|[2601.14133](http://arxiv.org/abs/2601.14133)|null|\n",
        "2601.14091": "|**2026-01-20**|**Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems**|机器人有望在未来的建筑行业中发挥重要作用，但由于成本高且难以适应动态任务而面临挑战。本研究探讨了基础模型在增强建筑机器人任务规划的适应性和通用性方面的潜力。使用轻量级开源大语言模型 (LLM) 和视觉语言模型 (VLM) 提出并实现了四种模型。这些模型包括一个单一代理和三个多代理团队，它们协作创建机器人行动计划。这些模型针对三个施工角色进行评估：油漆工、安全检查员和地砖铺设员。结果表明，四智能体团队在大多数指标上都优于最先进的 GPT-4o，同时成本效益高出十倍。此外，拥有三名和四名智能体的团队展示了改进的通用性。通过讨论代理行为如何影响输出，本研究增强了人工智能团队的理解，并支持未来在建筑之外的各种非结构化环境中的研究。|[2601.14091](http://arxiv.org/abs/2601.14091)|null|\n",
        "2601.14038": "|**2026-01-20**|**Correcting and Quantifying Systematic Errors in 3D Box Annotations for Autonomous Driving**|准确的地面实况注释对于监督学习和评估自动驾驶车辆系统的性能至关重要。这些车辆通常配备有源传感器，例如激光雷达，以预定义的模式扫描环境。在动态场景中，基于此类传感器数据的 3D 框注释具有挑战性，在动态场景中，对象在不同的​​时间戳处被观察，因此位置也不同。如果不正确处理这种现象，方框注释中很容易引入系统错误。我们的工作是第一个在广泛使用的公开数据集中发现此类注释错误的工作。通过我们新颖的离线估计方法，我们纠正注释​​，使它们遵循物理上可行的轨迹，并实现与传感器数据的空间和时间一致性。我们第一次为这个问题定义了指标；我们在 Argoverse 2、MAN TruckScenes 和我们的专有数据集上评估我们的方法。我们的方法将这些数据集中的框注释质量提高了 17% 以上。此外，我们量化了其中的标注错误，发现原始标注错位达 2.5 m，其中高度动态的对象受影响最大。最后，我们测试了基准测试中错误的影响，发现该影响大于当前最先进方法相对于之前最先进方法通常实现的改进；表明准确的注释对于正确解释性能至关重要。我们的代码可在 https://github.com/alexandre-justo-miro/annotation- Correction-3D-boxes 获取。|[2601.14038](http://arxiv.org/abs/2601.14038)|null|\n",
        "2601.13976": "|**2026-01-20**|**FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation**|要在视觉和语言导航（VLN）中实现人类水平的表现，需要一个实体代理来共同理解多模态指令和视觉空间上下文，同时对长动作序列进行推理。最近的工作，例如 NavCoT 和 NavGPT-2，展示了思想链 (CoT) 推理在提高可解释性和长期规划方面的潜力。此外，OctoNav-R1 和 CoT-VLA 等多模态扩展进一步验证了 CoT 是实现类人导航推理的一条有前途的途径。然而，现有的方法面临着严重的缺点：纯文本 CoT 缺乏空间基础，很容易过度适应稀疏的注释推理步骤，而多模态 CoT 通过生成想象的视觉观察而导致严重的标记膨胀，使得实时导航不切实际。在这项工作中，我们提出了 FantasyVLN，这是一个统一的隐式推理框架，它保留了 CoT 推理的优点，而无需显式的令牌开销。具体来说，在 CoT 推理训练期间，使用预训练的视觉自回归器 (VAR) 将想象的视觉标记编码到紧凑的潜在空间中，并且该模型在统一的多 CoT 策略下从文本、视觉和多模态 CoT 模式中联合学习。在推理时，我们的模型执行直接指令到动作的映射，同时仍然享受推理感知表示。 LH-VLN 上的大量实验表明，与显式 CoT 方法相比，我们的方法实现了推理感知且实时的导航，提高了成功率和效率，同时将推理延迟减少了一个数量级。|[2601.13976](http://arxiv.org/abs/2601.13976)|null|\n",
        "2601.13876": "|**2026-01-20**|**Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education**|科学演示对于有效的 STEM 教育非常重要，但教师在多种场合安全、一致地进行科学演示面临着挑战，而机器人技术可以在这些场合提供帮助。然而，当前的视觉-语言-动作（VLA）模型需要大量的计算资源，并牺牲语言生成能力来最大限度地提高效率，这使得它们不适合需要可解释的解释生成系统的资源有限的教育环境。我们提出了 \\textit{教学 VLA 框架}，该框架通过四个组件将教学调整应用于轻量级 VLA 模型：恢复语言生成能力的文本修复、用于转移教学知识的大语言模型（LLM）蒸馏、教育环境的安全培训以及根据科学教育背景调整的教学评估。我们使用与科学教育专家合作开发的评估框架，评估涵盖物理、化学、生物学和地球科学的五个科学演示的教学 VLA 框架。我们的评估通过教师调查和法学硕士法官评估来评估任务绩效（成功率、协议合规性、效率、安全性）和教学质量。我们还提供生成文本的定性分析。实验结果表明，教学 VLA 框架可实现与基线模型相当的任务绩效，同时生成适合情境的教育解释。|[2601.13876](http://arxiv.org/abs/2601.13876)|null|\n",
        "2601.13809": "|**2026-01-20**|**DroneVLA: VLA based Aerial Manipulation**|随着空中平台从被动观察者发展为主动操纵者，挑战转向设计直观的界面，使非专家用户能够自然地指挥这些系统。这项工作引入了自主空中操纵系统的新颖概念，该系统能够解释高级自然语言命令以检索物体并将其传递给人类用户。该系统旨在将基于 Grounding DINO 和视觉语言动作 (VLA) 模型的 MediaPipe 与配备 1-DOF 夹具和英特尔实感 RGB-D 摄像头的定制无人机集成。 VLA 执行语义推理来解释用户提示的意图，并生成优先级任务队列以掌握场景中的相关对象。接地 DINO 和动态 A* 规划算法用于导航和安全地重新定位物体。为了确保切换阶段安全、自然的交互，系统采用了由 MediaPipe 驱动的以人为本的控制器。该模块提供实时人体姿态估计，使无人机能够利用视觉伺服技术在用户正前方保持稳定、清晰的位置，从而实现舒适的交接。我们通过现实世界的定位和导航实验证明了该系统的有效性，最大误差、平均欧氏误差和均方根误差分别为 0.164m、0.070m 和 0.084m，凸显了 VLA 用于空中操纵操作的可行性。|[2601.13809](http://arxiv.org/abs/2601.13809)|null|\n",
        "2601.13793": "|**2026-01-20**|**PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles**|在本文中，我们提出了一种 ETA 模型（预计到达时间），该模型利用历史道路速度模式的注意力机制。随着自动驾驶和智能交通系统的日益普及，对准确可靠的 ETA 估算的需求不断增长，在导航、出行规划和交通管理中发挥着至关重要的作用。然而，由于交通流的动态性和复杂性，预测预计到达时间仍然是一项具有挑战性的任务。传统方法通常以简单的方式结合实时和历史流量数据，或者依赖于复杂的基于规则的计算。虽然最近的深度学习模型已显示出潜力，但它们通常需要很高的计算成本，并且不能有效捕获对 ETA 预测至关重要的时空模式。 ETA 预测本质上涉及时空因果关系，我们提出的模型通过利用注意力机制来提取和利用沿路线的每个时空点积累的时间特征来解决这个问题。该架构可实现高效、准确的 ETA 估计，同时保持模型的轻量级和可扩展性。我们使用现实世界的驾驶数据集验证我们的方法，并通过以任务感知的方式有效地集成道路特征、实时交通状况和历史速度模式来证明我们的方法优于现有基线。|[2601.13793](http://arxiv.org/abs/2601.13793)|null|\n",
        "2601.15260": "|**2026-01-21**|**DrivIng: A Large-Scale Multimodal Driving Dataset with Full Digital Twin Integration**|感知是自动驾驶的基石，使车辆能够了解周围环境并做出安全、可靠的决策。开发强大的感知算法需要大规模、高质量的数据集，涵盖不同的驾驶条件并支持全面的评估。现有数据集通常缺乏高保真数字孪生，限制了系统测试、边缘情况模拟、传感器修改和模拟到真实的评估。为了解决这一差距，我们推出了 DrivIng，这是一个大型多模式数据集，具有跨越城市、郊区和高速公路段的约 18 公里路线的完整地理参考数字孪生。我们的数据集提供来自 6 个 RGB 摄像头、1 个 LiDAR 和基于 ADMA 的高精度定位的连续记录，涵盖白天、黄昏和夜间的捕获。所有序列均以 10 Hz 频率通过 12 个类别的 3D 边界框和轨道 ID 进行注释，产生约 120 万个注释实例。除了数字孪生的优势之外，DrivIng 还能够将真实流量一对一地传输到模拟中，保留代理交互，同时实现现实且灵活的场景测试。为了支持可重复的研究和稳健的验证，我们使用最先进的感知模型对 DrivIng 进行基准测试，并公开发布数据集、数字孪生、高清地图和代码库。|[2601.15260](http://arxiv.org/abs/2601.15260)|null|\n",
        "2601.15234": "|**2026-01-21**|**Cosmic strings, domain walls and environment-dependent clustering**|最近的宇宙学数据有利于幻影穿越暗能量，激发具有非最小耦合的模型，从而在结构形成中引入第五种力。将这些模型与本地测试相协调通常需要严格的筛选，从而导致依赖于环境的聚类。我们通过非最小耦合标量场驱动的后期结构诱导相变来研究这种效应。为此，我们引入了 Norns，一种完全相对论的宇宙粒子网格代码，它自洽地演化出一个复杂的标量场——对称子的泛化，产生全局 U(1) 弦而不是畴壁。通过模拟，我们比较了弦和墙形成模型，量化了对物质功率谱、晕质量函数和缺陷动力学的影响。强烈的环境依赖性效应可能会在低密度区域产生与 LCDM 的显着偏差，同时保持总体功率谱变化适度（k~0.3-0.5 h Mpc^-1 时约 4-15%，z > 0.2 的亚百分比）。我们发现，有吸引力的第五力可以局部抑制空隙中的结构生长，同时通过驱动空隙的流出来增强周围过密区域的结构生长。这些效应在物质密度概率密度函数和标记的晕功率谱中留下了独特的特征，这些特征很可能在低红移数据中被检测到。|[2601.15234](http://arxiv.org/abs/2601.15234)|null|\n",
        "2601.15197": "|**2026-01-21**|**BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries**|视觉-语言-动作 (VLA) 模型在机器人操作方面显示出了前景，但通常很难推广到新指令或复杂的多任务场景。我们确定了当前训练范式中的一个关键病态，其中目标驱动的数据收集会产生数据集偏差。在这样的数据集中，语言指令仅通过视觉观察就可以高度预测，从而导致指令和动作之间的条件互信息消失，我们将这种现象称为信息崩溃。因此，模型退化为仅视觉策略，忽略语言限制并在分布外（OOD）设置中失败。为了解决这个问题，我们提出了 BayesianVLA，这是一种通过贝叶斯分解强制执行指令的新颖框架。通过引入可学习的潜在动作查询，我们构建了一个双分支架构来估计仅视觉先验 $p(a \\mid v)$ 和语言条件后验 $π(a \\mid v, \\ell)$。然后，我们优化策略以最大化操作和指令之间的条件逐点互信息（PMI）。这个目标有效地惩罚了视觉捷径并奖励了明确解释语言命令的行为。不需要新数据，BayesianVLA 显着提高了泛化能力。在 SimplerEnv 和 RoboCasa 上进行的广泛实验展示了巨大的收益，包括在具有挑战性的 OOD SimplerEnv 基准上提高了 11.3%，验证了我们的方法在实际应用中稳健地处理语言的能力。|[2601.15197](http://arxiv.org/abs/2601.15197)|null|\n",
        "2601.14945": "|**2026-01-21**|**TIDAL: Temporally Interleaved Diffusion and Action Loop for High-Frequency VLA Control**|大规模视觉-语言-动作 (VLA) 模型提供语义泛化，但推理延迟较高，将其限制为低频批处理和执行范例。这种频率不匹配会产生执行盲点，从而导致目标在开环执行窗口期间移动的动态环境中出现故障。我们提出了 TIDAL（时间交错扩散和动作循环），这是一种将语义推理与高频驱动解耦的分层框架。 TIDAL 作为基于扩散的 VLA 的主干不可知模块，使用双频架构来重新分配计算预算。具体来说，低频宏意图循环缓存语义嵌入，而高频微控制循环则将单步流集成与执行交错。此设计可在边缘硬件上实现约 9 Hz 的控制更新（相对于约 2.4 Hz 基线），而不会增加边际开销。为了处理由此产生的延迟变化，我们引入了一种时间错位的训练策略，其中策略使用过时的语义意图和实时本体感知来学习预测补偿。此外，我们通过结合差分运动预测器来解决静态视觉编码器对速度不敏感的问题。 TIDAL 是架构性的，使其与系统级优化正交。实验表明，在动态拦截任务中，性能比开环基线提高了 2 倍。尽管静态成功率出现边际回归，但我们的方法使反馈频率增加了 4 倍，并将语义嵌入的有效范围扩展到超出本机动作块大小。在非暂停推理协议下，当标准基线因延迟而失败时，TIDAL 仍然保持稳健。|[2601.14945](http://arxiv.org/abs/2601.14945)|null|\n",
        "2601.14702": "|**2026-01-21**|**AutoDriDM: An Explainable Benchmark for Decision-Making of Vision-Language Models in Autonomous Driving**|自动驾驶是一个极具挑战性的领域，需要在复杂场景下进行可靠的感知和安全的决策。最近的视觉语言模型（VLM）展示了推理和泛化能力，为自动驾驶开辟了新的可能性；然而，现有的基准和指标过分强调感知能力，未能充分评估决策过程。在这项工作中，我们提出了 AutoDriDM，这是一个以决策为中心的渐进基准，包含跨越三个维度（对象、场景和决策）的 6,650 个问题。我们评估主流的 VLM 来描绘自动驾驶中感知到决策的能力边界，我们的相关性分析揭示了感知和决策性能之间的弱一致性。我们进一步对模型的推理过程进行可解释性分析，识别逻辑推理错误等关键故障模式，并引入分析器模型来自动进行大规模注释。 AutoDriDM 弥合了以感知为中心的评估和以决策为中心的评估之间的差距，为现实世界的自动驾驶提供更安全、更可靠的 VLM 指导。|[2601.14702](http://arxiv.org/abs/2601.14702)|null|\n",
        "2601.14628": "|**2026-01-21**|**A Brain-inspired Embodied Intelligence for Fluid and Fast Reflexive Robotics Control**|实体智能的最新进展利用了数据和模型参数的大规模扩展来掌握自然语言命令跟踪和多任务控制。相比之下，生物系统表现出从稀疏的经验中快速获取技能的天生能力。至关重要的是，当前的机器人政策很难复制生物运动固有的动态稳定性、反射性响应能力和时间记忆。在这里，我们提出了神经形态视觉-语言-动作（NeuroVLA），这是一个模仿皮层、小脑和脊髓之间生物神经系统结构组织的框架。我们采用系统级仿生设计：高级模型规划目标，自适应小脑模块使用高频传感器反馈稳定运动，仿生脊柱层执行闪电般快速的动作生成。 NeuroVLA 代表了神经形态 VLA 在物理机器人上的首次部署，实现了最先进的性能。我们在没有额外数据或特殊指导的情况下观察到生物运动特征的出现：它停止了机械臂的晃动，节省了大量能量（在神经形态处理器上仅 0.4w），显示出时间记忆能力并在不到 20 毫秒的时间内触发安全反射。|[2601.14628](http://arxiv.org/abs/2601.14628)|null|\n",
        "2601.14622": "|**2026-01-21**|**Probing Prompt Design for Socially Compliant Robot Navigation with Vision Language Models**|语言模型越来越多地用于社交机器人导航，但现有的基准在很大程度上忽视了社交顺从行为的原则性提示设计。这种限制在实践中尤其重要，因为许多系统依赖小型视觉语言模型 (VLM) 来提高效率。与大型语言模型相比，小型 VLM 的决策能力较弱，因此有效的提示设计对于准确导航至关重要。受人类学习和动机认知理论的启发，我们从两个维度研究提示设计：系统指导（以行动为中心、以推理为导向和感知推理提示）和动机框架，其中模型与人类、其他人工智能系统或他们过去的自己竞争。对两个符合社会规范的导航数据集进行的实验揭示了三个关键发现。首先，对于未微调的 GPT-4o，与人类的竞争取得了最佳性能，而与其他人工智能系统的竞争则表现最差。对于微调模型，与模型过去的自我的竞争产生最强的结果，其次是与人类的竞争，其性能进一步受到即时设计、模型选择和数据集特征之间的耦合效应的影响。其次，不适当的系统提示设计会显着降低性能，即使与直接微调相比也是如此。第三，虽然直接微调极大地改善了语义级指标，例如感知、预测和推理，但它在动作准确性方面的收益有限。相比之下，我们的系统提示在动作准确性方面产生了不成比例的更大改进，表明所提出的提示设计主要充当决策级约束而不是代表性增强。|[2601.14622](http://arxiv.org/abs/2601.14622)|null|\n",
        "2601.14587": "|**2026-01-21**|**Explainable OOHRI: Communicating Robot Capabilities and Limitations as Augmented Reality Affordances**|人机交互对于发出个性化指令和在可能发生故障时协助机器人至关重要。然而，机器人在很大程度上仍然是黑匣子，用户无法深入了解其不断发展的功能和局限性。为了解决这一差距，我们提出了可解释的面向对象的 HRI (X-OOHRI)，这是一种增强现实 (AR) 界面，可通过视觉指示符、径向菜单、颜色编码和解释标签传达机器人动作的可能性和约束。我们的系统使用视觉语言模型将对象属性和机器人限制编码为面向对象的结构，从而允许动态生成解释并直接操作在模拟环境中空间对齐的虚拟双胞胎。我们将端到端管道与物理机器人集成，并展示从低级拾放到高级指令的各种用例。最后，我们通过用户研究评估 X-OOHRI，发现参与者有效地发出面向对象的命令，开发机器人局限性的准确心理模型，并参与混合主动解决方案。|[2601.14587](http://arxiv.org/abs/2601.14587)|null|\n",
        "2601.14514": "|**2026-01-20**|**\"Just in Time\" World Modeling Supports Human Planning and Reasoning**|概率心理模拟被认为在人类推理、规划和预测中发挥着关键作用，但复杂环境中的模拟需求超出了人类现实能力的极限。越来越多的证据表明，人们使用环境的简化表示来模拟，从而抽象出不相关的细节，但目前尚不清楚人们如何有效地确定这些简化。在这里，我们提出了一个用于基于模拟的推理的“即时”框架，该框架演示了如何以最少的附加计算在线构建此类表示。该模型使用模拟、视觉搜索和表示修改的紧密交错，当前模拟指导查看位置，视觉搜索标记应编码以供后续模拟的对象。尽管只对一小部分对象进行编码，但该模型可以做出高效的预测。我们发现，在网格世界规划任务和一系列行为测量的物理推理任务中，与替代模型相比，这一解释有强有力的实证支持。总之，这些结果提供了人们如何构建简化表示以支持有效心理模拟的具体算法说明。|[2601.14514](http://arxiv.org/abs/2601.14514)|null|\n",
        "2601.14438": "|**2026-01-20**|**Vision-Based Natural Language Scene Understanding for Autonomous Driving: An Extended Dataset and a New Model for Traffic Scene Description Generation**|交通场景理解对于自动驾驶车辆准确感知和解释其环境至关重要，从而确保安全导航。本文提出了一种新颖的框架，可将单个前视摄像头图像转换为简洁的自然语言描述，有效捕获空间布局、语义关系和驾驶相关线索。所提出的模型利用混合注意机制来增强空间和语义特征提取，并集成这些特征以生成上下文丰富且详细的场景描述。为了解决该领域专业数据集可用性有限的问题，开发了一个源自 BDD100K 数据集的新数据集，并为其构建提供了全面的指南。此外，该研究还深入讨论了相关评估指标，确定了最适合该任务的措施。使用 CIDEr 和 SPICE 等指标进行的广泛定量评估，辅以人类判断评估，表明所提出的模型在新开发的数据集上实现了强劲的性能并有效地实现了其预期目标。|[2601.14438](http://arxiv.org/abs/2601.14438)|null|\n",
        "2601.15284": "|**2026-01-21**|**Walk through Paintings: Egocentric World Models from Internet Priors**|如果视频生成模型不仅能够想象一个合理的未来，而且能够想象出正确的未来，准确地反映世界如何随着每一个动作而变化，结果会怎样呢？我们通过提出自我中心世界模型（EgoWM）来解决这个问题，这是一种简单的、与架构无关的方法，可以将任何预训练的视频扩散模型转换为动作条件的世界模型，从而实现可控的未来预测。我们不是从头开始训练，而是重新利用互联网规模视频模型的丰富世界先验，并通过轻量级调节层注入运动命令。这使得模型能够忠实地遵循行为，同时保持现实性和强泛化性。我们的方法可以自然地跨实施例和动作空间扩展，从 3-DoF 移动机器人到 25-DoF 类人机器人，其中预测以自我为中心的关节角度驱动的动力学更具挑战性。该模型为导航和操作任务提供连贯的推出，只需要适度的微调。为了独立于视觉外观来评估物理正确性，我们引入了结构一致性评分（SCS），它衡量稳定的场景元素是否与所提供的动作一致地演变。与之前最先进的导航世界模型相比，EgoWM 将 SCS 提高了 80%，同时将推理延迟降低了六倍，并对不可见的环境（包括绘画内的导航）进行了强大的泛化。|[2601.15284](http://arxiv.org/abs/2601.15284)|null|\n",
        "2601.15281": "|**2026-01-21**|**StableWorld: Towards Stable and Consistent Long Interactive Video Generation**|在本文中，我们探讨了交互式视频生成中被忽视的稳定性和时间一致性的挑战，它通过相机移动和文本提示等交互行为合成动态且可控的视频世界。尽管世界建模取得了显着进展，但当前的方法仍然存在严重的不稳定性和时间退化，常常导致长视域交互过程中的空间漂移和场景崩溃。为了更好地理解这个问题，我们首先调查了不稳定的根本原因，并确定错误累积的主要来源源于同一场景，其中生成的帧逐渐偏离初始干净状态并将错误传播到后续帧。基于这一观察，我们提出了一种简单而有效的方法，\\textbf{StableWorld}，一种动态帧驱逐机制。通过不断过滤掉退化的帧，同时保留几何一致的帧，StableWorld 有效地从源头防止累积漂移，从而使交互生成更加稳定和时间一致性。在多个交互式视频模型（例如 Matrix-Game、Open-Oasis 和 Hunyuan-GameCraft）上取得的有希望的结果表明，StableWorld 是模型无关的，可以应用于不同的交互式视频生成框架，以显着提高跨不同交互式场景的稳定性、时间一致性和泛化性。|[2601.15281](http://arxiv.org/abs/2601.15281)|null|\n",
        "2601.16207": "|**2026-01-22**|**IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance**|许多视觉-语言-动作（VLA）模型将图像块扁平化为一维标记序列，削弱了精确操作所需的二维空间线索。我们引入了 IVRA，这是一种轻量级、免训练的方法，它通过利用模型内置视觉编码器中已有的亲和力提示来提高空间理解，而不需要任何外部编码器或重新训练。 IVRA 有选择地将这些相似性信号注入实例级功能所在的语言模型层。这种推理时间干预重新调整了视觉标记交互，更好地保留了几何结构，同时保持所有模型参数固定。我们通过将 IVRA 应用于跨越 2D 和 3D 操作（VIMA 和 LIBERO）的模拟基准以及各种真实机器人任务的各种 VLA 架构（LLaRA、OpenVLA 和 FLOWER）来展示 IVRA 的通用性。在 2D VIMA 上，IVRA 在低数据条件下比基线 LLaRA 提高了 +4.2% 的平均成功率。在 3D LIBERO 上，它比 OpenVLA 和 FLOWER 基线产生一致的增益，包括基线精度接近饱和时的改进（96.3% 至 97.1%）。所有代码和模型将公开发布。可视化效果可在以下位置获得：jongwoopark7978.github.io/IVRA|[2601.16207](http://arxiv.org/abs/2601.16207)|null|\n",
        "2601.16163": "|**2026-01-22**|**Cosmos Policy: Fine-Tuning Video Models for Visuomotor Control and Planning**|最近的视频生成模型展示了捕捉复杂的物理交互和场景随时间演变的卓越能力。为了利用其时空先验，机器人研究采用了用于策略学习的视频模型，但由于需要多个阶段的后训练和新的架构组件来生成动作，从而引入了复杂性。在这项工作中，我们介绍了 Cosmos Policy，这是一种简单的方法，通过对目标平台上收集的机器人演示数据进行单阶段的后训练，将大型预训练视频模型 (Cosmos-Predict2) 调整为有效的机器人策略，无需进行架构修改。 Cosmos Policy 学习在视频模型的潜在扩散过程中直接生成编码为潜在帧的机器人动作，利用模型的预训练先验和核心学习算法来捕获复杂的动作分布。此外，Cosmos 策略会生成未来的状态图像和值（预期累积奖励），这些图像和值类似地被编码为潜在框架，从而能够以更高的成功可能性对行动轨迹进行测试时规划。在我们的评估中，Cosmos Policy 在 LIBERO 和 RoboCasa 模拟基准上实现了最先进的性能（平均成功率分别为 98.5% 和 67.1%），并且在具有挑战性的现实世界双手操作任务中获得了最高的平均得分，优于从头开始训练的强大扩散策略、基于视频模型的策略以及在相同机器人演示上微调的最先进的视觉语言动作模型。此外，根据政策推出数据，Cosmos Policy 可以从经验中学习，以完善其世界模型和价值函数，并利用基于模型的规划在具有挑战性的任务中实现更高的成功率。我们在 https://research.nvidia.com/labs/dir/cosmos-policy/ 发布代码、模型和训练数据|[2601.16163](http://arxiv.org/abs/2601.16163)|null|\n",
        "2601.16108": "|**2026-01-22**|**Multimodal Climate Disinformation Detection: Integrating Vision-Language Models with External Knowledge Sources**|气候虚假信息已成为当今数字世界的主要挑战，尤其是随着社交媒体上广泛分享的误导性图像和视频的兴起。这些虚假说法往往令人信服且难以发现，这可能会拖延应对气候变化的行动。虽然视觉语言模型（VLM）已被用来识别视觉虚假信息，但它们仅依赖于训练时可用的知识。这限制了他们推理最近事件或更新的能力。本文的主要目标是通过将 VLM 与外部知识相结合来克服这一限制。通过检索反向图像结果、在线事实检查和可信专家内容等最新信息，系统可以更好地评估图像及其声明是否准确、误导、虚假或无法验证。这种方法提高了模型处理现实世界气候虚假信息的能力，并支持在快速变化的信息环境中保护公众对科学的理解的努力。|[2601.16108](http://arxiv.org/abs/2601.16108)|null|\n",
        "2601.16065": "|**2026-01-22**|**DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models**|视觉语言动作（VLA）模型利用视觉语言模型（VLM）强大的感知能力来理解环境并直接输出动作，在机器人操作方面取得了显着的进展。然而，默认情况下，VLA 模型可能会过度关注与任务无关区域中的图像标记，我们将其描述为“分散注意力的标记”。这种行为可能会干扰模型在每个步骤中生成所需操作标记，从而影响任务的成功率。在本文中，我们介绍了一种简单而有效的即插即用分散注意力标记修剪（DTP）框架，该框架可以动态检测和修剪这些分散注意力的图像标记。通过纠正模型的视觉注意模式，我们的目标是提高任务成功率，并在不改变其原始架构或添加额外输入的情况下探索模型的性能上限。 SIMPLER Benchmark（Li 等人，2024）上的实验表明，我们的方法在不同类型的新型 VLA 模型中始终实现了任务成功率的相对提高，证明了基于 Transformer 的 VLA 的通用性。进一步的分析揭示了所有测试模型的任务成功率与任务无关区域的关注量之间存在负相关，这凸显了 VLA 模型的普遍现象，可以指导未来的研究。我们还将我们的代码发布在：https://anonymous.4open.science/r/CBD3。|[2601.16065](http://arxiv.org/abs/2601.16065)|null|\n",
        "2601.16007": "|**2026-01-22**|**PhysicsMind: Sim and Real Mechanics Benchmarking for Physical Reasoning and Prediction in Foundational VLMs and World Models**|现代基础多模态大语言模型 (MLLM) 和视频世界模型在数学、常识和视觉推理方面取得了显着进步，但它们对底层物理的掌握仍然有待探索。试图衡量这个问题的现有基准依赖于合成的视觉问答模板或关注感知视频质量，这与衡量视频遵守物理定律的程度无关。为了解决这种碎片化问题，我们引入了PhysicsMind，这是一个具有真实和模拟环境的统一基准，可根据三个规范原理（质心、杠杆平衡和牛顿第一定律）评估规律一致的推理和生成。 PhysicsMind 包括两个主要任务：i）VQA 任务，测试模型是否可以推理并确定图像或短视频中的物理量和值；ii）视频生成（VG）任务，评估预测的运动轨迹是否遵循与地面真实情况相同的质心、扭矩和惯性约束。在PhysicsMind 上评估了一系列最新的模型和视频生成模型，发现它们依赖于外观启发法，同时经常违反基本力学。这些差距表明，当前的扩展和训练仍然不足以实现强大的物理理解，这凸显了PhysicsMind作为物理感知多模态模型的重点测试平台。我们的数据将在接受后发布。|[2601.16007](http://arxiv.org/abs/2601.16007)|null|\n",
        "2601.15991": "|**2026-01-22**|**A multi-wavelength approach of AGN feedback in LINERs: The case of NGC 4438**|低电离核发射线区域（LINER）中多相流出已被证实是频繁存在的，但发射它们的机制仍在研究中。我们的目标是探索 LINER NGC4438 中检测到的电离气体流出、射电连续谱结构和 X 射线发射之间的联系。我们分析了 LINER NGC4438 的 L、C 和 X 波段图像（从 1.4 到 12 GHz），结合了来自增强型多元件无线电链接干涉仪网络 (e-MERLIN) 和 Karl G Jansky 甚大阵列 (VLA) 的高分辨率数据。我们生成无线电通量、光谱指数图和能量模型，使我们能够表征源。我们结合光学积分场光谱 (IFS) 数据 (GTC/MEGARA) 和钱德拉 X 射线数据，具有相当的分辨率，以更好地追踪外流、活动星系核及其潜在的联系。我们展示了新的 L、C 和 X 波段高分辨率、高灵敏度射电图像和光谱指数图，可在 NGC 4438 中探测 $\\sim$ 25 pc 尺度。这些数据揭示了射电结构和电离气泡之间的密切形态对应关系。使用基于射电通量和光谱指数的空间分辨能量模型，我们首次将紧凑的活动星系核发射从延伸的气泡中解开，建立了它们独特的物理起源。我们测量射电气泡的动能为 $\\sim 5\\times 10^{44}$ erg s$^{-1}$，超过电离流出的功率三个数量级以上。我们的多波长分析表明，NGC 4438 正在经历喷流模式反馈，其中低光度、弱准直的喷流撞击致密的北部星际介质。这种相互作用驱动冲击电离气体，产生中等速度的流出，从该区域去除材料，并产生与无线电和 H$α$ 腔一致的热 X 射线发射。|[2601.15991](http://arxiv.org/abs/2601.15991)|null|\n",
        "2601.15951": "|**2026-01-22**|**EVolSplat4D: Efficient Volume-based Gaussian Splatting for 4D Urban Scene Synthesis**|静态和动态城市场景的新颖视图合成（NVS）对于自动驾驶模拟至关重要，但现有方法往往难以平衡重建时间和质量。虽然最先进的神经辐射场和 3D 高斯喷射方法可以实现照片级真实感，但它们通常依赖于耗时的每个场景优化。相反，新兴的前馈方法经常采用每像素高斯表示，这会导致在复杂、动态环境中聚合多视图预测时出现 3D 不一致。我们提出了 EvolSplat4D，这是一种前馈框架，通过统一三个专门分支中基于体积和基于像素的高斯预测，超越了现有的每像素范式。对于近距离静态区域，我们直接从 3D 特征体积预测多个帧上 3D 高斯的一致几何形状，并辅以语义增强的基于图像的渲染模块来预测其外观。对于动态演员，我们利用以对象为中心的规范空间和运动调整渲染模块来聚合时间特征，确保稳定的 4D 重建，尽管运动先验存在噪声。远场场景由高效的每像素高斯分支处理，以确保全场景覆盖。 KITTI-360、KITTI、Waymo 和 PandaSet 数据集上的实验结果表明，EvolSplat4D 能够以卓越的准确性和一致性重建静态和动态环境，优于按场景优化和最先进的前馈基线。|[2601.15951](http://arxiv.org/abs/2601.15951)|null|\n",
        "2601.15844": "|**2026-01-22**|**Radio-Interferometric Image Reconstruction with Denoising Diffusion Restoration Models**|从不完整的傅里叶信息重建射电天空图像是射电天文学的一个关键挑战。在这项工作中，我们提出了一种基于去噪扩散概率模型（DDPM）的无线电天空数据驱动先验的无线电干涉图像重建方法。我们首先根据 VLA FIRST 巡天的射电星系观测数据训练 DDPM。我们创建射电星系的模拟 VLA、EHT 和 ALMA 观测，然后使用称为去噪扩散恢复模型 (DDRM) 的无监督后验采样方法来重建相应的图像，并使用我们的 DDPM 作为先验。我们的方法与测量的无线电干涉数据无关，并且自然地结合了测量过程的物理原理。我们能够重建具有非常高保真度 PSNR>60 的图像，这比使用条件 DDPM 的 CLEAN 和类似图像重建方法有显着改进|[2601.15844](http://arxiv.org/abs/2601.15844)|null|\n",
        "2601.15761": "|**2026-01-22**|**Off-Policy Actor-Critic with Sigmoid-Bounded Entropy for Real-World Robot Learning**|由于样本效率低下、奖励稀疏和视觉观察嘈杂，在现实世界中部署强化学习仍然具有挑战性。之前的工作利用演示和人类反馈来提高学习效率和稳健性。然而，离线到在线方法需要大量数据集并且可能不稳定，而 VLA 辅助强化学习则依赖于大规模预训练和微调。因此，一种低成本、数据要求极低的现实世界强化学习方法尚未出现。我们引入了 \\textbf{SigEnt-SAC}，这是一种非策略演员批评家方法，它使用单个专家轨迹从头开始学习。我们的关键设计是一个 sigmoid 有界熵项，它可以防止负熵驱动的针对分布外行为的优化并减少 Q 函数振荡。我们根据代表性基线对 D4RL 任务上的 SigEnt-SAC 进行基准测试。实验表明，SigEnt-SAC 大大减轻了 Q 函数振荡，并且比现有方法更快地达到 100% 的成功率。最后，我们在多个实施例中的四个现实世界机器人任务上验证 SigEnt-SAC，其中代理从原始图像和稀疏奖励中学习；结果表明，SigEnt-SAC 只需少量的现实世界交互即可学习成功的策略，这为现实世界的 RL 部署提供了一种低成本且实用的途径。|[2601.15761](http://arxiv.org/abs/2601.15761)|null|\n",
        "2601.15729": "|**2026-01-22**|**DualShield: Safe Model Predictive Diffusion via Reachability Analysis for Interactive Autonomous Driving**|扩散模型已成为自动驾驶中多模式运动规划的强大方法。然而，它们的实际部署通常受到执行车辆动力学固有的困难以及对其他智能体准确预测的严重依赖的阻碍，使得它们在不确定的交互下容易出现安全问题。为了解决这些限制，我们引入了 DualShield，这是一种规划和控制框架，它以双重能力利用 Hamilton-Jacobi (HJ) 可达性值函数。首先，价值函数充当主动指导，将扩散去噪过程引导至安全且动态可行的区域。其次，它们使用控制屏障值函数（CBVF）形成反应式安全防护罩，以修改执行的操作并确保安全。这种双重机制保留了扩散模型丰富的探索能力，同时在不确定甚至对抗性相互作用下提供原则性的安全保证。在具有挑战性的无保护掉头场景中的模拟表明，与不确定性下不同规划范式的领先方法相比，DualShield 显着提高了安全性和任务效率。|[2601.15729](http://arxiv.org/abs/2601.15729)|null|\n",
        "2601.16973": "|**2026-01-23**|**VisGym: Diverse, Customizable, Scalable Environments for Multimodal Agents**|现代视觉语言模型（VLM）在多步骤视觉交互中的特征仍然很差，特别是在它们如何整合长期视野中的感知、记忆和行动方面。我们推出 VisGym，这是一个拥有 17 个环境的体育馆，用于评估和训练 VLM。该套件涵盖符号谜题、真实图像理解、导航和操作，并提供对难度、输入表示、规划范围和反馈的灵活控制。我们还提供多步求解器来生成结构化演示，从而实现监督微调。我们的评估表明，所有前沿模型都在交互设置中陷入困境，在简单（46.6％）和困难（26.0％）配置中的成功率都很低。我们的实验揭示了显着的局限性：模型难以有效地利用长上下文，在无限历史记录中的表现比在截断窗口中的表现更差。此外，我们发现一些基于文本的符号任务一旦以视觉方式呈现就会变得更加困难。然而，明确的目标观察、文本反馈和在部分可观察或未知动态设置中进行监督微调的探索性演示会产生一致的收益，突出显示具体的故障模式和改进多步骤视觉决策的途径。代码、数据和模型可以在：https://visgym.github.io/ 找到。|[2601.16973](http://arxiv.org/abs/2601.16973)|null|\n",
        "2601.16780": "|**2026-01-23**|**PocketDVDNet: Realtime Video Denoising for Real Camera Noise**|对于自动对焦、自动​​驾驶和监控等应用来说，真实的多分量传感器噪声下的实时视频去噪仍然具有挑战性。我们提出了 PocketDVDNet，这是一种使用我们的模型压缩框架开发的轻量级视频降噪器，该框架结合了稀疏引导的结构化修剪、物理信息噪声模型和知识蒸馏，以在减少资源需求的情况下实现高质量恢复。从参考模型开始，我们引入稀疏性，应用有针对性的通道修剪，并对教师进行现实多分量噪声的重新培训。学生网络学习隐式噪声处理，无需显式噪声图输入。 PocketDVDNet 将原始模型大小减少了 74%，同时提高了去噪质量并实时处理 5 帧补丁。这些结果表明，积极的压缩与域适应的蒸馏相结合，可以协调实用的实时视频去噪的性能和效率。|[2601.16780](http://arxiv.org/abs/2601.16780)|null|\n",
        "2601.16667": "|**2026-01-23**|**ReViP: Reducing False Completion in Vision-Language-Action Models with Vision-Proprioception Rebalance**|视觉-语言-动作 (VLA) 模型通过结合视觉、语言和本体感觉来预测动作，具有先进的机器人操作能力。然而，以前的方法将本体感受信号直接与 VLM 编码的视觉语言特征融合，导致状态主导偏差和错误完成，尽管存在可见的执行失败。我们将此归因于模态不平衡，即政策过度依赖内部状态而未充分利用视觉证据。为了解决这个问题，我们提出了 ReViP，这是一种新颖的 VLA 框架，具有视觉本体感觉再平衡功能，可增强视觉基础和扰动下的鲁棒性。关键的见解是引入辅助任务感知环境先验，以自适应地调节语义感知和本体感受动态之间的耦合。具体来说，我们使用外部 VLM 作为任务阶段观察者，从视觉观察中提取实时的以任务为中心的视觉线索，从而驱动视觉本体感知特征线性调制，以增强环境意识并减少状态驱动的错误。此外，为了评估错误完成，我们提出了第一个基于 LIBERO 构建的错误完成基准套件，具有对象删除等受控设置。大量实验表明，与我们套件上强大的 VLA 基线相比，ReViP 有效降低了错误完成率并提高了成功率，并将收益扩展到 LIBERO、RoboTwin 2.0 和实际评估。|[2601.16667](http://arxiv.org/abs/2601.16667)|null|\n",
        "2601.16409": "|**2026-01-23**|**Gen-DBA: Generative Database Agents (Towards a Move 37 for Databases)**|Move\\,37 标志着人工智能的重大突破之一，因为它有能力超越人类的专业知识，并在战略性两人围棋棋盘游戏中发现超越传统游戏玩法的新颖策略。自然语言处理、计算机视觉和机器人领域也经历了类似的现象，分别是大型语言模型（LLM）、视觉语言模型（VLM）和视觉语言动作模型（VLA）形式的大型基础模型的出现。在本文中，我们调查了数据库系统人工智能研究 (AI4DB) 的现状，并评估 AI4DB 系统距离实现自己的 Move\\,37 时刻还有多远。我们设想生成数据库代理（简称 Gen-DBA）作为实现数据库系统 Move\\,37 的途径，它将把生成推理和创造力带入数据库学习任务领域。这篇愿景论文通过提出构建 Gen-DBA 的方法来探索这个方向，该方法包括但不限于 Transformer 主干、基于硬件的标记化机制、两阶段目标导向的下一个标记预测训练范例以及生成推理过程。|[2601.16409](http://arxiv.org/abs/2601.16409)|null|\n",
        "2601.16404": "|**2026-01-23**|**Photoinduced metastable cation disorder in metal halide double perovskites**|无铅钙钛矿已成为光电子领域卤化铅同类产品的环保替代品。其中，双钙钛矿Cs2AgInCl6家族通过适当的成分工程，通过强电子-声子耦合和自俘获激子（STE）的形成，表现出显着的白光发射。尽管有这些优点，但控制其激发态行为的基本光动力学和结构动力学仍然知之甚少。在这里，我们报告了 Cs2AgInCl6 双钙钛矿家族中的长寿命亚稳态相，并使用瞬态光谱、时间分辨 X 射线衍射 (TR-XRD) 和 X 射线吸收 (TR-XAS) 等一系列工具揭示了这一过程以及随之而来的电子和结构演化。我们发现光诱导的瞬态亚稳相与 B 位点 (Ag-In) 无序相关，从而导致光学带隙显着减小。在TR-XRD和第一原理计算的支持下，Ag-In无序驱动了具有毫秒寿命的富Ag和富In域的形成，并且寿命在较低温度下增加。 TR-XAS 进一步揭示光生 STE 将 Ag+ 氧化为 Ag2+，促进这种高度时间不对称的有序-无序转变。我们的研究结果证明了一种由空穴局部 STE 形成介导的新机制，能够将双钙钛矿中的瞬态光诱导状态延长至数毫秒状态，从而为获得这些材料的亚稳态相的功能特性提供了可能性。|[2601.16404](http://arxiv.org/abs/2601.16404)|null|\n",
        "2601.16351": "|**2026-01-22**|**Elucidating Three-Dimensional Coherent Structures in a Multi-Stream Jet**|名义二维 (2D) 剪切层已被广泛研究，并且其主要动力学已得到很好的理解。然而，在实际配置中，这种剪切层的行为受到邻近表面的影响。在这项研究中，我们研究了在真实喷嘴中相对较厚的分流板下游发展的三维 (3D) 相干结构，该喷嘴具有侧壁、由单个扩展坡道形成的上边界和由突出甲板定义的下边界。因此，除了由核心流和旁路流之间的混合产生的主分流板剪切层 (SPSL) 之外，该流还包含与环境的上剪切层 (USL) 和下剪切层 (LSL)。通过分析大涡模拟数据来表征非定常流动动力学，而平均流动则提供了对潜在放大机制的深入了解。频谱固有正交分解揭示了跨频段的宽带和音调动态的清晰分离。宽带低频模式具有高度 3D 性，起源于 USL 和 LSL。相反，音调高频内容与 SPSL 中的 2D 不稳定性相关。宽带和音调特征也出现在非线性能量转移机制中。 Triglobal 解析分析进一步阐明了 USL 和 LSL 内的放大机制。低频响应模式通过喷嘴几何形状附近的局部强制来激发，并受 3D 开尔文-亥姆霍兹动力学控制。喷嘴角部产生的低频流向涡流驱动矩形射流的轴切换行为特征。造波器分析进一步表明，这些角涡是自持低频动力学的一部分。|[2601.16351](http://arxiv.org/abs/2601.16351)|null|\n",
        "2601.16336": "|**2026-01-22**|**DMAVA: Distributed Multi-Autonomous Vehicle Architecture Using Autoware**|模拟和验证多辆自动驾驶车辆 (AV) 之间的协调是一项具有挑战性的任务，因为大多数现有的模拟架构仅限于单车操作或依赖集中控制。本文提出了一种分布式多 AV 架构 (DMAVA)，可实现跨多个物理主机的同步、实时自动驾驶模拟。每辆车都运行自己完整的 AV 堆栈，并独立于其他 AV 运行。模拟中的车辆通过低延迟的以数据为中心的通信层保持同步协调。所提出的系统集成了 ROS 2 Humble、Autoware Universe、AWSIM Labs 和 Zenoh，以支持在基于 Unity 的共享环境中并发执行多个 Autoware 堆栈。在多主机配置上进行的实验证明了稳定的定位、可靠的主机间通信和完全同步的闭环控制。 DMAVA 还作为多车辆自主代客泊车的基础，展示了其向更高级别合作自主的可扩展性。演示视频和源代码位于：https://github.com/zubxxr/distributed-multi-autonomous-vehicle-architecture。|[2601.16336](http://arxiv.org/abs/2601.16336)|null|\n",
        "2601.16299": "|**2026-01-22**|**Collective Rabi-driven vibrational activation in molecular polaritons**|混合光-物质态，称为分子极化子，是由电子或振动强耦合（ESC 和 VSC）与有限电磁场产生的。虽然这些已经得到了广泛的研究，但驱动腔中电子-核动力学的影响仍然很大程度上未知。在这里，我们报告了一种先前未被认识的振动激活机制，该机制在驱动光学腔中的集体 ESC 下出现。使用自洽地将麦克斯韦方程组与量子分子动力学结合起来的半经典模拟，我们证明集体电子拉比振荡一致地驱动核运动。这种效应是通过使用最小二能级模型中的振动波包动力学和基于与 Ehrenfest 动力学的时间相关密度泛函紧束缚的原子模拟来捕获的。振动激活非单调地取决于拉比频率，并且当集体极化子分裂与分子振动模式共振时最大化。该机制表现出与受激拉曼弛豫机制一致的特征。我们的结果为现实的空腔电子核动力学建立了一个自洽的框架。|[2601.16299](http://arxiv.org/abs/2601.16299)|null|\n"
    }
}