{
    "Video Diffusion": {
        "2512.24724": "|**2025-12-31**|**FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation**|在这项工作中，我们表明模型容量的影响随时间步长的不同而变化：它对于早期和晚期阶段至关重要，但在中间阶段基本上可以忽略不计。因此，我们提出了 FlowBlending，一种阶段感知的多模型采样策略，分别在容量敏感阶段和中间阶段采用大模型和小模型。我们进一步引入简单的标准来选择阶段边界，并提供速度发散分析作为识别容量敏感区域的有效代理。在 LTX-Video (2B/13B) 和 WAN 2.1 (1.3B/14B) 中，FlowBlending 的推理速度提高了 1.65 倍，失败次数减少了 57.35%，同时保持了大型模型的视觉保真度、时间连贯性和语义对齐。 FlowBlending 还与现有的采样加速技术兼容，可实现高达 2 倍的额外加速。项目页面位于：https://jibin86.github.io/flowblending_project_page。|[2512.24724](http://arxiv.org/abs/2512.24724)|null|\n",
        "2512.24551": "|**2025-12-31**|**PhyGDPO: Physics-Aware Groupwise Direct Preference Optimization for Physically Consistent Text-to-Video Generation**|文本到视频（T2V）生成的最新进展已经实现了良好的视觉质量，但合成忠实遵循物理定律的视频仍然是一个开放的挑战。现有的主要基于图形或提示扩展的方法很难推广到简单的模拟环境之外或学习隐式物理推理。缺乏具有丰富物理相互作用和现象的训练数据也是一个问题。在本文中，我们首先介绍了一种物理增强视频数据构建管道 PhyAugPipe，它利用具有思维链推理的视觉语言模型 (VLM) 来收集大规模训练数据集 PhyVidGen-135K。然后，我们制定了一个有原则的物理感知分组直接偏好优化（PhyGDPO）框架，该框架建立在分组 Plackett-Luce 概率模型的基础上，以捕获超越成对比较的整体偏好。在 PhyGDPO 中，我们设计了一种物理引导奖励 (PGR) 方案，该方案嵌入基于 VLM 的物理奖励，以引导优化实现物理一致性。我们还提出了一种 LoRA-Switch Reference (LoRA-SR) 方案，该方案消除了内存繁重的参考重复，以实现高效训练。实验表明，我们的方法在 PhyGenBench 和 VideoPhy2 上显着优于最先进的开源方法。请查看我们的项目页面 https://caiyuanhao1998.github.io/project/PhyGDPO 以获取更多视频结果。我们的代码、模型和数据将发布在https://github.com/caiyuanhao1998/Open-PhyGDPO|[2512.24551](http://arxiv.org/abs/2512.24551)|null|\n",
        "2512.25075": "|**2025-12-31**|**SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time**|我们提出了 SpaceTimePilot，这是一种视频扩散模型，可以解开空间和时间以实现可控的生成渲染。给定单目视频，SpaceTimePilot 可以在生成过程中独立改变摄像机视点和运动序列，重新渲染场景，以实现跨空间和时间的连续和任意探索。为了实现这一目标，我们在扩散过程中引入了一种有效的动画时间嵌入机制，允许对输出视频相对于源视频的运动序列进行显式控制。由于没有数据集提供具有连续时间变化的同一动态场景的配对视频，我们提出了一种简单而有效的时间扭曲训练方案，该方案重新利用现有的多视图数据集来模拟时间差异。该策略有效地监督模型学习时间控制并实现鲁棒的时空解缠结。为了进一步提高双重控制的精度，我们引入了两个额外的组件：改进的相机调节机制，允许从第一帧开始改变相机，以及CamxTime，第一个合成时空全覆盖渲染数据集，可在场景内提供完全自由的时空视频轨迹。对时间扭曲方案和 CamxTime 数据集的联合训练可以产生更精确的时间控制。我们在现实世界和合成数据上评估了 SpaceTimePilot，与之前的工作相比，展示了清晰的时空解离和强大的结果。项目页面：https://zheninghuang.github.io/Space-Time-Pilot/ 代码：https://github.com/ZheningHuang/spacetimepilot|[2512.25075](http://arxiv.org/abs/2512.25075)|null|\n",
        "2512.24952": "|**2025-12-31**|**VIPER: Process-aware Evaluation for Generative Video Reasoning**|视频生成领域的最新突破展示了一种称为帧链 (CoF) 推理的新兴功能，其中模型通过生成连续帧来解决复杂的任务。虽然这些模型显示出生成视频推理 (GVR) 的前景，但现有的评估框架通常依赖于单帧评估，这可能会导致结果黑客攻击，即模型通过错误的过程得出正确的结论。为了解决这个问题，我们提出了一种流程感知的评估范式。我们推出了 VIPER，这是一个涵盖时间、结构、符号、空间、物理和规划推理等 16 项任务的综合基准测试。此外，我们提出了过程结果一致性（POC@r），这是一种新的指标，利用带有分层标题的 VLM-as-Judge 来评估中间步骤和最终结果的有效性。我们的实验表明，最先进的视频模型仅实现了约 20% POC@1.0，并且表现出显着的结果黑客攻击。我们进一步探讨了测试时间缩放和采样鲁棒性的影响，强调了当前视频生成和真正的广义视觉推理之间的巨大差距。我们的基准将公开发布。|[2512.24952](http://arxiv.org/abs/2512.24952)|null|\n",
        "2512.24766": "|**2025-12-31**|**Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow**|生成视频建模已成为一种引人注目的工具，可以对开放世界操纵的合理物理交互进行零镜头推理。然而，将这种人类主导的运动转化为机器人系统所需的低级动作仍然是一个挑战。我们观察到，在给定初始图像和任务指令的情况下，这些模型擅长合成合理的物体运动。因此，我们引入了 Dream2Flow，这是一个通过 3D 对象流作为中间表示来桥接视频生成和机器人控制的框架。我们的方法从生成的视频中重建 3D 对象运动，并将操作制定为对象轨迹跟踪。通过将状态变化与实现这些变化的执行器分离，Dream2Flow 克服了实施例差距，并实现了预训练视频模型的零镜头引导，以操纵不同类别的对象，包括刚性、铰接式、可变形和粒状。通过轨迹优化或强化学习，Dream2Flow 将重建的 3D 对象流转换为可执行的低级命令，而无需特定于任务的演示。仿真和现实世界实验强调 3D 对象流作为通用且可扩展的接口，用于使视频生成模型适应开放世界的机器人操作。视频和可视化可在 https://dream2flow.github.io/ 上获取。|[2512.24766](http://arxiv.org/abs/2512.24766)|null|\n",
        "2601.00678": "|**2026-01-02**|**Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians**|人类擅长仅凭一张图像来预测场景的未来动态。能够模仿这种能力的视频生成模型是智能系统的重要组成部分。最近的方法提高了单图像条件视频生成中的时间相干性和 3D 一致性。然而，这些方法通常缺乏强大的用户可控性，例如修改相机路径，限制了它们在实际应用中的适用性。大多数现有的相机控制的图像到视频模型都难以准确建模相机运动、保持时间一致性和保持几何完整性。利用显式中间 3D 表示可实现与给定摄像机轨迹对齐的连贯视频生成，从而提供了一种有前景的解决方案。尽管这些方法通常使用 3D 点云来渲染场景并在后期引入对象运动，但尽管允许精确控制相机运动，但这种两步过程仍然无法实现完全的时间一致性。我们提出了一种新颖的框架，在单次前向传递中给定单个图像的情况下，构建 3D 高斯场景表示并对合理的对象运动进行采样。这使得能够快速生成相机引导的视频，而无需迭代去噪将对象运动注入渲染帧。在 KITTI、Waymo、RealEstate10K 和 DL3DV-10K 数据集上进行的大量实验表明，我们的方法实现了最先进的视频质量和推理效率。该项目页面位于 https://melonienimasha.github.io/Pixel-to-4D-Website。|[2601.00678](http://arxiv.org/abs/2601.00678)|null|\n",
        "2601.00504": "|**2026-01-01**|**MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation**|准确模拟现有 3D 对象和各种材料通常需要专业知识和耗时的物理参数调整才能实现所需的动态行为。我们引入了 MotionPhysics，这是一个端到端的可微分框架，它可以根据用户提供的自然语言提示来推断感兴趣的 3D 场景的合理物理参数，从而无需从地面实况轨迹或带注释的视频中进行指导。我们的方法首先利用多模态大语言模型来估计材料参数值，这些参数值被限制在合理的范围内。我们进一步提出了一种可学习的运动蒸馏损失，它从预训练的视频扩散模型中提取鲁棒的运动先验，同时最小化外观和几何归纳偏差以指导模拟。我们在三十多个场景中评估运动物理，包括现实世界、人工设计和人工智能生成的 3D 对象，涵盖弹性固体、金属、泡沫、沙子以及牛顿和非牛顿流体等多种材料。我们证明 MotionPhysics 在自然语言的指导下产生视觉逼真的动态模拟，超越了现有技术，同时自动确定物理上合理的参数。代码和项目页面位于：https://wangmiaowei.github.io/MotionPhysics.github.io/。|[2601.00504](http://arxiv.org/abs/2601.00504)|null|\n",
        "2601.00393": "|**2026-01-01**|**NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos**|在本文中，我们提出了 NeoVerse，一种多功能的 4D 世界模型，能够进行 4D 重建、新轨迹视频生成和丰富的下游应用。我们首先确定当前 4D 世界建模方法中可扩展性的常见限制，该限制是由昂贵且专门的多视图 4D 数据或繁琐的训练预处理引起的。相比之下，我们的 NeoVerse 建立在一个核心理念之上，该理念使整个管道可扩展至各种野外单目视频。具体来说，NeoVerse 具有无姿态前馈 4D 重建、在线单目退化模式模拟和其他良好对齐的技术。这些设计使 NeoVerse 具有多功能性并可推广到各个领域。同时，NeoVerse 在标准重建和生成基准方面实现了最先进的性能。我们的项目页面位于 https://neoverse-4d.github.io|[2601.00393](http://arxiv.org/abs/2601.00393)|null|\n",
        "2601.00126": "|**2025-12-31**|**Compositional Diffusion with Guided search for Long-Horizon Planning**|生成模型已成为强大的规划工具，组合方法通过组合本地模块化生成模型为长期任务分布建模提供了特别的希望。这种构图范式跨越了不同的领域，从多步骤操作规划到全景图像合成到长视频生成。然而，组合生成模型面临着一个严峻的挑战：当局部分布是多峰时，现有的组合方法平均不兼容的模式，产生的计划既不局部可行，也不全局一致。我们提出了带有引导搜索的组合扩散（CDGS），它通过将搜索直接嵌入扩散去噪过程来解决这个\\emph{模式平均}问题。我们的方法通过基于总体的采样探索局部模式的不同组合，使用基于可能性的过滤修剪不可行的候选者，并通过重叠片段之间的迭代重采样来强制全局一致性。 CDGS 在七项机器人操作任务上与预言机的性能相匹配，优于缺乏组合性或需要长期训练数据的基线。该方法可以跨领域推广，通过有效的本地到全局消息传递实现连贯的文本引导的全景图像和长视频。更多详细信息：https://cdgsearch.github.io/|[2601.00126](http://arxiv.org/abs/2601.00126)|null|\n",
        "2601.00051": "|**2025-12-31**|**TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model**|世界模型旨在赋予人工智能系统以连贯且时间一致的方式表示、生成动态环境并与之交互的能力。虽然最近的视频生成模型表现出了令人印象深刻的视觉质量，但它们在实时交互、长视野一致性和动态场景的持久记忆方面仍然有限，阻碍了它们向实际世界模型的演进。在本报告中，我们介绍了 TeleWorld，这是一种实时多模态 4D 世界建模框架，它将视频生成、动态场景重建和长期世界记忆统一在闭环系统中。 TeleWorld 引入了一种新颖的生成-重构-指导范式，其中生成的视频流被不断重构为动态 4D 时空表示，从而指导后续生成保持空间、时间和物理一致性。为了支持低延迟的长视野生成，我们采用了基于自回归扩散的视频模型，该模型通过宏观微观规划（MMPL）进行了增强，这是一种分层规划方法，可减少从帧级到段级的误差累积，并结合高效的分布匹配蒸馏（DMD），从而在实际计算预算下实现实时合成。我们的方法在统一的 4D 框架内实现了动态对象建模和静态场景表示的无缝集成，将世界模型推进到实用、交互式和计算可访问的系统。大量实验表明，TeleWorld 在静态和动态世界理解、长期一致性和实时生成效率方面均取得了出色的性能，将其定位为迈向交互式、支持记忆的多模式生成和体现智能的世界模型的实用步骤。|[2601.00051](http://arxiv.org/abs/2601.00051)|null|\n",
        "2601.01568": "|**2026-01-04**|**MM-Sonate: Multimodal Controllable Audio-Video Generation with Zero-Shot Voice Cloning**|联合音频-视频生成旨在合成同步的多感官内容，但当前的统一模型难以实现细粒度的声学控制，特别是对于身份保留语音。现有方法要么因级联生成而遭受时间错位，要么缺乏在联合合成框架内执行零样本语音克隆的能力。在这项工作中，我们提出了 MM-Sonate，一种多模态流匹配框架，它将可控音频-视频联合生成与零样本语音克隆功能相结合。与依赖于粗略语义描述的先前作品不同，MM-Sonate 利用统一的指令音素输入来强制执行严格的语言和时间对齐。为了实现零样本语音克隆，我们引入了一种音色注入机制，可以有效地将说话者身份与语言内容分离。此外，为了解决多模态设置中标准无分类器引导的局限性，我们提出了一种基于噪声的负调节策略，该策略利用自然噪声先验来显着增强声保真度。实证评估表明，MM-Sonate 在联合生成基准中建立了新的最先进的性能，在唇形同步和语音清晰度方面显着优于基线，同时实现了与专门的文本到语音系统相当的语音克隆保真度。|[2601.01568](http://arxiv.org/abs/2601.01568)|null|\n",
        "2601.01528": "|**2026-01-04**|**DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving**|视频生成模型作为世界模型的一种形式，已成为人工智能领域最令人兴奋的前沿之一，它让智能体能够通过对复杂场景的时间演化进行建模来想象未来。在自动驾驶中，这一愿景催生了驾驶世界模型：想象自我和代理未来的生成模拟器，实现可扩展的模拟、极端情况的安全测试以及丰富的合成数据生成。然而，尽管研究活动快速增长，但该领域缺乏严格的基准来衡量进展和指导优先事项。现有的评估仍然有限：通用视频指标忽视了安全关键的成像因素；轨迹的合理性很少被量化；时间和代理级别的一致性被忽略；自我调节的可控性被忽略。此外，当前的数据集无法涵盖现实世界部署所需的条件的多样性。为了解决这些差距，我们推出了 DrivingGen，这是第一个生成驾驶世界模型的综合基准测试。 DrivingGen 将来自驾驶数据集和互联网规模视频源的多样化评估数据集（涵盖不同的天气、一天中的时间、地理区域和复杂的操作）与一套新指标相结合，共同评估视觉真实性、轨迹合理性、时间一致性和可控性。对 14 个最先进模型进行基准测试揭示了明显的权衡：通用模型看起来更好，但违反物理原理，而驾驶专用模型可以真实地捕捉运动，但视觉质量落后。 DrivingGen 提供统一的评估框架，以培育可靠、可控和可部署的驾驶世界模型，从而实现可扩展的模拟、规划和数据驱动的决策。|[2601.01528](http://arxiv.org/abs/2601.01528)|null|\n",
        "2601.01352": "|**2026-01-04**|**Slot-ID: Identity-Preserving Video Generation from Reference Videos via Slot-Based Temporal Identity Encoding**|制作保留用户指定身份的即时忠实视频仍然具有挑战性：模型需要从稀疏参考中推断面部动态，同时平衡身份保留和运动自然度之间的紧张关系。对单个图像进行调节完全忽略了时间特征，这会导致姿势锁定运动、不自然的扭曲以及当视点和表情发生变化时出现“平均”面孔。为此，我们引入了扩散变换器视频生成器的身份条件变体，它使用短参考视频而不是单个肖像。我们的关键想法是将动态纳入参考文献中。一个短片揭示了特定主题的模式，例如微笑如何形成、姿势和灯光。从这个片段中，Sinkhorn 路由编码器学习紧凑的身份令牌，捕获特征动态，同时保持预训练的骨干网兼容。尽管仅添加了轻量级调节，但该方法始终可以提高大姿势变化和富有表现力的面部行为下的身份保留，同时在不同的主题和提示中保持即时的忠实性和视觉真实感。|[2601.01352](http://arxiv.org/abs/2601.01352)|null|\n",
        "2601.00996": "|**2026-01-02**|**VEAT Quantifies Implicit Associations in Text-to-Video Generator Sora and Reveals Challenges in Bias Mitigation**|Sora 等文本转视频 (T2V) 生成器引发了人们对生成的内容是否反映社会偏见的担忧。我们通过引入视频嵌入关联测试 (VEAT) 和单类别 VEAT (SC-VEAT)，将嵌入关联测试从文字和图像扩展到视频。我们通过从广泛使用的基线（包括隐式关联测试（IAT）场景和 OASIS 图像类别）重现关联的方向和大小来验证这些方法。然后，我们对 17 个职业和 7 个奖项中的种族（非洲裔美国人与欧洲裔美国人）和性别（女性与男性）与效价（愉快与不愉快）的关联进行了量化。 Sora 视频将欧洲裔美国人和女性更多地与愉悦联系在一起（d>0.8）。效应大小与现实世界的人口分布相关：职业中男性和白人的百分比（r=0.93，r=0.83）以及获奖者中男性和非黑人的百分比（r=0.88，r=0.99）。应用明确的去偏见提示通常会降低效应大小的大小，但可能会适得其反：两种与黑人相关的职业（看门人、邮政服务）在去偏见后变得更加与黑人相关。总之，这些结果表明，如果不严格评估和负责任地部署，易于访问的 T2V 发生器实际上可能会放大代表性危害。|[2601.00996](http://arxiv.org/abs/2601.00996)|null|\n",
        "2601.00943": "|**2026-01-02**|**PhyEduVideo: A Benchmark for Evaluating Text-to-Video Models for Physics Education**|生成式人工智能模型，特别是文本到视频（T2V）系统，通过自动创建引人入胜且直观的视觉解释，为改变科学教育提供了一条有前途的途径。在这项工作中，我们通过引入解释性视频生成的专用基准，迈出了评估其在物理教育中的潜力的第一步。该基准旨在评估 T2V 模型通过视觉插图传达核心物理概念的能力。我们基准测试中的每个物理概念都被分解为细粒度的教学点，每个点都附有精心设计的提示，旨在对教学点进行视觉解释。 T2V 模型根据其根据这些提示生成准确视频的能力进行评估。我们的目标是系统地探索使用 T2V 模型生成高质量、符合课程的教育内容的可行性，为实现由人工智能驱动的可扩展、可访问和个性化的学习体验铺平道路。我们的评估表明，当前的模型可以生成视觉上连贯的视频，具有平滑的运动和最小的闪烁，但其概念准确性不太可靠。力学、流体和光学等领域的表现令人鼓舞，但模型在电磁学和热力学方面遇到了困难，这些领域的抽象相互作用很难描述。这些发现强调了教育视频生成中视觉质量和概念正确性之间的差距。我们希望这个基准测试能够帮助社区缩小这一差距，并转向能够大规模提供准确、符合课程的物理内容的 T2V 系统。基准测试和随附的代码库可在 https://github.com/meghamariamkm/PhyEduVideo 上公开获取。|[2601.00943](http://arxiv.org/abs/2601.00943)|null|\n",
        "2601.02358": "|**2026-01-05**|**VINO: A Unified Visual Generator with Interleaved OmniModal Context**|我们推出了 VINO，一个统一的视觉生成器，可以在单个框架内执行图像和视频生成和编辑。 VINO 不依赖特定于任务的模型或每种模态的独立模块，而是使用以文本、图像和视频为条件的共享扩散主干，从而在一个模型下实现广泛的视觉创建和编辑任务。具体来说，VINO 将视觉语言模型 (VLM) 与多模态扩散变压器 (MMDiT) 结合起来，其中多模态输入被编码为交错条件标记，然后用于指导扩散过程。该设计支持多参考基础、长格式指令遵循以及跨静态和动态内容的一致身份保留，同时避免特定于模态的架构组件。为了训练这样一个统一的系统，我们引入了一个多阶段训练管道，该管道逐步将视频生成基础模型扩展为能够进行图像和视频输入和输出的统一的多任务生成器。在不同的生成和编辑基准中，VINO 展示了强大的视觉质量、忠实的指令遵循、改进的参考和属性保留以及更可控的多身份编辑。我们的结果强调了实现可扩展的统一视觉生成的实用路径，以及交错的上下文计算作为通用视觉创建基础的前景。|[2601.02358](http://arxiv.org/abs/2601.02358)|null|\n",
        "2601.02204": "|**2026-01-05**|**NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation**|我们提出了 NextFlow，一个统一的仅解码器自回归变压器，在 6 万亿个交错的文本图像离散标记上进行训练。通过利用统一自回归架构中的统一视觉表示，NextFlow 原生激活多模态理解和生成功能，解锁图像编辑、交错内容和视频生成的能力。受模态独特性质的启发（其中文本是严格顺序的，而图像本质上是分层的），我们保留文本的下一个标记预测，但采用下一个尺度预测进行视觉生成。这与传统的光栅扫描方法不同，只需 5 秒即可生成 1024x1024 图像，比同类 AR 模型快几个数量级。我们通过强大的训练方法解决多尺度生成的不稳定性。此外，我们引入了强化学习的前缀调整策略。实验表明，NextFlow 在统一模型中实现了最先进的性能，并且在视觉质量方面可与专门的扩散基线相媲美。|[2601.02204](http://arxiv.org/abs/2601.02204)|null|\n",
        "2601.02125": "|**2026-01-05**|**SingingBot: An Avatar-Driven System for Robotic Face Singing Performance**|为机器人面孔配备唱歌功能对于具有同理心的人机交互至关重要。然而，现有的机器人面部驾驶研究主要集中在对话或模仿静态表情上，难以满足持续的情感表达和歌唱连贯性的高要求。为了解决这个问题，我们提出了一种新颖的化身驱动框架来吸引机器人唱歌。我们首先利用嵌入广泛人类先验的肖像视频生成模型来合成生动的歌唱化身，提供可靠的表达和情感引导。随后，这些面部特征通过跨越广泛表达空间的面向语义的映射功能转移到机器人。此外，为了定量评估机器人歌唱的情感丰富度，我们提出了情感动态范围指标来衡量效价-唤醒空间内的情感宽度，揭示了广泛的情感范围对于吸引人的表演至关重要。综合实验证明，我们的方法在保持唇音同步的同时实现了丰富的情感表达，显着优于现有方法。|[2601.02125](http://arxiv.org/abs/2601.02125)|null|\n",
        "2601.02107": "|**2026-01-05**|**MagicFight: Personalized Martial Arts Combat Video Generation**|在通用文本到视频生成的激增中，个性化人类视频生成领域取得了显着的进步，主要集中在单人场景上。然而，据我们所知，两人互动的领域，特别是在武术格斗的背景下，仍然是未知的。我们发现了一个重大差距：现有的单人舞蹈生成模型不足以捕捉两名交战战士的微妙性和复杂性，从而导致身份混乱、肢体异常和动作不匹配等挑战。为了解决这个问题，我们引入了一项开创性的新任务：个性化武术战斗视频生成。我们的方法 MagicFight 是专门为克服这些障碍而设计的。鉴于这项开创性任务，我们面临着缺乏适当的数据集的问题。因此，我们使用游戏物理引擎 Unity 生成定制数据集，精心制作大量 3D 角色、武术动作和场景，旨在表现战斗的多样性。 MagicFight 改进并调整了现有的模型和策略，以生成高保真两人战斗视频，保持个人身份并确保无缝、连贯的动作序列，从而为交互式视频内容创建领域的未来创新奠定基础。   网站：https://MingfuYAN.github.io/MagicFight/ 数据集：https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta|[2601.02107](http://arxiv.org/abs/2601.02107)|null|\n"
    },
    "3D": {
        "2512.24742": "|**2025-12-31**|**Splatwizard: A Benchmark Toolkit for 3D Gaussian Splatting Compression**|最近出现的 3D 高斯分布 (3DGS) 标志着实时新颖视图合成的重大突破。然而，基于 3DGS 的算法的快速普及迫切需要标准化和综合的评估工具，尤其是压缩任务。现有的基准测试通常缺乏全面评估不同方法的独特特征所需的具体指标，例如渲染速度、率失真权衡、内存效率和几何精度。为了弥补这一差距，我们推出了 Splatwizard，这是一个专门为 3DGS 压缩模型进行基准测试而设计的统一基准测试工具包。 Splatwizard 提供了一个易于使用的框架来实现新的 3DGS 压缩模型并利用先前工作提出的最先进的技术。此外，框架中还包含一个集成管道，可自动计算关键性能指标，包括基于图像的质量指标、重建网格的倒角距离、渲染帧速率和计算资源消耗。代码可在 https://github.com/splatwizard/splatwizard 获取|[2512.24742](http://arxiv.org/abs/2512.24742)|null|\n",
        "2512.24647": "|**2025-12-31**|**Solving the inverse Source Problems for wave equation with final time measurements by a data driven approach**|本文开发了一种离散数据驱动的方法，用于通过最终时间测量来解决波动方程的逆源问题。重点关注 $L^2$-Tikhonov 正则化方法，我们使用噪声离散空间观测来分析其在两种不同噪声模型下的收敛性。通过利用前向算子的谱分解并将噪声分离技术引入变分框架，我们为重构解 $u$ 和源项 $f$ 建立了误差界限，而不需要经典源条件。此外，源误差的预期收敛速度是在较弱的拓扑中导出的。我们还将分析扩展到具有有限元离散化的完全离散情况，表明总体误差仅取决于噪声水平、正则化参数、时间步长和空间网格大小。这些估计为在没有先验信息的情况下以数据驱动的方式选择最佳正则化参数提供了基础。数值实验验证了理论结果并证明了所提算法的效率。|[2512.24647](http://arxiv.org/abs/2512.24647)|null|\n",
        "2512.24577": "|**2025-12-31**|**QAOA-MaxCut has barren plateaus for almost all graphs**|近年来，QAOA 一直是深入研究的主题，但相对应的动态李代数 (DLA)——VQA 表达性和可训练性的关键指标——除了高度对称的实例之外，仍然知之甚少。指数级缩放的 DLA 维度与优化领域中所谓的贫瘠高原 (BP) 的存在相关，这使得训练变得棘手。在这项工作中，我们研究了应用于规范 MaxCut 的 QAOA 的 DLA，适用于加权图和未加权图。对于加权图，我们表明，当从连续分布中提取权重时，对于除路径和循环之外的所有连通图，DLA 维数几乎肯定会增长为 $θ(4^n)$。在更常见的未加权设置中，我们表明，除指数消失部分之外的所有图都渐近地具有 $ θ(4 ^ n) $ 大 DLA 维度。还确定了相应 DLA 的整个简单李代数分解，从中我们证明损失函数的方差为 $O(1/2^n)$，这意味着这些加权和未加权图上的 QAOA 都受到 BP 的影响。此外，我们还给出了 DLA 具有指数维数的图族的显式构造，包括 MaxCut 在 $\\mathsf P$ 中的情况。我们对未加权情况的证明基于许多分裂引理和 DLA 自由条件，这些条件允许人们将极其复杂的李代数问题转换为合适的图论问题。这些构成了新算法的基础，该算法计算此类 DLA 的速度比以前的方法快几个数量级，从而将标准硬件上的运行时间从几天缩短到几秒钟。我们将此算法应用于 MQLib，这是一个经典的 MaxCut 基准套件，覆盖超过 3,500 个实例，最多 53,130 个顶点，并发现，忽略边权重，至少 75% 的实例拥有维度至少为 $2^{128}$ 的 DLA。|[2512.24577](http://arxiv.org/abs/2512.24577)|null|\n",
        "2512.24564": "|**2025-12-31**|**CPR: Causal Physiological Representation Learning for Robust ECG Analysis under Distribution Shifts**|用于心电图 (ECG) 诊断的深度学习模型已经取得了显着的准确性，但在对抗对抗性扰动方面表现出脆弱性，特别是模仿生物形态的平滑对抗性扰动 (SAP)。现有的防御措施面临着严峻的困境：对抗训练（AT）提供了鲁棒性，但会产生令人望而却步的计算负担，而随机平滑（RS）等经过认证的方法会引入显着的推理延迟，使得它们对于实时临床监测来说不切实际。我们认为这种脆弱性源于模型对非鲁棒虚假相关性的依赖，而不是不变的病理特征。为了解决这个问题，我们提出因果生理表征学习（CPR）。与不受语义限制的标准去噪方法不同，CPR 在因果解开框架内结合了生理结构先验。通过结构因果模型 (SCM) 对心电图生成进行建模，CPR 强制实施结构干预，将不变的病理形态（P-QRS-T 复合波）与非因果伪影严格分开。 PTB-XL 的经验结果表明，CPR 明显优于标准临床预处理方法。具体来说，在 SAP 攻击下，CPR 的 F1 得分为 0.632，超过 Median Smoothing (0.541 F1) 9.1%。至关重要的是，CPR 与随机平滑经过认证的稳健性相匹配，同时保持单遍推理效率，在稳健性、效率和临床可解释性之间提供卓越的权衡。|[2512.24564](http://arxiv.org/abs/2512.24564)|null|\n",
        "2512.24534": "|**2025-12-31**|**BF-APNN: A Low-Memory Method for Accelerating the Solution of Radiative Transfer Equations**|辐射传递方程（RTE）表现出高维和多尺度特征，使得传统数值方法计算量大。现有的深度学习方法在低维或线性 RTE 中表现良好，但在高维或非线性 RTE 中仍然面临许多挑战。为了克服这些挑战，我们提出了基函数渐近保持神经网络（BF-APNN），该框架继承了辐射传递渐近保持神经网络（RT-APNN）的优点并加速了求解过程。通过对微观组件采用基函数扩展（源自微观-宏观分解），BF-APNN 有效减轻了训练期间与评估高维积分相关的计算负担。数值实验涉及具有非线性、不连续性和多尺度行为特征的具有挑战性的 RTE 场景，结果表明，与 RT-APNN 相比，BF-APNN 大大减少了训练时间，同时保持了较高的解精度。此外，BF-APNN 在解决复杂的高维 RTE 问题方面表现出卓越的性能，凸显了其作为辐射传输计算的强大工具的潜力。|[2512.24534](http://arxiv.org/abs/2512.24534)|null|\n",
        "2512.25075": "|**2025-12-31**|**SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time**|我们提出了 SpaceTimePilot，这是一种视频扩散模型，可以解开空间和时间以实现可控的生成渲染。给定单目视频，SpaceTimePilot 可以在生成过程中独立改变摄像机视点和运动序列，重新渲染场景，以实现跨空间和时间的连续和任意探索。为了实现这一目标，我们在扩散过程中引入了一种有效的动画时间嵌入机制，允许对输出视频相对于源视频的运动序列进行显式控制。由于没有数据集提供具有连续时间变化的同一动态场景的配对视频，我们提出了一种简单而有效的时间扭曲训练方案，该方案重新利用现有的多视图数据集来模拟时间差异。该策略有效地监督模型学习时间控制并实现鲁棒的时空解缠结。为了进一步提高双重控制的精度，我们引入了两个额外的组件：改进的相机调节机制，允许从第一帧开始改变相机，以及CamxTime，第一个合成时空全覆盖渲染数据集，可在场景内提供完全自由的时空视频轨迹。对时间扭曲方案和 CamxTime 数据集的联合训练可以产生更精确的时间控制。我们在现实世界和合成数据上评估了 SpaceTimePilot，与之前的工作相比，展示了清晰的时空解离和强大的结果。项目页面：https://zheninghuang.github.io/Space-Time-Pilot/ 代码：https://github.com/ZheningHuang/spacetimepilot|[2512.25075](http://arxiv.org/abs/2512.25075)|null|\n",
        "2512.25071": "|**2025-12-31**|**Edit3r: Instant 3D Scene Editing from Sparse Unposed Images**|我们提出了 Edit3r，这是一个前馈框架，可以从未摆姿势、视图不一致、指令编辑的图像中一次性重建和编辑 3D 场景。与之前需要针对场景进行优化的方法不同，Edit3r 直接预测指令对齐的 3D 编辑，从而无需优化或姿态估计即可实现快速且逼真的渲染。训练这种模型的一个关键挑战在于缺乏用于监督的多视图一致编辑图像。我们通过（i）基于 SAM2 的重新着色策略来解决这个问题，该策略生成可靠的、跨视图一致的监督，以及（ii）不对称输入策略，将重新着色的参考视图与原始辅助视图配对，鼓励网络融合和对齐不同的观察结果。据推断，我们的模型可以有效地处理通过 InstructPix2Pix 等 2D 方法编辑的图像，尽管在训练期间没有接触到此类编辑。对于大规模定量评估，我们引入了DL3DV-Edit-Bench，这是一个基于DL3DV测试分割构建的基准测试，具有20个不同的场景、4种编辑类型和总共100个编辑。全面的定量和定性结果表明，与最近的基线相比，Edit3r 实现了卓越的语义对齐和增强的 3D 一致性，同时以显着更高的推理速度运行，使其在实时 3D 编辑应用程序中具有广阔的前景。|[2512.25071](http://arxiv.org/abs/2512.25071)|null|\n",
        "2512.24986": "|**2025-12-31**|**PhysTalk: Language-driven Real-time Physics in 3D Gaussian Scenes**|逼真的视觉模拟无处不在，但它们的创作需要计算时间、渲染和专业的动画知识。从文本输入生成开放词汇视觉效果成为一种有前途的解决方案，可以释放巨大的创造潜力。然而，当前的管道缺乏物理现实性和有效的语言接口，需要缓慢的离线优化。相比之下，PhysTalk 采用 3D 高斯溅射 (3DGS) 场景作为输入，并将任意用户提示转换为实时、基于物理的交互式 4D 动画。大型语言模型 (LLM) 生成可执行代码，通过轻量级代理和粒子动力学直接修改 3DGS 参数。值得注意的是，PhysTalk 是第一个将 3DGS 与物理模拟器直接耦合的框架，无需依赖耗时的网格提取。在保留开放词汇的同时，该设计通过对任意多材质对象的碰撞感知、基于物理的操作来实现交互式 3D 高斯动画。最后，PhysTalk 无需训练且计算量轻：这使得 4D 动画可以广泛使用，并将这些工作流程从“渲染和等待”范式转变为与现代物理信息管道的交互式对话。|[2512.24986](http://arxiv.org/abs/2512.24986)|null|\n",
        "2512.24985": "|**2025-12-31**|**DarkEQA: Benchmarking Vision-Language Models for Embodied Question Answering in Low-Light Indoor Environments**|视觉语言模型（VLM）越来越多地被采用作为实体代理的中央推理模块。现有的基准测试是在理想、光线充足的条件下评估其功能，但强大的 24/7 运行要求在各种视觉退化情况下都具有性能，包括夜间低光条件或黑暗环境中——这是一个在很大程度上被忽视的核心必要条件。为了解决这一尚未充分探索的挑战，我们提出了 DarkEQA，这是一个开源基准，用于在多级低光条件下评估 EQA 相关的感知基元。 DarkEQA 通过在受控降级下评估以自我为中心的观察的问答来隔离感知瓶颈，从而实现归因稳健性分析。 DarkEQA 的一个关键设计特点是其物理保真度：在线性 RAW 空间中对视觉退化进行建模，模拟基于物理的照明下降和传感器噪声，然后采用 ISP 启发的渲染管道。我们通过评估各种最先进的 VLM 和低光图像增强 (LLIE) 模型来展示 DarkEQA 的实用性。我们的分析系统地揭示了 VLM 在这些具有挑战性的视觉条件下运行时的局限性。我们的代码和基准数据集将在接受后发布。|[2512.24985](http://arxiv.org/abs/2512.24985)|null|\n",
        "2512.24970": "|**2025-12-31**|**Random Batch Sum-of-Gaussians Method for Molecular Dynamics of Born-Mayer-Huggins Systems**|玻恩-梅耶-哈金斯 (BMH) 势结合了库仑相互作用、色散和短程指数斥力，广泛用于熔盐等离子材料。然而，BMH 系统的大规模分子动力学模拟通常受到计算、通信和内存成本的限制。我们最近提出了随机批量高斯和（RBSOG）方法，该方法通过使用高斯和（SOG）分解将势分解为短程和长程部分，并在傅里叶空间中对长程部分应用重要性采样，从而加速库仑计算。在这项工作中，我们将 RBSOG 扩展到 BMH 系统，并结合随机批处理列表 (RBL) 方案来进一步加速短程部分，从而产生一个统一的框架，用于具有 BMH 潜力的高效模拟。 SOG 分解和 RBL 的结合能够有效且可扩展地处理 BMH 系统中的长程和短程相互作用，特别是 RBL 可以通过随机批量邻居列表很好地处理中程指数排斥和色散。提供误差估计以显示 RBL 力的理论收敛性。我们在 2048 美元的 CPU 核心上使用高达 5\\times10^6$ 原子的熔融氯化钠和混合碱金属卤化物来评估该框架。与基于 Ewald 的粒子-粒子粒子网格方法和仅 RBSOG 方法相比，我们的方法在使用 $1000$ 核心时分别实现了大约 $4\\sim10\\times$ 和 $2\\times$ 加速，在相同水平的结构和热力学精度下，并且内存使用量减少。这些结果证明了我们的方法在远程交互 MD 模拟的准确性和可扩展性方面具有有吸引力的性能。|[2512.24970](http://arxiv.org/abs/2512.24970)|null|\n",
        "2512.24951": "|**2025-12-31**|**Laser intracavity absorption magnetometry for optical quantum sensing**|腔内吸收光谱 (ICAS) 是一种成熟的技术，用于以超高灵敏度检测微弱吸收信号。在这里，我们将这一概念扩展到使用金刚石中的氮空位（NV）中心的磁力测量。我们引入了激光腔内吸收磁力计（LICAM），这一概念原则上适用于更广泛的光学量子传感器，包括光泵磁力计。使用可自我维持运行的电驱动、边缘发射二极管激光器，我们证明 LICAM 可以实现在环境条件下运行的高灵敏度磁力计。在接近激光阈值时，与传统的单通道几何结构相比，我们的光学对比度提高了 475 倍，磁灵敏度提高了 180 倍。单模二极管激光器的速率方程模型准确地描述了实验结果。根据我们的测量，我们确定了 $\\mathrm{pT}\\,\\mathrm{Hz}^{-1/2}$ 范围内的预计散粒噪声限制灵敏度，并表明，通过实际设备的改进，可以实现低至 $\\mathrm{fT}\\,\\mathrm{Hz}^{-1/2}$ 范围的灵敏度。|[2512.24951](http://arxiv.org/abs/2512.24951)|null|\n",
        "2512.24848": "|**2025-12-31**|**PrivacyBench: A Conversational Benchmark for Evaluating Privacy in Personalized AI**|个性化人工智能代理依赖于对用户数字足迹的访问，其中通常包括来自私人电子邮件、聊天和购买历史记录的敏感数据。然而，这种访问会带来根本性的社会和隐私风险：缺乏社会情境意识的系统可能会无意中泄露用户秘密，从而威胁到数字福祉。我们引入了 PrivacyBench，这是一个基准，具有包含嵌入式秘密的基于社会的数据集和用于衡量秘密保存的多轮对话评估。测试检索增强生成 (RAG) 助手表明，他们在高达 26.56% 的交互中泄露秘密。隐私意识提示可将泄漏率降低至 5.12%，但该措施仅提供部分缓解。检索机制继续不加区别地访问敏感数据，这将隐私保护的全部负担转移到了生成器身上。这会造成单点故障，导致当前架构不适合大规模部署。我们的研究结果强调迫切需要结构性、隐私设计保障措施，以确保为每个人提供一个道德和包容的网络。|[2512.24848](http://arxiv.org/abs/2512.24848)|null|\n",
        "2512.24827": "|**2025-12-31**|**Discovering Coordinated Joint Options via Inter-Agent Relative Dynamics**|暂时延长的操作提高了在单代理环境中探索和计划的能力。在多智能体设置中，联合状态空间随着智能体数量的指​​数增长使得协调行为变得更加有价值。然而，同样的指数增长使得多代理选项的设计特别具有挑战性。现有的多智能体选项发现方法通常会产生松散耦合或完全独立的行为，从而牺牲协调性。为了解决这些限制，我们描述了一种多代理选项发现的新方法。具体来说，我们提出了一种联合状态抽象，它压缩状态空间，同时保留发现强协调行为所需的信息。我们的方法建立在归纳偏差的基础上，即代理状态的同步为缺乏明确目标的情况下的协调提供了自然的基础。我们首先近似与团队最大对齐的虚拟状态，即 \\textit{Fermat} 状态，并用它来定义 \\textit{spreadness} 的度量，捕获每个单独状态维度上的团队级别的错位。基于这种表示，我们然后采用神经图拉普拉斯估计器来导出捕获代理之间状态同步模式的选项。我们评估了两个多智能体域中多个场景的结果选项，表明与替代选项发现方法相比，它们产生了更强的下游协调能力。|[2512.24827](http://arxiv.org/abs/2512.24827)|null|\n",
        "2512.24794": "|**2025-12-31**|**Nonlinear Noise2Noise for Efficient Monte Carlo Denoiser Training**|Noise2Noise 方法允许使用成对的输入和目标图像来训练基于机器学习的降噪器，其中输入和目标都可能有噪声。这消除了使用很难获得的干净目标图像进行训练的需要。然而，Noise2Noise 训练有一个主要限制：应用于噪声目标的非线性函数会扭曲结果。出现这种偏差是因为非线性使得噪声目标的期望值与干净的目标图像不同。由于非线性函数在图像处理中很常见，因此避免使用非线性函数会限制可对噪声目标执行的预处理类型。我们的主要见解是，某些非线性函数可以应用于噪声目标，而不会给结果带来明显的偏差。我们开发了一个理论框架来分析这些非线性的影响，并描述一类具有最小偏差的非线性函数。   我们展示了我们对蒙特卡罗渲染生成的高动态范围（HDR）图像进行去噪的方法。 Noise2Noise 训练在处理 HDR 图像时可能会遇到问题，训练过程会被异常值淹没并且表现不佳。我们考虑解决这些训练问题的常用方法：将非线性色调映射函数应用于模型输出和目标图像以减少其动态范围。由于涉及非线性，该方法之前被认为与 Noise2Noise 训练不兼容。我们表明，损失函数和色调映射函数的某些组合可以减少异常值的影响，同时引入最小的偏差。我们将我们的方法应用于现有的基于机器学习的蒙特卡罗降噪器，其中原始实现是使用高样本计数参考图像进行训练的。我们的结果接近原始实现的结果，但仅使用噪声训练数据生成。|[2512.24794](http://arxiv.org/abs/2512.24794)|null|\n",
        "2512.24763": "|**2025-12-31**|**UniC-Lift: Unified 3D Instance Segmentation via Contrastive Learning**|3D 高斯散射 (3DGS) 和神经辐射场 (NeRF) 具有先进的新颖视图合成。最近的方法将多视图 2D 分割扩展到 3D，从而实现实例/语义分割以更好地理解场景。一个关键挑战是跨视图的 2D 实例标签不一致，导致 3D 预测效果不佳。现有方法采用两阶段方法，其中一些方法依赖于超参数敏感聚类的对比学习，而另一些方法则预处理标签以确保一致性。我们提出了一个统一的框架，合并这些步骤，通过引入用于高斯原语分割的可学习特征嵌入来减少训练时间并提高性能。然后，通过新颖的“嵌入到标签”过程，将这种嵌入有效地解码为实例标签，从而有效地集成优化。虽然这个统一的框架提供了巨大的好处，但我们在对象边界观察到了伪影。为了解决对象边界问题，我们提出沿着这些边界进行硬挖掘样本。然而，直接将硬挖掘应用于特征嵌入被证明是不稳定的。因此，我们在计算三元组损失之前对栅格化特征嵌入应用线性层，这可以稳定训练并显着提高性能。我们的方法在 ScanNet、Replica3D 和 Messy-Rooms 数据集上的定性和定量优于基线。|[2512.24763](http://arxiv.org/abs/2512.24763)|null|\n",
        "2601.00796": "|**2026-01-02**|**AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction**|从单目视频重建动态 3D 场景需要同时捕获高频外观细节和时间连续运动。使用单个高斯原语的现有方法受到其低通滤波性质的限制，而标准 Gabor 函数会引入能量不稳定。此外，缺乏时间连续性约束通常会导致插值期间出现运动伪影。我们提出了 AdaGaR，一个统一的框架，解决显式动态场景建模中的频率自适应性和时间连续性问题。我们引入了自适应 Gabor 表示，通过可学习的频率权重和自适应能量补偿来扩展高斯模型，以平衡细节捕捉和稳定性。为了实现时间连续性，我们采用具有时间曲率正则化的三次 Hermite 样条来确保平滑的运动演化。结合深度估计、点跟踪和前景掩模的自适应初始化机制在早期训练中建立稳定的点云分布。 Tap-Vid DAVIS 上的实验展示了最先进的性能（PSNR 35.49、SSIM 0.9433、LPIPS 0.0723）以及跨帧插值、深度一致性、视频编辑和立体视图合成的强大泛化能力。项目页面：https://jiewenchan.github.io/AdaGaR/|[2601.00796](http://arxiv.org/abs/2601.00796)|null|\n",
        "2601.00702": "|**2026-01-02**|**DefVINS: Visual-Inertial Odometry for Deformable Scenes**|可变形场景违反了支撑经典视觉惯性里程计 (VIO) 的刚性假设，当变形主导视觉视差时，通常会导致局部非刚性运动过度拟合或严重漂移。我们引入了 DefVINS，一种视觉惯性里程计框架，它明确地将刚性、IMU 锚定状态与由嵌入变形图表示的非刚性扭曲分开。该系统使用标准 VIO 程序进行初始化，该程序修复了重力、速度和 IMU 偏差，之后随着估计的条件良好，逐渐激活非刚性自由度。包括可观测性分析，以描述惯性测量如何限制刚性运动，并在存在变形的情况下使其他不可观测的模式变得可识别。该分析促进了 IMU 锚定的使用，并为基于条件的激活策略提供了信息，该策略可防止不良激励下的不适定更新。烧蚀研究证明了将惯性约束与可观察性变形激活相结合的好处，从而提高了非刚性环境下的鲁棒性。|[2601.00702](http://arxiv.org/abs/2601.00702)|null|\n",
        "2601.00678": "|**2026-01-02**|**Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians**|人类擅长仅凭一张图像来预测场景的未来动态。能够模仿这种能力的视频生成模型是智能系统的重要组成部分。最近的方法提高了单图像条件视频生成中的时间相干性和 3D 一致性。然而，这些方法通常缺乏强大的用户可控性，例如修改相机路径，限制了它们在实际应用中的适用性。大多数现有的相机控制的图像到视频模型都难以准确建模相机运动、保持时间一致性和保持几何完整性。利用显式中间 3D 表示可实现与给定摄像机轨迹对齐的连贯视频生成，从而提供了一种有前景的解决方案。尽管这些方法通常使用 3D 点云来渲染场景并在后期引入对象运动，但尽管允许精确控制相机运动，但这种两步过程仍然无法实现完全的时间一致性。我们提出了一种新颖的框架，在单次前向传递中给定单个图像的情况下，构建 3D 高斯场景表示并对合理的对象运动进行采样。这使得能够快速生成相机引导的视频，而无需迭代去噪将对象运动注入渲染帧。在 KITTI、Waymo、RealEstate10K 和 DL3DV-10K 数据集上进行的大量实验表明，我们的方法实现了最先进的视频质量和推理效率。该项目页面位于 https://melonienimasha.github.io/Pixel-to-4D-Website。|[2601.00678](http://arxiv.org/abs/2601.00678)|null|\n",
        "2601.00599": "|**2026-01-02**|**The thermodynamics of pressure activated assembly of supramolecules in isochoric and isobaric systems**|冷冻保存的功效受到难以获得足够高的细胞内冷冻保护溶质浓度而不在加载过程中引起渗透损伤或化学毒性的限制。这项热力学研究引入了一种将冷冻保护剂直接或通过血管灌注输送到细胞中的新概念机制。在此框架中，通过压力激活由冷冻保护剂单体或低聚物组成的膜渗透超分子组装体的分解，原位产生高浓度的细胞内冷冻保护溶质，可以实现有效的冷冻保护。这些超分子最初以低浓度存在，预计通过被动分配或内吞作用以最小的渗透效应进入细胞，并随后在分解时转化为高细胞内浓度的冷冻保护剂。我们提出，在等容（恒定体积）冷冻过程中固有产生的或在等压（恒定压力）条件下外部施加的升高的静水压力可以使超分子组装体不稳定，其解离状态所占的摩尔体积比组装状态的摩尔体积更小。在等容冷冻下，固定体积内的冰形成会产生显着的压力增加，这是相变的热力学结果，使压力成为由亥姆霍兹自由能控制的因变量。在等压条件下，压力通过吉布斯自由能充当外部控制变量。在这两种配方中，压力激活的分解将膜传输与冷冻保护剂的可用性分离，并能够在冷却或冷冻过程中精确地同步溶质生成，而无需预加载渗透活性溶质。|[2601.00599](http://arxiv.org/abs/2601.00599)|null|\n",
        "2601.00583": "|**2026-01-02**|**HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts**|虽然联邦学习 (FL) 可以在不损害数据隐私的情况下对大型语言模型 (LLM) 进行微调，但 LLM 的庞大规模使得设备上培训对于资源受限的客户端（例如移动设备）来说不切实际。因此，专家混合（MoE）模型已成为一种计算高效的解决方案，它在模型训练期间仅激活稀疏的专家子集，以在不牺牲性能的情况下减轻计算负担。尽管将 MoE 集成到 FL 微调中具有巨大的潜力，但它仍然面临三个关键挑战：i）为客户选择合适的专家仍然具有挑战性，因为缺乏可靠的指标来衡量每个专家对本地微调性能的影响，ii）跨客户端的异构计算资源严重阻碍了基于 MoE 的 LLM 微调，因为跨不同输入样本的动态专家激活可能会压垮资源受限的设备，以及 iii）特定于客户端的专家子集和路由偏好会破坏全局聚合，其中未对齐专家更新和不一致的门控网络会产生破坏性干扰。为了应对这些挑战，我们提出了 HFedMoE，这是一种基于 MoE 的异构 FL 微调框架，可为每个客户定制专家子集，以实现计算高效的 LLM 微调。具体来说，HFedMoE 根据专家对微调性能的贡献来识别专家的重要性，然后从信息瓶颈的角度自适应地选择专家子集，以与每个客户端的计算预算保持一致。稀疏感知模型聚合策略还旨在聚合主动微调的专家和具有重要性加权贡献的门控参数。大量实验表明 HFedMoE 在训练精度和收敛速度方面优于最先进的基准。|[2601.00583](http://arxiv.org/abs/2601.00583)|null|\n",
        "2601.00552": "|**2026-01-02**|**Tabletop X-ray ghost video of moving objects**|X射线成像广泛应用于临床医学、工业检测和各种科学研究领域。不幸的是，目前使用的大多数 X 射线二维 (2D) 探测器都存在像素数量和读出时间之间的根本权衡问题，这使得它们不适合快速移动物体成像，并且读出死区时间会导致帧丢失。 X 射线重影成像 (XGI) 提供了一种仅使用高灵敏度单像素探测器对物体进行成像的替代方法。然而，现有 XGI 方法的一个关键限制是所需的总采集时间过长，这使得它对于实际应用来说不切实际。在本文中，我们提出了一种基于编码到快速旋转掩模上的随机二进制模式的快速空间调制方案。以高达每秒 200 帧的成像速率和 225 微米的分辨率展示了移动物体的清晰 X 射线可视化。我们的方法首次大大提高了XGI成像速度，为运动物体的X射线成像应用铺平了道路，例如旋转航空发动机的检查和体内医学成像。|[2601.00552](http://arxiv.org/abs/2601.00552)|null|\n",
        "2601.00541": "|**2026-01-02**|**Asymptotic Distribution-Free Tests for Ultra-high Dimensional Parametric Regressions via Projected Empirical Processes and $p$-value Combination**|本文开发了一种基于预测经验过程和 p 值组合来测试稀疏参数回归模型拟合优度的新颖方法，其中协变量维度可能大大超过样本大小。在这种超高维设置中，传统的基于经验过程的检验常常会失败，因为维数灾难或它们对参数估计量的渐近线性和正态性的依赖——这些属性在超高维场景下可能不成立。为了克服这些挑战，我们首先将经典的鞅变换扩展到温和条件下的超高维设置，并基于对单位球体上的任何投影的鞅变换、投影残差标记经验过程构建 Cramer-von Mises 类型检验。鞅变换使该投影检验渐近无分布，并使我们能够仅使用参数估计器的标准收敛率导出其极限分布。虽然在温和条件下，单位球体上的几乎所有投影的投影测试都是一致的，但它仍然可能会遭受特定投影的功率损失。因此，我们进一步采用强大的 p 值组合程序（例如柯西组合）来聚合多个预测的 p 值，从而增强整体稳健性。此外，认识到基于经验过程的测试擅长检测低频信号，而局部平滑测试通常优于高频信号，因此我们提出了一种新颖的混合测试，使用柯西组合聚合这两种方法。由此产生的混合测试对于低频和高频替代方案都很有效。 $\\cdots$|[2601.00541](http://arxiv.org/abs/2601.00541)|null|\n",
        "2601.00535": "|**2026-01-02**|**FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection**|大规模文本到图像（T2I）扩散模型擅长开放域合成，但在精确文本渲染方面仍然存在困难，特别是对于多行布局、密集排版和中文等长尾脚本。先前的解决方案通常需要昂贵的再培训或严格的外部布局限制，这会降低美观性并限制灵活性。我们提出了 \\textbf{FreeText}，这是一种免训练、即插即用的框架，它通过利用 \\emph{Diffusion Transformer (DiT)} 模型的内在机制来改进文本渲染。 \\textbf{FreeText} 将问题分解为 \\emph{写在哪里} 和 \\emph{写什么}。对于 \\emph{where to write}，我们通过从内生图像到文本注意力中读取标记方式的空间属性来定位写入区域，使用类似接收器的标记作为稳定的空间锚点和拓扑感知的细化来生成高置信度的掩模。对于\\emph{写什么}，我们引入了频谱调制字形注入（SGMI），它通过频域带通调制先注入噪声对齐的字形，以加强字形结构并抑制语义泄漏（呈现概念而不是单词）。在 longText-Benchmark、CVTG 和我们的 CLT-Bench 上对 Qwen-Image、FLUX.1-dev 和 SD3 变体进行的广泛实验表明，文本可读性得到了一致的提高，同时在很大程度上保留了语义对齐和美学质量，并且推理开销适中。|[2601.00535](http://arxiv.org/abs/2601.00535)|null|\n",
        "2601.00491": "|**2026-01-01**|**Transfer-learned Kolosov-Muskhelishvili Informed Neural Networks for Fracture Mechanics**|基于物理的神经网络已广泛应用于固体力学问题。然而，平衡控制偏微分方程和边界条件仍然具有挑战性，特别是在断裂力学中，准确的预测很大程度上取决于裂纹尖端附近的精细采样。为了克服这些限制，本研究开发了具有 Williams 丰富功能的 Kolosov-Muskhelishvili 知情神经网络。得益于全纯表示，控制方程可通过构造得到满足，并且只需要边界点进行训练。在一系列基准问题中，Kolosov-Muskhelishvili 知情神经网络与分析法和有限元方法参考文献表现出极好的一致性，对于模式 I 和模式 II 载荷，平均相对误差低于 1\\%，$R^2$ 高于 0.99。此外，使用迁移学习策略将三个裂纹扩展准则（最大切向应力、最大能量释放率和局部对称原理）集成到框架中来预测裂纹扩展方向。所有标准下的预测路径几乎相同，并且迁移学习策略将所需的训练时间减少了 70% 以上。总体而言，开发的框架提供了一种统一、无网格且物理一致的方法，用于准确、高效的裂纹扩展分析。|[2601.00491](http://arxiv.org/abs/2601.00491)|null|\n",
        "2601.00399": "|**2026-01-01**|**A weak Galerkin least squares finite element method for linear convection equations in non-divergence form**|本文针对非散度形式的一阶线性对流方程开发了一种弱伽辽金最小二乘（WG--LS）有限元方法。该方法是使用不连续有限元函数制定的，不需要对对流矢量或反应系数进行任何矫顽力假设。由此产生的离散问题导致对称和正定线性系统，并且适用于一般的多边形和多面体网格。在系数的最小规律性假设下，在合适的能量范数下为 WG--LS 近似建立最优阶误差估计。数值实验验证了理论收敛结果并证明了该方法的准确性和效率。|[2601.00399](http://arxiv.org/abs/2601.00399)|null|\n",
        "2601.01800": "|**2026-01-05**|**Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving**|强化学习 (RL) 在自动驾驶 (AD) 领域显示出巨大的潜力，但其易受扰动的影响仍然是现实世界部署的关键障碍。作为主要对策，对抗性训练通过在对手故意引入扰动的情况下训练 AD 代理来提高策略的稳健性。现有方法通常将交互建模为具有连续攻击的零和游戏。然而，此类设计忽视了代理和对手之间固有的不对称性，无法反映安全关键风险的稀疏性，导致所实现的鲁棒性不足以满足实际的 AD 场景。为了解决这些限制，我们引入了关键性感知的鲁棒强化学习（CARRL），这是一种新颖的对抗性训练方法，用于处理自动驾驶中稀疏的、安全关键的风险。 CARRL 由两个相互作用的部分组成：风险暴露对手 (REA) 和风险目标稳健代理 (RTRA)。我们将 REA 和 RTRA 之间的交互建模为一般和游戏，使 REA 能够专注于暴露安全关键型故障（例如碰撞），而 RTRA 则学会平衡安全性与驾驶效率。 REA 采用解耦优化机制，在预算有限的情况下更好地识别和利用稀疏的安全关键时刻。然而，这种集中攻击不可避免地导致对抗性数据的缺乏。 RTRA 通过双重重放缓冲区共同利用良性和对抗性体验来应对这种稀缺性，并在扰动下强制执行政策一致性以稳定行为。实验结果表明，与最先进的基线方法相比，我们的方法在所有情况下将碰撞率降低了至少 22.66%。|[2601.01800](http://arxiv.org/abs/2601.01800)|null|\n",
        "2601.01784": "|**2026-01-05**|**DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization**|AIGC 技术的快速发展可以通过篡改视频中的小片段来误导观众，从而导致视频级检测不准确且缺乏说服力。因此，旨在精确定位被篡改片段的时间伪造定位（TFL）变得至关重要。然而，现有的方法往往受到\\emph{局部视图}的限制，无法捕获全局异常。为了解决这个问题，我们提出了一个用于时间伪造定位的 \\underline{d} 双流图学习和 \\underline{d}isentanglement 框架（DDNet）。通过协调局部工件的\\emph{时间距离流}和用于远程连接的\\emph{语义内容流}，DDNet 可以防止全局线索被局部平滑性淹没。此外，我们引入了跟踪解缠结和适应（TDA）来隔离通用伪造指纹，并引入跨级特征嵌入（CLFE）来通过层次特征的深度融合构建强大的特征基础。 ForgeryNet 和 TVIL 基准测试表明，我们的方法在 AP@0.95 中比最先进的方法性能高出约 9%，并且跨域鲁棒性显着提高。|[2601.01784](http://arxiv.org/abs/2601.01784)|null|\n",
        "2601.01749": "|**2026-01-05**|**MANGO:Natural Multi-speaker 3D Talking Head Generation via 2D-Lifted Enhancement**|目前音频驱动的3D头部生成方法主要针对单扬声器场景，缺乏自然、双向的听和说交互。实现无缝对话行为（即说和听状态的流畅转换）仍然是一个关键挑战。现有的 3D 对话化身方法依赖于容易出错的伪 3D 标签，无法捕捉细粒度的面部动态。为了解决这些限制，我们引入了一种新颖的两阶段框架 MANGO，它通过交替训练来利用纯图像级监督来减轻伪 3D 标签引入的噪声，从而实现与现实世界对话行为的更好对齐。具体来说，在第一阶段，带有双音频交互模块的基于扩散的变压器对多扬声器音频的自然 3D 运动进行建模。在第二阶段，我们使用快速 3D 高斯渲染器生成高保真图像，并通过交替训练为 3D 运动提供 2D 级光度监控。此外，我们还推出了 MANGO-Dialog，这是一个高质量的数据集，包含 500 多个身份的超过 50 小时的对齐 2D-3D 对话数据。大量实验表明，我们的方法在模拟两人 3D 对话运动方面实现了卓越的准确性和真实性，显着提高了音频驱动头部说话的保真度和可控性。|[2601.01749](http://arxiv.org/abs/2601.01749)|null|\n",
        "2601.01731": "|**2026-01-05**|**A generalized Scharfetter-Gummel scheme for nonlocal cross-diffusion systems**|分析了多维环面上非局域交叉扩散系统的隐式欧拉有限体积格式。这些方程描述了具有排斥或吸引相互作用的种群物种的动态。该数值方案基于非局部通量项的广义 Scharfetter-Gummel 离散化。对于仅可积的核函数，该方案保留了正性、总质量和熵结构。当网格尺寸趋于零时，显示了离散解的存在性及其对连续问题解的收敛性。一个关键的困难是 Scharfetter-Gummel 近似中广义伯努利函数的简并性。这个问题可以通过证明离散费舍尔信息的统一估计来克服，这需要玻尔兹曼和拉奥熵不等式。数值模拟在一维和二维空间维度上说明了该方案的特征。|[2601.01731](http://arxiv.org/abs/2601.01731)|null|\n",
        "2601.01660": "|**2026-01-04**|**Animated 3DGS Avatars in Diverse Scenes with Consistent Lighting and Shadows**|我们提出了一种在动画 3D 高斯泼溅 (3DGS) 头像与 3DGS 场景或与插入静态场景中的动态对象交互时实现一致光照和阴影的方法。我们的主要贡献是深度高斯阴影贴图 (DGSM)，它是经典阴影贴图算法的现代模拟，专为体积 3DGS 表示而定制。基于经典的深度阴影映射思想，我们证明 3DGS 允许沿着光线进行封闭形式的光累积，从而无需网格化即可实现体积阴影计算。对于每个估计的光，我们将同心径向壳上的透射率制成表格，并将其存储在八面体图集中，现代 GPU 可以根据查询实时采样，以减弱受影响的场景高斯分布，从而一致地投射和接收阴影。为了重新照亮移动的头像，我们使用以球谐函数 (SH) 为基础表示的 HDRI 探针来近似局部环境照明，并应用快速每高斯辐射率传输，避免显式 BRDF 估计或离线优化。我们演示了来自 AvatarX 和 ActorsHQ 的化身的环境一致照明，合成到 ScanNet++、DL3DV 和 SuperSplat 场景中，并展示了与插入对象的交互。在单个和多个头像设置中，DGSM 和 SH 重新照明完全在体积 3DGS 表示中运行，产生连贯的阴影和重新照明，同时避免网格化。|[2601.01660](http://arxiv.org/abs/2601.01660)|null|\n",
        "2601.01618": "|**2026-01-04**|**Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation**|长视距机器人操作对于现实世界的部署越来越重要，需要复杂布局中的空间消歧和动态交互下的时间弹性。然而，现有的端到端和分层的视觉-语言-行动（VLA）策略通常依赖于纯文本线索，同时保持计划意图的潜在性，这破坏了杂乱或未指定场景中的参考基础，阻碍了通过闭环交互对长期目标进行有效的任务分解，并通过模糊行动选择背后的基本原理来限制因果解释。为了解决这些问题，我们首先引入 Visual Sketch，这是一种令人难以置信的视觉中间体，可以在机器人当前视图中渲染点、框、箭头和类型化关系，以外部化空间意图，将语言与场景几何连接起来。在 Visual Sketch 的基础上，我们提出了 Action-Sketcher，这是一个 VLA 框架，它在循环的 See-Think-Sketch-Act 工作流程中运行，并通过自适应令牌门控策略进行协调，用于推理触发器、草图修订和动作发布，从而支持反应性校正和人类交互，同时保留实时动作预测。为了实现可扩展的训练和评估，我们利用交错的图像、文本、视觉草图监督和动作序列来策划不同的语料库，并使用多阶段课程方案来训练 Action-Sketcher，该课程方案结合了用于模态统一的交错序列对齐、用于精确语言基础的语言到草图的一致性、以及通过草图到动作强化来增强鲁棒性的模仿学习。对杂乱场景和多对象任务、模拟和现实世界任务进行的大量实验表明，长期成功率有所提高，对动态场景变化的鲁棒性更强，并且通过可编辑草图和逐步计划增强了可解释性。项目网站：https://action-sketcher.github.io|[2601.01618](http://arxiv.org/abs/2601.01618)|null|\n",
        "2601.01433": "|**2026-01-04**|**Adaptive finite difference methods for the Willmore flow: mesh redistribution algorithm and tangential velocity approach**|我们开发了两种自适应有限差分方法用于威尔莫尔流的数值模拟，采用 k 阶后向微分公式 (BDFk) 进行时间离散化，并结合沿演化界面进行动态网格自适应的监控函数。第一种方法基于由监控函数驱动的加权弧长均匀分布策略，以自适应地重新分布网格点。由曲率及其变化构建的自适应监视器选择机制增强了几何复杂性较强的区域的空间分辨率，同时保留了网格规律性。第二种方法通过将切向速度合并到威尔莫尔流中来消除显式重新参数化，并将网格重新分布固有地嵌入到几何演化中。我们进一步为第二种方法开发了能量稳定校正算法，以在理论层面保证离散能量稳定性。在这两种方法中，监控功能都是自适应框架的核心组件，对基本的几何信息（例如曲率和曲率变化）进行编码，以指导网格细化和重新分布。大量数值实验表明，所提出的基于 BDFk 的自适应方案能够准确捕获 Willmore 流的几何演化，并对涉及复杂界面几何形状的问题表现出出色的鲁棒性和计算效率。|[2601.01433](http://arxiv.org/abs/2601.01433)|null|\n",
        "2601.00939": "|**2026-01-04**|**ShadowGS: Shadow-Aware 3D Gaussian Splatting for Satellite Imagery**|3D 高斯分布 (3DGS) 已成为卫星图像 3D 重建的一种新颖范例。然而，在多时相卫星图像中，由于光照条件的变化，普遍存在的阴影表现出明显的不一致。为了解决这个问题，我们提出了 ShadowGS，一种基于 3DGS 的新颖框架。它利用遥感基于物理的渲染方程，结合高效的光线行进技术，精确建模几何一致的阴影，同时保持高效的渲染。此外，它还可以有效地分解场景中的不同照明组件和明显属性。此外，我们引入了阴影一致性约束，显着提高了 3D 重建的几何精度。我们还结合了一种新颖的阴影贴图，以提高稀疏视图输入的性能。大量实验表明，ShadowGS 只需几分钟的训练，就在阴影解耦精度、3D 重建精度和新颖的视图合成质量方面优于当前最先进的方法。 ShadowGS 在各种设置下表现出强大的性能，包括 RGB、全色锐化和稀疏视图卫星输入。|[2601.00939](http://arxiv.org/abs/2601.00939)|null|\n",
        "2601.01298": "|**2026-01-03**|**Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware**|当前的多智能体大型语言模型 (LLM) 框架受到线性内存扩展的影响，导致“系统 2”并行推理在消费类硬件上不切实际。我们提出了 Warp Cortex，这是一种异步架构，理论上可以通过将代理逻辑与物理内存解耦来实现百万代理认知扩展。通过单例权重共享和新颖的拓扑突触（受到拓扑数据分析 (TDA) 的混合标志技术的启发），我们将权重的内存复杂度从 O(N * L) 降低到 O(1)，上下文的 O(N * k)，其中 k << L。通过将 KV 缓存视为潜在空间中的点云，我们应用见证复合体启发的稀疏化来保留上下文流形的持久同源特征。在单个 NVIDIA RTX 4090 上，我们凭经验演示了 2.2 GB 总 VRAM 下的 100 个并发代理，在计算延迟成为瓶颈之前理论容量超过 1,000 个代理。我们进一步介绍了引用注入，这是一种非侵入式 KV 缓存更新机制，允许异步子代理在不中断流的情况下影响主生成。|[2601.01298](http://arxiv.org/abs/2601.01298)|null|\n",
        "2601.01288": "|**2026-01-03**|**PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS**|基于像素的强化学习通常受到 3D 渲染环境的性能和复杂性的瓶颈。研究人员面临着高速、低级引擎和速度较慢、更易于访问的 Python 框架之间的权衡。为了解决这个问题，我们引入了 PyBatchRender，这是一个用于高吞吐量、批量 3D 渲染的 Python 库，可在简单场景上实现超过 100 万帧每秒 (FPS)。它基于 Panda3D 游戏引擎构建，利用其成熟的生态系统，同时通过优化的批量渲染来提高性能，加速速度高达 1000 倍。 PyBatchRender 被设计为与物理无关的渲染器，用于从像素进行强化学习，比专用库提供更大的灵活性，比典型游戏引擎包装器更简单的设置，并且速度可与 Madrona 等最先进的 C++ 引擎相媲美。用户可以使用数十行代码完全使用 Python 创建自定义场景，从而实现可扩展 AI 训练的快速原型设计。它开源且易于集成，有助于研究人员和开发人员实现高性能 3D 仿真的民主化。该库位于 https://github.com/dolphin-in-a-coma/PyBatchRender。|[2601.01288](http://arxiv.org/abs/2601.01288)|null|\n",
        "2601.02352": "|**2026-01-05**|**On the temperature of the quantum black hole**|广义相对论的一个重要特点是，当黑洞的视界区域变得无害时，其外部就会加倍，从而产生一个因果上不相连的平行宇宙。这种复杂性在特霍夫特的统一性论证中发挥着核心作用，强调物理宇宙与其在地平线另一边的复制品之间的精确识别。然而，这导致了另一种张力，即霍金温度的两倍校正。这种差异令人担忧，因为林德勒温度是通用的并且符合贝肯斯坦-霍金熵。我们证明，如果形成相应密度矩阵的状态采用广义热场双结构，则玻尔兹曼因子的失配得到修复。这为一些有趣的讨论留下了空间。|[2601.02352](http://arxiv.org/abs/2601.02352)|null|\n",
        "2601.02339": "|**2026-01-05**|**Joint Semantic and Rendering Enhancements in 3D Gaussian Modeling with Anisotropic Local Encoding**|最近的工作提出使用语义特征向量扩展 3DGS，以实现同步语义分割和图像渲染。然而，这些方法通常单独处理语义和渲染分支，仅依赖 2D 监督而忽略 3D 高斯几何。此外，当前的自适应策略仅根据渲染梯度来调整高斯集，这在微妙或无纹理区域中可能是不够的。在这项工作中，我们提出了一个用于 3D 语义高斯建模的联合增强框架，该框架可以协同语义和渲染分支。首先，与传统的点云形状编码不同，我们引入了使用 Laplace-Beltrami 算子的各向异性 3D 高斯切比雪夫描述符来捕获细粒度的 3D 形状细节，从而区分具有相似外观的对象并减少对潜在噪声 2D 引导的依赖。此外，我们不只依赖渲染梯度，而是利用局部语义和形状信号自适应地调整高斯分配和球谐函数，通过选择性资源分配来提高渲染效率。最后，我们采用跨场景知识转移模块来持续更新学习的形状模式，从而实现更快的收敛和稳健的表示，而无需从头开始为每个新场景重新学习形状信息。对多个数据集的实验表明，在保持高渲染帧速率的同时，分割精度和渲染质量有所提高。|[2601.02339](http://arxiv.org/abs/2601.02339)|null|\n",
        "2601.02305": "|**2026-01-05**|**On Statistical Inference for Rates of Change in Spatial Processes over Riemannian Manifolds**|从部分实现或分散的数据进行空间过程的统计推断已经在从环境科学到商业和经济学的各个领域取得了巨大的发展。对相关变化率的推断最近取得了一些进展。文献仅限于欧几里得领域，其中寻求对任意位置的方向导数、沿着选定的感兴趣方向的速率进行推断。事实证明，在这些设置中，高阶率（特别是方向曲率）的推断也很有用。现代空间数据通常来自非欧几里得领域。这份手稿特别考虑了在紧凑黎曼流形上定义的空间过程。我们为矢量场上此类过程的空间变化率开发了一个全面的推理框架。在此过程中，我们形式化了过程实现的平滑性并构造了微分过程——导数和曲率过程。我们推导出确保这些过程存在的核条件，并建立由流形上的“父”高斯过程（GP）和相关微分过程组成的联合多元过程的有效性。对这些速率的预测推断是根据流形上的实现过程设计的。在实践中，流形以多面体网格的形式出现。我们的模拟实验成功地评估了在此类网格上观察到的过程的导数，验证了我们的理论发现。通过增强我们对流形上的 GP 的理解，这份手稿解锁了 GP 广泛使用的机器学习和统计学中的各种潜在应用。我们提出了一种完全基于模型的方法，用于根据流形上分散位置的部分观察或实现的数据来推断空间过程所产生的微分过程。|[2601.02305](http://arxiv.org/abs/2601.02305)|null|\n",
        "2601.02281": "|**2026-01-05**|**InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams**|实现持久、大规模 3D 视觉几何理解的宏伟愿景受到可扩展性和长期稳定性的不可调和的需求的束缚。虽然像 VGGT 这样的离线模型实现了鼓舞人心的几何功能，但它们基于批处理的性质使它们与实时系统无关。流媒体架构虽然是实时操作的预期解决方案，但已被证明是不够的。现有方法要么无法支持真正的无限范围输入，要么遭受长序列的灾难性漂移。我们用 InfiniteVGGT 打破了这个长期存在的困境，InfiniteVGGT 是一种因果视觉几何变换器，通过有界但自适应且永久表达的 KV 缓存来操作滚动内存的概念。利用这一点，我们设计了一种无需训练、与注意力无关的修剪策略，可以智能地丢弃过时的信息，有效地在每个新帧中“滚动”记忆。 InfiniteVGGT 与 FlashAttention 完全兼容，最终缓解了这种妥协，实现了无限范围的流式传输，同时在长期稳定性方面优于现有的流式传输方法。对这样一个系统的最终测试是其在真正无限范围内的性能，由于缺乏极其长期、连续的基准，这种能力不可能得到严格验证。为了解决这一关键差距，我们引入了 Long3D 基准，该基准首次能够对大约 10,000 帧的序列进行连续 3D 几何估计的严格评估。这为长期 3D 几何理解的未来研究提供了明确的评估平台。代码位于：https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT|[2601.02281](http://arxiv.org/abs/2601.02281)|null|\n",
        "2601.02267": "|**2026-01-05**|**DiffProxy: Multi-View Human Mesh Recovery via Diffusion-Generated Dense Proxies**|从多视图图像中恢复人体网格面临着一个根本性的挑战：现实世界的数据集包含不完美的真实注释，这会影响模型的训练，而具有精确监督的合成数据则受到域差距的影响。在本文中，我们提出了 DiffProxy，这是一种新颖的框架，可以生成用于网格恢复的多视图一致的人类代理。 DiffProxy 的核心是利用基于扩散的生成先验来连接综合训练和现实世界的泛化。其主要创新包括：（1）用于生成多视图一致、像素对齐的人体代理的多条件机制； （2）手部细化模块，结合灵活的视觉提示，增强局部细节； (3) 一种不确定性感知测试时间缩放方法，可提高优化过程中对挑战性情况的鲁棒性。这些设计确保网格恢复过程有效地受益于基于扩散的管道的精确合成地面实况和生成优势。 DiffProxy 完全基于合成数据进行训练，在五个现实世界基准测试中实现了最先进的性能，展示了强大的零样本泛化能力，特别是在具有遮挡和部分视图的挑战性场景上。项目页面：https://wrk226.github.io/DiffProxy.html|[2601.02267](http://arxiv.org/abs/2601.02267)|null|\n",
        "2601.02211": "|**2026-01-05**|**Unraveling MMDiT Blocks: Training-free Analysis and Enhancement of Text-conditioned Diffusion**|基于变压器的扩散模型的最新突破，特别是多模态扩散变压器 (MMDiT) 驱动的模型（如 FLUX 和 Qwen Image），促进了文本到图像生成和编辑方面令人兴奋的体验。为了理解基于 MMDiT 的模型的内部机制，现有方法试图分析位置编码和注意力层等特定组件的效果。然而，对不同块及其与文本条件的相互作用如何促进合成过程的全面理解仍然难以实现。在本文中，我们首先开发一个系统管道，通过删除、禁用和增强相应块的文本隐藏状态来全面研究每个块的功能。我们的分析表明，1）语义信息出现在较早的块中，更精细的细节在后面的块中呈现，2）删除特定块通常比禁用文本条件的破坏性更小，3）增强选择性块中的文本条件可以改善语义属性。基于这些观察，我们进一步提出了新颖的免训练策略，以改进文本对齐、精确编辑和加速。大量的实验表明，我们的方法优于各种基线，并且在文本到图像生成、图像编辑和推理加速方面保持灵活性。我们的方法在 SD3.5 上将 T2I-Combench++ 从 56.92% 提高到 63.00%，将 GenEval 从 66.42% 提高到 71.63%，而不会牺牲合成质量。这些结果促进了对 MMDiT 模型的理解，并提供了宝贵的见解，以释放进一步改进的新可能性。|[2601.02211](http://arxiv.org/abs/2601.02211)|null|\n",
        "2601.02202": "|**2026-01-05**|**Density-based topology optimization for turbulent fluid flow using the standard k-epsilon RANS model with wall-functions imposed through an implicit wall penalty formulation**|湍流对边界附近的网格要求很高，以保证精度。在拓扑优化 (TO) 的背景下，如此精细的网格变得不切实际，并且通用方法因精度低和边界层厚度高估而受到阻碍。壁函数是缓解计算要求的自然方法，但由于分散的设计参数化，它们并不是自然地强加在基于密度的 TO 中。我们提出了雷诺平均纳维斯托克斯 (RANS) 的隐式壁函数公式，这是标准 k-epsilon 模型，直接从设计变量的梯度中提取壁法线信息，并启用基于惩罚的公式，将壁函数强加到 RANS 方程中，而不需要贴体网格。该方法为高雷诺数湍流拓扑优化提供了可靠的途径，提供了与显式壁体拟合分析相当的边界层精度，同时保留了基于密度的 TO 的灵活性。此外，由于壁效应是使用壁函数建模的，因此可以在较粗糙的网格上获得准确的解，从而显着降低计算成本。该方法在雷诺数高达 Re = 2e5 的三个规范基准上进行了验证：弯管； U 形弯头；和特斯拉阀门。在所有情况下，所提出的方法都能准确地恢复近壁速度剖面，与具有显式壁函数的贴体网格的验证模拟紧密匹配。相比之下，传统的湍流 TO 公式如果没有建议的壁函数处理，会错误地预测边界层的发展并产生次优结果。|[2601.02202](http://arxiv.org/abs/2601.02202)|null|\n",
        "2601.02144": "|**2026-01-05**|**Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts**|专家混合 (MoE) 架构通过使用参数“路由器”将令牌分派给稀疏的专家子集，有效地扩展大型语言模型。通常，该路由器经过一次训练，然后就被冻结，导致路由决策在分布变化时变得脆弱。我们通过引入 kNN-MoE 来解决这一限制，kNN-MoE 是一种检索增强的路由框架，可重用来自过去类似案例记忆的最佳专家分配。该内存是通过直接优化 token-wise 路由 logits 来离线构建的，以最大化参考集的可能性。至关重要的是，我们使用检索到的邻居的聚合相似度作为置信驱动的混合系数，从而允许该方法在没有找到相关情况时回退到冻结路由器。实验表明 kNN-MoE 的性能优于零样本基线，并且可以与计算成本高昂的监督微调相媲美。|[2601.02144](http://arxiv.org/abs/2601.02144)|null|\n",
        "2601.02103": "|**2026-01-05**|**HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures**|最近基于 3D Gaussian Splatting 的 3D 感知头部生成模型实现了实时、真实感和视图一致的头部合成。然而，一个根本的限制仍然存在：照明和内在外观的深度纠缠阻碍了可控的重新照明。现有的解缠结方法依赖于强假设来实现弱监督学习，这限制了它们复杂照明的能力。为了应对这一挑战，我们引入了 HeadLighter，这是一种新颖的监督框架，可以学习头部生成模型中外观和照明的物理合理分解。具体来说，我们设计了一个双分支架构，分别对光照不变的头部属性和物理接地的渲染组件进行建模。采用渐进式解缠结训练将头部外观先验逐渐注入生成架构中，并通过在受控光照条件下使用光舞台设置捕获的多视图图像进行监督。我们进一步引入了一种蒸馏策略来生成用于真实渲染的高质量法线。实验表明，我们的方法保留了高质量的生成和实时渲染，同时支持显式照明和视点编辑。我们将公开发布我们的代码和数据集。|[2601.02103](http://arxiv.org/abs/2601.02103)|null|\n",
        "2601.02102": "|**2026-01-05**|**360-GeoGS: Geometrically Consistent Feed-Forward 3D Gaussian Splatting Reconstruction for 360 Images**|3D 场景重建是 AR、机器人和数字孪生等空间智能应用的基础。传统的多视图立体与稀疏视点或低纹理区域作斗争，而神经渲染方法虽然能够产生高质量的结果，但需要每个场景的优化并且缺乏实时效率。显式 3D 高斯分布 (3DGS) 可实现高效渲染，但大多数前馈变体侧重于视觉质量而不是几何一致性，从而限制了空间感知任务中准确的表面重建和整体可靠性。本文提出了一种新颖的 360 度图像前馈 3DGS 框架，能够生成几何一致的高斯图元，同时保持高渲染质量。引入深度法线几何正则化，将渲染的深度梯度与法线信息结合起来，监督高斯旋转、缩放和位置，以提高点云和表面精度。实验结果表明，该方法在保持较高渲染质量的同时显着提高了几何一致性，为空间感知任务中的3D重建提供了有效的解决方案。|[2601.02102](http://arxiv.org/abs/2601.02102)|null|\n"
    },
    "具生智能&自动驾驶": {
        "2512.24712": "|**2025-12-31**|**LSRE: Latent Semantic Rule Encoding for Real-Time Semantic Risk Detection in Autonomous Driving**|现实世界的自动驾驶必须遵守复杂的人类社会规则，这些规则超出了法律规定的交通法规。许多语义约束，例如让给紧急车辆、遵守交通官员的手势或停车等校车，对人类来说是直观的，但难以明确编码。尽管大型视觉语言模型（VLM）可以解释此类语义，但其推理成本使得它们对于实时部署来说不切实际。这项工作提出了 LSRE，一种潜在语义规则编码框架，它将稀疏采样的 VLM 判断转换为循环世界模型的潜在空间内的决策边界。通过将语言定义的安全语义编码到轻量级潜在分类器中，LSRE 能够以 10 Hz 的频率进行实时语义风险评估，而无需每帧 VLM 查询。 CARLA 中六个语义失败场景的实验表明，LSRE 获得了与大型 VLM 基线相当的语义风险检测精度，同时提供了更早的危险预测并保持了较低的计算延迟。 LSRE 进一步推广到罕见的语义相似测试用例，表明语言引导的潜在分类为自动驾驶中的语义安全监控提​​供了一种有效且可部署的机制。|[2512.24712](http://arxiv.org/abs/2512.24712)|null|\n",
        "2512.24673": "|**2025-12-31**|**VLA-RAIL: A Real-Time Asynchronous Inference Linker for VLA Models and Robots**|视觉-语言-动作（VLA）模型在机器人技术领域取得了显着的突破，其中动作块在这些进步中发挥着主导作用。鉴于机器人运动控制的实时性和连续性，融合连续动作块队列的策略对 VLA 模型的整体性能具有深远的影响。现有方法在机器人动作执行中存在抖动、停顿甚至暂停的问题，这不仅限制了可实现的执行速度，而且降低了任务完成的整体成功率。本文介绍了 VLA-RAIL（实时异步推理链接器），这是一种新颖的框架，旨在通过异步进行模型推理和机器人运动控制并保证平滑、连续和高速的动作执行来解决这些问题。该论文的核心贡献有两个方面：轨迹平滑器（Trajectory Smoother）使用多项式拟合有效地滤除一个动作块轨迹中的噪声和抖动；块融合器（Chunk Fuser）无缝对齐当前执行轨迹和新到达的块，确保两个连续动作块之间的位置、速度和加速度连续性。我们在动态模拟任务和几个实际操作任务的基准上验证了 VLA-RAIL 的有效性。实验结果表明，VLA-RAIL显着降低了运动抖动，提高了执行速度，提高了任务成功率，这将成为VLA模型大规模部署的关键基础设施。|[2512.24673](http://arxiv.org/abs/2512.24673)|null|\n",
        "2512.24653": "|**2025-12-31**|**RoboMIND 2.0: A Multimodal, Bimanual Mobile Manipulation Dataset for Generalizable Embodied Intelligence**|虽然数据驱动的模仿学习彻底改变了机器人操作，但目前的方法仍然受到缺乏大规模、多样化的现实世界演示的限制。因此，现有模型在非结构化环境中泛化长期双手任务和移动操作的能力仍然有限。为了弥补这一差距，我们推出了 RoboMIND 2.0，这是一个全面的现实世界数据集，包含在 6 个不同的机器人实施例和 739 个复杂任务中收集的超过 310K 个双臂操作轨迹。至关重要的是，为了支持接触丰富和空间扩展任务的研究，该数据集包含 12K 触觉增强片段和 20K 移动操作轨迹。为了补充这些物理数据，我们构建了现实世界环境的高保真数字孪生，并发布了额外的 20K 轨迹模拟数据集，以促进稳健的模拟到真实的传输。为了充分发挥 RoboMIND 2.0 的潜力，我们提出了 MIND-2 系统，这是一个通过离线强化学习优化的分层双系统框架。 MIND-2 集成了一个高级语义规划器 (MIND-2-VLM)，可将抽象的自然语言指令分解为基础子目标，再加上一个低级视觉-语言-动作执行器 (MIND-2-VLA)，可生成精确的、本体感觉感知的运动动作。|[2512.24653](http://arxiv.org/abs/2512.24653)|null|\n",
        "2512.24619": "|**2025-12-31**|**Decentralized No-Regret Frequency-Time Scheduling for FMCW Radar Interference Avoidance**|汽车 FMCW 雷达对于现代 ADAS 和自动驾驶系统不可或缺，但其不断增加的密度也加剧了相互干扰的风险。现有的缓解技术，包括反应性接收器端抑制、主动波形设计和协作调度，通常面临可扩展性、对侧信道通信的依赖或距离多普勒分辨率下降的限制。基于我们早期关于分散频域无遗憾跳跃的工作，本文引入了一个统一的时频博弈论框架，使雷达能够适应频谱和时间资源。我们将干扰避免问题表述为重复的反协调博弈，其中每个雷达使用遗憾最小化动态自主更新频率子带和线性调频脉冲级时间偏移的混合策略。我们表明，所提出的时频无遗憾跳跃算法实现了外部和交换遗憾的消失，并且诱导的经验游戏收敛到$\\varepsilon$-粗相关均衡或相关均衡。理论分析提供了联合域中的遗憾界限，揭示了时间自适应如何隐式地规范频率选择并增强针对异步干扰的鲁棒性。多雷达场景的数值实验表明，与时频随机跳频和集中式基于纳什的基准相比，SINR、碰撞率和距离多普勒质量有了显着改善。|[2512.24619](http://arxiv.org/abs/2512.24619)|null|\n",
        "2512.24922": "|**2025-12-31**|**Semi-Supervised Diversity-Aware Domain Adaptation for 3D Object detection**|3D 物体探测器是自动驾驶车辆感知系统的基本组成部分。虽然这些检测器在标准自动驾驶基准上取得了出色的性能，但它们通常很难在不同领域进行推广 - 例如，在美国训练的模型可能在亚洲或欧洲等地区表现不佳。本文提出了一种基于神经元激活模式的新型激光雷达域适应方法，证明如果正确选择了目标域中的一小部分、具有代表性和多样化的样本子集，则可以通过仅注释它们来实现最先进的性能。所提出的方法需要非常小的注释预算，并且当与受持续学习启发的后训练技术相结合时，可以防止原始模型的权重漂移。经验评估表明，所提出的域自适应方法优于线性探测和最先进的域自适应技术。|[2512.24922](http://arxiv.org/abs/2512.24922)|null|\n",
        "2512.24851": "|**2025-12-31**|**VLN-MME: Diagnosing MLLMs as Language-guided Visual Navigation agents**|多模态大语言模型 (MLLM) 在广泛的视觉语言任务中表现出了卓越的能力。然而，它们作为具体代理的性能需要多轮对话空间推理和顺序动作预测，需要进一步探索。我们的工作通过引入一个统一且可扩展​​的评估框架来探索 MLLM 作为零样本代理，通过将传统导航数据集桥接到一个名为 VLN-MME 的标准化基准，来研究视觉和语言导航 (VLN) 背景下的这种潜力。我们通过高度模块化且易于访问的设计简化了评估。这种灵活性简化了实验，实现了跨不同 MLLM 架构、代理设计和导航任务的结构化比较和组件级消融。至关重要的是，在我们的框架的支持下，我们观察到通过思想链（CoT）推理和自我反思来增强我们的基线代理会导致性能意外下降。这表明 MLLM 在具体导航任务中表现出较差的上下文感知能力；尽管它们可以遵循指令并构建输出，但它们的 3D 空间推理保真度较低。 VLN-MME 为在具体导航设置中系统评估通用 MLLM 奠定了基础，并揭示了其顺序决策能力的局限性。我们相信这些发现为 MLLM 作为具体代理的后期培训提供了重要的指导。|[2512.24851](http://arxiv.org/abs/2512.24851)|null|\n",
        "2601.00755": "|**2026-01-02**|**A formal theory on problem space as a semantic world model in systems engineering**|经典问题空间理论将问题解决建模为通过状态、算子、目标和约束的结构化空间的导航。系统工程（SE）采用类似的构造（功能分析、操作分析、情景、权衡研究），但仍然缺乏问题空间本身的严格系统理论表示。在当前的实践中，推理通常直接从利益相关者的目标进行到规定性的工件。这使得关于操作环境、允许的交互和上下文条件的基本假设隐含或过早地嵌入到架构或需求中。本文通过将问题空间形式化为包含在需求和解决方案承诺之前定义的理论构造的显式语义世界模型来解决这一差距。这些构造与开发的公理、定理和推论一起建立了严格的标准，用于明确的边界语义、成功的利益相关者目标满足的上下文相关交互可追溯性，以及问题空间规范的充分性，在该规范上可以独立于解决方案设计进行有纪律的推理。它清楚地区分了问题领域的真实情况和选择的解决方案。本文最后讨论了该理论对实践者的重要性，并提供了利益相关者和工程师之间基于对话的假设案例研究，展示了该理论如何在设计任何规定性工件之前指导问题框架。|[2601.00755](http://arxiv.org/abs/2601.00755)|null|\n",
        "2601.00742": "|**2026-01-02**|**Materials Informatics: Emergence To Autonomous Discovery In The Age Of AI**|这一视角探讨了材料信息学的演变，从物理学和信息论的基础到通过人工智能 (AI) 的成熟。我们追溯了该领域的发展轨迹，从早期里程碑到材料基因组计划的变革性影响以及最近出现的大型语言模型 (LLM)。我们将材料信息学视为一个不断发展的生态系统，而不仅仅是一个工具包，回顾了推动逆向设计和自主驾驶实验室的关键方法，例如贝叶斯优化、强化学习和 Transformers。我们专门解决法学硕士整合的实际挑战，比较专家模型与通才模型，并讨论不确定性量化的解决方案。展望未来，我们评估人工智能从预测工具到协作研究伙伴的转变。通过利用主动学习和检索增强生成（RAG），该领域正在迈向自主材料科学的新时代，其日益以“人类脱离循环”的发现过程为特征。|[2601.00742](http://arxiv.org/abs/2601.00742)|null|\n",
        "2601.00393": "|**2026-01-01**|**NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos**|在本文中，我们提出了 NeoVerse，一种多功能的 4D 世界模型，能够进行 4D 重建、新轨迹视频生成和丰富的下游应用。我们首先确定当前 4D 世界建模方法中可扩展性的常见限制，该限制是由昂贵且专门的多视图 4D 数据或繁琐的训练预处理引起的。相比之下，我们的 NeoVerse 建立在一个核心理念之上，该理念使整个管道可扩展至各种野外单目视频。具体来说，NeoVerse 具有无姿态前馈 4D 重建、在线单目退化模式模拟和其他良好对齐的技术。这些设计使 NeoVerse 具有多功能性并可推广到各个领域。同时，NeoVerse 在标准重建和生成基准方面实现了最先进的性能。我们的项目页面位于 https://neoverse-4d.github.io|[2601.00393](http://arxiv.org/abs/2601.00393)|null|\n",
        "2601.00367": "|**2026-01-01**|**PatchBlock: A Lightweight Defense Against Adversarial Patches for Embedded EdgeAI Devices**|对抗性攻击对 EdgeAI 应用中机器学习模型的可靠部署构成了重大挑战，例如自动驾驶和监控，这些应用依赖于资源受限的设备进行实时推理。其中，基于补丁的对抗攻击，即向对象应用小的恶意补丁（例如贴纸），可以欺骗神经网络做出错误的预测，从而可能产生严重的后果。在本文中，我们提出了 PatchBlock，这是一个轻量级框架，旨在检测和消除图像中的对抗性补丁。利用异常值检测和降维，PatchBlock 可以识别受对抗性噪声影响的区域并抑制其影响。它作为传感器级别的预处理模块运行，与 GPU 推理并行地在 CPU 上高效运行，从而保持系统吞吐量，同时避免额外的 GPU 开销。该框架遵循三阶段流程：将输入分割成块（分块），通过重新设计的隔离森林检测异常区域，并进行有针对性的切割以实现更快的收敛（分离），并对已识别的异常值应用降维（缓解）。 PatchBlock 与模型和补丁无关，可以对现有管道进行改造，并在传感器输入和下游模型之间无缝集成。对多个神经架构、基准数据集、攻击类型和不同边缘设备的评估表明，PatchBlock 不断提高鲁棒性，在 Google Adversarial Patch 等强补丁攻击下恢复高达 77% 的模型精度，同时保持高可移植性和最小的干净精度损失。此外，PatchBlock 在效率、计算时间和每个样本的能耗方面优于最先进的防御，使其适合 EdgeAI 应用。|[2601.00367](http://arxiv.org/abs/2601.00367)|null|\n",
        "2601.00270": "|**2026-01-01**|**Rectifying Adversarial Examples Using Their Vulnerabilities**|基于深度神经网络的分类器在处理对抗性示例 (AE) 时容易出错。 AE 是人类无法检测到的扰动最小的输入数据，对依赖于安全的应用程序构成重大风险。因此，人们进行了广泛的研究来开发减轻其威胁的防御机制。大多数现有方法主要侧重于根据输入样本特征区分AE，强调AE检测，而没有在攻击前解决样本的正确分类问题。虽然某些任务可能只需要拒绝检测到的 AE，但其他任务则需要识别正确的原始输入类别，例如自动驾驶中的交通标志识别。本研究的目的是提出一种纠正 AE 的方法，以估计其原始输入的正确标签。我们的方法基于重新攻击 AE，将其移出决策边界以进行准确的标签预测，有效解决纠正使用白盒攻击方法创建的最小可感知 AE 的问题。然而，有效纠正距边界一定距离的黑盒攻击所产生的不良事件，或被针对性攻击错误分类为低置信度类别的不良事件，仍然存在挑战。通过采用仅考虑 AE 作为输入的直接方法，所提出的方法可以解决各种攻击，同时避免参数调整或初步训练的要求。结果表明，所提出的方法在纠正通过各种攻击方法（包括定向攻击和黑盒攻击）生成的 AE 方面表现出一致的性能。此外，在对抗各种攻击的稳定性方面，它优于传统的校正和输入转换方法。|[2601.00270](http://arxiv.org/abs/2601.00270)|null|\n",
        "2601.00156": "|**2026-01-01**|**Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions**|在本文中，我们介绍了面部分析中一个尚未探索的问题：针对任意选择的面部区域（称为 FaceFocalDesc）生成和识别多属性自然语言描述，其中包含面部动作单元（AU）、情绪状态和年龄估计。我们认为，系统专注于单个面部区域的能力可以带来更好的理解和控制。为了实现这一能力，我们为任意选择的面部区域构建了一个新的多属性描述数据集，提供丰富的区域级注释和自然语言描述。此外，我们提出了一种基于 Qwen2.5-VL 的微调视觉语言模型，称为 Focal-RegionFace，用于面部状态分析，该模型通过多个逐步微调阶段逐步细化对局部面部特征的关注，从而实现可解释的年龄估计、FAU 和情绪检测。实验结果表明，Focal-RegionFace 在新基准上在传统和广泛使用的指标以及新提出的指标方面均取得了最佳性能。这充分验证了其在细粒度多属性人脸区域焦点分析场景中的有效性和通用性。|[2601.00156](http://arxiv.org/abs/2601.00156)|null|\n",
        "2601.00051": "|**2025-12-31**|**TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model**|世界模型旨在赋予人工智能系统以连贯且时间一致的方式表示、生成动态环境并与之交互的能力。虽然最近的视频生成模型表现出了令人印象深刻的视觉质量，但它们在实时交互、长视野一致性和动态场景的持久记忆方面仍然有限，阻碍了它们向实际世界模型的演进。在本报告中，我们介绍了 TeleWorld，这是一种实时多模态 4D 世界建模框架，它将视频生成、动态场景重建和长期世界记忆统一在闭环系统中。 TeleWorld 引入了一种新颖的生成-重构-指导范式，其中生成的视频流被不断重构为动态 4D 时空表示，从而指导后续生成保持空间、时间和物理一致性。为了支持低延迟的长视野生成，我们采用了基于自回归扩散的视频模型，该模型通过宏观微观规划（MMPL）进行了增强，这是一种分层规划方法，可减少从帧级到段级的误差累积，并结合高效的分布匹配蒸馏（DMD），从而在实际计算预算下实现实时合成。我们的方法在统一的 4D 框架内实现了动态对象建模和静态场景表示的无缝集成，将世界模型推进到实用、交互式和计算可访问的系统。大量实验表明，TeleWorld 在静态和动态世界理解、长期一致性和实时生成效率方面均取得了出色的性能，将其定位为迈向交互式、支持记忆的多模式生成和体现智能的世界模型的实用步骤。|[2601.00051](http://arxiv.org/abs/2601.00051)|null|\n",
        "2601.01800": "|**2026-01-05**|**Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving**|强化学习 (RL) 在自动驾驶 (AD) 领域显示出巨大的潜力，但其易受扰动的影响仍然是现实世界部署的关键障碍。作为主要对策，对抗性训练通过在对手故意引入扰动的情况下训练 AD 代理来提高策略的稳健性。现有方法通常将交互建模为具有连续攻击的零和游戏。然而，此类设计忽视了代理和对手之间固有的不对称性，无法反映安全关键风险的稀疏性，导致所实现的鲁棒性不足以满足实际的 AD 场景。为了解决这些限制，我们引入了关键性感知的鲁棒强化学习（CARRL），这是一种新颖的对抗性训练方法，用于处理自动驾驶中稀疏的、安全关键的风险。 CARRL 由两个相互作用的部分组成：风险暴露对手 (REA) 和风险目标稳健代理 (RTRA)。我们将 REA 和 RTRA 之间的交互建模为一般和游戏，使 REA 能够专注于暴露安全关键型故障（例如碰撞），而 RTRA 则学会平衡安全性与驾驶效率。 REA 采用解耦优化机制，在预算有限的情况下更好地识别和利用稀疏的安全关键时刻。然而，这种集中攻击不可避免地导致对抗性数据的缺乏。 RTRA 通过双重重放缓冲区共同利用良性和对抗性体验来应对这种稀缺性，并在扰动下强制执行政策一致性以稳定行为。实验结果表明，与最先进的基线方法相比，我们的方法在所有情况下将碰撞率降低了至少 22.66%。|[2601.01800](http://arxiv.org/abs/2601.01800)|null|\n",
        "2601.01762": "|**2026-01-05**|**AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving**|端到端自动驾驶快速发展，实现了复杂环境下的联合感知和规划。在规划阶段，最先进的（SOTA）端到端自动驾驶模型将规划分解为并行的横向和纵向预测。虽然有效，但这种并行设计可能会导致 i) 规划路径和速度之间的协调失败，以及 ii) 未充分利用驾驶路径作为纵向规划的先验，从而冗余地编码静态信息。为了解决这个问题，我们提出了一种新颖的级联框架，该框架明确规定了行驶路径上的纵向规划，从而实现协调和碰撞感知的横向和纵向规划。具体来说，我们引入了一种路径条件公式，该公式明确地将行驶路径纳入纵向规划中。在此基础上，该模型预测沿行驶路径的纵向位移，而不是完整的 2D 轨迹路点。这种设计简化了纵向推理，并将其与横向规划更紧密地结合在一起。此外，我们引入了一种面向规划的数据增强策略，通过添加代理和重新标记纵向目标以避免碰撞来模拟罕见的安全关键事件，例如车辆切入。在具有挑战性的 Bench2Drive 基准上进行评估，我们的方法设定了新的 SOTA，驾驶得分为 89.07，成功率为 73.18%，这表明协调性和安全性显着提高|[2601.01762](http://arxiv.org/abs/2601.01762)|null|\n",
        "2601.01743": "|**2026-01-05**|**AI Agent Systems: Architectures, Applications, and Evaluation**|人工智能代理——将基础模型与推理、规划、记忆和工具使用相结合的系统——正在迅速成为自然语言意图和现实世界计算之间的实用接口。这项调查综合了人工智能代理架构的新兴前景：（i）审议和推理（例如，思想链式分解、自我反思和验证以及约束感知决策），（ii）规划和控制（从反应性策略到分层和多步骤规划器），以及（iii）工具调用和环境交互（检索、代码执行、API 和多模式感知）。我们将之前的工作组织成一个统一的分类法，涵盖代理组件（策略/LLM核心、内存、世界模型、规划器、工具路由器和评论家）、编排模式（单代理与\\多代理；集中与\\分散协调）和部署设置（离线分析与\\在线交互协助；安全关键与\\开放式任务）。我们讨论关键的设计权衡——延迟与准确性、自主性与可控性、能力与可靠性——并强调评估如何因非确定性、长期信用分配、工具和环境可变性以及重试和上下文增长等隐性成本而变得复杂。最后，我们总结了测量和基准测试实践（任务套件、人类偏好和效用指标、约束下的成功、稳健性和安全性），并确定了开放的挑战，包括工具操作的验证和护栏、可扩展的内存和上下文管理、代理决策的可解释性以及实际工作负载下的可重复评估。|[2601.01743](http://arxiv.org/abs/2601.01743)|null|\n",
        "2601.01705": "|**2026-01-05**|**Explicit World Models for Reliable Human-Robot Collaboration**|本文讨论了传感噪声、模糊指令和人机交互下的鲁棒性主题。我们对可靠的实体人工智能问题采取了截然不同的策略：我们不关注旨在实现模型可预测性和鲁棒性的形式验证方法，而是强调人机交互​​的动态性、模糊性和主观性，这需要实体人工智能系统以一致、可理解和符合人类期望的方式感知、解释和响应人类意图。我们认为，当实体主体在本质上是社交的、多模式的和流动的人类环境中运行时，可靠性是根据上下文确定的，并且仅对参与交互的人类的目标和期望才有意义。这就需要一种根本不同的方法来实现可靠的嵌入式人工智能，其核心是构建和更新一个可访问的“显式世界模型”，代表人类和人工智能之间的共同点，用于使机器人行为与人类期望保持一致。|[2601.01705](http://arxiv.org/abs/2601.01705)|null|\n",
        "2601.01676": "|**2026-01-04**|**LabelAny3D: Label Any Object 3D in the Wild**|从单眼输入检测 3D 空间中的物体对于从机器人到场景理解等应用至关重要。尽管在室内和自动驾驶领域具有先进的性能，但由于缺乏 3D 野外数据集以及 3D 注释的挑战，现有的单目 3D 检测模型在处理野外图像方面遇到了困难。我们引入了 LabelAny3D，这是一个 \\emph{综合分析} 框架，它可以从 2D 图像重建整体 3D 场景，以有效地生成高质量的 3D 边界框注释。在此基础上，我们提出了 COCO3D，这是开放词汇单目 3D 检测的新基准，源自 MS-COCO 数据集，涵盖了现有 3D 数据集中缺少的广泛对象类别。实验表明，LabelAny3D 生成的注释提高了多个基准中的单目 3D 检测性能，在质量上优于先前的自动标记方法。这些结果证明了基础模型驱动注释在现实、开放世界环境中扩展 3D 识别的前景。|[2601.01676](http://arxiv.org/abs/2601.01676)|null|\n",
        "2601.01618": "|**2026-01-04**|**Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation**|长视距机器人操作对于现实世界的部署越来越重要，需要复杂布局中的空间消歧和动态交互下的时间弹性。然而，现有的端到端和分层的视觉-语言-行动（VLA）策略通常依赖于纯文本线索，同时保持计划意图的潜在性，这破坏了杂乱或未指定场景中的参考基础，阻碍了通过闭环交互对长期目标进行有效的任务分解，并通过模糊行动选择背后的基本原理来限制因果解释。为了解决这些问题，我们首先引入 Visual Sketch，这是一种令人难以置信的视觉中间体，可以在机器人当前视图中渲染点、框、箭头和类型化关系，以外部化空间意图，将语言与场景几何连接起来。在 Visual Sketch 的基础上，我们提出了 Action-Sketcher，这是一个 VLA 框架，它在循环的 See-Think-Sketch-Act 工作流程中运行，并通过自适应令牌门控策略进行协调，用于推理触发器、草图修订和动作发布，从而支持反应性校正和人类交互，同时保留实时动作预测。为了实现可扩展的训练和评估，我们利用交错的图像、文本、视觉草图监督和动作序列来策划不同的语料库，并使用多阶段课程方案来训练 Action-Sketcher，该课程方案结合了用于模态统一的交错序列对齐、用于精确语言基础的语言到草图的一致性、以及通过草图到动作强化来增强鲁棒性的模仿学习。对杂乱场景和多对象任务、模拟和现实世界任务进行的大量实验表明，长期成功率有所提高，对动态场景变化的鲁棒性更强，并且通过可编辑草图和逐步计划增强了可解释性。项目网站：https://action-sketcher.github.io|[2601.01618](http://arxiv.org/abs/2601.01618)|null|\n",
        "2601.01577": "|**2026-01-04**|**HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller**|当前自主控制器强化学习的尝试对数据要求较高，但结果表现不佳、不稳定，无法把握和锚定安全概念，并且由于像素重建的性质而过度关注噪声特征。虽然当前的自我监督学习方法通​​过利用联合嵌入预测架构（JEPA）来学习高维表示是有趣且有效的替代方案，因为该想法模仿了人脑使用想象力和最小观察样本获取新技能的自然能力。本研究介绍了 Hanoi-World，这是一种基于 JEPA 的世界模型，使用循环神经网络 (RNN) 进行具有有效推理时间的长期水平规划。在不同环境下的 Highway-Env 包上进行的实验展示了在安全意识的同时制定驾驶计划的有效能力，与 SOTA 基线相比具有相当大的碰撞率|[2601.01577](http://arxiv.org/abs/2601.01577)|null|\n",
        "2601.01551": "|**2026-01-04**|**Optically Transparent Meta-Grating Embedded in Rear Windshields for Automotive Radar Detection**|雷达通过实现可靠的物体检测，从而为驾驶员提供帮助，并在未来成为自动驾驶的主要传感器之一，在汽车安全中发挥着至关重要的作用。道路参与者的雷达能见度取决于其雷达截面 (RCS)。虽然 RCS 是一种固有属性，但增强它，类似于使用反光背心实现光学可见性，可以通过协作目标设计显着改善雷达探测。然而，现代车辆并不是为此目的而设计的，并且由于行业的保守方法和车辆外部可用空间有限，没有使用嵌入式反射器。后挡风玻璃提供了广阔的未使用区域，但它们仍然必须发挥其主要功能并保持透明。我们建议通过嵌入一个反射面来利用该区域，该反射面考虑了询问场景的几何形状和后挡风玻璃的角度倾斜，确保波被回反射回雷达。该表面被实现为具有周期性的细导线阵列，为设计入射角提供同相激励。鉴于汽车雷达在毫米波范围 (77-81 GHz) 下运行，因此需要具有亚毫米制造精度的大尺寸表面。这是通过将由银纳米粒子和粘合剂组成的导电墨水压印到玻璃的凹槽中来实现的。制造的 10x10 平方米。样品的光学透明度约为 90%，其 RCS 为 8 平方米，超过了汽车的典型 RCS。将这种性能外推到带有嵌入式元光栅的整个后窗，典型的 RCS 为 1000 平方米。可以实现，从而将可检测范围提高了近一个数量级。智能窗户支持无线通信中的高级应用，例如汽车场景、物联网等。|[2601.01551](http://arxiv.org/abs/2601.01551)|null|\n",
        "2601.01528": "|**2026-01-04**|**DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving**|视频生成模型作为世界模型的一种形式，已成为人工智能领域最令人兴奋的前沿之一，它让智能体能够通过对复杂场景的时间演化进行建模来想象未来。在自动驾驶中，这一愿景催生了驾驶世界模型：想象自我和代理未来的生成模拟器，实现可扩展的模拟、极端情况的安全测试以及丰富的合成数据生成。然而，尽管研究活动快速增长，但该领域缺乏严格的基准来衡量进展和指导优先事项。现有的评估仍然有限：通用视频指标忽视了安全关键的成像因素；轨迹的合理性很少被量化；时间和代理级别的一致性被忽略；自我调节的可控性被忽略。此外，当前的数据集无法涵盖现实世界部署所需的条件的多样性。为了解决这些差距，我们推出了 DrivingGen，这是第一个生成驾驶世界模型的综合基准测试。 DrivingGen 将来自驾驶数据集和互联网规模视频源的多样化评估数据集（涵盖不同的天气、一天中的时间、地理区域和复杂的操作）与一套新指标相结合，共同评估视觉真实性、轨迹合理性、时间一致性和可控性。对 14 个最先进模型进行基准测试揭示了明显的权衡：通用模型看起来更好，但违反物理原理，而驾驶专用模型可以真实地捕捉运动，但视觉质量落后。 DrivingGen 提供统一的评估框架，以培育可靠、可控和可部署的驾驶世界模型，从而实现可扩展的模拟、规划和数据驱动的决策。|[2601.01528](http://arxiv.org/abs/2601.01528)|null|\n",
        "2601.01386": "|**2026-01-04**|**ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking**|停车是自动驾驶系统 (ADS) 的一项关键任务，在拥挤的停车位和 GPS 无法识别的环境中面临着独特的挑战。然而，现有的工作重点是 2D 停车位感知、映射和定位，而 3D 重建仍有待探索，这对于捕获停车场景中的复杂空间几何形状至关重要。单纯地提高重建停车场景的视觉质量并不能直接使自动停车受益，因为停车的关键入口是车位感知模块。为了解决这些限制，我们策划了第一个名为 ParkRecon3D 的基准测试，专门为停车场景重建而设计。它包括来自四个环视鱼眼摄像头的传感器数据，以及经过校准的外部参数和密集的停车位注释。然后，我们提出了 ParkGaussian，这是第一个集成 3D 高斯分布 (3DGS) 进行停车场景重建的框架。为了进一步提高重建和下游停车位检测之间的一致性，我们引入了一种槽位感知重建策略，该策略利用现有的停车感知方法来提高槽位区域的合成质量。 ParkRecon3D 上的实验表明，ParkGaussian 实现了最先进的重建质量，并更好地保持了下游任务的感知一致性。代码和数据集将发布在：https://github.com/wm-research/ParkGaussian|[2601.01386](http://arxiv.org/abs/2601.01386)|null|\n",
        "2601.02297": "|**2026-01-05**|**The Polarization and Magnetic Field of the Radio Arc as Observed by ALMA at 100 GHz**|40 多年来，独特的银河中心非热丝 (NTF) 一直是研究的焦点。 NTF 最突出的表现是一束平行的细丝，称为射电弧。使用甚大阵列 (VLA) 在 10 GHz 下进行的射电极化观测揭示了射电弧中的交变磁场模式，这可能是沿视线遇到多个场系统的结果，也可能是射电弧的固有特征。由于对源头进行了较大的旋转测量，这些 VLA 观测结果无法区分这些可能性。我们展示了 ALMA 100 GHz 射电弧观测结果，不受显着法拉第效应的影响。这里报告的观测结果既是 ALMA 首次用于研究 NTF，也是首次对射电弧进行 100 GHz 极化观测。我们发现相对于 NTF 细丝方向均匀旋转的磁场，旋转角度沿每根细丝的长度恒定。然而，我们发现不同的射电弧灯丝中存在系统不同的磁场方向。我们使用这种场模式来更新我们对射电弧局部视线结构的理解。我们发现从 ALMA 观测推断出的磁场可能是多个磁场系统混淆的结果，或者是因为极化集中在 NTF 细丝内。|[2601.02297](http://arxiv.org/abs/2601.02297)|null|\n",
        "2601.02295": "|**2026-01-05**|**CycleVLA: Proactive Self-Correcting Vision-Language-Action Models via Subtask Backtracking and Minimum Bayes Risk Decoding**|目前机器人故障检测和纠正的工作通常以事后方式进行，仅在故障发生后分析错误并应用纠正。这项工作引入了 CycleVLA，这是一个为视觉-语言-动作模型 (VLA) 配备主动自我纠正功能的系统，能够预测初期故障并在执行过程中完全显现之前进行恢复。 CycleVLA 通过集成一个进度感知 VLA（标记最常发生故障的关键子任务转换点）、一个基于 VLM 的故障预测器和规划器（在预测故障时触发子任务回溯）以及一个基于最小贝叶斯风险 (MBR) 解码的测试时间扩展策略来实现这一目标，以提高回溯后的重试成功率。大量实验表明，CycleVLA 可以提高训练有素和训练不足的 VLA 的性能，并且 MBR 可以作为 VLA 的有效零样本测试时间扩展策略。项目页面：https://dannymcy.github.io/cyclevla/|[2601.02295](http://arxiv.org/abs/2601.02295)|null|\n",
        "2601.02046": "|**2026-01-05**|**Agentic Retoucher for Text-To-Image Generation**|SDXL 和 FLUX 等文本到图像 (T2I) 扩散模型已经实现了令人印象深刻的照片级真实感，但四肢、面部、文本等中仍然普遍存在小规模扭曲。现有的细化方法要么执行成本高昂的迭代重新生成，要么依赖空间基础薄弱的视觉语言模型（VLM），导致语义漂移和不可靠的本地编辑。为了缩小这一差距，我们提出了 Agentic Retoucher，这是一种分层决策驱动框架，它将生成后校正重新表述为类人感知-推理-行动循环。具体来说，我们设计了（1）一个感知代理，它在文本图像一致性提示下学习上下文显着性，以实现细粒度的失真定位；（2）一个推理代理，通过渐进式偏好对齐执行与人类一致的推理诊断；（3）一个动作代理，根据用户偏好指导自适应地规划局部修复。这种设计将感知证据、语言推理和可控纠正整合到一个统一的、自我纠正的决策过程中。为了实现细粒度监督和定量评估，我们进一步构建了 GenBlemish-27K，这是一个 6K T2I 图像的数据集，其中包含 12 个类别的 27K 个带注释的伪影区域。大量实验表明，Agentic Retoucher 在感知质量、失真定位和人类偏好调整方面始终优于最先进的方法，为自我校正和感知可靠的 T2I 生成建立了新的范例。|[2601.02046](http://arxiv.org/abs/2601.02046)|null|\n",
        "2601.01989": "|**2026-01-05**|**VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis**|行人意图预测是3级自动驾驶向4级自动驾驶过渡的关键技术之一。为了了解行人过路处的行为，应考虑几个要素和特征，以使未来的道路对每个人来说都更安全。我们引入了一种基于 Transformer/视频视觉 Transformer 的不同大小的算法，该算法使用不同的数据模态。我们在流行的行人行为数据集 JAAD 上评估了我们的算法，并达到了 SOTA 性能，并在准确度、AUC 和 F1 分数等指标上通过了 SOTA。通过广泛的消融研究，研究了不同模型设计选择带来的优势。|[2601.01989](http://arxiv.org/abs/2601.01989)|null|\n",
        "2601.01948": "|**2026-01-05**|**Learning Diffusion Policy from Primitive Skills for Robot Manipulation**|扩散策略（DP）最近显示出在机器人操作中产生动作的巨大前景。然而，现有的方法通常依赖于全局指令来产生短期控制信号，这可能导致动作生成中的失调。我们推测，被称为细粒度、短视野操作的原始技能，例如“向上移动”和“打开夹具”，为机器人学习提供了更直观、更有效的界面。为了弥补这一差距，我们提出了 SDP，这是一种将可解释的技能学习与条件行动计划相结合的技能条件 DP。 SDP 抽象了跨任务的八种可重用的原始技能，并采用视觉语言模型从视觉观察和语言指令中提取离散表示。基于它们，设计了一个轻量级路由器网络，为每个状态分配所需的原始技能，这有助于构建单一技能策略来生成与技能一致的操作。通过将复杂任务分解为一系列原始技能并选择单一技能策略，SDP 可确保不同任务之间的技能行为一致。对两个具有挑战性的模拟基准和现实世界的机器人部署进行的大量实验表明，SDP 始终优于 SOTA 方法，为具有扩散策略的基于技能的机器人学习提供了新的范例。|[2601.01948](http://arxiv.org/abs/2601.01948)|null|\n"
    }
}