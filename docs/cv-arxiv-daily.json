{
    "Video Diffusion": {
        "2601.04194": "|**2026-01-07**|**Choreographing a World of Dynamic Objects**|物理 4D（3D + 时间）世界中的动态对象不断演化、变形并与其他对象交互，从而产生多样化的 4D 场景动态。在本文中，我们提出了一种通用生成管道 CHORD，用于 CHOReographing 动态对象和场景并合成此类现象。用于创建这些动态的传统基于规则的图形管道基于特定类别的启发式方法，但属于劳动密集型且不可扩展。最近基于学习的方法通常需要大规模数据集，这可能无法涵盖所有​​感兴趣的对象类别。相反，我们的方法通过提出基于蒸馏的管道来提取隐藏在 2D 视频的欧拉表示中的丰富拉格朗日运动信息，从而继承了视频生成模型的普遍性。我们的方法是通用的、通用的并且与类别无关。我们通过实验生成各种多体 4D 动力学来证明其有效性，展示其与现有方法相比的优势，并证明其在生成机器人操纵策略方面的适用性。项目页面：https://yanzhelyu.github.io/chord|[2601.04194](http://arxiv.org/abs/2601.04194)|null|\n",
        "2601.04153": "|**2026-01-07**|**Diffusion-DRF: Differentiable Reward Flow for Video Diffusion Fine-Tuning**|直接偏好优化 (DPO) 最近通过增强视觉保真度和文本对齐来改进文本到视频 (T2V) 的生成。然而，当前的方法依赖于来自人类注释或学习奖励模型的不可微偏好信号。这种依赖使得训练标签密集、容易出现偏差且易于博弈，这通常会引发奖励黑客攻击和不稳定的训练。我们提出了 Diffusion-DRF，这是一种可微分奖励流，用于使用冻结的现成视觉语言模型（VLM）作为免训练批评家来微调视频扩散模型。 Diffusion-DRF 通过扩散去噪链直接反向传播 VLM 反馈，将 logit 级响应转换为令牌感知梯度以进行优化。我们提出了一个自动化的、方面结构的提示管道来获得可靠的多维 VLM 反馈，而梯度检查点可以通过最终的去噪步骤实现高效的更新。 Diffusion-DRF 提高了视频质量和语义对齐，同时减轻奖励黑客攻击和崩溃——无需额外的奖励模型或偏好数据集。它与模型无关，并且很容易推广到其他基于扩散的生成任务。|[2601.04153](http://arxiv.org/abs/2601.04153)|null|\n",
        "2601.04090": "|**2026-01-07**|**Gen3R: 3D Scene Generation Meets Feed-Forward Reconstruction**|我们提出了 Gen3R，一种将基础重建模型和视频扩散模型的强大先验联系起来的方法，用于场景级 3D 生成。我们重新调整 VGGT 重建模型的用途，通过在其标记上训练适配器来产生几何潜在特征，这些标记被正则化以与预训练视频扩散模型的外观潜在特征保持一致。通过联合生成这些解开但对齐的潜在变量，Gen3R 可以生成 RGB 视频和相应的 3D 几何图形，包括相机姿势、深度图和全局点云。实验表明，我们的方法在单图像和多图像条件 3D 场景生成方面取得了最先进的结果。此外，我们的方法可以通过利用生成先验来增强重建的鲁棒性，证明了重建和生成模型紧密耦合的互惠互利。|[2601.04090](http://arxiv.org/abs/2601.04090)|null|\n",
        "2601.04068": "|**2026-01-08**|**Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models**|将文本到视频的扩散模型与人类偏好保持一致对于生成高质量视频至关重要。现有的直接偏好优化（DPO）方法依赖于多样本排序和特定于任务的批评模型，这种方法效率低下，并且经常产生模糊的全局监督。为了解决这些限制，我们提出了 LocalDPO，这是一种新颖的后训练框架，它从真实视频构建本地化偏好对并优化时空区域级别的对齐。我们设计了一个自动化管道来有效地收集偏好对数据，该数据通过每个提示进行一次推理来生成偏好对，从而消除了对外部批评家模型或手动注释的需要。具体来说，我们将高质量的真实视频视为正样本，并通过使用随机时空掩模局部破坏它们并使用冻结的基础模型仅恢复掩模区域来生成相应的负样本。在训练过程中，我们引入了区域感知 DPO 损失，将偏好学习限制在损坏区域以实现快速收敛。 Wan2.1 和 CogVideoX 上的实验表明，与其他训练后方法相比，LocalDPO 持续提高了视频保真度、时间一致性和人类偏好分数，为视频生成器对齐建立了更高效、更细粒度的范例。|[2601.04068](http://arxiv.org/abs/2601.04068)|null|\n",
        "2601.03665": "|**2026-01-07**|**PhysVideoGenerator: Towards Physically Aware Video Generation via Latent Physics Guidance**|当前的视频生成模型可以生成高质量的美学视频，但通常很难学习现实世界物理动力学的表示，从而导致诸如不自然的物体碰撞、不一致的重力和时间闪烁等伪影。在这项工作中，我们提出了 PhysVideoGenerator，这是一个概念验证框架，它将可学习的物理学先验嵌入到视频生成过程中。我们引入了一种轻量级预测器网络 PredictorP，它直接从噪声扩散潜伏中回归从预训练视频联合嵌入预测架构（V-JEPA 2）中提取的高级物理特征。这些预测的物理标记通过专用的交叉注意力机制注入到基于 DiT 的生成器 (Latte) 的时间注意力层中。我们的主要贡献是证明了这种联合训练范例的技术可行性：我们证明扩散潜伏包含足够的信息来恢复 V-JEPA 2 物理表示，并且多任务优化在训练过程中保持稳定。该报告记录了架构设计、技术挑战和训练稳定性验证，为未来大规模评估物理感知生成模型奠定了基础。|[2601.03665](http://arxiv.org/abs/2601.03665)|null|\n",
        "2601.03655": "|**2026-01-07**|**VideoMemory: Toward Consistent Video Generation via Memory Integration**|在多个镜头中保持一致的角色、道具和环境是叙事视频生成的主要挑战。现有模型可以生成高质量的短片，但当场景发生变化或实体在长时间间隔后重新出现时，通常无法保留实体的身份和外观。我们提出了 VideoMemory，一个以实体为中心的框架，通过动态内存库将叙事规划与视觉生成集成在一起。给定结构化脚本，多智能体系统将叙述分解为镜头，从内存中检索实体表示，并根据这些检索到的状态合成关键帧和视频。动态内存库存储角色、道具和背景的明确视觉和语义描述符，并在每次拍摄后进行更新，以反映故事驱动的变化，同时保留身份。这种检索更新机制可以对远处镜头中的实体进行一致的描绘，并支持连贯的长格式生成。为了评估此设置，我们构建了一个 54 例多镜头一致性基准，涵盖角色、道具和背景持续场景。大量实验表明，VideoMemory 在不同的叙事序列中实现了强大的实体级连贯性和高感知质量。|[2601.03655](http://arxiv.org/abs/2601.03655)|null|\n",
        "2601.05138": "|**2026-01-08**|**VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control**|视频世界模型旨在模拟动态的真实世界环境，但现有方法难以对摄像机和多对象运动提供统一且精确的控制，因为视频本质上是在投影的 2D 图像平面中进行动态操作。为了弥补这一差距，我们引入了 VerseCrafter，这是一种 4D 感知视频世界模型，可以在统一的 4D 几何世界状态中对摄像机和对象动态进行明确且连贯的控制。我们的方法以新颖的 4D 几何控制表示为中心，它通过静态背景点云和每个对象的 3D 高斯轨迹对世界状态进行编码。这种表示不仅可以捕获对象的路径，还可以捕获其随时间变化的概率 3D 占用情况，为刚性边界框或参数模型提供灵活的、与类别无关的替代方案。这些 4D 控件被渲染为预训练视频扩散模型的调节信号，从而能够生成精确遵循指定动态的高保真、视图一致的视频。不幸的是，另一个主要挑战在于缺乏具有明确 4D 注释的大规模训练数据。我们通过开发一个自动数据引擎来解决这个问题，该引擎可以从野外视频中提取所需的 4D 控件，从而使我们能够在海量且多样化的数据集上训练我们的模型。|[2601.05138](http://arxiv.org/abs/2601.05138)|null|\n",
        "2601.04778": "|**2026-01-08**|**CounterVid: Counterfactual Video Generation for Mitigating Action and Temporal Hallucinations in Video-Language Models**|视频语言模型（VLM）实现了强大的多模态理解，但仍然容易产生幻觉，特别是在推理动作和时间顺序时。现有的缓解策略，例如文本过滤或随机视频扰动，通常无法解决根本原因：过度依赖语言先验而不是细粒度的视觉动态。我们提出了一种用于反事实视频生成的可扩展框架，该框架合成仅在动作或时间结构上不同的视频，同时保留场景上下文。我们的流程将用于行动建议和编辑指导的多模式法学硕士与基于扩散的图像和视频模型相结合，以大规模生成语义硬底片。使用这个框架，我们构建了 CounterVid，这是一个包含约 26k 个偏好对的合成数据集，目标是动作识别和时间推理。我们进一步介绍 MixDPO，这是一种统一的直接偏好优化方法，联合利用文本和视觉偏好。使用 MixDPO 微调 Qwen2.5-VL 可产生一致的改进，特别是在时间顺序方面，并有效地转移到标准视频幻觉基准。代码和模型将公开。|[2601.04778](http://arxiv.org/abs/2601.04778)|null|\n",
        "2601.04359": "|**2026-01-07**|**PackCache: A Training-Free Acceleration Method for Unified Autoregressive Video Generation via Compact KV-Cache**|统一的自回归模型是一个基于 Transformer 的框架，它将不同的多模态任务（例如文本、图像、视频）作为共享令牌空间下的单序列建模问题来解决。此类模型依靠 KV-cache 机制将注意力计算从 O(T^2) 减少到 O(T)；然而，KV 缓存大小随着生成令牌的数量线性增长，并且它迅速成为限制推理效率和生成长度的主要瓶颈。统一自回归视频生成继承了这一限制。我们的分析表明，KV 缓存标记表现出独特的时空属性：（i）文本和条件图像标记充当持续受到高度关注的持久语义锚，以及（ii）对先前帧的关注随着时间距离自然衰减。利用这些观察结果，我们引入了 PackCache，这是一种免训练的 KV 缓存管理方法，通过三种协调机制动态压缩 KV 缓存：保留语义引用的条件锚定、根据时间距离分配缓存预算的跨帧衰减建模以及在缓存删除下保持连贯 3D 结构的空间保留位置嵌入。在效率方面，PackCache 在 48 帧长序列上将端到端生成速度提高了 1.7-2.2 倍，展示了其实现更长序列视频生成的强大潜力。值得注意的是，最后四帧（受逐渐扩展的 KV 缓存影响最大的部分，因此也是剪辑中最昂贵的部分）对于 48 帧视频，PackCache 分别在 A40 和 H200 上提供了 2.6 倍和 3.7 倍的加速。|[2601.04359](http://arxiv.org/abs/2601.04359)|null|\n",
        "2601.04342": "|**2026-01-07**|**ReHyAt: Recurrent Hybrid Attention for Video Diffusion Transformers**|视频扩散模型的最新进展已转向基于变压器的架构，实现了最先进的视频生成，但代价是二次注意力复杂性，这严重限制了较长序列的可扩展性。我们引入了 ReHyAt，这是一种循环混合注意力机制，它将 softmax 注意力的保真度与线性注意力的效率结合起来，实现了块式循环重构和恒定的内存使用。与仅并发线性 SANA Video 不同，ReHyAt 的混合设计允许对现有基于 softmax 的模型进行高效蒸馏，将训练成本降低两个数量级至约 160 个 GPU 小时，同时在质量上具有竞争力。我们的轻量级蒸馏和微调管道提供了一种方法，可以应用于未来最先进的基于 softmax 的双向模型。 VBench 和 VBench-2.0 上的实验以及人类偏好研究表明，ReHyAt 实现了最先进的视频质量，同时将注意力成本从二次降低到线性，从而解锁了长时间和设备上视频生成的实用可扩展性。项目页面位于 https://qualcomm-ai-research.github.io/rehyat。|[2601.04342](http://arxiv.org/abs/2601.04342)|null|\n",
        "2601.05241": "|**2026-01-08**|**RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation**|操纵数据的多样性、数量和质量对于训练有效的机器人策略至关重要。然而，由于硬件和物理设置的限制，收集大规模的现实世界操作数据仍然难以在不同的环境中扩展。最近的工作使用文本提示条件图像扩散模型，通过改变视觉观察中的背景和桌面对象来增强操作数据。然而，这些方法往往忽视了最先进的政策模型所需的多视角和时间连贯观察的实际需求。此外，仅靠文本提示无法可靠地指定场景设置。为了给扩散模型提供明确的视觉指导，我们引入了视觉识别提示，它提供示例图像作为条件输入，以指导生成所需的场景设置。为此，我们还构建了一个可扩展的管道，以从大型机器人数据集中管理视觉身份池。使用我们的增强操作数据来训练下游视觉语言动作和视觉运动策略模型，可以在模拟和真实机器人设置中产生一致的性能增益。|[2601.05241](http://arxiv.org/abs/2601.05241)|null|\n",
        "2601.05239": "|**2026-01-08**|**Plenoptic Video Generation**|摄像机控制的生成视频重新渲染方法，例如 ReCamMaster，已经取得了显着的进展。然而，尽管它们在单视图设置中取得了成功，但这些作品往往很难在多视图场景中保持一致性。由于生成模型固有的随机性，确保幻觉区域的时空一致性仍然具有挑战性。为了解决这个问题，我们引入了 PlenopticDreamer，这是一个同步生成幻觉以维持时空记忆的框架。核心思想是以自回归方式训练多输入单输出视频条件模型，并辅以摄像机引导的视频检索策略，该策略自适应地选择前几代的显着视频作为条件输入。此外，我们的训练还结合了渐进式上下文缩放以提高收敛性、自我调节以增强针对错误累积引起的远程视觉退化的鲁棒性，以及长视频调节机制以支持扩展视频生成。 Basic 和 Agibot 基准测试的大量实验表明，PlenopticDreamer 实现了最先进的视频重新渲染，提供卓越的视图同步、高保真视觉效果、精确的摄像机控制和多样化的视图转换（例如，第三人称到第三人称，以及机器人操作中从头视图到抓手视图）。项目页面：https://research.nvidia.com/labs/dir/plenopticdreamer/|[2601.05239](http://arxiv.org/abs/2601.05239)|null|\n",
        "2601.05966": "|**2026-01-09**|**VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction**|视频生成领域的最新进展主要由扩散和流匹配模型主导，这些模型可以产生高质量的结果，但计算量仍然很大且难以扩展。在这项工作中，我们介绍了 VideoAR，这是第一个用于视频生成的大规模视觉自回归 (VAR) 框架，它将多尺度下一帧预测与自回归建模相结合。 VideoAR 通过将帧内 VAR 建模与因果下一帧预测相集成，消除了空间和时间依赖性，并由可有效编码时空动态的 3D 多尺度分词器支持。为了提高长期一致性，我们提出了多尺度时间 RoPE、跨帧纠错和随机帧掩模，它们共同减轻了错误传播并稳定了时间相干性。我们的多阶段预训练管道逐步调整空间和时间学习，以提高分辨率和持续时间。根据经验，VideoAR 在自回归模型中取得了最先进的结果，将 UCF-101 上的 FVD 从 99.5 提高到 88.6，同时将推理步骤减少了 10 倍以上，并达到了 81.74 的 VBench 分数，与基于扩散的模型相比要高出一个数量级。这些结果表明，VideoAR 缩小了自回归和扩散范式之间的性能差距，为未来的视频生成研究提供了可扩展、高效且时间一致的基础。|[2601.05966](http://arxiv.org/abs/2601.05966)|null|\n",
        "2601.05848": "|**2026-01-09**|**Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals**|视频生成领域的最新进展使得能够模拟机器人和规划的潜在未来的“世界模型”的开发成为可能。然而，为这些模型指定精确的目标仍然是一个挑战；文本指令通常过于抽象，无法捕捉物理细微差别，而目标图像通常无法为动态任务指定。为了解决这个问题，我们引入了 Goal Force，这是一种新颖的框架，允许用户通过明确的力向量和中间动力学来定义目标，反映了人类如何概念化物理任务。我们在合成因果原语（例如弹性碰撞和倒下的多米诺骨牌）的精选数据集上训练视频生成模型，教导它通过时间和空间传播力。尽管接受了简单物理数据的训练，但我们的模型对复杂的现实世界场景（包括工具操作和多对象因果链）表现出出色的零样本泛化能力。我们的结果表明，通过将视频生成基于基本的物理交互，模型可以作为隐式神经物理模拟器出现，从而无需依赖外部引擎即可实现精确的物理感知规划。我们在项目页面发布了所有数据集、代码、模型权重和交互式视频演示。|[2601.05848](http://arxiv.org/abs/2601.05848)|null|\n",
        "2601.05729": "|**2026-01-09**|**TAGRPO: Boosting GRPO on Image-to-Video Generation with Direct Trajectory Alignment**|最近的研究证明了将组相对策略优化（GRPO）集成到流匹配模型中的有效性，特别是对于文本到图像和文本到视频的生成。然而，我们发现直接将这些技术应用于图像到视频（I2V）模型通常无法产生一致的奖励改进。为了解决这个限制，我们提出了 TAGRPO，这是一个受对比学习启发的强大的 I2V 模型训练后框架。我们的方法基于这样的观察：从相同的初始噪声生成的推出视频为优化提供了卓越的指导。利用这一见解，我们提出了一种应用于中间潜伏的新型 GRPO 损失，鼓励与高奖励轨迹直接对齐，同时最大化与低奖励对应轨迹的距离。此外，我们引入了用于展示视频的内存库，以增强多样性并减少计算开销。尽管很简单，但 TAGRPO 在 I2V 生成方面比 DanceGRPO 实现了显着改进。|[2601.05729](http://arxiv.org/abs/2601.05729)|null|\n",
        "2601.05722": "|**2026-01-09**|**Rotate Your Character: Revisiting Video Diffusion Models for High-Quality 3D Character Generation**|从单个图像生成高质量的 3D 角色仍然是数字内容创建中的一项重大挑战，特别是由于复杂的身体姿势和自遮挡。在本文中，我们介绍了 RCM（旋转角色模型），这是一种高级图像到视频扩散框架，专为高质量小说视图合成 (NVS) 和 3D 角色生成而定制。与现有的基于扩散的方法相比，RCM 具有几个关键优势：(1) 将具有任何复杂姿势的角色转换为规范姿势，从而在整个观看轨道上实现一致的新颖视图合成；(2) 生成 1024x1024 分辨率的高分辨率轨道视频；(3) 给定不同的初始相机姿势，可控制观察位置；(4) 多视图调节支持最多 4 个输入图像，适应不同的用户场景。大量实验表明，RCM 在新颖的视图合成和 3D 生成质量方面均优于最先进的方法。|[2601.05722](http://arxiv.org/abs/2601.05722)|null|\n",
        "2601.05511": "|**2026-01-09**|**GaussianSwap: Animatable Video Face Swapping with 3D Gaussian Splatting**|我们引入了 GaussianSwap，一种新颖的视频人脸交换框架，它从目标视频构建基于 3D 高斯 Splatting 的人脸头像，同时将身份从源图像转移到头像。传统的视频交换框架仅限于生成基于像素的格式的面部表示。由此产生的交换面仅作为一组非结构化像素存在，没有任何动画或交互操作的能力。我们的工作引入了从传统的基于像素的视频生成到创建具有交换面孔的高保真头像的范式转变。该框架首先对目标视频进行预处理，以提取 FLAME 参数、相机姿势和分割蒙版，然后将 3D 高斯分布跨帧绑定到 FLAME 模型，从而实现动态面部控制。为了确保身份保留，我们提出了一种由三种最先进的人脸识别模型构建的复合身份嵌入，用于头像微调。最后，我们将换脸头像渲染在背景帧上，得到换脸视频。实验结果表明，GaussianSwap 实现了卓越的身份保留、视觉清晰度和时间一致性，同时实现了以前无法实现的交互式应用程序。|[2601.05511](http://arxiv.org/abs/2601.05511)|null|\n",
        "2601.06391": "|**2026-01-10**|**Object-WIPER : Training-Free Object and Associated Effect Removal in Videos**|在本文中，我们介绍了 Object-WIPER，这是一个免训练框架，用于从视频中删除动态对象及其相关的视觉效果，并用语义一致和时间连贯的内容修复它们。我们的方法利用预先训练的文本到视频扩散转换器（DiT）。给定输入视频、用户提供的对象掩码以及描述目标对象及其效果的查询标记，我们通过视觉文本交叉注意和视觉自注意来定位相关的视觉标记。这会产生一个中间效果掩码，我们将其与用户掩码融合以获得要替换的最终前景标记掩码。我们首先通过 DiT 反转视频以获得结构化噪声，然后用高斯噪声重新初始化屏蔽标记，同时保留背景标记。在去噪过程中，我们复制反转过程中保存的背景标记的值，以保持场景保真度。为了解决缺乏适当评估的问题，我们引入了一种新的对象删除指标，该指标奖励连续帧中前景标记之间的时间一致性、每帧内前景和背景标记之间的一致性以及输入和输出前景标记之间的相异性。 DAVIS 和新策划的现实世界关联效应基准 (WIPER-Bench) 上的实验表明，Object-WIPER 在指标方面超越了基于训练和无训练的基线，无需任何再训练即可实现干净的去除和时间稳定的重建。我们的新基准、源代码和预训练模型将公开。|[2601.06391](http://arxiv.org/abs/2601.06391)|null|\n",
        "2601.06287": "|**2026-01-09**|**Perception Test 2025: Challenge Summary and a Unified VQA Extension**|第三次感知测试挑战赛是与 IEEE/CVF 国际计算机视觉会议 (ICCV) 2025 同期举办的全天研讨会。其主要目标是对最先进的视频模型进行基准测试并衡量多模态感知的进展。今年，研讨会还有 2 个客座曲目：KiVA（图像理解挑战）和 Physic-IQ（视频生成挑战）。在本报告中，我们总结了主要感知测试挑战的结果，详细介绍了现有任务以及基准测试的新增内容。在本次迭代中，我们强调任务统一，因为这对当前的 SOTA 多模态模型提出了更具挑战性的测试。该挑战包括五个综合轨道：统一视频 QA、统一对象和点跟踪、统一动作和声音本地化、接地视频 QA 和长达一小时的视频 QA，以及仍可供提交的分析和可解释性轨道。值得注意的是，统一视频 QA 轨道引入了一个新颖的子集，它将传统的感知任务（例如点跟踪和时间动作定位）重新表述为视频语言模型可以本地解决的多项选择视频 QA 问题。统一的对象和点跟踪合并了原始的对象跟踪和点跟踪任务，而统一的动作和声音定位合并了原始的时间动作定位和时间声音定位轨道。因此，我们要求竞争对手使用统一的方法，而不是使用特定于任务的模型来设计管道。通过提出这样一个统一的挑战，Perception Test 2025 强调了现有模型在通过统一接口处理不同感知任务时面临的重大困难。|[2601.06287](http://arxiv.org/abs/2601.06287)|null|\n",
        "2601.07832": "|**2026-01-12**|**MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head**|虽然 Transformer 架构在许多领域占据主导地位，但其二次自注意力复杂性阻碍了其在大规模应用中的使用。线性注意力提供了一种有效的替代方案，但其直接应用通常会降低性能，现有的修复通常会通过额外的模块（例如深度可分离卷积）重新引入计算开销，从而违背了最初的目的。在这项工作中，我们确定了这些方法中的一个关键失败模式：全局上下文崩溃，其中模型失去了表征多样性。为了解决这个问题，我们提出了多头线性注意力（MHLA），它通过沿着令牌维度计算分割头内的注意力来保留这种多样性。我们证明 MHLA 保持了线性复杂度，同时恢复了 Softmax Attention 的大部分表达能力，并验证了其在多个领域的有效性，在相同时间复杂度下，在 ImageNet 分类上实现了 3.6\\% 的改进，在 NLP 上实现了 6.3\\% 的增益，在图像生成上实现了 12.6\\% 的改进，在视频生成上实现了 41\\% 的增强。|[2601.07832](http://arxiv.org/abs/2601.07832)|null|\n",
        "2601.07823": "|**2026-01-12**|**Video Generation Models in Robotics -- Applications, Research Challenges, Future Directions**|视频生成模型已经成为物理世界的高保真模型，能够合成高质量视频，捕捉代理与其环境之间的细粒度交互，这些交互取决于多模式用户输入。它们令人印象深刻的功能解决了基于物理的模拟器面临的许多长期挑战，推动了许多问题领域的广泛采用，例如机器人技术。例如，视频模型可以实现逼真、物理一致的变形体模拟，而无需做出令人望而却步的简化假设，这是基于物理的模拟的主要瓶颈。此外，视频模型可以作为基础世界模型，以细粒度和富有表现力的方式捕捉世界的动态。因此，它们在描述复杂的物理交互时克服了纯语言抽象的有限表达能力。在本次调查中，我们回顾了视频模型及其在机器人技术中作为具体世界模型的应用，包括模仿学习中具有成本效益的数据生成和动作预测、强化学习中的动态和奖励建模、视觉规划和政策评估。此外，我们强调了阻碍视频模型在机器人技术中可靠集成的重要挑战，其中包括指令遵循不佳、违反物理等幻觉以及不安全的内容生成，以及重要的数据管理、培训和推理成本等基本限制。我们提出了解决这些开放研究挑战的潜在未来方向，以激励研究并最终促进更广泛的应用，特别是在安全关键的环境中。|[2601.07823](http://arxiv.org/abs/2601.07823)|null|\n",
        "2601.07660": "|**2026-01-12**|**StdGEN++: A Comprehensive System for Semantic-Decomposed 3D Character Generation**|我们推出了 StdGEN++，这是一种新颖且全面的系统，用于从不同的输入生成高保真、语义分解的 3D 角色。现有的 3D 生成方法通常会生成整体网格，缺乏游戏和动画工业管道所需的结构灵活性。为了解决这一差距，StdGEN++ 建立在双分支语义感知大型重建模型（双分支 S-LRM）的基础上，该模型以前馈方式联合重建几何、颜色和每个组件的语义。为了实现生产级保真度，我们引入了一种与混合隐式字段兼容的新颖的语义表面提取形式。该机制通过从粗到细的提议方案来加速，从而显着减少内存占用并实现高分辨率网格生成。此外，我们提出了一种基于视频扩散的纹理分解模块，将外观分解为可编辑层（例如，分离的虹膜和皮肤），解决面部区域的语义混淆。实验表明，StdGEN++ 实现了最先进的性能，在几何精度和语义解缠方面显着优于现有方法。至关重要的是，由此产生的结构独立性解锁了先进的下游功能，包括无损编辑、符合物理的动画和视线跟踪，使其成为自动化角色资产生产的强大解决方案。|[2601.07660](http://arxiv.org/abs/2601.07660)|null|\n",
        "2601.07396": "|**2026-01-12**|**Forecast the Principal, Stabilize the Residual: Subspace-Aware Feature Caching for Efficient Diffusion Transformers**|扩散变压器 (DiT) 模型在图像和视频生成方面取得了前所未有的质量，但其迭代采样过程在计算上仍然令人望而却步。为了加速推理，通过跨时间步重用中间表示出现了特征缓存方法。然而，现有的缓存方法统一处理所有特征组件。我们揭示了 DiT 特征空间包含不同的主子空间和残差子空间，具有不同的时间行为：主子空间平稳且可预测地演化，而残差子空间表现出不稳定的低能量振荡，难以准确预测。基于这一见解，我们提出了 SVD-Cache，这是一种子空间感知的缓存框架，它通过奇异值分解（SVD）分解扩散特征，将指数移动平均（EMA）预测应用于主要的低秩分量，并直接重用残差子空间。大量的实验表明，SVD-Cache 在不同的模型和方法中实现了近乎无损的效果，包括在 FLUX 和 HunyuanVideo 上实现了 5.55$\\times$ 的加速，以及与蒸馏、量化和稀疏注意力等模型加速技术的兼容性。我们的代码位于补充材料中，并将在 Github 上发布。|[2601.07396](http://arxiv.org/abs/2601.07396)|null|\n",
        "2601.07287": "|**2026-01-12**|**Focal Guidance: Unlocking Controllability from Semantic-Weak Layers in Video Diffusion Models**|图像到视频（I2V）生成的任务旨在根据参考图像和文本提示合成视频。这需要扩散模型在去噪过程中协调高频视觉约束和低频文本指导。然而，虽然现有的 I2V 模型优先考虑视觉一致性，但如何有效地结合这种双重指导以确保严格遵守文本提示仍有待探索。在这项工作中，我们观察到，在基于扩散变压器 (DiT) 的 I2V 模型中，某些中间层表现出弱语义响应（称为语义弱层），如文本视觉相似性可测量的下降所示。我们将此归因于一种称为“条件隔离”的现象，即对视觉特征的注意力部分脱离文本指导，并过度依赖学习的视觉先验。为了解决这个问题，我们提出了焦点引导（FG），它增强了语义弱层的可控性。 FG 包括两种机制：（1）细粒度语义引导（FSG）利用 CLIP 来识别参考框架中的关键区域，并将它们用作锚点来指导语义弱层。 （2）注意力缓存将注意力图从语义响应层转移到语义弱层，注入显式语义信号并减轻它们对模型学习的视觉先验的过度依赖，从而增强对文本指令的遵守。为了进一步验证我们的方法并解决这方面缺乏评估的问题，我们引入了一个用于评估 I2V 模型中指令遵循的基准。在此基准测试中，Focal Guidance 证明了其有效性和普适性，将 Wan2.1-I2V 的总分提升至 0.7250 (+3.97\\%)，并将基于 MMDiT 的 HunyuanVideo-I2V 提升至 0.5571 (+7.44\\%)。|[2601.07287](http://arxiv.org/abs/2601.07287)|null|\n"
    },
    "3D": {
        "2601.04120": "|**2026-01-07**|**A Single-Loop Bilevel Deep Learning Method for Optimal Control of Obstacle Problems**|障碍问题的最优控制出现在广泛的应用中，并且由于其非平滑性、非线性和双层结构而在计算上具有挑战性。经典数值方法依赖于基于网格的离散化，通常需要解决一系列代价高昂的子问题。在这项工作中，我们提出了一种单循环双层深度学习方法，该方法是无网格的，可扩展到高维和复杂领域，并避免重复求解离散子问题。该方法采用约束嵌入神经网络来近似状态并控制并保留双层结构。为了有效地训练神经网络，我们提出了一种单循环随机一阶双层算法（S2-FOBA），该算法消除了嵌套优化，并且不依赖于限制性的较低级别唯一性假设。我们在温和的假设下分析了 S2-FOBA 的收敛行为。对基准示例（包括复杂域上规则和不规则障碍物的分布式障碍控制问题）的数值实验表明，与经典数值方法相比，该方法取得了令人满意的精度，同时降低了计算成本。|[2601.04120](http://arxiv.org/abs/2601.04120)|null|\n",
        "2601.04099": "|**2026-01-07**|**A constrained-transport embedded boundary method for compressible resistive magnetohydrodynamics**|近年来人们对脉冲功率磁惯性聚变装置的兴趣日益浓厚，我们提出了一种在笛卡尔网格上实现任意形状的嵌入边界，同时求解可压缩电阻磁流体动力学方程的方法。该方法是围绕方程的有限体积公式构建的，其中黎曼求解器用于计算网格单元之间的面上的通量，以及归纳方程的面心约束输运公式。通过始终计算笛卡尔网格的面和边缘上的通量，可以避免与切割单元相关的小时间步长问题。我们扩展了该方法，使用幻影流体方法来模拟两种具有不同属性的材料之间的移动界面，并展示了一些初步结果，包括磁流体静力学平衡的冲击波驱动和磁驱动动态压缩。我们对该方法进行了彻底的验证，并表明它在没有不连续性的情况下以二阶收敛，在材料属性不连续的情况下以一阶收敛。|[2601.04099](http://arxiv.org/abs/2601.04099)|null|\n",
        "2601.04075": "|**2026-01-07**|**A higher order sparse grid combination technique**|我们证明了一种广义稀疏网格组合技术，它将有限差分解的多元外推与标准组合公式相结合，将规则网格上的二阶精确方案提升为四阶组合稀疏网格解。在分析中，在一般维度上工作，我们将方案的多元误差展开中的所有项表征为一系列半离散问题的解。首先在对方案的截断误差、解的稳定性和规律性的适当假设下正式进行。然后，我们用平滑数据验证泊松问题示例的假设，并说明最多七个维度的实际收敛。|[2601.04075](http://arxiv.org/abs/2601.04075)|null|\n",
        "2601.04054": "|**2026-01-07**|**LinkD: AutoRegressive Diffusion Model for Mechanical Linkage Synthesis**|由于连续节点放置、离散拓扑配置和非线性运动学约束之间的复杂耦合，设计机械连杆以实现目标末端执行器轨迹提出了根本性挑战。高度非线性的运动与配置关系意味着关节位置的小扰动会极大地改变轨迹，而组合扩展的设计空间使得传统的优化和启发式方法在计算上变得难以处理。我们引入了一种自回归扩散框架，该框架通过将机制表示为顺序构造的图来利用连杆组装的二元性质，其中节点对应于关节，边缘对应于刚性连杆。我们的方法将因果变换器与去噪扩散概率模型（DDPM）相结合，两者都以通过变换器编码器编码的目标轨迹为条件。因果变换器自回归逐节点预测离散拓扑，而 DDPM 则细化每个节点的空间坐标和与先前生成的节点的边缘连接。这种顺序生成实现了自适应试错综合，其中表现出运动锁定或碰撞的有问题的节点可以选择性地重新生成，从而允许在设计期间自主纠正简并配置。我们基于图形的数据驱动方法超越了传统的优化方法，实现了可扩展的逆向设计，可推广到具有任意节点数的机制。我们展示了包含多达 20 个节点的链接系统的成功综合，并且可扩展至 N 节点架构。这项工作推进了自回归图生成方法和计算运动学综合，为复杂机械系统的可扩展逆向设计建立了新的范例。|[2601.04054](http://arxiv.org/abs/2601.04054)|null|\n",
        "2601.04013": "|**2026-01-07**|**Effects of Horizontal Discretization on Triangular and Hexagonal Grids on Linear Baroclinic and Symmetric Instabilities**|由于全球海洋环流模型是在允许涡流的分辨率下运行的，因此在选择运动方程的离散化时，准确再现斜压不稳定性的增长率是一个主要问题。从这个角度来看，我们分析了几种海洋环流模型中使用的具有不同类型变量交错的三角形和六边形网格上的离散化。通过将 Eady 配置中的线性斜压不稳定性分析扩展到更复杂网格上的离散化，揭示了一些数值上的微妙之处。与四边形网格上的离散化相比，分析的离散化对于不稳定的杂散模式（部分由网格几何形状产生）的鲁棒性较差。一些微妙之处的出现是因为交错三角形和六边形网格上的杂散模式不遵守伽利略不变性。因此，它们的增长率表现出对背景流和网格之间的对齐以及均匀背景流的强度的依赖性。与寄生模式的相互作用在对称不稳定性轴上变得更加重要，其中不稳定的物理分支和寄生分支在波数空间中更难以分离。我们的分析表明，在大多数情况下，适度的双调和粘度和扩散会抑制虚假分支。然而，为了实现这一目标，需要仔细校准每个考虑的离散化的粘度和扩散率参数。|[2601.04013](http://arxiv.org/abs/2601.04013)|null|\n",
        "2601.03993": "|**2026-01-07**|**PosterVerse: A Full-Workflow Framework for Commercial-Grade Poster Generation with HTML-Based Scalable Typography**|商业级海报设计需要将审美吸引力与精确、信息丰富的内容传递无缝结合。当前的自动海报生成系统面临着重大限制，包括不完整的设计工作流程、文本渲染精度差以及商业应用灵活性不足。为了应对这些挑战，我们提出了 PosterVerse，这是一种完整工作流程的商业级海报生成方法，可以无缝地自动化整个设计过程，同时提供高密度和可扩展的文本渲染。 PosterVerse 通过三个关键阶段复制专业设计：(1) 使用微调的 LLM 创建蓝图，从用户需求中提取关键设计元素，(2) 通过定制的扩散模型生成图形背景，以创建视觉上吸引人的图像，以及 (3) 使用 MLLM 支持的 HTML 引擎进行统一的布局文本渲染，以保证高文本准确性和灵活的定制。此外，我们还推出了 PosterDNA，这是一个商业级的、基于 HTML 的数据集，专为训练和验证海报设计模型而定制。据我们所知，PosterDNA是第一个引入HTML排版文件的中文海报生成数据集，实现可扩展的文本渲染，从根本上解决渲染小而高密度文本的挑战。实验结果表明，PosterVerse 始终能够生成具有吸引人的视觉效果、准确的文本对齐和可定制布局的商业级海报，使其成为自动化商业海报设计的有前途的解决方案。代码和模型可在 https://github.com/wuhaer/PosterVerse 获取。|[2601.03993](http://arxiv.org/abs/2601.03993)|null|\n",
        "2601.03975": "|**2026-01-07**|**Cavity-Driven Multispectral Gain for High-Sensitivity NV Center Magnetometers**|我们报告了一种基于 NV 系综与介电腔耦合的腔式固态磁力计，实现了 12 pT/$\\sqrt{\\rm{Hz}}$ 灵敏度和多光谱特征近三倍的增益。这些特征源于腔引起的 NV 超精细能级分裂，并利用系统双修饰状态中强大的量子相干性来实现高灵敏度。我们预测模拟的近期灵敏度接近 100 fT/$\\sqrt{\\rm{Hz}}$，接近约翰逊-奈奎斯特极限。我们的结果将频率复用确立为一种新的操作范例，为环境条件下的计量提供强大且可扩展的量子资源。|[2601.03975](http://arxiv.org/abs/2601.03975)|null|\n",
        "2601.03954": "|**2026-01-07**|**Computing the Intrinsic Delaunay Triangulation of a Closed Polyhedral Surface**|每个本质上是多面体的表面都可以用门户边形来表示：欧几里得平面中的多边形集合，并抽象地标识出一些对等长的边。虽然这种表示形式可以说比网格（R3 中的平面多边形形成表面）更简单，但它具有无限的快乐：表面中的最短路径可以任意多次访问同一个多边形。这种病态行为是高效算法的障碍。另一方面，Löffler、Ophelders、Staals 和 Silveira (SoCG 2023) 最近证明，（内在的）Delaunay 三角剖分具有有限的幸福感。   在本文中，给定一个由三角形入口边 T 表示的闭合多面体曲面 S，我们提供了一种算法来计算 S 的 Delaunay 三角剖分，其顶点是 S 的奇点（包围角不同于 2pi 的点）。我们算法的时间复杂度是三角形数量和 T 的纵横比 r 对数的多项式。在我们的计算模型中，我们表明 log(r) 中的依赖性是不可避免的。我们的算法可用于在计算三角形门户网站表面上的最短路径之前对其进行预处理，并确定两个三角形门户网站的表面是否等距。|[2601.03954](http://arxiv.org/abs/2601.03954)|null|\n",
        "2601.03943": "|**2026-01-07**|**A laser plasma soliton fusion scheme**|我们引入了一种由激光等离子体孤子实现的新型聚变方案，该方案有望克服达到盈亏平衡条件的几个基本障碍。具体而言，我们使用氘氚（DT）作为燃料。孤立子内部的强电磁场显着增强了 DT 聚变截面，其有质动力势能疏散电子，并将 D/T 加速到适合聚变反应的动能。虽然电子几乎立即被排出，但更重的 D/T 以皮秒时间尺度移动。这种时间尺度的差异为DT聚变在无电子环境中有效发生提供了时间窗口。我们注入两个连续的激光，其中第一个将激发等离子体孤子，第二个更强烈且具有匹配的较低频率，将共振地增强孤子电磁场。我们施加等离子体密度梯度来诱导孤子运动。在其生命周期内被移动孤子扫过的等离子体柱内的所有 D/T 都将参与这种聚变机制。我们证明盈亏平衡条件是可以实现的。利用光纤激光器和 iCAN 激光器技术进行高重复率和高强度操作，千兆瓦输出也许是可以想象的。|[2601.03943](http://arxiv.org/abs/2601.03943)|null|\n",
        "2601.03935": "|**2026-01-07**|**Accelerated simulation of multiscale gas-radiation coupling flows via a general synthetic iterative scheme**|气体-辐射耦合严重影响高超声速再入流，其中极端温度会导致明显的非平衡气体和辐射热传输。因此，准确有效的辐射气体动力学模拟对于大气进入车辆热防护系统的可靠设计是必不可少的。在这项研究中，使用通用合成迭代方案（GSIS）在广泛的流动和辐射传输范围内求解了辐射气流的玻尔兹曼型动力学模型。该方法将非结构化有限体积离散速度方法与一组宏观综合方程相结合。在此框架内，动力学模型为合成方程中的本构关系提供了高阶闭包。同时，宏观综合方程驱动介观动力学系统的演化，显着加速近连续体系的稳态收敛，线性傅里叶稳定性分析证实了这一点。至关重要的是，该算法被证明是渐进保持的，可以正确恢复连续谱和光学厚度极限，由辐射纳维-斯托克斯-傅里叶方程表示，在独立于平均自由程的粗网格上控制不同的平移、旋转、振动和辐射温度。对具有挑战性的基准（包括阿波罗再入舱上的三维高超音速流）的数值模拟表明，GSIS 在辐射气流的多尺度模拟中比传统迭代方案实现了数量级的加速，同时准确捕获高超音速环境中的非平衡效应和辐射传热。|[2601.03935](http://arxiv.org/abs/2601.03935)|null|\n",
        "2601.05186": "|**2026-01-08**|**Non-Thermal Leptogenesis in the BLSM with Inverse Seesaw Mechanism**|我们研究了标准模型 (BLSM) 的测量 $U(1)_{B-L}$ 扩展中非热轻子发生的可行性，以及用于中微子质量产生的逆跷跷板 (ISS) 机制。在这个框架中，右手中微子通常具有 $\\mathcal{O}(1)$ 汤川耦合，这会引起强烈的冲刷效应并使传统的热轻子发生无效。我们证明，成功的重子发生场景仍然可以通过非热轻子发生来实现，其中右旋中微子是由重 $B\\!-\\!L$ 希格斯玻色子 $χ$ 的衰变产生的。我们明确分析了稀释因子 $T_R/M_χ$ 与国际空间站的冲刷参数特征之间的相互作用，强调了抑制冲刷效应和保持充分再加热之间的紧张关系。我们表明，只要适当调整标量质谱，就可以产生可行的轻子不对称性，从而降低再加热温度，同时保持冲洗受到控制。由此产生的轻子不对称性通过闪子过程有效地转化为观测到的宇宙重子不对称性。我们的结果表明，反向跷跷板 $B\\!-\\!L$ 模型仍然是非热轻体发生和重子发生的预测性且稳健的框架。|[2601.05186](http://arxiv.org/abs/2601.05186)|null|\n",
        "2601.05138": "|**2026-01-08**|**VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control**|视频世界模型旨在模拟动态的真实世界环境，但现有方法难以对摄像机和多对象运动提供统一且精确的控制，因为视频本质上是在投影的 2D 图像平面中进行动态操作。为了弥补这一差距，我们引入了 VerseCrafter，这是一种 4D 感知视频世界模型，可以在统一的 4D 几何世界状态中对摄像机和对象动态进行明确且连贯的控制。我们的方法以新颖的 4D 几何控制表示为中心，它通过静态背景点云和每个对象的 3D 高斯轨迹对世界状态进行编码。这种表示不仅可以捕获对象的路径，还可以捕获其随时间变化的概率 3D 占用情况，为刚性边界框或参数模型提供灵活的、与类别无关的替代方案。这些 4D 控件被渲染为预训练视频扩散模型的调节信号，从而能够生成精确遵循指定动态的高保真、视图一致的视频。不幸的是，另一个主要挑战在于缺乏具有明确 4D 注释的大规模训练数据。我们通过开发一个自动数据引擎来解决这个问题，该引擎可以从野外视频中提取所需的 4D 控件，从而使我们能够在海量且多样化的数据集上训练我们的模型。|[2601.05138](http://arxiv.org/abs/2601.05138)|null|\n",
        "2601.05120": "|**2026-01-08**|**Multigroup Radiation Diffusion on a Moving Mesh: Implementation in RICH and Application to Tidal Disruption Events**|辐射流体动力学（RHD）决定了各种高能天体物理现象的整体演化和可观测发射。由于其复杂性，RHD 问题通常必须通过数值模拟来研究。我们扩展了公开可用的 RICH 代码，该代码之前在灰色通量有限扩散 (FLD) 的限制下求解 RHD 方程，以便与多组 FLD 求解器一起运行。 RICH 是一种半拉格朗日代码，可求解非结构化移动网格上的 RHD 方程，并且是第一个多组 RHD 移动网格代码，使其特别适用于具有极端动态范围和动态重要辐射力的问题。我们根据多个分析基准验证我们的多组模块，包括 RHD 多普勒项的新颖测试。代码的计算效率得到了一种加速光学厚单元收敛的新方案的帮助。最后，我们使用 $10^4 M_\\odot$ 中等质量黑洞，将多群 RICH 应用于恒星潮汐破坏事件 (TDE) 的试点研究。我们的模拟在峰值光学/紫外光之前自洽地产生明亮的早期 X 射线闪光，与超大质量黑洞 TDE 的（灰色）RICH 模拟的后处理以及 TDE AT 2022dsb 的 X 射线观测定性一致。|[2601.05120](http://arxiv.org/abs/2601.05120)|null|\n",
        "2601.05116": "|**2026-01-08**|**From Rays to Projections: Better Inputs for Feed-Forward View Synthesis**|前馈视图合成模型以最小的 3D 归纳偏差一次性预测新视图。现有的工作将相机编码为普吕克射线图，它将预测与任意世界坐标规范联系起来，并使它们对小型相机变换敏感，从而破坏了几何一致性。在本文中，我们询问什么输入最适合模型以实现稳健且一致的视图合成。我们提出了投影调节，它用提供稳定 2D 输入的目标视图投影提示替换原始相机参数。这将任务从光线空间中的脆弱几何回归问题重新构建为条件良好的目标视图图像到图像转换问题。此外，我们引入了针对此线索量身定制的屏蔽自动编码预训练策略，从而可以使用大规模未校准数据进行预训练。与视图一致性基准上的光线条件基线相比，我们的方法显示出更高的保真度和更强的跨视图一致性。它还在标准新颖视图合成基准上实现了最先进的质量。|[2601.05116](http://arxiv.org/abs/2601.05116)|null|\n",
        "2601.05094": "|**2026-01-08**|**How Dark is Dark? A Reflectance and Scattering Analysis of Black Materials**|黑色材料在图像配准、相机校准、杂散光抑制和视觉设计等应用中发挥着至关重要的作用。尽管许多此类材料在漫射照明下看起来相似地较暗，但它们的反射率行为可能会因观察和照明几何形状而有很大差异。超黑材料可实现出色的光衰减，但通常受到成本和机械脆弱性的限制，这促使人们评估更坚固、更易于使用的替代品。在本研究中，我们采用测角测量系统来捕获一系列黑色材料的各向同性双向反射率分布函数，包括超黑参考 Vantablack、Musou Black 和黑色天鹅绒等市售替代品以及标准哑光黑色涂层。我们根据漫反射和镜面散射以及总积分散射来分析它们的反射特性，以量化与角度相关的反射。此外，我们使用由测量的 BRDF 驱动的基于物理的渲染和对感知黑暗的心理物理学评估来比较它们的感知外观。这些分析共同提供了对黑色材料的全面评估，将反射特性与视觉外观和感知性能联系起来，从而为光学应用提供明智的材料选择。|[2601.05094](http://arxiv.org/abs/2601.05094)|null|\n",
        "2601.05071": "|**2026-01-08**|**A high order accurate and provably stable fully discrete continuous Galerkin framework on summation-by-parts form for advection-diffusion equations**|我们提出了一种高阶精确的完全离散数值方案，用于在基于连续伽辽金 (CG) 的有限元框架内求解初始边值问题 (IBVP)。这里考虑按部分求和（SBP）形式的空间和时间近似。使用同时逼近项 (SAT) 技术弱施加初始条件和边界条件。由此产生的 SBP-SAT 公式根据初始和外部边界数据产生能量估计，从而在空间和时间上实现能量稳定的离散化。使用制造解决方案（MMS）的方法对所提出的方法进行数值评估。该方案在空间和时间方向上实现了超收敛，对于$p\\geq 2$，精度为$\\mathcal{O}(p+2)$，其中$p$指的是拉格朗日基的阶数。在一个应用案例中，我们表明，即使在粗网格上，完全离散的公式也能有效地捕获时空变化，从而证明了该方法的计算有效性。|[2601.05071](http://arxiv.org/abs/2601.05071)|null|\n",
        "2601.05063": "|**2026-01-08**|**Quantitative mapping from conventional MRI using self-supervised physics-guided deep learning: applications to a large-scale, clinically heterogeneous dataset**|磁共振成像 (MRI) 是临床神经影像的基石，但传统 MRI 提供的定性信息严重依赖于扫描仪硬件和采集设置。虽然定量 MRI (qMRI) 提供了内在的组织参数，但对专门采集协议和重建算法的要求限制了其可用性并阻碍了大规模生物标志物研究。本研究提出了一种自监督物理引导深度学习框架，可直接从广泛使用的临床常规 T1 加权、T2 加权和 FLAIR MRI 推断定量 T1、T2 和质子密度 (PD) 图。该框架在大规模临床异构数据集上进行了训练和评估，该数据集包括我们机构六年来在四个不同 3 T MRI 扫描仪系统上采集的 4,121 个扫描会话，捕获了真实世界的临床变异性。该框架将基于 Bloch 的信号模型直接集成到训练目标中。在 600 多次测试中，生成的图显示出与文献范围一致的白质和灰质值。此外，生成的图显示扫描仪硬件和采集协议组的不变性，组间变异系数 $\\leq$ 1.1%。针对特定对象的分析表明，扫描仪系统和序列参数具有出色的体素重现性，T1 和 T2 的 Pearson $r$ 和一致性相关系数超过 0.82。所有定量参数的平均相对体素差异都很低，尤其是 T2（$<$6%）。这些结果表明，所提出的框架可以稳健地将各种临床常规 MRI 数据转换为定量图，可能为大规模定量生物标志物研究铺平道路。|[2601.05063](http://arxiv.org/abs/2601.05063)|null|\n",
        "2601.05041": "|**2026-01-08**|**The Initial Value Problem for the Generalised Einstein Equations**|我们讨论了闭散度情况下希钦广义几何中的爱因斯坦方程的初值问题（对应于 II 型十维超重力中 NS-NS 扇区的玻色子部分的运动方程），并建立了最大全局双曲展开（MGHD）的存在性。在 $n+1$ 维流形上定义的动力场是时空度量、称为膨胀函数的标量场和称为 $B$ 场的两种形式。我们开发了洛伦兹规范的推广，将其应用于 $B$ 场（并与打破微分同胚不变性的合适规范条件相结合），使系统成为一个波动方程，其主要符号由（动态）度量给出。给定初始数据，我们构建满足规范条件的发展。我们表明，所有其他发展都（在适当的意义上）通过微分同胚与这种发展相关，从而建立了几何唯一性。 MGHD 的存在源于 Choquet-Bruhat 和 Geroch 的著名结果。   在展示发展的存在性和几何唯一性时，我们遵循 Ringström 为与标量场耦合的爱因斯坦方程详细开发的方法。在初步部分中，我们提出了一种与对该问题所做的具体假设无关的表述，因此可以直接适应其他系统。|[2601.05041](http://arxiv.org/abs/2601.05041)|null|\n",
        "2601.05035": "|**2026-01-08**|**Patch-based Representation and Learning for Efficient Deformation Modeling**|在本文中，我们提出了一种基于面片的表面表示形式 PolyFit，它是通过在表面面片上局部拟合射流函数而获得的。这种表示可以以有监督的方式从分析函数和真实数据中有效地学习。一旦学习，它就可以推广到各种类型的表面。使用 PolyFit，可以通过更新一组紧凑的射流系数来有效地使表面变形，而不是针对计算机视觉和图形中的许多下游任务优化每个顶点的自由度。我们通过两种应用展示了我们提出的方法的功能：1）模板形状（SfT）：目标是使图像/视频中看到的对象的输入 3D 模板变形。使用 PolyFit，我们采用测试时优化，可提供具有竞争力的准确性，同时明显快于基于离线物理的求解器，并且在适度的额外运行时间下，其准确性优于最新的物理引导神经模拟器。 2）服装立体裁剪。我们训练了一个自我监督的、与网格和服装无关的模型，该模型可以概括分辨率和服装类型，提供比强基线快一个数量级的推理。|[2601.05035](http://arxiv.org/abs/2601.05035)|null|\n",
        "2601.04984": "|**2026-01-08**|**OceanSplat: Object-aware Gaussian Splatting with Trinocular View Consistency for Underwater Scene Reconstruction**|我们介绍了 OceanSplat，这是一种基于 3D 高斯分布的新颖方法，用于准确表示水下场景中的 3D 几何形状。为了克服水下光学退化引起的多视图不一致，我们的方法通过渲染相对于每个输入视图的水平和垂直平移的相机视图并通过反向扭曲对齐它们来强制三目视图一致性。此外，这些平移的相机视图用于通过三角测量之前导出合成极线深度，其充当自监督深度正则化器。这些几何约束有助于 3D 高斯的空间优化并保留水下环境中的场景结构。我们还提出了一种深度感知的 alpha 调整，该调整在早期训练期间根据 3D 高斯的 $z$ 分量和观察方向调节 3D 高斯的不透明度，从而阻止介质诱导图元的形成。通过我们的贡献，3D 高斯从散射介质中解脱出来，实现了对象几何形状的稳健表示，并显着减少了重建水下场景中的浮动伪影。对真实水下和模拟场景的实验表明，OceanSplat 在散射介质中的场景重建和恢复方面远远优于现有方法。|[2601.04984](http://arxiv.org/abs/2601.04984)|null|\n",
        "2601.05251": "|**2026-01-08**|**Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video**|我们提出了 Mesh4D，一种用于单目 4D 网格重建的前馈模型。给定动态对象的单眼视频，我们的模型会重建对象的完整 3D 形状和运动，表示为变形场。我们的主要贡献是一个紧凑的潜在空间，它可以在一次传递中对整个动画序列进行编码。这个潜在空间是由自动编码器学习的，在训练过程中，自动编码器由训练对象的骨骼结构引导，为合理的变形提供强大的先验。至关重要的是，推理时不需要骨架信息。编码器采用时空注意力，产生对象整体变形的更稳定的表示。在此表示的基础上，我们训练了一个潜在扩散模型，该模型以输入视频和从第一帧重建的网格为条件，预测一个镜头中的完整动画。我们在重建和新颖的视图合成基准上评估了 Mesh4D，在恢复准确的 3D 形状和变形方面优于现有方法。|[2601.05251](http://arxiv.org/abs/2601.05251)|null|\n",
        "2601.05250": "|**2026-01-08**|**QNeRF: Neural Radiance Fields on a Simulated Gate-Based Quantum Computer**|最近，量子视野 (QVF) 在模型紧凑性和学习所提供的 2D 或 3D 信号的收敛速度方面显示出有希望的改进。与此同时，新颖视图合成在神经辐射场 (NeRF) 方面取得了重大进展，其中模型从 2D 图像中学习紧凑的表示以渲染 3D 场景，尽管代价是更大的模型和强化训练。在这项工作中，我们通过引入 QNeRF 来扩展 QVF 的方法，QNeRF 是第一个专为 2D 图像的新颖视图合成而设计的混合量子经典模型。 QNeRF 利用参数化量子电路通过量子叠加和纠缠来编码空间和视图相关信息，从而产生比经典模型更紧凑的模型。我们提出了两种架构变体。 Full QNeRF 最大限度地利用所有量子振幅来增强表征能力。相比之下，双分支 QNeRF 通过分支空间和视图相关的量子态准备引入了任务通知的归纳偏置，大大降低了该操作的复杂性，并确保了可扩展性和潜在的硬件兼容性。我们的实验表明，当在中等分辨率的图像上进行训练时，QNeRF 可以匹配或优于经典 NeRF 基线，同时使用的参数数量还不到一半。这些结果表明，量子机器学习可以作为计算机视觉中级任务中连续信号表示的有竞争力的替代方案，例如从 2D 观测中学习 3D 表示。|[2601.05250](http://arxiv.org/abs/2601.05250)|null|\n",
        "2601.05239": "|**2026-01-08**|**Plenoptic Video Generation**|摄像机控制的生成视频重新渲染方法，例如 ReCamMaster，已经取得了显着的进展。然而，尽管它们在单视图设置中取得了成功，但这些作品往往很难在多视图场景中保持一致性。由于生成模型固有的随机性，确保幻觉区域的时空一致性仍然具有挑战性。为了解决这个问题，我们引入了 PlenopticDreamer，这是一个同步生成幻觉以维持时空记忆的框架。核心思想是以自回归方式训练多输入单输出视频条件模型，并辅以摄像机引导的视频检索策略，该策略自适应地选择前几代的显着视频作为条件输入。此外，我们的训练还结合了渐进式上下文缩放以提高收敛性、自我调节以增强针对错误累积引起的远程视觉退化的鲁棒性，以及长视频调节机制以支持扩展视频生成。 Basic 和 Agibot 基准测试的大量实验表明，PlenopticDreamer 实现了最先进的视频重新渲染，提供卓越的视图同步、高保真视觉效果、精确的摄像机控制和多样化的视图转换（例如，第三人称到第三人称，以及机器人操作中从头视图到抓手视图）。项目页面：https://research.nvidia.com/labs/dir/plenopticdreamer/|[2601.05239](http://arxiv.org/abs/2601.05239)|null|\n",
        "2601.05237": "|**2026-01-08**|**ObjectForesight: Predicting Future 3D Object Trajectories from Human Videos**|人类可以毫不费力地预测物体如何通过交互移动或改变——想象一个杯子被举起，一把刀切开，或者一个盖子被关闭。我们的目标是赋予计算系统类似的能力，直接从被动视觉观察中预测未来可能的物体运动。我们引入了 ObjectForesight，这是一种以对象为中心的 3D 动力学模型，可以根据短的自我中心视频序列预测刚性对象的未来 6-DoF 姿势和轨迹。与在像素或潜在空间中运行的传统世界或动态模型不同，ObjectForesight 在对象级别以 3D 形式明确表示世界，从而实现几何基础和时间连贯的预测，以捕获对象可供性和轨迹。为了大规模训练这样的模型，我们利用分割、网格重建和 3D 姿态估计方面的最新进展来整理包含 200 万多个带有伪地面实况 3D 对象轨迹的短片的数据集。通过大量的实验，我们表明 ObjectForesight 在准确性、几何一致性以及对未见过的对象和场景的泛化方面取得了显着的进步，建立了一个可扩展的框架，用于直接从观察中学习基于物理的、以对象为中心的动力学模型。 objectforesight.github.io|[2601.05237](http://arxiv.org/abs/2601.05237)|null|\n",
        "2601.06025": "|**2026-01-09**|**Manifold limit for the training of shallow graph convolutional neural networks**|我们研究了在流形假设下在采样点云的邻近图上训练浅图卷积神经网络（GCNN）的离散到连续一致性。图卷积是通过图拉普拉斯算子在频谱上定义的，其低频频谱近似于底层平滑流形的 Laplace-Beltrami 算子的频谱，而可能无限宽度的浅层 GCNN 是参数空间上的测量空间上的线性函数。从函数分析的角度来看，图信号被视为流形上函数的空间离散化，这导致了训练数据在图分辨率上保持一致的自然概念。为了实现收敛结果，连续参数空间被选择为单位球的弱紧积，并对输出权重和偏差施加 Sobolev 正则，但不对卷积参数施加 Sobolev 正则。相应的离散参数空间继承了相应的谱衰减，并且还受到适合拉普拉斯图的信息谱窗口的频率截止的限制。在这些假设下，我们证明了正则化经验风险最小化泛函的$Г$收敛性及其全局最小化函数的相应收敛性，即参数度量的弱收敛性和函数在紧集上的一致收敛性。这为此类网络的训练提供了网格和样本独立性的形式化。|[2601.06025](http://arxiv.org/abs/2601.06025)|null|\n",
        "2601.05968": "|**2026-01-09**|**Skyrme-Hartree-Fock-Bogoliubov mass models on a 3D mesh: V. The N2LO extension of the Skyrme EDF**|我们推出 BSkG5，它是布鲁塞尔 Skyrme 网格 (BSkG) 系列的最新产品，也是第一个基于次次次前导阶 (N2LO) Skyrme 能量密度泛函 (EDF) 的大型核结构模型。通过使用包含多达四个梯度的中心项扩展传统的 Skyrme EDF ansatz，我们能够将核基态特性的出色全局描述与纯中子物质的刚性状态方程结合起来，该状态方程与中子星的所有天文观测一致。更准确地说，新模型与早期 BSkG 模型的精度相匹配，但少了两个参数：2457 个原子质量的均方根偏差为 0.649 MeV，810 个电荷半径的均方根偏差为 0.0267 fm，45 个锕系元素核的初级裂变势垒的均方根偏差为 0.43 MeV。我们证明，即使对于要求苛刻的多体计算，N2LO EDF 的复杂性也并非不可克服。|[2601.05968](http://arxiv.org/abs/2601.05968)|null|\n",
        "2601.05945": "|**2026-01-09**|**Superdiffusive central limit theorem for a class of driven diffusive systems at the critical dimension**|我们研究一类驱动扩散系统的大规模行为，该系统由随机偏微分方程（具有一般非线性的随机伯格斯方程 (SBE)）在临界尺寸和无限体积下建模。我们的主要结果表明，在对数超扩散时空缩放下，它由[G. Cannizzaro, Q. Moulard, & F. Toninelli, arxiv.org/abs/2501.00344, 2025] 的二次 SBE，但具有适当的重正化系数，从而严格证明并部分纠正了 [H. Cannizzaro, Q. Moulard, & F. Toninelli, arxiv.org/abs/2501.00344, 2025] van Beijeren、R. Kutner 和 H. Spohn，物理学家。 Rev. Lett.，1986] 基于 Spohn 的非线性脉动流体动力学理论。此外，我们的结果是第一个非平衡系统的普遍性结果，也是[M. Hairer, J. Quastel，数学论坛，Pi，卷。 6, 2018, e3]，达到临界尺寸并超越弱耦合。我们工作中的主要挑战是非线性的温和增长条件，这使得微观方程的适定性变得不平凡。其他关键的新颖之处包括对生成器非二次部分的精细估计的推导，以及与二次 SBE 解相关的求解器的新近似。|[2601.05945](http://arxiv.org/abs/2601.05945)|null|\n",
        "2601.05936": "|**2026-01-09**|**Coupled Level-Set Lattice Boltzmann Method on Adaptive Cartesian Grids**|提出了一种基于自适应笛卡尔网格的新型耦合水平集格子玻尔兹曼方法，用于模拟液-气多相流。该方法解决了精确建模以尖锐界面和大密度比为特征的多相系统的固有挑战。通过对通过界面处的边界条件耦合的每个流体相采用单独的求解算法，该方法更加准确和高效。该研究强调了使用格子玻尔兹曼方法与水平集技术一起有效跟踪界面同时促进自适应网格细化的优势。对各种测试案例（例如不混溶分层流和上升气泡）的应用证明了该方法能够捕获复杂的界面动力学并根据文献数据验证其准确性。|[2601.05936](http://arxiv.org/abs/2601.05936)|null|\n",
        "2601.05873": "|**2026-01-09**|**Universal and Asymptotically Optimal Data and Task Allocation in Distributed Computing**|我们研究分布式计算中通信和计算成本的联合最小化，其中主节点协调 $N$ 个工作节点来评估 $n$ 个文件库上的函数。假设该函数被分解为任意子函数集 $\\mathbf{X}$，每个子函数依赖于 $d$ 输入文件，将我们的分布式计算问题呈现为 $d$ 均匀超图边缘分区问题，其中由顶点（文件）之间的 $d$ 依赖关系定义的边缘集（子函数集）必须跨 $N$ 不相交组（工人）进行分区。目的是设计一个文件和子函数分配，对应于 $\\mathbf{X}$ 的分区，最小化通信成本 $π_{\\mathbf{X}}$（表示每个服务器的不同文件的最大数量），同时最小化与最大工作子函数负载相对应的计算成本 $δ_{\\mathbf{X}}$。对于广泛的参数，我们提出了一种确定性分配解决方案，即 \\emph{Interweaved-Cliques (IC) design}，其受信息论启发的交织团结构对于一大类分解 $\\mathbf{X}$ 同时实现了顺序最优的通信和计算成本。这种最优性源自我们的可实现性和逆界，这揭示了在 $\\mathbf{X}$ 密度的合理假设下，通信成本的最佳缩放采用 $n/N^{1/d}$ 的形式，表明我们的设计实现了按 $N^{1/d}$ 缩放的阶次最优 \\textit{partitioning Gain}，同时还实现了阶次最优计算成本。有趣的是，这种顺序最优性是以确定性方式实现的，而且非常重要的是，它是从 $\\mathbf{X}$ 盲目实现的，因此无需重新整理文件即可计算多个所需的函数。|[2601.05873](http://arxiv.org/abs/2601.05873)|null|\n",
        "2601.05853": "|**2026-01-09**|**LayerGS: Decomposition and Inpainting of Layered 3D Human Avatars via 2D Gaussian Splatting**|我们提出了一种新颖的框架，用于将任意姿势的人类分解为可动画的多层 3D 人类化身，将身体和服装分开。传统的单层重建方法将服装锁定为一种身份，而先前的多层方法则难以应对遮挡区域。我们通过将每一层编码为一组 2D 高斯函数来克服这两个限制，以实现精确的几何形状和真实感渲染，并通过分数蒸馏采样 (SDS) 使用预训练的 2D 扩散模型修复隐藏区域。我们的三阶段训练策略首先通过单层重建来重建粗糙的规范服装，然后通过多层训练来共同恢复内层身体和外层服装细节。在两个 3D 人体基准数据集（4D-Dress、T human2.0）上进行的实验表明，我们的方法比之前最先进的技术实现了更好的渲染质量以及层分解和重组，从而能够在新颖的视点和姿势下进行逼真的虚拟试穿，并推进用于沉浸式应用程序的高保真 3D 人体资产的实际创建。我们的代码位于 https://github.com/RockyXu66/LayerGS|[2601.05853](http://arxiv.org/abs/2601.05853)|null|\n",
        "2601.05839": "|**2026-01-09**|**GeoSurDepth: Spatial Geometry-Consistent Self-Supervised Depth Estimation for Surround-View Cameras**|准确的环视深度估计为激光传感器提供了一种有竞争力的替代方案，对于自动驾驶中的 3D 场景理解至关重要。虽然先前的研究提出了各种主要侧重于在光度水平上强制执行交叉视图约束的方法，但很少有人明确利用单目和环视设置中固有的丰富几何结构。在这项工作中，我们提出了 GeoSurDepth，一个利用几何一致性作为环视深度估计的主要线索的框架。具体来说，我们利用基础模型作为伪几何先验和特征表示增强工具来指导网络保持空间 3D 空间中的表面法线一致性，并规范 2D 中对象和纹理一致的深度估计。此外，我们引入了一种新颖的视图合成管道，其中通过空间扭曲重建密集深度来实现 2D-3D 提升，鼓励跨时间、空间和时空上下文的额外光度监督，并补偿单视图图像重建的局限性。最后，新提出的自适应联合运动学习策略使网络能够自适应地强调信息丰富的空间几何线索，以改进运动推理。对 DDAD 和 nuScenes 的大量实验表明，GeoSurDepth 实现了最先进的性能，验证了我们方法的有效性。我们的框架强调了利用几何相干性和一致性来实现稳健的自监督多视图深度估计的重要性。|[2601.05839](http://arxiv.org/abs/2601.05839)|null|\n",
        "2601.05780": "|**2026-01-09**|**Stability and convergence analysis of unconditionally original energy dissipative implicit-explicit Runge--Kutta methods for the phase field crystal models without Lipschitz assumptions**|相场晶体（PFC）方法是模拟原子长度尺度和扩散时间尺度晶体微结构演化的有效技术。由于高阶导数（六阶）和强非线性项（局部 Lipschitz），开发高阶稳定方案并建立相应的误差估计特别具有挑战性。在本研究中，我们首先建立了高阶隐式-显式（IMEX）龙格-库塔方法的通用框架，该框架保留了非线性项上全局 Lipschitz 截断的辅助模型的原始能量耗散。通过使用Sobolev嵌入定理和柯西交错定理，我们证明了辅助模型的解与不具有全局Lipschitz性质的原始模型的解相同，只要初始值的自由能是明确定义的。此外，我们严格证明了 L-无穷范数下解的一致有界性和无条件全局时间稳定性。这允许一个简单的框架来导出最佳的任意高阶 L-无穷大误差估计，而不依赖于 Lipschitz 假设。特别是，与现有文献相比，误差估计的论点以更加简化和优雅的方式提出，而不对时间步长或网格大小施加任何限制。事实上，所报告的框架建立在原始模型的截断辅助问题的基础上，可以直接扩展到广泛的梯度流，包括 Allen-Cahn 方程、非局部 PFC 模型和外延薄膜生长方程，提供无条件能量耗散，而无需强制 Lipschitz 连续性。最后，我们提出数值示例来验证我们的分析结果并证明捕获长期动态的有效性。|[2601.05780](http://arxiv.org/abs/2601.05780)|null|\n",
        "2601.05765": "|**2026-01-09**|**More Power to the Particles: Analytic Geometry for Partial Optimal Transport-based Fluid simulation**|我们提出了一种基于部分最优传输（例如加卢埃-梅里戈方案或功率粒子方法）的自由表面流体模拟和变形力学所需的几何结构的解析构造。此类方法以前依赖于利用经典的凸细胞裁剪算法对细胞进行离散化。然而，这会导致大量的计算成本和评估量的粗略近似。相比之下，我们的算法有效地计算广义拉盖尔细胞，即拉盖尔细胞和球体之间的交集。这使得可以更精确地计算小面的体积和面积，并大大减少获得几何形状所需的操作数量。此外，我们还提供了一个仅基于计算的体积结构的专用渲染框架。|[2601.05765](http://arxiv.org/abs/2601.05765)|null|\n",
        "2601.05738": "|**2026-01-09**|**FeatureSLAM: Feature-enriched 3D gaussian splatting SLAM in real time**|我们提出了一种实时跟踪 SLAM 系统，该系统使用 3D 高斯分布 (3DGS) 将高效的相机跟踪与照片级真实感特征丰富的映射结合起来。我们的主要贡献是将密集特征光栅化集成到小说视图合成中，并与视觉基础模型保持一致。这产生了强大的语义，超越了基本的 RGB-D 输入，有助于跟踪和映射的准确性。与之前的语义 SLAM 方法（嵌入预定义的类标签）不同，FeatureSLAM 通过自由视点、开放集分割实现全新的下游任务。在标准基准测试中，我们的方法实现了实时跟踪，与最先进的系统相当，同时提高了跟踪稳定性和地图保真度，而无需过多的计算。从数量上讲，与最近的固定集 SLAM 基线相比，我们获得了 9% 的位姿误差降低和 8% 的映射精度提高。我们的结果证实，实时特征嵌入的 SLAM 不仅对于启用新的下游应用程序有价值。它还提高了底层跟踪和映射子系统的性能，提供与离线 3DGS 模型相当的语义和语言屏蔽结果，以及最先进的跟踪、深度和 RGB 渲染。|[2601.05738](http://arxiv.org/abs/2601.05738)|null|\n",
        "2601.07082": "|**2026-01-11**|**An efficient hyper reduced-order model for segregated solvers for geometrical parametrization problems**|我们提出了一种高效的超降阶模型（HROM），专为几何参数化问题中的隔离有限体积求解器而设计。该方法遵循先离散后投影的策略：首先使用有限体积或有限元离散化组装全阶算子，然后使用通过 DEIM 等超简化技术选择的一小组空间采样点投影到低维空间。这种方法消除了在线计算成本对完整网格尺寸的依赖。该方法在三个基准问题上进行评估：线性输运方程、非线性伯格斯方程和不可压缩纳维-斯托克斯方程。结果表明，超简化模型与全阶解紧密匹配，同时大幅减少了计算时间。由于在在线阶段仅评估网格单元的稀疏子集，因此该方法自然可并行化并可扩展到非常大的网格。这些发现表明，超还原可以与分离求解器和几何参数化有效结合，以实现快速、准确的 CFD 模拟。|[2601.07082](http://arxiv.org/abs/2601.07082)|null|\n",
        "2601.07079": "|**2026-01-11**|**Adaptive Robust Control for Uncertain Systems with Ellipsoid-Set Learning**|尽管不确定系统的随机控制方法取得了巨大的成功，但此类方法处理非高斯不确定性的能力有限。这项工作提出了一种针对线性不确定系统的自适应鲁棒控制，其过程噪声、观测噪声和系统状态由椭球集而不是高斯分布来描述。我们设计了一种椭球集学习方法来估计状态集的边界，并将学习集纳入控制律推导中，以减少鲁棒控制中的保守性。此外，我们考虑状态空间矩阵中的参数不确定性。特别是，我们为不确定参数分配有限的候选，并为每个候选构建一系列候选条件鲁棒控制问题。我们通过聚合候选条件控制律得出最终控制律。通过这种方式，我们将控制方案分离为并行的鲁棒控制，将学习和控制解耦，否则会使控制无法实现。我们在线性二次调节和跟踪控制的情况下在数值模拟中证明了所提出的控制的有效性。|[2601.07079](http://arxiv.org/abs/2601.07079)|null|\n",
        "2601.06982": "|**2026-01-11**|**Match Made with Matrix Completion: Efficient Learning under Matching Interference**|匹配市场越来越需要了解需求和供给之间的匹配质量，以便有效设计匹配政策。在实践中，由于参与者的多样性不断增加，匹配奖励是高维的。我们利用这两个市场中匹配奖励的自然低秩矩阵结构，并建议利用矩阵完成来加速有限离线数据的奖励学习。在这种情况下，矩阵补全的一个独特属性是，奖励矩阵的条目是在匹配干扰的情况下观察的——即，由于匹配或预算限制，条目不是独立观察的，而是相互依赖的。这种匹配依赖性带来了独特的技术挑战，例如矩阵补全文献中现有分析工具的次优性或不适用，因为它们通常依赖于样本独立性。在本文中，我们首先证明标准核范数正则化在匹配干扰下理论上仍然有效。我们在这种情况下提供了近乎最优的弗罗贝尼乌斯范数保证，并结合了新的分析技术。接下来，为了指导某些匹配决策，我们基于核范数估计器开发了一种新颖的“双重增强”估计器，具有近乎最优的入口保证。我们的双重增强程序可以适用于更广泛的采样方案，即使具有依赖性，这可能是独立的兴趣。此外，我们将我们的方法扩展到具有匹配约束（例如最佳匹配和稳定匹配）的在线学习设置，并在矩阵维度中提出改进的遗憾界限。最后，我们使用劳动力市场的合成数据和真实数据证明了我们的方法的实用价值。|[2601.06982](http://arxiv.org/abs/2601.06982)|null|\n",
        "2601.06932": "|**2026-01-11**|**Symphonym: Universal Phonetic Embeddings for Cross-Script Toponym Matching via Teacher-Student Distillation**|将不同语言和书写系统的地名联系起来是数字人文和地理信息检索中的一个基本挑战。现有的方法依赖于特定于语言的语音算法或音译规则，当名称跨越脚本边界时，这些算法或音译规则就会失败——没有任何字符串度量可以确定以西里尔语或阿拉伯语呈现的“莫斯科”指的是同一个城市。   我提出了 Symphony，这是一种神经嵌入系统，可将 20 个书写系统中的地名映射到统一的 128 维语音空间中。经过发音语音特征训练的教师网络（通过 Epitran 和 PanPhon）生成目标嵌入，而学生网络则学习从原始字符中近似这些嵌入。推理时，只需要轻量级的Student（170万个参数），无需运行时语音转换即可部署。   培训采用三阶段课程，涉及来自 GeoNames、Wikidata 和 Getty 地名同义词库的 5700 万个地名。第一阶段训练老师 467K 语音基础三连音。第 2 阶段将 2300 万个样本中的学生输出与教师输出进行对齐，实现 96.6% 的余弦相似度。第 3 阶段对 330 万个硬否定三元组进行微调 - 否定与锚共享前缀和脚本，但指的是不同的地方 - 以加强区分。   MEHDIE 希伯来语-阿拉伯语基准的评估达到 89.2% Recall@1，优于 Levenshtein (81.5%) 和 Jaro-Winkler (78.5%)。系统针对跨脚本匹配进行了优化；相同脚本的变体可以通过互补的字符串方法来处理。 Symphony 将在世界历史地名词典的 6700 万个地名中实现模糊语音协调和搜索。代码和模型是公开的。|[2601.06932](http://arxiv.org/abs/2601.06932)|null|\n",
        "2601.06928": "|**2026-01-11**|**RenderFlow: Single-Step Neural Rendering via Flow Matching**|传统的基于物理的渲染 (PBR) 管道通过计算密集型光传输模拟生成逼真的图像。尽管最近的深度学习方法利用扩散模型先验和几何缓冲区（G-缓冲区）来产生视觉上引人注目的结果，而无需明确的场景几何或光模拟，但它们仍然受到两个主要限制。首先，扩散过程的迭代性质引入了相当大的延迟。其次，这些生成模型固有的随机性损害了物理准确性和时间一致性。为了应对这些挑战，我们提出了一种新颖的、端到端的、确定性的、单步神经渲染框架 RenderFlow，它建立在流匹配范例的基础上。为了进一步增强渲染质量和泛化能力，我们提出了一种高效且有效的稀疏关键帧指导模块。我们的方法显着加速了渲染过程，并且通过选择性地合并稀疏渲染的关键帧作为指导，增强了输出的物理合理性和整体视觉质量。由此产生的管道实现了近乎实时的性能和逼真的渲染质量，有效地缩小了现代生成模型的效率与传统基于物理的渲染的精度之间的差距。此外，我们通过引入一个轻量级的、基于适配器的模块来展示我们框架的多功能性，该模块有效地将预训练的前向模型重新用于内在分解的逆渲染任务。|[2601.06928](http://arxiv.org/abs/2601.06928)|null|\n",
        "2601.06841": "|**2026-01-11**|**Efficient Subdivision of Bézier Curves/Surfaces via Blossoms**|我们考虑使用花朵进行贝塞尔曲线/曲面细分的问题。根据计算控制点的需要，我们提出了用于花朵评估的封闭式公式。这种方法提供了直接有效的方法来获得贝塞尔曲线以及张量积和三角形贝塞尔曲面的细分。它大大简化了细分控制点的计算，这在需要动态细化或调整曲线/曲面的应用中至关重要。例如，在 CAD/CAM 系统、建筑设计或动画中，快速准确地确定新控制点的能力对于操纵和渲染复杂形状至关重要。更高效的细分可以促进复杂的操作，例如查找曲面之间的交点或平滑地混合多个曲面。|[2601.06841](http://arxiv.org/abs/2601.06841)|null|\n",
        "2601.06839": "|**2026-01-11**|**PRISM: Color-Stratified Point Cloud Sampling**|我们提出了 PRISM，一种用于 RGB-LiDAR 点云的新型颜色引导分层采样方法。我们的方法的动机是观察到独特的场景特征通常表现出色彩多样性，而重复的冗余特征在颜色上是均匀的。传统的下采样方法（随机采样、体素网格、法线空间采样）会强制执行空间均匀性，同时忽略此光度内容。相反，PRISM 分配与色度多样性成正比的采样密度。通过将 RGB 颜色空间视为分层域并为每个颜色仓施加最大容量 k，该方法保留了具有高颜色变化的纹理丰富区域，同时显着减少了视觉上均匀的表面。这将采样空间从空间覆盖转移到视觉复杂性，以生成更稀疏的点云，保留 3D 重建任务的基本特征。|[2601.06839](http://arxiv.org/abs/2601.06839)|null|\n",
        "2601.06773": "|**2026-01-11**|**The optimal error analysis of nonuniform L1 method for the variable-exponent subdiffusion model**|这项工作研究了非均匀时间网格下变指数次扩散模型的完全离散方案的最优误差估计。我们应用摄动方法将原始模型重新表示为其等效形式，并应用L1格式和插值求积规则分别对重新表示的模型中的Caputo导数项和卷积项进行离散化。然后，我们证明了非均匀网格下的时间收敛率 $O(N^{-\\min\\{2-α(0), rα(0)\\}})$，这改进了 [Zheng, CSIAM T. Appl.数学。 2025] $r\\geq \\frac{2-α(0)}{α(0)}$。给出的数值结果证实了理论结果。|[2601.06773](http://arxiv.org/abs/2601.06773)|null|\n",
        "2601.06659": "|**2026-01-10**|**Detecting the Onset and Progression of Spinodal Decomposition using Transient Grating Spectroscopy**|旋节线分解会降低耐腐蚀性并使材料脆化。在灾难性材料降解之前快速、最终、非破坏性地检测旋节线分解开始的能力将代表材料测试的重大进步。我们证明，可以使用原位和异位瞬态光栅光谱 (TGS) 通过模量硬化来检测二元 Fe-Cr 合金中的旋节线分解。关键的机理见解是弹性模量作为 Cr 含量函数的非线性，使得旋节线分解的 Fe-Cr 合金比初始铬成分一定范围的等效固溶体更硬。我们使用差示扫描量热法 (DSC) 确认了 36 at.% 铬合金中存在旋节线分解，与已知的旋节线分解能量学相关，并通过原子模拟表明，36 at.% 铬合金中的旋节线分解后预期弹性模量硬化。这项研究的结果表明，TGS 可以作为一种实用工具，对易受此类降解影响的关键材料进行无损评估。|[2601.06659](http://arxiv.org/abs/2601.06659)|null|\n",
        "2601.06621": "|**2026-01-10**|**Stereo Audio Rendering for Personal Sound Zones Using a Binaural Spatially Adaptive Neural Network (BSANN)**|提出了一种用于个人声音区域（PSZ）的双耳渲染框架，以使多个头部跟踪听众能够接收完全独立的立体声音频节目。目前的 PSZ 系统通常依赖于单声道渲染，因此无法单独控制左耳和右耳，这限制了空间成像的质量和准确性。所提出的方法采用双耳空间自适应神经网络（BSANN）来生成耳朵优化的扬声器滤波器，从而在多个听众的每只耳朵处重建所需的声场。该框架集成了消声测量的扬声器频率响应、分析建模的换能器方向性和刚性球头相关传递函数 (HRTF)，以提高声学准确性和空间渲染保真度。显式主动串扰消除 (XTC) 级进一步改善了三维空间感知。实验表明，测量的客观性能指标显着提高，包括区域间隔离 (IZI)、程序间隔离 (IPI) 和串扰消除 (XTC)，对数频率加权值分别为 10.23/10.03 dB (IZI)、11.11/9.16 dB (IPI) 和 10.55/11.13 dB (XTC)。 100-20,000 赫兹。耳控控制、精确声学建模和集成有源 XTC 的结合使用产生了统一的渲染方法，可提供更好的隔离性能、增强的对房间不对称性的鲁棒性以及在真实声学环境中更忠实的空间再现。|[2601.06621](http://arxiv.org/abs/2601.06621)|null|\n",
        "2601.07767": "|**2026-01-12**|**Are LLM Decisions Faithful to Verbal Confidence?**|大型语言模型（LLM）可以对其自身的不确定性产生令人惊讶的复杂估计。然而，目前尚不清楚这种表达的信心在多大程度上与模型的推理、知识或决策相关。为了测试这一点，我们引入了$\\textbf{RiskEval}$：一个旨在评估模型是否根据不同的错误惩罚调整其弃权策略的框架。我们对几个前沿模型的评估揭示了一种严重的分离：模型在表达其口头信心时既没有成本意识，也没有在决定在高罚条件下参与或弃权时做出战略响应。即使极端惩罚使频繁弃权成为数学上的最佳策略，模型也几乎从不弃权，从而导致效用崩溃。这表明，经过校准的口头置信度分数可能不足以创建值得信赖和可解释的人工智能系统，因为当前模型缺乏将不确定性信号转化为最佳和风险敏感决策的战略机构。|[2601.07767](http://arxiv.org/abs/2601.07767)|null|\n",
        "2601.07757": "|**2026-01-12**|**On the Compact Discontinuous Galerkin method for polytopal meshes**|紧致间断伽辽金法由 Peraire 和 Persson 在 (SIAM J. Sci. Comput., 30, 1806--1824, 2008) 中提出。在这项工作中，我们提出了该方法的 $hp$ 版本的稳定性和收敛性分析，该方法应用于多面体网格上的椭圆问题。此外，我们引入了快速实用的算法，允许在统一框架内实现 CDG、LDG 和 BR2 方法。我们的数值实验表明，CDG 方法可生成紧凑的刚度矩阵模板，与 LDG 和 BR2 方法相比，组装和求解时间更快。我们通过数值研究矫顽力如何取决于各种网格类型的方法参数，特别关注每个网格元素的面数。最后，我们证明了在使用可变多项式次数时为数值通量选择正确方向的重要性。|[2601.07757](http://arxiv.org/abs/2601.07757)|null|\n",
        "2601.07723": "|**2026-01-12**|**FMAC: a Fair Fiducial Marker Accuracy Comparison Software**|本文提出了一种使用基准标记对姿态估计的准确性进行公平比较的方法。这些比较依赖于大量高保真合成图像，能够深入探索 6 个自由度。空间的低差异采样允许通过绘制 36 对组合来检查每个自由度与位姿误差之间的相关性。图像使用基于物理的光线追踪代码进行渲染，该代码是专门开发用于直接使用任何相机的标准校准系数的。该软件可再现图像扭曲、散焦和衍射模糊。此外，子像素采样应用于锐利边缘，以增强渲染图像的保真度。在介绍了渲染算法及其实验验证后，本文提出了一种评估位姿精度的方法。该方法应用于众所周知的标记，揭示它们在姿势估计方面的优点和缺点。该代码是开源的，可在 GitHub 上获取。|[2601.07723](http://arxiv.org/abs/2601.07723)|null|\n",
        "2601.07670": "|**2026-01-12**|**Tachyonic gravitational dark matter production after inflation**|我们提出了一种新颖的引力机制，用于由膨胀后曲率引起的速子不稳定性驱动的暗物质的非热产生。与通常研究的与重力的非最小耦合不同，我们的框架考虑了与时空曲率不变量二次耦合的真实观众标量场。我们证明，暴涨结束时时空曲率的快速重组可以动态地使暗物质场呈现快光状态，从而引发自发对称性破缺和爆炸性粒子产生的短暂阶段。作为一个具体的、理论上受控的例子，我们关注高斯-博内拓扑不变量。通过将分析估计与完全非线性的 $3+1$ 经典晶格模拟相结合，我们跟踪系统的非平衡演化并计算由此产生的暗物质丰度。我们发现这种纯粹的引力机制可以在广泛的质量和暴胀尺度上稳健地再现观察到的暗物质遗迹密度，还提供了一个简单的拟合函数，使得我们的结果能够独立于晶格应用。|[2601.07670](http://arxiv.org/abs/2601.07670)|null|\n",
        "2601.07660": "|**2026-01-12**|**StdGEN++: A Comprehensive System for Semantic-Decomposed 3D Character Generation**|我们推出了 StdGEN++，这是一种新颖且全面的系统，用于从不同的输入生成高保真、语义分解的 3D 角色。现有的 3D 生成方法通常会生成整体网格，缺乏游戏和动画工业管道所需的结构灵活性。为了解决这一差距，StdGEN++ 建立在双分支语义感知大型重建模型（双分支 S-LRM）的基础上，该模型以前馈方式联合重建几何、颜色和每个组件的语义。为了实现生产级保真度，我们引入了一种与混合隐式字段兼容的新颖的语义表面提取形式。该机制通过从粗到细的提议方案来加速，从而显着减少内存占用并实现高分辨率网格生成。此外，我们提出了一种基于视频扩散的纹理分解模块，将外观分解为可编辑层（例如，分离的虹膜和皮肤），解决面部区域的语义混淆。实验表明，StdGEN++ 实现了最先进的性能，在几何精度和语义解缠方面显着优于现有方法。至关重要的是，由此产生的结构独立性解锁了先进的下游功能，包括无损编辑、符合物理的动画和视线跟踪，使其成为自动化角色资产生产的强大解决方案。|[2601.07660](http://arxiv.org/abs/2601.07660)|null|\n",
        "2601.07633": "|**2026-01-12**|**Performance Benchmarks for 2-View and 3-View Fiber-Projection Fine-Grained Particle Detectors**|细粒度闪烁体探测器对于核物理和粒子物理中的精确测量至关重要，其中相互作用顶点和次级粒子方向的精确重建使得信号与背景事件分离。众所周知的设计选择是光纤读出几何结构：传统的 2 视图系统使用正交的 X 和 Y 光纤，而下一代 3 视图设计添加了第三个 Z 光纤层，可提供明确的 3D 体素识别。 2 视图方法遭受组合重影的影响，即光纤投影模糊性产生的错误 3D 候选，降低了高多样性事件中的重建性能。本文提出了全面的模拟基准，量化了 2 视图和 3 视图几何图形之间关键指标的性能差异。我们发现，3 视图几何体根据事件拓扑将重影命中减少了 30--90%，在复杂的拓扑中提供了强大的顶点分辨率，并为簇射方向重建保持了卓越的角度分辨率。这些基准为未来探测器的设计优化提供信息，并为中微子物理、稀有 kaon/pion 衰变和对撞机量热等广泛实验的重建算法开发提供定量指导。|[2601.07633](http://arxiv.org/abs/2601.07633)|null|\n",
        "2601.07583": "|**2026-01-12**|**Machine learning nonequilibrium phase transitions in charge-density wave insulators**|非平衡电子力在电压驱动的相变中发挥着核心作用，但众所周知，在动态模拟中评估其成本非常昂贵。在这里，我们开发了一个与非平衡电子耦合的绝热晶格动力学的机器学习框架，并演示了荷斯坦模型中门控诱导绝缘体从电荷密度波态到金属的转变。尽管可以通过非平衡格林函数 (NEGF) 计算获得精确的电子力，但其高昂的计算成本使得长时间的动态模拟成本过高。通过利用电子响应的局部性，我们训练神经网络直接从晶格配置预测瞬时局部电子力，从而绕过时间演化过程中重复的 NEGF 计算。当与布朗动力学相结合时，产生的机器学习力场定量地再现了从完整的 NEGF 模拟中获得的畴壁运动和非平衡相变动力学，同时实现了计算效率的数量级增益。我们的结果将直接力学习确立为一种有效且准确的方法，用于模拟驱动量子材料中的非平衡晶格动力学。|[2601.07583](http://arxiv.org/abs/2601.07583)|null|\n",
        "2601.07571": "|**2026-01-12**|**GPU accelerated surface-based gaze mapping for XR experiences**|扩展现实是一个快速增长的领域，越来越需要分析和理解用户行为。特别是，在沉浸式体验中理解人类视觉注意力对于许多应用来说至关重要。视觉注意力的可视化和分析通常是通过根据眼动追踪数据构建注视密度图来完成的。这种视觉注意力映射对于 3 自由度 (3DoF) 体验（\\textit{即}，涉及 360 个图像或视频）来说可以很好地掌握，但对于 6DoF 数据来说就更不好了，因为用户可以在 3D 空间中自由移动。在这种情况下，视觉注意力信息必须映射到 3D 对象本身。存在一些用于构造这种基于表面的 6DoF 注意力图的解决方案，但是它们具有几个缺点：处理时间、对网格分辨率和/或纹理映射的强烈依赖、和/或用于进一步处理的不切实际的数据表示。在此背景下，我们提出了一种新颖的基于 GPU 的算法，该算法可以在交互时生成并实时渲染的同时解决上述问题。在具有挑战性的场景上进行的实验证明了我们方法的准确性和鲁棒性。为了促进这一领域的研究，源代码被公开发布并集成到 PLUME 中，以便于在 XR 实验中使用。|[2601.07571](http://arxiv.org/abs/2601.07571)|null|\n",
        "2601.07540": "|**2026-01-12**|**ViewMorpher3D: A 3D-aware Diffusion Framework for Multi-Camera Novel View Synthesis in Autonomous Driving**|自动驾驶系统严重依赖多视图图像来确保准确的感知和稳健的决策。为了有效地开发和评估感知堆栈和规划算法，逼真的闭环模拟器是必不可少的。虽然高斯溅射等 3D 重建技术为模拟器构建提供了有希望的途径，但渲染的新颖视图通常会出现伪影，特别是在外推视角或可用观察稀疏时。   我们推出 ViewMorpher3D，这是一种基于图像扩散模型的多视图图像增强框架，旨在提升驾驶场景中的真实感和多视图一致性。与单视图方法不同，ViewMorpher3D 联合处理一组以相机姿势、3D 几何先验以及时间相邻或空间重叠参考视图为条件的渲染视图。这使得模型能够推断缺失的细节、抑制渲染伪影并强制执行跨视图一致性。   我们的框架可容纳不同数量的摄像机和灵活的参考/目标视图配置，使其能够适应不同的传感器设置。对现实世界驾驶数据集的实验表明，图像质量指标得到了显着改善，有效减少了伪影，同时保持了几何保真度。|[2601.07540](http://arxiv.org/abs/2601.07540)|null|\n",
        "2601.07484": "|**2026-01-12**|**R3-RECON: Radiance-Field-Free Active Reconstruction via Renderability**|在主动重建中，实体代理必须决定接下来要查看哪里，以有效获取支持高质量新颖视图渲染的视图。最近关于神经渲染主动视图规划的工作主要通过辐射场反向传播或估计 3D 高斯基元的信息熵来导出次最佳视图 (NBV) 标准。虽然有效，但这些策略将视图选择与繁重的、特定于表示的机制紧密结合在一起，并且无法考虑轻量级在线部署所需的计算和资源限制。在本文中，我们从以可渲染性为中心的角度重新审视主动重建。我们提出 $\\mathbb{R}^{3}$-RECON，一个无辐射场的主动重建框架，它从轻量级体素图在 SE(3) 上引入隐式的、姿势条件可渲染性场。我们的公式将每个体素的在线观察统计数据聚合成一个统一的标量可渲染性分数，该分数更新成本低廉，并且可以在毫秒内以封闭形式在任意候选视点进行查询，而不需要梯度或辐射场训练。该可渲染性场与图像空间重建误差密切相关，自然地指导 NBV 选择。我们进一步引入了一个全景扩展，可以估计全向（360$^\\circ$）视图效用，以加速候选评估。在标准室内复制数据集中，$\\mathbb{R}^{3}$-RECON 比最近具有匹配视图和时间预算的活动 GS 基线实现了更均匀的新颖视图质量和更高的 3D 高斯泼溅 (3DGS) 重建精度。|[2601.07484](http://arxiv.org/abs/2601.07484)|null|\n"
    },
    "具生智能&自动驾驶": {
        "2601.04158": "|**2026-01-07**|**Radio Activity from the Rapidly Rotating T dwarf 2MASS 2228-4310**|我们使用 Karl G. Jansky 甚大阵列 (VLA) 档案数据在 C 波段 (4-8 GHz) 观测了两个观测时期（$2\\times96$ 分钟），展示了对 2MASS J22282889-4310262 (2M2228)（一颗 T6/T6.5 褐矮星）的探测。检测到 2M2228 的时间和频率平均斯托克斯 I 和 V 峰值通量密度为 $67.3\\pm4.9\\ μ \\rm{Jy beam}^{-1}$ 和 $14.4\\pm3.0\\ μ\\text{Jy beam}^{-1}$（第一个历元）和 $107.2\\pm5.2\\ μ\\rm{Jy\\ beam}^{-1}$ 和第二个时期的$-20.7\\pm1.2\\ μ\\text{Jy beam}^{-1}$。这一发现构成了迄今为止在射电波长下检测到的第八个、尤其是旋转速度最快的 T 型矮星。我们的观察揭示了分数偏振比 $f_\\text{c}>50$% 的高度偏振爆发。使用斯托克斯 I 光曲线，我们分别测量两个观测时期 $\\sim47$ 和 $\\sim58$ 分钟的发生间隔，其中第一次爆发在先前测量的中红外光度周期 $85.8\\pm0.32$ 分钟的半个周期时间尺度内对齐。我们将发射归因于电子回旋脉泽发射（ECME），并将磁场强度限制为 $B\\gtrsim1.4$ kG。我们强调，考虑到观测持续时间较短，推断的周期是临时的。先前证明的大气稳定性和2M2228中新检测到的射电发射相结合，使其成为一个有前途的实验室，用于测试磁层流驱动的极光模型，并指导未来协调詹姆斯·韦伯太空望远镜（JWST）和射电观测，以探索极光活动与T型褐矮星大气动力学之间的联系。|[2601.04158](http://arxiv.org/abs/2601.04158)|null|\n",
        "2601.04137": "|**2026-01-07**|**Wow, wo, val! A Comprehensive Embodied World Model Evaluation Turing Test**|随着世界模型在 Embodied AI 中的发展势头，越来越多的作品探索使用视频基础模型作为下游具体任务（如 3D 预测或交互式生成）的预测世界模型。然而，在探索这些下游任务之前，视频基础模型仍然有两个关键问题没有得到解答：（1）它们的生成泛化是否足以维持人类观察者眼中的感知保真度，以及（2）它们是否足够强大，可以作为现实世界具体代理的普遍先验。为了提供回答这些问题的标准化框架，我们引入了体现图灵测试基准：WoW-World-Eval (Wow,wo,val)。 Wow-wo-val 基于 609 个机器人操作数据，检查了五种核心能力，包括感知、规划、预测、泛化和执行。我们提出了一个包含 22 个指标的综合评估协议来评估模型的生成能力，其总体得分与人类偏好之间实现了较高的皮尔逊相关性（>0.93），为人类图灵测试奠定了可靠的基础。在 Wow-wo-val 上，模型在长期规划方面仅达到 17.27，在物理一致性方面最多达到 68.02，表明时空一致性和物理推理有限。对于逆动态模型图灵测试，我们首先使用 IDM 来评估视频基础模型在现实世界中的执行准确性。然而，大多数模型的成功率都下降到约 0%，而《魔兽世界》则保持了 40.74% 的成功率。这些发现表明生成的视频与现实世界之间存在明显差距，凸显了在具体人工智能中对世界模型进行基准测试的紧迫性和必要性。|[2601.04137](http://arxiv.org/abs/2601.04137)|null|\n",
        "2601.04061": "|**2026-01-07**|**CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos**|与丰富的人类视频演示相比，通用视觉-语言-动作模型目前受到机器人数据稀缺的阻碍。现有的潜在动作模型试图利用视频数据，但经常遭受视觉纠缠，捕捉噪音而不是操纵技能。为了解决这个问题，我们提出了对比潜在动作预训练（CLAP），这是一个将视频中的视觉潜在空间与机器人轨迹中的本体感受潜在空间对齐的框架。通过采用对比学习，CLAP 将视频转换映射到量化的、物理可执行的码本上。在此表示的基础上，我们引入了一种双公式 VLA 框架，该框架提供 CLAP-NTP（一种擅长指令跟踪和对象泛化的自回归模型）和 CLAP-RF（一种基于整流流的策略，专为高频、精确操作而设计）。此外，我们提出了一种知识匹配（KM）正则化策略，以减轻微调期间的灾难性遗忘。大量实验表明，CLAP 的性能显着优于强大的基线，能够将技能从人类视频有效转移到机器人执行。项目页面：https://lin-shan.com/CLAP/。|[2601.04061](http://arxiv.org/abs/2601.04061)|null|\n",
        "2601.04052": "|**2026-01-07**|**Stable Language Guidance for Vision-Language-Action Models**|视觉-语言-动作（VLA）模型在广义机器人控制方面展示了令人印象深刻的能力；然而，众所周知，它们仍然容易受到语言扰动的影响。我们发现了一种关键的“模态崩溃”现象，即强烈的视觉先验压倒了稀疏的语言信号，导致代理过度适应特定的指令短语，同时忽略了潜在的语义意图。为了解决这个问题，我们提出了 \\textbf{Residual Semantic Steering (RSS)}，这是一个将物理可供性与语义执行分开的概率框架。 RSS 引入了两项理论创新：(1) \\textbf{蒙特卡罗句法集成}，它通过密集的、LLM 驱动的分布扩展来近似真实的语义后验；(2) \\textbf{Residual Affordance Steering}，一种双流解码机制，通过减去先验的视觉可供性来明确隔离语言的因果影响。理论分析表明，RSS 有效地最大化了行动和意图之间的相互信息，同时抑制了视觉干扰。不同操作基准的实证结果表明，RSS 实现了最先进的鲁棒性，即使在对抗性语言扰动下也能保持性能。|[2601.04052](http://arxiv.org/abs/2601.04052)|null|\n",
        "2601.04035": "|**2026-01-07**|**MobileDreamer: Generative Sketch World Model for GUI Agent**|移动 GUI 代理在现实世界的自动化和实际应用中显示出强大的潜力。然而，大多数现有代理仍然处于反应状态，主要根据当前屏幕做出决策，这限制了它们在长期任务中的性能。通过重复交互构建世界模型可以预测行动结果并支持移动 GUI 代理更好的决策。这是具有挑战性的，因为模型必须具有空间意识来预测动作后状态，同时保持足够的效率以进行实际部署。在本文中，我们提出了 MobileDreamer，这是一种基于世界模型的高效前瞻框架，用于根据世界模型提供的未来想象来装备 GUI 代理。它由文本草图世界模型和GUI代理的展开想象组成。文本草图世界模型通过学习过程预测动作后状态，将数字图像转换为与关键任务相关的草图，并设计一种新颖的顺序不变学习策略来保留 GUI 元素的空间信息。 GUI代理的推出想象策略通过利用世界模型的预测能力来优化动作选择过程。 Android World 上的实验表明，MobileDreamer 实现了最先进的性能，并将任务成功率提高了 5.25%。世界模型评估进一步验证了我们的文本草图建模能够准确预测关键 GUI 元素。|[2601.04035](http://arxiv.org/abs/2601.04035)|null|\n",
        "2601.03905": "|**2026-01-07**|**Current Agents Fail to Leverage World Model as Tool for Foresight**|基于视觉语言模型构建的智能体越来越多地面临需要预测未来状态而不是依赖短期推理的任务。生成世界模型提供了一种有希望的补救措施：智能体可以将它们用作外部模拟器，以在采取行动之前预见结果。本文实证检验了当前的智能体是否可以利用此类世界模型作为工具来增强他们的认知。在不同的代理和视觉问答任务中，我们观察到一些代理很少调用模拟（低于 1%），经常误用预测的推出（大约 15%），并且在模拟可用或强制执行时经常表现出不一致甚至性能下降（高达 5%）。归因分析进一步表明，主要瓶颈在于智能体决定何时进行模拟、如何解释预测结果以及如何将预见性融入下游推理的能力。这些发现强调需要一种机制来促进与世界模型的校准、战略交互，为未来代理系统中更可靠的预期认知铺平道路。|[2601.03905](http://arxiv.org/abs/2601.03905)|null|\n",
        "2601.03904": "|**2026-01-07**|**Towards Safe Autonomous Driving: A Real-Time Motion Planning Algorithm on Embedded Hardware**|确保自动驾驶车辆 (AV) 的功能安全需要运动规划模块，该模块不仅要在严格的实时约束下运行，还要在系统故障时保持可控性。现有的防护概念，例如在线验证（OV），提供了检测不可行的规划输出的安全层。然而，它们缺乏主动机制来确保在主规划器发生故障时安全运行。本文提出了针对故障操作自动驾驶（AD）的主动安全扩展的第一步。我们在运行实时操作系统 (RTOS) 的汽车级嵌入式平台上部署了基于采样的轻量级轨迹规划器。规划器在计算资源有限的情况下不断计算轨迹，为未来的应急规划架构奠定了基础。实验结果证明了具有有限延迟和最小抖动的确定性定时行为，验证了在安全认证硬件上进行轨迹规划的可行性。该研究强调了将主动后备机制整合为下一代保障框架的一个组成部分的潜力和仍然存在的挑战。代码位于：https://github.com/TUM-AVS/real-time-motion-planning|[2601.03904](http://arxiv.org/abs/2601.03904)|null|\n",
        "2601.03789": "|**2026-01-07**|**CSI-MAE: A Masked Autoencoder-based Channel Foundation Model**|自监督学习 (SSL) 已成为机器学习中的一项关键技术，可解决有限的标记数据、高注释成本和可变的无线信道条件等挑战。它对于开发信道基础模型 (CFM) 至关重要，该模型从信道状态信息 (CSI) 中提取潜在特征并适应不同的无线设置。然而，现有的 CFM 存在明显的缺点：严重依赖场景特定数据阻碍泛化，它们专注于单/双任务，缺乏零样本学习能力。在本文中，我们提出了 CSI-MAE，一种利用屏蔽自动编码器进行跨场景泛化的泛化 CFM。它经过 3GPP 信道模型数据集的训练，通过 CSI 感知和生成集成了传感和通信，并在不同的任务中被证明是有效的。轻量级解码器微调策略可以降低训练成本，同时保持有竞争力的性能。在这种方法下，CSI-MAE 匹配或超越了监督模型。通过全参数微调，实现了最先进的性能。其卓越的零样本可转移性也可与跨场景应用中的监督技术相媲美，从而推动无线通信创新。|[2601.03789](http://arxiv.org/abs/2601.03789)|null|\n",
        "2601.03782": "|**2026-01-07**|**PointWorld: Scaling 3D World Models for In-The-Wild Robotic Manipulation**|人类通过目光和身体的预期动作来预测 3D 世界将如何响应，这种能力对于机器人操作同样重要。我们引入了 PointWorld，一种大型预训练 3D 世界模型，它将共享 3D 空间中的状态和动作统一为 3D 点流：给定一个或几个 RGB-D 图像和一系列低级机器人动作命令，PointWorld 预测 3D 中响应给定动作的每像素位移。通过将动作表示为 3D 点流而不是具体实施例的动作空间（例如关节位置），该公式直接以机器人的物理几何形状为条件，同时无缝集成跨实施例的学习。为了训练我们的 3D 世界模型，我们在 3D 视觉和模拟环境的最新进展的支持下，在开放世界环境中构建了一个涵盖真实和模拟机器人操作的大型数据集，单臂 Franka 和双手类人机器人总计约 200 万条轨迹和 500 小时。通过对主干、动作表示、学习目标、部分可观察性、数据混合、域传输和缩放进行严格的大规模实证研究，我们提炼出大规模 3D 世界建模的设计原则。凭借实时（0.1秒）的推理速度，PointWorld可以有效地集成到模型预测控制（MPC）框架中进行操作。我们证明，单个预训练检查点使现实世界的 Franka 机器人能够执行刚体推动、可变形和铰接物体操作以及工具使用，无需任何演示或后期训练，所有这些都来自在野外捕获的单个图像。项目网站：https://point-world.github.io/。|[2601.03782](http://arxiv.org/abs/2601.03782)|null|\n",
        "2601.03741": "|**2026-01-07**|**I2E: From Image Pixels to Actionable Interactive Environments for Text-Guided Image Editing**|现有的文本引导图像编辑方法主要依赖于端到端像素级修复范例。尽管它在简单的场景中取得了成功，但这种范例在需要精确的局部控制和复杂的多对象空间推理的合成编辑任务方面仍然存在很大的困难。这种范例受到以下因素的严重限制：1) 规划和执行的隐式耦合，2) 缺乏对象级控制粒度，以及 3) 对非结构化、以像素为中心的建模的依赖。为了解决这些限制，我们提出了 I2E，一种新颖的“分解然后行动”范例，它将图像编辑重新视为结构化环境中的可操作交互过程。 I2E 利用分解器将非结构化图像转换为离散的、可操作的对象层，然后引入物理感知的视觉语言动作代理，通过思想链推理将复杂的指令解析为一系列原子动作。此外，我们还构建了I2E-Bench，这是一个专为多实例空间推理和高精度编辑而设计的基准。 I2E-Bench 和多个公共基准测试的实验结果表明，I2E 在处理复杂的组合指令、保持物理合理性和确保多轮编辑稳定性方面显着优于最先进的方法。|[2601.03741](http://arxiv.org/abs/2601.03741)|null|\n",
        "2601.05230": "|**2026-01-08**|**Learning Latent Action World Models In The Wild**|能够在现实世界中进行推理和规划的智能体需要能够预测其行为的后果。虽然世界模型具备这种能力，但它们通常需要动作标签，而大规模获取这些标签可能很复杂。这激发了潜在动作模型的学习，该模型可以仅从视频中学习动作空间。我们的工作解决了在野外视频中学习潜在动作世界模型的问题，扩大了专注于简单机器人模拟、视频游戏或操纵数据的现有工作的范围。虽然这使我们能够捕捉更丰富的动作，但它也带来了来自视频多样性的挑战，例如环境噪声或视频中缺乏共同的体现。为了解决一些挑战，我们讨论了操作应遵循的属性以及相关的架构选择和评估。我们发现连续但受约束的潜在动作能够捕获野外视频中动作的复杂性，这是常见的矢量量化所无法做到的。例如，我们发现来自代理的环境变化（例如人类进入房间）可以通过视频传输。这凸显了学习特定于野外视频的动作的能力。在视频中缺乏共同体现的情况下，我们主要能够学习相对于相机在空间中定位的潜在动作。尽管如此，我们能够训练一个将已知动作映射到潜在动作的控制器，使我们能够使用潜在动作作为通用接口，并使用我们的世界模型解决规划任务，其性能与动作条件基线相似。我们的分析和实验为将潜在动作模型扩展到现实世界提供了一步。|[2601.05230](http://arxiv.org/abs/2601.05230)|null|\n",
        "2601.05172": "|**2026-01-08**|**CoV: Chain-of-View Prompting for Spatial Reasoning**|3D 环境中的实体问答 (EQA) 通常需要收集分布在多个视点且部分被遮挡的上下文。然而，最近的视觉语言模型（VLM）仅限于一组固定且有限的输入视图，这限制了它们在推理时获取与问题相关的上下文的能力，并阻碍了复杂的空间推理。我们提出了视图链 (CoV) 提示，这是一种无需训练、测试时的推理框架，可通过从粗到细的探索过程将 VLM 转变为主动的观点推理器。 CoV 首先采用视图选择代理来过滤冗余帧并识别与问题对齐的锚视图。然后，它通过将迭代推理与离散摄像机动作交织来执行细粒度视图调整，从底层 3D 场景表示中获取新的观察结果，直到收集到足够的上下文或达到步骤预算。   我们在四种主流 VLM 上的 OpenEQA 上评估 CoV，并在 LLM-Match 上获得平均 +11.56\\% 的改进，在 Qwen3-VL-Flash 上获得最大 +13.62\\% 的增益。 CoV 进一步展示了测试时间扩展：增加最小行动预算可带来额外的 +2.51\\% 平均改进，在 Gemini-2.5-Flash 上达到 +3.73\\% 的峰值。在 ScanQA 和 SQA3D 上，CoV 提供了强大的性能（例如，ScanQA 上为 116 CIDEr / 31.9 EM@1，SQA3D 上为 51.1 EM@1）。总体而言，这些结果表明，与问题对齐的视图选择与开放视图搜索相结合是一种有效的、与模型无关的策略，可在无需额外训练的情况下改进 3D EQA 中的空间推理。|[2601.05172](http://arxiv.org/abs/2601.05172)|null|\n",
        "2601.05138": "|**2026-01-08**|**VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control**|视频世界模型旨在模拟动态的真实世界环境，但现有方法难以对摄像机和多对象运动提供统一且精确的控制，因为视频本质上是在投影的 2D 图像平面中进行动态操作。为了弥补这一差距，我们引入了 VerseCrafter，这是一种 4D 感知视频世界模型，可以在统一的 4D 几何世界状态中对摄像机和对象动态进行明确且连贯的控制。我们的方法以新颖的 4D 几何控制表示为中心，它通过静态背景点云和每个对象的 3D 高斯轨迹对世界状态进行编码。这种表示不仅可以捕获对象的路径，还可以捕获其随时间变化的概率 3D 占用情况，为刚性边界框或参数模型提供灵活的、与类别无关的替代方案。这些 4D 控件被渲染为预训练视频扩散模型的调节信号，从而能够生成精确遵循指定动态的高保真、视图一致的视频。不幸的是，另一个主要挑战在于缺乏具有明确 4D 注释的大规模训练数据。我们通过开发一个自动数据引擎来解决这个问题，该引擎可以从野外视频中提取所需的 4D 控件，从而使我们能够在海量且多样化的数据集上训练我们的模型。|[2601.05138](http://arxiv.org/abs/2601.05138)|null|\n",
        "2601.05105": "|**2026-01-08**|**UniLiPs: Unified LiDAR Pseudo-Labeling with Geometry-Grounded Dynamic Scene Decomposition**|在自动驾驶应用中，未标记的 LiDAR 日志本质上是隐藏在视线中的密集 3D 几何图形的金矿，但如果没有人类标签，它们几乎毫无用处，这凸显了自主感知研究的主要成本障碍。在这项工作中，我们通过利用 LiDAR 扫描的时间几何一致性来解决这一瓶颈，将文本和 2D 视觉基础模型中的线索直接提升并融合到 3D 中，无需任何手动输入。我们引入了一种无监督的多模态伪标记方法，该方法依赖于从时间累积的 LiDAR 地图中学习到的强大几何先验，以及一种新颖的迭代更新规则，该规则强制执行联合几何语义一致性，反之亦然，检测移动对象的不一致。我们的方法同时生成 3D 语义标签、3D 边界框和密集 LiDAR 扫描，证明了跨三个数据集的强大泛化能力。我们通过实验验证我们的方法与现有的语义分割和对象检测伪标记方法相比具有优势，这些方法通常需要额外的手动监督。我们确认，即使是几何一致的致密 LiDAR 的一小部分，也能在 80-150 米和 150-250 米范围内分别将深度预测提高 51.5% 和 22.0% MAE。|[2601.05105](http://arxiv.org/abs/2601.05105)|null|\n",
        "2601.05083": "|**2026-01-08**|**Driving on Registers**|我们推出了 DrivoR，这是一种简单高效的基于变压器的架构，用于端到端自动驾驶。我们的方法建立在预训练的视觉变压器（ViT）的基础上，并引入了相机感知的寄存器令牌，将多相机特征压缩为紧凑的场景表示，从而在不牺牲准确性的情况下显着减少下游计算。这些令牌驱动两个轻量级变压器解码器，生成候选轨迹并对其进行评分。评分解码器学习模仿预言机并预测代表安全性、舒适性和效率等方面的可解释的子分数，从而在推理时实现行为调节驾驶。尽管设计极简，DrivoR 的性能优于或匹配 NAVSIM-v1、NAVSIM-v2 和真实感闭环 HUGSIM 基准的强大当代基准。我们的结果表明，纯变压器架构与目标令牌压缩相结合，足以实现准确、高效和自适应的端到端驱动。代码和检查点将通过项目页面提供。|[2601.05083](http://arxiv.org/abs/2601.05083)|null|\n",
        "2601.04968": "|**2026-01-08**|**SparseLaneSTP: Leveraging Spatio-Temporal Priors with Sparse Transformers for 3D Lane Detection**|3D 车道检测已成为自动驾驶领域的一项关键挑战，包括车道标记和 3D 路面的识别和定位。传统的 3D 方法通过密集的鸟瞰 (BEV) 特征来检测车道，但错误的转换通常会导致特征表示与真实的 3D 路面不对齐。虽然最近的稀疏车道检测器已经超越了密集的 BEV 方法，但它们完全忽视了有价值的特定于车道的先验。此外，现有方法无法利用历史车道观测，而历史车道观测有可能解决能见度较差情况下的模糊性。为了解决这些挑战，我们提出了 SparseLaneSTP，这是一种将车道结构的几何属性和时间信息集成到稀疏车道变换器中的新颖方法。它引入了一种新的特定于车道的时空注意机制，一种针对稀疏架构和时间正则化量身定制的连续车道表示。识别现有 3D 车道数据集的弱点，我们还使用简单而有效的自动标记策略引入精确且一致的 3D 车道数据集。我们的实验部分证明了我们贡献的好处，并展示了现有 3D 车道检测基准以及我们的新颖数据集上所有检测和错误指标的最先进性能。|[2601.04968](http://arxiv.org/abs/2601.04968)|null|\n",
        "2601.04955": "|**2026-01-08**|**Rapid emergence of overmassive black holes in the early Universe**|超大质量黑洞（SMBH）的起源仍然是天体物理学中长期存在的问题。最近的 JWST 观测结果揭示了 z>4-6 处的超大质量黑洞数量出乎意料地丰富，其中 BH 质量远高于局部标度关系，并且当前的宇宙学模型无法再现。这种超大质量黑洞如何在年轻星系中形成并快速生长仍不清楚。在这里，我们提出了完全宇宙学辐射-流体动力学模拟，该模拟首次自洽地跟踪了原星团环境中超大质量黑洞的诞生、早期生长和新兴可观测特征。我们发现 $10^6 M_\\text{sun}$ 量级的重种子自然形成，超出了典型的理论预期一个数量级。这些种子迅速发育出致密、光学厚的圆盘，其强电子散射产生与小红点（LRD）中所见的广泛的 H$α$ 发射。持续的超级爱丁顿吸积随后推动快速增长至 $\\sim 3 \\times 10^7 ~M_\\text{sun}$ by $z \\sim 8$。这些结果提供了一个统一的物理场景，其中 LRD 对应于重种子形成的短暂、隐蔽阶段，自然演化为 JWST 检测到的超大质量类星体，并最终成为当今超大质量黑洞的前身。|[2601.04955](http://arxiv.org/abs/2601.04955)|null|\n",
        "2601.04891": "|**2026-01-08**|**Scaling Vision Language Models for Pharmaceutical Long Form Video Reasoning on Industrial GenAI Platform**|视觉语言模型（VLM）在多模态推理任务上表现出了强大的性能，但大多数评估都集中在短视频上，并假设计算资源不受限制。在医药内容理解等工业环境中，从业者必须在严格的 GPU、延迟和成本限制下处理长视频，而许多现有方法无法扩展。在这项工作中，我们提出了一个工业 GenAI 框架，可以处理超过 200,000 个 PDF、8 种格式（例如 MP4、M4V 等）的 25,326 个视频以及 20 多种语言的 888 个多语言音频文件。我们的研究做出了三个贡献：（i）制药领域多模态推理的工业大规模架构； (ii) 对两个领先基准（Video-MME 和 MMBench）的 40 多个 VLM 以及涵盖 14 个疾病领域的 25,326 个视频的专有数据集进行实证分析； (iii) 与长视频推理相关的四个发现：多模态的作用、注意力机制权衡、时间推理限制以及 GPU 限制下视频分割的挑战。结果显示，SDPA 对商用 GPU 的关注使效率提高了 3-8 倍，多模态改进了高达 8/12 的任务域（尤其是长度相关的任务），并清除了开源和闭源 VLM 中时间对齐和关键帧检测的瓶颈。本文不是提出新的“A+B”模型，而是描述了当前 VLM 在实际部署约束下的实际限制、权衡和故障模式，并为研究人员和从业者设计可扩展的多模态系统以实现工业领域的长格式视频理解提供了可行的指导。|[2601.04891](http://arxiv.org/abs/2601.04891)|null|\n",
        "2601.04824": "|**2026-01-08**|**SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models**|事件的自动识别和重复行为分析对于视频监控至关重要。然而，大多数现有的基于内容的视频检索基准侧重于场景级相似性，并没有评估监控中所需的动作辨别。为了解决这一差距，我们引入了 SOVABench（监视相反车辆行为基准），这是一个根据监控录像构建的现实世界检索基准，以与车辆相关的行为为中心。 SOVABench 定义了两种评估协议（对间和对内）来评估交叉动作辨别和时间方向理解。尽管动作区别对于人类观察者来说通常是直观的，但我们的实验表明，它们对于最先进的视觉和多模态模型仍然具有挑战性。   利用多模态大型语言模型 (MLLM) 的视觉推理和指令跟踪功能，我们提出了一个免训练框架，用于根据 MLLM 生成的图像和视频描述生成可解释的嵌入。该框架在 SOVABench 以及多个空间和计数基准上实现了强大的性能，而对比视觉语言模型经常在这些基准上失败。构建基准的代码、注释和说明是公开的。|[2601.04824](http://arxiv.org/abs/2601.04824)|null|\n",
        "2601.04775": "|**2026-01-08**|**Towards a Unified Theoretical Framework for Self-Supervised MRI Reconstruction**|对高分辨率、非侵入性成像的需求继续推动磁共振成像 (MRI) 的创新，但较长的采集时间阻碍了可访问性和实时应用。虽然基于深度学习的重建方法加速了 MRI 的发展，但其主要的监督范式依赖于难以获取的完全采样的参考数据。最近，自我监督学习（SSL）方法已成为有前途的替代方案，但大多数都是凭经验设计的且支离破碎。因此，我们引入 UNITS（自监督统一理论），这是自监督 MRI 重建的通用框架。 UNITS 将先前的 SSL 策略统一在一个通用的形式中，从而实现一致的解释和系统的基准测试。我们证明 SSL 可以达到与监督学习相同的预期性能。在此理论保证下，我们引入了采样随机性和灵活的数据利用，提高了域外分布下的网络泛化能力并稳定了训练。这些贡献共同将 UNITS 确立为可解释、可推广和临床适用的自监督 MRI 重建的理论基础和实践范式。|[2601.04775](http://arxiv.org/abs/2601.04775)|null|\n",
        "2601.05248": "|**2026-01-08**|**LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model**|视觉-语言-动作（VLA）模型最近在机器人操作方面表现出了强大的泛化能力。一些现有的 VLA 方法试图通过在动作执行之前显式生成语言推理轨迹或未来的视觉观察来提高动作准确性。然而，显式推理通常会产生不可忽略的推理延迟，这限制了机器人操作所需的时间分辨率。此外，这种推理仅限于语言空间，造成了难以忠实地捕捉不可言喻的物理属性的表征瓶颈。为了缓解这些限制，我们提出了 LaST$_0$，这是一个框架，可以在通过潜在时空思维链 (CoT) 进行行动之前实现高效推理，捕获通常难以用语言表达的细粒度物理和机器人动态。具体来说，我们引入了一个令牌有效的潜在 CoT 空间，它可以对未来的视觉动态、3D 结构信息和机器人本体感受状态进行建模，并进一步跨时间扩展这些表示，以实现时间一致的隐式推理轨迹。此外，LaST$_0$ 采用通过 Mixture-of-Transformers 设计实现的双系统架构，其中推理专家进行低频潜在推理，代理专家根据面向机器人的潜在表示生成高频动作。为了促进协调，LaST$_0$ 使用异构操作频率进行训练，从而在部署期间实现推理和动作推理速率之间的自适应切换。在 10 个模拟任务和 6 个现实世界操作任务中，LaST$_0$ 比之前的 VLA 方法分别将平均成功率提高了 8% 和 13%，同时实现了更快的推理速度。项目网站：https://sites.google.com/view/last0|[2601.05248](http://arxiv.org/abs/2601.05248)|null|\n",
        "2601.05241": "|**2026-01-08**|**RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation**|操纵数据的多样性、数量和质量对于训练有效的机器人策略至关重要。然而，由于硬件和物理设置的限制，收集大规模的现实世界操作数据仍然难以在不同的环境中扩展。最近的工作使用文本提示条件图像扩散模型，通过改变视觉观察中的背景和桌面对象来增强操作数据。然而，这些方法往往忽视了最先进的政策模型所需的多视角和时间连贯观察的实际需求。此外，仅靠文本提示无法可靠地指定场景设置。为了给扩散模型提供明确的视觉指导，我们引入了视觉识别提示，它提供示例图像作为条件输入，以指导生成所需的场景设置。为此，我们还构建了一个可扩展的管道，以从大型机器人数据集中管理视觉身份池。使用我们的增强操作数据来训练下游视觉语言动作和视觉运动策略模型，可以在模拟和真实机器人设置中产生一致的性能增益。|[2601.05241](http://arxiv.org/abs/2601.05241)|null|\n",
        "2601.05946": "|**2026-01-09**|**A Critical Examination of Active Learning Workflows in Materials Science**|主动学习 (AL) 在材料科学中发挥着至关重要的作用，可实现诸如构建用于原子模拟的机器学习原子间势以及自动驾驶实验室的运行等应用。尽管应用广泛，但 AL 工作流程的可靠性和有效性取决于隐含的设计假设，而这些假设很少被系统地检验。在这里，我们严格评估材料科学中部署的 AL 工作流程，并研究关键设计选择（例如替代模型、采样策略、不确定性量化和评估指标）与其性能的关系。通过识别常见陷阱并讨论实际的缓解策略，我们为从业者提供材料科学中 AL 工作流程的高效设计、评估和解释的指导。|[2601.05946](http://arxiv.org/abs/2601.05946)|null|\n",
        "2601.05940": "|**2026-01-09**|**Reverse segregation and self-organization in inclined chute flows of bidisperse granular mixtures**|在细粒和粗粒球形颗粒的双分散混合物的稳定倾斜溜槽流的通常分离情况下，粗颗粒向自由表面上升，在流动堆顶部形成富含粗粒的区域。相反，超过大约 4 的阈值粗细直径比时，粗颗粒的重量超过了偏析驱动力，导致单个粗颗粒下沉在堆内并产生反向偏析状态。然而，当粒径比超过 4 {\\textit{并且}} 粗颗粒质量分数相当大时，对桩结构集体演化的理解仍然缺乏。为了探索这种广泛的双分散极限，我们进行了离散元法模拟，考虑了高达 8 的平均粒径比和 0.1 至 0.9 的粗颗粒质量分数。稳态流动剖面揭示了一些取决于直径比和质量分数的有趣行为。这些包括先前确定的从普通偏析到反向偏析的转变，以及新发现的自组织成沿剪切梯度方向堆叠的交替的粗粒和细粒层的趋势，层厚度由粗粒直径决定。更全面地了解这种规模的分离可以为商业规模的增强混合或分层技术铺平道路。|[2601.05940](http://arxiv.org/abs/2601.05940)|null|\n",
        "2601.05930": "|**2026-01-09**|**Can We Predict Before Executing Machine Learning Agents?**|自主机器学习代理彻底改变了科学发现，但它们仍然受到生成-执行-反馈范式的限制。以前的方法存在严重的执行瓶颈，因为假设评估严格依赖于昂贵的物理执行。为了绕过这些物理限制，我们从世界模型中汲取灵感，将执行先验内在化，用即时预测推理代替昂贵的运行时检查。在这项工作中，我们形式化了以数据为中心的解决方案偏好的任务，并构建了一个包含 18,438 个成对比较的综合语料库。我们证明，法学硕士在提供经过验证的数据分析报告时表现出显着的预测能力，实现了 61.5% 的准确度和强大的置信度校准。最后，我们在 FOREAGENT 中实例化该框架，该代理采用 Predict-then-Verify 循环，实现了 6 倍的收敛加速，同时超出基于执行的基线 +6%。我们的代码和数据集很快将在 https://github.com/zjunlp/predict-before-execute 上公开。|[2601.05930](http://arxiv.org/abs/2601.05930)|null|\n",
        "2601.05867": "|**2026-01-09**|**When legs and bodies synchronize: Two-level collective dynamics in dense crowds**|超密集的人群中，人与人之间不可避免地发生身体接触，造成了重大的安全隐患。然而，推动他们集体行为的潜在动力仍然知之甚少。现有的密集人群模型大多是二维的和基于接触的，忽略了控制个体平衡运动的生物力学机制。在这项研究中，我们引入了一个最小的两级行人模型，该模型将上半身和腿部动力学耦合起来，使我们能够捕获个体尺度上平衡和不平衡状态之间的转变。尽管以前的模型未能实现这一目标，但这种耦合产生了凭经验观察到的集体行为，例如自组织波浪和人群内的大规模旋转运动。该模型将基本的个体生物力学概念和宏观流动动力学联系起来，为建模和理解超密集人群中的集体运动提供了一个新的框架。|[2601.05867](http://arxiv.org/abs/2601.05867)|null|\n",
        "2601.05848": "|**2026-01-09**|**Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals**|视频生成领域的最新进展使得能够模拟机器人和规划的潜在未来的“世界模型”的开发成为可能。然而，为这些模型指定精确的目标仍然是一个挑战；文本指令通常过于抽象，无法捕捉物理细微差别，而目标图像通常无法为动态任务指定。为了解决这个问题，我们引入了 Goal Force，这是一种新颖的框架，允许用户通过明确的力向量和中间动力学来定义目标，反映了人类如何概念化物理任务。我们在合成因果原语（例如弹性碰撞和倒下的多米诺骨牌）的精选数据集上训练视频生成模型，教导它通过时间和空间传播力。尽管接受了简单物理数据的训练，但我们的模型对复杂的现实世界场景（包括工具操作和多对象因果链）表现出出色的零样本泛化能力。我们的结果表明，通过将视频生成基于基本的物理交互，模型可以作为隐式神经物理模拟器出现，从而无需依赖外部引擎即可实现精确的物理感知规划。我们在项目页面发布了所有数据集、代码、模型权重和交互式视频演示。|[2601.05848](http://arxiv.org/abs/2601.05848)|null|\n",
        "2601.05839": "|**2026-01-09**|**GeoSurDepth: Spatial Geometry-Consistent Self-Supervised Depth Estimation for Surround-View Cameras**|准确的环视深度估计为激光传感器提供了一种有竞争力的替代方案，对于自动驾驶中的 3D 场景理解至关重要。虽然先前的研究提出了各种主要侧重于在光度水平上强制执行交叉视图约束的方法，但很少有人明确利用单目和环视设置中固有的丰富几何结构。在这项工作中，我们提出了 GeoSurDepth，一个利用几何一致性作为环视深度估计的主要线索的框架。具体来说，我们利用基础模型作为伪几何先验和特征表示增强工具来指导网络保持空间 3D 空间中的表面法线一致性，并规范 2D 中对象和纹理一致的深度估计。此外，我们引入了一种新颖的视图合成管道，其中通过空间扭曲重建密集深度来实现 2D-3D 提升，鼓励跨时间、空间和时空上下文的额外光度监督，并补偿单视图图像重建的局限性。最后，新提出的自适应联合运动学习策略使网络能够自适应地强调信息丰富的空间几何线索，以改进运动推理。对 DDAD 和 nuScenes 的大量实验表明，GeoSurDepth 实现了最先进的性能，验证了我们方法的有效性。我们的框架强调了利用几何相干性和一致性来实现稳健的自监督多视图深度估计的重要性。|[2601.05839](http://arxiv.org/abs/2601.05839)|null|\n",
        "2601.05806": "|**2026-01-09**|**Modular Autonomy with Conversational Interaction: An LLM-driven Framework for Decision Making in Autonomous Driving**|大型语言模型 (LLM) 的最新进展为自动驾驶系统 (ADS) 创建自然语言界面提供了新的机会，超越了严格的输入。本文解决了将人类语言的复杂性映射到模块化 ADS 软件的结构化动作空间的挑战。我们提出了一个框架，将基于 LLM 的交互层与 Autoware（一种广泛使用的开源软件）集成。该系统使乘客能够发出高级命令，从查询状态信息到修改驾驶行为。我们的方法基于三个关键组成部分：交互类别的分类、用于命令翻译的以应用程序为中心的领域特定语言（DSL）以及安全保护验证层。两阶段的法学硕士架构通过根据最终的执行状态提供反馈来确保高度透明度。评估确认了系统的计时效率和翻译稳健性。模拟成功验证了所有五个交互类别的命令执行。这项工作为模块化和安全意识自治堆栈中的可扩展、DSL 辅助交互奠定了基础。|[2601.05806](http://arxiv.org/abs/2601.05806)|null|\n",
        "2601.05787": "|**2026-01-09**|**From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation**|视觉语言模型越来越多地部署为操作桌面和浏览器的计算机使用代理（CUA）。性能最佳的 CUA 是基于框架的系统，可分解规划和执行，而端到端的屏幕截图到操作策略更易于部署，但在 OSWorld-Verified 等基准测试中落后。像 OSWorld 这样的 GUI 数据集存在两个瓶颈：它们仅公开数百个交互式、可验证的任务和环境，并且必须通过与这些环境交互来收集专家轨迹，从而使得此类数据难以扩展。因此，我们询问可验证奖励（RLVR）的强化学习如何最好地利用一小部分现有的专家轨迹来训练端到端策略。天真地将这些离策略轨迹混合到在策略 RLVR 中是很脆弱的：即使在格式转换之后，专家轨迹也会表现出结构不匹配和学习者的分布变化。我们提出了 BEPA（双层专家策略同化），它通过基本策略 (LEVEL-1) 下的自滚动可达轨迹和 RLVR (LEVEL-2) 中使用的按任务动态更新的缓存，将静态专家跟踪转换为策略一致的指导。在 OSWorld-Verified 上，BEPA 将 UITARS1.5-7B 的成功率从 22.87% 提高到 32.13%，并将保留的分裂率从 5.74% 提高到 10.30%，在 MMBench-GUI 和 Online-Mind2Web 上保持一致的增长。我们的代码和数据可在以下位置获取：https://github.com/LEON-gittech/Verl_GUI.git|[2601.05787](http://arxiv.org/abs/2601.05787)|null|\n",
        "2601.05685": "|**2026-01-09**|**Drivora: A Unified and Extensible Infrastructure for Search-based Autonomous Driving Testing**|基于搜索的测试对于评估自动驾驶系统 (ADS) 的安全性和可靠性至关重要。然而，现有的方法通常建立在异构框架（例如，不同的场景空间、模拟器和 ADS）上，这需要付出相当大的努力来重用和适应不同的设置。为了应对这些挑战，我们推出了 Drivora，这是一个统一且可扩展​​的基础架构，用于基于广泛使用的 CARLA 模拟器构建的基于搜索的 ADS 测试。 Drivora 引入了统一的场景定义 OpenScenario，它使用低级可操作参数指定场景，以确保与现有方法的兼容性，同时支持新测试设计的可扩展性（例如，多自动驾驶车辆测试）。除此之外，Drivora 将测试引擎、场景执行和 ADS 集成解耦。测试引擎利用进化计算探索新场景，并支持核心组件的灵活定制。场景执行可以使用并行执行机制运行任意场景，最大限度地提高大规模批量模拟的硬件利用率。对于 ADS 集成，Drivora 通过统一接口提供对 12 个 ADS 的访问，从而简化了配置并简化了新 ADS 的合并。我们的工具可在 https://github.com/MingfeiCheng/Drivora 上公开获取。|[2601.05685](http://arxiv.org/abs/2601.05685)|null|\n",
        "2601.05653": "|**2026-01-09**|**EvoQRE: Modeling Bounded Rationality in Safety-Critical Traffic Simulation via Evolutionary Quantal Response Equilibrium**|自动驾驶汽车现有的交通模拟框架通常依赖于模仿学习或博弈论方法来解决纳什或粗略相关均衡，隐含地假设完全理性的代理。然而，人类驾驶员表现出有限理性，在认知和感知约束下做出近似最优的决策。我们提出了 EvoQRE，这是一个原则框架，用于将安全关键型交通交互建模为通过量子响应均衡 (QRE) 和进化博弈动力学解决的一般和马尔可夫博弈。 EvoQRE 将预先训练的生成世界模型与熵正则化复制动力学相结合，在保持平衡结构的同时捕获随机人类行为。我们提供了严格的理论结果，证明所提出的动力学在两时间尺度随机近似下收敛于 Logit-QRE，在弱单调性假设下显式收敛率为 O(log k / k^{1/3})。我们使用基于混合物和基于能量的策略表示进一步将 QRE 扩展到连续行动空间。 Waymo 开放运动数据集和 nuPlan 基准测试表明，EvoQRE 实现了最先进的现实性、改进的安全指标，并通过可解释的合理性参数可控地生成各种安全关键场景。|[2601.05653](http://arxiv.org/abs/2601.05653)|null|\n",
        "2601.07119": "|**2026-01-12**|**SC-MII: Infrastructure LiDAR-based 3D Object Detection on Edge Devices for Split Computing with Multiple Intermediate Outputs Integration**|使用基于 LiDAR 的点云数据和深度神经网络进行 3D 物体检测对于自动驾驶技术至关重要。然而，由于高计算需求和能耗，在边缘设备上部署最先进的模型面临着挑战。此外，单个激光雷达设置存在盲点。本文提出了 SC-MII，即边缘设备上基于多基础设施 LiDAR 的 3D 物体检测，用于具有多个中间输出集成的分割计算。在 SC-MII 中，边缘设备通过初始 DNN 层处理本地点云，并将中间输出发送到边缘服务器。服务器集成这些功能并完成推理，减少延迟和设备负载，同时提高隐私性。在真实数据集上的实验结果显示，速度提高了 2.19 倍，边缘设备处理时间减少 71.6%，准确率最多下降 1.09%。|[2601.07119](http://arxiv.org/abs/2601.07119)|null|\n",
        "2601.07092": "|**2026-01-11**|**Efficient Visual Question Answering Pipeline for Autonomous Driving via Scene Region Compression**|自动驾驶越来越依赖视觉问答 (VQA)，使车辆能够通过分析视觉输入和文本查询来了解复杂的环境。目前，该领域 VQA 的首要关注点是对快速延迟和实时处理的严格要求，因为延迟直接影响这一安全关键型应用程序中的实际安全性。然而，当前最先进的 VQA 模型，特别是大型视觉语言模型 (VLM)，通常优先考虑性能而不是计算效率。这些模型通常会为每一帧处理密集的补丁标记，从而导致过高的计算成本 (FLOP) 和显着的推理延迟，尤其是对于长视频序列。这种关注限制了它们在实时自动驾驶场景中的实际部署。为了解决这个问题，我们提出了一种用于自动驾驶 VQA 任务的高效 VLM 框架，SRC-Pipeline。它学习将早期帧令牌压缩为少量高级令牌，同时保留最近帧的完整补丁令牌。自动驾驶视频问答任务的实验表明，我们的方法在保持可比性能的同时实现了 66% 的 FLOP 减少，使 VLM 能够在实时、安全关键的自动驾驶环境中更有效地运行。|[2601.07092](http://arxiv.org/abs/2601.07092)|null|\n",
        "2601.07060": "|**2026-01-11**|**PALM: Progress-Aware Policy Learning via Affordance Reasoning for Long-Horizon Robotic Manipulation**|视觉-语言-动作（VLA）模型的最新进展在机器人操作方面显示出了希望，但它们仍然在长期、多步骤任务方面遇到困难。现有方法缺乏内部推理机制，无法识别与任务相关的交互线索或跟踪子任务内的进度，从而导致严重的执行错误，例如重复操作、错过步骤和过早终止。为了应对这些挑战，我们引入了 PALM，这是一个 VLA 框架，围绕以交互为中心的可供性推理和子任务进度线索构建策略学习。 PALM 提炼出互补的可供性表示，捕获对象相关性、接触几何、空间放置和运动动力学，并作为视觉运动控制的任务相关锚点。为了进一步稳定长期执行，PALM 可以预测子任务内的连续进度，从而实现无缝子任务转换。在广泛的模拟和现实世界实验中，PALM 始终优于基线，在 LIBERO-LONG 上实现了 91.8% 的成功率，在 CALVIN ABC->D 上平均长度提高了 12.5%，在三个长视野泛化设置中比现实世界基线提高了 2 倍。|[2601.07060](http://arxiv.org/abs/2601.07060)|null|\n",
        "2601.07043": "|**2026-01-11**|**PANDA-film: an automated system for electrodeposition of polymer thin films and their wetting analysis**|聚合物薄膜广泛用作功能性和保护性涂层。然而，由于必须考虑大量因素以及大多数合成和表征方法的手动性质，确定产生所需功能的组成和加工条件是一个繁琐的过程。自动驾驶实验室 (SDL) 或准备和测试材料样品的机器人系统旨在通过有效探索复杂参数空间来克服这一瓶颈。在本文中，我们报告了聚合物分析与发现阵列 (PANDA) 薄膜的开发和测试，这是一种模块化 SDL，用于电化学合成聚合物薄膜，然后确定其水接触角作为表面能的量度。该系统设计为高度模块化，并基于低成本龙门平台，以方便采用。除了验证流体处理和电化学任务之外，我们还引入了两种新颖的模块化功能，使 PANDA-film 能够持续研究薄膜的润湿特性：(1) 电磁加盖/脱盖系统，以减轻流体蒸发，以及 (2) 自上而下的光学方法，用于根据反射率确定水接触角。这些功能通过使用聚合物网络电沉积 (EPoN) 沉积和表征聚甲基丙烯酸烯丙酯 (PAMA) 薄膜来验证。包括复制 PANDA-film 硬件和软件的全面详细信息。|[2601.07043](http://arxiv.org/abs/2601.07043)|null|\n",
        "2601.07013": "|**2026-01-11**|**Conditional Normalizing Flows for Forward and Backward Joint State and Parameter Estimation**|用于状态估计的传统滤波算法（例如经典卡尔曼滤波、无迹卡尔曼滤波和粒子滤波器）在应用于不确定性遵循任意非高斯分布和潜在多模态分布的非线性系统时表现出性能下降。本研究回顾了最近通过基于条件归一化流的非线性过滤进行状态估计的方法，其中条件嵌入是由标准 MLP 架构、变压器或选择性状态空间模型（如 Mamba-SSM）生成的。此外，我们还测试了最佳传输启发的动力学损失项在减轻由大量变换组成的流中过度参数化方面的有效性。我们研究了这些方法在与自动驾驶和患者群体动态相关的应用中的性能，特别关注它们如何处理时间反演和链式预测。最后，我们评估了各种调节策略在现实世界的 COVID-19 联合 SIR 系统预测和参数估计中的应用性能。|[2601.07013](http://arxiv.org/abs/2601.07013)|null|\n",
        "2601.06748": "|**2026-01-11**|**On-the-Fly VLA Adaptation via Test-Time Reinforcement Learning**|视觉-语言-动作模型最近已成为通用机器人学习的强大范例，使代理能够将视觉观察和自然语言指令映射到可执行的机器人动作。尽管很受欢迎，但它们主要通过监督微调或训练时强化学习进行训练，需要明确的微调阶段、人工干预或受控数据收集。因此，现有方法仍然不适合具有挑战性的模拟或物理世界部署，其中机器人必须自主、灵活地响应不断变化的环境。为了解决这一限制，我们引入了 VLA 测试时强化学习 (TT-VLA)，这是一个能够在推理过程中进行动态策略调整的框架。 TT-VLA 制定了密集的奖励机制，利用逐步的任务进度信号来细化测试期间的行动策略，同时保留 SFT/RL 训练的先验，使其成为当前 VLA 模型的有效补充。实证结果表明，我们的方法增强了模拟和现实环境中动态的、以前未见过的场景中的整体适应性、稳定性和任务成功率。我们相信 TT-VLA 为实现自我改进、部署就绪的 VLA 迈出了原则性的一步。|[2601.06748](http://arxiv.org/abs/2601.06748)|null|\n",
        "2601.06604": "|**2026-01-10**|**Object-Centric World Models Meet Monte Carlo Tree Search**|在本文中，我们介绍了 ObjectZero，这是一种新颖的强化学习 (RL) 算法，它利用对象级表示的强大功能来更有效地对动态环境进行建模。与将世界作为单个无差别输入进行处理的传统方法不同，我们的方法采用图神经网络（GNN）来捕获多个对象之间复杂的交互。这些可以被操纵并相互交互的对象是我们的模型理解环境的基础。我们在充满各种交互式对象的复杂环境中训练该算法，展示了其有效学习和预测对象动态的能力。我们的结果强调，基于以对象为中心的表示操作的结构化世界模型可以成功集成到使用蒙特卡罗树搜索作为规划模块的基于模型的强化学习算法中。|[2601.06604](http://arxiv.org/abs/2601.06604)|null|\n",
        "2601.06474": "|**2026-01-10**|**SparseOccVLA: Bridging Occupancy and Vision-Language Models via Sparse Queries for Unified 4D Scene Understanding and Planning**|在自动驾驶中，视觉语言模型（VLM）擅长高级推理，而语义占用则提供细粒度的细节。尽管各个领域取得了重大进展，但仍然没有一种方法可以有效地整合这两种范式。传统的 VLM 面临着令牌爆炸和有限的时空推理的问题，而语义占用提供了统一、明确的空间表示，但过于密集，无法与 VLM 有效集成。为了应对这些挑战并弥合 VLM 和占用率之间的差距，我们提出了 SparseOccVLA，这是一种新颖的视觉-语言-动作模型，它统一了由稀疏占用查询支持的场景理解、占用预测和轨迹规划。从轻量级稀疏占用编码器开始，SparseOccVLA 生成紧凑但信息丰富的稀疏占用查询，充当视觉和语言之间的单一桥梁。这些查询与语言空间对齐，并由法学硕士进行推理，以实现统一的场景理解和未来的占用预测。此外，我们引入了 LLM 引导的锚扩散规划器，具有解耦锚评分和去噪，以及跨模型轨迹条件融合。 SparseOccVLA 在 CIDEr 上相对于 OmniDrive-nuScenes 上最先进的技术提高了 7%，在 Occ3D-nuScenes 上的 mIoU 分数提高了 0.5，并在 nuScenes 基准上设置了最先进的开环规划指标，展示了其强大的整体能力。|[2601.06474](http://arxiv.org/abs/2601.06474)|null|\n",
        "2601.06451": "|**2026-01-10**|**CulinaryCut-VLAP: A Vision-Language-Action-Physics Framework for Food Cutting via a Force-Aware Material Point Method**|食品切割是视觉和机器人操作交叉领域的一种高度实用但尚未充分开发的应用。这项任务仍然具有挑战性，因为刀和可变形材料之间的相互作用是高度非线性的，通常会带来大变形、频繁接触和拓扑变化，这反过来又阻碍了稳定和安全的大规模数据收集。   为了应对这些挑战，我们提出了一个统一的框架，将视觉语言动作（VLA）数据集与基于材料点方法（MPM）构建的物理真实切割模拟器结合起来。我们的模拟器采用 MLS-MPM 作为其计算核心，即使在拓扑变化的切割下，也能减少数值耗散和能量漂移，同时保留旋转和剪切响应。在切割过程中，力和应力分布是根据颗粒和网格之间的脉冲交换来估计的，从而能够稳定跟踪瞬态接触力和能量传递。   我们还提供了一个基准数据集，集成了不同的切割轨迹、多视图视觉观察和细粒度的语言指令，以及力-扭矩和工具-姿势标签，以提供物理一致的训练信号。   这些组件实现了学习-评估循环，尊重切割的核心物理原理，并为在可变形物体操作中推进 VLA 模型奠定了安全、可重复和可扩展的基础。|[2601.06451](http://arxiv.org/abs/2601.06451)|null|\n",
        "2601.06442": "|**2026-01-10**|**WHU-PCPR: A cross-platform heterogeneous point cloud dataset for place recognition in complex urban scenes**|基于点云的位置识别（PCPR）在自动驾驶、机器人定位和导航以及地图更新等应用中展现出巨大的潜力。在实际应用中，用于位置识别的点云通常是从不同平台和不同场景的激光雷达获取的。然而，现有的PCPR数据集缺乏场景、平台和传感器的多样性，限制了相关研究的有效发展。为了解决这一差距，我们建立了 WHU-PCPR，这是一个专为地点识别而设计的跨平台异构点云数据集。该数据集通过其独特的特征与现有数据集区分开来：1）跨平台异构点云：从测量级车载移动激光扫描（MLS）系统和低成本便携式头盔式激光扫描（PLS）系统收集，每个系统都配备了不同的机械和固态LiDAR传感器。 2）复杂的定位场景：涵盖城市和校园道路场景的实时和长期变化。 3）大范围空间覆盖：60个月内轨迹长82.3公里，无重复路线约30公里。基于WHU-PCPR，我们对几种具有代表性的PCPR方法进行了广泛的评估和深入分析，并对关键挑战和未来的研究方向进行了简洁的讨论。数据集和基准代码可在 https://github.com/zouxianghong/WHU-PCPR 获取。|[2601.06442](http://arxiv.org/abs/2601.06442)|null|\n",
        "2601.07823": "|**2026-01-12**|**Video Generation Models in Robotics -- Applications, Research Challenges, Future Directions**|视频生成模型已经成为物理世界的高保真模型，能够合成高质量视频，捕捉代理与其环境之间的细粒度交互，这些交互取决于多模式用户输入。它们令人印象深刻的功能解决了基于物理的模拟器面临的许多长期挑战，推动了许多问题领域的广泛采用，例如机器人技术。例如，视频模型可以实现逼真、物理一致的变形体模拟，而无需做出令人望而却步的简化假设，这是基于物理的模拟的主要瓶颈。此外，视频模型可以作为基础世界模型，以细粒度和富有表现力的方式捕捉世界的动态。因此，它们在描述复杂的物理交互时克服了纯语言抽象的有限表达能力。在本次调查中，我们回顾了视频模型及其在机器人技术中作为具体世界模型的应用，包括模仿学习中具有成本效益的数据生成和动作预测、强化学习中的动态和奖励建模、视觉规划和政策评估。此外，我们强调了阻碍视频模型在机器人技术中可靠集成的重要挑战，其中包括指令遵循不佳、违反物理等幻觉以及不安全的内容生成，以及重要的数据管理、培训和推理成本等基本限制。我们提出了解决这些开放研究挑战的潜在未来方向，以激励研究并最终促进更广泛的应用，特别是在安全关键的环境中。|[2601.07823](http://arxiv.org/abs/2601.07823)|null|\n",
        "2601.07821": "|**2026-01-12**|**Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation**|基于深度强化学习的后训练算法可以突破机器人模型针对特定目标的限制，例如通用性、准确性和鲁棒性。然而，在现实世界的探索过程中，需要干预的故障（IR 故障）（例如，机器人溅水或打碎易碎玻璃）不可避免地会发生，这阻碍了这种范例的实际部署。为了解决这个问题，我们引入了故障感知离线到在线强化学习（FARL），这是一种新的范式，可以最大限度地减少现实世界强化学习期间的故障。我们创建了 FailureBench，这是一个包含需要人工干预的常见故障场景的基准，并提出了一种算法，该算法集成了基于世界模型的安全批评家和离线训练的恢复策略，以防止在线探索期间出现故障。广泛的模拟和真实实验证明了 FARL 在显着减少 IR 故障方面的有效性，同时提高了在线强化学习训练后的性能和泛化能力。 FARL 将 IR 故障减少了 73.1%，同时在现实世界的 RL 训练后将性能平均提高了 11.3%。视频和代码可在 https://failure-aware-rl.github.io 上获取。|[2601.07821](http://arxiv.org/abs/2601.07821)|null|\n",
        "2601.07692": "|**2026-01-12**|**Leveraging 3D Representation Alignment and RGB Pretrained Priors for LiDAR Scene Generation**|LiDAR 场景合成是解决自动驾驶等机器人任务 3D 数据稀缺问题的新兴解决方案。最近的方法采用扩散或流动匹配模型来生成逼真的场景，但与具有数百万个样本的 RGB 数据集相比，3D 数据仍然有限。我们引入了 R3DPA，这是第一个用于解锁 LiDAR 点云图像预训练先验的 LiDAR 场景生成方法，并利用自监督 3D 表示来获得最先进的结果。具体来说，我们 (i) 将生成模型的中间特征与自监督 3D 特征对齐，这大大提高了生成质量； (ii) 将知识从大规模图像预训练生成模型转移到 LiDAR 生成，从而缓解 LiDAR 数据集有限的问题； (iii) 在推理时启用点云控制，以仅使用无条件模型进行对象修复和场景混合。在 KITTI-360 基准测试中，R3DPA 实现了最先进的性能。代码和预训练模型可在 https://github.com/valeoai/R3DPA 获取。|[2601.07692](http://arxiv.org/abs/2601.07692)|null|\n",
        "2601.07540": "|**2026-01-12**|**ViewMorpher3D: A 3D-aware Diffusion Framework for Multi-Camera Novel View Synthesis in Autonomous Driving**|自动驾驶系统严重依赖多视图图像来确保准确的感知和稳健的决策。为了有效地开发和评估感知堆栈和规划算法，逼真的闭环模拟器是必不可少的。虽然高斯溅射等 3D 重建技术为模拟器构建提供了有希望的途径，但渲染的新颖视图通常会出现伪影，特别是在外推视角或可用观察稀疏时。   我们推出 ViewMorpher3D，这是一种基于图像扩散模型的多视图图像增强框架，旨在提升驾驶场景中的真实感和多视图一致性。与单视图方法不同，ViewMorpher3D 联合处理一组以相机姿势、3D 几何先验以及时间相邻或空间重叠参考视图为条件的渲染视图。这使得模型能够推断缺失的细节、抑制渲染伪影并强制执行跨视图一致性。   我们的框架可容纳不同数量的摄像机和灵活的参考/目标视图配置，使其能够适应不同的传感器设置。对现实世界驾驶数据集的实验表明，图像质量指标得到了显着改善，有效减少了伪影，同时保持了几何保真度。|[2601.07540](http://arxiv.org/abs/2601.07540)|null|\n",
        "2601.07516": "|**2026-01-12**|**Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions**|视觉语言模型越来越多地用作多模式会话代理（MCA）来执行不同的会话任务。最近，强化学习 (RL) 已被广泛探索，用于使 MCA 适应各种人机交互场景。尽管在泛化性能方面显示出巨大的增强，但通过 RL 微调 MCA 在处理极大的文本标记空间方面仍然面临挑战。为了解决这个问题，我们学习了一个紧凑的潜在动作空间来进行强化学习微调。具体来说，我们采用从观察中学习的机制来构建潜在动作空间的密码本，其中利用未来的观察来估计当前的潜在动作，这些动作可以进一步用于重建未来的观察。然而，图像-文本配对数据的稀缺阻碍了学习具有足够覆盖范围的码本。因此，我们利用成对的图像文本数据和纯文本数据来构建潜在动作空间，使用跨模式投影仪将文本嵌入转换为图像文本嵌入。我们在成对的图像文本数据上初始化跨模态投影仪，并在大量纯文本数据上进一步训练它，并使用新颖的循环一致性损失来增强其鲁棒性。我们证明，我们基于潜在动作的方法在各种 RL 算法的两个对话任务上优于竞争基线。|[2601.07516](http://arxiv.org/abs/2601.07516)|null|\n",
        "2601.07474": "|**2026-01-12**|**Task Prototype-Based Knowledge Retrieval for Multi-Task Learning from Partially Annotated Data**|多任务学习 (MTL) 在自动驾驶和机器人等现实应用中至关重要，可以同时处理不同的任务。然而，由于标签成本的原因，获取所有任务的完整注释数据是不切实际的。现有的部分标记 MTL 方法通常依赖于未标记任务的预测，这使得难以建立可靠的任务关联，并可能导致负迁移和次优性能。为了解决这些问题，我们提出了一个基于原型的知识检索框架，该框架实现了稳健的 MTL，而不是依赖于未标记任务的预测。我们的框架由两个关键组件组成：（1）嵌入任务特定特征并量化任务关联的任务原型，以及（2）知识检索转换器，根据这些关联自适应地细化特征表示。为了实现这一目标，我们引入了关联知识生成（AKG）损失，以确保任务原型一致地捕获特定于任务的特征。大量的实验证明了我们框架的有效性，突出了其强大的多任务学习的潜力，即使只注释了任务的子集。|[2601.07474](http://arxiv.org/abs/2601.07474)|null|\n",
        "2601.07463": "|**2026-01-12**|**Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning**|离线多智能体强化学习（MARL）旨在使用预先收集的数据集解决多智能体系统中的协作决策问题。现有的离线 MARL 方法主要限制数据集分布内的训练，导致策略过于保守，难以在数据支持之外进行泛化。虽然基于模型的方法通过使用学习世界模型生成的合成数据扩展原始数据集提供了一种有前途的解决方案，但多智能体系统的高维性、非平稳性和复杂性使得准确估计离线 MARL 中的转换和奖励函数变得具有挑战性。考虑到直接建模联合动力学的困难，我们提出了一种局部到全局（LOGO）世界模型，这是一种利用局部预测（更容易估计）来推断全局状态动态的新颖框架，从而提高预测准确性，同时隐式捕获智能体依赖关系。使用经过训练的世界模型，我们生成合成数据来扩充原始数据集，扩展有效的状态-动作空间。为了确保可靠的策略学习，我们进一步引入了一种不确定性感知采样机制，该机制通过预测不确定性对合成数据进行自适应加权，减少近似误差传播到策略。与传统的基于集成的方法相比，我们的方法仅需要一个额外的编码器来进行不确定性估计，从而在保持准确性的同时显着减少计算开销。针对 8 个基线的 8 个场景的广泛实验表明，我们的方法超越了标准离线 MARL 基准的最先进基线，为可推广的离线多智能体学习建立了一个新的基于模型的基线。|[2601.07463](http://arxiv.org/abs/2601.07463)|null|\n",
        "2601.07393": "|**2026-01-12**|**Software-Hardware Co-optimization for Modular E2E AV Paradigm: A Unified Framework of Optimization Approaches, Simulation Environment and Evaluation Metrics**|模块化端到端（ME2E）自动驾驶范例将模块化可解释性与全局优化能力相结合，并表现出强大的性能。然而，现有的研究主要集中在准确性的提高，而推理延迟和能耗等关键的系统级因素往往被忽视，导致模型设计日益复杂，阻碍了实际部署。先前在模型压缩和加速方面的努力通常是单独优化软件或硬件方面。纯软件优化无法从根本上消除中间张量访问和算子调度开销，而纯硬件优化则受到模型结构和精度的限制。因此，此类优化在现实世界中带来的好处通常是有限的。为了应对这些挑战，本文提出了一种可重用的ME2E自动驾驶推理软硬件协同优化和闭环评估框架。该框架在统一的系统级目标下将软件级模型优化与硬件级计算优化联合集成。此外，引入多维度评估指标，综合考虑安全性、舒适性、效率、延迟和能耗来评估系统性能，从而能够定量比较不同优化策略。跨多个 ME2E 自动驾驶堆栈的实验表明，所提出的框架保留了基线水平的驾驶性能，同时显着降低了推理延迟和能耗，实现了整体系统级的实质性改进。这些结果表明，所提出的框架为 ME2E 自动驾驶系统的高效部署提供了实用且可操作的指导。|[2601.07393](http://arxiv.org/abs/2601.07393)|null|\n",
        "2601.07154": "|**2026-01-12**|**Motion Focus Recognition in Fast-Moving Egocentric Video**|从视觉-语言-动作（VLA）系统到机器人技术，现有的以自我为中心的数据集主要关注动作识别任务，而很大程度上忽视了运动分析在运动和其他快速运动场景中的固有作用。为了弥补这一差距，我们提出了一种实时运动焦点识别方法，可以从任何以自我为中心的视频中估计主体的运动意图。我们的方法利用相机姿态估计的基础模型，并引入系统级优化来实现高效且可扩展的推理。在收集的以自我为中心的动作数据集上进行评估，我们的方法通过滑动批量推理策略实现了实时性能和可管理的内存消耗。这项工作使得以运动为中心的分析对于边缘部署变得实用，并为现有的以自我为中心的体育和快速运动活动研究提供了补充视角。|[2601.07154](http://arxiv.org/abs/2601.07154)|null|\n"
    }
}