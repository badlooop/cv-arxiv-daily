---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.10.11
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-08**|**BEVLoc: Cross-View Localization and Matching via Birds-Eye-View Synthesis**|地对空匹配是户外机器人技术中一项至关重要且具有挑战性的任务，特别是在GPS缺失或不可靠的情况下。建筑物或大型茂密森林等结构会产生干扰，需要GNSS替代全球定位估计。真正的困难在于调和地面和空中图像之间的视角差异，以实现可接受的定位。从自动驾驶社区获得灵感，我们提出了一种新的框架，用于合成鸟瞰图（BEV）场景表示，以在越野环境中与航空地图进行匹配和定位。我们利用对比学习和特定领域的硬负挖掘来训练网络，以学习合成BEV和航空地图之间的相似表示。在推理过程中，BEVLoc通过从粗到细的匹配策略引导识别航空地图中最可能的位置。我们的研究结果表明，在语义多样性有限的极其困难的森林环境中，初步结果很有希望。我们分析了模型的粗匹配和细匹配性能，评估了模型的原始匹配能力及其作为GNSS替代品的性能。我们的工作深入研究了越野地图本地化，同时为本地化的未来发展建立了基础基线。我们的代码可在以下网址获得：https://github.com/rpl-cmu/bevloc et.al.|[2410.06410](http://arxiv.org/abs/2410.06410)|null|
|**2024-10-08**|**HiSplat: Hierarchical 3D Gaussian Splatting for Generalizable Sparse-View Reconstruction**|从多个视点重建3D场景是立体视觉中的一项基本任务。最近，可推广的3D高斯散斑技术的进步通过前馈预测每像素高斯参数而无需额外优化，实现了从稀疏输入视图中为看不见的场景进行高质量的新颖视图合成。然而，现有的方法通常生成单尺度3D高斯分布，缺乏对大规模结构和纹理细节的表示，导致定位错误和伪影。本文提出了一种新的框架HiSplat，该框架在可推广的3D高斯散点中引入了一种分层方式，通过从粗到细的策略构建分层的3D高斯分布。具体来说，HiSplat生成大的粗粒度高斯分布来捕捉大规模结构，然后生成细粒度高斯分布来增强精细的纹理细节。为了促进尺度间的相互作用，我们提出了一个用于高斯补偿的误差感知模块和一个用于Gaussian修复的调制融合模块。我们的方法实现了分层表示的联合优化，允许仅使用两个视图参考图像进行新颖的视图合成。对各种数据集的综合实验表明，与之前的单尺度方法相比，HiSplat显著提高了重建质量和跨数据集泛化能力。对不同尺度三维高斯分布的相应消融研究和分析揭示了有效性背后的机制。项目网站：https://open3dvlab.github.io/HiSplat/ et.al.|[2410.06245](http://arxiv.org/abs/2410.06245)|null|
|**2024-10-08**|**Comparative Analysis of Novel View Synthesis and Photogrammetry for 3D Forest Stand Reconstruction and extraction of individual tree parameters**|准确高效的树木三维重建对于森林资源评估和管理至关重要。近景摄影测量（CRP）通常用于重建森林场景，但面临着效率低、质量差等挑战。最近，包括神经辐射场（NeRF）和3D高斯散斑（3DGS）在内的新型视图合成（NVS）技术已显示出在有限图像下进行3D植物重建的前景。然而，现有的研究主要集中在果园或单株树木中的小型植物上，这给它们在更大、更复杂的林分中的应用带来了不确定性。在这项研究中，我们收集了具有不同复杂性的森林地块的连续图像，并使用NeRF和3DGS进行了密集重建。将得到的点云与摄影测量和激光扫描的点云进行了比较。结果表明，NVS方法显著提高了重建效率。摄影测量难以处理复杂的林分，导致点云的树冠噪声过大，树木重建不正确，如树干重复。NeRF虽然对树冠区域更好，但在视野有限的地面区域可能会产生误差。3DGS方法生成更稀疏的点云，特别是在主干区域，影响胸径（DBH）精度。这三种方法都可以提取树高信息，其中NeRF的精度最高；然而，摄影测量在DBH精度方面仍然具有优势。这些发现表明，NVS方法在林分三维重建方面具有巨大潜力，为复杂的森林资源清查和可视化任务提供了宝贵支持。 et.al.|[2410.05772](http://arxiv.org/abs/2410.05772)|null|
|**2024-10-07**|**PH-Dropout: Prctical Epistemic Uncertainty Quantification for View Synthesis**|使用神经辐射场（NeRF）和高斯散斑（GS）的视图合成在渲染现实世界场景时表现出了令人印象深刻的保真度。然而，在视图综合中缺乏准确有效的认知不确定性量化（UQ）的实用方法。现有的NeRF方法要么引入了大量的计算开销（例如，“训练时间增加10倍”或“重复训练10倍”），要么仅限于特定的不确定性条件或模型。值得注意的是，GS模型缺乏全面认知UQ的系统方法。这种能力对于提高神经视图合成的鲁棒性和可扩展性至关重要，可以实现主动模型更新、误差估计和基于不确定性的可扩展集成建模。本文从函数近似的角度重新审视了基于NeRF和GS的方法，确定了3D表示学习中的关键差异和联系。基于这些见解，我们介绍了PH Dropout（事后Dropout），这是第一种直接在预训练的NeRF和GS模型上进行认知不确定性估计的实时准确方法。广泛的评估验证了我们的理论发现，并证明了PH Dropout的有效性。 et.al.|[2410.05468](http://arxiv.org/abs/2410.05468)|null|
|**2024-10-07**|**DreamSat: Towards a General 3D Model for Novel View Synthesis of Space Objects**|新颖的视图合成（NVS）能够生成场景的新图像或将一组2D图像转换为全面的3D模型。在空间领域意识的背景下，由于空间变得越来越拥挤，NVS可以准确地绘制空间物体和碎片的地图，提高空间操作的安全性和效率。同样，在会合和近距离作战任务中，3D模型可以提供目标物体的形状、大小和方向的详细信息，从而更好地规划和预测目标的行为。在这项工作中，我们探索了这些重建技术的泛化能力，旨在通过在190个高质量航天器模型的高质量数据集上微调最先进的单视图重建模型Zero123 XL，并将其集成到DreamGaussian框架中，提出一种从单视图图像重建3D航天器的新方法DreamSat，从而避免对每个新场景进行再训练的必要性。我们展示了在多个指标上重建质量的一致改进，包括对比语言图像预训练（CLIP）得分（+0.33%）、峰值信噪比（PSNR）（+2.53%）、结构相似性指数（SSIM）（+2.38%）和学习感知图像补丁相似性（LPIPS）（+0.16%）。%）在30张以前从未见过的航天器图像的测试集上。我们的方法通过利用最先进的扩散模型和3D高斯溅射技术，解决了航天工业中缺乏特定领域的3D重建工具的问题。这种方法保持了DreamGaussian框架的效率，同时提高了航天器重建的准确性和细节。这项工作的代码可以在GitHub上访问(https://github.com/ARCLab-MIT/space-nvs). et.al.|[2410.05097](http://arxiv.org/abs/2410.05097)|**[link](https://github.com/arclab-mit/space-nvs)**|
|**2024-10-10**|**6DGS: Enhanced Direction-Aware Gaussian Splatting for Volumetric Rendering**|随着神经辐射场（NeRF）和3D高斯散射（3DGS）的发展，新型视图合成技术取得了显著进步。然而，在不影响实时渲染的情况下实现高质量仍然具有挑战性，特别是对于具有视图相关效果的基于物理的光线跟踪。最近，N维高斯（N-DG）引入了6D空间角度表示，以更好地结合视图相关的效果，但高斯表示和控制方案都是次优的。在本文中，我们重新审视了6D高斯分布，并引入了6D高斯散斑（6DGS），它增强了颜色和不透明度表示，并利用6D空间中的额外方向信息来优化高斯控制。我们的方法与3DGS框架完全兼容，并通过更好地建模视图相关效果和精细细节，显著提高了实时辐射场渲染。实验证明，6DGS明显优于3DGS和N-DG，与3DGS相比，PSNR提高了15.73dB，高斯点减少了66.5%。项目页面为：https://gaozhongpai.github.io/6dgs/ et.al.|[2410.04974](http://arxiv.org/abs/2410.04974)|null|
|**2024-10-07**|**TeX-NeRF: Neural Radiance Fields from Pseudo-TeX Vision**|神经辐射场（NeRF）因其卓越的视觉效果而受到广泛关注。然而，大多数现有的NeRF方法都是从可见光相机捕获的RGB图像中重建3D场景。在黑暗、低光照或恶劣天气等实际情况下，可见光摄像头会变得无效。因此，我们提出了TeX-NeRF，这是一种仅使用红外图像的3D重建方法，它先验地引入了物体材料的发射率，使用伪TeX视觉对红外图像进行预处理，并将场景的温度（T）、发射率（e）和纹理（X）分别映射到HSV颜色空间的饱和度（S）、色调（H）和值（V）通道中。使用处理后的图像的新颖视图合成产生了优异的结果。此外，我们介绍了3D TeX数据集，这是第一个包含红外图像及其相应的伪TeX视觉图像的数据集。实验证明，我们的方法不仅与高质量RGB图像实现的场景重建质量相匹配，而且为场景中的对象提供了准确的温度估计。 et.al.|[2410.04873](http://arxiv.org/abs/2410.04873)|null|
|**2024-10-06**|**Deformable NeRF using Recursively Subdivided Tetrahedra**|虽然神经辐射场（NeRF）在新颖的视图合成中显示出希望，但它们的隐式表示限制了对对象操纵的显式控制。现有的研究提出了整合显式几何代理来实现变形。然而，这些方法面临着两个主要挑战：第一，耗时且计算量大的四面体化过程；其次，处理复杂或薄的结构通常会导致四面体网格过多、存储密集或质量差，从而损害变形能力。为了应对这些挑战，我们提出了DeformRF，这是一种将四面体网格的可操作性与特征网格表示的高质量渲染能力无缝集成的方法。为了避免每个对象的四面体形状不好和四面体化，我们提出了一种两阶段训练策略。从几乎规则的四面体网格开始，我们的模型最初保留了对象周围的关键四面体，随后在第二阶段使用更细粒度的网格细化对象细节。我们还提出了递归细分四面体的概念，以隐式创建更高分辨率的网格。这实现了多分辨率编码，同时只需要存储在第一训练阶段生成的粗略四面体网格。我们在合成和真实捕获的数据集上对DeformRF进行了全面评估。定量和定性结果都证明了我们的方法在新的视图合成和变形任务中的有效性。项目页面：https://ustc3dv.github.io/DeformRF/ et.al.|[2410.04402](http://arxiv.org/abs/2410.04402)|null|
|**2024-10-06**|**StreetSurfGS: Scalable Urban Street Surface Reconstruction with Planar-based Gaussian Splatting**|重建城市街道场景至关重要，因为它在自动驾驶和城市规划等应用中起着至关重要的作用。这些场景的特点是长而窄的相机轨迹、遮挡、复杂的对象关系和跨多个尺度的数据稀疏性。尽管最近取得了进展，但主要针对以对象为中心的场景设计的现有表面重建方法很难有效地适应街道场景的独特特征。为了应对这一挑战，我们引入了StreetSurfGS，这是第一种采用高斯散斑法的方法，专门为可扩展的城市街道场景表面重建而定制。StreetSurfGS利用基于平面的八叉树表示和分段训练来降低内存成本，适应独特的相机特性，并确保可扩展性。此外，为了减轻对象重叠引起的深度不准确，我们提出了一种正则化中的引导平滑策略，以消除不准确的边界点和异常值。此外，为了解决稀疏视图和多尺度挑战，我们使用了一种利用相邻和长期信息的双步匹配策略。大量实验验证了StreetSurfGS在新颖视图合成和曲面重建方面的有效性。 et.al.|[2410.04354](http://arxiv.org/abs/2410.04354)|null|
|**2024-10-05**|**Test-Time Adaptation for Keypoint-Based Spacecraft Pose Estimation Based on Predicted-View Synthesis**|由于在训练过程中难以复制真实条件，当在合成数据上训练并应用于实际操作数据时，航天器姿态估计的监督算法的性能会下降。为了解决这个问题，我们提出了一种测试时间自适应方法，该方法利用了近距离操作期间获取的图像之间的时间冗余。我们的方法包括从连续的航天器图像中提取特征，估计它们的姿态，然后使用这些信息合成重建的视图。我们通过将综合视图与实际视图进行比较，建立了一个自我监督学习目标。在训练过程中，我们监督姿态估计和图像合成，而在测试时，我们优化自我监督目标。此外，我们引入了正则化损失，以防止与航天器关键点结构不一致的解决方案。我们的代码可在以下网址获得：https://github.com/JotaBravo/spacecraft-tta. et.al.|[2410.04298](http://arxiv.org/abs/2410.04298)|**[link](https://github.com/jotabravo/spacecraft-tta)**|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-09**|**Z-upscaling: Optical Flow Guided Frame Interpolation for Isotropic Reconstruction of 3D EM Volumes**|我们提出了一种新的基于光流的方法来提高各向异性3D EM体积的轴向分辨率，以实现各向同性3D重建。假设在对齐良好的EM体积中3D生物结构的空间连续性，我们推断可以利用通常用于视频时间分辨率增强的光流估计技术。像素级运动是在沿z的相邻2D切片之间估计的，使用空间梯度流估计来插值和生成新的2D切片，从而得到各向同性体素。我们利用最新的最先进的学习方法进行视频帧插值和迁移学习技术，并在公开的超微结构EM体积上证明了我们的方法的成功。 et.al.|[2410.07043](http://arxiv.org/abs/2410.07043)|**[link](https://github.com/fisseha21/z-upscaling)**|
|**2024-10-09**|**ES-Gaussian: Gaussian Splatting Mapping via Error Space-Based Gaussian Completion**|准确且经济实惠的室内3D重建对于有效的机器人导航和交互至关重要。传统的基于激光雷达的测绘提供了高精度，但成本高、重量重、功耗大，新颖的视图渲染能力有限。基于视觉的测绘虽然经济高效，能够捕获视觉数据，但由于点云稀疏，往往难以进行高质量的3D重建。我们提出了ES Gaussian，这是一种端到端系统，使用低空相机和单线LiDAR进行高质量的3D室内重建。我们的系统具有视觉误差构造（VEC）功能，通过识别和校正二维误差图中几何细节不足的区域来增强稀疏点云。此外，我们介绍了一种由单线LiDAR引导的新型3DGS初始化方法，克服了传统多视图设置的局限性，并在资源受限的环境中实现了有效的重建。我们新的Dreame SR数据集和公开数据集的大量实验结果表明，ES Gaussian优于现有方法，特别是在具有挑战性的场景中。项目页面可在https://chenlu-china.github.io/ES-Gaussian/. et.al.|[2410.06613](http://arxiv.org/abs/2410.06613)|null|
|**2024-10-08**|**Comparative Analysis of Novel View Synthesis and Photogrammetry for 3D Forest Stand Reconstruction and extraction of individual tree parameters**|准确高效的树木三维重建对于森林资源评估和管理至关重要。近景摄影测量（CRP）通常用于重建森林场景，但面临着效率低、质量差等挑战。最近，包括神经辐射场（NeRF）和3D高斯散斑（3DGS）在内的新型视图合成（NVS）技术已显示出在有限图像下进行3D植物重建的前景。然而，现有的研究主要集中在果园或单株树木中的小型植物上，这给它们在更大、更复杂的林分中的应用带来了不确定性。在这项研究中，我们收集了具有不同复杂性的森林地块的连续图像，并使用NeRF和3DGS进行了密集重建。将得到的点云与摄影测量和激光扫描的点云进行了比较。结果表明，NVS方法显著提高了重建效率。摄影测量难以处理复杂的林分，导致点云的树冠噪声过大，树木重建不正确，如树干重复。NeRF虽然对树冠区域更好，但在视野有限的地面区域可能会产生误差。3DGS方法生成更稀疏的点云，特别是在主干区域，影响胸径（DBH）精度。这三种方法都可以提取树高信息，其中NeRF的精度最高；然而，摄影测量在DBH精度方面仍然具有优势。这些发现表明，NVS方法在林分三维重建方面具有巨大潜力，为复杂的森林资源清查和可视化任务提供了宝贵支持。 et.al.|[2410.05772](http://arxiv.org/abs/2410.05772)|null|
|**2024-10-08**|**Single picture single photon single pixel 3D imaging through unknown thick scattering medium**|通过厚散射介质成像带来了重大挑战，特别是对于三维（3D）应用。这份手稿展示了一种通过这种介质实现单图像3D成像的新方案，将散射介质视为透镜。这种方法可以捕获包含隐藏在不同深度的物体信息的综合图像。通过利用离焦深度和散射介质厚度的减小进行单像素成像，所提出的方法确保了强大的3D成像能力。我们开发了传统的基于度量和基于深度学习的方法来提取每个像素的深度信息，使我们能够探索正面和负面物体的位置，无论是浅层还是深层。值得注意的是，该方案能够同时对隐藏在散射介质中的目标进行3D重建。具体来说，我们成功地重建了埋在5毫米和30毫米深处的目标，总介质厚度为60毫米。此外，我们可以有效地区分三个不同深度的目标。值得注意的是，该方案不需要散射介质的先验知识，也不需要侵入性程序、参考测量或校准。 et.al.|[2410.05607](http://arxiv.org/abs/2410.05607)|null|
|**2024-10-07**|**SharpSLAM: 3D Object-Oriented Visual SLAM with Deblurring for Agile Drones**|本文重点研究了通过提高RGB图像质量来提高DSP-SLAM中3D重建和分割质量的算法。我们开发的SharpSLAM算法旨在通过图像去模糊来减少高动态运动对视觉面向对象SLAM的影响，改进面向对象SLPM的各个方面，包括定位、映射和对象重建。实验结果表明，由于特征和相应地图点的数量增加，目标检测质量显著提高，F评分从82.9%提高到86.2%。有符号距离函数的RMSE也从17.2厘米降低到15.4厘米。此外，我们的解决方案增强了对象定位，IoU从74.5%增加到75.7%。SharpSLAM算法有可能大大提高DSP-SLAM中3D重建和分割的质量，并影响广泛的领域，包括机器人、自动驾驶汽车和增强现实。 et.al.|[2410.05405](http://arxiv.org/abs/2410.05405)|null|
|**2024-10-07**|**DreamSat: Towards a General 3D Model for Novel View Synthesis of Space Objects**|新颖的视图合成（NVS）能够生成场景的新图像或将一组2D图像转换为全面的3D模型。在空间领域意识的背景下，由于空间变得越来越拥挤，NVS可以准确地绘制空间物体和碎片的地图，提高空间操作的安全性和效率。同样，在会合和近距离作战任务中，3D模型可以提供目标物体的形状、大小和方向的详细信息，从而更好地规划和预测目标的行为。在这项工作中，我们探索了这些重建技术的泛化能力，旨在通过在190个高质量航天器模型的高质量数据集上微调最先进的单视图重建模型Zero123 XL，并将其集成到DreamGaussian框架中，提出一种从单视图图像重建3D航天器的新方法DreamSat，从而避免对每个新场景进行再训练的必要性。我们展示了在多个指标上重建质量的一致改进，包括对比语言图像预训练（CLIP）得分（+0.33%）、峰值信噪比（PSNR）（+2.53%）、结构相似性指数（SSIM）（+2.38%）和学习感知图像补丁相似性（LPIPS）（+0.16%）。%）在30张以前从未见过的航天器图像的测试集上。我们的方法通过利用最先进的扩散模型和3D高斯溅射技术，解决了航天工业中缺乏特定领域的3D重建工具的问题。这种方法保持了DreamGaussian框架的效率，同时提高了航天器重建的准确性和细节。这项工作的代码可以在GitHub上访问(https://github.com/ARCLab-MIT/space-nvs). et.al.|[2410.05097](http://arxiv.org/abs/2410.05097)|**[link](https://github.com/arclab-mit/space-nvs)**|
|**2024-10-07**|**Real-time Ship Recognition and Georeferencing for the Improvement of Maritime Situational Awareness**|在海洋基础设施至关重要的时代，先进的态势感知解决方案变得越来越重要。光学相机系统的使用可以实时使用海上录像。本文研究了如何利用深度学习和计算机视觉来推进实时船舶识别和地理参考，以提高海上态势感知能力。介绍了一种新的数据集ShipSG，其中包含3505张图像和11625个具有相应类别和地理位置的船面具。在探索了最先进的技术后，为NVIDIA Jetson AGX Xavier嵌入式系统设计了一种定制的实时分割架构ScatYOLOv8+CBAM。该架构将2D散射变换和注意力机制添加到YOLOv8中，实现了75.46%的mAP和每帧25.3ms，比最先进的方法高出5%以上。为了提高嵌入式系统上高分辨率图像中小型和远程船舶的识别能力，引入了一种增强的切片机制，将mAP提高了8%至11%。此外，还提出了一种地理参考方法，对于距离400米以内的船舶，实现了18米的定位误差，对于400米至1200米之间的船舶，则实现了44米的定位精度。这些发现也适用于现实世界的场景，如检测异常的船舶行为、相机完整性评估和3D重建。本文的方法优于现有方法，并为将识别和地理参考的船舶集成到实时系统中提供了一个框架，提高了海事利益相关者的运营效率和决策能力。本文通过建立船舶分割和地理参考研究的基准，为海洋计算机视觉领域做出了贡献，展示了基于深度学习的识别和地理参考方法在实时海洋监测中的可行性。 et.al.|[2410.04946](http://arxiv.org/abs/2410.04946)|null|
|**2024-10-07**|**TeX-NeRF: Neural Radiance Fields from Pseudo-TeX Vision**|神经辐射场（NeRF）因其卓越的视觉效果而受到广泛关注。然而，大多数现有的NeRF方法都是从可见光相机捕获的RGB图像中重建3D场景。在黑暗、低光照或恶劣天气等实际情况下，可见光摄像头会变得无效。因此，我们提出了TeX-NeRF，这是一种仅使用红外图像的3D重建方法，它先验地引入了物体材料的发射率，使用伪TeX视觉对红外图像进行预处理，并将场景的温度（T）、发射率（e）和纹理（X）分别映射到HSV颜色空间的饱和度（S）、色调（H）和值（V）通道中。使用处理后的图像的新颖视图合成产生了优异的结果。此外，我们介绍了3D TeX数据集，这是第一个包含红外图像及其相应的伪TeX视觉图像的数据集。实验证明，我们的方法不仅与高质量RGB图像实现的场景重建质量相匹配，而且为场景中的对象提供了准确的温度估计。 et.al.|[2410.04873](http://arxiv.org/abs/2410.04873)|null|
|**2024-10-06**|**Multimodal 3D Fusion and In-Situ Learning for Spatially Aware AI**|增强现实中虚拟世界和物理世界的无缝集成得益于系统对物理环境的语义“理解”。AR研究长期以来一直专注于上下文感知的潜力，展示了利用3D环境中的语义进行各种对象级交互的新功能。与此同时，计算机视觉界在神经视觉语言理解方面取得了长足的进步，以增强自主任务的环境感知。在这项工作中，我们引入了一种多模态3D对象表示，该表示将语义和语言知识与几何表示相结合，实现了涉及物理对象的用户引导机器学习。我们首先提出了一种快速的多模态3D重建流水线，通过将CLIP视觉语言特征融合到环境和对象模型中，为AR带来语言理解。然后，我们提出了“原位”机器学习，它与多模态表示相结合，使用户能够以空间和语言上有意义的方式与物理空间和对象进行交互。我们通过Magic Leap 2上的两个现实AR应用程序展示了所提出系统的有用性：a）使用自然语言在物理环境中进行空间搜索；b）跟踪对象随时间变化的智能库存系统。我们还提供完整的实施和演示数据，网址为(https://github.com/cy-xu/spatially_aware_AI)鼓励对空间感知人工智能的进一步探索和研究。 et.al.|[2410.04652](http://arxiv.org/abs/2410.04652)|**[link](https://github.com/cy-xu/spatially_aware_ai)**|
|**2024-10-05**|**IceCloudNet: 3D reconstruction of cloud ice from Meteosat SEVIRI**|IceCloudNet是一种基于机器学习的新方法，能够预测高质量的垂直分辨云冰水含量（IWC）和冰晶数浓度（N $_\textrm{ice}$）。这些预测基于地球静止卫星观测（SEVIRI）的时空覆盖和分辨率以及主动卫星反演（DARDAR）的垂直分辨率。IceCloudNet由基于ConvNeXt的U-Net和3D PatchGAN鉴别器模型组成，并通过从共置的SEVIRI图像中预测DAR轮廓进行训练。尽管由于其狭窄的立交桥，DARDAR数据的可用性很低，但IceCloudNet能够高精度地预测云的出现、空间结构和微物理特性。该模型已应用于十年的SEVIRI数据，生成了一个垂直分辨率的IWC数据集和N$\textrm{ice}$ 的含冰云数据集，其分辨率为3 kmx3 kmx240 mx15分钟，空间域为西经30度至东经30度，南纬30度至北纬30度。所生成的数据集将DARDAR可用期间的垂直云剖面的可用性提高了六个数量级以上，此外，IceCloudNet能够生成DARDARDAR基础上最近结束的卫星任务寿命之外的垂直云轮廓。 et.al.|[2410.04135](http://arxiv.org/abs/2410.04135)|**[link](https://github.com/tabularaza27/ice_cloud_net)**|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-09**|**Simulating realistic self-interacting dark matter models including small and large-angle scattering**|暗物质（DM）自相互作用改变了星系尺度上的物质分布，并缓解了观测的紧张局势。自相互作用截面的一个特征是它的角度依赖性，影响合并星系团中星系和DM晕之间的偏移。虽然存在用于建模主要是前向主导或主要是大角度散射的算法，但在N $体模拟中结合现实的角度依赖关系（如光介质模型）仍然具有挑战性。我们开发、验证和应用了一种新颖有效的方法，结合现有的方法在混合方案中描述小角度和大角度散射机制。在临界角以下，使用通过阻力与横向动量扩散相结合的有效描述，而在角度依赖性以上，则明确采样。首先，我们使用具有已知解析解的测试装置验证该方案，并检查我们的结果在预期范围内对临界角的选择不敏感。接下来，我们证明了我们的方案将现实光介质模型的计算速度提高了多个数量级。最后，我们将该方法应用于星系团合并，并讨论了星系和DM之间的偏移对横截面角度依赖性的敏感性。我们的方案确保了介质质量[m\phi$和DM质量[m\chi$在$0.1v/c\lesssim-m\phi/m\chi\lesssim v/c$范围内的精确偏移，而对于较大（较小）的质量比，则接近各向同性（前向主导）自散射的偏移。这里的$v$是典型的速度标度。等效地，对于总截面和动量传递截面的比率，上限条件可以表示为$1.1\lesssim\sigma_{\rm tot}/\sigma_{\mathrm{\widetilde{T}}}\lesssim 10$，在各向同性（正向主导）极限下，该比率为$1$（$\infty$ ）。 et.al.|[2410.07175](http://arxiv.org/abs/2410.07175)|null|
|**2024-10-09**|**IterComp: Iterative Composition-Aware Feedback Learning from Model Gallery for Text-to-Image Generation**|RPG、Stable diffusion 3和FLUX等先进的扩散模型在合成文本到图像的生成方面取得了显著进展。然而，这些方法通常在组合生成方面表现出明显的优势，其中一些在处理属性绑定方面表现出色，另一些在空间关系方面表现出色。这种差异凸显了对一种方法的需求，这种方法可以利用各种模型的互补优势来全面提高合成能力。为此，我们引入了IterComp，这是一个新的框架，它聚合了来自多个模型的组合感知模型偏好，并采用迭代反馈学习方法来增强组合生成。具体来说，我们策划了一个包含六个强大的开源扩散模型的画廊，并评估了它们的三个关键组成指标：属性绑定、空间关系和非空间关系。基于这些指标，我们开发了一个由众多图像排名对组成的构图感知模型偏好数据集，用于训练构图感知奖励模型。然后，我们提出了一种迭代反馈学习方法，以闭环方式增强组合性，使基础扩散模型和奖励模型能够在多次迭代中逐步自我细化。理论证明了该方法的有效性，广泛的实验表明，我们比之前的SOTA方法（如Omost和FLUX）具有显著的优势，特别是在多类别对象组合和复杂语义对齐方面。IterComp为扩散模型和成分生成的奖励反馈学习开辟了新的研究途径。代码：https://github.com/YangLing0818/IterComp et.al.|[2410.07171](http://arxiv.org/abs/2410.07171)|**[link](https://github.com/yangling0818/itercomp)**|
|**2024-10-09**|**AvatarGO: Zero-shot 4D Human-Object Interaction Generation and Animation**|扩散模型的最新进展导致了4D全身人体-物体交互（HOI）的生成和动画的显著改进。然而，现有的方法主要集中在基于SMPL的运动生成上，这受到现实大规模交互数据稀缺的限制。此约束会影响他们创建日常HOI场景的能力。本文使用具有预先训练的扩散模型的零样本方法来解决这一挑战。尽管有这种潜力，但由于扩散模型缺乏对物体与人体“在哪里”和“如何”相互作用的理解，实现我们的目标是困难的。为了解决这些问题，我们引入了AvatarGO，这是一个新颖的框架，旨在直接从文本输入生成可动画化的4D HOI场景。具体来说，1）对于“在哪里”的挑战，我们提出了LLM引导的联系人重定向，该重定向利用Lang SAM从文本提示中识别联系人身体部位，确保精确表示人与物体的空间关系。2） 对于“如何”的挑战，我们引入了对应感知运动优化，该优化使用SMPL-X的线性混合蒙皮函数为人类和对象模型构建运动场。我们的框架不仅生成连贯的合成运动，而且在处理穿透问题方面表现出更大的鲁棒性。对现有方法的广泛实验验证了AvatarGO在各种人体对象对和不同姿势上的卓越生成和动画能力。作为第一次尝试合成具有对象交互的4D化身，我们希望AvatarGO能够为以人为中心的4D内容创作打开新的大门。 et.al.|[2410.07164](http://arxiv.org/abs/2410.07164)|null|
|**2024-10-09**|**InstructG2I: Synthesizing Images from Multimodal Attributed Graphs**|在这篇论文中，我们研究了一个被忽视但至关重要的任务Graph2Image：从多模态属性图（MMAG）生成图像。由于图大小的爆炸式增长、图实体之间的依赖关系以及对图条件可控性的需求，这项任务带来了重大挑战。为了应对这些挑战，我们提出了一种名为InstructG2I的图上下文条件扩散模型。InstructG2I首先利用图结构和多模态信息，通过结合基于视觉语言特征的个性化页面排名和重新排名，进行信息邻居采样。然后，Graph QFormer编码器将图节点自适应地编码为一组辅助的图提示，以指导扩散的去噪过程。最后，我们提出了无图分类器的引导，通过改变图引导的强度和节点的多个连接边来实现可控生成。在来自不同领域的三个数据集上进行的广泛实验证明了我们方法的有效性和可控性。该代码可在以下网址获得https://github.com/PeterGriffinJin/InstructG2I. et.al.|[2410.07157](http://arxiv.org/abs/2410.07157)|null|
|**2024-10-09**|**Trans4D: Realistic Geometry-Aware Transition for Compositional Text-to-4D Synthesis**|扩散模型的最新进展证明了其在图像和视频生成方面的卓越能力，进一步提高了4D合成的有效性。现有的4D生成方法可以根据用户友好的条件生成高质量的4D对象或场景，使游戏和视频行业受益。然而，这些方法很难合成场景中复杂4D过渡和交互的显著对象变形。为了应对这一挑战，我们提出了Trans4D，这是一种新颖的文本到4D合成框架，可以实现逼真的复杂场景过渡。具体来说，我们首先使用多模态大型语言模型（MLLM）来生成物理感知场景描述，用于4D场景初始化和有效的过渡时间规划。然后，我们提出了一种几何感知的4D过渡网络，以实现基于该计划的复杂场景级4D过渡，其中涉及富有表现力的几何对象变形。大量实验表明，Trans4D在生成具有准确和高质量过渡的4D场景方面始终优于现有的最先进方法，验证了其有效性。代码：https://github.com/YangLing0818/Trans4D et.al.|[2410.07155](http://arxiv.org/abs/2410.07155)|**[link](https://github.com/yangling0818/trans4d)**|
|**2024-10-09**|**Measuring Minority Carrier Diffusion Length Using High-Injection Scanning Photocurrent Microscopy**|扫描光电流显微镜（SPCM）已被广泛用于表征电荷输运特性，特别是半导体的少数载流子扩散长度。然而，使用SPCM研究轻掺杂或本征半导体仍然具有挑战性。先前工作中使用的方法需要低水平的光注入，这在载流子浓度较低的半导体中不容易实现。在这项工作中，我们使用有限元模拟表明，在高光激发下，少数扩散长度也可以量化。该方法不仅适用于掺杂半导体和本征半导体，还解除了在测试设备中实现肖特基接触的限制——这是之前研究中假设的必要条件。这些结果显著扩展了SPCM在研究广谱半导体材料方面的通用性，在实验条件下具有前所未有的灵活性。 et.al.|[2410.07089](http://arxiv.org/abs/2410.07089)|null|
|**2024-10-09**|**FlowBotHD: History-Aware Diffuser Handling Ambiguities in Articulated Objects Manipulation**|我们介绍了一种新的方法来操纵具有模糊性的铰接对象，例如打开一扇门，在这种方法中，多模态和遮挡会产生关于打开侧和方向的模糊性。当打开完全关闭的门的方法（推、拉、滑动）不确定，或者应该打开的一侧不确定时，就会发生多模态。遮挡从某些角度进一步模糊了门的形状，在遮挡过程中造成了进一步的模糊。为了应对这些挑战，我们提出了一种历史感知扩散网络，该网络对关节对象的多模态分布进行建模，并使用历史来消除动作歧义，并在遮挡下做出稳定的预测。实验和分析证明了我们的方法的最新性能，特别是对模糊引起的故障模式的改进。我们的项目网站可在https://flowbothd.github.io/. et.al.|[2410.07078](http://arxiv.org/abs/2410.07078)|null|
|**2024-10-09**|**A short proof of diffusivity for the directed polymers in the weak disorder phase**|我们提供了一个新的简短而基本的证据，证明了在弱无序相中，定向聚合物在随机环境中的扩散率。 et.al.|[2410.07068](http://arxiv.org/abs/2410.07068)|null|
|**2024-10-09**|**Active fluids form system-spanning filamentary networks**|活性液晶液-液相分离的最新实验实现为软物质和生物中普遍存在的相分离与混沌活性流之间的相互作用提供了见解。在这封信中，我们使用连续体理论来研究有源液晶和无源流体的相分离，并报告了两个新的结果。首先，我们对共存区相边界的活性诱导抑制进行了分析推导，这是模拟和实验中首次报道的结果。我们表明，临界点的移动是自搅拌主动流和相分离扩散通量之间平衡的结果。其次，我们表明，这种平衡是导致相分离状态形态发生巨大变化的原因，从而产生了一种新的混合活性相，该混合活性相由一个动态的丝状活性网络组成，该网络侵入整个系统区域，捕获被动材料的液滴。即使活性材料的体积分数非常低，这种结构也存在。我们的工作为理解如何将活动用作雕刻界面的新手柄这一目标迈出了重要的一步。 et.al.|[2410.07058](http://arxiv.org/abs/2410.07058)|null|
|**2024-10-09**|**Transients by Black Hole Formation from Red Supergiants: Impact of Dense Circumstellar Matter**|失败的超新星（SNe）可能是形成恒星质量黑洞的主要通道，预计伴随着比典型的核心坍缩SNe弱得多的质量喷射。我们进行了一系列一维辐射流体动力学模拟，以探索红超巨星祖先失败的SNe的发射，利用最近对这些恒星周围的弱爆炸和致密星周物质（CSM）的理解。我们从这些模拟和半解析建模中发现，CSM中的扩散延长了由冲击爆发/冷却驱动的早期发射。早期发射在光学和紫外波段的峰值亮度为10^7 $-10^8~L_odot$ ，持续时间为几天至几周。密集CSM的存在有助于通过鲁宾天文台、ULTRASAT和UVEX等近期广域调查来检测这些事件的早期亮峰。 et.al.|[2410.07055](http://arxiv.org/abs/2410.07055)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-07**|**Fast Training of Sinusoidal Neural Fields via Scaling Initialization**|神经场是一种新兴的范式，它将数据表示为由神经网络参数化的连续函数。尽管有许多优点，但神经场通常具有较高的训练成本，这阻碍了更广泛的采用。在本文中，我们关注一个流行的神经场家族，称为正弦神经场（SNF），并研究如何初始化它以最大限度地提高训练速度。我们发现，基于信号传播原理设计的SNF标准初始化方案是次优的。特别是，我们证明，通过简单地将每个权重（最后一层除外）乘以一个常数，我们可以将SNF训练加速10 $\times$。这种方法被称为$\textit{weight scaling}$ ，在各种数据域上持续提供显著的加速，使SNF的训练速度比最近提出的架构更快。为了理解为什么权重缩放效果良好，我们进行了广泛的理论和实证分析，结果表明，权重缩放不仅有效地解决了频谱偏差，而且具有良好的优化轨迹。 et.al.|[2410.04779](http://arxiv.org/abs/2410.04779)|null|
|**2024-10-04**|**End-to-End Reaction Field Energy Modeling via Deep Learning based Voxel-to-voxel Transform**|在计算生物化学和生物物理学中，理解静电相互作用的作用对于阐明生物分子的结构、动力学和功能至关重要。泊松-玻尔兹曼（PB）方程是通过描述带电分子内部和周围的静电势来模拟这些相互作用的基础工具。然而，由于生物分子表面的复杂性和需要考虑可移动离子，求解PB方程带来了重大的计算挑战。虽然求解PB方程的传统数值方法是准确的，但它们的计算成本很高，并且随着系统规模的增加而扩展性较差。为了应对这些挑战，我们引入了PBNeF，这是一种新的机器学习方法，灵感来自基于神经网络的偏微分方程求解器的最新进展。我们的方法将PB方程的输入和边界静电条件转化为可学习的体素表示，使神经场变换器能够预测PB解，进而预测反应场势能。大量实验表明，与传统的PB求解器相比，PBNeF的速度提高了100倍以上，同时保持了与广义玻恩（GB）模型相当的精度。 et.al.|[2410.03927](http://arxiv.org/abs/2410.03927)|null|
|**2024-10-08**|**DressRecon: Freeform 4D Human Reconstruction from Monocular Video**|我们提出了一种从单目视频中重建时间一致的人体模型的方法，重点是极其宽松的衣服或手持物体的交互。之前在人体重建方面的工作要么局限于没有物体交互的紧身衣服，要么需要校准的多视图捕捉或个性化的模板扫描，而大规模收集这些数据成本很高。我们对高质量但灵活的重建的关键见解是，将关于关节体形状的通用人类先验（从大规模训练数据中学习）与视频特定的关节“骨骼袋”变形（通过测试时间优化适合单个视频）仔细结合。我们通过学习一个神经隐式模型来实现这一点，该模型将身体和衣服的变形作为单独的运动模型层来解开。为了捕捉服装的微妙几何形状，我们在优化过程中利用了基于图像的先验，如人体姿势、表面法线和光流。由此产生的神经场可以提取到时间一致的网格中，或进一步优化为显式3D高斯分布，以实现高保真交互式渲染。在具有高度挑战性的服装变形和物体交互的数据集上，DressReston可以产生比现有技术更高保真的3D重建。项目页面：https://jefftan969.github.io/dressrecon/ et.al.|[2409.20563](http://arxiv.org/abs/2409.20563)|null|
|**2024-09-25**|**TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans**|我们介绍了一种新的框架，该框架从单眼视频中学习全身说话的人的动态神经辐射场（NeRF）。之前的工作只代表身体姿势或面部。然而，人类通过全身进行交流，结合身体姿势、手势和面部表情。在这项工作中，我们提出了TalkinNeRF，这是一个基于NeRF的统一网络，代表了整体4D人体运动。给定一个受试者的单眼视频，我们学习身体、面部和手的相应模块，这些模块结合在一起生成最终结果。为了捕捉复杂的手指关节，我们学习了手的额外变形场。我们的多身份表示能够同时训练多个科目，以及在完全看不见的姿势下进行强大的动画。只要输入一段短视频，它也可以推广到新的身份。我们展示了最先进的性能，用于为全身说话的人类制作动画，具有精细的手部发音和面部表情。 et.al.|[2409.16666](http://arxiv.org/abs/2409.16666)|null|
|**2024-09-24**|**Generative 3D Cardiac Shape Modelling for In-Silico Trials**|我们提出了一种深度学习方法，基于将形状表示为神经有符号距离场的零级集，对合成主动脉形状进行建模和生成，该方法受一系列可训练的嵌入向量的约束，并对每个形状的几何特征进行编码。通过使神经场在采样表面点上消失并强制其空间梯度具有单位范数，在从CT图像重建的主动脉根部网格数据集上训练网络。实证结果表明，我们的模型可以高保真地表示主动脉形状。此外，通过从学习到的嵌入向量中采样，我们可以生成类似于真实患者解剖结构的新形状，可用于计算机模拟试验。 et.al.|[2409.16058](http://arxiv.org/abs/2409.16058)|null|
|**2024-09-21**|**MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors**|由于缺乏几何指导和不完美的视图相关2D先验，从单眼图像中精确重建密集和语义注释的3D网格仍然是一项具有挑战性的任务。尽管我们已经见证了隐式神经场景表示的最新进展，能够简单地从多视图图像中进行精确的2D渲染，但很少有研究仅使用单眼先验来解决3D场景理解问题。在本文中，我们提出了MOSE，这是一种神经场语义重建方法，可以将推断的图像级噪声先验提升到3D，在3D和2D空间中产生精确的语义和几何。我们方法的关键动机是利用通用类不可知的分段掩码作为指导，在训练过程中促进渲染语义的局部一致性。在语义的帮助下，我们进一步将平滑正则化应用于无纹理区域，以获得更好的几何质量，从而实现几何和语义的互惠互利。在ScanNet数据集上的实验表明，我们的MOSE在3D语义分割、2D语义分割和3D表面重建任务的所有指标上都优于相关基线。 et.al.|[2409.14019](http://arxiv.org/abs/2409.14019)|null|
|**2024-09-17**|**SplatFields: Neural Gaussian Splats for Sparse 3D and 4D Reconstruction**|从多视图图像中数字化3D静态场景和4D动态事件长期以来一直是计算机视觉和图形学领域的一个挑战。最近，3D高斯散斑（3DGS）已经成为一种实用且可扩展的重建方法，由于其令人印象深刻的重建质量、实时渲染能力以及与广泛使用的可视化工具的兼容性而越来越受欢迎。然而，该方法需要大量的输入视图来实现高质量的场景重建，这引入了一个重大的实际瓶颈。在捕捉动态场景时，这一挑战尤为严峻，因为部署广泛的相机阵列的成本可能高得令人望而却步。在这项工作中，我们发现斑点特征缺乏空间自相关性是导致3DGS技术在稀疏重建环境中性能不佳的因素之一。为了解决这个问题，我们提出了一种优化策略，通过将splat特征建模为相应隐式神经场的输出，有效地正则化splat特征。这导致在各种场景中重建质量的一致提高。我们的方法有效地处理了静态和动态情况，这在不同设置和场景复杂性的广泛测试中得到了证明。 et.al.|[2409.11211](http://arxiv.org/abs/2409.11211)|null|
|**2024-10-02**|**Neural Fields for Adaptive Photoacoustic Computed Tomography**|光声计算机断层扫描（PACT）是一种具有广泛医学应用的非侵入性成像技术。传统的PACT图像重建算法受到组织中声速不均匀（SOS）引起的波前失真的影响，导致图像质量下降。考虑到这些影响可以提高图像质量，但测量SOS分布的实验成本很高。另一种方法是仅使用PA信号对初始压力图像和SOS进行联合重建。现有的关节重建方法存在局限性：计算成本高，无法直接恢复SOS，以及依赖于不准确的简化假设。隐式神经表示或神经场是计算机视觉中的一种新兴技术，用于通过基于坐标的神经网络学习物理场的有效和连续表示。在这项工作中，我们介绍了NF-APACT，这是一种高效的自监督框架，利用神经场来估计SOS，以实现准确和鲁棒的多通道解卷积。我们的方法比现有方法更快、更准确地消除了SOS像差。我们在一个新的数值体模以及实验收集的体模和体内数据上证明了我们的方法的成功。我们的代码和数字幻影可在https://github.com/Lukeli0425/NF-APACT. et.al.|[2409.10876](http://arxiv.org/abs/2409.10876)|null|
|**2024-09-09**|**Lagrangian Hashing for Compressed Neural Field Representations**|我们提出了拉格朗日散列，这是一种神经场的表示，结合了依赖于欧拉网格（即~InstantNGP）的快速训练NeRF方法的特征，以及使用配备有特征的点作为表示信息的方法（例如3D高斯散点或PointNeRF）。我们通过将基于点的表示合并到InstantNGP表示的分层哈希表的高分辨率层中来实现这一点。由于我们的点具有影响域，我们的表示可以被解释为哈希表中存储的高斯混合。我们提出的损失鼓励我们的高斯人向需要更多代表预算才能充分代表的地区移动。我们的主要发现是，我们的表示允许使用更紧凑的表示来重建信号，而不会影响质量。 et.al.|[2409.05334](http://arxiv.org/abs/2409.05334)|null|
|**2024-09-08**|**Exploring spectropolarimetric inversions using neural fields. Solar chromospheric magnetic field under the weak-field approximation**|全斯托克斯偏振数据集来源于狭缝光谱仪或窄带滤光片图，如今已被常规采集。随着二维光谱偏振仪和允许长时间高质量观测序列的观测技术的出现，数据速率正在增加。在光谱偏振反演中，显然需要通过利用推断物理量的时空相干性来超越传统的逐像素策略。我们探索了神经网络作为时间和空间（也称为神经场）上物理量的连续表示的潜力，用于光谱极化反演。我们已经实现并测试了一个神经场，以在弱场近似（WFA）下执行磁场矢量的推理（也称为物理知情神经网络的方法）。通过使用神经场来描述磁场矢量，我们可以通过假设物理量是坐标的连续函数来在空间和时间域中正则化解。我们研究了Ca II 8542 A谱线的合成和真实观测结果。我们还探讨了其他显式正则化的影响，例如使用外推磁场的信息或色球原纤维的取向。与传统的逐像素反演相比，神经场方法提高了磁场矢量重建的保真度，特别是横向分量。这种隐式正则化是一种提高观测值有效信噪比的方法。虽然它比逐像素WFA估计慢，但这种方法通过减少自由参数的数量并在解决方案中引入时空约束，显示出深度分层反演的巨大潜力。 et.al.|[2409.05156](http://arxiv.org/abs/2409.05156)|**[link](https://github.com/cdiazbas/neural_wfa)**|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

