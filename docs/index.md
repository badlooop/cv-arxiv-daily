---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.08.29
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-08-25**|**ReST: A Reconfigurable Spatial-Temporal Graph Model for Multi-Camera Multi-Object Tracking**|多摄像机多目标跟踪（MC-MOT）利用来自多个视图的信息来更好地处理遮挡和拥挤场景的问题。最近，使用基于图的方法来解决跟踪问题变得非常流行。然而，当前许多基于图的方法不能有效地利用关于空间和时间一致性的信息。相反，它们依赖于单摄像头跟踪器作为输入，这很容易出现碎片和ID切换错误。在本文中，我们提出了一种新的可重构图模型，该模型首先在空间上关联摄像机上所有检测到的对象，然后将其重新配置为用于时间关联的时间图。这种两阶段关联方法使我们能够提取强大的空间和时间感知特征，并解决碎片化轨迹的问题。此外，我们的模型是为在线跟踪而设计的，适用于现实世界中的应用。实验结果表明，所提出的图模型能够提取更多的判别特征用于对象跟踪，并且我们的模型在几个公共数据集上达到了最先进的性能。 et.al.|[2308.13229](http://arxiv.org/abs/2308.13229)|**[link](https://github.com/chengche6230/rest)**|
|**2023-08-24**|**NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes**|最近的隐式神经表示在新的视图合成中显示出了很好的结果。然而，现有的方法需要从许多视图进行昂贵的每场景优化，因此限制了它们在真实世界的无边界城市环境中的应用，在这些环境中，从极少数视图观察到感兴趣的对象或背景。为了缓解这一挑战，我们引入了一种名为NeO360的新方法，用于户外场景稀疏视图合成的神经场。NeO 360是一种可推广的方法，它从单个或几个摆出姿势的RGB图像重建360｛\deg｝场景。我们方法的本质是捕捉复杂的真实世界户外3D场景的分布，并使用可以从任何世界点查询的混合图像条件三平面表示。我们的表示结合了基于体素和鸟瞰图（BEV）的最佳表示，比每种表示都更有效、更具表现力。NeO 360的表示使我们能够从大量无界3D场景中学习，同时在推理过程中从一张图像中提供对新视图和新场景的可推广性。我们在所提出的具有挑战性的360｛\deg｝无界数据集NeRDS 360上演示了我们的方法，并表明NeO 360在新视图合成方面优于最先进的可推广方法，同时还提供编辑和合成功能。项目页面：https://zubair-irshad.github.io/projects/neo360.html et.al.|[2308.12967](http://arxiv.org/abs/2308.12967)|null|
|**2023-08-24**|**Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis**|静息状态功能性MRI（rs-fMRI）越来越多地用于多部位研究，以帮助神经系统疾病分析。现有研究通常存在由站点效应（如扫描仪/协议的差异）引起的显著跨站点/领域数据异质性。已经提出了许多方法来减少源域和目标域之间的fMRI异质性，这在很大程度上依赖于源数据的可用性。但是，由于多站点研究中的隐私问题和/或数据存储负担，获取源数据具有挑战性。为此，我们设计了一个用于fMRI分析的无源协作域自适应（SCDA）框架，其中只有预训练的源模型和未标记的目标数据是可访问的。具体而言，开发了一种用于目标fMRI分析的多视角特征富集方法（MFE），该方法由多个协作分支组成，用于从多个视图动态捕获未标记目标数据的fMRI特征。每个分支都有一个数据馈送模块、一个时空特征编码器和一个类预测器。设计了相互一致性约束，以鼓励从这些分支生成的相同输入的潜在特征的成对一致性，用于鲁棒表示学习。为了在没有源数据的情况下促进有效的跨领域知识转移，我们使用预训练的源模型的参数初始化MFE。我们还介绍了一种无监督预训练策略，使用来自三个大型辅助数据库的3806个未标记的fMRI，旨在获得通用特征编码器。在三个公共数据集和一个私人数据集上的实验结果证明了我们的方法在交叉扫描和交叉研究预测任务中的有效性。在大规模rs fMRI数据上预训练的模型已经向公众发布。 et.al.|[2308.12495](http://arxiv.org/abs/2308.12495)|**[link](https://github.com/yqfang9199/scda)**|
|**2023-08-23**|**ARF-Plus: Controlling Perceptual Factors in Artistic Radiance Fields for 3D Scene Stylization**|辐射场风格转移是一个新兴的领域，由于神经辐射场在三维重建和视图合成中的出色表现，作为三维场景风格化的一种手段，它最近受到了欢迎。我们强调了在辐射场风格转移方面的研究空白，即缺乏足够的感知可控性，这是由2D图像风格转移中的现有概念所驱动的。在本文中，我们提出了ARF Plus，一个对感知因素提供可管理控制的3D神经风格转移框架，以系统地探索3D场景风格化中的感知可控性。提出了四种不同类型的控制——颜色保持控制、（风格模式）比例控制、空间（选择性风格化区域）控制和深度增强控制——并将其集成到该框架中。来自真实世界数据集的定量和定性结果表明，在对3D场景进行风格化时，我们的ARF Plus框架中的四种类型的控件成功地实现了相应的感知控件。这些技术适用于单个样式输入以及场景中多个样式的同时应用。这开启了一个无限可能性的领域，允许对风格化效果进行定制修改，并灵活融合不同风格的优势，最终能够在3D场景中创造新颖而引人注目的风格效果。 et.al.|[2308.12452](http://arxiv.org/abs/2308.12452)|null|
|**2023-08-24**|**A Visualization System for Hexahedral Mesh Quality Study**|在本文中，我们介绍了一种新的三维十六进制网格视觉分析系统，该系统通过聚合字形强调质量较差的区域，突出重叠元素，并以三种形式提供详细的边界误差检查。通过支持多视图的多级分析，我们的系统有效地评估了各种网格模型，并比较了六面体网格的网格生成和优化算法的性能。 et.al.|[2308.12158](http://arxiv.org/abs/2308.12158)|null|
|**2023-08-22**|**Enhancing NeRF akin to Enhancing LLMs: Generalizable NeRF Transformer with Mixture-of-View-Experts**|跨场景可推广的NeRF模型可以直接合成看不见场景的新视图，已成为NeRF领域的一个新焦点。现有的几种尝试依赖于越来越端到端的“神经化”架构，即用变压器等高性能神经网络取代场景表示和/或渲染模块，并将新颖的视图合成转化为前馈推理管道。虽然这些前馈“神经化”架构仍然不能很好地开箱即用地适应不同的场景，但我们建议将它们与来自大型语言模型（LLM）的强大的专家混合（MoE）思想联系起来，该思想通过在更大的整体模型容量和灵活的每实例专业化之间进行平衡，展示了卓越的泛化能力。从最近一种名为GNT的可推广NeRF架构开始，我们首先证明了MoE可以巧妙地插入以增强模型。我们进一步定制了共享的永久专家和几何体感知的一致性损失，以分别增强跨场景一致性和空间平滑性，这对于可推广的视图合成至关重要。我们提出的模型被称为GNT with Mixture-of-View-Experts（GNT-MOVE），在转移到看不见的场景时，实验显示了最先进的结果，表明在零样本和少拍摄设置中都有更好的跨场景泛化。我们的代码可在https://github.com/VITA-Group/GNT-MOVE. et.al.|[2308.11793](http://arxiv.org/abs/2308.11793)|**[link](https://github.com/vita-group/gnt-move)**|
|**2023-08-22**|**IT3D: Improved Text-to-3D Generation with Explicit View Synthesis**|从强大的大型文本到图像扩散模型（LDM）中提取知识，推动了文本到3D技术的最新进展。尽管如此，现有的文本到3D方法经常会遇到诸如过度饱和、细节不足和不切实际的输出等挑战。这项研究提出了一种新的策略，利用显式合成的多视图图像来解决这些问题。我们的方法涉及利用LDM授权的图像到图像管道，以基于粗略3D模型的渲染生成高质量的图像。尽管生成的图像在很大程度上缓解了上述问题，但由于大扩散模型固有的生成性质，诸如视图不一致和显著的内容差异等挑战仍然存在，这给有效利用这些图像带来了巨大的困难。为了克服这一障碍，我们主张将鉴别器与新的扩散GAN双重训练策略相结合，以指导3D模型的训练。对于合并的鉴别器，合成的多视图图像被视为真实数据，而优化的3D模型的渲染则充当假数据。我们进行了一系列全面的实验，证明了我们的方法相对于基线方法的有效性。 et.al.|[2308.11473](http://arxiv.org/abs/2308.11473)|**[link](https://github.com/buaacyw/it3d-text-to-3d)**|
|**2023-08-22**|**ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes**|我们展示了ScanNet++，这是一个大规模的数据集，将室内场景的高质量和商品级几何图形和颜色的捕捉结合在一起。每个场景都是用亚毫米分辨率的高端激光扫描仪拍摄的，还有来自单反相机的3300万像素图像和来自iPhone的RGB-D流。场景重建进一步用开放的语义词汇表进行注释，明确注释标签模糊场景以进行全面的语义理解。ScanNet++为新视图合成提供了一个新的现实世界基准，既有高质量的RGB捕获，也有重要的商品级图像，此外还有一个全面封装多样和模糊语义标记场景的3D语义场景理解新基准。目前，ScanNet++包含460个场景、28万张单反图像和370多万个iPhone RGBD帧。 et.al.|[2308.11417](http://arxiv.org/abs/2308.11417)|null|
|**2023-08-22**|**Enhancing Interpretable Object Abstraction via Clustering-based Slot Initialization**|使用槽的以对象为中心的表示显示了从合成场景中的低级感知特征向高效、灵活和可解释的抽象的发展。当前的方法随机化时隙的初始状态，然后进行迭代细化。正如我们在本文中所展示的，随机时隙初始化显著影响最终时隙预测的准确性。此外，当前的方法需要来自数据的先验知识的预定数量的时隙，这限制了在现实世界中的适用性。在我们的工作中，我们使用以感知输入特征为条件的聚类算法来初始化槽表示。这需要体系结构中的一个附加层来初始化给定已识别集群的插槽。我们设计了该层的置换不变和置换等变版本，以实现聚类后的可交换槽表示。此外，我们使用均值偏移聚类来自动识别给定场景的槽数。我们评估了我们在各种数据集的对象发现和新视图合成任务上的方法。结果表明，我们的方法始终优于先前的工作，尤其是在复杂场景下。 et.al.|[2308.11369](http://arxiv.org/abs/2308.11369)|null|
|**2023-08-22**|**Novel-view Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views**|在沉浸式通信中，手与物体的交互理解和几乎没有解决的新颖视角合成是非常需要的，而由于手的高度变形和手与物体之间的严重遮挡，这是具有挑战性的。在本文中，我们提出了一种用于稀疏视图中手-物体交互的神经渲染和姿态估计系统，该系统还可以实现3D手-物体的交互编辑。我们分享了最近场景理解工作的灵感，该工作表明，预先建立的特定场景模型可以显著改善和解锁视觉任务，尤其是在输入稀疏的情况下，并将其扩展到动态手-物交互场景中，并提出分两个阶段解决问题。我们首先在离线阶段使用神经表示分别学习手和物体的形状和外观先验知识。在在线阶段，我们设计了一个基于渲染的联合模型拟合框架，以了解手与对象的动态交互与预先构建的手与对象模型以及交互先验，从而克服了手与对象之间的渗透和分离问题，并实现了新的视图合成。为了在一个序列中的手-物体交互过程中获得稳定的接触，我们提出了一个稳定的接触损失，以使接触区域一致。实验表明，我们的方法优于最先进的方法。项目网页中提供了代码和数据集https://iscas3dv.github.io/HO-NeRF. et.al.|[2308.11198](http://arxiv.org/abs/2308.11198)|null|

## 3D Reconstruction

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-08-23**|**ARF-Plus: Controlling Perceptual Factors in Artistic Radiance Fields for 3D Scene Stylization**|辐射场风格转移是一个新兴的领域，由于神经辐射场在三维重建和视图合成中的出色表现，作为三维场景风格化的一种手段，它最近受到了欢迎。我们强调了在辐射场风格转移方面的研究空白，即缺乏足够的感知可控性，这是由2D图像风格转移中的现有概念所驱动的。在本文中，我们提出了ARF Plus，一个对感知因素提供可管理控制的3D神经风格转移框架，以系统地探索3D场景风格化中的感知可控性。提出了四种不同类型的控制——颜色保持控制、（风格模式）比例控制、空间（选择性风格化区域）控制和深度增强控制——并将其集成到该框架中。来自真实世界数据集的定量和定性结果表明，在对3D场景进行风格化时，我们的ARF Plus框架中的四种类型的控件成功地实现了相应的感知控件。这些技术适用于单个样式输入以及场景中多个样式的同时应用。这开启了一个无限可能性的领域，允许对风格化效果进行定制修改，并灵活融合不同风格的优势，最终能够在3D场景中创造新颖而引人注目的风格效果。 et.al.|[2308.12452](http://arxiv.org/abs/2308.12452)|null|
|**2023-08-21**|**Coordinate Quantized Neural Implicit Representations for Multi-view Reconstruction**|近年来，在从多视图图像中学习用于三维重建的神经隐式表示方面取得了巨大进展。作为补充坐标的额外输入，使用正弦函数作为位置编码在利用基于坐标的神经网络揭示高频细节方面发挥着关键作用。然而，高频位置编码使优化不稳定，这导致了有噪声的重建和空空间中的伪影。为了在一般意义上解决这个问题，我们引入了学习具有量化坐标的神经隐式表示，这减少了优化过程中该领域的不确定性和模糊性。代替连续坐标，我们使用量化坐标之间的最近插值将连续坐标离散为离散坐标，这些量化坐标是通过以极高分辨率离散场而获得的。我们使用离散坐标及其位置编码来通过体积渲染学习隐式函数。这显著减少了采样空间中的变化，并对来自不同视图的光线的交点触发了更多的多视图一致性约束，从而能够以更有效的方式推断隐式函数。我们的量化坐标不会带来任何计算负担，并且可以无缝地使用最新的方法。我们根据广泛使用的基准进行的评估表明，我们优于最先进的基准。我们的代码可在https://github.com/MachinePerceptionLab/CQ-NIR. et.al.|[2308.11025](http://arxiv.org/abs/2308.11025)|**[link](https://github.com/machineperceptionlab/cq-nir)**|
|**2023-08-19**|**Root Pose Decomposition Towards Generic Non-rigid 3D Reconstruction with Monocular Videos**|这项工作专注于基于单目RGB视频序列的非刚性物体的3D重建。具体来说，我们的目标是为通用对象类别和随意捕捉的场景构建高保真度模型。为此，我们不假设对象的已知根姿势，也不使用特定类别的模板或密集姿势先验。我们的根姿势分解（RPD）方法的关键思想是保持每帧根姿势变换，同时通过局部变换建立密集场来校正根姿势。局部变换的优化是通过对规范空间的点配准来执行的。我们还将RPD应用于具有对象遮挡和个体差异的多对象场景。因此，RPD允许对包含具有大变形、复杂运动模式、遮挡和不同个体的尺度多样性的对象的复杂场景进行非刚性3D重建。这样的管道可能会扩展到野外的各种物体。我们的实验表明，RPD在具有挑战性的DAVIS、OVIS和AMA数据集上超越了最先进的方法。 et.al.|[2308.10089](http://arxiv.org/abs/2308.10089)|null|
|**2023-08-19**|**TSAR-MVS: Textureless-aware Segmentation and Correlative Refinement Guided Multi-View Stereo**|由于图像之间缺乏可靠的像素对应关系，无纹理区域的重建长期以来一直是MVS中具有挑战性的问题。在本文中，我们提出了无纹理感知分割和相关细化引导的多视图立体（TSAR-MVS），这是一种通过滤波、细化和分割有效解决三维重建中无纹理区域带来的挑战的新方法。首先，我们实现了联合假设滤波，这是一种将置信度估计器与视差不连续检测器相结合的技术，以消除不正确的深度估计。其次，为了以置信深度扩展像素，我们引入了一种迭代相关细化策略，该策略利用RANSAC生成超像素，然后是中值滤波器，以扩大准确确定的像素的影响。最后，我们提出了一种无纹理感知分割方法，该方法利用边缘检测和线检测来准确识别要使用3D平面拟合的大的无纹理区域。在大量数据集上的实验表明，我们的方法显著优于大多数非学习方法，并且在保留精细细节的同时，对无纹理区域表现出鲁棒性。 et.al.|[2308.09990](http://arxiv.org/abs/2308.09990)|null|
|**2023-08-19**|**A Theory of Topological Derivatives for Inverse Rendering of Geometry**|我们介绍了一个可微曲面演化的理论框架，该框架允许通过使用拓扑导数对图像泛函进行变分优化来实现离散拓扑变化。虽然先前的几何体反向渲染方法依赖于拓扑变化的轮廓梯度，但这种信号是稀疏的。相反，我们的理论推导了拓扑导数，这些导数将消失空穴和相位的引入与图像强度的变化联系起来。因此，我们能够以空穴或相成核的形式实现可微分的形状扰动。我们通过优化2D中的闭合曲线和3D中的曲面来验证所提出的理论，以深入了解当前方法的局限性，并实现改进的应用，如图像矢量化、从文本提示生成矢量图形、形状模糊图的单图像重建和多视图3D重建。 et.al.|[2308.09865](http://arxiv.org/abs/2308.09865)|null|
|**2023-08-18**|**On the three-dimensional relation between the coronal dimming, erupting filament and CME. Case study of the 28 October 2021 X1.0 event**|我们研究了太阳轨道飞行器、STEREO-A、SDO和SOHO从多个角度观测到的2021年10月28日X1.0耀斑/CME事件中，变暗区域的时空演化与细丝喷发和CME传播的主导方向之间的关系。我们提出了一种通过跟踪其面积演变来估计主调光方向的方法，并通过计算每个像素的球体表面积来强调其精确估计。为了确定早期通量绳的传播方向，我们通过分级圆柱壳建模（GCS）和细丝的连接点对CME进行了三维重建。调光最初呈放射状扩展，后来向东南移动。喷发细丝在太阳表面上重建的高度演化的正交投影位于主要变暗增长的扇区中，而GCS重建的内部的正交投影与总变暗区域对齐。灯丝在约180 Mm的高度达到约250 km/s的最大速度。其运动方向从径向强烈倾斜（向东64 $^\circ$，向南32$^\icrc$）。CME和细丝腿之间在3D方向上的50$^\circ$ 差异与重建确定的CME半宽度密切对应，这表明重建的细丝与CME体的相关腿之间存在潜在关系。我们的发现强调，变暗增长的主导传播反映了太阳大气中喷发磁结构（细丝）的方向，尽管细丝的演化与全球CME膨胀的方向没有直接关系。整体变暗形态与CME重建的内部非常相似，验证了使用变暗观测来深入了解CME方向。 et.al.|[2308.09815](http://arxiv.org/abs/2308.09815)|null|
|**2023-08-18**|**A deep learning approach for the 3D reconstruction of dust density and temperature in star-forming regions**|目的：我们介绍了一种新的深度学习方法，用于从单个恒星形成云核心（<0.2pc）的多波长尘埃发射观测中重建三维尘埃密度和温度分布。方法：我们通过使用POLARIS辐射传输代码处理云工厂模拟的云芯来构建训练数据集，以产生12至1300 $\mu$m之间23个波长的合成尘埃发射观测值。我们通过沿着单个视线重建云结构来简化任务，并为此目的训练条件可逆神经网络（cNN）。cNN属于归一化流方法组，能够预测目标灰尘特性的完全后验分布。我们测试了不同的cNN设置，从包括所有23个波长的场景到仅在7个波长进行观测的更现实的有限情况。我们在综合测试数据上评估了这些模型的预测性能。结果：我们报道了23个波长的cNN模型的良好重建性能，在$\log（n_{dust}/m^{-3}）$中实现了约1.8%的中值绝对相对误差，在$\log（T_{dust}/K）$中获得了约1%的中值绝对绝对相对误差。我们确定了在密度范围的低端高估和在密度和温度的高端低估的趋势，这可能与训练数据中的偏差有关。将覆盖范围限制为仅七个波长的组合，我们仍然发现令人满意的性能，在$\log（n_{dust}/m^{-3}）$和$\lod（T_{dust}/K）$ 中的平均绝对相对误差约为3.3%和2.5%。结论：这项概念验证研究表明，在现实的观测约束下，基于cNN的灰尘密度和温度三维重建方法非常有前景，甚至是可行的。 et.al.|[2308.09657](http://arxiv.org/abs/2308.09657)|null|
|**2023-08-18**|**O^2-Recon: Completing 3D Reconstruction of Occluded Objects in the Scene with a Pre-trained 2D Diffusion Model**|遮挡是RGB-D视频三维重建中的一个常见问题，通常会阻碍对象的完整重建，并带来持续的问题。在本文中，我们提出了一种新的框架，通过基于2D扩散的绘画模型来重建物体隐藏部分的完整表面。具体来说，我们利用预先训练的扩散模型来填充2D图像的隐藏区域。然后，我们在绘制的图像中使用这些来优化用于3D重建的每个实例的神经隐式表面表示。由于制作这一过程所需的彩绘面具很棘手，我们采用了一种“人在环”的策略，只需要很少的人参与就可以制作出高质量的面具。此外，物体的某些部分可能被完全隐藏，因为视频通常是从有限的视角拍摄的。为了确保恢复这些不可见区域，我们开发了一种级联网络架构，用于预测有符号距离场，利用位置编码的不同频带并保持整体平滑。除了常用的渲染损失、Eikonal损失和轮廓损失外，我们还采用了基于CLIP的语义一致性损失来从看不见的相机角度引导曲面。在ScanNet场景上的实验表明，我们提出的框架在场景级RGB-D视频的对象级重建中实现了最先进的准确性和完整性。 et.al.|[2308.09591](http://arxiv.org/abs/2308.09591)|null|
|**2023-08-18**|**DMCVR: Morphology-Guided Diffusion Model for 3D Cardiac Volume Reconstruction**|通过电影磁共振成像（cMRI）进行精确的3D心脏重建对于改善心血管疾病诊断和了解心脏运动至关重要。然而，目前在临床环境中使用的基于心脏MRI的重建技术是2D的，通过平面的分辨率有限，导致重建的心脏体积质量低。为了从稀疏的2D图像堆栈中更好地重建3D心脏体积，我们提出了一种用于3D心脏体积重建的形态学引导扩散模型DMCVR，该模型综合了高分辨率2D图像和相应的3D重建体积。我们的方法优于以前的方法，因为它将心脏形态限制在生成模型上，消除了潜在代码耗时的迭代优化过程，并提高了生成质量。所学习的潜在空间为重建3D心脏形状提供了具有高度可解释价值的每个2D cMRI切片的全局语义、局部心脏形态和细节。我们的实验表明，DMCVR在二维生成和三维重建性能等方面都非常有效。有了DMCVR，我们可以制作高分辨率的3D心脏MRI重建，超越了目前的技术。我们提出的框架在提高心脏病诊断和治疗计划的准确性方面具有巨大潜力。代码可访问https://github.com/hexiaoxiao-cs/DMCVR. et.al.|[2308.09223](http://arxiv.org/abs/2308.09223)|**[link](https://github.com/hexiaoxiao-cs/dmcvr)**|
|**2023-08-17**|**A Fusion of Variational Distribution Priors and Saliency Map Replay for Continual 3D Reconstruction**|单图像三维重建是一项研究挑战，重点是从单视图图像中预测三维物体形状。这项任务需要大量的数据采集来预测形状的可见部分和遮挡部分。此外，基于学习的方法面临着为所有可能的类创建综合训练数据集的困难。为此，我们提出了一种基于连续学习的3D重建方法，其中我们的目标是使用变分先验设计一个模型，即使在对新类进行训练后，该模型仍然可以合理地重建以前看到的类。变分先验表示抽象形状和战斗遗忘，而显著性映射则以较少的内存使用来保留对象属性。由于存储大量训练数据的资源限制，这一点至关重要。此外，我们引入了基于显著性地图的体验回放，以捕捉全局和不同的对象特征。与已建立的方法相比，全面的实验在定量和定性方面都显示出有竞争力的结果。 et.al.|[2308.08812](http://arxiv.org/abs/2308.08812)|null|

## Diffusion

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-08-25**|**Cover times of many diffusive or subdiffusive searchers**|覆盖时间衡量穷举搜索的速度，穷举搜索需要探索整个空间区域。应用包括免疫系统狩猎病原体、动物收集食物、机器人排雷或清洁以及计算机搜索算法。从数学上讲，覆盖时间是随机搜索器第一次进入目标区域（通常是整个空间域）中每个点的指定“检测半径”内。由于其广泛的应用及其基本的概率重要性，覆盖时间在物理学和概率文献中得到了广泛的研究。这项先前的工作通常研究了具有消失检测半径或大目标区域的单个搜索器的覆盖时间。这项先前的工作进一步声称，多个搜索者的覆盖时间可以通过简单地重新缩放单个搜索器的覆盖时间来估计。在本文中，我们研究了许多扩散或次扩散搜索者的覆盖时间，并表明先验估计随着搜索者数量的增长而分解。我们证明了在多搜索器极限中这种覆盖时间的所有矩的一个相当普遍的公式，该公式仅取决于（i）搜索器的特征（子）扩散率和（ii）搜索器起始位置和目标中最远点之间的特定测地距离。该公式在其他方面独立于检测半径、空间维度、目标大小和域大小。我们在几个例子中说明了我们的结果，并将其与详细的随机模拟进行了比较。 et.al.|[2308.13417](http://arxiv.org/abs/2308.13417)|null|
|**2023-08-25**|**Separation of interacting active particles in an asymmetric channel**|我们研究了质量为 $m$的相互作用活性粒子（自推进）在不对称通道中的扩散行为。颗粒沿着通道的长度受到外部振荡力的作用。在这种设置中，粒子可能会出现整流。在没有相互作用的情况下，粒子的平均速度$\langle v\rangle$在中等$m$值时显示最大值。这意味着中等大小的粒子比其他粒子具有更高的速度。然而，通过结合粒子之间的短程相互作用，$\langle v\rangle$在较低的$m$ 值处表现出额外的峰值，表明较低和中等m的粒子可以同时与其他粒子分离。此外，通过调节相互作用强度、自推进速度和振荡力的参数，可以选择性地分离较低的百万美元、中等的百万美元或两者的颗粒。讨论了作为这些参数的函数估计最佳质量的经验关系。这些发现有利于将选择性的百万美元颗粒从其余颗粒中分离出来。 et.al.|[2308.13390](http://arxiv.org/abs/2308.13390)|null|
|**2023-08-25**|**Distribution-Aligned Diffusion for Human Mesh Recovery**|从单个RGB图像中恢复3D人体网格是一项具有挑战性的任务，因为深度模糊和自遮挡会导致高度的不确定性。同时，扩散模型最近在通过逐步去噪噪声输入来生成高质量输出方面取得了很大成功。受其能力的启发，我们探索了一种基于扩散的人体网格恢复方法，并提出了一种人体网格扩散（HMDiff）框架，该框架将网格恢复框定为反向扩散过程。我们还提出了一种分布对齐技术（DAT），该技术将特定于输入的分布信息注入到扩散过程中，并提供有用的先验知识来简化网格恢复任务。我们的方法在三个广泛使用的数据集上实现了最先进的性能。项目页面：https://gongjia0208.github.io/HMDiff/. et.al.|[2308.13369](http://arxiv.org/abs/2308.13369)|null|
|**2023-08-25**|**Is the topological surface state floating on top of a thick lead layer? The case of the Pb/Bi2Se3 interface**|关于拓扑表面态在厚Pb层顶部浮动的令人困惑的问题，现在可能已经得到了答案。在不同的温度和吸附质覆盖条件下，对Pb在Bi2Se3上形成的界面进行了研究，使我们能够证明文献中报道的证据可能与Pb原子表现出的表面扩散现象有关，这使得基底部分未被覆盖。综合密度泛函理论计算表明，尽管原子在界面上有特定的排列，但拓扑表面状态不能漂浮在adlayer的顶部，而是倾向于在基底内向内移动。 et.al.|[2308.13316](http://arxiv.org/abs/2308.13316)|null|
|**2023-08-25**|**Age of Information Diffusion on Social Networks: Optimizing Multi-Stage Seeding Strategies**|为了推广病毒式营销，主要社交平台（如Facebook Marketplace和拼多多）在在线社交网络中反复选择并邀请不同的用户（作为种子）与朋友分享有关产品或服务的最新信息。因此，我们有动机优化社交网络中病毒营销的多阶段播种过程，并采用最新的信息峰值和平均年龄（AoI）概念来衡量网络用户收到的推广信息的及时性。我们的问题与关于社交网络中信息传播的文献不同，后者仅限于一次性播种，而忽略了AoI动态或随时间的信息替换。作为关键的一步，我们设法开发封闭形式的表达式，以表征和跟踪任何社交网络上的AoI动态。对于峰值AoI问题，我们首先通过从支配集问题的高度非直接约简来证明我们的多级播种问题的NP硬度，然后提出了一种新的多项式时间算法，该算法实现了良好的近似保证（例如，对于线性网络拓扑，小于2）。为了最小化平均AoI，我们还通过将其从集覆盖问题适当地简化来证明我们的问题是NP难的。得益于我们对平均AoI目标的双侧界分析，我们建立了一个新的近似分析框架，并将我们的问题与一个简化的和距离最小化问题联系起来。这种有趣的联系激励我们开发另一种多项式时间算法，以实现良好的近似保证。此外，我们的理论结果得到了真实社交网络实验的充分证实。 et.al.|[2308.13303](http://arxiv.org/abs/2308.13303)|null|
|**2023-08-25**|**EfficientDreamer: High-Fidelity and Robust 3D Creation via Orthogonal-view Diffusion Prior**|尽管图像扩散模型在文本驱动的3D内容创建方面取得了重大进展，但它在准确捕捉文本提示的预期含义方面，尤其是在方向信息方面，往往不够。这一缺点导致了Janus问题，在Janus问题中，在这种扩散模型的指导下产生了多面3D模型。在本文中，我们提出了一种用于在正交视图图像引导下生成高保真3D内容的鲁棒流水线。具体来说，我们介绍了一种新的2D扩散模型，该模型为给定的文本提示生成由四个正交视图子图像组成的图像。然后用这个扩散模型创建3D内容，这增强了3D一致性并提供了强的结构化语义先验。这解决了臭名昭著的Janus问题，并显著提高了发电效率。此外，我们采用了渐进的3D合成策略，该策略显著提高了创建的3D内容的质量。定量和定性评估都表明，我们的方法比以前的文本到三维技术有了显著的改进。 et.al.|[2308.13223](http://arxiv.org/abs/2308.13223)|null|
|**2023-08-25**|**On the radial growth of ballistic aggregation and other aggregation models**|对于整数格 $\mathbb｛Z｝^d$，$d\geq2$上的一类聚集模型，包括经典的扩散限制聚集（DLA）模型，我们研究了团簇的生长。我们观察到，用于获得DLA模型中径向增长的几乎确定上界的Kesten方法推广到一大类这样的模型。我们特别用它来证明所谓的弹道模型的边界，在该模型中，到达的粒子沿着直线行进。我们的界暗示了$\mathbb｛Z｝^2$ 中弹道聚集团簇的分形维数为2，这证明了物理学文献中一个长期存在的猜想。 et.al.|[2308.13193](http://arxiv.org/abs/2308.13193)|null|
|**2023-08-25**|**Diff-Retinex: Rethinking Low-light Image Enhancement with A Generative Diffusion Model**|在本文中，我们重新思考了微光图像增强任务，并提出了一种用于微光图像增强的物理可解释和生成扩散模型，称为Diff-Retinex。我们的目标是整合物理模型和生成网络的优势。此外，我们希望通过生成网络来补充甚至推断微光图像中缺失的信息。因此，Diff Retinex将微光图像增强问题公式化为Retinex分解和条件图像生成。在Retinex分解中，我们集成了Transformer中注意力的优势，精心设计了Retinex Transformer分解网络（TDN），将图像分解为照度图和反射率图。然后，我们设计了多路径生成扩散网络来重建正常光的Retinex概率分布，并分别解决了这些分量中的各种退化，包括暗照明、噪声、颜色偏差、场景内容丢失等。由于生成扩散模型，Diff Retinex将低光细微细节的恢复付诸实践。在真实世界的微光数据集上进行的大量实验定性和定量地证明了该方法的有效性、优越性和通用性。 et.al.|[2308.13164](http://arxiv.org/abs/2308.13164)|null|
|**2023-08-25**|**A Survey of Diffusion Based Image Generation Models: Issues and Their Solutions**|最近，在开发大型模型方面取得了重大进展。随着ChatGPT的成功，引入了许多语言模型，表现出了非凡的性能。在图像生成模型中也观察到了类似的进步，如谷歌的Imagen模型、OpenAI的DALL-E 2和稳定扩散模型，它们在生成图像方面表现出了令人印象深刻的能力。然而，与大型语言模型类似，这些模型仍然面临尚未解决的挑战。幸运的是，开源稳定扩散模型及其基本数学原理的可用性使学术界能够广泛分析当前图像生成模型的性能，并在这种稳定扩散框架的基础上进行改进。本调查旨在研究与图像生成模型相关的现有问题和当前解决方案。 et.al.|[2308.13142](http://arxiv.org/abs/2308.13142)|null|
|**2023-08-24**|**The Dusty Rossby Wave Instability (DRWI): Linear Analysis and Simulations of Turbulent Dust-Trapping Rings in Protoplanetary Discs**|最近的数值模拟表明，尘埃聚集和星子的形成可能在环状圆盘的亚结构中进行，在那里，尘埃被困在弱湍流压力的最大值中。在这种有外部湍流且没有压力梯度的环中，流动不稳定性很难操作。为了探索在这种情况下形成星子的潜在途径，我们分析了剪切片框架下湍流集尘环的稳定性。我们自洽地建立了压力最大值和处于平衡状态的尘埃环，前者通过外力与粘度的平衡，后者通过尘埃漂移与湍流扩散的平衡。我们发现了两种类型的 $\gtrsim-H$标度不稳定性（$H$ 是压力标度高度），我们称之为尘埃Rossby波不稳定性（DRWI）。I型是从标准RWI推广而来的，RWI在最大压力下是静止的，并在相对尖锐的压力凸起中占主导地位。II型是一种新确定的需要存在灰尘的行驶模式。它可以在相对温和的颠簸中运行，包括许多对标准RWI稳定的颠簸，其生长速度在很大程度上由平衡气体和灰尘密度梯度决定。我们进一步进行了两次流体模拟，以验证两种类型的DRWI。虽然I型将强烈的灰尘浓度引入类似于标准RWI的大气体涡流中，但灰尘环在II型中得以保留，同时在环内表现出额外的结块。DRWI为湍流尘埃捕获环形成星子/行星胚胎和方位不对称尘埃结构提供了一条很有前途的途径。 et.al.|[2308.13108](http://arxiv.org/abs/2308.13108)|null|

## NeRF

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-08-24**|**NOVA: NOvel View Augmentation for Neural Composition of Dynamic Objects**|我们提出了一种新的视图增强（NOVA）策略，以训练NeRF在静态场景中对动态对象进行逼真的3D合成。与之前的工作相比，当在新的视图和时间将多个动态对象插入3D场景时，我们的框架显著减少了混合伪影；实现了可比较的PSNR，而不需要诸如光流之类的附加地面实况模态；并且总体上在神经合成中提供了易用性、灵活性和可扩展性。我们的代码库在GitHub上。 et.al.|[2308.12560](http://arxiv.org/abs/2308.12560)|**[link](https://github.com/dakshitagrawal/nova)**|
|**2023-08-23**|**Blending-NeRF: Text-Driven Localized Editing in Neural Radiance Fields**|文本驱动的3D对象本地化编辑特别困难，因为在不扭曲对象形式的情况下将原始3D对象与预期的新对象和样式效果本地混合不是一个简单的过程。为了解决这个问题，我们提出了一种新的基于NeRF的模型，即混合NeRF，它由两个NeRF网络组成：预训练的NeRF和可编辑的NeRF。此外，我们引入了新的混合操作，允许blending NeRF正确编辑通过文本定位的目标区域。通过使用预先训练的视觉语言对齐模型CLIP，我们指导Blending NeRF添加具有不同颜色和密度的新对象，修改纹理，并移除原始对象的部分。我们的大量实验表明，Blending NeRF可以从各种文本提示中生成自然和本地编辑的3D对象。 et.al.|[2308.11974](http://arxiv.org/abs/2308.11974)|null|
|**2023-08-25**|**Pose Modulated Avatars from Video**|现在，使用底层骨骼驱动的神经辐射场（NeRF），可以从一组稀疏的相机中重建动态人体运动和形状。然而，建模与骨骼姿势相关的布料和皮肤变形仍然是一个挑战。与隐式学习或依赖于代理表面的现有化身模型不同，我们的方法的动机是观察到不同的姿势需要独特的频率分配。忽略这一区别会在平滑区域产生嘈杂的伪影，或者在尖锐区域模糊细粒度的纹理和形状细节。我们开发了一个在频域中具有自适应性和显式性的两分支神经网络。第一个分支是图神经网络，它以骨骼姿态为输入，对身体各部分之间的相关性进行局部建模。第二分支将这些相关特征组合到一组全局频率，然后调制特征编码。我们的实验表明，我们的网络在保留细节和泛化能力方面优于最先进的方法。 et.al.|[2308.11951](http://arxiv.org/abs/2308.11951)|null|
|**2023-08-22**|**Enhancing NeRF akin to Enhancing LLMs: Generalizable NeRF Transformer with Mixture-of-View-Experts**|跨场景可推广的NeRF模型可以直接合成看不见场景的新视图，已成为NeRF领域的一个新焦点。现有的几种尝试依赖于越来越端到端的“神经化”架构，即用变压器等高性能神经网络取代场景表示和/或渲染模块，并将新颖的视图合成转化为前馈推理管道。虽然这些前馈“神经化”架构仍然不能很好地开箱即用地适应不同的场景，但我们建议将它们与来自大型语言模型（LLM）的强大的专家混合（MoE）思想联系起来，该思想通过在更大的整体模型容量和灵活的每实例专业化之间进行平衡，展示了卓越的泛化能力。从最近一种名为GNT的可推广NeRF架构开始，我们首先证明了MoE可以巧妙地插入以增强模型。我们进一步定制了共享的永久专家和几何体感知的一致性损失，以分别增强跨场景一致性和空间平滑性，这对于可推广的视图合成至关重要。我们提出的模型被称为GNT with Mixture-of-View-Experts（GNT-MOVE），在转移到看不见的场景时，实验显示了最先进的结果，表明在零样本和少拍摄设置中都有更好的跨场景泛化。我们的代码可在https://github.com/VITA-Group/GNT-MOVE. et.al.|[2308.11793](http://arxiv.org/abs/2308.11793)|**[link](https://github.com/vita-group/gnt-move)**|
|**2023-08-22**|**SAMSNeRF: Segment Anything Model (SAM) Guides Dynamic Surgical Scene Reconstruction by Neural Radiance Field (NeRF)**|从手术视频中准确重建手术场景对于各种应用至关重要，包括术中导航和图像引导机器人手术自动化。然而，以前的方法主要依赖于深度估计，在使用移动的手术工具重建手术场景方面效果有限。为了解决这一限制并在所有帧中为手术工具提供准确的3D位置预测，我们提出了一种称为SAMSNeRF的新方法，该方法结合了分段任意模型（SAM）和神经辐射场（NeRF）技术。我们的方法使用SAM生成手术工具的精确分割掩模，这指导了NeRF对动态手术场景重建的细化。我们在公共内窥镜检查手术视频上的实验结果表明，我们的方法成功地重建了高保真动态手术场景，并准确地反映了手术工具的空间信息。我们提出的方法可以在手术过程中为外科医生提供精确的手术工具三维位置信息，从而显著增强手术导航和自动化。源代码将很快发布。 et.al.|[2308.11774](http://arxiv.org/abs/2308.11774)|null|
|**2023-08-22**|**Novel-view Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views**|在沉浸式通信中，手与物体的交互理解和几乎没有解决的新颖视角合成是非常需要的，而由于手的高度变形和手与物体之间的严重遮挡，这是具有挑战性的。在本文中，我们提出了一种用于稀疏视图中手-物体交互的神经渲染和姿态估计系统，该系统还可以实现3D手-物体的交互编辑。我们分享了最近场景理解工作的灵感，该工作表明，预先建立的特定场景模型可以显著改善和解锁视觉任务，尤其是在输入稀疏的情况下，并将其扩展到动态手-物交互场景中，并提出分两个阶段解决问题。我们首先在离线阶段使用神经表示分别学习手和物体的形状和外观先验知识。在在线阶段，我们设计了一个基于渲染的联合模型拟合框架，以了解手与对象的动态交互与预先构建的手与对象模型以及交互先验，从而克服了手与对象之间的渗透和分离问题，并实现了新的视图合成。为了在一个序列中的手-物体交互过程中获得稳定的接触，我们提出了一个稳定的接触损失，以使接触区域一致。实验表明，我们的方法优于最先进的方法。项目网页中提供了代码和数据集https://iscas3dv.github.io/HO-NeRF. et.al.|[2308.11198](http://arxiv.org/abs/2308.11198)|null|
|**2023-08-22**|**Efficient View Synthesis with Neural Radiance Distribution Field**|最近对神经辐射场（NeRF）的研究表明，在高质量视图合成方面取得了重大进展。NeRF的一个主要限制是由于需要多个网络转发来渲染单个像素，因此其渲染效率较低。现有的改进NeRF的方法要么减少所需样本的数量，要么优化实现以加速网络转发。尽管做出了这些努力，但由于辐射场的固有表示，多次采样的问题仍然存在。相反，神经光场（NeLF）通过每像素仅查询一个单个网络转发来降低NeRF的计算成本。为了实现与NeRF接近的视觉质量，现有的NeLF方法需要更大的网络容量，这限制了它们在实践中的渲染效率。在这项工作中，我们提出了一种称为神经辐射分布场（NeRDF）的新表示，该表示以实时有效的视图合成为目标。具体来说，我们使用类似于NeRF的小型网络，同时通过像NeLF中那样的每像素单个网络转发来保持渲染速度。关键是用频率基对每条射线的辐射分布进行建模，并使用网络预测频率权重。然后通过对辐射分布进行体积渲染来计算像素值。实验表明，与现有方法相比，我们提出的方法在速度、质量和网络大小之间提供了更好的权衡：在类似网络大小的情况下，我们比NeRF实现了~254倍的加速，性能仅略有下降。我们的项目页面位于yushung-wu.github.io/NeRDF。 et.al.|[2308.11130](http://arxiv.org/abs/2308.11130)|null|
|**2023-08-21**|**CamP: Camera Preconditioning for Neural Radiance Fields**|神经辐射场（NeRF）可以被优化以获得物体和大规模场景的高保真3D场景重建。然而，NeRF需要精确的相机参数作为输入——不准确的相机参数会导致渲染模糊。通常使用运动结构（SfM）方法作为NeRF的预处理步骤来估计外部和内部相机参数，但这些技术很少产生完美的估计。因此，先前的工作已经提出与NeRF一起联合优化相机参数，但这些方法在具有挑战性的设置中容易出现局部最小值。在这项工作中，我们分析了不同的相机参数化如何影响这个联合优化问题，并观察到标准参数化相对于小扰动在大小上表现出很大的差异，这可能导致病态优化问题。我们建议使用代理问题来计算白化变换，该变换消除了相机参数之间的相关性并归一化了它们的效果，并且我们建议在联合优化期间使用该变换作为相机参数的预处理器。我们的预处理相机优化显著提高了Mip-NeRF 360数据集场景的重建质量：与不针对Zip-NeRF等相机进行优化的最先进的NeRF方法相比，我们降低了67%的错误率（RMSE），与使用SCNeRF相机参数化的最先进联合优化方法相比，降低了29%。我们的方法易于实现，不会显著增加运行时间，可以应用于各种相机参数化，并且可以直接集成到其他类似NeRF的模型中。 et.al.|[2308.10902](http://arxiv.org/abs/2308.10902)|null|
|**2023-08-20**|**Strata-NeRF : Neural Radiance Fields for Stratified Scenes**|神经辐射场（NeRF）方法学习场景的基本3D表示，并生成高保真的照片逼真的新视图。然而，大多数建议的设置都集中于对单个对象或场景的单个级别进行建模。然而，在现实世界中，我们可能会在多个层次上捕捉场景，从而产生分层捕捉。例如，游客通常先捕捉纪念碑的外部结构，然后再捕捉内部结构。在3D中建模这样的场景，并在级别之间无缝切换，可以极大地改善身临其境的体验。然而，大多数现有技术都难以对此类场景进行建模。我们提出了Strata NeRF，这是一个隐含地捕捉多个层次场景的单个神经辐射场。Strata NeRF通过将NeRF调节在允许场景结构突然变化的矢量量化（VQ）潜在表示上来实现这一点。我们在包括不同场景的多层合成数据集中评估了我们的方法的有效性，然后在真实世界的RealEstate10K数据集上进一步验证了它的泛化能力。我们发现，与现有方法相比，Strata NeRF可以有效地捕捉分层场景，最大限度地减少伪影，并合成高保真度视图。 et.al.|[2308.10337](http://arxiv.org/abs/2308.10337)|null|
|**2023-08-19**|**HollowNeRF: Pruning Hashgrid-Based NeRFs with Trainable Collision Mitigation**|神经辐射场（NeRF）已经引起了极大的关注，最近的工作，如Instant NGP，通过基于哈希网格的位置编码和神经网络的组合来加速NeRF的训练和评估。然而，有效利用3D场景的空间稀疏性仍然是一个挑战。为了剔除特征网格中不必要的区域，现有的解决方案依赖于对象形状的先验知识，或者在训练过程中通过重复的模型评估来周期性地估计对象形状，这是昂贵和浪费的。为了解决这个问题，我们提出了HollowNeRF，这是一种新的基于哈希网格的NeRF压缩解决方案，它在训练阶段自动稀疏特征网格。HollowNeRF不是直接压缩密集特征，而是训练指导有效特征修剪的粗略3D显著性掩模，并在训练期间使用交替方向乘法器（ADMM）修剪器来稀疏3D显著性掩码。通过利用3D场景中的稀疏性来重新分布哈希冲突，HollowNeRF提高了渲染质量，同时使用了可比的最先进解决方案的一小部分参数，从而实现了更好的成本-精度权衡。我们的方法提供了与Instant NGP相当的渲染质量，同时仅使用了31%的参数。此外，我们的解决方案仅使用56%的参数就可以实现高达1dB的PSNR精度增益。 et.al.|[2308.10122](http://arxiv.org/abs/2308.10122)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

