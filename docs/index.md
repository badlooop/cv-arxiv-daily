---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.06.25
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-24**|**Articulate your NeRF: Unsupervised articulated object modeling via conditional view synthesis**|我们提出了一种新的无监督方法来学习具有刚性零件的关节对象的姿态和零件分割。给定一个物体在不同关节状态下的两个观察结果，我们的方法通过使用第一个观察结果的隐式模型来学习物体零件的几何形状和外观，从第二个观察结果中提取零件分割和关节，同时呈现后一个观察结果。此外，为了解决零件分割和连接联合优化的复杂性，我们提出了一种基于体素网格的初始化策略和解耦优化程序。与先前的无监督工作相比，我们的模型获得了显著更好的性能，并推广到具有多个部分的对象，同时它可以有效地从少数视图进行后期观察。 et.al.|[2406.16623](http://arxiv.org/abs/2406.16623)|null|
|**2024-06-24**|**Crowd-Sourced NeRF: Collecting Data from Production Vehicles for 3D Street View Reconstruction**|最近，神经辐射场（NeRF）在新的视图合成中取得了令人印象深刻的结果。Block NeRF展示了利用NeRF构建大城市规模模型的能力。对于大规模建模，需要大量的图像数据。从专门设计的数据采集车上采集图像无法支持大规模应用。如何获取大量高质量的数据仍然是一个悬而未决的问题。注意到汽车行业拥有大量的图像数据，众包是大规模数据收集的便捷方式。在本文中，我们提出了一个众包框架，该框架利用生产车辆捕获的大量数据来使用NeRF模型重建场景。这种方法解决了大规模重建的关键问题，即数据来自哪里以及如何使用它们。首先，对众包海量数据进行过滤，以消除冗余，并在时间和空间上保持平衡分布。然后执行来自运动模块的结构来细化相机姿态。最后，使用图像以及姿势来训练某个块中的NeRF模型。我们强调，我们提出了一个综合框架，集成了多个模块，包括数据选择、稀疏3D重建、序列外观嵌入、地表深度监测和遮挡完成。完整的系统能够从众包数据中有效地处理和重建高质量的3D场景。进行了大量的定量和定性实验来验证我们的系统的性能。此外，我们提出了一个名为“第一视角导航”的应用程序，该应用程序利用NeRF模型生成3D街景，并用合成视频引导驾驶员。 et.al.|[2406.16289](http://arxiv.org/abs/2406.16289)|null|
|**2024-06-23**|**LiveScene: Language Embedding Interactive Radiance Fields for Physical Scene Rendering and Control**|本文旨在通过将交互式对象重构从单一对象层次扩展到复杂场景层次，推动物理世界交互式场景重构的进展。为此，我们首先构建了一个模拟和一个真实场景级的物理交互数据集，该数据集包含28个场景，每个场景具有多个交互对象。此外，为了准确地建模复杂场景中多个对象的交互运动，我们提出了LiveScene，这是第一个场景级语言嵌入的交互式神经辐射场，可以有效地重建和控制复杂场景中的多个交互对象。LiveScene引入了一种高效的因子分解，将交互式场景分解为多个局部可变形场，以单独重构单个交互式对象，实现了对复杂场景中多个交互式对象的首次精确独立控制。此外，我们引入了一种感知交互的语言嵌入方法，该方法生成不同的语言嵌入，以在不同的交互状态下定位各个交互对象，从而能够使用自然语言任意控制交互对象。最后，我们在构建的数据集OminiSim和InterReal上评估LiveScene，这些数据集具有各种模拟和真实世界的复杂场景。大量的实验结果表明，该方法实现了SOTA新的视图合成和语言基础性能，在CoNeRF Synthetic、OminiSim#通道和InterReal#通道数据集上的PSNR分别超过现有方法+9.89、+1.30和+1.99，在OminiSim上的mIOU分别超过了现有方法+65.12。项目页面：\ href{https://livescenes.github.io}{https://livescenes.github.io}. et.al.|[2406.16038](http://arxiv.org/abs/2406.16038)|null|
|**2024-06-21**|**Taming 3DGS: High-Quality Radiance Fields with Limited Resources**|三维高斯散点（3DGS）以其快速、可解释和高保真的渲染方式改变了新的视图合成，但其资源需求限制了其可用性。特别是在受约束的设备上，由于模型的过度内存消耗，训练性能会迅速下降，而且往往无法完成。该方法与不确定数量的高斯收敛——其中许多是冗余的——这使得渲染变得不必要地慢，并阻止了它在期望固定大小输入的下游任务中的使用。为了解决这些问题，我们在预算内解决训练和渲染3DGS模型的挑战。我们使用了一种有指导的、纯粹建设性的致密化过程，将致密化引向高斯，从而提高重建质量。模型大小以可控的方式不断增加，以达到精确的预算，使用基于分数的高斯密度和测量其贡献的训练时间先验。我们进一步解决了训练速度障碍：在仔细分析3DGS的原始管道后，我们导出了用于梯度计算和属性更新的更快、数值等效的解决方案，包括用于高效反向传播的替代并行化。我们还提出了在适当的情况下保持质量的近似值，以进一步减少训练时间。总之，这些增强功能提供了一个强健、可扩展的解决方案，减少了训练时间，降低了计算和内存需求，并具有高质量。我们的评估表明，在预算设置中，我们使用3DGS获得了有竞争力的质量指标，同时实现了模型大小和训练时间的4-5倍减少。有了更慷慨的预算，我们的衡量质量超过了他们。这些进步为受限环境（例如移动设备）中的新型视图合成打开了大门。 et.al.|[2406.15643](http://arxiv.org/abs/2406.15643)|null|
|**2024-06-21**|**E2GS: Event Enhanced Gaussian Splatting**|事件摄像机以其高动态范围、无运动模糊和低能耗而闻名，由于这些特性，最近得到了广泛的应用。在过去的几年里，基于事件的三维重建领域取得了显著进展，基于神经辐射场（NeRF）的方法展示了真实感视图合成的结果。然而，NeRF的体绘制范式需要大量的训练和绘制时间。在本文中，我们介绍了事件增强高斯散射（E2GS），这是一种将事件数据合并到高斯散射中的新方法，最近在新视图合成领域取得了重大进展。我们的E2GS有效地利用了模糊图像和事件数据，显著改善了图像去模糊，并产生了高质量的新视图合成。我们在合成和真实世界数据集上的全面实验表明，我们的E2GS可以生成视觉上吸引人的渲染，同时提供更快的训练和渲染速度（140 FPS）。我们的代码可在https://github.com/deguchihiroyuki/E2GS. et.al.|[2406.14978](http://arxiv.org/abs/2406.14978)|**[link](https://github.com/deguchihiroyuki/e2gs)**|
|**2024-06-21**|**Relighting Scenes with Object Insertions in Neural Radiance Fields**|将对象插入场景和重新照明是增强现实（AR）中常用的应用。以前的方法侧重于使用CAD模型插入虚拟对象或从单视图图像中插入真实对象，导致AR应用场景非常有限。我们提出了一种新的基于NeRF的管道，用于将对象NeRF插入场景NeRF，实现新的视图合成和逼真的重新照明，支持物理交互，如从描绘对象和场景的两组图像中相互投射阴影。照明环境是球面谐波和球面高斯的混合表示，非常好地表示了高频和低频照明组件，并支持非朗伯曲面。具体而言，我们利用体积渲染的优势，通过比较相机视图和光源视图之间的深度图并生成生动的软阴影，引入了一种高效阴影渲染的创新方法。所提出的方法在广泛的实验评估中实现了现实的再照明效果。 et.al.|[2406.14806](http://arxiv.org/abs/2406.14806)|null|
|**2024-06-20**|**Deblurring Neural Radiance Fields with Event-driven Bundle Adjustment**|神经辐射场（NeRF）以高质量的多视图图像作为输入，实现了令人印象深刻的3D表示学习和新颖的视图合成结果。然而，图像中的运动模糊经常发生在低光照和高速运动场景中，这显著降低了NeRF的重建质量。以前的去模糊NeRF方法难以估计曝光时间内的信息，无法准确地对运动模糊进行建模。相比之下，以高时间分辨率测量强度变化的仿生事件相机弥补了这一信息不足。在本文中，我们提出了用于去模糊神经辐射场的事件驱动束调整（EBAD NeRF），以通过利用混合事件RGB数据来联合优化可学习姿态和NeRF参数。引入强度变化度量事件损失和照片度量模糊损失来加强相机运动模糊的显式建模。对合成数据和真实捕获数据的实验结果表明，与先前的工作相比，EBAD NeRF可以在曝光时间内获得准确的相机姿态，并学习更清晰的3D表示。 et.al.|[2406.14360](http://arxiv.org/abs/2406.14360)|null|
|**2024-06-19**|**Simultaneous Map and Object Reconstruction**|在本文中，我们提出了一种利用激光雷达对大规模城市场景进行动态表面重建的方法。基于深度的重建往往侧重于小规模对象或将移动对象视为异常值的大规模SLAM重建。我们采用整体视角，优化动态场景的组成模型，将世界分解为刚性移动的对象和背景。为了实现这一点，我们从最近的新颖视图合成方法中获得灵感，并将重建问题作为全局优化，最小化我们预测的表面和输入激光雷达扫描之间的距离。我们展示了如何将这种全局优化分解为配准和表面重建步骤，这些步骤可以通过现成的方法很好地处理，而无需任何重新训练。通过对连续时间运动进行仔细建模，我们的重建可以补偿旋转激光雷达传感器的滚动快门效应。这允许第一个系统（据我们所知）对刚性移动物体的激光雷达扫描进行适当的运动补偿，补充了广泛使用的静态场景运动补偿技术。除了将动态重建本身作为一个目标之外，我们还表明，这样的系统可以用于自动标记部分注释的序列，并为难以标记的问题（如深度完成和场景流）生成地面实况注释。 et.al.|[2406.13896](http://arxiv.org/abs/2406.13896)|null|
|**2024-06-19**|**Splatter a Video: Video Gaussian Representation for Versatile Processing**|视频表示是一个长期存在的问题，对各种下游任务至关重要，如跟踪、深度预测、分割、视图合成和编辑。然而，由于缺乏3D结构，当前的方法要么难以对复杂的运动进行建模，要么依赖于不适合操纵任务的隐式3D表示。为了应对这些挑战，我们引入了一种新的显式3D表示视频高斯表示——将视频嵌入到3D高斯中。我们提出的表示使用显式高斯作为代理对3D规范空间中的视频外观进行建模，并将每个高斯与视频运动的3D运动相关联。这种方法提供了比分层图集或体积像素矩阵更内在和更明确的表示。为了获得这样的表示，我们从基础模型中提取二维先验，如光流和深度，以在这种不适定的环境中正则化学习。广泛的应用证明了我们新视频表示的多功能性。它已被证明在许多视频处理任务中有效，包括跟踪、一致的视频深度和特征细化、运动和外观编辑以及立体视频生成。项目页面：https://sunyangtian.github.io/spatter_a_video_web/ et.al.|[2406.13870](http://arxiv.org/abs/2406.13870)|null|
|**2024-06-18**|**HumanSplat: Generalizable Single-Image Human Gaussian Splatting with Structure Priors**|尽管高保真度人体重建技术最近取得了进展，但对密集捕获图像或耗时的每次优化的要求大大阻碍了它们在更广泛场景中的应用。为了解决这些问题，我们提出了HumanSplat，它以可推广的方式从单个输入图像中预测任何人的3D高斯飞溅特性。特别是，HumanSplat包括一个2D多视图扩散模型和一个具有人体结构先验的潜在重建转换器，这些先验能够在一个统一的框架内熟练地集成几何先验和语义特征。进一步设计了一种包含人体语义信息的层次损失，以实现高保真纹理建模，并更好地约束估计的多个视图。在标准基准和野外图像上的综合实验表明，HumanSplat在实现真实感新颖视图合成方面超越了现有的最先进方法。 et.al.|[2406.12459](http://arxiv.org/abs/2406.12459)|**[link](https://github.com/humansplat/humansplat.github.io)**|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-24**|**Crowd-Sourced NeRF: Collecting Data from Production Vehicles for 3D Street View Reconstruction**|最近，神经辐射场（NeRF）在新的视图合成中取得了令人印象深刻的结果。Block NeRF展示了利用NeRF构建大城市规模模型的能力。对于大规模建模，需要大量的图像数据。从专门设计的数据采集车上采集图像无法支持大规模应用。如何获取大量高质量的数据仍然是一个悬而未决的问题。注意到汽车行业拥有大量的图像数据，众包是大规模数据收集的便捷方式。在本文中，我们提出了一个众包框架，该框架利用生产车辆捕获的大量数据来使用NeRF模型重建场景。这种方法解决了大规模重建的关键问题，即数据来自哪里以及如何使用它们。首先，对众包海量数据进行过滤，以消除冗余，并在时间和空间上保持平衡分布。然后执行来自运动模块的结构来细化相机姿态。最后，使用图像以及姿势来训练某个块中的NeRF模型。我们强调，我们提出了一个综合框架，集成了多个模块，包括数据选择、稀疏3D重建、序列外观嵌入、地表深度监测和遮挡完成。完整的系统能够从众包数据中有效地处理和重建高质量的3D场景。进行了大量的定量和定性实验来验证我们的系统的性能。此外，我们提出了一个名为“第一视角导航”的应用程序，该应用程序利用NeRF模型生成3D街景，并用合成视频引导驾驶员。 et.al.|[2406.16289](http://arxiv.org/abs/2406.16289)|null|
|**2024-06-23**|**MLPHand: Real Time Multi-View 3D Hand Mesh Reconstruction via MLP Modeling**|多视图手部网格重建是虚拟现实和人机交互应用中的一项关键任务，但它仍然是一项艰巨的挑战。尽管现有的多视角手部重建方法实现了显著的准确性，但它们通常会带来巨大的计算负担，阻碍实时推理。为此，我们提出了MLPHand，这是一种用于实时多视图单手重建的新方法。MLP-Hand由两个主要模块组成：（1）一个基于MLP的轻量级Skeleton2Mesh模型，可有效地从手部骨骼中恢复手部网格；（2）一个多视图几何特征融合预测模块，可利用来自多个视图的详细几何信息增强Skeleton4Mesh模型。在三个广泛使用的数据集上的实验表明，MLPHand可以将计算复杂度降低90%，同时实现与现有最先进基线相当的重建精度。 et.al.|[2406.16137](http://arxiv.org/abs/2406.16137)|null|
|**2024-06-23**|**Learning with Noisy Ground Truth: From 2D Classification to 3D Reconstruction**|深度神经网络在数据密集型计算机视觉应用中取得了巨大成功，而这种成功在很大程度上依赖于大量干净的数据。在现实世界中，有时很难获得干净的数据。例如，在图像分类和分割任务中，数百万个样本的精确注释通常非常昂贵和耗时。在3D静态场景重建任务中，大多数与NeRF相关的方法都需要对静态场景进行基本假设（例如，一致的照明条件和持久的物体位置），这在现实世界的场景中经常被违反。为了解决这些问题，带噪声地面实况学习（LNGT）已成为一种有效的学习方法，并显示出巨大的潜力。在这项简短的调查中，我们提出了一个正式的定义，将LNGT-LNGT的分析统一到不同机器学习任务（分类和回归）的背景下。基于这一定义，我们提出了一种新的分类法，根据机器学习的基本定义，根据误差分解对现有工作进行分类。此外，我们对记忆效应进行了深入分析，并对未来从2D分类到3D重建的潜在研究机会进行了深入讨论，希望为后续研究提供指导。 et.al.|[2406.15982](http://arxiv.org/abs/2406.15982)|null|
|**2024-06-22**|**psPRF:Pansharpening Planar Neural Radiance Field for Generalized 3D Reconstruction Satellite Imagery**|目前大多数卫星NeRF变体都是针对一个特定场景设计的，无法推广到新的几何结构。此外，RGB图像需要平移锐化作为独立的预处理步骤。本文介绍了psPRF，这是一种平面神经辐射场，用于使用有理多项式相机（RPC）从卫星传感器获得的成对低分辨率RGB（LR-RGB）和高分辨率全色（HR-PAN）图像。为了从LR-RGB和HR-PAN图像中捕获跨模态先验，对于Unet形结构，我们将编码器与显式频谱到空间卷积（SSConv）相适应，以增强多模态表示能力。为了支持psRPF跨场景的泛化能力，我们采用了投影损失来确保强大的几何自监督。使用多场景WorldView-3 LR-RGB和HR-PAN对对所提出的方法进行了评估，并实现了最先进的性能。 et.al.|[2406.15707](http://arxiv.org/abs/2406.15707)|null|
|**2024-06-21**|**E2GS: Event Enhanced Gaussian Splatting**|事件摄像机以其高动态范围、无运动模糊和低能耗而闻名，由于这些特性，最近得到了广泛的应用。在过去的几年里，基于事件的三维重建领域取得了显著进展，基于神经辐射场（NeRF）的方法展示了真实感视图合成的结果。然而，NeRF的体绘制范式需要大量的训练和绘制时间。在本文中，我们介绍了事件增强高斯散射（E2GS），这是一种将事件数据合并到高斯散射中的新方法，最近在新视图合成领域取得了重大进展。我们的E2GS有效地利用了模糊图像和事件数据，显著改善了图像去模糊，并产生了高质量的新视图合成。我们在合成和真实世界数据集上的全面实验表明，我们的E2GS可以生成视觉上吸引人的渲染，同时提供更快的训练和渲染速度（140 FPS）。我们的代码可在https://github.com/deguchihiroyuki/E2GS. et.al.|[2406.14978](http://arxiv.org/abs/2406.14978)|**[link](https://github.com/deguchihiroyuki/e2gs)**|
|**2024-06-19**|**MVSBoost: An Efficient Point Cloud-based 3D Reconstruction**|高效准确的3D重建对于各种应用至关重要，包括增强现实和虚拟现实、医学成像和电影特效。虽然传统的多视图立体（MVS）系统在这些应用中是基础，但在隐式3D场景建模中使用神经隐式场为处理复杂拓扑和连续曲面带来了新的可能性。然而，神经隐式场往往存在计算效率低、过拟合和严重依赖数据质量的问题，限制了其实际应用。本文提出了一种增强的MVS框架，该框架通过运动结构（SfM）和用于点云致密化、网格重建和纹理化的高级图像处理，将多视图360度图像与稳健的相机姿态估计相结合。我们的方法显著改进了传统的MVS方法，在真实合成360数据集上使用切角距离度量进行验证，提供了卓越的准确性和精度。所开发的MVS技术增强了3D重建的细节和清晰度，并在复杂场景重建中展示了卓越的计算效率和稳健性，有效地处理了遮挡和不同的视点。这些改进表明，我们的MVS框架可以与当前最先进的神经隐场方法竞争，并有可能超越这些方法，尤其是在需要实时处理和可扩展性的场景中。 et.al.|[2406.13515](http://arxiv.org/abs/2406.13515)|null|
|**2024-06-19**|**Assessing the 3D resolution of refocused correlation plenoptic images using a general-purpose image quality estimator**|相关全光成像（CPI）是一种很有前途的光场成像（LFI）方法，这是一种能够同时测量场景中光强分布和传播方向的技术。LFI允许单次3D采样，为广泛的应用提供快速的3D重建。然而，LFI中通常用于获得3D信息的微透镜阵列限制了图像分辨率，图像分辨率随着体积重建能力的增强而迅速下降。CPI通过使用两个具有空间分辨率的光电探测器来解耦光场信息测量，从而消除了对微透镜的需求，从而解决了这一限制。3D信息被编码在四维相关函数中，该函数在后处理中被解码以重建图像，而没有传统LFI中看到的分辨率损失。本文评估了CPI的断层成像性能，证明了重新聚焦重建方法提供了与传统成像系统相当的轴向切片能力。提出了一种基于图像保真度的通用分析方法来定量研究轴向和横向分辨率。该分析充分表征了任何CPI架构的体积分辨率，提供了对其成像性能的全面评估。 et.al.|[2406.13501](http://arxiv.org/abs/2406.13501)|null|
|**2024-06-19**|**Self-Supervised Diffusion Model for 3-D Seismic Data Reconstruction**|地震数据重建是补偿不均匀和不完全地震几何的有效工具。与二维地震数据重建方法相比，三维重建方法可以更多地考虑地震数据中的空间结构相关性。在早期的研究中，三维重建方法主要是理论驱动的，由于其对地震数据的先验假设，因此存在一些局限性。为了释放这些局限性，基于深度学习的重建方法兴起，并在处理重建问题方面显示出潜力。然而，现有的深度学习方法主要有两个缺点。一方面，现有的大多数基于深度学习的方法都采用卷积神经网络，在处理复杂或时变分布的数据时存在一些困难。最近，有报道称，扩散模型能够通过逐渐使数据分布复杂化来优化网络，从而解决具有复杂分布的数据。另一方面，现有的方法需要足够的成对数据来训练网络，这是很难获得的，尤其是对于缺乏的三维地震数据。基于深度先验的无监督和基于采样的自监督网络为这个问题提供了一个可用的解决方案。在本文中，我们开发了一个用于三维地震数据重建的自监督扩散模型（S2DM）。所提出的模型主要包括扩散恢复模型和变分时空模块。大量的合成和现场实验证明了所提出的S2DM算法的优越性。 et.al.|[2406.13252](http://arxiv.org/abs/2406.13252)|null|
|**2024-06-18**|**Semantic Graph Consistency: Going Beyond Patches for Regularizing Self-Supervised Vision Transformers**|具有视觉转换器（ViTs）的自监督学习（SSL）已被证明对表示学习有效，在各种下游任务上的出色表现证明了这一点。尽管取得了这些成功，但现有的基于ViT的SSL架构并没有完全利用ViT主干，尤其是ViT的补丁令牌。在本文中，我们引入了一个新的语义图一致性（SGC）模块来规范基于ViT的SSL方法，并有效地利用补丁令牌。我们将图像重新定义为图，将图像补丁作为节点，并通过使用图神经网络将显式消息传递到SSL框架中来注入关系归纳偏差。我们的SGC损失充当了一个正则化因子，利用未充分开发的ViTs补丁令牌来构建图，并在图像的多个视图中增强图特征之间的一致性。在包括ImageNet、RESISC和Food-101在内的各种数据集上进行的广泛实验表明，我们的方法显著提高了学习表示的质量，当有限的标记数据用于线性评估时，性能提高了5-10%。这些实验与一系列全面的消融相结合，证明了我们的方法在各种环境中的前景。 et.al.|[2406.12944](http://arxiv.org/abs/2406.12944)|null|
|**2024-06-18**|**HumanSplat: Generalizable Single-Image Human Gaussian Splatting with Structure Priors**|尽管高保真度人体重建技术最近取得了进展，但对密集捕获图像或耗时的每次优化的要求大大阻碍了它们在更广泛场景中的应用。为了解决这些问题，我们提出了HumanSplat，它以可推广的方式从单个输入图像中预测任何人的3D高斯飞溅特性。特别是，HumanSplat包括一个2D多视图扩散模型和一个具有人体结构先验的潜在重建转换器，这些先验能够在一个统一的框架内熟练地集成几何先验和语义特征。进一步设计了一种包含人体语义信息的层次损失，以实现高保真纹理建模，并更好地约束估计的多个视图。在标准基准和野外图像上的综合实验表明，HumanSplat在实现真实感新颖视图合成方面超越了现有的最先进方法。 et.al.|[2406.12459](http://arxiv.org/abs/2406.12459)|**[link](https://github.com/humansplat/humansplat.github.io)**|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-24**|**StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal**|这项工作解决了从单目彩色输入（即图像和视频）进行高质量表面法线估计的挑战，该领域最近通过重新调整扩散先验的用途而发生了革命性的变化。然而，以前的尝试仍然难以进行随机推理，这与Image2Normal任务的确定性相冲突，以及代价高昂的集合步骤，这会减慢估计过程。我们的方法StableNormal通过减少推理方差来减轻扩散过程的随机性，从而在没有任何额外的集合过程的情况下产生“稳定和尖锐”的正态估计。StableNormal在具有挑战性的成像条件下工作稳定，如极端照明、模糊和低质量。它还可以抵御透明和反射表面，以及有大量物体的杂乱场景。具体而言，StableNormal采用了从粗到细的策略，该策略从一步正态估计器（YOSO）开始，推导出相对粗糙但可靠的初始正态猜测，然后是语义引导的细化过程（SG-DRN），该过程细化法线以恢复几何细节。StableNormal的有效性通过在DIODE室内、iBims、ScannetV2和NYUv2等标准数据集以及在表面重建和法线增强等各种下游任务中的竞争性能得到了证明。这些结果证明，StableNormal保留了准确正态估计的“稳定性”和“清晰度”。StableNormal代表了重新利用扩散先验进行确定性估计的尝试。为了使其民主化，代码和模型已在hf.co/Stable-X中公开 et.al.|[2406.16864](http://arxiv.org/abs/2406.16864)|null|
|**2024-06-24**|**FreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models**|扩散模型在视频生成中表现出了显著的能力，这进一步激发了将轨迹控制引入生成过程的兴趣。虽然现有的工作主要集中在基于训练的方法（例如，条件适配器）上，但我们认为，扩散模型本身允许在不需要任何训练的情况下对生成的内容进行适当的控制。在这项研究中，我们引入了一种无调谐框架，通过对噪声构建和注意力计算施加指导，实现轨迹可控的视频生成。具体来说，1）我们首先展示了几个有指导意义的现象，并分析了初始噪声如何影响生成内容的运动轨迹。2） 随后，我们提出了FreeTraj，这是一种无调谐的方法，通过修改噪声采样和注意力机制来实现轨迹控制。3） 此外，我们扩展了FreeTraj，以便于使用可控轨迹生成更长、更大的视频。配备了这些设计，用户可以灵活地手动提供轨迹或选择LLM轨迹规划器自动生成的轨迹。大量实验验证了我们的方法在增强视频扩散模型的轨迹可控性方面的有效性。 et.al.|[2406.16863](http://arxiv.org/abs/2406.16863)|null|
|**2024-06-24**|**Dreamitate: Real-World Visuomotor Policy Learning via Video Generation**|操作中的一个关键挑战是学习一种可以稳健地推广到不同视觉环境的策略。学习稳健策略的一个很有前途的机制是利用视频生成模型，该模型是在互联网视频的大规模数据集上预训练的。在本文中，我们提出了一个视觉运动策略学习框架，该框架对给定任务的人类演示的视频扩散模型进行微调。在测试时，我们生成了一个以新颖场景的图像为条件的任务执行示例，并直接使用该合成执行来控制机器人。我们的关键见解是，使用通用工具可以毫不费力地弥合人手和机器人操纵器之间的具体差距。我们在四个日益复杂的任务上评估了我们的方法，并证明利用互联网规模的生成模型可以使学习到的策略比现有的行为克隆方法实现更高程度的泛化。 et.al.|[2406.16862](http://arxiv.org/abs/2406.16862)|null|
|**2024-06-24**|**General Binding Affinity Guidance for Diffusion Models in Structure-Based Drug Design**|基于结构的药物设计（SBDD）专注于产生有效的配体，这些配体与指定的蛋白质口袋强而特异地结合。几种方法使用机器学习SBDD在3D空间中生成这些配体，条件是所需蛋白质袋的结构。最近，扩散模型通过对原子位置和类型的基本分布进行建模，在这里取得了成功。虽然这些方法在考虑蛋白质袋的结构细节方面是有效的，但它们往往没有明确考虑结合亲和力。结合亲和力表征配体与蛋白质袋结合的紧密程度，并通过与结合过程相关的自由能的变化来测量。它是衡量配体和蛋白质袋之间相互作用有效性的最关键指标之一。为了解决这一问题，我们提出了BADGER：具有增强细化的结合亲和力扩散指导。BADGER是一种通用的指导方法，用于引导扩散采样过程改善蛋白质与配体的结合，使我们能够调整配体与蛋白质之间结合亲和力的分布。我们的方法是通过使用神经网络（NN）对能量函数进行建模来实现的，能量函数通常由AutoDock Vina（ADV）近似。ADV的能量函数是不可微分的，并基于配体和靶蛋白受体之间的相互作用来估计亲和力。通过使用神经网络作为可微能量函数代理，我们利用我们学习的能量函数的梯度作为任何训练的扩散模型之上的指导方法。我们表明，我们的方法将生成的配体与其蛋白质受体的结合亲和力提高了60%，显著超过了以前的机器学习方法。我们还表明，我们的指导方法是灵活的，可以很容易地应用于其他基于扩散的SBDD框架。 et.al.|[2406.16821](http://arxiv.org/abs/2406.16821)|null|
|**2024-06-24**|**Damping effects of viscous dissipation on growth of symmetric instability**|对称不稳定性（SI）是由旋转与锋面喷流的横向和垂直剪切相互作用引起的锋面不稳定性，是剪切、离心和重力不稳定性的概括。虽然SI的起源已经在许多观测和模型中进行了研究，但对其在物理海洋中生长的直觉主要来自恒定粘度线性不稳定性分析和大涡模拟（LES）。在真实海洋中，由SI产生的正向级联，其中许多精细到微观尺度的过程与生长的SI速度细胞相互作用，人们对此知之甚少。虽然已经观察到许多对称不稳定流动的情况，但在这些位置观察到的增强湍流动能（TKE）耗散（ $\epsilon$）并不常见。我们使用理想地转喷流的数值不稳定性分析来表明，来自其他湍流过程（例如，竞争不稳定性、内波过程或边界层过程）的先前存在的湍流的粘性扩散效应可以抑制真实海洋中SI的增长。例如，由均匀扩散率和粘度$\kappa=\nu=10^｛-4｝m^2/s$表示的中等水平的环境湍流，将SI的增长最快模式的波长范围从$\mathcal｛O｝（10-100）$m限制到$\mathcal｛O}（100）$m，并将其电子折叠时间尺度延长$\mathical｛O’（1-10）$hrs；表明先前存在的湍流的净粘性扩散效应可以抑制SI的增长。粘性阻尼是真实海洋中SI结构罕见的一种可能解释，我们的结果促使在区域模型中参数化SI时包含对先前时间步长$\epsilon$或$\kappa$ 的依赖性。 et.al.|[2406.16818](http://arxiv.org/abs/2406.16818)|null|
|**2024-06-24**|**ClotheDreamer: Text-Guided Garment Generation with 3D Gaussians**|从文本中合成高保真度的3D服装对于数字化身的创建是可取的，但具有挑战性。最近通过分数蒸馏采样（SDS）的基于扩散的方法实现了新的可能性，但要么与人体复杂结合，要么难以重复使用。我们介绍了ClotheDreamer，这是一种基于3D高斯的方法，用于根据文本提示生成可穿戴、可生产的3D服装资产。我们提出了一种新的表示方式——解纠缠Clothe-Gussian Splatting（DCGS），以实现单独的优化。DCGS将穿着衣服的化身表示为一个高斯模型，但冻结身体高斯飞溅。为了提高质量和完整性，我们结合双向SDS来分别根据姿势条件监督服装化身和服装RGBD渲染，并提出了一种新的宽松服装修剪策略。我们的方法还可以支持自定义服装模板作为输入。得益于我们的设计，合成3D服装可以很容易地应用于虚拟试穿，并支持物理精确的动画。大量实验展示了我们的方法优越且具有竞争力的性能。我们的项目页面位于https://ggxxii.github.io/clothedreamer. et.al.|[2406.16815](http://arxiv.org/abs/2406.16815)|null|
|**2024-06-24**|**3D distortion-free, reduced field of view diffusion-prepared GRE at 3T**|目的：开发一种无3D失真的减少FOV扩散制备的GRE序列，并证明其在健康志愿者脊髓扩散成像中的体内应用。方法：在扩散准备中，使用相位编码方向上的切片选择性倾斜脉冲，结合幅度稳定器，实现3D多镜头减少FOV扩散准备GRE（RFOV-DP-GRE）采集。在体模中评估了所开发的减少FOV方法的疗效和ADC估计的准确性。此外，招募了5名健康志愿者，并使用所提出的序列和用于脊髓成像的标准自旋回波扩散加权单次EPI序列（DW-SS-EPI）在3T下进行扫描。由两名专家读者评估图像质量、感知信噪比和图像失真，并对表观信噪比进行定量测量。结果：体模扫描证明了所提出的减少FOV方法的有效性。与DW-SS-EPI相比，RFOV-DP-GRE测量了一致的ADC估计值。在体内，与DW-SS-EPI相比，RFOV-DP-GRE显示出改善的图像质量和减少的感知失真，同时保持感知SNR。结论：使用所提出的序列可以实现三维无失真扩散制备成像 et.al.|[2406.16809](http://arxiv.org/abs/2406.16809)|null|
|**2024-06-24**|**Portrait3D: 3D Head Generation from Single In-the-wild Portrait Image**|虽然最近的工作在一次拍摄3D常见对象生成方面取得了巨大成功，但从单个图像生成高质量和逼真度的3D头部仍然是一个巨大的挑战。以前基于文本的3D头生成方法受到文本描述的限制，而基于图像的方法难以生成高质量的头几何图形。为了解决这个具有挑战性的问题，我们提出了一种新的框架Portrait3D，以生成高质量的3D头，同时保留其身份。我们的工作将肖像图像的身份信息整合到三个部分：1）几何初始化，2）几何雕刻和3）纹理生成阶段。给定一个参考人像图像，我们首先将身份特征与文本特征对齐，以实现ID感知引导增强，其中包含表示人脸信息的控制信号。然后，我们使用canny图、肖像图像的ID特征和预先训练的文本到法线/深度扩散模型来生成ID感知几何监督，并使用3D-GAN反演来生成ID认知几何初始化。此外，由于能够将身份信息注入3D头部生成，我们使用ID感知指导来计算用于几何造型的ID感知分数蒸馏（ISD）。对于纹理生成，我们采用ID一致的纹理修复和细化，它逐渐扩展纹理修复的视图，以获得初始化UV纹理贴图。然后，我们使用id感知引导来为有噪声的多视图图像提供图像级监督，以获得精细的纹理图。大量实验表明，我们可以从单一的野生肖像图像中生成具有精确几何形状和纹理的高质量3D头。项目页面位于https://jinkun-hao.github.io/Portrait3D/. et.al.|[2406.16710](http://arxiv.org/abs/2406.16710)|null|
|**2024-06-24**|**Geometry-Aware Score Distillation via 3D Consistent Noising and Gradient Consistency Modeling**|分数蒸馏采样（SDS）是一种将预训练的2D扩散模型的分数蒸馏为3D表示的方法，最近在文本到3D的生成任务中取得了重大进展。然而，这种方法仍然面临着关键的几何不一致性问题，如Janus问题。从这样一个假设开始，即这种不一致性问题可能是由从不同角度预测的2D分数之间的多视角不一致引起的，我们引入了GSD，这是一个简单通用的即插即用框架，用于将3D一致性和几何意识纳入SDS过程。我们的方法由三个部分组成：3D一致性噪声处理，旨在产生完全遵循标准高斯分布的3D一致性噪音图，基于几何的梯度扭曲，用于识别不同视点的预测梯度之间的对应关系，以及新的梯度一致性损失，用于优化场景几何结构，以产生更一致的梯度。我们证明，我们的方法显著提高了性能，以最小的计算成本成功地解决了文本到三维生成任务中的几何不一致问题，并与现有的基于分数蒸馏的模型兼容。我们的项目页面位于https://ku-cvlab.github.io/GSD/. et.al.|[2406.16695](http://arxiv.org/abs/2406.16695)|null|
|**2024-06-24**|**Repulsive Score Distillation for Diverse Sampling of Diffusion Models**|分数蒸馏采样是将扩散模型集成到复杂视觉生成中的关键。尽管取得了令人印象深刻的成果，但它仍存在模式崩溃和缺乏多样性的问题。为了应对这一挑战，我们利用分数蒸馏的梯度流解释提出了排斥分数蒸馏（RSD）。特别是，我们提出了一个基于粒子系综排斥的变分框架，以促进多样性。使用包含粒子之间耦合的变分近似，排斥表现为一种简单的正则化，允许粒子基于它们的相对成对相似性进行相互作用，例如通过径向基核进行测量。我们为无约束和有约束的采样场景设计了RSD。对于约束采样，我们关注潜在空间中的逆问题，该问题导致增广变分公式，在计算、质量和多样性之间取得了良好的平衡。我们在文本到图像生成和反问题方面的大量实验表明，与最先进的替代方案相比，RSD在多样性和质量之间实现了卓越的权衡。 et.al.|[2406.16683](http://arxiv.org/abs/2406.16683)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-17**|**DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features**|我们提出了DistilleNeRF，这是一种自监督学习框架，解决了在自动驾驶中从有限的2D观测中理解3D环境的挑战。我们的方法是一个可推广的前馈模型，它从稀疏的单帧多视图相机输入中预测丰富的神经场景表示，并通过可微分渲染进行自监督训练，以重建RGB、深度或特征图像。我们的第一个见解是通过生成密集的深度和虚拟相机目标进行训练，利用每场景优化的神经辐射场（NeRF），从而帮助我们的模型从稀疏的非重叠图像输入中学习3D几何。其次，为了学习语义丰富的3D表示，我们建议从预先训练的2D基础模型（如CLIP或DINOv2）中提取特征，从而实现各种下游任务，而不需要昂贵的3D人工注释。为了利用这两个见解，我们引入了一种新的模型架构，该架构具有两级提升-飞溅-拍摄编码器和参数化稀疏分层体素表示。在NuScenes数据集上的实验结果表明，DistilleNeRF在场景重建、新视图合成和深度估计方面显著优于现有的可比自监督方法；并且它允许竞争性的零样本3D语义占用预测，以及通过提取的基础模型特征来理解开放世界场景。演示和代码将在https://distillnerf.github.io/. et.al.|[2406.12095](http://arxiv.org/abs/2406.12095)|null|
|**2024-06-18**|**Effective Rank Analysis and Regularization for Enhanced 3D Gaussian Splatting**|从多视图图像中进行三维重建是计算机视觉和图形学的基本挑战之一。近年来，三维高斯散射（3DGS）已经成为一种很有前途的技术，能够实时渲染和高质量的三维重建。该方法利用了三维高斯表示和基于瓦片的飞溅技术，绕过了昂贵的神经场查询。尽管3DGS具有潜力，但由于高斯收敛为具有一个主导方差的各向异性高斯，3DGS仍面临挑战，包括针状伪影、次优几何结构和不准确法线。我们建议使用有效秩分析来检查3D高斯基元的形状统计，并识别高斯确实收敛为有效秩为1的针状形状。为了解决这个问题，我们引入了有效秩作为正则化，它约束高斯的结构。我们的新正则化方法增强了法线和几何重建，同时减少了针状伪影。该方法可以作为附加模块集成到其他3DGS变体中，在不影响视觉逼真度的情况下提高其质量。 et.al.|[2406.11672](http://arxiv.org/abs/2406.11672)|null|
|**2024-06-13**|**Well-posedness and regularity of solutions to neural field problems with dendritic processing**|我们研究了最近提出的神经场模型的解决方案，在该模型中，树突被建模为源自体细胞层的垂直纤维的连续体。由于电压通过具有非局部源的电缆方程沿树枝状方向传播，因此该模型具有各向异性扩散算子以及突触耦合的积分项。因此，相应的柯西问题与经典的神经场方程明显不同。我们证明了问题的弱公式允许一个唯一的解，嵌入估计类似于非线性局部反应扩散方程的嵌入估计。我们的分析依赖于无扩散问题的扰动弱解，即标准神经场，迄今为止尚未对其弱问题进行研究。我们找到了有扩散和无扩散问题的严格渐近估计，并证明了这两个模型的解在有限时间间隔上在适当的范数下保持接近。我们提供了微扰结果的数值证据。 et.al.|[2406.09222](http://arxiv.org/abs/2406.09222)|null|
|**2024-06-13**|**Preserving Identity with Variational Score for General-purpose 3D Editing**|我们提出了Piva（用变分分数蒸馏保持同一性），这是一种新的基于优化的方法，用于编辑基于扩散模型的图像和3D模型。具体来说，我们的方法受到了最近提出的2D图像编辑方法——德尔塔去噪分数（DDS）的启发。我们指出了DDS在二维和三维编辑中的局限性，这会导致细节丢失和过饱和。为了解决这一问题，我们提出了一个额外的分数提取术语，以强制执行身份保护。这导致了更稳定的编辑过程，逐步优化NeRF模型以匹配目标提示，同时保留关键的输入特征。我们证明了我们的方法在零样本图像和神经场编辑中的有效性。我们的方法成功地改变了视觉属性，添加了微妙和实质性的结构元素，转换了形状，并在标准的2D和3D编辑基准上取得了有竞争力的结果。此外，我们的方法没有施加任何约束，如掩蔽或预训练，使其与广泛的预训练扩散模型兼容。这允许进行多功能编辑，而不需要神经场到网格的转换，提供更用户友好的体验。 et.al.|[2406.08953](http://arxiv.org/abs/2406.08953)|null|
|**2024-06-12**|**Category-level Neural Field for Reconstruction of Partially Observed Objects in Indoor Environment**|通过各种成功案例，神经隐式表示在三维重建中引起了人们的关注。对于进一步的应用，如场景理解或编辑，一些作品已经显示出在对象组成重建方面的进展。尽管它们在观测区域具有优越的性能，但在重建部分观测到的对象时，它们的性能仍然有限。为了更好地处理这个问题，我们引入了类别级神经场，该神经场在场景中属于同一类别的对象之间学习有意义的公共3D信息。我们的主要想法是根据观察到的形状对对象进行子分类，以便更好地训练类别级模型。然后，我们利用神经场，通过选择基于射线的不确定性选择的代表性对象并与之对齐，来执行配准部分观测对象的挑战性任务。在模拟和真实世界数据集上的实验表明，我们的方法改进了几个类别的未观察零件的重建。 et.al.|[2406.08176](http://arxiv.org/abs/2406.08176)|**[link](https://github.com/Taekbum/category-nerf-reconstruction-official)**|
|**2024-06-12**|**OpenObj: Open-Vocabulary Object-Level Neural Radiance Fields with Fine-Grained Understanding**|近年来，人们对由视觉语言模型（VLM）促进的开放词汇三维场景重建产生了浓厚的兴趣，VLM在开放集检索中展示了非凡的能力。然而，现有的方法面临一些局限性：它们要么专注于学习逐点特征，导致语义理解模糊，要么只处理对象级重建，从而忽略对象内部的复杂细节。为了应对这些挑战，我们引入了OpenObj，这是一种创新的方法，用于构建具有细粒度理解的开放词汇表对象级神经辐射场（NeRF）。从本质上讲，OpenObj建立了一个健壮的框架，用于在对象级别进行高效和严密的场景建模和理解。此外，我们将零件级特征融入神经领域，从而实现物体内部的细致入微的表示。这种方法捕获对象级实例，同时保持细粒度的理解。在多个数据集上的结果表明，OpenObj在零样本语义分割和检索任务中取得了优异的性能。此外，OpenObj支持多尺度的真实世界机器人任务，包括全局移动和局部操纵。 et.al.|[2406.08009](http://arxiv.org/abs/2406.08009)|**[link](https://github.com/BIT-DYN/OpenObj)**|
|**2024-06-11**|**Image Neural Field Diffusion Models**|扩散模型在对复杂数据分布建模方面表现出了令人印象深刻的能力，与GANs相比具有几个关键优势，例如稳定的训练、更好地覆盖训练分布的模式，以及在没有额外训练的情况下解决反问题的能力。然而，大多数扩散模型学习固定分辨率图像的分布。我们建议通过在图像神经场上训练扩散模型来学习连续图像的分布，该模型可以以任何分辨率渲染，并显示出其相对于固定分辨率模型的优势。为了实现这一点，一个关键的挑战是获得一个代表真实感图像神经场的潜在空间。受最近几项技术的启发，我们提出了一种简单有效的方法，但有一些关键的变化，使图像神经场具有真实感。我们的方法可以用于将现有的潜在扩散自动编码器转换为图像神经场自动编码器。我们证明，图像神经场扩散模型可以使用混合分辨率图像数据集进行训练，优于固定分辨率扩散模型和超分辨率模型，并且可以有效地解决不同尺度条件下的逆问题。 et.al.|[2406.07480](http://arxiv.org/abs/2406.07480)|null|
|**2024-06-10**|**Space-Time Continuous PDE Forecasting using Equivariant Neural Fields**|最近，条件神经场（NeF）通过将解学习为条件NeF的潜在空间中的流，已成为偏微分方程的强大建模范式。尽管受益于NeFs的有利特性，如网格不可知性和时空连续动力学建模，但这种方法限制了将PDE的已知约束强加给解决方案的能力，例如对称性或边界条件，有利于建模的灵活性。相反，我们提出了一种基于时空连续NeF的求解框架，该框架通过在潜在空间中保留几何信息，尊重PDE的已知对称性。我们表明，将解建模为感兴趣组 $G$ 上的点云流，可以提高泛化和数据效率。我们验证了我们的框架很容易推广到看不见的空间和时间位置，以及初始条件的几何变换——在其他基于NeF的PDE预测方法失败的地方——并在一些具有挑战性的几何结构中超过基线进行改进。 et.al.|[2406.06660](http://arxiv.org/abs/2406.06660)|null|
|**2024-06-11**|**LOP-Field: Brain-inspired Layout-Object-Position Fields for Robotic Scene Understanding**|空间认知使动物具有非常高效的导航能力，这在很大程度上取决于对空间环境的场景级理解。最近，人们发现，大鼠大脑嗅后皮层的神经群体比场景中的物体更能强烈地适应空间布局。受局部场景中空间布局表示的启发，我们提出了实现布局对象位置（LOP）关联的LOP域，以对机器人场景理解的层次表示进行建模。在基础模型和隐式场景表示的支持下，神经场被实现为机器人的场景存储器，存储具有位置、对象和布局信息的场景的可查询表示。为了验证所建立的LOP关联，对该模型进行了测试，以使用定量指标从3D位置推断区域信息，实现了超过88%的平均准确度。还表明，与最先进的定位方法相比，所提出的使用区域信息的方法可以在文本和RGB输入的情况下实现改进的对象和视图定位结果。 et.al.|[2406.05985](http://arxiv.org/abs/2406.05985)|null|
|**2024-06-17**|**Grounding Continuous Representations in Geometry: Equivariant Neural Fields**|最近，神经场已经成为表示连续信号的强大建模范式。在条件神经领域中，一个领域由一个潜在变量表示，该变量对NeF进行了调节，否则其参数化将在整个数据集上共享。我们提出了基于交叉注意力变换器的等变神经场，其中NeFs以几何条件变量，即潜在点云为条件，从而实现从潜在到场的等变解码。我们的等变方法引入了一个可操纵性性质，通过该性质，场和势能都以几何为基础，并服从变换定律。如果场变换，势能相应地表示变换，反之亦然。至关重要的是，等变关系确保潜在的能够（1）真实地表示几何模式，允许在潜在空间中进行几何推理，（2）在空间相似的模式上进行权重共享，允许有效地学习场的数据集。与其他非等变NeF方法相比，使用分类实验和拟合整个数据集的能力验证了这些主要特性。我们通过展示独特的局部场编辑特性，进一步验证了ENF的潜力。 et.al.|[2406.05753](http://arxiv.org/abs/2406.05753)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

