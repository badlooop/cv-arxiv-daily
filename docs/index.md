---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.05.27
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-05-24**|**Feature Splatting for Better Novel View Synthesis with Low Overlap**|3D高斯飞溅已经成为一种非常有前途的场景表示，在新的视图合成中实现最先进的质量明显快于竞争对手。然而，它使用球面谐波来表示场景颜色限制了3D高斯的表现力，因此，当我们离开训练视图时，该表示的泛化能力也受到了限制。在本文中，我们提出将3D高斯的颜色信息编码为每高斯特征向量，我们将其表示为特征飞溅（FeatSplat）。为了合成一个新的视图，首先将高斯“飞溅”到图像平面中，然后对相应的特征向量进行阿尔法混合，最后通过小MLP对混合向量进行解码，以渲染RGB像素值。为了进一步告知模型，我们将相机嵌入连接到混合特征向量，以使解码也以视点信息为条件。我们的实验表明，这些用于编码辐射的新模型显著改进了远离训练视图的低重叠视图的新视图合成。最后，我们还展示了我们的特征向量表示的能力和便利性，展示了它不仅能够为新视图生成RGB值，而且能够生成其每像素语义标签。我们将在接受后发布代码。关键词：高斯散射、新视图合成、特征散射 et.al.|[2405.15518](http://arxiv.org/abs/2405.15518)|null|
|**2024-05-24**|**NVS-Solver: Video Diffusion Model as Zero-Shot Novel View Synthesizer**|通过利用预先训练的大型视频扩散模型的强大生成能力，我们提出了NVS解算器，这是一种新的视图合成（NVS）范式，无需训练即可进行操作。NVS解算器自适应地调整具有给定视图的扩散采样过程，以便能够从静态场景的单个或多个视图或动态场景的单目视频中创建显著的视觉体验。具体来说，在我们的理论建模的基础上，我们用扭曲的输入视图表示的给定场景先验迭代地调制分数函数，以控制视频扩散过程。此外，通过理论上探索估计误差的边界，我们根据视点姿态和扩散步骤的数量以自适应的方式实现调制。对静态和动态场景的广泛评估证实了我们的NVS解算器在数量和质量上都优于最先进的方法。\textit｛源代码在｝\href{https://github.com/ZHU-Zhiyu/NVS_Solver}{https://github.com/ZHU-Zhiyu/NVS $\_$$ Solver｝。 et.al.|[2405.15364](http://arxiv.org/abs/2405.15364)|**[link](https://github.com/zhu-zhiyu/nvs_solver)**|
|**2024-05-24**|**DisC-GS: Discontinuity-aware Gaussian Splatting**|最近，高斯散射（Gaussian Splatting）是一种将3D场景表示为高斯分布集合的方法，在解决新视图合成任务方面受到了极大的关注。在本文中，我们强调了高斯散射的一个基本限制：由于高斯分布的连续性，它无法准确地渲染图像中的不连续性和边界。为了解决这个问题，我们提出了一种新的框架，使高斯Splatting能够执行不连续感知的图像渲染。此外，我们在我们的框架中引入了一种B’zier边界梯度近似策略，以保持所提出的不连续感知渲染过程的“可微性”。大量实验证明了我们的框架的有效性。 et.al.|[2405.15196](http://arxiv.org/abs/2405.15196)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|高动态范围（HDR）新视图合成（NVS）旨在使用HDR成像技术从新视点创建真实感图像。与普通低动态范围（LDR）图像相比，渲染的HDR图像捕获更宽范围的亮度级别，其中包含更多的场景细节。现有的HDR NVS方法主要基于NeRF。它们的训练时间长，推理速度慢。在本文中，我们提出了一种新的框架，即高动态范围高斯散射（HDR-GS），它可以有效地渲染新的HDR视图，并在用户输入曝光时间的情况下重建LDR图像。具体来说，我们设计了一个双动态范围（DDR）高斯点云模型，该模型使用球面谐波来拟合HDR颜色，并使用基于MLP的色调映射器来渲染LDR颜色。然后将HDR和LDR颜色馈送到两个并行可微分光栅化（PDR）过程中，以重建HDR和LDPR视图。为了为HDR NVS中基于3D高斯飞溅的方法的研究奠定数据基础，我们重新校准了相机参数并计算了高斯点云的初始位置。实验表明，我们的HDR-GS在LDR和HDR-NVS上分别超过了最先进的基于NeRF的方法3.84和1.91dB，同时具有1000倍的推理速度，只需要6.3%的训练时间。 et.al.|[2405.15125](http://arxiv.org/abs/2405.15125)|null|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|三维高斯散射（3DGS）已经成为三维场景重建和新型视图合成领域的新兴研究热点。鉴于训练3DGS需要大量的时间和计算成本，保护此类3D资产的版权、完整性和隐私至关重要。隐写术作为加密传输和版权保护的关键技术，已被广泛研究。然而，它仍然缺乏针对3DGS的深入探索。与前代NeRF不同，3DGS具有两个明显的特征：1）显式的3D表示；以及2）实时渲染速度。这些特性导致3DGS点云文件是公开和透明的，每个高斯点都具有明确的物理意义。因此，在将信息嵌入3DGS点云文件的同时，确保原始3D场景的安全性和保真度是一项极具挑战性的任务。为了解决上述问题，我们首先提出了一种用于3DGS的隐写术框架，称为GS Hider，它可以以不可见的方式将3D场景和图像嵌入到原始GS点云中，并准确地提取隐藏的消息。具体来说，我们设计了一个耦合的安全特征属性来替换原始3DGS的球面谐波系数，然后使用场景解码器和消息解码器来解开原始RGB场景和隐藏消息。大量实验表明，所提出的GS隐藏器可以在不影响渲染质量的情况下有效隐藏多模式消息，并具有卓越的安全性、鲁棒性、容量和灵活性。我们的项目位于：https://xuanyuzhang21.github.io/project/gshider. et.al.|[2405.15118](http://arxiv.org/abs/2405.15118)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|神经辐射场（NeRF）通常难以重建和渲染高度镜面反射的对象，这些对象的外观随着视点的变化而快速变化。最近的工作提高了NeRF渲染远处环境照明的详细镜面外观的能力，但无法合成较近内容的一致反射。此外，这些技术依赖于计算成本高昂的大型神经网络来对出射辐射进行建模，这严重限制了优化和渲染速度。我们使用一种基于光线跟踪的方法来解决这些问题：我们的模型不是向昂贵的神经网络查询每条相机光线上各点的出射视图相关辐射，而是从这些点投射反射光线，并通过NeRF表示进行跟踪，以渲染使用小型廉价网络解码为颜色的特征向量。我们证明，我们的模型在包含闪亮物体的场景的视图合成方面优于现有方法，并且它是唯一一种能够在真实世界场景中合成照片级真实镜面外观和反射的NeRF方法，同时需要与当前最先进的视图合成模型相当的优化时间。 et.al.|[2405.14871](http://arxiv.org/abs/2405.14871)|null|
|**2024-05-23**|**Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis**|在计算机视觉中，仅从单个视点精确重建复杂的动态场景仍然是一项具有挑战性的任务。当前的动态新颖视图合成方法通常需要来自许多不同相机视点的视频，这需要仔细的记录设置，并大大限制了它们在野外以及具体的人工智能应用中的实用性。在本文中，我们提出了 $\textbf{GCD}$ ，这是一种可控的单目动态视图合成管道，它利用大规模扩散先验，在给定任何场景的视频的情况下，以一组相对相机姿态参数为条件，从任何其他选择的视角生成同步视频。我们的模型不需要深度作为输入，也不明确地对3D场景几何进行建模，而是执行端到端的视频到视频转换，以有效地实现其目标。尽管只在合成多视图视频数据上进行训练，但零样本现实世界的泛化实验在机器人、物体持久性和驾驶环境等多个领域都显示出了有希望的结果。我们相信，我们的框架有可能在丰富的动态场景理解、机器人感知和虚拟现实的交互式3D视频观看体验中解锁强大的应用程序。 et.al.|[2405.14868](http://arxiv.org/abs/2405.14868)|null|
|**2024-05-23**|**Tele-Aloha: A Low-budget and High-authenticity Telepresence System Using Sparse RGB Cameras**|在本文中，我们针对对等通信场景，提出了一种低预算、高真实性的双向遥现系统Tele Aloha。与以前的系统相比，Tele Aloha仅使用四个稀疏RGB相机、一个消费级GPU和一个自动立体屏幕来实现高分辨率（2048x2048）、实时性（30fps）、低延迟（小于150ms）和强大的远程通信。作为Tele Aloha的核心，我们提出了一种高效的上半身视图合成算法。首先，我们设计了一个级联视差估计器来获得鲁棒的几何线索。此外，还引入了一个通过高斯散射的神经光栅化器，将潜在特征投影到目标视图上，并将其解码为降低的分辨率。此外，考虑到高质量的捕获数据，我们利用加权混合机制将解码图像细化为2K的最终分辨率。利用世界领先的自动立体显示和低延迟虹膜跟踪，即使没有任何可穿戴的头戴式显示设备，用户也能够体验到强烈的三维感。总之，我们的远程呈现系统在现实生活中的实验中展示了共同存在感，激发了下一代的交流。 et.al.|[2405.14866](http://arxiv.org/abs/2405.14866)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|镜面物体（如有光泽的金属或有光泽的油漆）的新颖视图合成仍然是一个重大挑战。不仅光泽外观，全局照明效果（包括环境中其他对象的反射）也是忠实再现场景的关键组件。在本文中，我们提出了神经定向编码（NDE），这是一种用于渲染镜面对象的神经辐射场（NeRF）的视图相关外观编码。无损检测将基于特征网格的空间编码概念转移到角度域，显著提高了对高频角度信号建模的能力。与以前只使用角度输入的编码函数的方法相比，我们还对空间特征进行了锥跟踪，以获得空间变化的方向编码，这解决了具有挑战性的互反射效应。在合成数据集和真实数据集上的大量实验表明，具有NDE的NeRF模型（1）在镜面对象的视图合成方面优于现有技术，（2）与小型网络一起工作，以实现快速（实时）推理。项目网页和源代码位于：\url{https://lwwu2.github.io/nde/}. et.al.|[2405.14847](http://arxiv.org/abs/2405.14847)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|三维高斯散射（3DGS）的最新进展在新的视图合成（NVS）任务中显示出有希望的结果。凭借其卓越的渲染性能和高保真度渲染质量，3DGS在以前的NeRF同行中表现出色。最新的3DGS方法要么专注于提高渲染效率的不稳定性，要么专注于减小模型大小。另一方面，3DGS在大规模场景中的训练效率并没有得到太多关注。在这项工作中，我们提出了DoGaussian，一种分布式训练3DGS的方法。我们的方法首先将场景分解为K个块，然后将交替方向乘法器方法（ADMM）引入3DGS的训练过程中。在训练过程中，我们的DoGaussian在主节点上维护一个全局3DGS模型，在从节点上维护K个局部3DGS模型。K个局部3DGS模型在训练后被丢弃，并且我们在推理过程中只查询全局3DGS模型。通过场景分解减少了训练时间，并通过共享三维高斯的共识保证了训练的收敛性和稳定性。当在大规模场景上进行评估时，我们的方法将3DGS的训练加速了6倍以上，同时实现了最先进的渲染质量。我们的项目页面位于https://aibluefisher.github.io/DoGaussian. et.al.|[2405.13943](http://arxiv.org/abs/2405.13943)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-05-24**|**LAM3D: Large Image-Point-Cloud Alignment Model for 3D Reconstruction from Single Image**|大型重建模型在从单个或多个输入图像自动生成3D内容的领域取得了重大进展。尽管这些模型取得了成功，但由于仅从图像数据推导3D形状的固有挑战，这些模型通常会产生几何不准确的3D网格。在这项工作中，我们介绍了一种新的框架，即大图像和点云对齐模型（LAM3D），它利用3D点云数据来增强生成的3D网格的保真度。我们的方法从开发基于点云的网络开始，该网络可以有效地生成精确且有意义的潜在三平面，为精确的三维网格重建奠定基础。在此基础上，我们的图像点云特征对齐技术处理单个输入图像，与潜在的三平面对齐，为图像特征注入稳健的3D信息。该过程不仅丰富了图像特征，而且有助于在不需要多视图输入的情况下生成高保真3D网格，显著减少了几何失真。我们的方法仅用6秒就从单个图像中实现了最先进的高保真3D网格重建，在各种数据集上的实验证明了其有效性。 et.al.|[2405.15622](http://arxiv.org/abs/2405.15622)|null|
|**2024-05-24**|**DiffCalib: Reformulating Monocular Camera Calibration as Diffusion-Based Dense Incident Map Generation**|单眼相机校准是众多3D视觉应用的关键前提条件。尽管取得了相当大的进步，但现有的方法往往依赖于特定的假设，难以在不同的现实世界场景中进行推广，并且性能受到训练数据不足的限制。最近，在扩展数据集上训练的扩散模型已被证实能够保持生成多样化、高质量图像的能力。这一成功表明，模型在有效理解各种视觉信息方面具有强大的潜力。在这项工作中，我们利用嵌入预先训练的扩散模型中的全面视觉知识，实现更稳健、更准确的单目相机固有估计。具体而言，我们将相机固有参数的四个自由度（4-DoF）估计问题重新表述为密集入射图生成任务。该图详细说明了RGB图像中每个像素的入射角，其格式与扩散模型的范例非常一致。然后，在推理过程中，可以使用简单的非学习RANSAC算法从事件图中导出相机固有值。此外，为了进一步提高性能，我们联合估计深度图，为事件图估计提供额外的几何信息。在多个测试数据集上进行的大量实验表明，我们的模型实现了最先进的性能，预测误差减少了40%。此外，实验还表明，我们的管道估计的精确相机固有图和深度图可以极大地有利于实际应用，如从单个野生图像进行3D重建。 et.al.|[2405.15619](http://arxiv.org/abs/2405.15619)|null|
|**2024-05-24**|**NVS-Solver: Video Diffusion Model as Zero-Shot Novel View Synthesizer**|通过利用预先训练的大型视频扩散模型的强大生成能力，我们提出了NVS解算器，这是一种新的视图合成（NVS）范式，无需训练即可进行操作。NVS解算器自适应地调整具有给定视图的扩散采样过程，以便能够从静态场景的单个或多个视图或动态场景的单目视频中创建显著的视觉体验。具体来说，在我们的理论建模的基础上，我们用扭曲的输入视图表示的给定场景先验迭代地调制分数函数，以控制视频扩散过程。此外，通过理论上探索估计误差的边界，我们根据视点姿态和扩散步骤的数量以自适应的方式实现调制。对静态和动态场景的广泛评估证实了我们的NVS解算器在数量和质量上都优于最先进的方法。\textit｛源代码在｝\href{https://github.com/ZHU-Zhiyu/NVS_Solver}{https://github.com/ZHU-Zhiyu/NVS $\_$$ Solver｝。 et.al.|[2405.15364](http://arxiv.org/abs/2405.15364)|**[link](https://github.com/zhu-zhiyu/nvs_solver)**|
|**2024-05-23**|**CraftsMan: High-fidelity Mesh Generation with 3D Native Generation and Interactive Geometry Refiner**|我们提出了一种新的生成3D建模系统，称为CraftsMan，它可以生成具有高度变化的形状、规则的网格拓扑和详细表面的高保真3D几何体，值得注意的是，它允许以交互方式细化几何体。尽管在3D生成方面取得了重大进展，但现有方法仍然难以解决漫长的优化过程、不规则的网格拓扑、嘈杂的表面以及适应用户编辑的困难，从而阻碍了它们在3D建模软件中的广泛采用和实现。我们的作品受到了工匠的启发，他通常先勾勒出作品的整体图形，然后再阐述表面细节。具体而言，我们使用3D原生扩散模型，该模型在从基于潜在集的3D表示中学习的潜在空间上进行操作，以在几秒钟内生成具有规则网格拓扑的粗略几何结构。特别地，该过程将文本提示或参考图像作为输入，并利用强大的多视图（MV）扩散模型来生成粗糙几何体的多个视图，这些视图被输入到我们的MV条件的3D扩散模型中，用于生成3D几何体，显著提高了鲁棒性和可推广性。然后，使用基于法线的几何体细化器来显著增强曲面细节。此细化可以自动执行，也可以与用户提供的编辑交互执行。大量实验表明，与现有方法相比，我们的方法在生成优质3D资产方面取得了很高的效果。主页https://craftsman3d.github.io/密码https://github.com/wyysf-98/CraftsMan et.al.|[2405.14979](http://arxiv.org/abs/2405.14979)|**[link](https://github.com/wyysf-98/craftsman)**|
|**2024-05-23**|**EvGGS: A Collaborative Learning Framework for Event-based Generalizable Gaussian Splatting**|活动摄像机具有高动态范围和低延迟等优点，非常适合具有挑战性的照明条件和快速移动的场景。然而，从原始事件流重建3D场景是困难的，因为事件数据是稀疏的并且不携带绝对的颜色信息。为了释放其在3D重建中的潜力，我们提出了第一个基于事件的可推广3D重建框架，称为EvGGS，该框架以前馈的方式仅从事件输入中将场景重建为3D高斯，并且可以推广到看不见的情况，而无需任何再训练。该框架包括深度估计模块、强度重建模块和高斯回归模块。这些子模块以级联的方式连接，我们通过设计的联合损失来协同训练它们，使它们相互促进。为了促进相关研究，我们构建了一个新的基于事件的3D数据集，其中包含各种实物和灰度图像、深度图、相机姿势和轮廓的校准标签。实验表明，联合训练的模型明显优于单独训练的模型。我们的方法在重建质量和深度/强度预测方面优于所有基线，渲染速度令人满意。 et.al.|[2405.14959](http://arxiv.org/abs/2405.14959)|**[link](https://github.com/mercerai/evggs)**|
|**2024-05-23**|**Improving Single Domain-Generalized Object Detection: A Focus on Diversification and Alignment**|在这项工作中，我们解决了用于对象检测的域泛化问题，特别关注只有单个源域可用的场景。我们提出了一种有效的方法，包括两个关键步骤：使源域多样化和基于类预测置信度和定位的对齐检测。首先，我们证明了通过仔细选择一组增广，基本检测器可以在很好的范围内优于现有的单域泛化方法。这突出了领域多样化在提高物体探测器性能方面的重要性。其次，我们介绍了一种从多个视图对齐检测的方法，同时考虑分类和定位输出。这种对齐过程导致了更好的广义和校准良好的目标探测器模型，这对于安全关键应用中的准确决策至关重要。我们的方法与检测器无关，可以无缝应用于单级和两级检测器。为了验证我们提出的方法的有效性，我们在具有挑战性的领域转移场景中进行了广泛的实验和消融。结果一致表明，与现有方法相比，我们的方法具有优越性。我们的代码和型号可在以下网址获得：https://github.com/msohaildanish/DivAlign et.al.|[2405.14497](http://arxiv.org/abs/2405.14497)|null|
|**2024-05-23**|**Multi-view Remote Sensing Image Segmentation With SAM priors**|遥感中的多视图分割（RS）寻求从场景内的不同视角对图像进行分割。最近的方法利用了从隐式神经场（INF）中提取的3D信息，增强了多个视图的结果一致性，同时使用有限的标签（甚至在3-5个标签内）来简化劳动力。尽管如此，由于不充分的全场景监督和INF中不充分的语义特征，在有限视图标签的约束下实现卓越性能仍然具有挑战性。我们建议将视觉基础模型Segment Anything（SAM）的先验注入INF，以在有限的训练数据下获得更好的结果。具体而言，我们对比测试视图和训练视图之间的SAM特征，以导出每个测试视图的伪标签，增强场景范围的标签信息。随后，我们通过转换器将SAM特征引入场景的INF中，补充语义信息。实验结果表明，我们的方法优于主流方法，证实了SAM作为INF的补充对该任务的有效性。 et.al.|[2405.14171](http://arxiv.org/abs/2405.14171)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|三维高斯散射（3DGS）的最新进展在新的视图合成（NVS）任务中显示出有希望的结果。凭借其卓越的渲染性能和高保真度渲染质量，3DGS在以前的NeRF同行中表现出色。最新的3DGS方法要么专注于提高渲染效率的不稳定性，要么专注于减小模型大小。另一方面，3DGS在大规模场景中的训练效率并没有得到太多关注。在这项工作中，我们提出了DoGaussian，一种分布式训练3DGS的方法。我们的方法首先将场景分解为K个块，然后将交替方向乘法器方法（ADMM）引入3DGS的训练过程中。在训练过程中，我们的DoGaussian在主节点上维护一个全局3DGS模型，在从节点上维护K个局部3DGS模型。K个局部3DGS模型在训练后被丢弃，并且我们在推理过程中只查询全局3DGS模型。通过场景分解减少了训练时间，并通过共享三维高斯的共识保证了训练的收敛性和稳定性。当在大规模场景上进行评估时，我们的方法将3DGS的训练加速了6倍以上，同时实现了最先进的渲染质量。我们的项目页面位于https://aibluefisher.github.io/DoGaussian. et.al.|[2405.13943](http://arxiv.org/abs/2405.13943)|null|
|**2024-05-22**|**Diffusing Winding Gradients (DWG): A Parallel and Scalable Method for 3D Reconstruction from Unoriented Point Clouds**|本文提出了一种从无方向点云重建水密三维曲面的方法。从随机初始化的法线开始，该方法通过扩散广义绕组数（GWN）场的梯度来迭代细化每个法线。在收敛后，使用标准Marching Cubes算法提取目标表面。我们的方法概念简单，易于实现，不需要数值求解器，这使它与现有方法不同。它专为并行化和可扩展性而设计，可以有效地处理CPU和GPU上的大型模型。实验结果表明，我们的方法在从无方向点云重建方面优于所有现有方法，特别是在运行时性能方面。在拥有1000万至2000万点的大型机型上，我们在NVIDIA GTX 4090 GPU上实现的CUDA通常比iPSR快30-100倍，iPSR是在配备Intel i9 CPU的高端PC上测试的领先顺序方法。此外，我们的方法对噪声表现出卓越的鲁棒性，并有效地处理具有薄结构的模型，超过了现有方法。我们将公开源代码，以鼓励进一步的研究和应用。 et.al.|[2405.13839](http://arxiv.org/abs/2405.13839)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|神经渲染技术的最新进展显著提高了3D重建的保真度。值得注意的是，3D高斯飞溅（3DGS）的出现标志着一个重要的里程碑，它采用了离散场景表示，促进了高效的训练和实时渲染。一些研究已经成功地将3DGS的实时渲染能力扩展到动态场景。然而，当在截然不同的天气和照明条件下拍摄训练图像时，就会出现挑战。这种情况对3DGS及其变体在实现精确重建方面提出了挑战。尽管基于NeRF的方法（NeRF-W、CLNeRF）在处理这种具有挑战性的条件方面显示出了前景，但它们的计算需求阻碍了实时渲染能力。在本文中，我们提出了高斯时间机（GTM），它用由轻量级多层感知器（MLP）解码的离散时间嵌入向量对高斯基元的时间相关属性进行建模。通过调整高斯基元的不透明度，我们可以重建对象的可见性变化。为了提高几何一致性，我们进一步提出了一种分解的颜色模型。GTM在3个数据集上实现了最先进的渲染保真度，在渲染方面比基于NeRF的同行快100倍。此外，GTM成功地解开了外观变化，并渲染了平滑的外观插值。 et.al.|[2405.13694](http://arxiv.org/abs/2405.13694)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-05-24**|**Self-consistent evaluation of proximity and inverse proximity effects with pair-breaking in diffusive SN junctions**|我们考虑一个平面超导正常金属（SN）结，同时存在非弹性和自旋翻转散射过程。在扩散极限中，我们使用Usadel方程的一维公式来计算单粒子态密度的自洽能量依赖性，该自洽能量依存性是对破坏自旋翻转项的各种空间轮廓与超导和金属侧界面距离的函数。对断裂过程以零能量填充超导间隙，这反映在结附近的扫描隧道显微镜/光谱实验中的零偏压隧道电导中。我们还研究了在接合处具有部分透明界面的影响。我们将我们的发现与最近在4Hb-TaS $_2$ 上的实验中观察到的1H阶跃边缘的零偏压电导的指数上升进行了比较[A.K.Nayak等人，Nat.Phys.171413（2021）]。 et.al.|[2405.15770](http://arxiv.org/abs/2405.15770)|null|
|**2024-05-24**|**FastDrag: Manipulate Anything in One Step**|使用生成模型的基于拖动的图像编辑提供了对图像内容的精确控制，使用户只需点击几下即可操作图像中的任何内容。然而，主流方法通常采用 $n$ 步迭代进行潜在语义优化，以实现基于拖动的图像编辑，这是耗时的，并限制了实际应用。在本文中，我们介绍了一种新的基于一步拖动的图像编辑方法，即FastDrag，以加快编辑过程。我们方法的核心是潜在翘曲函数（LWF），它模拟拉伸材料的行为，以调整潜在空间内单个像素的位置。这一创新实现了一步潜在语义优化，从而显著提高了编辑速度。同时，我们提出的双边最近邻插值（BNNI）策略解决了应用LWF后出现的零区域问题。该策略使用来自相邻区域的相似特征对这些区域进行插值，从而增强语义完整性。此外，引入了一种一致性保持策略，通过采用原始图像中的语义信息来保持编辑后的图像与原始图像之间的一致性，这些信息在扩散反演过程中被保存为自关注模块中的键值对，以指导扩散采样。我们的FastDrag在DragBench数据集上进行了验证，证明了与现有方法相比，处理时间有了显著改进，同时实现了增强的编辑性能。 et.al.|[2405.15769](http://arxiv.org/abs/2405.15769)|null|
|**2024-05-24**|**InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation**|最近的会说话的化身生成模型在实现与音频的逼真和准确的嘴唇同步方面取得了长足的进步，但在控制和传达化身的详细表情和情绪方面往往不足，使得生成的视频不那么生动和可控。在本文中，我们提出了一种新的文本引导方法，用于生成情感表达的2D化身，提供细粒度的控制、改进的交互性和对生成的视频的可推广性。我们的框架名为InstructionAvatar，利用自然语言界面来控制化身的情绪和面部动作。从技术上讲，我们设计了一个自动注释管道来构建一个指令-视频配对训练数据集，该数据集配备了一个新颖的基于双分支扩散的生成器，用于同时预测具有音频和文本指令的化身。实验结果表明，InstructionAvatar产生的结果与这两种条件都很好地一致，并且在细粒度的情绪控制、唇同步质量和自然度方面优于现有方法。我们的项目页面是https://wangyuchi369.github.io/InstructAvatar/. et.al.|[2405.15758](http://arxiv.org/abs/2405.15758)|null|
|**2024-05-24**|**Looking Backward: Streaming Video-to-Video Translation with Feature Banks**|本文介绍了StreamV2V，这是一种通过用户提示实现实时流式视频到视频（V2V）转换的扩散模型。与之前使用批处理有限帧的V2V方法不同，我们选择以流方式处理帧，以支持无限帧。StreamV2V的核心是一个将现在与过去联系起来的向后看原则。这是通过维护一个特征库来实现的，该特征库将过去帧的信息存档。对于传入帧，StreamV2V将自我关注扩展到包括存储的密钥和值，并将类似的过去功能直接融合到输出中。通过合并存储的和新的特征，不断更新特征库，使其紧凑但信息丰富。StreamV2V以其适应性和效率脱颖而出，无需微调即可与图像扩散模型无缝集成。它可以在一个A100 GPU上运行20 FPS，分别比FlowVid、CoDeF、Rerender和TokenFlow快15倍、46倍、108倍和158倍。定量指标和用户研究证实了StreamV2V保持时间一致性的卓越能力。 et.al.|[2405.15757](http://arxiv.org/abs/2405.15757)|null|
|**2024-05-24**|**Score-based generative models are provably robust: an uncertainty quantification perspective**|通过不确定性量化（UQ）的观点，我们表明基于分数的生成模型（SGM）在实际实现中对多种误差源是可证明的稳健的。我们的主要工具是Wasserstein不确定性传播（WUP）定理，这是一个模型形式的UQ界，描述了学习分数函数的 $L^2$误差如何传播到Wasserstein-1（$\mathbf{d}_1$）球围绕着福克-普朗克方程演化下的真实数据分布。我们展示了（a）有限样本近似、（b）提前停止、（c）分数匹配目标选择、（d）分数函数参数化表达和（e）参考分布选择导致的误差如何影响$\mathbf生成模型的质量{d}_1可计算量的$bound。WUP定理依赖于Hamilton-Jacobi-Bellman偏微分方程（PDE）的Bernstein估计和扩散过程的正则化性质。具体来说，PDE正则性理论表明，随机性是确保SGM算法具有可证明鲁棒性的关键机制。WUP定理适用于$\mathbf以外的积分概率度量{d}_1$，例如总变化距离和最大平均差异。$\mathbf中的样本复杂度和泛化界{d}_1$ 直接来自WUP定理。我们的方法需要最小的假设，对流形假设是不可知的，并避免了目标分布的绝对连续性假设。此外，我们的结果阐明了SGM中多个误差源之间的权衡。 et.al.|[2405.15754](http://arxiv.org/abs/2405.15754)|null|
|**2024-05-24**|**Murray-von Neumann dimension for strictly semifinite weights**|给定一个配备有忠实正规严格半群权 $\varphi$的von Neumann代数$M$，我们发展了$（M，\varphi）$上的Murray von Neuman维数的概念，该概念是为与包含$M^\varphi\subet M$相关的基本构造上的模定义的。对于$\varphi=\tau$一个忠实的正态迹，这恢复了有限von Neumann代数的通常Murray von Neuman维数。如果$M$是类型$\mathrm{III}_\$0<\lambda<1$或完整类型$\mathrm的lambda$因子{III}_1$factor与$\text｛Sd｝（M）\neq\mathbb｛R｝$，则在极值几乎周期性权重中，维度函数仅取决于$\varphi$（按比例缩放）。作为一个应用，我们证明了如果具有可分离预值$N\subet M$的扩散因子的包含具有期望$\mathcal｛E｝$，并且允许相容的极值几乎周期状态$\varphi$，那么这个维度量限制了索引$\text｛Ind｝｛\mathcal{E｝｝｝$，并且当模算子$\Delta_\varphi$和$\Delta｛\varphi|_N｝$ 具有相同的点谱时，实际上等于它。在追求这个结果的过程中，我们还证明了这样的包含总是允许Pimsner-Popa正交基。 et.al.|[2405.15725](http://arxiv.org/abs/2405.15725)|null|
|**2024-05-24**|**Hierarchical Uncertainty Exploration via Feedforward Posterior Trees**|在求解不适定逆问题时，人们通常希望探索潜在解的空间，而不是用一个看似合理的重构来表示。后验分布中嵌入了对这些可行解决方案及其相关概率的有价值的见解。然而，当面对高维度的数据（如图像）时，可视化这种分布成为一个巨大的挑战，需要在用户检查之前应用有效的摘要技术。在这项工作中，我们介绍了一种使用树值预测来可视化多个粒度级别的后验结果的新方法。我们的方法预测了任何输入测量的后验分布的树值分层摘要，只需神经网络的一次前向传递。我们展示了我们的方法在不同数据集和图像恢复挑战中的有效性，突出了其在不确定性量化和可视化方面的强大能力。我们的研究结果表明，我们的方法与从基于扩散的后验采样器对样本进行分层聚类的基线相比表现良好，但实现这一点的速度要快几个数量级。 et.al.|[2405.15719](http://arxiv.org/abs/2405.15719)|null|
|**2024-05-24**|**Simulation-based inference of radio millisecond pulsars in globular clusters**|毫秒脉冲星（MSPs）在球状星团（GC）中非常丰富，这为它们的产生提供了有利的环境。虽然最近强大的设施的出现导致了通过脉动搜索在GC中发现MSP的快速增加，但检测偏差仍然存在。在这项工作中，我们通过仔细研究GC的光度函数，研究了GC中当前和未来检测约束GC中MSP群体参数的能力。感兴趣的参数是GC托管的MSP的数量，以及它们的光度函数的平均值和宽度，这些参数通常会受到很大的不确定性的影响。正如我们所展示的，基于似然的研究可能会导致MSP群体规模的不良后验，但我们引入了一种基于边际神经比率估计的新的无似然分析，该分析始终产生良好的后验。我们专注于GC Terzan 5，它目前检测到48个MSP。我们发现，大约158个MSP应该托管在这个GC中，但这个数字的不确定性仍然很大。我们在模拟未来可能的观测结果的类Terzan 5数据集上探索我们的新方法的性能。我们发现，通过将GC的散射无线电发射的可靠测量添加到分析中，或者通过将当前无线电脉动调查的检测阈值提高至少两倍，可以获得对后验的显著改进。 et.al.|[2405.15691](http://arxiv.org/abs/2405.15691)|null|
|**2024-05-24**|**Jet Quenching of the Heavy Quarks in the Quark-Gluon Plasma and the Nonadditive Statistics**|利用Plastino-Plastino（PP）方程，计算了重夸克在夸克胶子等离子体中的输运系数，并推广了它们与微分能量损失的关系。PP方程表示探针粒子的异常扩散，并产生准指数平稳分布，该分布也是从C.Tsallis提出的非加性统计中获得的。我们估计了非加性夸克胶子介质中的能量损失，并计算了PP动力学的射流猝灭参数（ $\hat{q}$）。利用Dokshitzer和Kharzeev提出的模型，借助$hat｛q｝$的估计，我们计算了重夸克通过非加性夸克胶子等离子体的核抑制因子（$R_｛text｛AA｝｝$）。在许多情况下，分析中的参数是根据实验结果固定的，以最大限度地减少任意性。理论计算与实验$R_｛\text｛AA｝｝$ 数据之间有很好的一致性，表明快速重夸克可能在QGP内受到异常扩散。 et.al.|[2405.15679](http://arxiv.org/abs/2405.15679)|null|
|**2024-05-24**|**Taming Score-Based Diffusion Priors for Infinite-Dimensional Nonlinear Inverse Problems**|本文介绍了一种能够在函数空间中求解贝叶斯反问题的采样方法。它不假设似然的对数凹性，这意味着它与非线性逆问题兼容。该方法利用最近定义的基于无限维分数的扩散模型作为基于学习的先验，同时通过在函数空间上定义的Langevin型MCMC算法实现可证明的后验采样。受去噪算法为传统正则化建立的定点方法的启发，并与加权退火兼容，进行了一种新的收敛性分析。所获得的收敛界明确地取决于分数的近似误差；良好近似的分数对于获得良好近似的后验是至关重要的。提供了基于风格化和PDE的例子，证明了我们的收敛性分析的有效性。最后，我们讨论了该方法在学习分数和计算复杂性方面的挑战。 et.al.|[2405.15676](http://arxiv.org/abs/2405.15676)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-05-24**|**Blaze3DM: Marry Triplane Representation with Diffusion for 3D Medical Inverse Problem Solving**|解决图像恢复和重建等三维医学逆问题在现代医学领域至关重要。然而，3D医疗数据中的维度诅咒导致主流的体积方法遭受高资源消耗，并挑战模型成功捕捉自然分布，导致不可避免的体积不一致和伪影。最近的一些工作试图简化潜在空间中的生成，但缺乏对复杂图像细节进行有效建模的能力。为了解决这些局限性，我们提出了Blaze3DM，这是一种新的方法，通过集成紧凑的三平面神经场和强大的扩散模型，实现了快速高保真的生成。在技术上，Blaze3DM首先同时优化数据相关的三平面嵌入和共享解码器，将每个三平面重建回相应的3D体积。为了进一步增强3D一致性，我们引入了一个轻量级的3D感知模块来对三个垂直平面的相关性进行建模。然后，在潜在的三平面嵌入上训练扩散模型，并实现无条件和有条件的三平面生成，最终解码为任意大小的体积。对零样本三维医学逆问题求解的大量实验，包括稀疏视图CT、有限角度CT、压缩传感MRI和MRI各向同性超分辨率，表明Blaze3DM不仅实现了最先进的性能，而且显著提高了现有方法的计算效率（比以前的工作快22~40倍）。 et.al.|[2405.15241](http://arxiv.org/abs/2405.15241)|null|
|**2024-05-17**|**SNF-ROM: Projection-based nonlinear reduced order modeling with smooth neural fields**|降阶建模通过从数据中学习低阶空间表示并使用控制方程的流形投影动态演化这些表示，降低了求解偏微分方程的计算成本。虽然通常使用线性子空间降阶模型（ROM），但对于Kolmogorov $n$ -宽度缓慢衰减的问题，例如高雷诺数下以平流为主的流体流动，通常是次优的。人们对非线性ROM越来越感兴趣，它使用最先进的表示学习技术以较少的自由度准确地捕捉这种现象。我们提出了光滑神经场ROM（SNF-ROM），这是一种将无网格简化表示与Galerkin投影相结合的非线性简化建模框架。SNF-ROM体系结构将学习到的ROM轨迹约束为平滑变化的路径，这在根据支配PDE遍历简化流形时的动力学评估中是有益的。此外，我们设计了鲁棒正则化方案，以确保学习的神经场是光滑和可微的。这使我们能够使用自动微分来非侵入地计算简化系统的基于物理的动力学，并使用经典时间积分器来演化简化系统。SNF-ROM可以实现快速的离线训练，并提高在线动力学评估的准确性和稳定性。我们证明了SNF-ROM在一系列平流主导的线性和非线性PDE问题上的有效性，在这些问题上，我们始终优于最先进的ROM。 et.al.|[2405.14890](http://arxiv.org/abs/2405.14890)|null|
|**2024-05-23**|**NeuroGauss4D-PCI: 4D Neural Fields and Gaussian Deformation Fields for Point Cloud Interpolation**|点云插值面临着点稀疏性、复杂的时空动力学以及从稀疏的时间信息中导出完整的三维点云的困难等挑战。本文介绍了NeuroGauss4D PCI，它擅长在各种动态场景中建模复杂的非刚性变形。该方法从迭代高斯云软聚类模块开始，提供结构化的时间点云表示。所提出的时间径向基函数高斯残差利用高斯参数随时间插值，实现平滑的参数转换并捕获高斯分布的时间残差。此外，4D高斯变形场跟踪这些参数的演变，创建连续的时空变形场。4D神经场将低维时空坐标（ $x，y，z，t$ ）转换为高维潜在空间。最后，我们自适应有效地融合了来自神经场的潜在特征和来自高斯变形场的几何特征。NeuroGauss4D PCI在点云帧插值方面优于现有方法，在对象级（DHB）和大规模自动驾驶数据集（NL Drive）上都提供了领先的性能，并可扩展到自动标记和点云加密任务。源代码发布于https://github.com/jiangchaokang/NeuroGauss4D-PCI. et.al.|[2405.14241](http://arxiv.org/abs/2405.14241)|null|
|**2024-05-23**|**Multi-view Remote Sensing Image Segmentation With SAM priors**|遥感中的多视图分割（RS）寻求从场景内的不同视角对图像进行分割。最近的方法利用了从隐式神经场（INF）中提取的3D信息，增强了多个视图的结果一致性，同时使用有限的标签（甚至在3-5个标签内）来简化劳动力。尽管如此，由于不充分的全场景监督和INF中不充分的语义特征，在有限视图标签的约束下实现卓越性能仍然具有挑战性。我们建议将视觉基础模型Segment Anything（SAM）的先验注入INF，以在有限的训练数据下获得更好的结果。具体而言，我们对比测试视图和训练视图之间的SAM特征，以导出每个测试视图的伪标签，增强场景范围的标签信息。随后，我们通过转换器将SAM特征引入场景的INF中，补充语义信息。实验结果表明，我们的方法优于主流方法，证实了SAM作为INF的补充对该任务的有效性。 et.al.|[2405.14171](http://arxiv.org/abs/2405.14171)|null|
|**2024-05-22**|**Bridging Operator Learning and Conditioned Neural Fields: A Unifying Perspective**|算子学习是机器学习的一个新兴领域，旨在学习无穷维函数空间之间的映射。在这里，我们从计算机视觉中揭示了算子学习架构和条件神经场之间的联系，为研究流行的算子学习模型之间的差异提供了一个统一的视角。我们发现，许多常用的算子学习模型可以被视为神经场，其条件机制仅限于点和/或全局信息。受此启发，我们提出了连续视觉转换器（CViT），这是一种新的神经算子架构，它使用视觉转换器编码器，并使用交叉注意力来调制由可训练的基于网格的查询坐标位置编码构建的基场。尽管它很简单，但CViT在气候建模和流体动力学的挑战性基准中取得了最先进的结果。我们的贡献可以被视为在物理科学中适应先进的计算机视觉架构以构建更灵活、更准确的机器学习模型的第一步。 et.al.|[2405.13998](http://arxiv.org/abs/2405.13998)|**[link](https://github.com/predictiveintelligencelab/cvit)**|
|**2024-05-21**|**Unsupervised Searches for Cosmological Parity Violation: Improving Detection Power with the Neural Field Scattering Transform**|最近使用四点相关性的研究表明，星系分布中存在宇称破坏，尽管这些探测的重要性对用于模拟星系分布噪声特性的模拟的选择很敏感。在最近的一篇论文中，我们介绍了一种无监督学习方法，该方法提供了一种替代方法，通过直接从观测数据中学习奇偶性违反，避免了对模拟目录的依赖。然而，我们以前的无监督方法所使用的卷积神经网络（CNN）模型很难扩展到数据有限的更现实的场景。我们提出了一种新的方法，即神经场散射变换（NFST），它通过添加可训练滤波器来增强小波散射变换（WST）技术，该滤波器被参数化为神经场。我们首先调整NFST模型，以在简化的数据集中检测奇偶校验违规，然后在不同的训练集大小下，将其性能与WST和CNN基准进行比较。我们发现，NFST可以检测奇偶校验违规，数据比CNN少4倍，比WST少32倍。此外，在数据有限的情况下，NFST可以检测到高达 $6\sigma$ 置信度的奇偶校验违规，其中WST和CNN无法进行任何检测。我们发现，与基准模型相比，NFST增加的灵活性，特别是学习不对称滤波器的能力，以及NFST架构中内置的特定对称性，有助于提高其性能。我们进一步证明了NFST是易于解释的，这对于物理应用（如奇偶校验违反的检测）是有价值的。 et.al.|[2405.13083](http://arxiv.org/abs/2405.13083)|null|
|**2024-05-21**|**Implicit-ARAP: Efficient Handle-Guided Deformation of High-Resolution Meshes and Neural Fields via Local Patch Meshing**|在这项工作中，我们提出了神经符号距离场的局部补丁网格表示。该技术允许通过仅使用SDF信息及其梯度将平面面片网格投影和变形到标高集曲面上来离散输入SDF的标高集的局部区域。我们的分析表明，这种方法比标准的行进立方体算法更准确地逼近隐式曲面。然后，我们将这种表示应用于手柄引导变形的设置：我们引入了两个不同的管道，它们利用3D神经场来计算在给定约束集下高分辨率网格和神经场的“尽可能刚性”变形。我们对我们的方法和神经场和网格变形的各种基线进行了全面评估，结果表明，这两条管道在结果质量和稳健性方面都取得了令人印象深刻的效率和显著的改进。通过我们的新型流水线，我们引入了一种可扩展的方法来解决高分辨率网格上公认的几何处理问题，并为通过局部面片网格将其他几何任务扩展到隐式曲面领域铺平了道路。 et.al.|[2405.12895](http://arxiv.org/abs/2405.12895)|null|
|**2024-05-16**|**Single-shot volumetric fluorescence imaging with neural fields**|与需要在多个轴向平面上扫描的传统成像方法相比，单次体积荧光（SVF）成像提供了显著的优势，因为它可以在大视场上以高时间分辨率捕获生物过程。现有的SVF成像方法通常需要大的、复杂的点扩展函数（PSF）来满足压缩传感的多路复用要求，这限制了信噪比、分辨率和/或视场。在本文中，我们介绍了QuadraPol-PSF与神经场相结合，这是一种新的SVF成像方法。该方法在后焦平面利用成本效益高的定制偏振器和偏振相机来检测荧光，在紧凑的PSF内有效地编码3D场景，而没有深度模糊。此外，我们提出了一种基于神经场技术的重建算法，该算法解决了用于校正成像系统像差的相位检索方法的不精确性。该算法将实验PSF的准确性与计算生成的检索PSF的长景深相结合。QuadraPol PSF与神经场相结合，可将传统荧光显微镜的采集时间显著缩短约20倍，并可一次性捕获100 mm $^3$ 立方体积。我们通过对沙子表面细菌菌落的全聚焦成像和植物根系形态的可视化，验证了我们的硬件和算法的有效性。我们的方法为推进生物学研究和生态学研究提供了强有力的工具。 et.al.|[2405.10463](http://arxiv.org/abs/2405.10463)|null|
|**2024-05-08**|**${M^2D}$NeRF: Multi-Modal Decomposition NeRF with 3D Feature Fields**|神经场（NeRF）已经成为表示连续3D场景的一种很有前途的方法。然而，NeRF中缺乏语义编码对场景分解提出了重大挑战。为了应对这一挑战，我们提出了一个单一的模型，即多模式分解NeRF（${M^2D}$ NeRF），它能够进行基于文本和基于视觉补丁的编辑。具体来说，我们使用多模态特征提取将来自预训练的视觉和语言模型的教师特征集成到3D语义特征体积中，从而促进一致的3D编辑。为了增强三维特征体积中视觉特征和语言特征之间的一致性，我们引入了多模态相似性约束。我们还引入了一种基于补丁的联合对比损失，这有助于鼓励对象区域在3D特征空间中合并，从而产生更精确的边界。与先前的基于NeRF的方法相比，在各种真实世界场景上的实验显示出在3D场景分解任务中的优越性能。 et.al.|[2405.05010](http://arxiv.org/abs/2405.05010)|null|
|**2024-05-09**|**Radar Fields: Frequency-Space Neural Scene Representations for FMCW Radar**|神经场作为再现和新一代各种户外场景的场景表示，包括自动驾驶汽车和机器人必须处理的场景，已经得到了广泛的研究。虽然存在RGB和激光雷达数据的成功方法，但雷达作为传感模式的神经重建方法在很大程度上尚未被探索。雷达传感器在毫米波长下工作，对雾和雨中的散射具有鲁棒性，因此为主动和被动光学传感技术提供了一种互补的方式。此外，现有的雷达传感器具有很高的成本效益，并广泛应用于户外作业的机器人和车辆中。我们介绍了雷达场——一种为有源雷达成像器设计的神经场景重建方法。我们的方法将一个明确的、基于物理的传感器模型与一个隐含的神经几何和反射模型相结合，直接合成原始雷达测量值并提取场景占用率。所提出的方法不依赖于体绘制。相反，我们在傅立叶频率空间中学习场，并用原始雷达数据进行监督。我们在不同的室外场景中验证了该方法的有效性，包括车辆和基础设施密集的城市场景，以及在毫米波长传感特别有利的恶劣天气场景中。 et.al.|[2405.04662](http://arxiv.org/abs/2405.04662)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

