---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2026.01.11
> Usage instructions: [here](./docs/README.md#usage)

## Video Diffusion

- **2026-01-08** **RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation** [2601.05241](http://arxiv.org/abs/2601.05241)
  > 操纵数据的多样性、数量和质量对于训练有效的机器人策略至关重要。然而，由于硬件和物理设置的限制，收集大规模的现实世界操作数据仍然难以在不同的环境中扩展。最近的工作使用文本提示条件图像扩散模型，通过改变视觉观察中的背景和桌面对象来增强操作数据。然而，这些方法往往忽视了最先进的政策模型所需的多视角和时间连贯观察的实际需求。此外，仅靠文本提示无法可靠地指定场景设置。为了给扩散模型提供明确的视觉指导，我们引入了视觉识别提示，它提供示例图像作为条件输入，以指导生成所需的场景设置。为此，我们还构建了一个可扩展的管道，以从大型机器人数据集中管理视觉身份池。使用我们的增强操作数据来训练下游视觉语言动作和视觉运动策略模型，可以在模拟和真实机器人设置中产生一致的性能增益。

- **2026-01-08** **Plenoptic Video Generation** [2601.05239](http://arxiv.org/abs/2601.05239)
  > 摄像机控制的生成视频重新渲染方法，例如 ReCamMaster，已经取得了显着的进展。然而，尽管它们在单视图设置中取得了成功，但这些作品往往很难在多视图场景中保持一致性。由于生成模型固有的随机性，确保幻觉区域的时空一致性仍然具有挑战性。为了解决这个问题，我们引入了 PlenopticDreamer，这是一个同步生成幻觉以维持时空记忆的框架。核心思想是以自回归方式训练多输入单输出视频条件模型，并辅以摄像机引导的视频检索策略，该策略自适应地选择前几代的显着视频作为条件输入。此外，我们的训练还结合了渐进式上下文缩放以提高收敛性、自我调节以增强针对错误累积引起的远程视觉退化的鲁棒性，以及长视频调节机制以支持扩展视频生成。 Basic 和 Agibot 基准测试的大量实验表明，PlenopticDreamer 实现了最先进的视频重新渲染，提供卓越的视图同步、高保真视觉效果、精确的摄像机控制和多样化的视图转换（例如，第三人称到第三人称，以及机器人操作中从头视图到抓手视图）。项目页面：https://research.nvidia.com/labs/dir/plenopticdreamer/

- **2026-01-08** **VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control** [2601.05138](http://arxiv.org/abs/2601.05138)
  > 视频世界模型旨在模拟动态的真实世界环境，但现有方法难以对摄像机和多对象运动提供统一且精确的控制，因为视频本质上是在投影的 2D 图像平面中进行动态操作。为了弥补这一差距，我们引入了 VerseCrafter，这是一种 4D 感知视频世界模型，可以在统一的 4D 几何世界状态中对摄像机和对象动态进行明确且连贯的控制。我们的方法以新颖的 4D 几何控制表示为中心，它通过静态背景点云和每个对象的 3D 高斯轨迹对世界状态进行编码。这种表示不仅可以捕获对象的路径，还可以捕获其随时间变化的概率 3D 占用情况，为刚性边界框或参数模型提供灵活的、与类别无关的替代方案。这些 4D 控件被渲染为预训练视频扩散模型的调节信号，从而能够生成精确遵循指定动态的高保真、视图一致的视频。不幸的是，另一个主要挑战在于缺乏具有明确 4D 注释的大规模训练数据。我们通过开发一个自动数据引擎来解决这个问题，该引擎可以从野外视频中提取所需的 4D 控件，从而使我们能够在海量且多样化的数据集上训练我们的模型。

- **2026-01-08** **CounterVid: Counterfactual Video Generation for Mitigating Action and Temporal Hallucinations in Video-Language Models** [2601.04778](http://arxiv.org/abs/2601.04778)
  > 视频语言模型（VLM）实现了强大的多模态理解，但仍然容易产生幻觉，特别是在推理动作和时间顺序时。现有的缓解策略，例如文本过滤或随机视频扰动，通常无法解决根本原因：过度依赖语言先验而不是细粒度的视觉动态。我们提出了一种用于反事实视频生成的可扩展框架，该框架合成仅在动作或时间结构上不同的视频，同时保留场景上下文。我们的流程将用于行动建议和编辑指导的多模式法学硕士与基于扩散的图像和视频模型相结合，以大规模生成语义硬底片。使用这个框架，我们构建了 CounterVid，这是一个包含约 26k 个偏好对的合成数据集，目标是动作识别和时间推理。我们进一步介绍 MixDPO，这是一种统一的直接偏好优化方法，联合利用文本和视觉偏好。使用 MixDPO 微调 Qwen2.5-VL 可产生一致的改进，特别是在时间顺序方面，并有效地转移到标准视频幻觉基准。代码和模型将公开。

- **2026-01-07** **PackCache: A Training-Free Acceleration Method for Unified Autoregressive Video Generation via Compact KV-Cache** [2601.04359](http://arxiv.org/abs/2601.04359)
  > 统一的自回归模型是一个基于 Transformer 的框架，它将不同的多模态任务（例如文本、图像、视频）作为共享令牌空间下的单序列建模问题来解决。此类模型依靠 KV-cache 机制将注意力计算从 O(T^2) 减少到 O(T)；然而，KV 缓存大小随着生成令牌的数量线性增长，并且它迅速成为限制推理效率和生成长度的主要瓶颈。统一自回归视频生成继承了这一限制。我们的分析表明，KV 缓存标记表现出独特的时空属性：（i）文本和条件图像标记充当持续受到高度关注的持久语义锚，以及（ii）对先前帧的关注随着时间距离自然衰减。利用这些观察结果，我们引入了 PackCache，这是一种免训练的 KV 缓存管理方法，通过三种协调机制动态压缩 KV 缓存：保留语义引用的条件锚定、根据时间距离分配缓存预算的跨帧衰减建模以及在缓存删除下保持连贯 3D 结构的空间保留位置嵌入。在效率方面，PackCache 在 48 帧长序列上将端到端生成速度提高了 1.7-2.2 倍，展示了其实现更长序列视频生成的强大潜力。值得注意的是，最后四帧（受逐渐扩展的 KV 缓存影响最大的部分，因此也是剪辑中最昂贵的部分）对于 48 帧视频，PackCache 分别在 A40 和 H200 上提供了 2.6 倍和 3.7 倍的加速。

- **2026-01-07** **ReHyAt: Recurrent Hybrid Attention for Video Diffusion Transformers** [2601.04342](http://arxiv.org/abs/2601.04342)
  > 视频扩散模型的最新进展已转向基于变压器的架构，实现了最先进的视频生成，但代价是二次注意力复杂性，这严重限制了较长序列的可扩展性。我们引入了 ReHyAt，这是一种循环混合注意力机制，它将 softmax 注意力的保真度与线性注意力的效率结合起来，实现了块式循环重构和恒定的内存使用。与仅并发线性 SANA Video 不同，ReHyAt 的混合设计允许对现有基于 softmax 的模型进行高效蒸馏，将训练成本降低两个数量级至约 160 个 GPU 小时，同时在质量上具有竞争力。我们的轻量级蒸馏和微调管道提供了一种方法，可以应用于未来最先进的基于 softmax 的双向模型。 VBench 和 VBench-2.0 上的实验以及人类偏好研究表明，ReHyAt 实现了最先进的视频质量，同时将注意力成本从二次降低到线性，从而解锁了长时间和设备上视频生成的实用可扩展性。项目页面位于 https://qualcomm-ai-research.github.io/rehyat。

- **2026-01-07** **Choreographing a World of Dynamic Objects** [2601.04194](http://arxiv.org/abs/2601.04194)
  > 物理 4D（3D + 时间）世界中的动态对象不断演化、变形并与其他对象交互，从而产生多样化的 4D 场景动态。在本文中，我们提出了一种通用生成管道 CHORD，用于 CHOReographing 动态对象和场景并合成此类现象。用于创建这些动态的传统基于规则的图形管道基于特定类别的启发式方法，但属于劳动密集型且不可扩展。最近基于学习的方法通常需要大规模数据集，这可能无法涵盖所有​​感兴趣的对象类别。相反，我们的方法通过提出基于蒸馏的管道来提取隐藏在 2D 视频的欧拉表示中的丰富拉格朗日运动信息，从而继承了视频生成模型的普遍性。我们的方法是通用的、通用的并且与类别无关。我们通过实验生成各种多体 4D 动力学来证明其有效性，展示其与现有方法相比的优势，并证明其在生成机器人操纵策略方面的适用性。项目页面：https://yanzhelyu.github.io/chord

- **2026-01-07** **Diffusion-DRF: Differentiable Reward Flow for Video Diffusion Fine-Tuning** [2601.04153](http://arxiv.org/abs/2601.04153)
  > 直接偏好优化 (DPO) 最近通过增强视觉保真度和文本对齐来改进文本到视频 (T2V) 的生成。然而，当前的方法依赖于来自人类注释或学习奖励模型的不可微偏好信号。这种依赖使得训练标签密集、容易出现偏差且易于博弈，这通常会引发奖励黑客攻击和不稳定的训练。我们提出了 Diffusion-DRF，这是一种可微分奖励流，用于使用冻结的现成视觉语言模型（VLM）作为免训练批评家来微调视频扩散模型。 Diffusion-DRF 通过扩散去噪链直接反向传播 VLM 反馈，将 logit 级响应转换为令牌感知梯度以进行优化。我们提出了一个自动化的、方面结构的提示管道来获得可靠的多维 VLM 反馈，而梯度检查点可以通过最终的去噪步骤实现高效的更新。 Diffusion-DRF 提高了视频质量和语义对齐，同时减轻奖励黑客攻击和崩溃——无需额外的奖励模型或偏好数据集。它与模型无关，并且很容易推广到其他基于扩散的生成任务。

- **2026-01-07** **Gen3R: 3D Scene Generation Meets Feed-Forward Reconstruction** [2601.04090](http://arxiv.org/abs/2601.04090)
  > 我们提出了 Gen3R，一种将基础重建模型和视频扩散模型的强大先验联系起来的方法，用于场景级 3D 生成。我们重新调整 VGGT 重建模型的用途，通过在其标记上训练适配器来产生几何潜在特征，这些标记被正则化以与预训练视频扩散模型的外观潜在特征保持一致。通过联合生成这些解开但对齐的潜在变量，Gen3R 可以生成 RGB 视频和相应的 3D 几何图形，包括相机姿势、深度图和全局点云。实验表明，我们的方法在单图像和多图像条件 3D 场景生成方面取得了最先进的结果。此外，我们的方法可以通过利用生成先验来增强重建的鲁棒性，证明了重建和生成模型紧密耦合的互惠互利。

- **2026-01-08** **Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models** [2601.04068](http://arxiv.org/abs/2601.04068)
  > 将文本到视频的扩散模型与人类偏好保持一致对于生成高质量视频至关重要。现有的直接偏好优化（DPO）方法依赖于多样本排序和特定于任务的批评模型，这种方法效率低下，并且经常产生模糊的全局监督。为了解决这些限制，我们提出了 LocalDPO，这是一种新颖的后训练框架，它从真实视频构建本地化偏好对并优化时空区域级别的对齐。我们设计了一个自动化管道来有效地收集偏好对数据，该数据通过每个提示进行一次推理来生成偏好对，从而消除了对外部批评家模型或手动注释的需要。具体来说，我们将高质量的真实视频视为正样本，并通过使用随机时空掩模局部破坏它们并使用冻结的基础模型仅恢复掩模区域来生成相应的负样本。在训练过程中，我们引入了区域感知 DPO 损失，将偏好学习限制在损坏区域以实现快速收敛。 Wan2.1 和 CogVideoX 上的实验表明，与其他训练后方法相比，LocalDPO 持续提高了视频保真度、时间一致性和人类偏好分数，为视频生成器对齐建立了更高效、更细粒度的范例。

- **2026-01-07** **PhysVideoGenerator: Towards Physically Aware Video Generation via Latent Physics Guidance** [2601.03665](http://arxiv.org/abs/2601.03665)
  > 当前的视频生成模型可以生成高质量的美学视频，但通常很难学习现实世界物理动力学的表示，从而导致诸如不自然的物体碰撞、不一致的重力和时间闪烁等伪影。在这项工作中，我们提出了 PhysVideoGenerator，这是一个概念验证框架，它将可学习的物理学先验嵌入到视频生成过程中。我们引入了一种轻量级预测器网络 PredictorP，它直接从噪声扩散潜伏中回归从预训练视频联合嵌入预测架构（V-JEPA 2）中提取的高级物理特征。这些预测的物理标记通过专用的交叉注意力机制注入到基于 DiT 的生成器 (Latte) 的时间注意力层中。我们的主要贡献是证明了这种联合训练范例的技术可行性：我们证明扩散潜伏包含足够的信息来恢复 V-JEPA 2 物理表示，并且多任务优化在训练过程中保持稳定。该报告记录了架构设计、技术挑战和训练稳定性验证，为未来大规模评估物理感知生成模型奠定了基础。

- **2026-01-07** **VideoMemory: Toward Consistent Video Generation via Memory Integration** [2601.03655](http://arxiv.org/abs/2601.03655)
  > 在多个镜头中保持一致的角色、道具和环境是叙事视频生成的主要挑战。现有模型可以生成高质量的短片，但当场景发生变化或实体在长时间间隔后重新出现时，通常无法保留实体的身份和外观。我们提出了 VideoMemory，一个以实体为中心的框架，通过动态内存库将叙事规划与视觉生成集成在一起。给定结构化脚本，多智能体系统将叙述分解为镜头，从内存中检索实体表示，并根据这些检索到的状态合成关键帧和视频。动态内存库存储角色、道具和背景的明确视觉和语义描述符，并在每次拍摄后进行更新，以反映故事驱动的变化，同时保留身份。这种检索更新机制可以对远处镜头中的实体进行一致的描绘，并支持连贯的长格式生成。为了评估此设置，我们构建了一个 54 例多镜头一致性基准，涵盖角色、道具和背景持续场景。大量实验表明，VideoMemory 在不同的叙事序列中实现了强大的实体级连贯性和高感知质量。

- **2026-01-06** **LTX-2: Efficient Joint Audio-Visual Foundation Model** [2601.03233](http://arxiv.org/abs/2601.03233)
  > 最近的文本到视频扩散模型可以生成引人注目的视频序列，但它们仍然保持沉默——缺少音频提供的语义、情感和氛围线索。我们引入了 LTX-2，这是一种开源基础模型，能够以统一的方式生成高质量、时间同步的视听内容。 LTX-2 由具有 14B 参数视频流和 5B 参数音频流的非对称双流变压器组成，通过具有时间位置嵌入的双向音频-视频交叉注意层和用于共享时间步调节的跨模态 AdaLN 进行耦合。该架构可以实现统一视听模型的高效训练和推理，同时为视频生成分配比音频生成更多的容量。我们采用多语言文本编码器来实现更广泛的及时理解，并引入模态感知的无分类器指导（模态-CFG）机制来改进视听对齐和可控性。除了生成语音之外，LTX-2 还可以生成丰富、连贯的音轨，遵循每个场景的人物、环境、风格和情感，并配有自然背景和拟音元素。在我们的评估中，该模型实现了最先进的视听质量并迅速遵守开源系统，同时以专有模型的一小部分计算成本和推理时间提供与专有模型相当的结果。所有模型权重和代码均公开发布。

- **2026-01-06** **DiffBench Meets DiffAgent: End-to-End LLM-Driven Diffusion Acceleration Code Generation** [2601.03178](http://arxiv.org/abs/2601.03178)
  > 扩散模型在图像和视频生成方面取得了显着的成功。然而，它们固有的多步骤推理过程会带来大量的计算开销，阻碍了现实世界的部署。因此，加速扩散模型至关重要，但确定如何结合多种模型加速技术仍然是一个重大挑战。为了解决这个问题，我们引入了一个由大型语言模型（LLM）驱动的框架，用于自动加速代码生成和评估。首先，我们介绍 DiffBench，这是一个综合基准测试，它跨不同的扩散架构、优化组合和部署场景实现了三阶段自动评估管道。其次，我们提出了 DiffAgent，一种为任意扩散模型生成最佳加速策略和代码的代理。 DiffAgent 采用闭环工作流程，其中规划组件和调试组件迭代地细化代码生成组件的输出，而遗传算法从执行环境中提取性能反馈以指导后续代码细化。我们详细解释了 DiffBench 的构造以及 DiffAgent 的设计原理。大量实验表明，DiffBench 可以对生成的代码进行全面评估，并且 DiffAgent 在生成有效的扩散加速策略方面显着优于现有的 LLM。

- **2026-01-06** **DreamStyle: A Unified Framework for Video Stylization** [2601.02785](http://arxiv.org/abs/2601.02785)
  > 视频风格化是视频生成模型的重要下游任务，尚未得到彻底探索。其输入样式条件通常包括文本、样式图像和样式化的第一帧。每种条件都有其独特的优势：文本更灵活，风格图像提供更准确的视觉锚点，风格化的第一帧使长视频风格化变得可行。然而，现有方法很大程度上局限于单一类型的样式条件，这限制了它们的应用范围。此外，缺乏高质量的数据集会导致风格不一致和时间闪烁。为了解决这些限制，我们引入了 DreamStyle，一个统一的视频风格化框架，支持 (1) 文本引导、(2) 风格图像引导和 (3) 第一帧引导视频风格化，并配有精心设计的数据管理管道来获取高质量的配对视频数据。 DreamStyle 基于普通图像到视频 (I2V) 模型构建，并使用低秩适应 (LoRA) 和特定于令牌的向上矩阵进行训练，以减少不同条件令牌之间的混淆。定性和定量评估都表明，DreamStyle 能够胜任所有三项视频风格化任务，并且在风格一致性和视频质量方面优于竞争对手。

- **2026-01-06** **DreamLoop: Controllable Cinemagraph Generation from a Single Photograph** [2601.02646](http://arxiv.org/abs/2601.02646)
  > 动态照片将静态照片与选择性循环运动相结合，具有独特的艺术吸引力。以可控的方式从单张照片生成它们尤其具有挑战性。现有的图像动画技术仅限于简单的低频运动，并且只能在具有重复纹理（例如水和烟雾）的狭窄区域中运行。相比之下，大规模视频扩散模型并非针对电影图像限制而定制，并且缺乏生成无缝、受控循环所需的专门数据。我们推出了 DreamLoop，这是一种可控视频合成框架，专用于从单张照片生成电影图片，而不需要任何电影图片训练数据。我们的关键思想是通过针对两个目标进行训练来适应通用视频扩散模型：时间桥接和运动调节。这种策略可以实现灵活的电影图像生成。在推理过程中，通过使用输入图像作为第一帧和最后一帧条件，我们强制执行无缝循环。通过调节静态轨道，我们保持静态背景。最后，通过为目标对象提供用户指定的运动路径，我们的方法提供了对动画轨迹和时间的直观控制。据我们所知，DreamLoop 是第一种通过灵活直观的控制为一般场景生成电影图像的方法。我们证明，我们的方法可以生成符合用户意图的高质量、复杂的电影图像，其性能优于现有方法。

- **2026-01-05** **VINO: A Unified Visual Generator with Interleaved OmniModal Context** [2601.02358](http://arxiv.org/abs/2601.02358)
  > 我们推出了 VINO，一个统一的视觉生成器，可以在单个框架内执行图像和视频生成和编辑。 VINO 不依赖特定于任务的模型或每种模态的独立模块，而是使用以文本、图像和视频为条件的共享扩散主干，从而在一个模型下实现广泛的视觉创建和编辑任务。具体来说，VINO 将视觉语言模型 (VLM) 与多模态扩散变压器 (MMDiT) 结合起来，其中多模态输入被编码为交错条件标记，然后用于指导扩散过程。该设计支持多参考基础、长格式指令遵循以及跨静态和动态内容的一致身份保留，同时避免特定于模态的架构组件。为了训练这样一个统一的系统，我们引入了一个多阶段训练管道，该管道逐步将视频生成基础模型扩展为能够进行图像和视频输入和输出的统一的多任务生成器。在不同的生成和编辑基准中，VINO 展示了强大的视觉质量、忠实的指令遵循、改进的参考和属性保留以及更可控的多身份编辑。我们的结果强调了实现可扩展的统一视觉生成的实用路径，以及交错的上下文计算作为通用视觉创建基础的前景。

- **2026-01-05** **NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation** [2601.02204](http://arxiv.org/abs/2601.02204)
  > 我们提出了 NextFlow，一个统一的仅解码器自回归变压器，在 6 万亿个交错的文本图像离散标记上进行训练。通过利用统一自回归架构中的统一视觉表示，NextFlow 原生激活多模态理解和生成功能，解锁图像编辑、交错内容和视频生成的能力。受模态独特性质的启发（其中文本是严格顺序的，而图像本质上是分层的），我们保留文本的下一个标记预测，但采用下一个尺度预测进行视觉生成。这与传统的光栅扫描方法不同，只需 5 秒即可生成 1024x1024 图像，比同类 AR 模型快几个数量级。我们通过强大的训练方法解决多尺度生成的不稳定性。此外，我们引入了强化学习的前缀调整策略。实验表明，NextFlow 在统一模型中实现了最先进的性能，并且在视觉质量方面可与专门的扩散基线相媲美。

- **2026-01-05** **SingingBot: An Avatar-Driven System for Robotic Face Singing Performance** [2601.02125](http://arxiv.org/abs/2601.02125)
  > 为机器人面孔配备唱歌功能对于具有同理心的人机交互至关重要。然而，现有的机器人面部驾驶研究主要集中在对话或模仿静态表情上，难以满足持续的情感表达和歌唱连贯性的高要求。为了解决这个问题，我们提出了一种新颖的化身驱动框架来吸引机器人唱歌。我们首先利用嵌入广泛人类先验的肖像视频生成模型来合成生动的歌唱化身，提供可靠的表达和情感引导。随后，这些面部特征通过跨越广泛表达空间的面向语义的映射功能转移到机器人。此外，为了定量评估机器人歌唱的情感丰富度，我们提出了情感动态范围指标来衡量效价-唤醒空间内的情感宽度，揭示了广泛的情感范围对于吸引人的表演至关重要。综合实验证明，我们的方法在保持唇音同步的同时实现了丰富的情感表达，显着优于现有方法。

- **2026-01-05** **MagicFight: Personalized Martial Arts Combat Video Generation** [2601.02107](http://arxiv.org/abs/2601.02107)
  > 在通用文本到视频生成的激增中，个性化人类视频生成领域取得了显着的进步，主要集中在单人场景上。然而，据我们所知，两人互动的领域，特别是在武术格斗的背景下，仍然是未知的。我们发现了一个重大差距：现有的单人舞蹈生成模型不足以捕捉两名交战战士的微妙性和复杂性，从而导致身份混乱、肢体异常和动作不匹配等挑战。为了解决这个问题，我们引入了一项开创性的新任务：个性化武术战斗视频生成。我们的方法 MagicFight 是专门为克服这些障碍而设计的。鉴于这项开创性任务，我们面临着缺乏适当的数据集的问题。因此，我们使用游戏物理引擎 Unity 生成定制数据集，精心制作大量 3D 角色、武术动作和场景，旨在表现战斗的多样性。 MagicFight 改进并调整了现有的模型和策略，以生成高保真两人战斗视频，保持个人身份并确保无缝、连贯的动作序列，从而为交互式视频内容创建领域的未来创新奠定基础。   网站：https://MingfuYAN.github.io/MagicFight/ 数据集：https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta


## 3D

- **2026-01-08** **Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video** [2601.05251](http://arxiv.org/abs/2601.05251)
  > 我们提出了 Mesh4D，一种用于单目 4D 网格重建的前馈模型。给定动态对象的单眼视频，我们的模型会重建对象的完整 3D 形状和运动，表示为变形场。我们的主要贡献是一个紧凑的潜在空间，它可以在一次传递中对整个动画序列进行编码。这个潜在空间是由自动编码器学习的，在训练过程中，自动编码器由训练对象的骨骼结构引导，为合理的变形提供强大的先验。至关重要的是，推理时不需要骨架信息。编码器采用时空注意力，产生对象整体变形的更稳定的表示。在此表示的基础上，我们训练了一个潜在扩散模型，该模型以输入视频和从第一帧重建的网格为条件，预测一个镜头中的完整动画。我们在重建和新颖的视图合成基准上评估了 Mesh4D，在恢复准确的 3D 形状和变形方面优于现有方法。

- **2026-01-08** **QNeRF: Neural Radiance Fields on a Simulated Gate-Based Quantum Computer** [2601.05250](http://arxiv.org/abs/2601.05250)
  > 最近，量子视野 (QVF) 在模型紧凑性和学习所提供的 2D 或 3D 信号的收敛速度方面显示出有希望的改进。与此同时，新颖视图合成在神经辐射场 (NeRF) 方面取得了重大进展，其中模型从 2D 图像中学习紧凑的表示以渲染 3D 场景，尽管代价是更大的模型和强化训练。在这项工作中，我们通过引入 QNeRF 来扩展 QVF 的方法，QNeRF 是第一个专为 2D 图像的新颖视图合成而设计的混合量子经典模型。 QNeRF 利用参数化量子电路通过量子叠加和纠缠来编码空间和视图相关信息，从而产生比经典模型更紧凑的模型。我们提出了两种架构变体。 Full QNeRF 最大限度地利用所有量子振幅来增强表征能力。相比之下，双分支 QNeRF 通过分支空间和视图相关的量子态准备引入了任务通知的归纳偏置，大大降低了该操作的复杂性，并确保了可扩展性和潜在的硬件兼容性。我们的实验表明，当在中等分辨率的图像上进行训练时，QNeRF 可以匹配或优于经典 NeRF 基线，同时使用的参数数量还不到一半。这些结果表明，量子机器学习可以作为计算机视觉中级任务中连续信号表示的有竞争力的替代方案，例如从 2D 观测中学习 3D 表示。

- **2026-01-08** **Plenoptic Video Generation** [2601.05239](http://arxiv.org/abs/2601.05239)
  > 摄像机控制的生成视频重新渲染方法，例如 ReCamMaster，已经取得了显着的进展。然而，尽管它们在单视图设置中取得了成功，但这些作品往往很难在多视图场景中保持一致性。由于生成模型固有的随机性，确保幻觉区域的时空一致性仍然具有挑战性。为了解决这个问题，我们引入了 PlenopticDreamer，这是一个同步生成幻觉以维持时空记忆的框架。核心思想是以自回归方式训练多输入单输出视频条件模型，并辅以摄像机引导的视频检索策略，该策略自适应地选择前几代的显着视频作为条件输入。此外，我们的训练还结合了渐进式上下文缩放以提高收敛性、自我调节以增强针对错误累积引起的远程视觉退化的鲁棒性，以及长视频调节机制以支持扩展视频生成。 Basic 和 Agibot 基准测试的大量实验表明，PlenopticDreamer 实现了最先进的视频重新渲染，提供卓越的视图同步、高保真视觉效果、精确的摄像机控制和多样化的视图转换（例如，第三人称到第三人称，以及机器人操作中从头视图到抓手视图）。项目页面：https://research.nvidia.com/labs/dir/plenopticdreamer/

- **2026-01-08** **ObjectForesight: Predicting Future 3D Object Trajectories from Human Videos** [2601.05237](http://arxiv.org/abs/2601.05237)
  > 人类可以毫不费力地预测物体如何通过交互移动或改变——想象一个杯子被举起，一把刀切开，或者一个盖子被关闭。我们的目标是赋予计算系统类似的能力，直接从被动视觉观察中预测未来可能的物体运动。我们引入了 ObjectForesight，这是一种以对象为中心的 3D 动力学模型，可以根据短的自我中心视频序列预测刚性对象的未来 6-DoF 姿势和轨迹。与在像素或潜在空间中运行的传统世界或动态模型不同，ObjectForesight 在对象级别以 3D 形式明确表示世界，从而实现几何基础和时间连贯的预测，以捕获对象可供性和轨迹。为了大规模训练这样的模型，我们利用分割、网格重建和 3D 姿态估计方面的最新进展来整理包含 200 万多个带有伪地面实况 3D 对象轨迹的短片的数据集。通过大量的实验，我们表明 ObjectForesight 在准确性、几何一致性以及对未见过的对象和场景的泛化方面取得了显着的进步，建立了一个可扩展的框架，用于直接从观察中学习基于物理的、以对象为中心的动力学模型。 objectforesight.github.io

- **2026-01-08** **Non-Thermal Leptogenesis in the BLSM with Inverse Seesaw Mechanism** [2601.05186](http://arxiv.org/abs/2601.05186)
  > 我们研究了标准模型 (BLSM) 的测量 $U(1)_{B-L}$ 扩展中非热轻子发生的可行性，以及用于中微子质量产生的逆跷跷板 (ISS) 机制。在这个框架中，右手中微子通常具有 $\mathcal{O}(1)$ 汤川耦合，这会引起强烈的冲刷效应并使传统的热轻子发生无效。我们证明，成功的重子发生场景仍然可以通过非热轻子发生来实现，其中右旋中微子是由重 $B\!-\!L$ 希格斯玻色子 $χ$ 的衰变产生的。我们明确分析了稀释因子 $T_R/M_χ$ 与国际空间站的冲刷参数特征之间的相互作用，强调了抑制冲刷效应和保持充分再加热之间的紧张关系。我们表明，只要适当调整标量质谱，就可以产生可行的轻子不对称性，从而降低再加热温度，同时保持冲洗受到控制。由此产生的轻子不对称性通过闪子过程有效地转化为观测到的宇宙重子不对称性。我们的结果表明，反向跷跷板 $B\!-\!L$ 模型仍然是非热轻体发生和重子发生的预测性且稳健的框架。

- **2026-01-08** **VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control** [2601.05138](http://arxiv.org/abs/2601.05138)
  > 视频世界模型旨在模拟动态的真实世界环境，但现有方法难以对摄像机和多对象运动提供统一且精确的控制，因为视频本质上是在投影的 2D 图像平面中进行动态操作。为了弥补这一差距，我们引入了 VerseCrafter，这是一种 4D 感知视频世界模型，可以在统一的 4D 几何世界状态中对摄像机和对象动态进行明确且连贯的控制。我们的方法以新颖的 4D 几何控制表示为中心，它通过静态背景点云和每个对象的 3D 高斯轨迹对世界状态进行编码。这种表示不仅可以捕获对象的路径，还可以捕获其随时间变化的概率 3D 占用情况，为刚性边界框或参数模型提供灵活的、与类别无关的替代方案。这些 4D 控件被渲染为预训练视频扩散模型的调节信号，从而能够生成精确遵循指定动态的高保真、视图一致的视频。不幸的是，另一个主要挑战在于缺乏具有明确 4D 注释的大规模训练数据。我们通过开发一个自动数据引擎来解决这个问题，该引擎可以从野外视频中提取所需的 4D 控件，从而使我们能够在海量且多样化的数据集上训练我们的模型。

- **2026-01-08** **Multigroup Radiation Diffusion on a Moving Mesh: Implementation in RICH and Application to Tidal Disruption Events** [2601.05120](http://arxiv.org/abs/2601.05120)
  > 辐射流体动力学（RHD）决定了各种高能天体物理现象的整体演化和可观测发射。由于其复杂性，RHD 问题通常必须通过数值模拟来研究。我们扩展了公开可用的 RICH 代码，该代码之前在灰色通量有限扩散 (FLD) 的限制下求解 RHD 方程，以便与多组 FLD 求解器一起运行。 RICH 是一种半拉格朗日代码，可求解非结构化移动网格上的 RHD 方程，并且是第一个多组 RHD 移动网格代码，使其特别适用于具有极端动态范围和动态重要辐射力的问题。我们根据多个分析基准验证我们的多组模块，包括 RHD 多普勒项的新颖测试。代码的计算效率得到了一种加速光学厚单元收敛的新方案的帮助。最后，我们使用 $10^4 M_\odot$ 中等质量黑洞，将多群 RICH 应用于恒星潮汐破坏事件 (TDE) 的试点研究。我们的模拟在峰值光学/紫外光之前自洽地产生明亮的早期 X 射线闪光，与超大质量黑洞 TDE 的（灰色）RICH 模拟的后处理以及 TDE AT 2022dsb 的 X 射线观测定性一致。

- **2026-01-08** **From Rays to Projections: Better Inputs for Feed-Forward View Synthesis** [2601.05116](http://arxiv.org/abs/2601.05116)
  > 前馈视图合成模型以最小的 3D 归纳偏差一次性预测新视图。现有的工作将相机编码为普吕克射线图，它将预测与任意世界坐标规范联系起来，并使它们对小型相机变换敏感，从而破坏了几何一致性。在本文中，我们询问什么输入最适合模型以实现稳健且一致的视图合成。我们提出了投影调节，它用提供稳定 2D 输入的目标视图投影提示替换原始相机参数。这将任务从光线空间中的脆弱几何回归问题重新构建为条件良好的目标视图图像到图像转换问题。此外，我们引入了针对此线索量身定制的屏蔽自动编码预训练策略，从而可以使用大规模未校准数据进行预训练。与视图一致性基准上的光线条件基线相比，我们的方法显示出更高的保真度和更强的跨视图一致性。它还在标准新颖视图合成基准上实现了最先进的质量。

- **2026-01-08** **How Dark is Dark? A Reflectance and Scattering Analysis of Black Materials** [2601.05094](http://arxiv.org/abs/2601.05094)
  > 黑色材料在图像配准、相机校准、杂散光抑制和视觉设计等应用中发挥着至关重要的作用。尽管许多此类材料在漫射照明下看起来相似地较暗，但它们的反射率行为可能会因观察和照明几何形状而有很大差异。超黑材料可实现出色的光衰减，但通常受到成本和机械脆弱性的限制，这促使人们评估更坚固、更易于使用的替代品。在本研究中，我们采用测角测量系统来捕获一系列黑色材料的各向同性双向反射率分布函数，包括超黑参考 Vantablack、Musou Black 和黑色天鹅绒等市售替代品以及标准哑光黑色涂层。我们根据漫反射和镜面散射以及总积分散射来分析它们的反射特性，以量化与角度相关的反射。此外，我们使用由测量的 BRDF 驱动的基于物理的渲染和对感知黑暗的心理物理学评估来比较它们的感知外观。这些分析共同提供了对黑色材料的全面评估，将反射特性与视觉外观和感知性能联系起来，从而为光学应用提供明智的材料选择。

- **2026-01-08** **A high order accurate and provably stable fully discrete continuous Galerkin framework on summation-by-parts form for advection-diffusion equations** [2601.05071](http://arxiv.org/abs/2601.05071)
  > 我们提出了一种高阶精确的完全离散数值方案，用于在基于连续伽辽金 (CG) 的有限元框架内求解初始边值问题 (IBVP)。这里考虑按部分求和（SBP）形式的空间和时间近似。使用同时逼近项 (SAT) 技术弱施加初始条件和边界条件。由此产生的 SBP-SAT 公式根据初始和外部边界数据产生能量估计，从而在空间和时间上实现能量稳定的离散化。使用制造解决方案（MMS）的方法对所提出的方法进行数值评估。该方案在空间和时间方向上实现了超收敛，对于 $p\geq 2$，精度为$\mathcal{O}(p+2)$，其中$p$ 指的是拉格朗日基的阶数。在一个应用案例中，我们表明，即使在粗网格上，完全离散的公式也能有效地捕获时空变化，从而证明了该方法的计算有效性。

- **2026-01-08** **Quantitative mapping from conventional MRI using self-supervised physics-guided deep learning: applications to a large-scale, clinically heterogeneous dataset** [2601.05063](http://arxiv.org/abs/2601.05063)
  > 磁共振成像 (MRI) 是临床神经影像的基石，但传统 MRI 提供的定性信息严重依赖于扫描仪硬件和采集设置。虽然定量 MRI (qMRI) 提供了内在的组织参数，但对专门采集协议和重建算法的要求限制了其可用性并阻碍了大规模生物标志物研究。本研究提出了一种自监督物理引导深度学习框架，可直接从广泛使用的临床常规 T1 加权、T2 加权和 FLAIR MRI 推断定量 T1、T2 和质子密度 (PD) 图。该框架在大规模临床异构数据集上进行了训练和评估，该数据集包括我们机构六年来在四个不同 3 T MRI 扫描仪系统上采集的 4,121 个扫描会话，捕获了真实世界的临床变异性。该框架将基于 Bloch 的信号模型直接集成到训练目标中。在 600 多次测试中，生成的图显示出与文献范围一致的白质和灰质值。此外，生成的图显示扫描仪硬件和采集协议组的不变性，组间变异系数 $\leq$ 1.1%。针对特定对象的分析表明，扫描仪系统和序列参数具有出色的体素重现性，T1 和 T2 的 Pearson $r$ 和一致性相关系数超过 0.82。所有定量参数的平均相对体素差异都很低，尤其是 T2（$<$ 6%）。这些结果表明，所提出的框架可以稳健地将各种临床常规 MRI 数据转换为定量图，可能为大规模定量生物标志物研究铺平道路。

- **2026-01-08** **The Initial Value Problem for the Generalised Einstein Equations** [2601.05041](http://arxiv.org/abs/2601.05041)
  > 我们讨论了闭散度情况下希钦广义几何中的爱因斯坦方程的初值问题（对应于 II 型十维超重力中 NS-NS 扇区的玻色子部分的运动方程），并建立了最大全局双曲展开（MGHD）的存在性。在 $n+1$ 维流形上定义的动力场是时空度量、称为膨胀函数的标量场和称为 $B$ 场的两种形式。我们开发了洛伦兹规范的推广，将其应用于 $B$ 场（并与打破微分同胚不变性的合适规范条件相结合），使系统成为一个波动方程，其主要符号由（动态）度量给出。给定初始数据，我们构建满足规范条件的发展。我们表明，所有其他发展都（在适当的意义上）通过微分同胚与这种发展相关，从而建立了几何唯一性。 MGHD 的存在源于 Choquet-Bruhat 和 Geroch 的著名结果。   在展示发展的存在性和几何唯一性时，我们遵循 Ringström 为与标量场耦合的爱因斯坦方程详细开发的方法。在初步部分中，我们提出了一种与对该问题所做的具体假设无关的表述，因此可以直接适应其他系统。

- **2026-01-08** **Patch-based Representation and Learning for Efficient Deformation Modeling** [2601.05035](http://arxiv.org/abs/2601.05035)
  > 在本文中，我们提出了一种基于面片的表面表示形式 PolyFit，它是通过在表面面片上局部拟合射流函数而获得的。这种表示可以以有监督的方式从分析函数和真实数据中有效地学习。一旦学习，它就可以推广到各种类型的表面。使用 PolyFit，可以通过更新一组紧凑的射流系数来有效地使表面变形，而不是针对计算机视觉和图形中的许多下游任务优化每个顶点的自由度。我们通过两种应用展示了我们提出的方法的功能：1）模板形状（SfT）：目标是使图像/视频中看到的对象的输入 3D 模板变形。使用 PolyFit，我们采用测试时优化，可提供具有竞争力的准确性，同时明显快于基于离线物理的求解器，并且在适度的额外运行时间下，其准确性优于最新的物理引导神经模拟器。 2）服装立体裁剪。我们训练了一个自我监督的、与网格和服装无关的模型，该模型可以概括分辨率和服装类型，提供比强基线快一个数量级的推理。

- **2026-01-08** **OceanSplat: Object-aware Gaussian Splatting with Trinocular View Consistency for Underwater Scene Reconstruction** [2601.04984](http://arxiv.org/abs/2601.04984)
  > 我们介绍了 OceanSplat，这是一种基于 3D 高斯分布的新颖方法，用于准确表示水下场景中的 3D 几何形状。为了克服水下光学退化引起的多视图不一致，我们的方法通过渲染相对于每个输入视图的水平和垂直平移的相机视图并通过反向扭曲对齐它们来强制三目视图一致性。此外，这些平移的相机视图用于通过三角测量之前导出合成极线深度，其充当自监督深度正则化器。这些几何约束有助于 3D 高斯的空间优化并保留水下环境中的场景结构。我们还提出了一种深度感知的 alpha 调整，该调整在早期训练期间根据 3D 高斯的 $z$ 分量和观察方向调节 3D 高斯的不透明度，从而阻止介质诱导图元的形成。通过我们的贡献，3D 高斯从散射介质中解脱出来，实现了对象几何形状的稳健表示，并显着减少了重建水下场景中的浮动伪影。对真实水下和模拟场景的实验表明，OceanSplat 在散射介质中的场景重建和恢复方面远远优于现有方法。

- **2026-01-07** **A Single-Loop Bilevel Deep Learning Method for Optimal Control of Obstacle Problems** [2601.04120](http://arxiv.org/abs/2601.04120)
  > 障碍问题的最优控制出现在广泛的应用中，并且由于其非平滑性、非线性和双层结构而在计算上具有挑战性。经典数值方法依赖于基于网格的离散化，通常需要解决一系列代价高昂的子问题。在这项工作中，我们提出了一种单循环双层深度学习方法，该方法是无网格的，可扩展到高维和复杂领域，并避免重复求解离散子问题。该方法采用约束嵌入神经网络来近似状态并控制并保留双层结构。为了有效地训练神经网络，我们提出了一种单循环随机一阶双层算法（S2-FOBA），该算法消除了嵌套优化，并且不依赖于限制性的较低级别唯一性假设。我们在温和的假设下分析了 S2-FOBA 的收敛行为。对基准示例（包括复杂域上规则和不规则障碍物的分布式障碍控制问题）的数值实验表明，与经典数值方法相比，该方法取得了令人满意的精度，同时降低了计算成本。

- **2026-01-07** **A constrained-transport embedded boundary method for compressible resistive magnetohydrodynamics** [2601.04099](http://arxiv.org/abs/2601.04099)
  > 近年来人们对脉冲功率磁惯性聚变装置的兴趣日益浓厚，我们提出了一种在笛卡尔网格上实现任意形状的嵌入边界，同时求解可压缩电阻磁流体动力学方程的方法。该方法是围绕方程的有限体积公式构建的，其中黎曼求解器用于计算网格单元之间的面上的通量，以及归纳方程的面心约束输运公式。通过始终计算笛卡尔网格的面和边缘上的通量，可以避免与切割单元相关的小时间步长问题。我们扩展了该方法，使用幻影流体方法来模拟两种具有不同属性的材料之间的移动界面，并展示了一些初步结果，包括磁流体静力学平衡的冲击波驱动和磁驱动动态压缩。我们对该方法进行了彻底的验证，并表明它在没有不连续性的情况下以二阶收敛，在材料属性不连续的情况下以一阶收敛。

- **2026-01-07** **A higher order sparse grid combination technique** [2601.04075](http://arxiv.org/abs/2601.04075)
  > 我们证明了一种广义稀疏网格组合技术，它将有限差分解的多元外推与标准组合公式相结合，将规则网格上的二阶精确方案提升为四阶组合稀疏网格解。在分析中，在一般维度上工作，我们将方案的多元误差展开中的所有项表征为一系列半离散问题的解。首先在对方案的截断误差、解的稳定性和规律性的适当假设下正式进行。然后，我们用平滑数据验证泊松问题示例的假设，并说明最多七个维度的实际收敛。

- **2026-01-07** **LinkD: AutoRegressive Diffusion Model for Mechanical Linkage Synthesis** [2601.04054](http://arxiv.org/abs/2601.04054)
  > 由于连续节点放置、离散拓扑配置和非线性运动学约束之间的复杂耦合，设计机械连杆以实现目标末端执行器轨迹提出了根本性挑战。高度非线性的运动与配置关系意味着关节位置的小扰动会极大地改变轨迹，而组合扩展的设计空间使得传统的优化和启发式方法在计算上变得难以处理。我们引入了一种自回归扩散框架，该框架通过将机制表示为顺序构造的图来利用连杆组装的二元性质，其中节点对应于关节，边缘对应于刚性连杆。我们的方法将因果变换器与去噪扩散概率模型（DDPM）相结合，两者都以通过变换器编码器编码的目标轨迹为条件。因果变换器自回归逐节点预测离散拓扑，而 DDPM 则细化每个节点的空间坐标和与先前生成的节点的边缘连接。这种顺序生成实现了自适应试错综合，其中表现出运动锁定或碰撞的有问题的节点可以选择性地重新生成，从而允许在设计期间自主纠正简并配置。我们基于图形的数据驱动方法超越了传统的优化方法，实现了可扩展的逆向设计，可推广到具有任意节点数的机制。我们展示了包含多达 20 个节点的链接系统的成功综合，并且可扩展至 N 节点架构。这项工作推进了自回归图生成方法和计算运动学综合，为复杂机械系统的可扩展逆向设计建立了新的范例。

- **2026-01-07** **Effects of Horizontal Discretization on Triangular and Hexagonal Grids on Linear Baroclinic and Symmetric Instabilities** [2601.04013](http://arxiv.org/abs/2601.04013)
  > 由于全球海洋环流模型是在允许涡流的分辨率下运行的，因此在选择运动方程的离散化时，准确再现斜压不稳定性的增长率是一个主要问题。从这个角度来看，我们分析了几种海洋环流模型中使用的具有不同类型变量交错的三角形和六边形网格上的离散化。通过将 Eady 配置中的线性斜压不稳定性分析扩展到更复杂网格上的离散化，揭示了一些数值上的微妙之处。与四边形网格上的离散化相比，分析的离散化对于不稳定的杂散模式（部分由网格几何形状产生）的鲁棒性较差。一些微妙之处的出现是因为交错三角形和六边形网格上的杂散模式不遵守伽利略不变性。因此，它们的增长率表现出对背景流和网格之间的对齐以及均匀背景流的强度的依赖性。与寄生模式的相互作用在对称不稳定性轴上变得更加重要，其中不稳定的物理分支和寄生分支在波数空间中更难以分离。我们的分析表明，在大多数情况下，适度的双调和粘度和扩散会抑制虚假分支。然而，为了实现这一目标，需要仔细校准每个考虑的离散化的粘度和扩散率参数。

- **2026-01-07** **PosterVerse: A Full-Workflow Framework for Commercial-Grade Poster Generation with HTML-Based Scalable Typography** [2601.03993](http://arxiv.org/abs/2601.03993)
  > 商业级海报设计需要将审美吸引力与精确、信息丰富的内容传递无缝结合。当前的自动海报生成系统面临着重大限制，包括不完整的设计工作流程、文本渲染精度差以及商业应用灵活性不足。为了应对这些挑战，我们提出了 PosterVerse，这是一种完整工作流程的商业级海报生成方法，可以无缝地自动化整个设计过程，同时提供高密度和可扩展的文本渲染。 PosterVerse 通过三个关键阶段复制专业设计：(1) 使用微调的 LLM 创建蓝图，从用户需求中提取关键设计元素，(2) 通过定制的扩散模型生成图形背景，以创建视觉上吸引人的图像，以及 (3) 使用 MLLM 支持的 HTML 引擎进行统一的布局文本渲染，以保证高文本准确性和灵活的定制。此外，我们还推出了 PosterDNA，这是一个商业级的、基于 HTML 的数据集，专为训练和验证海报设计模型而定制。据我们所知，PosterDNA是第一个引入HTML排版文件的中文海报生成数据集，实现可扩展的文本渲染，从根本上解决渲染小而高密度文本的挑战。实验结果表明，PosterVerse 始终能够生成具有吸引人的视觉效果、准确的文本对齐和可定制布局的商业级海报，使其成为自动化商业海报设计的有前途的解决方案。代码和模型可在 https://github.com/wuhaer/PosterVerse 获取。

- **2026-01-07** **Cavity-Driven Multispectral Gain for High-Sensitivity NV Center Magnetometers** [2601.03975](http://arxiv.org/abs/2601.03975)
  > 我们报告了一种基于 NV 系综与介电腔耦合的腔式固态磁力计，实现了 12 pT/ $\sqrt{\rm{Hz}}$ 灵敏度和多光谱特征近三倍的增益。这些特征源于腔引起的 NV 超精细能级分裂，并利用系统双修饰状态中强大的量子相干性来实现高灵敏度。我们预测模拟的近期灵敏度接近 100 fT/$\sqrt{\rm{Hz}}$ ，接近约翰逊-奈奎斯特极限。我们的结果将频率复用确立为一种新的操作范例，为环境条件下的计量提供强大且可扩展的量子资源。

- **2026-01-07** **Computing the Intrinsic Delaunay Triangulation of a Closed Polyhedral Surface** [2601.03954](http://arxiv.org/abs/2601.03954)
  > 每个本质上是多面体的表面都可以用门户边形来表示：欧几里得平面中的多边形集合，并抽象地标识出一些对等长的边。虽然这种表示形式可以说比网格（R3 中的平面多边形形成表面）更简单，但它具有无限的快乐：表面中的最短路径可以任意多次访问同一个多边形。这种病态行为是高效算法的障碍。另一方面，Löffler、Ophelders、Staals 和 Silveira (SoCG 2023) 最近证明，（内在的）Delaunay 三角剖分具有有限的幸福感。   在本文中，给定一个由三角形入口边 T 表示的闭合多面体曲面 S，我们提供了一种算法来计算 S 的 Delaunay 三角剖分，其顶点是 S 的奇点（包围角不同于 2pi 的点）。我们算法的时间复杂度是三角形数量和 T 的纵横比 r 对数的多项式。在我们的计算模型中，我们表明 log(r) 中的依赖性是不可避免的。我们的算法可用于在计算三角形门户网站表面上的最短路径之前对其进行预处理，并确定两个三角形门户网站的表面是否等距。

- **2026-01-07** **A laser plasma soliton fusion scheme** [2601.03943](http://arxiv.org/abs/2601.03943)
  > 我们引入了一种由激光等离子体孤子实现的新型聚变方案，该方案有望克服达到盈亏平衡条件的几个基本障碍。具体而言，我们使用氘氚（DT）作为燃料。孤立子内部的强电磁场显着增强了 DT 聚变截面，其有质动力势能疏散电子，并将 D/T 加速到适合聚变反应的动能。虽然电子几乎立即被排出，但更重的 D/T 以皮秒时间尺度移动。这种时间尺度的差异为DT聚变在无电子环境中有效发生提供了时间窗口。我们注入两个连续的激光，其中第一个将激发等离子体孤子，第二个更强烈且具有匹配的较低频率，将共振地增强孤子电磁场。我们施加等离子体密度梯度来诱导孤子运动。在其生命周期内被移动孤子扫过的等离子体柱内的所有 D/T 都将参与这种聚变机制。我们证明盈亏平衡条件是可以实现的。利用光纤激光器和 iCAN 激光器技术进行高重复率和高强度操作，千兆瓦输出也许是可以想象的。

- **2026-01-07** **Accelerated simulation of multiscale gas-radiation coupling flows via a general synthetic iterative scheme** [2601.03935](http://arxiv.org/abs/2601.03935)
  > 气体-辐射耦合严重影响高超声速再入流，其中极端温度会导致明显的非平衡气体和辐射热传输。因此，准确有效的辐射气体动力学模拟对于大气进入车辆热防护系统的可靠设计是必不可少的。在这项研究中，使用通用合成迭代方案（GSIS）在广泛的流动和辐射传输范围内求解了辐射气流的玻尔兹曼型动力学模型。该方法将非结构化有限体积离散速度方法与一组宏观综合方程相结合。在此框架内，动力学模型为合成方程中的本构关系提供了高阶闭包。同时，宏观综合方程驱动介观动力学系统的演化，显着加速近连续体系的稳态收敛，线性傅里叶稳定性分析证实了这一点。至关重要的是，该算法被证明是渐进保持的，可以正确恢复连续谱和光学厚度极限，由辐射纳维-斯托克斯-傅里叶方程表示，在独立于平均自由程的粗网格上控制不同的平移、旋转、振动和辐射温度。对具有挑战性的基准（包括阿波罗再入舱上的三维高超音速流）的数值模拟表明，GSIS 在辐射气流的多尺度模拟中比传统迭代方案实现了数量级的加速，同时准确捕获高超音速环境中的非平衡效应和辐射传热。

- **2026-01-06** **Muses: Designing, Composing, Generating Nonexistent Fantasy 3D Creatures without Training** [2601.03256](http://arxiv.org/abs/2601.03256)
  > 我们推出了 Muses，这是第一个无需训练的方法，可以在前馈范式中生成奇妙的 3D 生物。以前的方法依赖于零件感知优化、手动组装或 2D 图像生成，由于复杂的零件级操作和有限的域外生成的挑战，通常会产生不切实际或不连贯的 3D 资产。相比之下，Muses 利用 3D 骨架（生物形态的基本表示）来明确、合理地组成不同的元素。这个骨架基础将 3D 内容创建形式化为设计、合成和生成的结构感知管道。 Muses 首先通过图形约束推理构建一个具有连贯布局和比例的创意组合 3D 骨架。然后，该骨架在结构化潜在空间内引导基于体素的组装过程，整合来自不同对象的区域。最后，应用骨骼条件下的图像引导外观建模，为组装后的形状生成风格一致且和谐的纹理。大量的实验确立了 Muses 在视觉保真度、与文本描述的一致性以及灵活 3D 对象编辑潜力方面的最先进性能。项目页面：https://luhexiao.github.io/Muses.github.io/。

- **2026-01-06** **InfiniDepth: Arbitrary-Resolution and Fine-Grained Depth Estimation with Neural Implicit Fields** [2601.03252](http://arxiv.org/abs/2601.03252)
  > 现有的深度估计方法从根本上仅限于预测离散图像网格上的深度。这种表示将其可扩展性限制为任意输出分辨率并阻碍几何细节恢复。本文介绍了 InfiniDepth，它将深度表示为神经隐式场。通过简单而有效的局部隐式解码器，我们可以查询连续二维坐标的深度，从而实现任意分辨率和细粒度的深度估计。为了更好地评估我们方法的能力，我们从五种不同的游戏中策划了高质量的 4K 合成基准，涵盖具有丰富几何和外观细节的不同场景。大量实验表明，InfiniDepth 在相对和度量深度估计任务的合成基准和现实基准上均实现了最先进的性能，尤其是在精细细节区域中表现出色。它还有利于在大视点变化下进行新颖的视图合成任务，从而产生具有更少孔洞和伪影的高质量结果。

- **2026-01-06** **The Squeezed Bispectrum from CHIME HI Emission and Planck CMB Lensing: Current Sensitivity and Forecasts** [2601.03240](http://arxiv.org/abs/2601.03240)
  > 如果信号能够成功地从极其明亮的无线电前景发射中分离出来，那么使用原子氢 (HI) 进行线强度映射就有可能有效地绘制大面积的宇宙图。这激发了互相关性，以确定测量的 HI 波动的宇宙学性质，并研究它们与星系和底层物质密度场的联系。然而，这些相同的前景使得与投影场（例如宇宙微波背景（CMB）的透镜效应）的互相关变得困难。事实上，相关的傅里​​叶模式沿着视线缓慢变化，因此最容易受到平滑频谱无线电连续谱前景的污染。在本文中，我们实施了一种避免此问题的方法，尝试使用大规模普朗克 CMB 透镜来测量加拿大氢强度测绘实验 (CHIME) 的小规模 21cm 功率的非线性引力耦合。该测量是位置相关的功率谱，即压缩积分双谱。使用 94 个夜晚 1.0 < z < 1.3$ 之间的 CHIME 数据以及积极的前景过滤，我们发现预期信号比当前噪声小五倍。我们预测，合并已收集的额外夜晚的 CHIME 数据将使信噪比达到 3，而无需进一步改进前景清理的过滤。

- **2026-01-06** **Stability, convergence, and geometric properties of second-order-in-time space-time discretizations for linear and semilinear wave equations** [2601.03160](http://arxiv.org/abs/2601.03160)
  > 我们通过建立与时间一阶公式的精确等价，重新审视线性和半线性波动方程的二阶时空离散。重点关注使用时间连续分段多项式试验函数的方案，我们分析了它们的稳定性、收敛性和几何特性。我们首先考虑弱时空公式，其中测试函数投影到时间上低一级的不连续多项式上，表明它等效于线性情况下 [French, Peterson 1996] 中提出的方案，并在 [Karakashian, Makridakis 2005] 中扩展到半线性情况。特别是，这种等价表明该方法在网格节点处能量守恒，但不是辛的。然后，我们引入通过高斯-勒让德和高斯-洛巴托时间求积获得的两个辛变体，并表明它们对应于特定的龙格-库塔时间积分器。这些联系阐明了所考虑的时空方法的几何结构。

- **2026-01-06** **Stroke Patches: Customizable Artistic Image Styling Using Regression** [2601.03114](http://arxiv.org/abs/2601.03114)
  > 我们提出了一种新颖的、基于回归的方法来对图像进行艺术造型。与最近的神经风格转移或基于扩散的方法不同，我们的方法允许通过使用一组可扩展的笔画补丁来显式控制渲染图像中的笔画组成和细节级别。笔划补丁集是由小程序按程序生成的，这些程序控制各个补丁中笔划的形状、大小、方向、密度、颜色和噪声级别。一旦在一组笔划补丁上进行训练，基于 U-Net 的回归模型就可以以各种不同的、令人回味的和可定制的风格渲染任何输入图像。

- **2026-01-06** **Flow Matching and Diffusion Models via PointNet for Generating Fluid Fields on Irregular Geometries** [2601.03030](http://arxiv.org/abs/2601.03030)
  > 我们提出了两种新颖的生成几何深度学习框架，称为 Flow Matching PointNet 和 Diffusion PointNet，用于通过将 PointNet 分别纳入流匹配和扩散模型来预测不规则几何形状上的流体流动变量。在这些框架中，反向生成过程根据看不见的几何形状的标准高斯噪声重建物理场。所提出的方法直接对计算域的点云表示（例如，有限体积网格的网格顶点）进行操作，因此避免了用于将几何形状投影到均匀晶格上的像素化​​的限制。与基于图神经网络的扩散模型相比，Flow Matching PointNet 和 Diffusion PointNet 在预测场中不会表现出高频噪声伪影。此外，与需要辅助中间网络来调节几何形状的方法不同，所提出的框架仅依赖于 PointNet，从而形成简单且统一的架构。所提出的框架的性能是在通过圆柱体的稳定不可压缩流上进行评估的，使用通过改变圆柱体的横截面形状和跨样本的方向构建的几何数据集。结果表明，与具有相同数量可训练参数的普通 PointNet 相比，Flow Matching PointNet 和 Diffusion PointNet 可以更准确地预测速度和压力场以及升力和阻力，并且对不完整的几何形状表现出更高的鲁棒性。

- **2026-01-06** **Linear Script Representations in Speech Foundation Models Enable Zero-Shot Transliteration** [2601.02906](http://arxiv.org/abs/2601.02906)
  > Whisper 等多语言语音基础模型是在网络规模数据上进行训练的，其中每种语言的数据由无数的区域变体组成。然而，不同的地区品种常常采用不同的文字来书写相同的语言，使得语音识别输出也受到输出文字的非确定性的影响。为了缓解这个问题，我们证明脚本在多语言语音模型的激活空间中进行线性编码，并且在推理时修改激活可以直接控制输出脚本。我们发现，即使在非常规的语言-脚本配对中（例如西里尔字母中的意大利语和拉丁字母中的日语），在测试时将此类脚本向量添加到激活中也可以引起脚本更改。我们应用这种方法来诱导对语音识别输出脚本的事后控制，我们观察 Whisper 所有模型大小的竞争性能。

- **2026-01-06** **Resolution deficits drive simulator sickness and compromise reading performance in virtual environments** [2601.02829](http://arxiv.org/abs/2601.02829)
  > 扩展现实 (XR) 正在发展成为通用计算平台，但其在生产力方面的采用却因视觉疲劳和模拟器眩晕症而受到阻碍。虽然这些症状通常归因于延迟或运动冲突，但文本清晰度对生理舒适度的确切影响仍不清楚。在这里，我们表明，在虚拟现实和视频透视环境中的阅读任务期间，次优的有效分辨率（即在完整的显示光学渲染管道之后到达眼睛的清晰度）是导致模拟器晕眩的主要驱动因素。通过在统一的 logMAR 量表上系统地操纵端到端有效分辨率，我们在一项受控的受试者内研究中测量了阅读心理物理学和疾病症状。我们发现，当分辨率降至 0 logMAR（正常视力）以下时，阅读性能和用户舒适度呈指数下降。值得注意的是，我们的结果表明 0 logMAR 是一个关键的生理临界点：优于该阈值的分辨率可产生肉眼水平的性能，同时将不适感降至最低，而较差的分辨率会引发恶心和动眼神经紧张的快速、非线性增加。这些发现表明，解决模糊文本所需的认知和感知工作直接损害了用户的舒适度，从而将人眼分辨率确立为未来人体工学 XR 系统设计的关键基线。

- **2026-01-06** **Towards Zero-Shot Point Cloud Registration Across Diverse Scales, Scenes, and Sensor Setups** [2601.02759](http://arxiv.org/abs/2601.02759)
  > 一些基于深度学习的点云配准方法难以实现零样本泛化，通常需要针对新环境进行特定于数据集的超参数调整或重新训练。我们确定了三个关键限制：（a）固定的用户定义参数（例如体素大小、搜索半径）无法在不同尺度上泛化，（b）学习的关键点检测器表现出较差的跨域可转移性，以及（c）绝对坐标放大了数据集之间的尺度不匹配。为了解决这三个问题，我们提出了 BUFFER-X，这是一种免训练的配准框架，它通过以下方式实现零样本泛化：（a）用于自动超参数估计的几何引导，（b）分布感知的最远点采样来替换学习检测器，以及（c）补丁级坐标归一化以确保尺度一致性。我们的方法采用分层多尺度匹配来提取局部、中间和全局感受野的对应关系，从而在不同的环境中实现稳健的配准。对于效率关键型应用，我们引入了 BUFFER-X-Lite，它通过早期退出策略和快速位姿求解器在保持精度的同时将总计算时间减少了 43%（相对于 BUFFER-X）。我们对一个综合基准进行评估，该基准包含 12 个涵盖物体尺度、室内和室外场景的数据集，包括异构 LiDAR 配置之间的跨传感器配准。结果表明，我们的方法可以有效地推广，无需手动调整或测试领域的先验知识。代码：https://github.com/MIT-SPARK/BUFFER-X。

- **2026-01-06** **Robust Mesh Saliency GT Acquisition in VR via View Cone Sampling and Geometric Smoothing** [2601.02721](http://arxiv.org/abs/2601.02721)
  > 可靠的 3D 网格显着性地面实况 (GT) 对于虚拟现实 (VR) 中以人为中心的视觉建模至关重要。然而，当前的3D网格显着性GT获取方法总体上与2D图像方法一致，忽略了3D几何拓扑和2D图像阵列之间的差异。当前的 VR 眼球追踪管道依赖于单光线采样和欧几里得平滑，触发纹理注意力和跨间隙的信号泄漏。本文提出了一个强大的框架来解决这些限制。我们首先引入视锥采样（VCS）策略，该策略通过高斯分布射线束模拟人类中央凹感受野，以提高复杂拓扑的采样鲁棒性。此外，还开发了混合流形-欧几里德约束扩散（HCD）算法，将流形测地线约束与欧几里德尺度融合，以确保拓扑一致的显着性传播。通过减轻“拓扑短路”和混叠，我们的框架提供了与人类自然感知相一致的高保真 3D 注意力获取范例，为 3D 网格显着性研究提供了更准确、更稳健的基线。

- **2026-01-05** **On the temperature of the quantum black hole** [2601.02352](http://arxiv.org/abs/2601.02352)
  > 广义相对论的一个重要特点是，当黑洞的视界区域变得无害时，其外部就会加倍，从而产生一个因果上不相连的平行宇宙。这种复杂性在特霍夫特的统一性论证中发挥着核心作用，强调物理宇宙与其在地平线另一边的复制品之间的精确识别。然而，这导致了另一种张力，即霍金温度的两倍校正。这种差异令人担忧，因为林德勒温度是通用的并且符合贝肯斯坦-霍金熵。我们证明，如果形成相应密度矩阵的状态采用广义热场双结构，则玻尔兹曼因子的失配得到修复。这为一些有趣的讨论留下了空间。

- **2026-01-05** **Joint Semantic and Rendering Enhancements in 3D Gaussian Modeling with Anisotropic Local Encoding** [2601.02339](http://arxiv.org/abs/2601.02339)
  > 最近的工作提出使用语义特征向量扩展 3DGS，以实现同步语义分割和图像渲染。然而，这些方法通常单独处理语义和渲染分支，仅依赖 2D 监督而忽略 3D 高斯几何。此外，当前的自适应策略仅根据渲染梯度来调整高斯集，这在微妙或无纹理区域中可能是不够的。在这项工作中，我们提出了一个用于 3D 语义高斯建模的联合增强框架，该框架可以协同语义和渲染分支。首先，与传统的点云形状编码不同，我们引入了使用 Laplace-Beltrami 算子的各向异性 3D 高斯切比雪夫描述符来捕获细粒度的 3D 形状细节，从而区分具有相似外观的对象并减少对潜在噪声 2D 引导的依赖。此外，我们不只依赖渲染梯度，而是利用局部语义和形状信号自适应地调整高斯分配和球谐函数，通过选择性资源分配来提高渲染效率。最后，我们采用跨场景知识转移模块来持续更新学习的形状模式，从而实现更快的收敛和稳健的表示，而无需从头开始为每个新场景重新学习形状信息。对多个数据集的实验表明，在保持高渲染帧速率的同时，分割精度和渲染质量有所提高。

- **2026-01-05** **On Statistical Inference for Rates of Change in Spatial Processes over Riemannian Manifolds** [2601.02305](http://arxiv.org/abs/2601.02305)
  > 从部分实现或分散的数据进行空间过程的统计推断已经在从环境科学到商业和经济学的各个领域取得了巨大的发展。对相关变化率的推断最近取得了一些进展。文献仅限于欧几里得领域，其中寻求对任意位置的方向导数、沿着选定的感兴趣方向的速率进行推断。事实证明，在这些设置中，高阶率（特别是方向曲率）的推断也很有用。现代空间数据通常来自非欧几里得领域。这份手稿特别考虑了在紧凑黎曼流形上定义的空间过程。我们为矢量场上此类过程的空间变化率开发了一个全面的推理框架。在此过程中，我们形式化了过程实现的平滑性并构造了微分过程——导数和曲率过程。我们推导出确保这些过程存在的核条件，并建立由流形上的“父”高斯过程（GP）和相关微分过程组成的联合多元过程的有效性。对这些速率的预测推断是根据流形上的实现过程设计的。在实践中，流形以多面体网格的形式出现。我们的模拟实验成功地评估了在此类网格上观察到的过程的导数，验证了我们的理论发现。通过增强我们对流形上的 GP 的理解，这份手稿解锁了 GP 广泛使用的机器学习和统计学中的各种潜在应用。我们提出了一种完全基于模型的方法，用于根据流形上分散位置的部分观察或实现的数据来推断空间过程所产生的微分过程。

- **2026-01-05** **InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams** [2601.02281](http://arxiv.org/abs/2601.02281)
  > 实现持久、大规模 3D 视觉几何理解的宏伟愿景受到可扩展性和长期稳定性的不可调和的需求的束缚。虽然像 VGGT 这样的离线模型实现了鼓舞人心的几何功能，但它们基于批处理的性质使它们与实时系统无关。流媒体架构虽然是实时操作的预期解决方案，但已被证明是不够的。现有方法要么无法支持真正的无限范围输入，要么遭受长序列的灾难性漂移。我们用 InfiniteVGGT 打破了这个长期存在的困境，InfiniteVGGT 是一种因果视觉几何变换器，通过有界但自适应且永久表达的 KV 缓存来操作滚动内存的概念。利用这一点，我们设计了一种无需训练、与注意力无关的修剪策略，可以智能地丢弃过时的信息，有效地在每个新帧中“滚动”记忆。 InfiniteVGGT 与 FlashAttention 完全兼容，最终缓解了这种妥协，实现了无限范围的流式传输，同时在长期稳定性方面优于现有的流式传输方法。对这样一个系统的最终测试是其在真正无限范围内的性能，由于缺乏极其长期、连续的基准，这种能力不可能得到严格验证。为了解决这一关键差距，我们引入了 Long3D 基准，该基准首次能够对大约 10,000 帧的序列进行连续 3D 几何估计的严格评估。这为长期 3D 几何理解的未来研究提供了明确的评估平台。代码位于：https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT

- **2026-01-05** **DiffProxy: Multi-View Human Mesh Recovery via Diffusion-Generated Dense Proxies** [2601.02267](http://arxiv.org/abs/2601.02267)
  > 从多视图图像中恢复人体网格面临着一个根本性的挑战：现实世界的数据集包含不完美的真实注释，这会影响模型的训练，而具有精确监督的合成数据则受到域差距的影响。在本文中，我们提出了 DiffProxy，这是一种新颖的框架，可以生成用于网格恢复的多视图一致的人类代理。 DiffProxy 的核心是利用基于扩散的生成先验来连接综合训练和现实世界的泛化。其主要创新包括：（1）用于生成多视图一致、像素对齐的人体代理的多条件机制； （2）手部细化模块，结合灵活的视觉提示，增强局部细节； (3) 一种不确定性感知测试时间缩放方法，可提高优化过程中对挑战性情况的鲁棒性。这些设计确保网格恢复过程有效地受益于基于扩散的管道的精确合成地面实况和生成优势。 DiffProxy 完全基于合成数据进行训练，在五个现实世界基准测试中实现了最先进的性能，展示了强大的零样本泛化能力，特别是在具有遮挡和部分视图的挑战性场景上。项目页面：https://wrk226.github.io/DiffProxy.html

- **2026-01-05** **Unraveling MMDiT Blocks: Training-free Analysis and Enhancement of Text-conditioned Diffusion** [2601.02211](http://arxiv.org/abs/2601.02211)
  > 基于变压器的扩散模型的最新突破，特别是多模态扩散变压器 (MMDiT) 驱动的模型（如 FLUX 和 Qwen Image），促进了文本到图像生成和编辑方面令人兴奋的体验。为了理解基于 MMDiT 的模型的内部机制，现有方法试图分析位置编码和注意力层等特定组件的效果。然而，对不同块及其与文本条件的相互作用如何促进合成过程的全面理解仍然难以实现。在本文中，我们首先开发一个系统管道，通过删除、禁用和增强相应块的文本隐藏状态来全面研究每个块的功能。我们的分析表明，1）语义信息出现在较早的块中，更精细的细节在后面的块中呈现，2）删除特定块通常比禁用文本条件的破坏性更小，3）增强选择性块中的文本条件可以改善语义属性。基于这些观察，我们进一步提出了新颖的免训练策略，以改进文本对齐、精确编辑和加速。大量的实验表明，我们的方法优于各种基线，并且在文本到图像生成、图像编辑和推理加速方面保持灵活性。我们的方法在 SD3.5 上将 T2I-Combench++ 从 56.92% 提高到 63.00%，将 GenEval 从 66.42% 提高到 71.63%，而不会牺牲合成质量。这些结果促进了对 MMDiT 模型的理解，并提供了宝贵的见解，以释放进一步改进的新可能性。

- **2026-01-05** **Density-based topology optimization for turbulent fluid flow using the standard k-epsilon RANS model with wall-functions imposed through an implicit wall penalty formulation** [2601.02202](http://arxiv.org/abs/2601.02202)
  > 湍流对边界附近的网格要求很高，以保证精度。在拓扑优化 (TO) 的背景下，如此精细的网格变得不切实际，并且通用方法因精度低和边界层厚度高估而受到阻碍。壁函数是缓解计算要求的自然方法，但由于分散的设计参数化，它们并不是自然地强加在基于密度的 TO 中。我们提出了雷诺平均纳维斯托克斯 (RANS) 的隐式壁函数公式，这是标准 k-epsilon 模型，直接从设计变量的梯度中提取壁法线信息，并启用基于惩罚的公式，将壁函数强加到 RANS 方程中，而不需要贴体网格。该方法为高雷诺数湍流拓扑优化提供了可靠的途径，提供了与显式壁体拟合分析相当的边界层精度，同时保留了基于密度的 TO 的灵活性。此外，由于壁效应是使用壁函数建模的，因此可以在较粗糙的网格上获得准确的解，从而显着降低计算成本。该方法在雷诺数高达 Re = 2e5 的三个规范基准上进行了验证：弯管； U 形弯头；和特斯拉阀门。在所有情况下，所提出的方法都能准确地恢复近壁速度剖面，与具有显式壁函数的贴体网格的验证模拟紧密匹配。相比之下，传统的湍流 TO 公式如果没有建议的壁函数处理，会错误地预测边界层的发展并产生次优结果。

- **2026-01-05** **Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts** [2601.02144](http://arxiv.org/abs/2601.02144)
  > 专家混合 (MoE) 架构通过使用参数“路由器”将令牌分派给稀疏的专家子集，有效地扩展大型语言模型。通常，该路由器经过一次训练，然后就被冻结，导致路由决策在分布变化时变得脆弱。我们通过引入 kNN-MoE 来解决这一限制，kNN-MoE 是一种检索增强的路由框架，可重用来自过去类似案例记忆的最佳专家分配。该内存是通过直接优化 token-wise 路由 logits 来离线构建的，以最大化参考集的可能性。至关重要的是，我们使用检索到的邻居的聚合相似度作为置信驱动的混合系数，从而允许该方法在没有找到相关情况时回退到冻结路由器。实验表明 kNN-MoE 的性能优于零样本基线，并且可以与计算成本高昂的监督微调相媲美。

- **2026-01-05** **HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures** [2601.02103](http://arxiv.org/abs/2601.02103)
  > 最近基于 3D Gaussian Splatting 的 3D 感知头部生成模型实现了实时、真实感和视图一致的头部合成。然而，一个根本的限制仍然存在：照明和内在外观的深度纠缠阻碍了可控的重新照明。现有的解缠结方法依赖于强假设来实现弱监督学习，这限制了它们复杂照明的能力。为了应对这一挑战，我们引入了 HeadLighter，这是一种新颖的监督框架，可以学习头部生成模型中外观和照明的物理合理分解。具体来说，我们设计了一个双分支架构，分别对光照不变的头部属性和物理接地的渲染组件进行建模。采用渐进式解缠结训练将头部外观先验逐渐注入生成架构中，并通过在受控光照条件下使用光舞台设置捕获的多视图图像进行监督。我们进一步引入了一种蒸馏策略来生成用于真实渲染的高质量法线。实验表明，我们的方法保留了高质量的生成和实时渲染，同时支持显式照明和视点编辑。我们将公开发布我们的代码和数据集。

- **2026-01-05** **360-GeoGS: Geometrically Consistent Feed-Forward 3D Gaussian Splatting Reconstruction for 360 Images** [2601.02102](http://arxiv.org/abs/2601.02102)
  > 3D 场景重建是 AR、机器人和数字孪生等空间智能应用的基础。传统的多视图立体与稀疏视点或低纹理区域作斗争，而神经渲染方法虽然能够产生高质量的结果，但需要每个场景的优化并且缺乏实时效率。显式 3D 高斯分布 (3DGS) 可实现高效渲染，但大多数前馈变体侧重于视觉质量而不是几何一致性，从而限制了空间感知任务中准确的表面重建和整体可靠性。本文提出了一种新颖的 360 度图像前馈 3DGS 框架，能够生成几何一致的高斯图元，同时保持高渲染质量。引入深度法线几何正则化，将渲染的深度梯度与法线信息结合起来，监督高斯旋转、缩放和位置，以提高点云和表面精度。实验结果表明，该方法在保持较高渲染质量的同时显着提高了几何一致性，为空间感知任务中的3D重建提供了有效的解决方案。

- **2026-01-05** **Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving** [2601.01800](http://arxiv.org/abs/2601.01800)
  > 强化学习 (RL) 在自动驾驶 (AD) 领域显示出巨大的潜力，但其易受扰动的影响仍然是现实世界部署的关键障碍。作为主要对策，对抗性训练通过在对手故意引入扰动的情况下训练 AD 代理来提高策略的稳健性。现有方法通常将交互建模为具有连续攻击的零和游戏。然而，此类设计忽视了代理和对手之间固有的不对称性，无法反映安全关键风险的稀疏性，导致所实现的鲁棒性不足以满足实际的 AD 场景。为了解决这些限制，我们引入了关键性感知的鲁棒强化学习（CARRL），这是一种新颖的对抗性训练方法，用于处理自动驾驶中稀疏的、安全关键的风险。 CARRL 由两个相互作用的部分组成：风险暴露对手 (REA) 和风险目标稳健代理 (RTRA)。我们将 REA 和 RTRA 之间的交互建模为一般和游戏，使 REA 能够专注于暴露安全关键型故障（例如碰撞），而 RTRA 则学会平衡安全性与驾驶效率。 REA 采用解耦优化机制，在预算有限的情况下更好地识别和利用稀疏的安全关键时刻。然而，这种集中攻击不可避免地导致对抗性数据的缺乏。 RTRA 通过双重重放缓冲区共同利用良性和对抗性体验来应对这种稀缺性，并在扰动下强制执行政策一致性以稳定行为。实验结果表明，与最先进的基线方法相比，我们的方法在所有情况下将碰撞率降低了至少 22.66%。

- **2026-01-05** **DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization** [2601.01784](http://arxiv.org/abs/2601.01784)
  > AIGC 技术的快速发展可以通过篡改视频中的小片段来误导观众，从而导致视频级检测不准确且缺乏说服力。因此，旨在精确定位被篡改片段的时间伪造定位（TFL）变得至关重要。然而，现有的方法往往受到\emph{局部视图}的限制，无法捕获全局异常。为了解决这个问题，我们提出了一个用于时间伪造定位的 \underline{d} 双流图学习和 \underline{d}isentanglement 框架（DDNet）。通过协调局部工件的\emph{时间距离流}和用于远程连接的\emph{语义内容流}，DDNet 可以防止全局线索被局部平滑性淹没。此外，我们引入了跟踪解缠结和适应（TDA）来隔离通用伪造指纹，并引入跨级特征嵌入（CLFE）来通过层次特征的深度融合构建强大的特征基础。 ForgeryNet 和 TVIL 基准测试表明，我们的方法在 AP@0.95 中比最先进的方法性能高出约 9%，并且跨域鲁棒性显着提高。

- **2026-01-05** **MANGO:Natural Multi-speaker 3D Talking Head Generation via 2D-Lifted Enhancement** [2601.01749](http://arxiv.org/abs/2601.01749)
  > 目前音频驱动的3D头部生成方法主要针对单扬声器场景，缺乏自然、双向的听和说交互。实现无缝对话行为（即说和听状态的流畅转换）仍然是一个关键挑战。现有的 3D 对话化身方法依赖于容易出错的伪 3D 标签，无法捕捉细粒度的面部动态。为了解决这些限制，我们引入了一种新颖的两阶段框架 MANGO，它通过交替训练来利用纯图像级监督来减轻伪 3D 标签引入的噪声，从而实现与现实世界对话行为的更好对齐。具体来说，在第一阶段，带有双音频交互模块的基于扩散的变压器对多扬声器音频的自然 3D 运动进行建模。在第二阶段，我们使用快速 3D 高斯渲染器生成高保真图像，并通过交替训练为 3D 运动提供 2D 级光度监控。此外，我们还推出了 MANGO-Dialog，这是一个高质量的数据集，包含 500 多个身份的超过 50 小时的对齐 2D-3D 对话数据。大量实验表明，我们的方法在模拟两人 3D 对话运动方面实现了卓越的准确性和真实性，显着提高了音频驱动头部说话的保真度和可控性。

- **2026-01-05** **A generalized Scharfetter-Gummel scheme for nonlocal cross-diffusion systems** [2601.01731](http://arxiv.org/abs/2601.01731)
  > 分析了多维环面上非局域交叉扩散系统的隐式欧拉有限体积格式。这些方程描述了具有排斥或吸引相互作用的种群物种的动态。该数值方案基于非局部通量项的广义 Scharfetter-Gummel 离散化。对于仅可积的核函数，该方案保留了正性、总质量和熵结构。当网格尺寸趋于零时，显示了离散解的存在性及其对连续问题解的收敛性。一个关键的困难是 Scharfetter-Gummel 近似中广义伯努利函数的简并性。这个问题可以通过证明离散费舍尔信息的统一估计来克服，这需要玻尔兹曼和拉奥熵不等式。数值模拟在一维和二维空间维度上说明了该方案的特征。


## 具生智能&自动驾驶

- **2026-01-08** **LaST $_{0}$ : Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model** [2601.05248](http://arxiv.org/abs/2601.05248)
  > 视觉-语言-动作（VLA）模型最近在机器人操作方面表现出了强大的泛化能力。一些现有的 VLA 方法试图通过在动作执行之前显式生成语言推理轨迹或未来的视觉观察来提高动作准确性。然而，显式推理通常会产生不可忽略的推理延迟，这限制了机器人操作所需的时间分辨率。此外，这种推理仅限于语言空间，造成了难以忠实地捕捉不可言喻的物理属性的表征瓶颈。为了缓解这些限制，我们提出了 LaST $_0$，这是一个框架，可以在通过潜在时空思维链 (CoT) 进行行动之前实现高效推理，捕获通常难以用语言表达的细粒度物理和机器人动态。具体来说，我们引入了一个令牌有效的潜在 CoT 空间，它可以对未来的视觉动态、3D 结构信息和机器人本体感受状态进行建模，并进一步跨时间扩展这些表示，以实现时间一致的隐式推理轨迹。此外，LaST$_0$ 采用通过 Mixture-of-Transformers 设计实现的双系统架构，其中推理专家进行低频潜在推理，代理专家根据面向机器人的潜在表示生成高频动作。为了促进协调，LaST$_0$ 使用异构操作频率进行训练，从而在部署期间实现推理和动作推理速率之间的自适应切换。在 10 个模拟任务和 6 个现实世界操作任务中，LaST$_0$ 比之前的 VLA 方法分别将平均成功率提高了 8% 和 13%，同时实现了更快的推理速度。项目网站：https://sites.google.com/view/last0

- **2026-01-08** **RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation** [2601.05241](http://arxiv.org/abs/2601.05241)
  > 操纵数据的多样性、数量和质量对于训练有效的机器人策略至关重要。然而，由于硬件和物理设置的限制，收集大规模的现实世界操作数据仍然难以在不同的环境中扩展。最近的工作使用文本提示条件图像扩散模型，通过改变视觉观察中的背景和桌面对象来增强操作数据。然而，这些方法往往忽视了最先进的政策模型所需的多视角和时间连贯观察的实际需求。此外，仅靠文本提示无法可靠地指定场景设置。为了给扩散模型提供明确的视觉指导，我们引入了视觉识别提示，它提供示例图像作为条件输入，以指导生成所需的场景设置。为此，我们还构建了一个可扩展的管道，以从大型机器人数据集中管理视觉身份池。使用我们的增强操作数据来训练下游视觉语言动作和视觉运动策略模型，可以在模拟和真实机器人设置中产生一致的性能增益。

- **2026-01-08** **Learning Latent Action World Models In The Wild** [2601.05230](http://arxiv.org/abs/2601.05230)
  > 能够在现实世界中进行推理和规划的智能体需要能够预测其行为的后果。虽然世界模型具备这种能力，但它们通常需要动作标签，而大规模获取这些标签可能很复杂。这激发了潜在动作模型的学习，该模型可以仅从视频中学习动作空间。我们的工作解决了在野外视频中学习潜在动作世界模型的问题，扩大了专注于简单机器人模拟、视频游戏或操纵数据的现有工作的范围。虽然这使我们能够捕捉更丰富的动作，但它也带来了来自视频多样性的挑战，例如环境噪声或视频中缺乏共同的体现。为了解决一些挑战，我们讨论了操作应遵循的属性以及相关的架构选择和评估。我们发现连续但受约束的潜在动作能够捕获野外视频中动作的复杂性，这是常见的矢量量化所无法做到的。例如，我们发现来自代理的环境变化（例如人类进入房间）可以通过视频传输。这凸显了学习特定于野外视频的动作的能力。在视频中缺乏共同体现的情况下，我们主要能够学习相对于相机在空间中定位的潜在动作。尽管如此，我们能够训练一个将已知动作映射到潜在动作的控制器，使我们能够使用潜在动作作为通用接口，并使用我们的世界模型解决规划任务，其性能与动作条件基线相似。我们的分析和实验为将潜在动作模型扩展到现实世界提供了一步。

- **2026-01-08** **CoV: Chain-of-View Prompting for Spatial Reasoning** [2601.05172](http://arxiv.org/abs/2601.05172)
  > 3D 环境中的实体问答 (EQA) 通常需要收集分布在多个视点且部分被遮挡的上下文。然而，最近的视觉语言模型（VLM）仅限于一组固定且有限的输入视图，这限制了它们在推理时获取与问题相关的上下文的能力，并阻碍了复杂的空间推理。我们提出了视图链 (CoV) 提示，这是一种无需训练、测试时的推理框架，可通过从粗到细的探索过程将 VLM 转变为主动的观点推理器。 CoV 首先采用视图选择代理来过滤冗余帧并识别与问题对齐的锚视图。然后，它通过将迭代推理与离散摄像机动作交织来执行细粒度视图调整，从底层 3D 场景表示中获取新的观察结果，直到收集到足够的上下文或达到步骤预算。   我们在四种主流 VLM 上的 OpenEQA 上评估 CoV，并在 LLM-Match 上获得平均 +11.56\% 的改进，在 Qwen3-VL-Flash 上获得最大 +13.62\% 的增益。 CoV 进一步展示了测试时间扩展：增加最小行动预算可带来额外的 +2.51\% 平均改进，在 Gemini-2.5-Flash 上达到 +3.73\% 的峰值。在 ScanQA 和 SQA3D 上，CoV 提供了强大的性能（例如，ScanQA 上为 116 CIDEr / 31.9 EM@1，SQA3D 上为 51.1 EM@1）。总体而言，这些结果表明，与问题对齐的视图选择与开放视图搜索相结合是一种有效的、与模型无关的策略，可在无需额外训练的情况下改进 3D EQA 中的空间推理。

- **2026-01-08** **VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control** [2601.05138](http://arxiv.org/abs/2601.05138)
  > 视频世界模型旨在模拟动态的真实世界环境，但现有方法难以对摄像机和多对象运动提供统一且精确的控制，因为视频本质上是在投影的 2D 图像平面中进行动态操作。为了弥补这一差距，我们引入了 VerseCrafter，这是一种 4D 感知视频世界模型，可以在统一的 4D 几何世界状态中对摄像机和对象动态进行明确且连贯的控制。我们的方法以新颖的 4D 几何控制表示为中心，它通过静态背景点云和每个对象的 3D 高斯轨迹对世界状态进行编码。这种表示不仅可以捕获对象的路径，还可以捕获其随时间变化的概率 3D 占用情况，为刚性边界框或参数模型提供灵活的、与类别无关的替代方案。这些 4D 控件被渲染为预训练视频扩散模型的调节信号，从而能够生成精确遵循指定动态的高保真、视图一致的视频。不幸的是，另一个主要挑战在于缺乏具有明确 4D 注释的大规模训练数据。我们通过开发一个自动数据引擎来解决这个问题，该引擎可以从野外视频中提取所需的 4D 控件，从而使我们能够在海量且多样化的数据集上训练我们的模型。

- **2026-01-08** **UniLiPs: Unified LiDAR Pseudo-Labeling with Geometry-Grounded Dynamic Scene Decomposition** [2601.05105](http://arxiv.org/abs/2601.05105)
  > 在自动驾驶应用中，未标记的 LiDAR 日志本质上是隐藏在视线中的密集 3D 几何图形的金矿，但如果没有人类标签，它们几乎毫无用处，这凸显了自主感知研究的主要成本障碍。在这项工作中，我们通过利用 LiDAR 扫描的时间几何一致性来解决这一瓶颈，将文本和 2D 视觉基础模型中的线索直接提升并融合到 3D 中，无需任何手动输入。我们引入了一种无监督的多模态伪标记方法，该方法依赖于从时间累积的 LiDAR 地图中学习到的强大几何先验，以及一种新颖的迭代更新规则，该规则强制执行联合几何语义一致性，反之亦然，检测移动对象的不一致。我们的方法同时生成 3D 语义标签、3D 边界框和密集 LiDAR 扫描，证明了跨三个数据集的强大泛化能力。我们通过实验验证我们的方法与现有的语义分割和对象检测伪标记方法相比具有优势，这些方法通常需要额外的手动监督。我们确认，即使是几何一致的致密 LiDAR 的一小部分，也能在 80-150 米和 150-250 米范围内分别将深度预测提高 51.5% 和 22.0% MAE。

- **2026-01-08** **Driving on Registers** [2601.05083](http://arxiv.org/abs/2601.05083)
  > 我们推出了 DrivoR，这是一种简单高效的基于变压器的架构，用于端到端自动驾驶。我们的方法建立在预训练的视觉变压器（ViT）的基础上，并引入了相机感知的寄存器令牌，将多相机特征压缩为紧凑的场景表示，从而在不牺牲准确性的情况下显着减少下游计算。这些令牌驱动两个轻量级变压器解码器，生成候选轨迹并对其进行评分。评分解码器学习模仿预言机并预测代表安全性、舒适性和效率等方面的可解释的子分数，从而在推理时实现行为调节驾驶。尽管设计极简，DrivoR 的性能优于或匹配 NAVSIM-v1、NAVSIM-v2 和真实感闭环 HUGSIM 基准的强大当代基准。我们的结果表明，纯变压器架构与目标令牌压缩相结合，足以实现准确、高效和自适应的端到端驱动。代码和检查点将通过项目页面提供。

- **2026-01-08** **SparseLaneSTP: Leveraging Spatio-Temporal Priors with Sparse Transformers for 3D Lane Detection** [2601.04968](http://arxiv.org/abs/2601.04968)
  > 3D 车道检测已成为自动驾驶领域的一项关键挑战，包括车道标记和 3D 路面的识别和定位。传统的 3D 方法通过密集的鸟瞰 (BEV) 特征来检测车道，但错误的转换通常会导致特征表示与真实的 3D 路面不对齐。虽然最近的稀疏车道检测器已经超越了密集的 BEV 方法，但它们完全忽视了有价值的特定于车道的先验。此外，现有方法无法利用历史车道观测，而历史车道观测有可能解决能见度较差情况下的模糊性。为了解决这些挑战，我们提出了 SparseLaneSTP，这是一种将车道结构的几何属性和时间信息集成到稀疏车道变换器中的新颖方法。它引入了一种新的特定于车道的时空注意机制，一种针对稀疏架构和时间正则化量身定制的连续车道表示。识别现有 3D 车道数据集的弱点，我们还使用简单而有效的自动标记策略引入精确且一致的 3D 车道数据集。我们的实验部分证明了我们贡献的好处，并展示了现有 3D 车道检测基准以及我们的新颖数据集上所有检测和错误指标的最先进性能。

- **2026-01-08** **Rapid emergence of overmassive black holes in the early Universe** [2601.04955](http://arxiv.org/abs/2601.04955)
  > 超大质量黑洞（SMBH）的起源仍然是天体物理学中长期存在的问题。最近的 JWST 观测结果揭示了 z>4-6 处的超大质量黑洞数量出乎意料地丰富，其中 BH 质量远高于局部标度关系，并且当前的宇宙学模型无法再现。这种超大质量黑洞如何在年轻星系中形成并快速生长仍不清楚。在这里，我们提出了完全宇宙学辐射-流体动力学模拟，该模拟首次自洽地跟踪了原星团环境中超大质量黑洞的诞生、早期生长和新兴可观测特征。我们发现 $10^6 M_\text{sun}$ 量级的重种子自然形成，超出了典型的理论预期一个数量级。这些种子迅速发育出致密、光学厚的圆盘，其强电子散射产生与小红点（LRD）中所见的广泛的 H$α$ 发射。持续的超级爱丁顿吸积随后推动快速增长至 $\sim 3 \times 10^7 ~M_\text{sun}$ by $z \sim 8$ 。这些结果提供了一个统一的物理场景，其中 LRD 对应于重种子形成的短暂、隐蔽阶段，自然演化为 JWST 检测到的超大质量类星体，并最终成为当今超大质量黑洞的前身。

- **2026-01-08** **Scaling Vision Language Models for Pharmaceutical Long Form Video Reasoning on Industrial GenAI Platform** [2601.04891](http://arxiv.org/abs/2601.04891)
  > 视觉语言模型（VLM）在多模态推理任务上表现出了强大的性能，但大多数评估都集中在短视频上，并假设计算资源不受限制。在医药内容理解等工业环境中，从业者必须在严格的 GPU、延迟和成本限制下处理长视频，而许多现有方法无法扩展。在这项工作中，我们提出了一个工业 GenAI 框架，可以处理超过 200,000 个 PDF、8 种格式（例如 MP4、M4V 等）的 25,326 个视频以及 20 多种语言的 888 个多语言音频文件。我们的研究做出了三个贡献：（i）制药领域多模态推理的工业大规模架构； (ii) 对两个领先基准（Video-MME 和 MMBench）的 40 多个 VLM 以及涵盖 14 个疾病领域的 25,326 个视频的专有数据集进行实证分析； (iii) 与长视频推理相关的四个发现：多模态的作用、注意力机制权衡、时间推理限制以及 GPU 限制下视频分割的挑战。结果显示，SDPA 对商用 GPU 的关注使效率提高了 3-8 倍，多模态改进了高达 8/12 的任务域（尤其是长度相关的任务），并清除了开源和闭源 VLM 中时间对齐和关键帧检测的瓶颈。本文不是提出新的“A+B”模型，而是描述了当前 VLM 在实际部署约束下的实际限制、权衡和故障模式，并为研究人员和从业者设计可扩展的多模态系统以实现工业领域的长格式视频理解提供了可行的指导。

- **2026-01-08** **SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models** [2601.04824](http://arxiv.org/abs/2601.04824)
  > 事件的自动识别和重复行为分析对于视频监控至关重要。然而，大多数现有的基于内容的视频检索基准侧重于场景级相似性，并没有评估监控中所需的动作辨别。为了解决这一差距，我们引入了 SOVABench（监视相反车辆行为基准），这是一个根据监控录像构建的现实世界检索基准，以与车辆相关的行为为中心。 SOVABench 定义了两种评估协议（对间和对内）来评估交叉动作辨别和时间方向理解。尽管动作区别对于人类观察者来说通常是直观的，但我们的实验表明，它们对于最先进的视觉和多模态模型仍然具有挑战性。   利用多模态大型语言模型 (MLLM) 的视觉推理和指令跟踪功能，我们提出了一个免训练框架，用于根据 MLLM 生成的图像和视频描述生成可解释的嵌入。该框架在 SOVABench 以及多个空间和计数基准上实现了强大的性能，而对比视觉语言模型经常在这些基准上失败。构建基准的代码、注释和说明是公开的。

- **2026-01-08** **Towards a Unified Theoretical Framework for Self-Supervised MRI Reconstruction** [2601.04775](http://arxiv.org/abs/2601.04775)
  > 对高分辨率、非侵入性成像的需求继续推动磁共振成像 (MRI) 的创新，但较长的采集时间阻碍了可访问性和实时应用。虽然基于深度学习的重建方法加速了 MRI 的发展，但其主要的监督范式依赖于难以获取的完全采样的参考数据。最近，自我监督学习（SSL）方法已成为有前途的替代方案，但大多数都是凭经验设计的且支离破碎。因此，我们引入 UNITS（自监督统一理论），这是自监督 MRI 重建的通用框架。 UNITS 将先前的 SSL 策略统一在一个通用的形式中，从而实现一致的解释和系统的基准测试。我们证明 SSL 可以达到与监督学习相同的预期性能。在此理论保证下，我们引入了采样随机性和灵活的数据利用，提高了域外分布下的网络泛化能力并稳定了训练。这些贡献共同将 UNITS 确立为可解释、可推广和临床适用的自监督 MRI 重建的理论基础和实践范式。

- **2026-01-07** **Radio Activity from the Rapidly Rotating T dwarf 2MASS 2228-4310** [2601.04158](http://arxiv.org/abs/2601.04158)
  > 我们使用 Karl G. Jansky 甚大阵列 (VLA) 档案数据在 C 波段 (4-8 GHz) 观测了两个观测时期（ $2\times96$ 分钟），展示了对 2MASS J22282889-4310262 (2M2228)（一颗 T6/T6.5 褐矮星）的探测。检测到 2M2228 的时间和频率平均斯托克斯 I 和 V 峰值通量密度为 $67.3\pm4.9\ μ \rm{Jy beam}^{-1}$ 和 $14.4\pm3.0\ μ\text{Jy beam}^{-1}$（第一个历元）和 $107.2\pm5.2\ μ\rm{Jy\ beam}^{-1}$ 和第二个时期的$-20.7\pm1.2\ μ\text{Jy beam}^{-1}$。这一发现构成了迄今为止在射电波长下检测到的第八个、尤其是旋转速度最快的 T 型矮星。我们的观察揭示了分数偏振比 $f_\text{c}>50$% 的高度偏振爆发。使用斯托克斯 I 光曲线，我们分别测量两个观测时期 $\sim47$ 和 $\sim58$ 分钟的发生间隔，其中第一次爆发在先前测量的中红外光度周期 $85.8\pm0.32$ 分钟的半个周期时间尺度内对齐。我们将发射归因于电子回旋脉泽发射（ECME），并将磁场强度限制为 $B\gtrsim1.4$ kG。我们强调，考虑到观测持续时间较短，推断的周期是临时的。先前证明的大气稳定性和2M2228中新检测到的射电发射相结合，使其成为一个有前途的实验室，用于测试磁层流驱动的极光模型，并指导未来协调詹姆斯·韦伯太空望远镜（JWST）和射电观测，以探索极光活动与T型褐矮星大气动力学之间的联系。

- **2026-01-07** **Wow, wo, val! A Comprehensive Embodied World Model Evaluation Turing Test** [2601.04137](http://arxiv.org/abs/2601.04137)
  > 随着世界模型在 Embodied AI 中的发展势头，越来越多的作品探索使用视频基础模型作为下游具体任务（如 3D 预测或交互式生成）的预测世界模型。然而，在探索这些下游任务之前，视频基础模型仍然有两个关键问题没有得到解答：（1）它们的生成泛化是否足以维持人类观察者眼中的感知保真度，以及（2）它们是否足够强大，可以作为现实世界具体代理的普遍先验。为了提供回答这些问题的标准化框架，我们引入了体现图灵测试基准：WoW-World-Eval (Wow,wo,val)。 Wow-wo-val 基于 609 个机器人操作数据，检查了五种核心能力，包括感知、规划、预测、泛化和执行。我们提出了一个包含 22 个指标的综合评估协议来评估模型的生成能力，其总体得分与人类偏好之间实现了较高的皮尔逊相关性（>0.93），为人类图灵测试奠定了可靠的基础。在 Wow-wo-val 上，模型在长期规划方面仅达到 17.27，在物理一致性方面最多达到 68.02，表明时空一致性和物理推理有限。对于逆动态模型图灵测试，我们首先使用 IDM 来评估视频基础模型在现实世界中的执行准确性。然而，大多数模型的成功率都下降到约 0%，而《魔兽世界》则保持了 40.74% 的成功率。这些发现表明生成的视频与现实世界之间存在明显差距，凸显了在具体人工智能中对世界模型进行基准测试的紧迫性和必要性。

- **2026-01-07** **CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos** [2601.04061](http://arxiv.org/abs/2601.04061)
  > 与丰富的人类视频演示相比，通用视觉-语言-动作模型目前受到机器人数据稀缺的阻碍。现有的潜在动作模型试图利用视频数据，但经常遭受视觉纠缠，捕捉噪音而不是操纵技能。为了解决这个问题，我们提出了对比潜在动作预训练（CLAP），这是一个将视频中的视觉潜在空间与机器人轨迹中的本体感受潜在空间对齐的框架。通过采用对比学习，CLAP 将视频转换映射到量化的、物理可执行的码本上。在此表示的基础上，我们引入了一种双公式 VLA 框架，该框架提供 CLAP-NTP（一种擅长指令跟踪和对象泛化的自回归模型）和 CLAP-RF（一种基于整流流的策略，专为高频、精确操作而设计）。此外，我们提出了一种知识匹配（KM）正则化策略，以减轻微调期间的灾难性遗忘。大量实验表明，CLAP 的性能显着优于强大的基线，能够将技能从人类视频有效转移到机器人执行。项目页面：https://lin-shan.com/CLAP/。

- **2026-01-07** **Stable Language Guidance for Vision-Language-Action Models** [2601.04052](http://arxiv.org/abs/2601.04052)
  > 视觉-语言-动作（VLA）模型在广义机器人控制方面展示了令人印象深刻的能力；然而，众所周知，它们仍然容易受到语言扰动的影响。我们发现了一种关键的“模态崩溃”现象，即强烈的视觉先验压倒了稀疏的语言信号，导致代理过度适应特定的指令短语，同时忽略了潜在的语义意图。为了解决这个问题，我们提出了 \textbf{Residual Semantic Steering (RSS)}，这是一个将物理可供性与语义执行分开的概率框架。 RSS 引入了两项理论创新：(1) \textbf{蒙特卡罗句法集成}，它通过密集的、LLM 驱动的分布扩展来近似真实的语义后验；(2) \textbf{Residual Affordance Steering}，一种双流解码机制，通过减去先验的视觉可供性来明确隔离语言的因果影响。理论分析表明，RSS 有效地最大化了行动和意图之间的相互信息，同时抑制了视觉干扰。不同操作基准的实证结果表明，RSS 实现了最先进的鲁棒性，即使在对抗性语言扰动下也能保持性能。

- **2026-01-07** **MobileDreamer: Generative Sketch World Model for GUI Agent** [2601.04035](http://arxiv.org/abs/2601.04035)
  > 移动 GUI 代理在现实世界的自动化和实际应用中显示出强大的潜力。然而，大多数现有代理仍然处于反应状态，主要根据当前屏幕做出决策，这限制了它们在长期任务中的性能。通过重复交互构建世界模型可以预测行动结果并支持移动 GUI 代理更好的决策。这是具有挑战性的，因为模型必须具有空间意识来预测动作后状态，同时保持足够的效率以进行实际部署。在本文中，我们提出了 MobileDreamer，这是一种基于世界模型的高效前瞻框架，用于根据世界模型提供的未来想象来装备 GUI 代理。它由文本草图世界模型和GUI代理的展开想象组成。文本草图世界模型通过学习过程预测动作后状态，将数字图像转换为与关键任务相关的草图，并设计一种新颖的顺序不变学习策略来保留 GUI 元素的空间信息。 GUI代理的推出想象策略通过利用世界模型的预测能力来优化动作选择过程。 Android World 上的实验表明，MobileDreamer 实现了最先进的性能，并将任务成功率提高了 5.25%。世界模型评估进一步验证了我们的文本草图建模能够准确预测关键 GUI 元素。

- **2026-01-07** **Current Agents Fail to Leverage World Model as Tool for Foresight** [2601.03905](http://arxiv.org/abs/2601.03905)
  > 基于视觉语言模型构建的智能体越来越多地面临需要预测未来状态而不是依赖短期推理的任务。生成世界模型提供了一种有希望的补救措施：智能体可以将它们用作外部模拟器，以在采取行动之前预见结果。本文实证检验了当前的智能体是否可以利用此类世界模型作为工具来增强他们的认知。在不同的代理和视觉问答任务中，我们观察到一些代理很少调用模拟（低于 1%），经常误用预测的推出（大约 15%），并且在模拟可用或强制执行时经常表现出不一致甚至性能下降（高达 5%）。归因分析进一步表明，主要瓶颈在于智能体决定何时进行模拟、如何解释预测结果以及如何将预见性融入下游推理的能力。这些发现强调需要一种机制来促进与世界模型的校准、战略交互，为未来代理系统中更可靠的预期认知铺平道路。

- **2026-01-07** **Towards Safe Autonomous Driving: A Real-Time Motion Planning Algorithm on Embedded Hardware** [2601.03904](http://arxiv.org/abs/2601.03904)
  > 确保自动驾驶车辆 (AV) 的功能安全需要运动规划模块，该模块不仅要在严格的实时约束下运行，还要在系统故障时保持可控性。现有的防护概念，例如在线验证（OV），提供了检测不可行的规划输出的安全层。然而，它们缺乏主动机制来确保在主规划器发生故障时安全运行。本文提出了针对故障操作自动驾驶（AD）的主动安全扩展的第一步。我们在运行实时操作系统 (RTOS) 的汽车级嵌入式平台上部署了基于采样的轻量级轨迹规划器。规划器在计算资源有限的情况下不断计算轨迹，为未来的应急规划架构奠定了基础。实验结果证明了具有有限延迟和最小抖动的确定性定时行为，验证了在安全认证硬件上进行轨迹规划的可行性。该研究强调了将主动后备机制整合为下一代保障框架的一个组成部分的潜力和仍然存在的挑战。代码位于：https://github.com/TUM-AVS/real-time-motion-planning

- **2026-01-07** **CSI-MAE: A Masked Autoencoder-based Channel Foundation Model** [2601.03789](http://arxiv.org/abs/2601.03789)
  > 自监督学习 (SSL) 已成为机器学习中的一项关键技术，可解决有限的标记数据、高注释成本和可变的无线信道条件等挑战。它对于开发信道基础模型 (CFM) 至关重要，该模型从信道状态信息 (CSI) 中提取潜在特征并适应不同的无线设置。然而，现有的 CFM 存在明显的缺点：严重依赖场景特定数据阻碍泛化，它们专注于单/双任务，缺乏零样本学习能力。在本文中，我们提出了 CSI-MAE，一种利用屏蔽自动编码器进行跨场景泛化的泛化 CFM。它经过 3GPP 信道模型数据集的训练，通过 CSI 感知和生成集成了传感和通信，并在不同的任务中被证明是有效的。轻量级解码器微调策略可以降低训练成本，同时保持有竞争力的性能。在这种方法下，CSI-MAE 匹配或超越了监督模型。通过全参数微调，实现了最先进的性能。其卓越的零样本可转移性也可与跨场景应用中的监督技术相媲美，从而推动无线通信创新。

- **2026-01-07** **PointWorld: Scaling 3D World Models for In-The-Wild Robotic Manipulation** [2601.03782](http://arxiv.org/abs/2601.03782)
  > 人类通过目光和身体的预期动作来预测 3D 世界将如何响应，这种能力对于机器人操作同样重要。我们引入了 PointWorld，一种大型预训练 3D 世界模型，它将共享 3D 空间中的状态和动作统一为 3D 点流：给定一个或几个 RGB-D 图像和一系列低级机器人动作命令，PointWorld 预测 3D 中响应给定动作的每像素位移。通过将动作表示为 3D 点流而不是具体实施例的动作空间（例如关节位置），该公式直接以机器人的物理几何形状为条件，同时无缝集成跨实施例的学习。为了训练我们的 3D 世界模型，我们在 3D 视觉和模拟环境的最新进展的支持下，在开放世界环境中构建了一个涵盖真实和模拟机器人操作的大型数据集，单臂 Franka 和双手类人机器人总计约 200 万条轨迹和 500 小时。通过对主干、动作表示、学习目标、部分可观察性、数据混合、域传输和缩放进行严格的大规模实证研究，我们提炼出大规模 3D 世界建模的设计原则。凭借实时（0.1秒）的推理速度，PointWorld可以有效地集成到模型预测控制（MPC）框架中进行操作。我们证明，单个预训练检查点使现实世界的 Franka 机器人能够执行刚体推动、可变形和铰接物体操作以及工具使用，无需任何演示或后期训练，所有这些都来自在野外捕获的单个图像。项目网站：https://point-world.github.io/。

- **2026-01-07** **I2E: From Image Pixels to Actionable Interactive Environments for Text-Guided Image Editing** [2601.03741](http://arxiv.org/abs/2601.03741)
  > 现有的文本引导图像编辑方法主要依赖于端到端像素级修复范例。尽管它在简单的场景中取得了成功，但这种范例在需要精确的局部控制和复杂的多对象空间推理的合成编辑任务方面仍然存在很大的困难。这种范例受到以下因素的严重限制：1) 规划和执行的隐式耦合，2) 缺乏对象级控制粒度，以及 3) 对非结构化、以像素为中心的建模的依赖。为了解决这些限制，我们提出了 I2E，一种新颖的“分解然后行动”范例，它将图像编辑重新视为结构化环境中的可操作交互过程。 I2E 利用分解器将非结构化图像转换为离散的、可操作的对象层，然后引入物理感知的视觉语言动作代理，通过思想链推理将复杂的指令解析为一系列原子动作。此外，我们还构建了I2E-Bench，这是一个专为多实例空间推理和高精度编辑而设计的基准。 I2E-Bench 和多个公共基准测试的实验结果表明，I2E 在处理复杂的组合指令、保持物理合理性和确保多轮编辑稳定性方面显着优于最先进的方法。

- **2026-01-06** **Standard Model Higgs Peaks: a Note on the Vacuum Instability during Inflation** [2601.03231](http://arxiv.org/abs/2601.03231)
  > 在标准模型中，当四次自耦合为负时，希格斯势在高场值下会变得不稳定。宇宙暴胀期间的大量子涨落可能会使希格斯场超出势垒，从而产生对我们可观测宇宙来说将是灾难性的区域。我们指出，描述希格斯值的峰值（最大值）的极值统计量是推断避免真空不稳定的条件的正确统计量。即使这一统计数据在暴涨期间对哈勃率给出了一个界限，仅比文献中普遍采用的系数强 $\sqrt{2}$ ，但它在质量上是不同的，我们认为值得传达它。

- **2026-01-06** **Enhancing Safety in Automated Ports: A Virtual Reality Study of Pedestrian-Autonomous Vehicle Interactions under Time Pressure, Visual Constraints, and Varying Vehicle Size** [2601.03218](http://arxiv.org/abs/2601.03218)
  > 自动驾驶提高了交通效率，但在复杂的港口环境中也带来了安全挑战。本研究调查环境因素、交通因素和行人特征如何影响港口自动驾驶车辆和行人之间的交互安全。通过对典型港口场景的虚拟现实 (VR) 模拟，33 名参与者在不同的能见度、车辆尺寸和时间压力条件下完成了人行横道任务。结果表明，低能见度条件、部分遮挡和较大的车辆尺寸会显着增加感知风险，促使行人等待更长时间并接受更大的间隙。具体来说，行人在与大型自动驾驶卡车排互动时往往会接受更大的间隙并等待更长的时间，这反映出由于他们感知到的威胁而更加谨慎。然而，局部障碍物也会缩短入侵后的时间，从而压缩安全裕度。年龄、性别和驾驶经验等个人属性进一步影响决策，而时间压力会破坏补偿行为并增加风险。基于这些发现，提出了安全策略，包括在多个视点安装广角摄像头、实现车辆与基础设施的实时通信、增强港口照明和标牌以及加强行人安全培训。这项研究为提高港口环境中基于视觉的自主系统的安全性和部署提供了实用的建议。

- **2026-01-06** **Limited Linguistic Diversity in Embodied AI Datasets** [2601.03136](http://arxiv.org/abs/2601.03136)
  > 语言在视觉-语言-动作（VLA）模型中起着至关重要的作用，但用于训练和评估这些系统的数据集的语言特征仍然缺乏记录。在这项工作中，我们对几个广泛使用的 VLA 语料库进行了系统的数据集审核，旨在描述这些数据集实际包含哪些类型的指令以及它们提供了多少语言多样性。我们沿着互补的维度量化教学语言，包括词汇多样性、重复和重叠、语义相似性和句法复杂性。我们的分析表明，许多数据集依赖于高度重复、类似模板的命令，结构变化有限，从而产生了狭窄的指令形式分布。我们将这些发现定位为当前 VLA 训练和评估数据中可用的语言信号的描述性文档，旨在支持更详细的数据集报告、更有原则的数据集选择以及扩大语言覆盖范围的有针对性的管理或增强策略。

- **2026-01-06** **SOP: A Scalable Online Post-Training System for Vision-Language-Action Models** [2601.03044](http://arxiv.org/abs/2601.03044)
  > 视觉-语言-动作（VLA）模型通过大规模预训练实现了很强的泛化性，但现实世界的部署除了广泛的泛用性之外还需要专家级的任务熟练程度。现有的 VLA 模型的后训练方法通常是离线的、单个机器人的或特定于任务的，限制了有效的策略适应和现实世界交互中的可扩展学习。我们引入了可扩展在线后训练（SOP）系统，该系统可以直接在物理世界中对通用 VLA 模型进行在线、分布式、多任务后训练。 SOP 通过闭环架构将执行和学习紧密结合在一起，其中一组机器人不断地将策略经验和人工干预信号传输到集中式云学习器，并异步接收更新的策略。这种设计支持及时的策略修正，通过并行部署扩展经验收集，并在适应过程中保留通用性。 SOP 与训练后算法的选择无关；我们用交互式模仿学习（HG-DAgger）和强化学习（RECAP）来实例化它。在一系列现实世界的操作任务中，包括布料折叠、盒子组装和杂货补货，我们表明 SOP 显着提高了大型预训练 VLA 模型的性能，同时保持跨任务的单一共享策略。有效的后期培训可以在现实世界交互的数小时内实现，并且性能与车队中的机器人数量几乎呈线性关系。这些结果表明，将在线学习与车队规模部署紧密结合，有助于在物理世界中实现高效、可靠和可扩展的通用机器人策略的后期培训。

- **2026-01-06** **Towards Efficient 3D Object Detection for Vehicle-Infrastructure Collaboration via Risk-Intent Selection** [2601.03001](http://arxiv.org/abs/2601.03001)
  > 车辆基础设施协同感知（VICP）对于解决自动驾驶中的遮挡问题至关重要，但通信带宽和特征冗余之间的权衡仍然是一个关键瓶颈。虽然与原始共享相比，中间融合减少了数据量，但现有框架通常依赖于空间压缩或静态置信图，这会低效地传输来自非关键背景区域的空间冗余特征。为了解决这个问题，我们提出了风险意图选择性检测（RiSe），这是一种交互感知框架，它将范式从识别可见区域转变为优先考虑风险关键区域。具体来说，我们引入了基于势场理论的势场轨迹相关模型（PTCM）来定量评估运动风险。作为补充，意图驱动区域预测模块 (IDAPM) 利用自我运动先验来主动预测和过滤对决策至关重要的关键鸟瞰 (BEV) 区域。通过集成这些组件，RiSe 实现了语义选择性融合方案，仅从高交互区域传输高保真特征，有效地充当特征降噪器。对 DeepAccident 数据集的大量实验表明，我们的方法将通信量减少到完整特征共享的 0.71%，同时保持最先进的检测精度，在带宽效率和感知性能之间建立了竞争性的帕累托前沿。

- **2026-01-06** **Beyond the Black Box: Theory and Mechanism of Large Language Models** [2601.02907](http://arxiv.org/abs/2601.02907)
  > 大型语言模型 (LLM) 的迅速出现引发了人工智能领域的深刻范式转变，带来了巨大的工程成功，对现代社会的影响日益增大。然而，当前领域中仍然存在一个关键的悖论：尽管具有实证效力，但我们对法学硕士的理论理解仍然处于不成比例的新生阶段，迫使这些系统在很大程度上被视为“黑匣子”。为了解决这种理论碎片化问题，本次调查提出了一种基于生命周期的统一分类法，将研究领域分为六个不同的阶段：数据准备、模型准备、训练、对齐、推理和评估。在此框架内，我们对驱动法学硕士绩效的基础理论和内部机制进行了系统回顾。具体来说，我们分析了核心理论问题，例如数据混合的数学合理性、各种架构的表示限制以及对齐算法的优化动态。超越当前的最佳实践，我们确定了关键的前沿挑战，包括合成数据自我改进的理论限制、安全保证的数学界限以及新兴智能的机械起源。通过将经验观察与严格的科学探究联系起来，这项工作为将法学硕士发展从工程启发法转向有原则的科学学科提供了一个结构化的路线图。

- **2026-01-06** **HOLO: Homography-Guided Pose Estimator Network for Fine-Grained Visual Localization on SD Maps** [2601.02730](http://arxiv.org/abs/2601.02730)
  > 标准清晰度 (SD) 地图上的视觉定位已成为一种有前途的低成本且可扩展的自动驾驶解决方案。然而，现有的基于回归的方法经常忽略固有的几何先验，导致训练效率不佳和定位精度有限。在本文中，我们提出了一种新颖的单应性引导姿态估计器网络，用于多视图图像和标准清晰度（SD）地图之间的细粒度视觉定位。我们通过将地面视图特征投影到 BEV 域并强制与地图特征进行语义对齐来构造满足单应性约束的输入对。然后，我们利用单应性关系来指导特征融合，并将姿势输出限制在有效的可行区域，与依赖基于注意力的融合和直接 3-DoF 姿势回归的现有方法相比，这显着提高了训练效率和定位精度。据我们所知，这是第一个将 BEV 语义推理与单应性学习相结合以进行图像到地图定位的工作。此外，通过显式地对单应性变换进行建模，所提出的框架自然地支持跨分辨率输入，从而增强了模型的灵活性。对 nuScenes 数据集的大量实验表明，我们的方法明显优于现有的最先进的视觉定位方法。代码和预训练模型将公开发布，以促进未来的研究。

- **2026-01-06** **Time-Scaling Is What Agents Need Now** [2601.02714](http://arxiv.org/abs/2601.02714)
  > 早期的人工智能范式表现出分离的认知功能：神经网络专注于“感知表征”，强化学习专注于“决策行为”，而符号人工智能则专注于“知识推理”。通过基于 Transformer 的大型模型和世界模型，这些范式正在汇聚成具有闭环“感知-决策-行动”能力的认知代理。   人类通过时间化顺序推理在有限的认知资源下解决复杂的问题。语言依赖于问题空间搜索来进行深层语义推理。虽然早期的大型语言模型（LLM）可以生成流畅的文本，但它们缺乏强大的语义推理能力。思想链 (CoT) 和思想树 (ToT) 等提示技术通过明确中间步骤来扩展推理路径。 DeepSeek-R1 等最新模型通过显式推理轨迹增强了性能。然而，这些方法在搜索完整性和效率方面存在局限性。   这凸显了对“时间缩放”的需求——随着时间的推移，系统地扩展和优化智能体展开推理的能力。时间缩放是指利用扩展时间路径的架构设计，能够实现更深入的问题空间探索、动态策略调整和增强的元认知控制，与认知约束下的人类顺序推理并行。它代表了在不成比例增加静态模型参数的情况下增强深度推理和解决问题的关键前沿。提高智能代理的能力需要将时间缩放原则放在首位，将显式时间推理管理作为基础。

- **2026-01-05** **Dynamic Synchronization of Driven Self-Oscillators: Modeling and Experiment** [2601.02584](http://arxiv.org/abs/2601.02584)
  > 在固定频率和振幅强迫下自持振荡器的同步已被很好地理解，但时变强迫如何破坏锁相的研究却少之又少。理论预测，驱动幅度或频率的缓慢、确定性调制可以导致一种特殊的同步机制，其特征是振荡相位间歇性锁定，超出与固定谐波强迫相关的阿诺德舌边界。我们在可控气动声学自振荡器（即哨子）中测试这些预测，该振荡器表现出强大的极限环，并受到具有可编程频率和幅度调制的外部声学强迫的影响。在缓慢变化的频率或强迫幅度下，观察到三种状态：（i）严格同步（ii）间歇同步，其特征是交替锁相和短暂的相滑事件，以及（iii）无同步，具有规则的相滑。特别是在严格的同步机制中，振荡器的相位将遵循任意缓慢变化的驱动相位，并且在幅度调制下，其幅度波动被强烈抑制。

- **2026-01-05** **InternVLA-A1: Unifying Understanding, Generation and Action for Robotic Manipulation** [2601.02456](http://arxiv.org/abs/2601.02456)
  > 流行的视觉-语言-动作 (VLA) 模型通常基于多模态大型语言模型 (MLLM) 构建，并在语义理解方面表现出卓越的熟练程度，但它们本质上缺乏推断物理世界动态的能力。因此，最近的方法已经转向世界模型，通常通过视频预测来制定；然而，这些方法常常缺乏语义基础，并且在处理预测错误时表现出脆弱性。为了协同语义理解与动态预测功能，我们提出了 InternVLA-A1。该模型采用统一的 Mixture-of-Transformers 架构，协调三位专家进行场景理解、视觉预见生成和动作执行。这些组件通过统一的屏蔽自注意力机制无缝交互。在 InternVL3 和 Qwen3-VL 的基础上，我们在 2B 和 3B 参数尺度上实例化 InternVLA-A1。我们在跨越 InternData-A1 和 Agibot-World 的混合合成真实数据集上预训练这些模型，覆盖超过 5.33 亿帧。这种混合训练策略有效地利用了合成模拟数据的多样性，同时最大限度地减少了模拟与真实的差距。我们通过 12 个现实世界的机器人任务和模拟基准评估了 InternVLA-A1。它的性能显着优于 pi0 和 GR00T N1.5 等领先模型，在日常任务方面实现了 14.5% 的提升，在动态设置（例如传送带分拣）方面实现了 40%-73.3% 的提升。

- **2026-01-05** **The Polarization and Magnetic Field of the Radio Arc as Observed by ALMA at 100 GHz** [2601.02297](http://arxiv.org/abs/2601.02297)
  > 40 多年来，独特的银河中心非热丝 (NTF) 一直是研究的焦点。 NTF 最突出的表现是一束平行的细丝，称为射电弧。使用甚大阵列 (VLA) 在 10 GHz 下进行的射电极化观测揭示了射电弧中的交变磁场模式，这可能是沿视线遇到多个场系统的结果，也可能是射电弧的固有特征。由于对源头进行了较大的旋转测量，这些 VLA 观测结果无法区分这些可能性。我们展示了 ALMA 100 GHz 射电弧观测结果，不受显着法拉第效应的影响。这里报告的观测结果既是 ALMA 首次用于研究 NTF，也是首次对射电弧进行 100 GHz 极化观测。我们发现相对于 NTF 细丝方向均匀旋转的磁场，旋转角度沿每根细丝的长度恒定。然而，我们发现不同的射电弧灯丝中存在系统不同的磁场方向。我们使用这种场模式来更新我们对射电弧局部视线结构的理解。我们发现从 ALMA 观测推断出的磁场可能是多个磁场系统混淆的结果，或者是因为极化集中在 NTF 细丝内。

- **2026-01-05** **CycleVLA: Proactive Self-Correcting Vision-Language-Action Models via Subtask Backtracking and Minimum Bayes Risk Decoding** [2601.02295](http://arxiv.org/abs/2601.02295)
  > 目前机器人故障检测和纠正的工作通常以事后方式进行，仅在故障发生后分析错误并应用纠正。这项工作引入了 CycleVLA，这是一个为视觉-语言-动作模型 (VLA) 配备主动自我纠正功能的系统，能够预测初期故障并在执行过程中完全显现之前进行恢复。 CycleVLA 通过集成一个进度感知 VLA（标记最常发生故障的关键子任务转换点）、一个基于 VLM 的故障预测器和规划器（在预测故障时触发子任务回溯）以及一个基于最小贝叶斯风险 (MBR) 解码的测试时间扩展策略来实现这一目标，以提高回溯后的重试成功率。大量实验表明，CycleVLA 可以提高训练有素和训练不足的 VLA 的性能，并且 MBR 可以作为 VLA 的有效零样本测试时间扩展策略。项目页面：https://dannymcy.github.io/cyclevla/

- **2026-01-05** **Agentic Retoucher for Text-To-Image Generation** [2601.02046](http://arxiv.org/abs/2601.02046)
  > SDXL 和 FLUX 等文本到图像 (T2I) 扩散模型已经实现了令人印象深刻的照片级真实感，但四肢、面部、文本等中仍然普遍存在小规模扭曲。现有的细化方法要么执行成本高昂的迭代重新生成，要么依赖空间基础薄弱的视觉语言模型（VLM），导致语义漂移和不可靠的本地编辑。为了缩小这一差距，我们提出了 Agentic Retoucher，这是一种分层决策驱动框架，它将生成后校正重新表述为类人感知-推理-行动循环。具体来说，我们设计了（1）一个感知代理，它在文本图像一致性提示下学习上下文显着性，以实现细粒度的失真定位；（2）一个推理代理，通过渐进式偏好对齐执行与人类一致的推理诊断；（3）一个动作代理，根据用户偏好指导自适应地规划局部修复。这种设计将感知证据、语言推理和可控纠正整合到一个统一的、自我纠正的决策过程中。为了实现细粒度监督和定量评估，我们进一步构建了 GenBlemish-27K，这是一个 6K T2I 图像的数据集，其中包含 12 个类别的 27K 个带注释的伪影区域。大量实验表明，Agentic Retoucher 在感知质量、失真定位和人类偏好调整方面始终优于最先进的方法，为自我校正和感知可靠的 T2I 生成建立了新的范例。

- **2026-01-05** **VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis** [2601.01989](http://arxiv.org/abs/2601.01989)
  > 行人意图预测是3级自动驾驶向4级自动驾驶过渡的关键技术之一。为了了解行人过路处的行为，应考虑几个要素和特征，以使未来的道路对每个人来说都更安全。我们引入了一种基于 Transformer/视频视觉 Transformer 的不同大小的算法，该算法使用不同的数据模态。我们在流行的行人行为数据集 JAAD 上评估了我们的算法，并达到了 SOTA 性能，并在准确度、AUC 和 F1 分数等指标上通过了 SOTA。通过广泛的消融研究，研究了不同模型设计选择带来的优势。

- **2026-01-05** **Learning Diffusion Policy from Primitive Skills for Robot Manipulation** [2601.01948](http://arxiv.org/abs/2601.01948)
  > 扩散策略（DP）最近显示出在机器人操作中产生动作的巨大前景。然而，现有的方法通常依赖于全局指令来产生短期控制信号，这可能导致动作生成中的失调。我们推测，被称为细粒度、短视野操作的原始技能，例如“向上移动”和“打开夹具”，为机器人学习提供了更直观、更有效的界面。为了弥补这一差距，我们提出了 SDP，这是一种将可解释的技能学习与条件行动计划相结合的技能条件 DP。 SDP 抽象了跨任务的八种可重用的原始技能，并采用视觉语言模型从视觉观察和语言指令中提取离散表示。基于它们，设计了一个轻量级路由器网络，为每个状态分配所需的原始技能，这有助于构建单一技能策略来生成与技能一致的操作。通过将复杂任务分解为一系列原始技能并选择单一技能策略，SDP 可确保不同任务之间的技能行为一致。对两个具有挑战性的模拟基准和现实世界的机器人部署进行的大量实验表明，SDP 始终优于 SOTA 方法，为具有扩散策略的基于技能的机器人学习提供了新的范例。

- **2026-01-05** **Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving** [2601.01800](http://arxiv.org/abs/2601.01800)
  > 强化学习 (RL) 在自动驾驶 (AD) 领域显示出巨大的潜力，但其易受扰动的影响仍然是现实世界部署的关键障碍。作为主要对策，对抗性训练通过在对手故意引入扰动的情况下训练 AD 代理来提高策略的稳健性。现有方法通常将交互建模为具有连续攻击的零和游戏。然而，此类设计忽视了代理和对手之间固有的不对称性，无法反映安全关键风险的稀疏性，导致所实现的鲁棒性不足以满足实际的 AD 场景。为了解决这些限制，我们引入了关键性感知的鲁棒强化学习（CARRL），这是一种新颖的对抗性训练方法，用于处理自动驾驶中稀疏的、安全关键的风险。 CARRL 由两个相互作用的部分组成：风险暴露对手 (REA) 和风险目标稳健代理 (RTRA)。我们将 REA 和 RTRA 之间的交互建模为一般和游戏，使 REA 能够专注于暴露安全关键型故障（例如碰撞），而 RTRA 则学会平衡安全性与驾驶效率。 REA 采用解耦优化机制，在预算有限的情况下更好地识别和利用稀疏的安全关键时刻。然而，这种集中攻击不可避免地导致对抗性数据的缺乏。 RTRA 通过双重重放缓冲区共同利用良性和对抗性体验来应对这种稀缺性，并在扰动下强制执行政策一致性以稳定行为。实验结果表明，与最先进的基线方法相比，我们的方法在所有情况下将碰撞率降低了至少 22.66%。

- **2026-01-05** **AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving** [2601.01762](http://arxiv.org/abs/2601.01762)
  > 端到端自动驾驶快速发展，实现了复杂环境下的联合感知和规划。在规划阶段，最先进的（SOTA）端到端自动驾驶模型将规划分解为并行的横向和纵向预测。虽然有效，但这种并行设计可能会导致 i) 规划路径和速度之间的协调失败，以及 ii) 未充分利用驾驶路径作为纵向规划的先验，从而冗余地编码静态信息。为了解决这个问题，我们提出了一种新颖的级联框架，该框架明确规定了行驶路径上的纵向规划，从而实现协调和碰撞感知的横向和纵向规划。具体来说，我们引入了一种路径条件公式，该公式明确地将行驶路径纳入纵向规划中。在此基础上，该模型预测沿行驶路径的纵向位移，而不是完整的 2D 轨迹路点。这种设计简化了纵向推理，并将其与横向规划更紧密地结合在一起。此外，我们引入了一种面向规划的数据增强策略，通过添加代理和重新标记纵向目标以避免碰撞来模拟罕见的安全关键事件，例如车辆切入。在具有挑战性的 Bench2Drive 基准上进行评估，我们的方法设定了新的 SOTA，驾驶得分为 89.07，成功率为 73.18%，这表明协调性和安全性显着提高

- **2026-01-05** **AI Agent Systems: Architectures, Applications, and Evaluation** [2601.01743](http://arxiv.org/abs/2601.01743)
  > 人工智能代理——将基础模型与推理、规划、记忆和工具使用相结合的系统——正在迅速成为自然语言意图和现实世界计算之间的实用接口。这项调查综合了人工智能代理架构的新兴前景：(i) 审议和推理（例如，思想链式分解、自我反思和验证以及约束感知决策），(ii) 规划和控制（从反应性策略到分层和多步骤规划器），以及 (iii) 工具调用和环境交互（检索、代码执行、API 和多模式感知）。我们将之前的工作组织成一个统一的分类法，涵盖代理组件（策略/LLM核心、内存、世界模型、规划器、工具路由器和评论家）、编排模式（单代理与\多代理；集中与\分散协调）和部署设置（离线分析与\在线交互协助；安全关键与\开放式任务）。我们讨论了关键的设计权衡——延迟与准确性、自主性与可控性、能力与可靠性——并强调了评估如何因非确定性、长期信用分配、工具和环境可变性以及重试和上下文增长等隐性成本而变得复杂。最后，我们总结了测量和基准测试实践（任务套件、人类偏好和效用指标、约束下的成功、稳健性和安全性），并确定了开放的挑战，包括工具操作的验证和护栏、可扩展的内存和上下文管理、代理决策的可解释性以及实际工作负载下的可重复评估。

- **2026-01-05** **Explicit World Models for Reliable Human-Robot Collaboration** [2601.01705](http://arxiv.org/abs/2601.01705)
  > 本文讨论了传感噪声、模糊指令和人机交互下的鲁棒性主题。我们对可靠的实体人工智能问题采取了截然不同的策略：我们不关注旨在实现模型可预测性和鲁棒性的形式验证方法，而是强调人机交互​​的动态性、模糊性和主观性，这需要实体人工智能系统以一致、可理解和符合人类期望的方式感知、解释和响应人类意图。我们认为，当实体主体在本质上是社交的、多模式的和流动的人类环境中运行时，可靠性是根据上下文确定的，并且仅对参与交互的人类的目标和期望才有意义。这就需要一种根本不同的方法来实现可靠的嵌入式人工智能，其核心是构建和更新一个可访问的“显式世界模型”，代表人类和人工智能之间的共同点，用于使机器人行为与人类期望保持一致。


[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

