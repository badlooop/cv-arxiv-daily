---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.04.28
> Usage instructions: [here](./docs/README.md#usage)

## Video Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-24**|**Dynamic Camera Poses and Where to Find Them**|在动态互联网视频上按比例注释相机姿势对于推进逼真视频生成和模拟等领域至关重要。然而，收集这样的数据集是困难的，因为大多数互联网视频都不适合姿势估计。此外，即使对于最先进的方法来说，注释动态互联网视频也带来了重大挑战。本文介绍了DynPose-100K，这是一个用相机姿态注释的动态互联网视频的大规模数据集。我们的收集管道使用一组精心组合的任务特定和通用模型来解决过滤问题。对于姿态估计，我们结合了点跟踪、动态掩蔽和运动结构的最新技术，以实现对最先进方法的改进。我们的分析和实验表明，DynPose-100K在几个关键属性上既大规模又多样化，为各种下游应用的进步开辟了道路。 et.al.|[2504.17788](http://arxiv.org/abs/2504.17788)|null|
|**2025-04-24**|**MV-Crafter: An Intelligent System for Music-guided Video Generation**|音乐视频作为一种流行的多媒体娱乐形式，为观众提供引人入胜的视听体验，在歌手和粉丝中广受欢迎。创作者可以通过视觉元素自然地表达他们对音乐的诠释。然而，音乐视频的创作过程需要熟练掌握脚本设计、视频拍摄和音乐视频同步，这对非专业人士来说是一个重大挑战。之前的工作设计了自动音乐视频生成框架。然而，它们的输入复杂，输出质量差。作为回应，我们推出了MV Crafter，这是一个能够制作具有同步音乐视频节奏和风格的高质量音乐视频的系统。我们的方法涉及三个模拟人类创作过程的技术模块：脚本生成模块、视频生成模块和音乐视频同步模块。MV Crafter利用大型语言模型生成考虑音乐语义的脚本。为了解决短视频片段与不同长度音乐同步的挑战，我们提出了一种动态节拍匹配算法和视觉包络诱导扭曲方法，以确保精确、单调的音乐视频同步。此外，我们设计了一个用户友好的界面，通过直观的编辑功能简化了创建过程。大量实验表明，MV Crafter为提高生成的音乐视频的质量提供了一种有效的解决方案。 et.al.|[2504.17267](http://arxiv.org/abs/2504.17267)|null|
|**2025-04-24**|**DIVE: Inverting Conditional Diffusion Models for Discriminative Tasks**|扩散模型在图像和视频生成等各种生成任务中取得了显著进展。本文研究了利用预训练扩散模型执行判别任务的问题。具体来说，我们通过将预训练的布局“反转”为图像扩散模型，将预训练冻结生成扩散模型的判别能力从分类任务扩展到更复杂的对象检测任务。为此，分别提出了一种基于梯度的离散优化方法来代替繁重的预测枚举过程，以及一种更准确地使用贝叶斯规则的先验分布模型。实验结果表明，该方法与COCO数据集上的基本判别目标检测基线相当。此外，我们的方法可以在不牺牲准确性的情况下大大加快之前基于扩散的分类方法。代码和型号可在https://github.com/LiYinqi/DIVE . et.al.|[2504.17253](http://arxiv.org/abs/2504.17253)|**[link](https://github.com/LiYinqi/DIVE)**|
|**2025-04-25**|**We'll Fix it in Post: Improving Text-to-Video Generation with Neuro-Symbolic Feedback**|当前的文本到视频（T2V）生成模型越来越受欢迎，因为它们能够从文本提示中生成连贯的视频。然而，当处理涉及多个对象或连续事件的更长、更复杂的提示时，这些模型往往难以生成语义和时间一致的视频。此外，与训练或微调相关的高计算成本使得直接改进不切实际。为了克服这些局限性，我们引入了NeuS-E，这是一种新型的零训练视频细化管道，它利用神经符号反馈来自动增强视频生成，实现了与提示的卓越对齐。我们的方法首先通过分析正式的视频表示来推导神经符号反馈，并精确定位语义不一致的事件、对象及其相应的帧。然后，此反馈将指导对原始视频进行有针对性的编辑。对开源和专有T2V模型的广泛实证评估表明，NeuS-E显著提高了不同提示之间的时间和逻辑一致性，提高了近40% et.al.|[2504.17180](http://arxiv.org/abs/2504.17180)|null|
|**2025-04-23**|**BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation**|文本到视频（T2V）生成模型已经迅速发展，并在娱乐、教育和营销等领域得到了广泛应用。然而，这些模型的对抗性弱点仍然很少被探索。我们观察到，在T2V生成任务中，生成的视频通常包含文本提示中未明确指定的大量冗余信息，如环境元素、次要对象和其他细节，为恶意攻击者嵌入隐藏的有害内容提供了机会。利用这种固有的冗余，我们引入了BadVideo，这是为T2V一代量身定制的第一个后门攻击框架。我们的攻击侧重于通过两种关键策略设计目标对抗输出：（1）时空组合，它结合了不同的时空特征来编码恶意信息；（2）动态元素转换，它随着时间的推移在冗余元素中引入转换，以传达恶意信息。基于这些策略，攻击者的恶意目标与用户的文本指令无缝集成，提供了高度的隐蔽性。此外，通过利用视频的时间维度，我们的攻击成功地避开了主要分析单个帧内空间信息的传统内容审核系统。大量实验表明，BadVideo在保持原始语义和在干净输入上保持出色性能的同时，实现了高攻击成功率。总的来说，我们的工作揭示了T2V模型的对抗性脆弱性，引起了人们对潜在风险和滥用的关注。我们的项目页面位于https://wrt2000.github.io/BadVideo2025/. et.al.|[2504.16907](http://arxiv.org/abs/2504.16907)|null|
|**2025-04-23**|**ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree and Visual Guidance**|尽管机器人操作视频合成的最新进展显示出希望，但在确保有效的指令遵循和实现高视觉质量方面仍存在重大挑战。最近的方法，如RoboDreamer，利用语言分解将指令划分为单独的低级原语，在这些原语上调节世界模型，以实现组合指令跟踪。然而，这些独立的原语没有考虑它们之间存在的关系。此外，最近的方法忽略了有价值的视觉引导，包括深度和语义引导，这两者对于提高视觉质量都至关重要。本文介绍了基于动作树和视觉引导的先进世界模型ManipDreamer。为了更好地了解指令原语之间的关系，我们将指令表示为动作树，并将嵌入分配给树节点，每条指令都可以通过在动作树中导航来获取其嵌入。指令嵌入可用于指导世界模型。为了提高视觉质量，我们通过引入与世界模型兼容的视觉引导适配器，将深度和语义引导结合起来。这种视觉适配器增强了视频生成的时间和物理一致性。基于动作树和视觉引导，ManipDreamer显著提高了指令遵循能力和视觉质量。对机器人操作基准的综合评估表明，与最近的RoboDreamer模型相比，ManipDreamer在可见和不可见任务中的视频质量指标都有了很大的提高，PSNR从19.55提高到21.05，SSIM从0.7474提高到0.7982，在不可见任务中将Flow Error从3.506降低到3.201。此外，我们的方法在6个RLbench任务中平均将机器人操纵任务的成功率提高了2.5%。 et.al.|[2504.16464](http://arxiv.org/abs/2504.16464)|null|
|**2025-04-23**|**VideoMark: A Distortion-Free Robust Watermarking Framework for Video Diffusion Models**|这项工作提出了VideoMark，这是一个用于视频扩散模型的无训练鲁棒水印框架。随着传播模型在生成高度逼真的视频方面的进步，对可靠的内容归因机制的需求变得至关重要。虽然图像扩散模型的水印技术取得了进展，但由于视频长度可变和易受时间攻击，将这些方法直接扩展到视频中会带来独特的挑战。VideoMark通过使用伪随机纠错（PRC）码在生成过程中嵌入水印信息的逐帧水印策略来解决这些限制。我们的方法生成一个扩展的水印消息序列，并为每个视频随机选择起始位置，确保潜在空间中的噪声分布均匀，并保持生成质量。对于水印提取，我们引入了一个时间匹配模块（TMM），该模块使用编辑距离将解码的消息与原始水印序列对齐，从而提供对帧删除等时间攻击的鲁棒性。实验结果表明，VideoMark在保持视频质量与无水印生成相当的同时，实现了比现有方法更高的解码精度。重要的是，我们的水印在没有密钥的情况下仍然无法被攻击者检测到，与其他水印框架相比，确保了很强的不可察觉性。VideoMark为基于扩散的视频生成中的内容归因提供了一种实用的解决方案，无需额外的训练或牺牲视频质量。我们的代码和数据可在\href获得{https://github.com/KYRIE-LI11/VideoMark}{https://github.com/KYRIE-LI11/VideoMark}. et.al.|[2504.16359](http://arxiv.org/abs/2504.16359)|null|
|**2025-04-22**|**Survey of Video Diffusion Models: Foundations, Implementations, and Applications**|扩散模型的最新进展彻底改变了视频生成，与传统的基于生成对抗网络的方法相比，它提供了更优的时间一致性和视觉质量。虽然这一新兴领域在应用方面显示出巨大的前景，但它在运动一致性、计算效率和伦理考虑方面面临着重大挑战。本调查全面回顾了基于扩散的视频生成，考察了其演变、技术基础和实际应用。我们对当前的方法进行了系统的分类，分析了架构创新和优化策略，并研究了去噪和超分辨率等低级视觉任务的应用。此外，我们还探索了基于扩散的视频生成与相关领域之间的协同作用，包括视频表示学习、问答和检索。与现有的调查（Lei等人，2024a；b；Melnik等人，2024；Cao等人，2023；Xing等人，2024c）相比，这些调查侧重于视频生成的特定方面，如人体视频合成（Lei等，2024a）或长格式内容生成（Lei et al.，2024b），我们的工作为基于扩散的方法提供了更广泛、更更新、更精细的视角，并专门讨论了视频生成中的评估指标、行业解决方案和培训工程技术。这项调查为在扩散模型和视频生成交叉领域工作的研究人员和从业者提供了基础资源，为推动这一快速发展的领域的理论框架和实际实施提供了见解。本次调查涉及的相关工作的结构化列表也可在https://github.com/Eyeline-Research/Survey-Video-Diffusion. et.al.|[2504.16081](http://arxiv.org/abs/2504.16081)|null|
|**2025-04-22**|**Efficient Temporal Consistency in Diffusion-Based Video Editing with Adaptor Modules: A Theoretical Framework**|基于适配器的方法通常用于以最小的额外复杂性提高模型性能，特别是在需要帧间一致性的视频编辑任务中。通过将小的、可学习的模块插入预训练的扩散模型中，这些适配器可以在不进行大量再训练的情况下保持时间连贯性。将快速学习与共享和帧特定令牌相结合的方法在以低训练成本保持帧间的连续性方面特别有效。在这项工作中，我们希望为适配器提供一个通用的理论框架，以便在时间一致性丢失的情况下，在基于DDIM的模型中保持帧一致性。首先，我们证明了时间一致性目标在有界特征范数下是可微的，并在其梯度上建立了Lipschitz界。其次，我们证明，如果学习率在适当的范围内，在这个目标上的梯度下降会单调地减少损失并收敛到局部最小值。最后，我们分析了DDIM反演过程中模块的稳定性，表明相关误差保持可控。这些理论发现将加强基于扩散的视频编辑方法的可靠性，这些方法依赖于适配器策略，并为视频生成任务提供理论见解。 et.al.|[2504.16016](http://arxiv.org/abs/2504.16016)|null|
|**2025-04-22**|**Reasoning Physical Video Generation with Diffusion Timestep Tokens via Reinforcement Learning**|尽管最近在视频生成方面取得了进展，但制作符合物理定律的视频仍然是一个重大挑战。传统的基于扩散的方法由于依赖于数据驱动的近似值，很难推断出看不见的物理条件（如速度）。为了解决这个问题，我们建议将符号推理和强化学习相结合，以增强视频生成中的物理一致性。我们首先介绍扩散时间步标记器（DDT），它通过恢复扩散过程中丢失的视觉属性来学习离散的递归视觉标记。递归视觉标记允许通过大型语言模型进行符号推理。在此基础上，我们提出了Phys AR框架，该框架分为两个阶段：第一阶段使用监督微调来传递符号知识，第二阶段应用强化学习通过基于物理条件的奖励函数来优化模型的推理能力。我们的方法允许模型动态调整和改进生成视频的物理属性，确保遵守物理定律。实验结果表明，PhysAR可以生成物理一致的视频。 et.al.|[2504.15932](http://arxiv.org/abs/2504.15932)|null|

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-24**|**CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from Casually Captured Videos**|最近，神经辐射场（NeRF）和3D高斯散斑（3DGS）等多视图图像的照片级逼真新视图合成因其卓越的性能而受到广泛关注。然而，大多数作品依赖于低动态范围（LDR）图像，这限制了更丰富场景细节的捕捉。一些先前的工作侧重于高动态范围（HDR）场景重建，通常需要在曝光时间内在固定的相机位置捕获具有不同曝光时间的多视图清晰图像，这在实践中既耗时又具有挑战性。为了获得更灵活的数据采集，我们提出了一种单阶段方法：\textbf{CasualHDRSplat}，即使在存在严重运动模糊和未知曝光时间变化的情况下，也能从随机捕获的视频中轻松、稳健地重建3D HDR场景，并启用自动曝光。\textbf{CasualHDRSplat}包含一个统一的可微分物理成像模型，该模型首先对成像过程应用连续时间轨迹约束，以便我们可以共同优化曝光时间、相机响应函数（CRF）、相机姿态和清晰的3D HDR场景。大量实验表明，我们的方法在鲁棒性和渲染质量方面优于现有方法。我们的源代码将在https://github.com/WU-CVGL/CasualHDRSplat et.al.|[2504.17728](http://arxiv.org/abs/2504.17728)|null|
|**2025-04-24**|**Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation**|我们提出了一种通过心理意象模拟在视觉语言模型（VLMs）中进行透视感知推理的框架。视角获取，即从另一个角度感知环境或情况的能力，是人类视觉理解的关键基准，对于与自主代理的环境交互和协作至关重要。尽管VLM在空间推理方面取得了进步，但最近的研究表明，现代VLM严重缺乏透视感知推理能力，并表现出强烈的自我中心解释倾向。为了弥合VLM和人类感知之间的差距，我们关注心理意象的作用，即人类通过抽象的表征来感知世界，从而促进视角的转变。受此启发，我们提出了一个名为抽象透视变化（APC）的透视感知推理框架，该框架有效地利用视觉基础模型，如对象检测、分割和方向估计，来构建场景抽象并实现透视变换。与各种VLM相比，我们在合成和真实图像基准上的实验表明，我们的框架在透视感知推理方面有了显著改进，进一步优于微调的空间推理模型和新的基于视图合成的方法。 et.al.|[2504.17207](http://arxiv.org/abs/2504.17207)|null|
|**2025-04-22**|**Satellite to GroundScape -- Large-scale Consistent Ground View Generation from Satellite Views**|从卫星图像生成一致的地面视图图像具有挑战性，主要是由于卫星和地面域之间的视角和分辨率存在很大差异。之前的工作主要集中在单视图生成上，这通常会导致相邻地面视图之间的不一致。在这项工作中，我们提出了一种新的交叉视图合成方法，旨在通过确保从卫星视图生成的地面视图图像的一致性来克服这些挑战。我们的方法基于固定的潜在扩散模型，引入了两个条件模块：卫星引导去噪，提取高级场景布局来指导去噪过程，以及卫星时间去噪，捕获相机运动以保持多个生成视图的一致性。我们还提供了一个包含100000多个透视对的大规模卫星地面数据集，以促进广泛的地面场景或视频生成。实验结果表明，我们的方法在感知和时间度量方面优于现有方法，在多视图输出中实现了高真实感和一致性。 et.al.|[2504.15786](http://arxiv.org/abs/2504.15786)|null|
|**2025-04-22**|**Pose Optimization for Autonomous Driving Datasets using Neural Rendering Models**|自动驾驶系统依赖于对自我汽车的准确感知和定位，以确保在具有挑战性的现实驾驶场景中的安全性和可靠性。公共数据集通过为模型开发和评估提供标准化资源，在基准测试和指导研究进展方面发挥着至关重要的作用。然而，这些数据集中传感器校准和车辆姿态的潜在不准确可能会导致对下游任务的错误评估，从而对自主系统的可靠性和性能产生不利影响。为了应对这一挑战，我们提出了一种基于神经辐射场（NeRF）的鲁棒优化方法，以细化传感器姿态和校准参数，增强数据集基准的完整性。为了验证在没有地面真实性的情况下优化姿态的准确性的提高，我们提出了一个全面的评估过程，该过程依赖于重投影指标、新视图合成渲染质量和几何对齐。我们证明，我们的方法在传感器姿态精度方面取得了显著提高。通过优化这些关键参数，我们的方法不仅提高了现有数据集的效用，还为更可靠的自动驾驶模型铺平了道路。为了促进该领域的持续进步，我们公开了优化的传感器姿态，为研究界提供了宝贵的资源。 et.al.|[2504.15776](http://arxiv.org/abs/2504.15776)|null|
|**2025-04-21**|**MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry Monocular Video**|我们提出了MoBGS，这是一种新颖的去模糊动态3D高斯散斑（3DGS）框架，能够以端到端的方式从模糊的单眼视频中重建清晰、高质量的新颖时空视图。现有的动态新颖视图合成（NVS）方法对随意捕获的视频中的运动模糊高度敏感，导致渲染质量显著下降。虽然最近的方法解决了NVS的运动模糊输入问题，但它们主要侧重于静态场景重建，缺乏针对动态对象的专用运动建模。为了克服这些局限性，我们的MoBGS引入了一种新的模糊自适应潜在相机估计（BLCE）方法，用于有效的潜在相机轨迹估计，改善了全局相机运动去模糊。此外，我们提出了一种受物理启发的潜在相机诱导曝光估计（LCEE）方法，以确保全局相机和局部对象运动的一致去模糊。我们的MoBGS框架确保了看不见的潜在时间戳的时间一致性，以及静态和动态区域的鲁棒运动分解。对立体模糊数据集和真实世界模糊视频的广泛实验表明，我们的MoBGS明显优于最新的先进方法（DyBluRF和Deblur4DGS），在运动模糊下实现了最先进的动态NVS性能。 et.al.|[2504.15122](http://arxiv.org/abs/2504.15122)|null|
|**2025-04-20**|**IXGS-Intraoperative 3D Reconstruction from Sparse, Arbitrarily Posed Real X-rays**|脊柱手术是一种高风险的干预措施，需要精确的执行，通常由基于图像的导航系统支持。最近，监督学习方法在从稀疏荧光透视数据重建3D脊柱解剖结构方面受到了关注，大大降低了对辐射密集型3D成像系统的依赖。然而，这些方法通常需要大量带注释的训练数据，并且可能难以在不同的患者解剖结构或成像条件下进行推广。高斯飞溅等实例学习方法可以避免大量的注释要求，从而提供一种替代方案。虽然高斯溅射显示出新的视图合成的前景，但它在稀疏、任意姿势的真实术中X射线中的应用在很大程度上仍未得到探索。这项工作通过扩展 $R^2$ -Gassian飞溅框架来解决这一局限性，以在这些具有挑战性的条件下重建解剖学上一致的3D体积。我们引入了一种使用样式转换的解剖引导放射学标准化步骤，提高了视图之间的视觉一致性，并提高了重建质量。值得注意的是，我们的框架不需要预训练，使其天生就能适应新的患者和解剖结构。我们使用离体数据集评估了我们的方法。专家手术评估证实了3D重建在导航方面的临床实用性，特别是在使用20到30个视图时，并强调了标准化对解剖清晰度的好处。通过定量2D指标（PSNR/SSIM）进行的基准测试证实了与理想设置相比的性能权衡，但也验证了标准化对原始输入的改进。这项工作证明了从任意稀疏视图X射线进行基于实例的体积重建的可行性，推进了手术导航的术中3D成像。 et.al.|[2504.14699](http://arxiv.org/abs/2504.14699)|null|
|**2025-04-20**|**VGNC: Reducing the Overfitting of Sparse-view 3DGS via Validation-guided Gaussian Number Control**|稀疏视图3D重建是实际3D重建应用中一项基本但具有挑战性的任务。最近，已经提出了许多基于3D高斯散斑（3DGS）框架的方法来解决稀疏视图3D重建问题。尽管这些方法取得了相当大的进步，但它们仍然存在过拟合的重大问题。为了减少过拟合，我们引入了VGNC，这是一种基于生成新视图合成（NVS）模型的新型验证引导高斯数控制（VGNC）方法。据我们所知，这是首次尝试通过生成验证图像来缓解稀疏视图3DGS的过拟合问题。具体来说，我们首先介绍了一种基于生成NVS模型的验证图像生成方法。然后，我们提出了一种高斯数控制策略，该策略利用生成的验证图像来确定最优高斯数，从而减少过拟合问题。我们在各种稀疏视图3DGS基线和数据集上进行了详细的实验，以评估VGNC的有效性。大量实验表明，我们的方法不仅减少了过拟合，而且在减少高斯点数量的同时提高了测试集的渲染质量。这种减少降低了存储需求，加速了训练和渲染。代码将被发布。 et.al.|[2504.14548](http://arxiv.org/abs/2504.14548)|null|
|**2025-04-20**|**Metamon-GS: Enhancing Representability with Variance-Guided Densification and Light Encoding**|3D高斯散点（3DGS）的引入通过利用高斯来表示场景，推进了新的视图合成。使用锚嵌入对高斯点特征进行编码显著提高了较新3DGS变体的性能。虽然已经取得了重大进展，但提高渲染性能仍然具有挑战性。特征嵌入很难在不同的光照条件下从不同的角度准确地表示颜色，这会导致外观褪色。另一个原因是缺乏适当的致密化策略来防止高斯点在初始化稀疏的区域生长，从而导致模糊和针状伪影。为了解决这些问题，我们从方差引导的致密化策略和多级哈希网格的创新角度提出了Metamon GS。方差引导的密集化策略专门针对像素中具有高梯度方差的高斯分布，并补偿了具有额外高斯分布的区域对改善重建的重要性。后者研究隐含的全局光照条件，并从不同的角度和特征嵌入准确地解释颜色。我们在公开数据集上的彻底实验表明，Metamon GS超越了其基线模型和以前的版本，在渲染新颖视图方面提供了卓越的质量。 et.al.|[2504.14460](http://arxiv.org/abs/2504.14460)|null|
|**2025-04-21**|**SLAM&Render: A Benchmark for the Intersection Between Neural Rendering, Gaussian Splatting and SLAM**|最初为新颖的视图合成和场景渲染开发的模型和方法，如神经辐射场（NeRF）和高斯散斑，正越来越多地被用作同步定位和映射（SLAM）中的表示。然而，现有的数据集未能包括这两个领域的具体挑战，例如SLAM中的多模态和顺序性，或神经渲染中跨视点和光照条件的泛化。为了弥合这一差距，我们引入了SLAM&Render，这是一个新的数据集，旨在为SLAM和新视图渲染之间的交叉点方法进行基准测试。它由40个序列组成，具有同步的RGB、深度、IMU、机器人运动学数据和地面真实姿态流。通过发布机器人运动学数据，该数据集还可以评估应用于机器人操纵器的新型SLAM策略。数据集序列涵盖了五种不同的设置，在四种不同的光照条件下展示消费者和工业对象，每个场景都有单独的训练和测试轨迹，以及对象重新排列。我们的实验结果是通过文献中的几个基线获得的，验证了SLAM和Render是这一新兴研究领域的相关基准。 et.al.|[2504.13713](http://arxiv.org/abs/2504.13713)|**[link](https://github.com/samuel-cerezo/SLAM-Render)**|
|**2025-04-17**|**Novel Demonstration Generation with Gaussian Splatting Enables Robust One-Shot Manipulation**|从远程操作演示中学习到的Visuomotor政策面临着数据收集时间长、成本高、数据多样性有限等挑战。现有的方法通过增强RGB空间中的图像观测或基于物理模拟器采用Real到Sim到Real的管道来解决这些问题。然而，前者仅限于二维数据增强，而后者则因不准确的几何重建而遭受不精确的物理模拟。本文介绍了RoboSplat，这是一种通过直接操纵3D高斯分布生成多样化、视觉逼真演示的新方法。具体来说，我们通过3D高斯散布（3DGS）重建场景，直接编辑重建的场景，并使用五种技术在六种类型的泛化中增强数据：不同对象类型的3D高斯替换、场景外观和机器人实施例；不同物体姿态的等变变换；针对各种照明条件的视觉属性编辑；用于新相机视角的新颖视图合成；以及用于不同对象类型的3D内容生成。全面的现实世界实验表明，RoboSplat在各种干扰下显著提高了视觉运动策略的泛化能力。值得注意的是，虽然经过数百次真实世界演示和额外2D数据增强训练的策略的平均成功率为57.2%，但RoboSplat在现实世界中的六种泛化类型的单次设置中达到了87.8%。 et.al.|[2504.13175](http://arxiv.org/abs/2504.13175)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-24**|**Range Image-Based Implicit Neural Compression for LiDAR Point Clouds**|本文提出了一种高效压缩光探测和测距（LiDAR）点云的新方案，实现了高精度的3D场景档案，这些档案为详细了解相应的3D场景铺平了道路。我们专注于2D距离图像~（RI）作为一种轻量级的格式，用于表示3D LiDAR观测结果。尽管传统的图像压缩技术可以提高RI的压缩效率，但由于比特精度的差异以及自然图像和RI之间不同的像素值分布特征，它们的实际性能预计会受到限制。我们提出了一种新的基于隐式神经表示的RI压缩方法，可以有效地处理浮点值像素。所提出的方法将RI分为深度和掩模图像，并分别使用具有模型修剪和量化的逐块和逐像素INR架构对其进行压缩。在KITTI数据集上的实验表明，在低比特率和解码延迟下，所提出的方法在3D重建和检测质量方面优于现有的基于图像、点云、RI和INR的压缩方法。 et.al.|[2504.17229](http://arxiv.org/abs/2504.17229)|null|
|**2025-04-23**|**Gaussian Splatting is an Effective Data Generator for 3D Object Detection**|我们研究了自动驾驶中3D物体检测的数据增强。我们利用基于高斯散斑的3D重建的最新进展，在驾驶场景中放置3D对象。与现有的基于扩散的合成基于边界元法布局的图像的方法不同，我们的方法通过明确施加的几何变换将3D对象直接放置在重建的3D空间中。这确保了对象放置的物理合理性和高度精确的3D姿态和位置注释。我们的实验表明，即使通过将有限数量的外部3D对象集成到真实场景中，增强数据也能显著提高3D对象检测性能，并且在对象检测方面优于现有的基于扩散的3D增强。对nuScenes数据集的广泛测试表明，与对象的外观多样性相比，在对象放置中施加高度的几何多样性会产生更大的影响。此外，我们表明，通过最大化检测损失或在相机图像中施加高视觉遮挡来生成硬示例，并不能为自动驾驶中基于相机的3D对象检测带来更有效的3D数据增强。 et.al.|[2504.16740](http://arxiv.org/abs/2504.16740)|null|
|**2025-04-23**|**Beyond Anonymization: Object Scrubbing for Privacy-Preserving 2D and 3D Vision Tasks**|我们引入了ROAR（鲁棒对象删除和重新注释），这是一个可扩展的隐私保护数据集混淆框架，可以消除敏感对象而不是修改它们。我们的方法将实例分割与生成修复相结合，在保留场景完整性的同时去除可识别的实体。对基于2D COCO的目标检测的广泛评估表明，ROAR达到了基线检测平均精度（AP）的87.5%，而图像丢弃仅达到了基线AP的74.2%，突显了擦洗在保持数据集效用方面的优势。由于遮挡和细粒度细节的丢失，小对象的退化甚至更严重。此外，在基于NeRF的3D重建中，我们的方法在保持SSIM和改善LPIPS的同时，PSNR损失最多为1.66 dB，表现出卓越的感知质量。我们的研究结果将对象移除确立为一种有效的隐私框架，以最小的性能权衡实现了强有力的隐私保证。研究结果突出了生成修复、遮挡鲁棒分割和特定任务清理方面的关键挑战，为隐私保护视觉系统的未来发展奠定了基础。 et.al.|[2504.16557](http://arxiv.org/abs/2504.16557)|null|
|**2025-04-23**|**PRaDA: Projective Radial Distortion Averaging**|我们解决了在具有挑战性的条件下自动校准径向失真相机的问题。准确确定失真参数通常需要1）解决涉及相机姿态、3D点和失真参数的完整运动结构（SfM）问题，这只有在提供了许多具有足够重叠的图像的情况下才有可能，或者2）严重依赖相对不太准确的基于学习的方法。在这项工作中，我们证明了失真校准可以与3D重建解耦，在保持基于SfM的方法的准确性的同时避免了许多相关的复杂性。这是通过在投影空间中工作来实现的，其中几何体在单应性之前是唯一的，单应性封装了除失真之外的所有相机参数。我们提出的方法，投影径向失真平均法，在完全投影的框架内对多个失真估计进行平均，而无需创建3d点和全束调整。通过依赖成对投影关系，我们的方法支持任何特征匹配方法，而无需在多幅图像上构建点轨迹。 et.al.|[2504.16499](http://arxiv.org/abs/2504.16499)|null|
|**2025-04-22**|**Intent-aware Diffusion with Contrastive Learning for Sequential Recommendation**|对比学习已被证明在训练顺序推荐模型方面是有效的，它结合了来自增强视图的自我监督信号。大多数现有方法通过随机数据增强从同一交互序列中生成多个视图，旨在对齐它们在嵌入空间中的表示。然而，用户在购买物品时通常有特定的意图（例如，购买衣服作为礼物或美容化妆品）。现有方法中使用的随机数据增强可能会引入噪声，破坏原始交互序列中隐含的潜在意图信息。此外，在对比学习中使用噪声增强序列可能会误导模型关注不相关的特征，扭曲嵌入空间，无法捕捉用户的真实行为模式和意图。为了解决这些问题，我们提出了用于顺序推荐的具有对比学习的意图感知扩散（InDiRec）。核心思想是生成与用户购买意图一致的项目序列，从而为对比学习提供更可靠的增强视图。具体来说，InDiRec首先使用K-means对序列表示进行意图聚类，以构建意图引导信号。接下来，它检索目标交互序列的意图表示，以指导条件扩散模型，生成共享相同潜在意图的积极视图。最后，对比学习被应用于最大限度地提高这些意图对齐视图与原始序列之间的表示一致性。在五个公共数据集上进行的广泛实验表明，与现有基线相比，InDiRec具有更优的性能，即使在嘈杂和稀疏的数据条件下也能学习到更稳健的表示。 et.al.|[2504.16077](http://arxiv.org/abs/2504.16077)|null|
|**2025-04-21**|**Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields**|弱引力透镜是星系形状的轻微扭曲，主要是由宇宙中暗物质的引力效应引起的。在我们的工作中，我们试图从2D望远镜图像中反转弱透镜信号，以重建宇宙暗物质场的3D图。虽然反演通常会产生暗物质场的二维投影，但暗物质分布的精确三维图对于定位感兴趣的结构和测试我们宇宙的理论至关重要。然而，3D反演带来了重大挑战。首先，与依赖于多个视点的标准3D重建不同，在这种情况下，图像仅从单个视点观察。通过观察整个体积中的星系发射器是如何被透镜化的，可以部分解决这一挑战。然而，这导致了第二个挑战：无透镜星系的形状和确切位置是未知的，只能在非常大的不确定性下进行估计。这引入了大量的噪声，几乎完全淹没了透镜信号。以前的方法通过对卷中的结构施加强有力的假设来解决这个问题。相反，我们提出了一种使用引力约束神经场来灵活模拟连续物质分布的方法。我们采用综合分析方法，通过完全可微的物理正向模型优化神经网络的权重，以再现图像测量中存在的透镜信号。我们展示了我们的模拟方法，包括模拟即将到来的望远镜调查数据的暗物质分布的真实模拟测量。我们的结果表明，我们的方法不仅可以超越以前的方法，而且重要的是还能够恢复潜在的令人惊讶的暗物质结构。 et.al.|[2504.15262](http://arxiv.org/abs/2504.15262)|null|
|**2025-04-20**|**IXGS-Intraoperative 3D Reconstruction from Sparse, Arbitrarily Posed Real X-rays**|脊柱手术是一种高风险的干预措施，需要精确的执行，通常由基于图像的导航系统支持。最近，监督学习方法在从稀疏荧光透视数据重建3D脊柱解剖结构方面受到了关注，大大降低了对辐射密集型3D成像系统的依赖。然而，这些方法通常需要大量带注释的训练数据，并且可能难以在不同的患者解剖结构或成像条件下进行推广。高斯飞溅等实例学习方法可以避免大量的注释要求，从而提供一种替代方案。虽然高斯溅射显示出新的视图合成的前景，但它在稀疏、任意姿势的真实术中X射线中的应用在很大程度上仍未得到探索。这项工作通过扩展 $R^2$ -Gassian飞溅框架来解决这一局限性，以在这些具有挑战性的条件下重建解剖学上一致的3D体积。我们引入了一种使用样式转换的解剖引导放射学标准化步骤，提高了视图之间的视觉一致性，并提高了重建质量。值得注意的是，我们的框架不需要预训练，使其天生就能适应新的患者和解剖结构。我们使用离体数据集评估了我们的方法。专家手术评估证实了3D重建在导航方面的临床实用性，特别是在使用20到30个视图时，并强调了标准化对解剖清晰度的好处。通过定量2D指标（PSNR/SSIM）进行的基准测试证实了与理想设置相比的性能权衡，但也验证了标准化对原始输入的改进。这项工作证明了从任意稀疏视图X射线进行基于实例的体积重建的可行性，推进了手术导航的术中3D成像。 et.al.|[2504.14699](http://arxiv.org/abs/2504.14699)|null|
|**2025-04-20**|**VGNC: Reducing the Overfitting of Sparse-view 3DGS via Validation-guided Gaussian Number Control**|稀疏视图3D重建是实际3D重建应用中一项基本但具有挑战性的任务。最近，已经提出了许多基于3D高斯散斑（3DGS）框架的方法来解决稀疏视图3D重建问题。尽管这些方法取得了相当大的进步，但它们仍然存在过拟合的重大问题。为了减少过拟合，我们引入了VGNC，这是一种基于生成新视图合成（NVS）模型的新型验证引导高斯数控制（VGNC）方法。据我们所知，这是首次尝试通过生成验证图像来缓解稀疏视图3DGS的过拟合问题。具体来说，我们首先介绍了一种基于生成NVS模型的验证图像生成方法。然后，我们提出了一种高斯数控制策略，该策略利用生成的验证图像来确定最优高斯数，从而减少过拟合问题。我们在各种稀疏视图3DGS基线和数据集上进行了详细的实验，以评估VGNC的有效性。大量实验表明，我们的方法不仅减少了过拟合，而且在减少高斯点数量的同时提高了测试集的渲染质量。这种减少降低了存储需求，加速了训练和渲染。代码将被发布。 et.al.|[2504.14548](http://arxiv.org/abs/2504.14548)|null|
|**2025-04-20**|**Back on Track: Bundle Adjustment for Dynamic Scene Reconstruction**|传统的SLAM系统依赖于捆绑调整，难以应对休闲视频中常见的高度动态场景。这样的视频纠缠了动态元素的运动，破坏了传统系统所需的静态环境的假设。现有技术要么过滤掉动态元素，要么独立地对它们的运动进行建模。然而，前者通常会导致重建不完整，而后者可能会导致运动估计不一致。这项工作采用了一种新颖的方法，利用3D点跟踪器将相机引起的运动与观察到的动态物体的运动分开。通过仅考虑相机引起的分量，束调整可以在所有场景元素上可靠地运行。我们通过基于比例图的轻量级后处理进一步确保视频帧的深度一致性。我们的框架将传统SLAM的核心——捆绑调整——与强大的基于学习的3D跟踪器前端相结合。我们的统一框架BA-Track集成了运动分解、束调整和深度细化，可以准确地跟踪相机运动，并产生时间连贯和尺度一致的密集重建，同时容纳静态和动态元素。我们在具有挑战性的数据集上的实验表明，相机姿态估计和3D重建精度有了显著提高。 et.al.|[2504.14516](http://arxiv.org/abs/2504.14516)|null|
|**2025-04-18**|**Mono3R: Exploiting Monocular Cues for Geometric 3D Reconstruction**|数据驱动的几何多视图3D重建基础模型（如DUSt3R）的最新进展在各种3D视觉任务中表现出了显著的性能，这得益于大规模、高质量3D数据集的发布。然而，正如我们所观察到的，受其基于匹配的原理的限制，现有模型的重建质量在匹配线索有限的具有挑战性的区域中会显著下降，特别是在弱纹理区域和低光照条件下。为了减轻这些局限性，我们建议利用单目几何估计的固有鲁棒性来弥补基于匹配的方法的固有缺点。具体来说，我们引入了一个单目引导的细化模块，该模块将单目几何先验集成到多视图重建框架中。这种集成大大增强了多视图重建系统的鲁棒性，从而实现了高质量的前馈重建。跨多个基准的综合实验表明，我们的方法在多视图相机姿态估计和点云精度方面都取得了实质性的改进。 et.al.|[2504.13419](http://arxiv.org/abs/2504.13419)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-24**|**LiDPM: Rethinking Point Diffusion for Lidar Scene Completion**|由于难以在宽视场内从白噪声中生成细粒度细节，因此在室外场景的尺度上直接在激光雷达点上训练扩散模型具有挑战性。利用扩散模型解决场景完成的最新工作通过将原始DDPM重新表述为局部扩散过程来解决这个问题。它与目前使用vanilla DDPM的在对象级别操作的常见做法形成鲜明对比。在这项工作中，我们缩小了这两条工作线之间的差距。我们确定了局部扩散公式中的近似值，表明它们不需要在场景级别运行，并且具有精心选择的起点的香草DDPM就足以完成。最后，我们证明了我们的方法LiDPM在SemanticKITTI上的场景完成方面取得了更好的结果。项目页面为https://astra-vision.github.io/LiDPM . et.al.|[2504.17791](http://arxiv.org/abs/2504.17791)|null|
|**2025-04-24**|**Token-Shuffle: Towards High-Resolution Image Generation with Autoregressive Models**|自回归（AR）模型在语言生成中长期占据主导地位，越来越多地应用于图像合成，但通常被认为不如基于扩散的模型具有竞争力。一个主要的限制是AR模型需要大量的图像标记，这限制了训练和推理效率以及图像分辨率。为了解决这个问题，我们提出了令牌洗牌，这是一种新颖而简单的方法，可以减少Transformer中的图像令牌数量。我们的关键见解是多模态大型语言模型（MLLM）中视觉词汇表的维度冗余，其中来自视觉编码器的低维视觉代码直接映射到高维语言词汇表。利用这一点，我们考虑了两个关键操作：令牌洗牌，它沿着通道维度合并空间局部令牌以减少输入令牌数量，以及令牌取消洗牌，它在Transformer块后解开推断的令牌以恢复输出的空间排列。与文本提示联合训练，我们的策略不需要额外的预训练文本编码器，使MLLM能够以统一的下一个标记预测方式支持极高分辨率的图像合成，同时保持高效的训练和推理。我们首次将AR文本到图像生成的边界提升到2048x2048的分辨率，并取得了令人满意的生成性能。在GenAI基准测试中，我们的2.7B模型在硬提示上的总分为0.77，比AR模型LlamaGen高出0.18，比扩散模型LDM高出0.15。详尽的大规模人工评估也证明了我们在文本对齐、视觉缺陷和视觉外观方面的出色图像生成能力。我们希望Token Shuffle可以作为MLLM中高效高分辨率图像生成的基础设计。 et.al.|[2504.17789](http://arxiv.org/abs/2504.17789)|null|
|**2025-04-24**|**Thermal Product Formula for Shear Modes**|我们研究了ArXiv[2304.12339]中提出的热积公式对AdS5中R带电黑膜剪切通道波动的有效性，其中剪切模式与非零动量下的电荷扩散模式耦合。当这些模式适当解耦时，我们能够根据该通道的准正态模式得到边界电流和能量动量张量的两点函数的精确公式。这个确切的配方是对之前版本的产品配方的简单修改。当我们有一个在剪切通道中引入额外耦合的体Chern-Simons项时，我们还得到了涉及边界全局R-对称异常的情况的类似公式。同样基于准正态模谱的见解，我们报告了与大异常系数值相关的不稳定性以及高动量长寿模的存在。 et.al.|[2504.17781](http://arxiv.org/abs/2504.17781)|null|
|**2025-04-24**|**Step1X-Edit: A Practical Framework for General Image Editing**|近年来，图像编辑模式得到了显著而快速的发展。最近推出的GPT-4o和Gemini2 Flash等尖端多模式模型引入了极具前景的图像编辑功能。这些模型在满足绝大多数用户驱动的编辑要求方面表现出了令人印象深刻的能力，标志着图像处理领域的重大进步。然而，开源算法与这些闭源模型之间仍然存在很大差距。因此，在本文中，我们的目标是发布一种最先进的图像编辑模型，称为Step1X Edit，它可以提供与GPT-4o和Gemini2 Flash等闭源模型相当的性能。更具体地说，我们采用多模态LLM来处理参考图像和用户的编辑指令。已提取潜在嵌入并将其与扩散图像解码器集成以获得目标图像。为了训练模型，我们构建了一个数据生成管道来生成高质量的数据集。为了进行评估，我们开发了GEdit Bench，这是一种植根于现实世界用户指令的新型基准。GEdit Bench上的实验结果表明，Step1X Edit的性能远远优于现有的开源基线，接近领先的专有模型的性能，从而为图像编辑领域做出了重大贡献。 et.al.|[2504.17761](http://arxiv.org/abs/2504.17761)|null|
|**2025-04-24**|**Asymptotic attraction with algebraic rates toward fronts of dispersive-diffusive Burgers equations**|Burgers方程是一个经典模型，在许多应用中都有出现。它的核心是一个简单的守恒定律，可以作为各种动力学现象的玩具模型。特别是，它支持明确的异性恋解决方案，包括正面和背面。对它们的稳定性进行了详细研究。人们对考虑色散和/或扩散修饰有着浓厚的兴趣，这在如此简单的环境中提出了新的动力学范式。更具体地说，KdV-Burgers模型已被证明支持具有固定值 $\pm\infty$的独特前沿（并非所有前沿都是单调的！）。许多文章，包括\cite{Pego}、\cite{1}、\cite{NS2}，都研究了单调（或接近单调）前沿的稳定性问题。在一篇突破性的论文中，作者在几个不同的方向上扩展了这些结果。他们考虑了更广泛的模型。前沿不需要是单调的，而是受光谱条件的约束。最重要的是，只要满足$\pm\infty$的异临床条件，该方法就允许大的扰动。也就是说，所述前沿具有渐近吸引力，或者等效地，极限集由一个点组成。本文的目的是通过提供显式的代数收敛率为\t到\infty$ 来扩展{BBHY}的结果。我们使用两个重要例子的额外能量估计，即KdV-Burgers和分数Burgers问题，从{BBHY}的结果中引导这些结果。这些速率可能不是最优的，但我们推测它们仍然是代数的。 et.al.|[2504.17745](http://arxiv.org/abs/2504.17745)|null|
|**2025-04-24**|**Time-reversed Stochastic Inflation**|宇宙暴胀可能表现出量子波动主导半经典演化的随机期。在这些机制中提取可观测值是一个出了名的困难程序，因为量子随机性使它们完全具有概率性。然而，在所有可能的量子历史中，与宇宙学相关的量子历史都受到随机暴胀结束的要求的制约。从观测的角度来看，将随机周期建模为从它们结束的时间开始，并在时间上向后演变，会更方便。我们提出了一种基于逆福克-普朗克方程的随机暴胀时间反演方法，该方法允许我们在量子机制结束前的给定时间无扰动地推导出场值的概率分布。作为一个有动机的例子，我们求解了平坦的半无限势，并推导出了量子产生的曲率涨落概率分布的一个新的精确公式。它是可归一化的，同时表现出缓慢衰减的Levy分布。我们的逆时间随机形式可以应用于任何暴胀势和量子扩散时代，包括那些可能导致原始黑洞形成的时代。 et.al.|[2504.17680](http://arxiv.org/abs/2504.17680)|null|
|**2025-04-24**|**Sharp Material Interface Limit of the Darcy-Boussinesq System**|我们研究了Darcy Boussinesq模型在具有扩散材料界面的分层多孔介质中对流的尖锐材料界面极限，该模型允许不同层之间的材料参数逐渐过渡。我们证明，随着这些过渡层的厚度接近零，在假设孔隙度恒定的情况下，流体界通常采用的具有界面边界条件的传统锐界面模型得以恢复。我们的结果通过将广泛使用的尖锐界面模型与扩散材料界面的更真实的物理情况联系起来，验证了该模型的有效性。这种限制过程是奇异的，涉及速度场中的边界层。我们的分析需要del et.al.|[2504.17661](http://arxiv.org/abs/2504.17661)|null|
|**2025-04-24**|**polyGen: A Learning Framework for Atomic-level Polymer Structure Generation**|合成聚合物材料支撑着能源、电子、消费品和医疗领域的基础技术，但它们的开发仍然受到设计时间延长的影响。尽管聚合物信息学工具支持加速，但聚合物模拟协议仍面临重大挑战：按需生成尊重聚合物结构构象多样性的逼真3D原子结构。无机晶体、生物聚合物和小分子的3D结构生成算法已经存在，但尚未涉及合成聚合物。在这项工作中，我们介绍了polyGen，这是第一个专门设计用于从最小输入（如重复单元化学）生成真实聚合物结构的潜在扩散模型，利用分子编码捕获整个结构中的聚合物连接。由于只有3855个DFT优化的聚合物结构的稀缺数据集，我们用DFT优化的分子结构来增强我们的训练，显示出相似化学结构之间的联合学习有所改善。我们还建立了结构匹配标准，以对我们的方法在这个新问题上进行基准测试。polyGen有效地产生了线性链和复杂分支结构的不同构象，尽管在处理具有高原子数的重复单元时其性能会降低。鉴于这些初步结果，polyGen代表了聚合物科学原子级结构生成的范式转变，这是预测现实原子级聚合物构象同时考虑其内在结构灵活性的第一个概念证明。 et.al.|[2504.17656](http://arxiv.org/abs/2504.17656)|null|
|**2025-04-24**|**Beyond Labels: Zero-Shot Diabetic Foot Ulcer Wound Segmentation with Self-attention Diffusion Models and the Potential for Text-Guided Customization**|糖尿病足溃疡（DFU）对医疗保健构成了重大挑战，需要精确有效的伤口评估来提高患者的治疗效果。本研究介绍了注意力扩散零样本无监督系统（ADZUS），这是一种新的文本引导扩散模型，可以在不依赖标记训练数据的情况下进行伤口分割。与需要大量注释的传统深度学习模型不同，ADZUS利用零样本学习基于描述性提示动态调整分割，在临床应用中提供增强的灵活性和适应性。实验评估表明，ADZUS超越了传统和最先进的分割模型，在慢性伤口数据集上实现了86.68%的IoU和94.69%的最高精度，优于FUSegNet等监督方法。对定制的DFU数据集的进一步验证增强了其稳健性，ADZUS的DSC中值为75%，大大超过了FUSegNet的45%。该模型的文本引导分割功能实现了分割输出的实时定制，允许基于临床描述对伤口特征进行有针对性的分析。尽管其性能具有竞争力，但基于扩散的推理的计算成本和潜在的微调需求仍然是未来需要改进的领域。ADZUS代表了伤口分割的变革性一步，为医学成像提供了一种可扩展、高效和适应性强的人工智能驱动解决方案。 et.al.|[2504.17628](http://arxiv.org/abs/2504.17628)|null|
|**2025-04-24**|**TarDiff: Target-Oriented Diffusion Guidance for Synthetic Electronic Health Record Time Series Generation**|合成电子健康记录（EHR）时间序列生成对于推进临床机器学习模型至关重要，因为它通过提供更多的训练数据来帮助解决数据稀缺问题。然而，大多数现有方法主要侧重于复制真实世界数据的统计分布和时间依赖性。我们认为，仅对观测数据的保真度并不能保证更好的模型性能，因为常见模式可能占主导地位，限制了罕见但重要条件的表示。这突显了生成合成样本以提高特定临床模型性能以实现其目标结果的必要性。为了解决这个问题，我们提出了TarDiff，这是一种新的面向目标的扩散框架，将特定任务的影响引导集成到合成数据生成过程中。与模拟训练数据分布的传统方法不同，TarDiff通过量化合成样本对通过影响函数提高下游模型性能的预期贡献来优化合成样本。具体来说，我们测量合成样本引起的任务特定损失的减少，并将这种影响梯度嵌入到反向扩散过程中，从而将生成转向效用优化的数据。在六个公开可用的EHR数据集上进行评估后，TarDiff达到了最先进的性能，在AUPRC和AUROC中分别比现有方法高出20.4%和18.4%。我们的研究结果表明，TarDiff不仅保留了时间保真度，还提高了下游模型的性能，为医疗分析中的数据稀缺和类别不平衡提供了一个稳健的解决方案。 et.al.|[2504.17613](http://arxiv.org/abs/2504.17613)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-23**|**Spot solutions to a neural field equation on oblate spheroids**|理解神经场中激发模式的动力学是神经科学的一个重要课题。神经场方程是描述相互作用神经元的激发动力学以进行理论分析的数学模型。尽管许多神经场方程的分析都集中在神经元相互作用对平面的影响上，但在对大脑等器官进行建模时，动力学的几何约束也是一个有吸引力的话题。本文报道了在球体作为模型曲面上定义的神经场方程中的模式动力学。我们将点解视为局部模式，并讨论曲面的几何特性如何改变它们的特性。为了分析具有小展平的球体上的斑点模式，我们首先在球面上构造精确的静止斑点解，并揭示它们的稳定性。然后，我们扩展了分析，以证明球状情况下驻点解的存在性和稳定性。我们的一个理论结果是推导了扁球体极点处定域的驻点解的稳定性判据。该标准决定了点解是保持在极点还是移动。最后，我们进行了数值模拟，根据我们的理论预测讨论了点解的动力学。我们的结果表明，点解的动力学取决于曲面和神经相互作用的协调。 et.al.|[2504.16342](http://arxiv.org/abs/2504.16342)|null|
|**2025-04-22**|**Low-Rank Adaptation of Neural Fields**|处理视觉数据通常涉及微小的调整或变化序列，例如图像滤波、表面平滑和视频存储。虽然现有的图形技术，如法线映射和视频压缩，利用冗余来有效地对这种小变化进行编码，但对神经场（NF）的小变化（视觉或物理功能的神经网络参数化）进行编码的问题却很少受到关注。我们提出了一种使用低秩自适应（LoRA）更新神经场的参数高效策略。LoRA是一种来自参数高效微调LLM社区的方法，它以最小的计算开销对预训练模型进行小更新编码。我们使LoRA适应特定于实例的神经场，避免了对大型预训练模型的需求，从而产生了适用于低计算硬件的流水线。我们通过图像滤波、视频压缩和几何编辑的实验验证了我们的方法，证明了它在表示神经场更新方面的有效性和通用性。 et.al.|[2504.15933](http://arxiv.org/abs/2504.15933)|null|
|**2025-04-21**|**Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields**|弱引力透镜是星系形状的轻微扭曲，主要是由宇宙中暗物质的引力效应引起的。在我们的工作中，我们试图从2D望远镜图像中反转弱透镜信号，以重建宇宙暗物质场的3D图。虽然反演通常会产生暗物质场的二维投影，但暗物质分布的精确三维图对于定位感兴趣的结构和测试我们宇宙的理论至关重要。然而，3D反演带来了重大挑战。首先，与依赖于多个视点的标准3D重建不同，在这种情况下，图像仅从单个视点观察。通过观察整个体积中的星系发射器是如何被透镜化的，可以部分解决这一挑战。然而，这导致了第二个挑战：无透镜星系的形状和确切位置是未知的，只能在非常大的不确定性下进行估计。这引入了大量的噪声，几乎完全淹没了透镜信号。以前的方法通过对卷中的结构施加强有力的假设来解决这个问题。相反，我们提出了一种使用引力约束神经场来灵活模拟连续物质分布的方法。我们采用综合分析方法，通过完全可微的物理正向模型优化神经网络的权重，以再现图像测量中存在的透镜信号。我们展示了我们的模拟方法，包括模拟即将到来的望远镜调查数据的暗物质分布的真实模拟测量。我们的结果表明，我们的方法不仅可以超越以前的方法，而且重要的是还能够恢复潜在的令人惊讶的暗物质结构。 et.al.|[2504.15262](http://arxiv.org/abs/2504.15262)|null|
|**2025-04-20**|**Efficient Implicit Neural Compression of Point Clouds via Learnable Activation in Latent Space**|隐式神经表示（INR），也称为神经场，已成为深度学习中的一种强大范式，使用基于坐标的神经网络对连续空间场进行参数化。在本文中，我们提出了\textbf{PICO}，这是一个基于INR的静态点云压缩框架。与主流的编码器-解码器范式不同，我们将点云压缩任务分解为两个单独的阶段：几何压缩和属性压缩，每个阶段都有不同的INR优化目标。受Kolmogorov-Arnold网络（KANs）的启发，我们引入了一种新的网络架构\textbf{LeAFNet}，它利用潜在空间中的可学习激活函数来更好地近似目标信号的隐函数。通过将点云压缩重新表述为神经参数压缩，我们通过量化和熵编码进一步提高了压缩效率。实验结果表明，\textbf{LeAFNet}在基于INR的点云压缩中优于传统的MLP。此外，与当前的MPEG点云压缩标准相比，\textbf{PICO}实现了卓越的几何压缩性能，D1 PSNR平均提高了4.92 $dB。在联合几何和属性压缩方面，我们的方法表现出了极具竞争力的结果，平均PCQM增益为2.7美元乘以10^{-3}$ 。 et.al.|[2504.14471](http://arxiv.org/abs/2504.14471)|null|
|**2025-04-17**|**Radial Basis Function Techniques for Neural Field Models on Surfaces**|我们提出了一种使用径向基函数（RBF）插值和求积求解曲面上神经场方程的数值框架。神经场模型描述了宏观大脑活动的演变，但建模研究往往忽视了弯曲皮质区域的复杂几何形状。传统的数值方法，如有限元或谱方法，在计算上可能很昂贵，并且在不规则域上实现具有挑战性。相比之下，基于RBF的方法提供了一种灵活的替代方案，通过提供插值和正交方案，以高阶精度有效地处理任意几何形状。我们首先为一般曲面上的神经场模型开发了一个基于RBF的插值投影框架。详细推导了平面和曲面域的求积法，确保了高阶精度和稳定性，因为它们取决于RBF超参数（基函数、增广多项式和模板大小）。通过数值实验，我们证明了我们的方法的收敛性，突出了它在灵活性和准确性方面优于传统方法。最后，我们阐述了复杂表面上时空活动的数值模拟，说明了该方法捕捉复杂波传播模式的能力。 et.al.|[2504.13379](http://arxiv.org/abs/2504.13379)|null|
|**2025-04-16**|**SCENT: Robust Spatiotemporal Learning for Continuous Scientific Data via Scalable Conditioned Neural Fields**|由于空间和时间依赖性之间的复杂相互作用、数据的高维度和可扩展性约束，时空学习具有挑战性。这些挑战在科学领域进一步加剧，在这些领域，数据通常是不规则分布的（例如，传感器故障的缺失值）和高容量的（例如高保真模拟），带来了额外的计算和建模困难。在本文中，我们提出了SCENT，这是一种用于可扩展和连续性知情的时空表示学习的新框架。SCENT在单一架构中统一了插值、重建和预测。SCENT建立在基于变换器的编码器-处理器-解码器骨干上，引入了可学习的查询来增强泛化能力，并引入了查询式交叉关注机制来有效捕获多尺度依赖关系。为了确保数据大小和模型复杂性的可扩展性，我们引入了稀疏注意力机制，实现了灵活的输出表示和任意分辨率的高效评估。我们通过广泛的模拟和真实世界的实验来验证SCENT，在实现卓越可扩展性的同时，在多个具有挑战性的任务中展示了最先进的性能。 et.al.|[2504.12262](http://arxiv.org/abs/2504.12262)|null|
|**2025-04-14**|**DNF-Avatar: Distilling Neural Fields for Real-time Animatable Avatar Relighting**|从单眼视频中创建可重现和可动画化的人类化身是一个新兴的研究课题，具有广泛的应用，例如虚拟现实、体育和视频游戏。之前的研究利用神经场和基于物理的渲染（PBR）来估计人类化身的几何形状并解开其外观属性。然而，这些方法的一个缺点是由于昂贵的蒙特卡洛射线追踪导致渲染速度较慢。为了解决这个问题，我们提出将隐式神经场（教师）的知识提取为显式的2D高斯飞溅（学生）表示，以利用高斯飞溅的快速光栅化特性。为了避免光线追踪，我们对PBR外观采用了分裂和近似。我们还提出了用于阴影计算的新型部分式环境遮挡探头。阴影预测是通过每像素只查询一次这些探测器来实现的，这为化身的实时重新照明铺平了道路。这些技术相结合，可以提供高质量的重新照明效果和逼真的阴影效果。我们的实验表明，所提出的学生模型与我们的教师模型实现了相当甚至更好的重新照明结果，同时在推理时快了370倍，达到了67 FPS的渲染速度。 et.al.|[2504.10486](http://arxiv.org/abs/2504.10486)|null|
|**2025-04-11**|**SN-LiDAR: Semantic Neural Fields for Novel Space-time View LiDAR Synthesis**|最近的研究已经开始探索激光雷达点云的新颖视图合成（NVS），旨在从看不见的视点生成逼真的激光雷达扫描。然而，大多数现有的方法都不能重建语义标签，而语义标签对于自动驾驶和机器人感知等许多下游应用至关重要。与受益于强大分割模型的图像不同，LiDAR点云缺乏如此大规模的预训练模型，这使得语义标注既费时又费力。为了应对这一挑战，我们提出了SN LiDAR，这是一种联合执行精确语义分割、高质量几何重建和逼真LiDAR合成的方法。具体来说，我们采用从粗到细的平面网格特征表示来从多帧点云中提取全局特征，并利用基于CNN的编码器从当前帧点云中提取局部语义特征。SemanticKITTI和KITTI-360的大量实验证明了SN LiDAR在语义和几何重建方面的优越性，有效地处理了动态对象和大规模场景。代码将在https://github.com/dtc111111/SN-Lidar. et.al.|[2504.08361](http://arxiv.org/abs/2504.08361)|**[link](https://github.com/dtc111111/sn-lidar)**|
|**2025-04-08**|**econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic Gaussians**|最近关于开放词汇神经场的工作的主要重点是从VLM中提取精确的语义特征，然后将它们有效地整合到多视图一致的3D神经场表示中。然而，大多数现有的工作都是在受信任的SAM上进行的，以规范图像级CLIP，而无需进一步细化。此外，一些现有的研究通过在与3DGS语义场融合之前对2D VLM的语义特征进行降维来提高效率，这不可避免地导致了多视图不一致。在这项工作中，我们提出了使用3DGS进行开放式词汇语义分割的econSG。我们的econSG由以下部分组成：1）置信区间引导正则化（CRR），它相互细化SAM和CLIP，以获得具有完整和精确边界的精确语义特征的两全其美。2）低维上下文空间，通过融合反投影的多视图2D特征来增强3D多视图一致性，同时提高计算效率，然后直接对融合的3D特征进行降维，而不是分别对每个2D视图进行操作。与现有方法相比，我们的econSG在四个基准数据集上显示了最先进的性能。此外，我们也是所有方法中最有效的培训。 et.al.|[2504.06003](http://arxiv.org/abs/2504.06003)|null|
|**2025-04-08**|**Meta-Continual Learning of Neural Fields**|神经场（NF）作为一种用于复杂数据表示的通用框架，已经获得了突出地位。这项工作揭示了一个新的问题设置，称为“神经场元连续学习”（MCL-NF），并引入了一种新的策略，该策略采用模块化架构与基于优化的元学习相结合。我们的策略侧重于克服现有神经场连续学习方法的局限性，如灾难性遗忘和缓慢收敛，实现了高质量的重建，显著提高了学习速度。我们进一步引入了神经辐射场的Fisher信息最大化损失（FIM-NeRF），它在样本级别最大化信息增益以增强学习泛化，并证明了收敛保证和泛化界限。我们在六个不同的数据集上对图像、音频、视频重建和视图合成任务进行了广泛的评估，证明了我们的方法在重建质量和速度方面优于现有的MCL和CL-NF方法。值得注意的是，我们的方法在降低参数要求的情况下，实现了神经场对城市级NeRF渲染的快速适应。 et.al.|[2504.05806](http://arxiv.org/abs/2504.05806)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

