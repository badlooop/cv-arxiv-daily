---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.04.24
> Usage instructions: [here](./docs/README.md#usage)

## Video Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-23**|**BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation**|文本到视频（T2V）生成模型已经迅速发展，并在娱乐、教育和营销等领域得到了广泛应用。然而，这些模型的对抗性弱点仍然很少被探索。我们观察到，在T2V生成任务中，生成的视频通常包含文本提示中未明确指定的大量冗余信息，如环境元素、次要对象和其他细节，为恶意攻击者嵌入隐藏的有害内容提供了机会。利用这种固有的冗余，我们引入了BadVideo，这是为T2V一代量身定制的第一个后门攻击框架。我们的攻击侧重于通过两种关键策略设计目标对抗输出：（1）时空组合，它结合了不同的时空特征来编码恶意信息；（2）动态元素转换，它随着时间的推移在冗余元素中引入转换，以传达恶意信息。基于这些策略，攻击者的恶意目标与用户的文本指令无缝集成，提供了高度的隐蔽性。此外，通过利用视频的时间维度，我们的攻击成功地避开了主要分析单个帧内空间信息的传统内容审核系统。大量实验表明，BadVideo在保持原始语义和在干净输入上保持出色性能的同时，实现了高攻击成功率。总的来说，我们的工作揭示了T2V模型的对抗性脆弱性，引起了人们对潜在风险和滥用的关注。我们的项目页面位于https://wrt2000.github.io/BadVideo2025/. et.al.|[2504.16907](http://arxiv.org/abs/2504.16907)|null|
|**2025-04-23**|**ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree and Visual Guidance**|尽管机器人操作视频合成的最新进展显示出希望，但在确保有效的指令遵循和实现高视觉质量方面仍存在重大挑战。最近的方法，如RoboDreamer，利用语言分解将指令划分为单独的低级原语，在这些原语上调节世界模型，以实现组合指令跟踪。然而，这些独立的原语没有考虑它们之间存在的关系。此外，最近的方法忽略了有价值的视觉引导，包括深度和语义引导，这两者对于提高视觉质量都至关重要。本文介绍了基于动作树和视觉引导的先进世界模型ManipDreamer。为了更好地了解指令原语之间的关系，我们将指令表示为动作树，并将嵌入分配给树节点，每条指令都可以通过在动作树中导航来获取其嵌入。指令嵌入可用于指导世界模型。为了提高视觉质量，我们通过引入与世界模型兼容的视觉引导适配器，将深度和语义引导结合起来。这种视觉适配器增强了视频生成的时间和物理一致性。基于动作树和视觉引导，ManipDreamer显著提高了指令遵循能力和视觉质量。对机器人操作基准的综合评估表明，与最近的RoboDreamer模型相比，ManipDreamer在可见和不可见任务中的视频质量指标都有了很大的提高，PSNR从19.55提高到21.05，SSIM从0.7474提高到0.7982，在不可见任务中将Flow Error从3.506降低到3.201。此外，我们的方法在6个RLbench任务中平均将机器人操纵任务的成功率提高了2.5%。 et.al.|[2504.16464](http://arxiv.org/abs/2504.16464)|null|
|**2025-04-23**|**VideoMark: A Distortion-Free Robust Watermarking Framework for Video Diffusion Models**|这项工作提出了VideoMark，这是一个用于视频扩散模型的无训练鲁棒水印框架。随着传播模型在生成高度逼真的视频方面的进步，对可靠的内容归因机制的需求变得至关重要。虽然图像扩散模型的水印技术取得了进展，但由于视频长度可变和易受时间攻击，将这些方法直接扩展到视频中会带来独特的挑战。VideoMark通过使用伪随机纠错（PRC）码在生成过程中嵌入水印信息的逐帧水印策略来解决这些限制。我们的方法生成一个扩展的水印消息序列，并为每个视频随机选择起始位置，确保潜在空间中的噪声分布均匀，并保持生成质量。对于水印提取，我们引入了一个时间匹配模块（TMM），该模块使用编辑距离将解码的消息与原始水印序列对齐，从而提供对帧删除等时间攻击的鲁棒性。实验结果表明，VideoMark在保持视频质量与无水印生成相当的同时，实现了比现有方法更高的解码精度。重要的是，我们的水印在没有密钥的情况下仍然无法被攻击者检测到，与其他水印框架相比，确保了很强的不可察觉性。VideoMark为基于扩散的视频生成中的内容归因提供了一种实用的解决方案，无需额外的训练或牺牲视频质量。我们的代码和数据可在\href获得{https://github.com/KYRIE-LI11/VideoMark}{https://github.com/KYRIE-LI11/VideoMark}. et.al.|[2504.16359](http://arxiv.org/abs/2504.16359)|null|
|**2025-04-22**|**Survey of Video Diffusion Models: Foundations, Implementations, and Applications**|扩散模型的最新进展彻底改变了视频生成，与传统的基于生成对抗网络的方法相比，它提供了更优的时间一致性和视觉质量。虽然这一新兴领域在应用方面显示出巨大的前景，但它在运动一致性、计算效率和伦理考虑方面面临着重大挑战。本调查全面回顾了基于扩散的视频生成，考察了其演变、技术基础和实际应用。我们对当前的方法进行了系统的分类，分析了架构创新和优化策略，并研究了去噪和超分辨率等低级视觉任务的应用。此外，我们还探索了基于扩散的视频生成与相关领域之间的协同作用，包括视频表示学习、问答和检索。与现有的调查（Lei等人，2024a；b；Melnik等人，2024；Cao等人，2023；Xing等人，2024c）相比，这些调查侧重于视频生成的特定方面，如人体视频合成（Lei等，2024a）或长格式内容生成（Lei et al.，2024b），我们的工作为基于扩散的方法提供了更广泛、更更新、更精细的视角，并专门讨论了视频生成中的评估指标、行业解决方案和培训工程技术。这项调查为在扩散模型和视频生成交叉领域工作的研究人员和从业者提供了基础资源，为推动这一快速发展的领域的理论框架和实际实施提供了见解。本次调查涉及的相关工作的结构化列表也可在https://github.com/Eyeline-Research/Survey-Video-Diffusion. et.al.|[2504.16081](http://arxiv.org/abs/2504.16081)|null|
|**2025-04-22**|**Efficient Temporal Consistency in Diffusion-Based Video Editing with Adaptor Modules: A Theoretical Framework**|基于适配器的方法通常用于以最小的额外复杂性提高模型性能，特别是在需要帧间一致性的视频编辑任务中。通过将小的、可学习的模块插入预训练的扩散模型中，这些适配器可以在不进行大量再训练的情况下保持时间连贯性。将快速学习与共享和帧特定令牌相结合的方法在以低训练成本保持帧间的连续性方面特别有效。在这项工作中，我们希望为适配器提供一个通用的理论框架，以便在时间一致性丢失的情况下，在基于DDIM的模型中保持帧一致性。首先，我们证明了时间一致性目标在有界特征范数下是可微的，并在其梯度上建立了Lipschitz界。其次，我们证明，如果学习率在适当的范围内，在这个目标上的梯度下降会单调地减少损失并收敛到局部最小值。最后，我们分析了DDIM反演过程中模块的稳定性，表明相关误差保持可控。这些理论发现将加强基于扩散的视频编辑方法的可靠性，这些方法依赖于适配器策略，并为视频生成任务提供理论见解。 et.al.|[2504.16016](http://arxiv.org/abs/2504.16016)|null|
|**2025-04-22**|**Reasoning Physical Video Generation with Diffusion Timestep Tokens via Reinforcement Learning**|尽管最近在视频生成方面取得了进展，但制作符合物理定律的视频仍然是一个重大挑战。传统的基于扩散的方法由于依赖于数据驱动的近似值，很难推断出看不见的物理条件（如速度）。为了解决这个问题，我们建议将符号推理和强化学习相结合，以增强视频生成中的物理一致性。我们首先介绍扩散时间步标记器（DDT），它通过恢复扩散过程中丢失的视觉属性来学习离散的递归视觉标记。递归视觉标记允许通过大型语言模型进行符号推理。在此基础上，我们提出了Phys AR框架，该框架分为两个阶段：第一阶段使用监督微调来传递符号知识，第二阶段应用强化学习通过基于物理条件的奖励函数来优化模型的推理能力。我们的方法允许模型动态调整和改进生成视频的物理属性，确保遵守物理定律。实验结果表明，PhysAR可以生成物理一致的视频。 et.al.|[2504.15932](http://arxiv.org/abs/2504.15932)|null|
|**2025-04-22**|**Satellite to GroundScape -- Large-scale Consistent Ground View Generation from Satellite Views**|从卫星图像生成一致的地面视图图像具有挑战性，主要是由于卫星和地面域之间的视角和分辨率存在很大差异。之前的工作主要集中在单视图生成上，这通常会导致相邻地面视图之间的不一致。在这项工作中，我们提出了一种新的交叉视图合成方法，旨在通过确保从卫星视图生成的地面视图图像的一致性来克服这些挑战。我们的方法基于固定的潜在扩散模型，引入了两个条件模块：卫星引导去噪，提取高级场景布局来指导去噪过程，以及卫星时间去噪，捕获相机运动以保持多个生成视图的一致性。我们还贡献了一个包含100000多个透视对的大规模卫星地面数据集，以促进广泛的地面场景或视频生成。实验结果表明，我们的方法在感知和时间度量方面优于现有方法，在多视图输出中实现了高真实感和一致性。 et.al.|[2504.15786](http://arxiv.org/abs/2504.15786)|null|
|**2025-04-22**|**DiTPainter: Efficient Video Inpainting with Diffusion Transformers**|许多现有的视频修复算法利用光流来构建相应的映射，然后通过映射将像素从相邻帧传播到缺失区域。尽管传播机制有效，但在处理不准确的光流或大掩模时，它们可能会遇到模糊和不一致的情况。最近，扩散变换器（DiT）已经成为视频生成任务的革命性技术。然而，用于视频生成的预训练DiT模型都包含大量参数，这使得应用于视频修复任务非常耗时。本文提出了一种基于扩散变换（DiT）的端到端视频修复模型DiTPainter。DiTPainter使用了一种为视频修复设计的高效变压器网络，该网络是从头开始训练的，而不是从任何大型预训练模型初始化。DiTPainter可以处理任意长度的视频，并且可以以可接受的时间成本应用于视频去盖和视频完成任务。实验表明，DiTPainter在质量和时空一致性方面优于现有的视频修复算法。 et.al.|[2504.15661](http://arxiv.org/abs/2504.15661)|null|
|**2025-04-21**|**Solving New Tasks by Adapting Internet Video Knowledge**|视频生成模型作为视觉规划者或政策监督者，在机器人领域展现出巨大的潜力。当在互联网规模的数据上进行预训练时，这样的视频模型可以很好地理解与自然语言的对齐，从而可以通过文本条件化促进对新的下游行为的泛化。然而，它们可能对病原体所居住的特定环境的特性不敏感。另一方面，在机器人行为的域内示例上训练视频模型自然会编码特定环境的复杂性，但可用演示的规模可能不足以支持通过自然语言规范对看不见的任务进行泛化。在这项工作中，我们研究了将域内信息与大规模预训练视频模型集成的不同适应技术，并探索了它们在多大程度上为机器人任务提供了新的文本条件泛化，同时考虑了它们的独立数据和资源考虑。我们成功地在机器人环境中证明，使用小规模的示例数据调整强大的视频模型可以成功地促进对新行为的泛化。特别是，我们提出了一种新的自适应策略，称为逆概率自适应，它不仅在机器人任务和设置中始终如一地实现了强大的泛化性能，而且对自适应数据的质量表现出鲁棒性，即使在只有次优域内演示可用的情况下，也能成功解决新任务。 et.al.|[2504.15369](http://arxiv.org/abs/2504.15369)|null|
|**2025-04-21**|**Tiger200K: Manually Curated High Visual Quality Video Dataset from UGC Platform**|最近开源文本到视频生成模型的激增极大地激励了研究界，但它们对专有训练数据集的依赖仍然是一个关键的制约因素。虽然像Koala-36M这样的现有开放数据集对早期平台的网络抓取视频进行了算法过滤，但它们仍然缺乏微调高级视频生成模型所需的质量。我们介绍Tiger200K，这是一个来自用户生成内容（UGC）平台的手动策划的高视觉质量视频数据集。通过优先考虑视觉保真度和美学质量，Tiger200K强调了人类专业知识在数据管理中的关键作用，并通过简单有效的管道（包括镜头边界检测、OCR、边界检测、运动过滤器和精细双语字幕）提供高质量、时间一致的视频文本对，用于微调和优化视频生成架构。该数据集将持续扩展，并作为开源项目发布，以推进视频生成模型的研究和应用。项目页面：https://tinytigerpan.github.io/tiger200k/ et.al.|[2504.15182](http://arxiv.org/abs/2504.15182)|null|

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-22**|**Satellite to GroundScape -- Large-scale Consistent Ground View Generation from Satellite Views**|从卫星图像生成一致的地面视图图像具有挑战性，主要是由于卫星和地面域之间的视角和分辨率存在很大差异。之前的工作主要集中在单视图生成上，这通常会导致相邻地面视图之间的不一致。在这项工作中，我们提出了一种新的交叉视图合成方法，旨在通过确保从卫星视图生成的地面视图图像的一致性来克服这些挑战。我们的方法基于固定的潜在扩散模型，引入了两个条件模块：卫星引导去噪，提取高级场景布局来指导去噪过程，以及卫星时间去噪，捕获相机运动以保持多个生成视图的一致性。我们还贡献了一个包含100000多个透视对的大规模卫星地面数据集，以促进广泛的地面场景或视频生成。实验结果表明，我们的方法在感知和时间度量方面优于现有方法，在多视图输出中实现了高真实感和一致性。 et.al.|[2504.15786](http://arxiv.org/abs/2504.15786)|null|
|**2025-04-22**|**Pose Optimization for Autonomous Driving Datasets using Neural Rendering Models**|自动驾驶系统依赖于对自我汽车的准确感知和定位，以确保在具有挑战性的现实驾驶场景中的安全性和可靠性。公共数据集通过为模型开发和评估提供标准化资源，在基准测试和指导研究进展方面发挥着至关重要的作用。然而，这些数据集中传感器校准和车辆姿态的潜在不准确可能会导致对下游任务的错误评估，从而对自主系统的可靠性和性能产生不利影响。为了应对这一挑战，我们提出了一种基于神经辐射场（NeRF）的鲁棒优化方法，以细化传感器姿态和校准参数，增强数据集基准的完整性。为了验证在没有地面真实性的情况下优化姿态的准确性的提高，我们提出了一个全面的评估过程，该过程依赖于重投影指标、新视图合成渲染质量和几何对齐。我们证明，我们的方法在传感器姿态精度方面取得了显著提高。通过优化这些关键参数，我们的方法不仅提高了现有数据集的效用，还为更可靠的自动驾驶模型铺平了道路。为了促进该领域的持续进步，我们公开了优化的传感器姿态，为研究界提供了宝贵的资源。 et.al.|[2504.15776](http://arxiv.org/abs/2504.15776)|null|
|**2025-04-21**|**MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry Monocular Video**|我们提出了MoBGS，这是一种新颖的去模糊动态3D高斯散斑（3DGS）框架，能够以端到端的方式从模糊的单眼视频中重建清晰、高质量的新颖时空视图。现有的动态新颖视图合成（NVS）方法对随意捕获的视频中的运动模糊高度敏感，导致渲染质量显著下降。虽然最近的方法解决了NVS的运动模糊输入问题，但它们主要侧重于静态场景重建，缺乏针对动态对象的专用运动建模。为了克服这些局限性，我们的MoBGS引入了一种新的模糊自适应潜在相机估计（BLCE）方法，用于有效的潜在相机轨迹估计，改善了全局相机运动去模糊。此外，我们提出了一种受物理启发的潜在相机诱导曝光估计（LCEE）方法，以确保全局相机和局部对象运动的一致去模糊。我们的MoBGS框架确保了看不见的潜在时间戳的时间一致性，以及静态和动态区域的鲁棒运动分解。对立体模糊数据集和真实世界模糊视频的广泛实验表明，我们的MoBGS明显优于最新的先进方法（DyBluRF和Deblur4DGS），在运动模糊下实现了最先进的动态NVS性能。 et.al.|[2504.15122](http://arxiv.org/abs/2504.15122)|null|
|**2025-04-20**|**IXGS-Intraoperative 3D Reconstruction from Sparse, Arbitrarily Posed Real X-rays**|脊柱手术是一种高风险的干预措施，需要精确的执行，通常由基于图像的导航系统支持。最近，监督学习方法在从稀疏荧光透视数据重建3D脊柱解剖结构方面受到了关注，大大降低了对辐射密集型3D成像系统的依赖。然而，这些方法通常需要大量带注释的训练数据，并且可能难以在不同的患者解剖结构或成像条件下进行推广。高斯飞溅等实例学习方法可以避免大量的注释要求，从而提供一种替代方案。虽然高斯溅射显示出新的视图合成的前景，但它在稀疏、任意姿势的真实术中X射线中的应用在很大程度上仍未得到探索。这项工作通过扩展 $R^2$ -Gassian飞溅框架来解决这一局限性，以在这些具有挑战性的条件下重建解剖学上一致的3D体积。我们引入了一种使用样式转换的解剖引导放射学标准化步骤，提高了视图之间的视觉一致性，并提高了重建质量。值得注意的是，我们的框架不需要预训练，使其天生就能适应新的患者和解剖结构。我们使用离体数据集评估了我们的方法。专家手术评估证实了3D重建在导航方面的临床实用性，特别是在使用20到30个视图时，并强调了标准化对解剖清晰度的好处。通过定量2D指标（PSNR/SSIM）进行的基准测试证实了与理想设置相比的性能权衡，但也验证了标准化对原始输入的改进。这项工作证明了从任意稀疏视图X射线进行基于实例的体积重建的可行性，推进了手术导航的术中3D成像。 et.al.|[2504.14699](http://arxiv.org/abs/2504.14699)|null|
|**2025-04-20**|**VGNC: Reducing the Overfitting of Sparse-view 3DGS via Validation-guided Gaussian Number Control**|稀疏视图3D重建是实际3D重建应用中一项基本但具有挑战性的任务。最近，已经提出了许多基于3D高斯散斑（3DGS）框架的方法来解决稀疏视图3D重建问题。尽管这些方法取得了相当大的进步，但它们仍然存在过拟合的重大问题。为了减少过拟合，我们引入了VGNC，这是一种基于生成新视图合成（NVS）模型的新型验证引导高斯数控制（VGNC）方法。据我们所知，这是首次尝试通过生成验证图像来缓解稀疏视图3DGS的过拟合问题。具体来说，我们首先介绍了一种基于生成NVS模型的验证图像生成方法。然后，我们提出了一种高斯数控制策略，该策略利用生成的验证图像来确定最优高斯数，从而减少过拟合问题。我们在各种稀疏视图3DGS基线和数据集上进行了详细的实验，以评估VGNC的有效性。大量实验表明，我们的方法不仅减少了过拟合，而且在减少高斯点数量的同时提高了测试集的渲染质量。这种减少降低了存储需求，加速了训练和渲染。代码将被发布。 et.al.|[2504.14548](http://arxiv.org/abs/2504.14548)|null|
|**2025-04-20**|**Metamon-GS: Enhancing Representability with Variance-Guided Densification and Light Encoding**|3D高斯散点（3DGS）的引入通过利用高斯来表示场景，推进了新的视图合成。使用锚嵌入对高斯点特征进行编码显著提高了较新3DGS变体的性能。虽然已经取得了重大进展，但提高渲染性能仍然具有挑战性。特征嵌入很难在不同的光照条件下从不同的角度准确地表示颜色，这会导致外观褪色。另一个原因是缺乏适当的致密化策略来防止高斯点在初始化稀疏的区域生长，从而导致模糊和针状伪影。为了解决这些问题，我们从方差引导的致密化策略和多级哈希网格的创新角度提出了Metamon GS。方差引导的密集化策略专门针对像素中具有高梯度方差的高斯分布，并补偿了具有额外高斯分布的区域对改善重建的重要性。后者研究隐含的全局光照条件，并从不同的角度和特征嵌入准确地解释颜色。我们在公开数据集上的彻底实验表明，Metamon GS超越了其基线模型和以前的版本，在渲染新颖视图方面提供了卓越的质量。 et.al.|[2504.14460](http://arxiv.org/abs/2504.14460)|null|
|**2025-04-21**|**SLAM&Render: A Benchmark for the Intersection Between Neural Rendering, Gaussian Splatting and SLAM**|最初为新颖的视图合成和场景渲染开发的模型和方法，如神经辐射场（NeRF）和高斯散斑，正越来越多地被用作同步定位和映射（SLAM）中的表示。然而，现有的数据集未能包括这两个领域的具体挑战，例如SLAM中的多模态和顺序性，或神经渲染中跨视点和光照条件的泛化。为了弥合这一差距，我们引入了SLAM&Render，这是一个新的数据集，旨在为SLAM和新视图渲染之间的交叉点方法进行基准测试。它由40个序列组成，具有同步的RGB、深度、IMU、机器人运动学数据和地面真实姿态流。通过发布机器人运动学数据，该数据集还可以评估应用于机器人操纵器的新型SLAM策略。数据集序列涵盖了五种不同的设置，在四种不同的光照条件下展示消费者和工业对象，每个场景都有单独的训练和测试轨迹，以及对象重新排列。我们的实验结果是通过文献中的几个基线获得的，验证了SLAM和Render是这一新兴研究领域的相关基准。 et.al.|[2504.13713](http://arxiv.org/abs/2504.13713)|**[link](https://github.com/samuel-cerezo/SLAM-Render)**|
|**2025-04-17**|**Novel Demonstration Generation with Gaussian Splatting Enables Robust One-Shot Manipulation**|从远程操作演示中学习到的Visuomotor政策面临着数据收集时间长、成本高、数据多样性有限等挑战。现有的方法通过增强RGB空间中的图像观测或基于物理模拟器采用Real到Sim到Real的管道来解决这些问题。然而，前者仅限于二维数据增强，而后者则因不准确的几何重建而遭受不精确的物理模拟。本文介绍了RoboSplat，这是一种通过直接操纵3D高斯分布生成多样化、视觉逼真演示的新方法。具体来说，我们通过3D高斯散布（3DGS）重建场景，直接编辑重建的场景，并使用五种技术在六种类型的泛化中增强数据：不同对象类型的3D高斯替换、场景外观和机器人实施例；不同物体姿态的等变变换；针对各种照明条件的视觉属性编辑；用于新相机视角的新颖视图合成；以及用于不同对象类型的3D内容生成。全面的现实世界实验表明，RoboSplat在各种干扰下显著提高了视觉运动策略的泛化能力。值得注意的是，虽然经过数百次真实世界演示和额外2D数据增强训练的策略的平均成功率为57.2%，但RoboSplat在现实世界中的六种泛化类型的单次设置中达到了87.8%。 et.al.|[2504.13175](http://arxiv.org/abs/2504.13175)|null|
|**2025-04-18**|**ODHSR: Online Dense 3D Reconstruction of Humans and Scenes from Monocular Videos**|在以人类为中心的3D世界的感知中，从野生视频中的单个单眼创建逼真的场景和人类重建非常重要。最近的神经渲染技术进步实现了整体的人体场景重建，但需要预先校准的相机和人体姿势，以及数天的训练时间。在这项工作中，我们介绍了一种新的统一框架，该框架以在线方式同时执行相机跟踪、人体姿态估计和人体场景重建。3D高斯散点用于高效地学习人类和场景的高斯基元，基于重建的相机跟踪和人体姿态估计模块旨在实现对姿态和外观的全面理解和有效解纠缠。具体来说，我们设计了一个人体变形模块来重建细节，并增强对不均匀姿势的泛化能力。为了准确了解人与场景之间的空间相关性，我们引入了遮挡感知的人体轮廓渲染和单目几何先验，进一步提高了重建质量。在EMDB和NeuMan数据集上的实验表明，在相机跟踪、人体姿态估计、新颖的视图合成和运行时方面，其性能优于或与现有方法相当。我们的项目页面位于https://eth-ait.github.io/ODHSR. et.al.|[2504.13167](http://arxiv.org/abs/2504.13167)|null|
|**2025-04-17**|**AerialMegaDepth: Learning Aerial-Ground Reconstruction and View Synthesis**|我们探索了从地面和空中混合视图中捕获的图像的几何重建任务。目前最先进的基于学习的方法无法处理航空地面图像对之间的极端视点变化。我们的假设是，缺乏用于训练的高质量、共同注册的空地数据集是导致这一失败的关键原因。这样的数据很难精确组装，因为很难以可扩展的方式进行重建。为了克服这一挑战，我们提出了一种可扩展的框架，将来自3D城市网格（如谷歌地球）的伪合成渲染与真实的地面众包图像（如MegaDepth）相结合。伪合成数据模拟了广泛的航空视点，而真实的众包图像有助于提高基于网格的渲染缺乏足够细节的地面图像的视觉保真度，有效地弥合了真实图像和伪合成渲染之间的领域差距。使用这个混合数据集，我们对几种最先进的算法进行了微调，并在现实世界的零样本空中任务上取得了重大改进。例如，我们观察到，基线DUSt3R将不到5%的空地对定位在相机旋转误差的5度以内，而对我们的数据进行微调可以将精度提高到近56%，解决了处理大视点变化的一个主要故障点。除了相机估计和场景重建之外，我们的数据集还提高了下游任务的性能，例如在具有挑战性的空地场景中进行新颖的视图合成，这证明了我们的方法在现实世界应用中的实用价值。 et.al.|[2504.13157](http://arxiv.org/abs/2504.13157)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-23**|**Gaussian Splatting is an Effective Data Generator for 3D Object Detection**|我们研究了自动驾驶中3D物体检测的数据增强。我们利用基于高斯散斑的3D重建的最新进展，在驾驶场景中放置3D对象。与现有的基于扩散的合成基于边界元法布局的图像的方法不同，我们的方法通过明确施加的几何变换将3D对象直接放置在重建的3D空间中。这确保了对象放置的物理合理性和高度精确的3D姿态和位置注释。我们的实验表明，即使通过将有限数量的外部3D对象集成到真实场景中，增强数据也能显著提高3D对象检测性能，并且在对象检测方面优于现有的基于扩散的3D增强。对nuScenes数据集的广泛测试表明，与对象的外观多样性相比，在对象放置中施加高度的几何多样性会产生更大的影响。此外，我们表明，通过最大化检测损失或在相机图像中施加高视觉遮挡来生成硬示例，并不能为自动驾驶中基于相机的3D对象检测带来更有效的3D数据增强。 et.al.|[2504.16740](http://arxiv.org/abs/2504.16740)|null|
|**2025-04-23**|**Beyond Anonymization: Object Scrubbing for Privacy-Preserving 2D and 3D Vision Tasks**|我们引入了ROAR（鲁棒对象删除和重新注释），这是一个可扩展的隐私保护数据集混淆框架，可以消除敏感对象而不是修改它们。我们的方法将实例分割与生成修复相结合，在保留场景完整性的同时去除可识别的实体。对基于2D COCO的目标检测的广泛评估表明，ROAR达到了基线检测平均精度（AP）的87.5%，而图像丢弃仅达到了基线AP的74.2%，突显了擦洗在保持数据集效用方面的优势。由于遮挡和细粒度细节的丢失，小对象的退化甚至更严重。此外，在基于NeRF的3D重建中，我们的方法在保持SSIM和改善LPIPS的同时，PSNR损失最多为1.66 dB，表现出卓越的感知质量。我们的研究结果将对象移除确立为一种有效的隐私框架，以最小的性能权衡实现了强有力的隐私保证。研究结果突出了生成修复、遮挡鲁棒分割和特定任务清理方面的关键挑战，为隐私保护视觉系统的未来发展奠定了基础。 et.al.|[2504.16557](http://arxiv.org/abs/2504.16557)|null|
|**2025-04-23**|**PRaDA: Projective Radial Distortion Averaging**|我们解决了在具有挑战性的条件下自动校准径向失真相机的问题。准确确定失真参数通常需要1）解决涉及相机姿态、3D点和失真参数的完整运动结构（SfM）问题，这只有在提供了许多具有足够重叠的图像的情况下才有可能，或者2）严重依赖相对不太准确的基于学习的方法。在这项工作中，我们证明了失真校准可以与3D重建解耦，在保持基于SfM的方法的准确性的同时避免了许多相关的复杂性。这是通过在投影空间中工作来实现的，其中几何体在单应性之前是唯一的，单应性封装了除失真之外的所有相机参数。我们提出的方法，投影径向失真平均法，在完全投影的框架内对多个失真估计进行平均，而无需创建3d点和全束调整。通过依赖成对投影关系，我们的方法支持任何特征匹配方法，而无需在多幅图像上构建点轨迹。 et.al.|[2504.16499](http://arxiv.org/abs/2504.16499)|null|
|**2025-04-22**|**Intent-aware Diffusion with Contrastive Learning for Sequential Recommendation**|对比学习已被证明在训练顺序推荐模型方面是有效的，它结合了来自增强视图的自我监督信号。大多数现有方法通过随机数据增强从同一交互序列中生成多个视图，旨在对齐它们在嵌入空间中的表示。然而，用户在购买物品时通常有特定的意图（例如，购买衣服作为礼物或美容化妆品）。现有方法中使用的随机数据增强可能会引入噪声，破坏原始交互序列中隐含的潜在意图信息。此外，在对比学习中使用噪声增强序列可能会误导模型关注不相关的特征，扭曲嵌入空间，无法捕捉用户的真实行为模式和意图。为了解决这些问题，我们提出了用于顺序推荐的具有对比学习的意图感知扩散（InDiRec）。核心思想是生成与用户购买意图一致的项目序列，从而为对比学习提供更可靠的增强视图。具体来说，InDiRec首先使用K-means对序列表示进行意图聚类，以构建意图引导信号。接下来，它检索目标交互序列的意图表示，以指导条件扩散模型，生成共享相同潜在意图的积极视图。最后，对比学习被应用于最大限度地提高这些意图对齐视图与原始序列之间的表示一致性。在五个公共数据集上进行的广泛实验表明，与现有基线相比，InDiRec具有更优的性能，即使在嘈杂和稀疏的数据条件下也能学习到更稳健的表示。 et.al.|[2504.16077](http://arxiv.org/abs/2504.16077)|null|
|**2025-04-21**|**Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields**|弱引力透镜是星系形状的轻微扭曲，主要是由宇宙中暗物质的引力效应引起的。在我们的工作中，我们试图从2D望远镜图像中反转弱透镜信号，以重建宇宙暗物质场的3D图。虽然反演通常会产生暗物质场的二维投影，但暗物质分布的精确三维图对于定位感兴趣的结构和测试我们宇宙的理论至关重要。然而，3D反演带来了重大挑战。首先，与依赖于多个视点的标准3D重建不同，在这种情况下，图像仅从单个视点观察。通过观察整个体积中的星系发射器是如何被透镜化的，可以部分解决这一挑战。然而，这导致了第二个挑战：无透镜星系的形状和确切位置是未知的，只能在非常大的不确定性下进行估计。这引入了大量的噪声，几乎完全淹没了透镜信号。以前的方法通过对卷中的结构施加强有力的假设来解决这个问题。相反，我们提出了一种使用引力约束神经场来灵活模拟连续物质分布的方法。我们采用综合分析方法，通过完全可微的物理正向模型优化神经网络的权重，以再现图像测量中存在的透镜信号。我们展示了我们的模拟方法，包括模拟即将到来的望远镜调查数据的暗物质分布的真实模拟测量。我们的结果表明，我们的方法不仅可以超越以前的方法，而且重要的是还能够恢复潜在的令人惊讶的暗物质结构。 et.al.|[2504.15262](http://arxiv.org/abs/2504.15262)|null|
|**2025-04-20**|**IXGS-Intraoperative 3D Reconstruction from Sparse, Arbitrarily Posed Real X-rays**|脊柱手术是一种高风险的干预措施，需要精确的执行，通常由基于图像的导航系统支持。最近，监督学习方法在从稀疏荧光透视数据重建3D脊柱解剖结构方面受到了关注，大大降低了对辐射密集型3D成像系统的依赖。然而，这些方法通常需要大量带注释的训练数据，并且可能难以在不同的患者解剖结构或成像条件下进行推广。高斯飞溅等实例学习方法可以避免大量的注释要求，从而提供一种替代方案。虽然高斯溅射显示出新的视图合成的前景，但它在稀疏、任意姿势的真实术中X射线中的应用在很大程度上仍未得到探索。这项工作通过扩展 $R^2$ -Gassian飞溅框架来解决这一局限性，以在这些具有挑战性的条件下重建解剖学上一致的3D体积。我们引入了一种使用样式转换的解剖引导放射学标准化步骤，提高了视图之间的视觉一致性，并提高了重建质量。值得注意的是，我们的框架不需要预训练，使其天生就能适应新的患者和解剖结构。我们使用离体数据集评估了我们的方法。专家手术评估证实了3D重建在导航方面的临床实用性，特别是在使用20到30个视图时，并强调了标准化对解剖清晰度的好处。通过定量2D指标（PSNR/SSIM）进行的基准测试证实了与理想设置相比的性能权衡，但也验证了标准化对原始输入的改进。这项工作证明了从任意稀疏视图X射线进行基于实例的体积重建的可行性，推进了手术导航的术中3D成像。 et.al.|[2504.14699](http://arxiv.org/abs/2504.14699)|null|
|**2025-04-20**|**VGNC: Reducing the Overfitting of Sparse-view 3DGS via Validation-guided Gaussian Number Control**|稀疏视图3D重建是实际3D重建应用中一项基本但具有挑战性的任务。最近，已经提出了许多基于3D高斯散斑（3DGS）框架的方法来解决稀疏视图3D重建问题。尽管这些方法取得了相当大的进步，但它们仍然存在过拟合的重大问题。为了减少过拟合，我们引入了VGNC，这是一种基于生成新视图合成（NVS）模型的新型验证引导高斯数控制（VGNC）方法。据我们所知，这是首次尝试通过生成验证图像来缓解稀疏视图3DGS的过拟合问题。具体来说，我们首先介绍了一种基于生成NVS模型的验证图像生成方法。然后，我们提出了一种高斯数控制策略，该策略利用生成的验证图像来确定最优高斯数，从而减少过拟合问题。我们在各种稀疏视图3DGS基线和数据集上进行了详细的实验，以评估VGNC的有效性。大量实验表明，我们的方法不仅减少了过拟合，而且在减少高斯点数量的同时提高了测试集的渲染质量。这种减少降低了存储需求，加速了训练和渲染。代码将被发布。 et.al.|[2504.14548](http://arxiv.org/abs/2504.14548)|null|
|**2025-04-20**|**Back on Track: Bundle Adjustment for Dynamic Scene Reconstruction**|传统的SLAM系统依赖于捆绑调整，难以应对休闲视频中常见的高度动态场景。这样的视频纠缠了动态元素的运动，破坏了传统系统所需的静态环境的假设。现有技术要么过滤掉动态元素，要么独立地对它们的运动进行建模。然而，前者通常会导致重建不完整，而后者可能会导致运动估计不一致。这项工作采用了一种新颖的方法，利用3D点跟踪器将相机引起的运动与观察到的动态物体的运动分开。通过仅考虑相机引起的分量，束调整可以在所有场景元素上可靠地运行。我们通过基于比例图的轻量级后处理进一步确保视频帧的深度一致性。我们的框架将传统SLAM的核心——捆绑调整——与强大的基于学习的3D跟踪器前端相结合。我们的统一框架BA-Track集成了运动分解、束调整和深度细化，可以准确地跟踪相机运动，并产生时间连贯和尺度一致的密集重建，同时容纳静态和动态元素。我们在具有挑战性的数据集上的实验表明，相机姿态估计和3D重建精度有了显著提高。 et.al.|[2504.14516](http://arxiv.org/abs/2504.14516)|null|
|**2025-04-18**|**Mono3R: Exploiting Monocular Cues for Geometric 3D Reconstruction**|数据驱动的几何多视图3D重建基础模型（如DUSt3R）的最新进展在各种3D视觉任务中表现出了显著的性能，这得益于大规模、高质量3D数据集的发布。然而，正如我们所观察到的，受其基于匹配的原理的限制，现有模型的重建质量在匹配线索有限的具有挑战性的区域中会显著下降，特别是在弱纹理区域和低光照条件下。为了减轻这些局限性，我们建议利用单目几何估计的固有鲁棒性来弥补基于匹配的方法的固有缺点。具体来说，我们引入了一个单目引导的细化模块，该模块将单目几何先验集成到多视图重建框架中。这种集成大大增强了多视图重建系统的鲁棒性，从而实现了高质量的前馈重建。跨多个基准的综合实验表明，我们的方法在多视图相机姿态估计和点云精度方面都取得了实质性的改进。 et.al.|[2504.13419](http://arxiv.org/abs/2504.13419)|null|
|**2025-04-18**|**ODHSR: Online Dense 3D Reconstruction of Humans and Scenes from Monocular Videos**|在以人类为中心的3D世界的感知中，从野生视频中的单个单眼创建逼真的场景和人类重建非常重要。最近的神经渲染技术进步实现了整体的人体场景重建，但需要预先校准的相机和人体姿势，以及数天的训练时间。在这项工作中，我们介绍了一种新的统一框架，该框架以在线方式同时执行相机跟踪、人体姿态估计和人体场景重建。3D高斯散点用于高效地学习人类和场景的高斯基元，基于重建的相机跟踪和人体姿态估计模块旨在实现对姿态和外观的全面理解和有效解纠缠。具体来说，我们设计了一个人体变形模块来重建细节，并增强对不均匀姿势的泛化能力。为了准确了解人与场景之间的空间相关性，我们引入了遮挡感知的人体轮廓渲染和单目几何先验，进一步提高了重建质量。在EMDB和NeuMan数据集上的实验表明，在相机跟踪、人体姿态估计、新颖的视图合成和运行时方面，其性能优于或与现有方法相当。我们的项目页面位于https://eth-ait.github.io/ODHSR. et.al.|[2504.13167](http://arxiv.org/abs/2504.13167)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-23**|**Latent Diffusion Planning for Imitation Learning**|模仿学习的最新进展得益于可扩展到复杂视觉运动任务、多模态分布和大型数据集的策略架构。然而，这些方法往往依赖于从大量专家演示中学习。为了解决这些缺点，我们提出了潜在扩散规划（LDP），这是一种模块化方法，由可以利用无动作演示的规划器和可以利用次优数据的逆动力学模型组成，两者都在学习的潜在空间上运行。首先，我们通过变分自编码器学习一个紧凑的潜在空间，从而能够有效地预测基于图像的域中的未来状态。然后，我们训练一个规划器和一个具有扩散目标的逆动力学模型。通过将计划与行动预测分开，LDP可以从次优和无行动数据的密集监督信号中受益。在模拟的视觉机器人操作任务中，LDP的表现优于最先进的模仿学习方法，因为它们无法利用这些额外的数据。 et.al.|[2504.16925](http://arxiv.org/abs/2504.16925)|null|
|**2025-04-23**|**DreamO: A Unified Framework for Image Customization**|最近，对图像定制（如身份、主题、风格、背景等）的广泛研究表明，在大规模生成模型中具有很强的定制能力。然而，大多数方法都是为特定任务设计的，限制了它们组合不同类型条件的通用性。开发一个统一的图像定制框架仍然是一个悬而未决的挑战。在本文中，我们介绍了DreamO，这是一个图像定制框架，旨在支持广泛的任务，同时促进多种条件的无缝集成。具体来说，DreamO利用扩散变换器（DiT）框架来统一处理不同类型的输入。在训练过程中，我们构建了一个包含各种定制任务的大规模训练数据集，并引入了特征路由约束，以方便从参考图像中精确查询相关信息。此外，我们设计了一种占位符策略，将特定占位符与特定位置的条件相关联，从而可以控制生成结果中条件的放置。此外，我们采用了一种渐进式训练策略，该策略由三个阶段组成：初始阶段侧重于数据有限的简单任务，以建立基线一致性；全面训练阶段，以全面增强定制能力；最终质量对齐阶段，以纠正低质量数据引入的质量偏差。大量实验表明，所提出的DreamO可以有效地执行各种高质量的图像定制任务，并灵活地集成不同类型的控制条件。 et.al.|[2504.16915](http://arxiv.org/abs/2504.16915)|null|
|**2025-04-23**|**Practical approaches for crystal structure predictions with inpainting generation and universal interatomic potentials**|我们提出了晶体主体引导生成（CHGGen），这是一种基于扩散的晶体结构预测框架。随着晶胞尺寸的增加，扩散模型的无条件生成在识别对称晶体方面的效果有限。CHGGen通过条件生成和修复方法解决了这一限制，该方法优化了预定义和对称化宿主结构内的一小部分原子位置。我们在ZnS-P $_2$S$_5$ 和Li-Si化学体系上演示了该方法，其中修复方法产生的对称结构比例高于无条件产生的比例。CHGGen的实际意义延伸到能够对晶体结构进行结构修饰，特别是对于具有部分占据、表面吸收和缺陷的系统。修复方法还允许与其他生成模型无缝集成，为加速材料发现提供了一个通用的框架。 et.al.|[2504.16893](http://arxiv.org/abs/2504.16893)|null|
|**2025-04-23**|**Planning with Diffusion Models for Target-Oriented Dialogue Systems**|目标导向对话（TOD）仍然是法学硕士时代的一个重大挑战，在这个时代，战略对话规划对于将对话引向特定目标至关重要。然而，现有的对话规划方法以循序渐进的方式生成对话计划，可能会出现复合错误和短视行为。为了解决这些局限性，我们引入了一种新的对话规划框架DiffTOD，它利用扩散模型来实现非顺序对话规划。DiffTOD将对话规划制定为具有条件引导的轨迹生成问题，并利用扩散语言模型来估计对话轨迹的可能性。为了优化对话行动策略，DiffTOD为不同的目标类型引入了三种量身定制的指导机制，在测试时为不同的TOD目标提供灵活的指导。在三种不同的TOD设置中进行的广泛实验表明，DiffTOD可以通过非顺序对话规划有效地进行非短视的前瞻性探索，并在长期内优化行动策略，并在复杂多样的对话场景中表现出很强的灵活性。我们的代码和数据可以通过以下方式访问https://anonymous.4open.science/r/DiffTOD. et.al.|[2504.16858](http://arxiv.org/abs/2504.16858)|null|
|**2025-04-23**|**Magnetorotational instability in a solar mean-field dynamo**|我们探讨了磁旋转不稳定性（MRI）是否可以在太阳的近表面剪切层（NSSL）中运行，以及它如何影响与发电机过程的相互作用。使用旋转剪切周期盒中 $\alpha\Omega$型发电机的水磁平均场模拟，我们表明，对于负剪切，MRI可以在一定的临界剪切参数以上运行。该参数与等分磁场强度成反比，超过等分磁场强度，$\alpha$淬火开始。与通常的$\Omega$效应一样，MRI产生环形磁场，但在笛卡尔坐标系的情况下，发现它会降低产生的磁场强度，从而抑制发电机过程。鉴于对太阳NSSL的应用，我们得出结论，湍流磁扩散率可能太大，无法激发MRI，因此预计只有标准的$\Omega$ 效应才能发挥作用。 et.al.|[2504.16849](http://arxiv.org/abs/2504.16849)|null|
|**2025-04-23**|**Physically Consistent Humanoid Loco-Manipulation using Latent Diffusion Models**|本文利用潜在扩散模型（LDMs）的能力生成逼真的RGB人体与物体交互场景，以指导仿人机器人的操作规划。为此，我们从生成的图像中提取接触位置和机器人配置，然后在全身轨迹优化（To）公式中使用，为类人机器人生成物理上一致的轨迹。我们在模拟中验证了我们的完整流水线，以适应不同的长时间运动操作场景，并对提出的接触和机器人配置提取流水线进行了广泛的分析。我们的结果表明，使用从LDM中提取的信息，我们可以生成需要长时间推理的物理一致的轨迹。 et.al.|[2504.16843](http://arxiv.org/abs/2504.16843)|null|
|**2025-04-23**|**Distributed Unknown Input Observers for Discrete-Time Linear Time-Invariant Systems**|本文介绍了一种分布式未知输入观测器（D-UIO）设计方法，该方法使用一种称为节点可检测性分解的技术，以分布式方式估计离散时间线性时不变（LTI）系统的状态，即使在有噪声测量和未知输入的情况下也是如此。在所考虑的场景中，传感器与底层通信图的节点相关联。每个节点都有一个有限的范围，因为它只能访问本地测量值并与邻居共享数据。设计观测器增益的问题分为两个子问题：（i）设计局部输出注入增益以减轻测量噪声的影响，以及（ii）设计扩散增益以通过共识协议补偿信息的缺乏。通过线性矩阵不等式（LMI）制定了一种直接且计算高效的综合策略，并通过半定规划求解。最后，给出了两个仿真场景，以说明当采用两种不同的节点分解时，分布式观测器的有效性。 et.al.|[2504.16815](http://arxiv.org/abs/2504.16815)|null|
|**2025-04-23**|**Thermal Evolution and Mass Loss on Short-Period, Low-Mass Planets During FU Orionis Outbursts**|超短周期（USP）行星代表了一类独特的系外行星，其特征是轨道紧密，质量相对较低，有些还表现出异常高的铁含量。先前的工作（Becker等人，2021）提出了一种动力学途径，其中行星可以在偶发性FU Orionis（FU Ori）爆发期间由于亚开普勒气体的阻力而向内迁移，这是一种年轻恒星物体表现出的突然吸积现象，从而有可能填充USP轨道。然而，这一迁移过程对这些行星的结构和成分演化的影响尚未得到探索。在这项工作中，我们模拟了行星表面材料对FU Ori事件的高圆盘温度特征的响应，并计算了在FU Ori活动期间，由于气态分子的汽化和随后的湍流扩散而损失的类地行星质量的分数。我们发现，在FU-Ori事件中，低质量行星可能会失去其地幔质量的很大一部分，这可能会导致低质量、富含铁的USP行星的普遍存在。 et.al.|[2504.16772](http://arxiv.org/abs/2504.16772)|null|
|**2025-04-23**|**Simple Graph Contrastive Learning via Fractional-order Neural Diffusion Networks**|图对比学习（GCL）作为一种无监督的图表示学习范式，最近取得了进展。GCL方法可分为基于增强和无增强方法。前者依赖于复杂的数据增强，而后者依赖于可以生成同一输入的不同视图的编码器。这两种方法都可能需要负样本进行训练。本文介绍了一种基于图神经扩散模型的无增广GCL框架。具体来说，我们利用由分数微分方程（FDE）控制的可学习编码器。每个FDE都由微分算子的序参数来表征。我们证明，改变这些参数可以让我们产生可学习的编码器，这些编码器可以生成不同的视图，捕获局部或全局信息，用于对比学习。我们的模型不需要负样本进行训练，适用于同源和异同源数据集。我们在各种数据集上展示了它的有效性，实现了最先进的性能。 et.al.|[2504.16748](http://arxiv.org/abs/2504.16748)|null|
|**2025-04-23**|**Gaussian Splatting is an Effective Data Generator for 3D Object Detection**|我们研究了自动驾驶中3D物体检测的数据增强。我们利用基于高斯散斑的3D重建的最新进展，在驾驶场景中放置3D对象。与现有的基于扩散的合成基于边界元法布局的图像的方法不同，我们的方法通过明确施加的几何变换将3D对象直接放置在重建的3D空间中。这确保了对象放置的物理合理性和高度精确的3D姿态和位置注释。我们的实验表明，即使通过将有限数量的外部3D对象集成到真实场景中，增强数据也能显著提高3D对象检测性能，并且在对象检测方面优于现有的基于扩散的3D增强。对nuScenes数据集的广泛测试表明，与对象的外观多样性相比，在对象放置中施加高度的几何多样性会产生更大的影响。此外，我们表明，通过最大化检测损失或在相机图像中施加高视觉遮挡来生成硬示例，并不能为自动驾驶中基于相机的3D对象检测带来更有效的3D数据增强。 et.al.|[2504.16740](http://arxiv.org/abs/2504.16740)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-23**|**Spot solutions to a neural field equation on oblate spheroids**|理解神经场中激发模式的动力学是神经科学的一个重要课题。神经场方程是描述相互作用神经元的激发动力学以进行理论分析的数学模型。尽管许多神经场方程的分析都集中在神经元相互作用对平面的影响上，但在对大脑等器官进行建模时，动力学的几何约束也是一个有吸引力的话题。本文报道了在球体作为模型曲面上定义的神经场方程中的模式动力学。我们将点解视为局部模式，并讨论曲面的几何特性如何改变它们的特性。为了分析具有小展平的球体上的斑点模式，我们首先在球面上构造精确的静止斑点解，并揭示它们的稳定性。然后，我们扩展了分析，以证明球状情况下驻点解的存在性和稳定性。我们的一个理论结果是推导了扁球体极点处定域的驻点解的稳定性判据。该标准决定了点解是保持在极点还是移动。最后，我们进行了数值模拟，根据我们的理论预测讨论了点解的动力学。我们的结果表明，点解的动力学取决于曲面和神经相互作用的协调。 et.al.|[2504.16342](http://arxiv.org/abs/2504.16342)|null|
|**2025-04-22**|**Low-Rank Adaptation of Neural Fields**|处理视觉数据通常涉及微小的调整或变化序列，例如图像滤波、表面平滑和视频存储。虽然现有的图形技术，如法线映射和视频压缩，利用冗余来有效地对这种小变化进行编码，但对神经场（NF）的小变化（视觉或物理功能的神经网络参数化）进行编码的问题却很少受到关注。我们提出了一种使用低秩自适应（LoRA）更新神经场的参数高效策略。LoRA是一种来自参数高效微调LLM社区的方法，它以最小的计算开销对预训练模型进行小更新编码。我们使LoRA适应特定于实例的神经场，避免了对大型预训练模型的需求，从而产生了适用于低计算硬件的流水线。我们通过图像滤波、视频压缩和几何编辑的实验验证了我们的方法，证明了它在表示神经场更新方面的有效性和通用性。 et.al.|[2504.15933](http://arxiv.org/abs/2504.15933)|null|
|**2025-04-21**|**Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields**|弱引力透镜是星系形状的轻微扭曲，主要是由宇宙中暗物质的引力效应引起的。在我们的工作中，我们试图从2D望远镜图像中反转弱透镜信号，以重建宇宙暗物质场的3D图。虽然反演通常会产生暗物质场的二维投影，但暗物质分布的精确三维图对于定位感兴趣的结构和测试我们宇宙的理论至关重要。然而，3D反演带来了重大挑战。首先，与依赖于多个视点的标准3D重建不同，在这种情况下，图像仅从单个视点观察。通过观察整个体积中的星系发射器是如何被透镜化的，可以部分解决这一挑战。然而，这导致了第二个挑战：无透镜星系的形状和确切位置是未知的，只能在非常大的不确定性下进行估计。这引入了大量的噪声，几乎完全淹没了透镜信号。以前的方法通过对卷中的结构施加强有力的假设来解决这个问题。相反，我们提出了一种使用引力约束神经场来灵活模拟连续物质分布的方法。我们采用综合分析方法，通过完全可微的物理正向模型优化神经网络的权重，以再现图像测量中存在的透镜信号。我们展示了我们的模拟方法，包括模拟即将到来的望远镜调查数据的暗物质分布的真实模拟测量。我们的结果表明，我们的方法不仅可以超越以前的方法，而且重要的是还能够恢复潜在的令人惊讶的暗物质结构。 et.al.|[2504.15262](http://arxiv.org/abs/2504.15262)|null|
|**2025-04-20**|**Efficient Implicit Neural Compression of Point Clouds via Learnable Activation in Latent Space**|隐式神经表示（INR），也称为神经场，已成为深度学习中的一种强大范式，使用基于坐标的神经网络对连续空间场进行参数化。在本文中，我们提出了\textbf{PICO}，这是一个基于INR的静态点云压缩框架。与主流的编码器-解码器范式不同，我们将点云压缩任务分解为两个单独的阶段：几何压缩和属性压缩，每个阶段都有不同的INR优化目标。受Kolmogorov-Arnold网络（KANs）的启发，我们引入了一种新的网络架构\textbf{LeAFNet}，它利用潜在空间中的可学习激活函数来更好地近似目标信号的隐函数。通过将点云压缩重新表述为神经参数压缩，我们通过量化和熵编码进一步提高了压缩效率。实验结果表明，\textbf{LeAFNet}在基于INR的点云压缩中优于传统的MLP。此外，与当前的MPEG点云压缩标准相比，\textbf{PICO}实现了卓越的几何压缩性能，D1 PSNR平均提高了4.92 $dB。在联合几何和属性压缩方面，我们的方法表现出了极具竞争力的结果，平均PCQM增益为2.7美元乘以10^{-3}$ 。 et.al.|[2504.14471](http://arxiv.org/abs/2504.14471)|null|
|**2025-04-17**|**Radial Basis Function Techniques for Neural Field Models on Surfaces**|我们提出了一种使用径向基函数（RBF）插值和求积求解曲面上神经场方程的数值框架。神经场模型描述了宏观大脑活动的演变，但建模研究往往忽视了弯曲皮质区域的复杂几何形状。传统的数值方法，如有限元或谱方法，在计算上可能很昂贵，并且在不规则域上实现具有挑战性。相比之下，基于RBF的方法提供了一种灵活的替代方案，通过提供插值和正交方案，以高阶精度有效地处理任意几何形状。我们首先为一般曲面上的神经场模型开发了一个基于RBF的插值投影框架。详细推导了平面和曲面域的求积法，确保了高阶精度和稳定性，因为它们取决于RBF超参数（基函数、增广多项式和模板大小）。通过数值实验，我们证明了我们的方法的收敛性，突出了它在灵活性和准确性方面优于传统方法。最后，我们阐述了复杂表面上时空活动的数值模拟，说明了该方法捕捉复杂波传播模式的能力。 et.al.|[2504.13379](http://arxiv.org/abs/2504.13379)|null|
|**2025-04-16**|**SCENT: Robust Spatiotemporal Learning for Continuous Scientific Data via Scalable Conditioned Neural Fields**|由于空间和时间依赖性之间的复杂相互作用、数据的高维度和可扩展性约束，时空学习具有挑战性。这些挑战在科学领域进一步加剧，在这些领域，数据通常是不规则分布的（例如，传感器故障的缺失值）和高容量的（例如高保真模拟），带来了额外的计算和建模困难。在本文中，我们提出了SCENT，这是一种用于可扩展和连续性知情的时空表示学习的新框架。SCENT在单一架构中统一了插值、重建和预测。SCENT建立在基于变换器的编码器-处理器-解码器骨干上，引入了可学习的查询来增强泛化能力，并引入了查询式交叉关注机制来有效捕获多尺度依赖关系。为了确保数据大小和模型复杂性的可扩展性，我们引入了稀疏注意力机制，实现了灵活的输出表示和任意分辨率的高效评估。我们通过广泛的模拟和真实世界的实验来验证SCENT，在实现卓越可扩展性的同时，在多个具有挑战性的任务中展示了最先进的性能。 et.al.|[2504.12262](http://arxiv.org/abs/2504.12262)|null|
|**2025-04-14**|**DNF-Avatar: Distilling Neural Fields for Real-time Animatable Avatar Relighting**|从单眼视频中创建可重现和可动画化的人类化身是一个新兴的研究课题，具有广泛的应用，例如虚拟现实、体育和视频游戏。之前的研究利用神经场和基于物理的渲染（PBR）来估计人类化身的几何形状并解开其外观属性。然而，这些方法的一个缺点是由于昂贵的蒙特卡洛射线追踪导致渲染速度较慢。为了解决这个问题，我们提出将隐式神经场（教师）的知识提取为显式的2D高斯飞溅（学生）表示，以利用高斯飞溅的快速光栅化特性。为了避免光线追踪，我们对PBR外观采用了分裂和近似。我们还提出了用于阴影计算的新型部分式环境遮挡探头。阴影预测是通过每像素只查询一次这些探测器来实现的，这为化身的实时重新照明铺平了道路。这些技术相结合，可以提供高质量的重新照明效果和逼真的阴影效果。我们的实验表明，所提出的学生模型与我们的教师模型实现了相当甚至更好的重新照明结果，同时在推理时快了370倍，达到了67 FPS的渲染速度。 et.al.|[2504.10486](http://arxiv.org/abs/2504.10486)|null|
|**2025-04-11**|**SN-LiDAR: Semantic Neural Fields for Novel Space-time View LiDAR Synthesis**|最近的研究已经开始探索激光雷达点云的新颖视图合成（NVS），旨在从看不见的视点生成逼真的激光雷达扫描。然而，大多数现有的方法都不能重建语义标签，而语义标签对于自动驾驶和机器人感知等许多下游应用至关重要。与受益于强大分割模型的图像不同，LiDAR点云缺乏如此大规模的预训练模型，这使得语义标注既费时又费力。为了应对这一挑战，我们提出了SN LiDAR，这是一种联合执行精确语义分割、高质量几何重建和逼真LiDAR合成的方法。具体来说，我们采用从粗到细的平面网格特征表示来从多帧点云中提取全局特征，并利用基于CNN的编码器从当前帧点云中提取局部语义特征。SemanticKITTI和KITTI-360的大量实验证明了SN LiDAR在语义和几何重建方面的优越性，有效地处理了动态对象和大规模场景。代码将在https://github.com/dtc111111/SN-Lidar. et.al.|[2504.08361](http://arxiv.org/abs/2504.08361)|**[link](https://github.com/dtc111111/sn-lidar)**|
|**2025-04-08**|**econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic Gaussians**|最近关于开放词汇神经场的工作的主要重点是从VLM中提取精确的语义特征，然后将它们有效地整合到多视图一致的3D神经场表示中。然而，大多数现有的工作都是在受信任的SAM上进行的，以规范图像级CLIP，而无需进一步细化。此外，一些现有的研究通过在与3DGS语义场融合之前对2D VLM的语义特征进行降维来提高效率，这不可避免地导致了多视图不一致。在这项工作中，我们提出了使用3DGS进行开放式词汇语义分割的econSG。我们的econSG由以下部分组成：1）置信区间引导正则化（CRR），它相互细化SAM和CLIP，以获得具有完整和精确边界的精确语义特征的两全其美。2） 一个低维上下文空间，通过融合反投影的多视图2D特征来增强3D多视图一致性，同时提高计算效率，然后直接对融合的3D特征进行降维，而不是分别对每个2D视图进行操作。与现有方法相比，我们的econSG在四个基准数据集上显示了最先进的性能。此外，我们也是所有方法中最有效的培训。 et.al.|[2504.06003](http://arxiv.org/abs/2504.06003)|null|
|**2025-04-08**|**Meta-Continual Learning of Neural Fields**|神经场（NF）作为一种用于复杂数据表示的通用框架，已经获得了突出地位。这项工作揭示了一个新的问题设置，称为“神经场元连续学习”（MCL-NF），并引入了一种新的策略，该策略采用模块化架构与基于优化的元学习相结合。我们的策略侧重于克服现有神经场连续学习方法的局限性，如灾难性遗忘和缓慢收敛，实现了高质量的重建，显著提高了学习速度。我们进一步引入了神经辐射场的Fisher信息最大化损失（FIM-NeRF），它在样本级别最大化信息增益以增强学习泛化，并证明了收敛保证和泛化界限。我们在六个不同的数据集上对图像、音频、视频重建和视图合成任务进行了广泛的评估，证明了我们的方法在重建质量和速度方面优于现有的MCL和CL-NF方法。值得注意的是，我们的方法在降低参数要求的情况下，实现了神经场对城市级NeRF渲染的快速适应。 et.al.|[2504.05806](http://arxiv.org/abs/2504.05806)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

