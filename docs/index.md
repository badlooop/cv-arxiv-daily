---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.01.13
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-01-09**|**Scaffold-SLAM: Structured 3D Gaussians for Simultaneous Localization and Photorealistic Mapping**|3D高斯散斑（3DGS）最近彻底改变了同步定位和映射（SLAM）中的新颖视图合成。然而，利用3DGS的现有SLAM方法未能同时为单眼、立体和RGB-D相机提供高质量的新颖视图渲染。值得注意的是，一些方法在RGB-D相机上表现良好，但在单眼相机的渲染质量方面却严重下降。在本文中，我们提出了脚手架SLAM，它可以在单目、立体和RGB-D相机上同时进行定位和高质量的真实感映射。我们引入了两项关键创新，以实现这种最先进的视觉质量。首先，我们提出了运动中的外观嵌入，使3D高斯模型能够更好地模拟不同相机姿态下的图像外观变化。其次，我们引入了一个频率正则化金字塔来引导高斯分布，使模型能够有效地捕捉场景中更精细的细节。对单眼、立体和RGB-D数据集的广泛实验表明，脚手架SLAM在真实感映射质量方面明显优于最先进的方法，例如，单眼相机的TUM RGB-D数据集中的PSNR高出16.76%。 et.al.|[2501.05242](http://arxiv.org/abs/2501.05242)|null|
|**2025-01-08**|**FatesGS: Fast and Accurate Sparse-View Surface Reconstruction using Gaussian Splatting with Depth-Feature Consistency**|最近，高斯散斑在计算机视觉领域引发了一种新的趋势。除了新颖的视图合成外，它还被扩展到多视图重建领域。最新的方法有助于完成详细的表面重建，同时确保快速的训练速度。然而，这些方法仍然需要密集的输入视图，并且它们的输出质量会随着稀疏视图的出现而显著降低。我们观察到高斯基元倾向于过拟合少数训练视图，导致有噪声的浮点运算和不完整的重建曲面。在本文中，我们提出了一种创新的稀疏视图重建框架，该框架利用视图内深度和多视图特征一致性来实现非常精确的表面重建。具体来说，我们利用单眼深度排名信息来监督斑块内深度分布的一致性，并采用平滑度损失来增强分布的连续性。为了实现更精细的表面重建，我们通过多视图投影特征优化了深度的绝对位置。在DTU和BlenedMVS上进行的大量实验表明，我们的方法优于最先进的方法，速度提高了60倍至200倍，实现了快速和细粒度的网格重建，而不需要昂贵的预训练。 et.al.|[2501.04628](http://arxiv.org/abs/2501.04628)|null|
|**2025-01-07**|**NeRFs are Mirror Detectors: Using Structural Similarity for Multi-View Mirror Scene Reconstruction with 3D Surface Primitives**|虽然神经辐射场（NeRF）在真实感新颖的视图合成方面取得了突破，但处理镜像表面仍然是一个特别的挑战，因为它们在场景表示中引入了严重的不一致性。之前的尝试要么侧重于重建单个反射物体，要么依赖于强有力的监督指导，即用户提供的镜子可见图像区域的额外注释，从而限制了实际可用性。相比之下，在本文中，我们提出了NeRF-MD，该方法表明NeRFs可以被视为镜像检测器，并且能够重建包含镜像表面的场景的神经辐射场，而不需要事先注释。为此，我们首先通过使用深度重投影损失训练标准NeRF来计算场景几何形状的初始估计。我们的关键见解在于，与镜像表面对应的场景部分仍将表现出明显的光度不一致，而其余部分已经以合理的方式重建。这使我们能够在训练的初始阶段通过将几何图元拟合到这种不一致的区域来检测镜面。利用这些信息，我们在第二个训练阶段联合优化辐射场和镜子几何形状，以提高其质量。我们展示了我们的方法能够忠实地检测场景中的镜子，并重建单个一致的场景表示，并展示了与基线和镜子感知方法相比的潜力。 et.al.|[2501.04074](http://arxiv.org/abs/2501.04074)|null|
|**2025-01-07**|**DehazeGS: Seeing Through Fog with 3D Gaussian Splatting**|当前的新颖视图合成任务主要依赖于高质量和清晰的图像。然而，在雾蒙蒙的场景中，散射和衰减会显著降低重建和渲染质量。尽管已经开发了基于NeRF的去方位重建算法，但它们使用深度全连接神经网络和每条射线采样策略会导致高昂的计算成本。此外，NeRF的隐含表现很难从朦胧的场景中恢复出精细的细节。相比之下，3D高斯散斑技术的最新进展通过将点云明确建模为3D高斯模型来实现高质量的3D场景重建。在本文中，我们提出利用显式高斯表示通过物理精确的正向渲染过程来解释雾状图像的形成过程。我们介绍了DehazeGS，这是一种能够从参与媒体中分解和渲染无雾背景的方法，仅使用多视图雾图像作为输入。我们对每个高斯分布内的传输进行建模，以模拟雾的形成。在此过程中，我们共同学习大气光和散射系数，同时优化模糊场景的高斯表示。在推理阶段，我们消除了散射和衰减对高斯分布的影响，并将其直接投影到二维平面上以获得清晰的视图。在合成和真实世界雾天数据集上的实验表明，DehazeGS在渲染质量和计算效率方面都达到了最先进的性能。 et.al.|[2501.03659](http://arxiv.org/abs/2501.03659)|null|
|**2025-01-06**|**Pointmap-Conditioned Diffusion for Consistent Novel View Synthesis**|在本文中，我们提出了PointmapDiffusion，这是一种利用预训练的2D扩散模型进行单图像新视图合成（NVS）的新框架。我们的方法是第一个利用点图（即光栅化的3D场景坐标）作为调节信号，从参考图像中捕获几何先验来指导扩散过程的方法。通过嵌入参考注意力块和点图特征的ControlNet，我们的模型在生成能力和几何一致性之间取得了平衡，实现了跨不同视点的精确视图合成。对不同真实世界数据集的广泛实验表明，与单图像NVS任务的其他基线相比，PointmapDiffusion以更少的可训练参数实现了高质量、多视图一致的结果。 et.al.|[2501.02913](http://arxiv.org/abs/2501.02913)|null|
|**2025-01-05**|**GS-DiT: Advancing Video Generation with Pseudo 4D Gaussian Fields through Efficient Dense 3D Point Tracking**|4D视频控制在视频生成中至关重要，因为它可以使用复杂的镜头技术，如多摄像头拍摄和推车变焦，而现有方法目前不支持这些技术。直接训练视频扩散变换器（DiT）来控制4D内容需要昂贵的多视图视频。受单目动态新颖视图合成（MDVS）的启发，该方法优化了4D表示并根据不同的4D元素（如相机姿态和对象运动编辑）渲染视频，我们将伪4D高斯场引入视频生成。具体来说，我们提出了一种新的框架，该框架构建了一个具有密集3D点跟踪的伪4D高斯场，并为所有视频帧渲染高斯场。然后，我们微调预训练的DiT，以在渲染视频的指导下生成视频，称为GS DiT。为了增强GS-DiT的训练，我们还提出了一种高效的密集3D点跟踪（D3D-PT）方法，用于伪4D高斯场构建。我们的D3D-PT在精度上优于最先进的稀疏3D点跟踪方法SpatialTracker，并将推理速度提高了两个数量级。在推理阶段，GS DiT可以生成具有相同动态内容的视频，同时遵循不同的相机参数，解决了当前视频生成模型的一个重大局限性。GS DiT展示了强大的泛化能力，并将高斯飞溅的4D可控性扩展到视频生成，而不仅仅是相机姿态。它通过操纵高斯场和相机内部函数来支持高级电影效果，使其成为创意视频制作的强大工具。演示可在https://wkbian.github.io/Projects/GS-DiT/. et.al.|[2501.02690](http://arxiv.org/abs/2501.02690)|null|
|**2025-01-03**|**CrossView-GS: Cross-view Gaussian Splatting For Large-scale Scene Reconstruction**|3D高斯散点（3DGS）已成为场景表示和重建的一种突出方法，利用密集分布的高斯基元实现高分辨率图像的实时渲染。虽然现有的3DGS方法在视图变化较小的场景中表现良好，但跨视图场景中的大视图变化给这些方法带来了优化挑战。为了解决这些问题，我们提出了一种基于双分支融合的跨视图高斯散斑方法，用于大规模场景重建。我们的方法将空中和地面视图独立重建为两个独立的分支，以建立高斯分布的基线，为初始化和加密过程中的交叉视图重建提供可靠的先验。具体来说，引入了一种梯度感知正则化策略，以缓解由显著视图差异引起的平滑问题。此外，利用独特的高斯补充策略将双分支的补充信息合并到交叉视图模型中。在基准数据集上的大量实验表明，与最先进的方法相比，我们的方法在新颖的视图合成方面取得了卓越的性能。 et.al.|[2501.01695](http://arxiv.org/abs/2501.01695)|null|
|**2025-01-02**|**EasySplat: View-Adaptive Learning makes 3D Gaussian Splatting Easy**|3D高斯散斑（3DGS）技术已经实现了令人满意的3D场景表示。尽管它们的性能令人印象深刻，但由于运动结构（SfM）方法在获取精确场景初始化方面的局限性，或者致密化策略的低效性，它们面临着挑战。本文介绍了一种新的框架EasySplat来实现高质量的3DGS建模。我们采用了一种新的方法来释放大规模点图方法的力量，而不是使用SfM进行场景初始化。具体来说，我们提出了一种基于视图相似性的高效分组策略，并使用鲁棒的点图先验来获得高质量的点云和相机姿态，用于3D场景初始化。在获得可靠的场景结构后，我们提出了一种新的致密化方法，该方法利用KNN方案，根据相邻高斯椭球体的平均形状自适应地分割高斯基元。通过这种方式，所提出的方法解决了初始化和优化的局限性，从而实现了高效准确的3DGS建模。大量实验表明，EasySplat在处理新颖的视图合成方面优于当前最先进的（SOTA）。 et.al.|[2501.01003](http://arxiv.org/abs/2501.01003)|null|
|**2024-12-31**|**SoundBrush: Sound as a Brush for Visual Scene Editing**|我们提出了SoundBrush，这是一种使用声音作为画笔来编辑和操纵视觉场景的模型。我们扩展了潜在扩散模型（LDM）的生成能力，以包含用于编辑视觉场景的音频信息。受现有图像编辑工作的启发，我们将这项任务视为一个监督学习问题，并利用各种现成的模型来构建一个声音配对的视觉场景数据集进行训练。这个生成丰富的数据集使SoundBrush能够学习将音频特征映射到LDM的文本空间中，从而允许在各种狂野声音的指导下进行视觉场景编辑。与现有方法不同，SoundBrush可以准确地操纵整体风景，甚至插入声音对象，以最好地匹配音频输入，同时保留原始内容。此外，通过与新颖的视图合成技术集成，我们的框架可以扩展到编辑3D场景，从而促进声音驱动的3D场景操作。演示可在https://soundbrush.github.io/. et.al.|[2501.00645](http://arxiv.org/abs/2501.00645)|null|
|**2024-12-31**|**SG-Splatting: Accelerating 3D Gaussian Splatting with Spherical Gaussians**|3D高斯散斑正在成为新颖视图合成中的一种最先进的技术，因其在视觉质量、速度和渲染效率之间令人印象深刻的平衡而受到认可。然而，依赖三次球面谐波进行颜色表示会带来巨大的存储需求和计算开销，从而导致内存占用大和渲染速度慢。我们引入了基于球面高斯颜色表示的SG Splatting，这是一种在新视图合成中提高渲染速度和质量的新方法。我们的方法首先使用球面高斯表示视图相关的颜色，而不是三次球面谐波，这大大减少了用于颜色表示的参数数量，并显著加速了渲染过程。然后，我们开发了一种有效的策略来组织多个球面高斯分布，优化它们的排列，以实现平衡和精确的场景表示。为了进一步提高渲染质量，我们提出了一种混合表示方法，将球面高斯与低次球面谐波相结合，有效地捕获了高频和低频颜色信息。SG Splatting还具有即插即用功能，可以轻松集成到现有系统中。这种方法提高了计算效率和整体视觉保真度，使其成为实时应用的实用解决方案。 et.al.|[2501.00342](http://arxiv.org/abs/2501.00342)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-01-09**|**Identifiability of Controlled Open Quantum Systems**|开放量子系统是量子力学和随机分析交叉领域的一个丰富研究领域。我们在双线性动力系统的框架内统一了受控开放量子系统的多种观点。我们从量子态层析成像的结果中定义了相应的可识别性概念，该结果是在不同长度控制信号的子序列下，在初始量子态的许多副本中获得的。我们解释并扩展了使用谱准则、基于Hankel矩阵的准则和频域准则对双线性系统可识别性的研究，并将其扩展到开放量子系统主方程的参数估计。这为识别开放量子系统的一些建设性方法奠定了基础。 et.al.|[2501.05270](http://arxiv.org/abs/2501.05270)|null|
|**2025-01-09**|**A Systematic Literature Review on Deep Learning-based Depth Estimation in Computer Vision**|深度估计（DE）提供关于场景的空间信息，并实现诸如3D重建、对象检测和场景理解等任务。最近，人们对使用基于深度学习（DL）的方法进行DE的兴趣越来越大。传统技术依赖于手工制作的特征，这些特征往往难以推广到不同的场景，需要大量的手动调整。然而，DE的DL模型可以从输入数据中自动提取相关特征，适应各种场景条件，并很好地泛化到看不见的环境。已经开发了许多基于DL的方法，因此有必要调查和综合最新技术（SOTA）。之前关于DE的综述主要集中在单眼或基于立体的技术上，而不是全面综述DE。此外，据我们所知，还没有全面关注DE的系统文献综述（SLR）。因此，正在进行这项SLR研究。最初，在电子数据库中搜索相关出版物，得到1284份出版物。使用定义的排除和质量标准，筛选出128篇出版物，并进一步筛选出59篇高质量的初步研究。对这些研究进行分析，以提取数据并回答定义的研究问题。基于这些结果，DL方法主要针对三种不同类型的DE：单眼、立体和多视图。20个公开可用的数据集用于训练、测试和评估DE的DL模型，其中KITTI、NYU Depth V2和Make 3D是使用最多的数据集。使用29个评估指标来评估DE的性能。初步研究中报告了35个基础模型，使用最多的前五个基础模型是ResNet-50、ResNet-18、ResNet-101、U-Net和VGG-16。最后，缺乏地面实况数据是主要研究报告的最重大挑战之一。 et.al.|[2501.05147](http://arxiv.org/abs/2501.05147)|null|
|**2025-01-07**|**Materialist: Physically Based Editing Using Single-Image Inverse Rendering**|为了基于单视图、基于逆物理的渲染进行图像编辑，我们提出了一种将基于学习的方法与渐进可微渲染相结合的方法。对于给定的图像，我们的方法利用神经网络来预测初始材料属性。然后，使用渐进可微渲染来优化环境贴图并细化材质属性，目标是使渲染结果与输入图像紧密匹配。我们只需要一张图像，而基于渲染方程的其他逆渲染方法需要多个视图。与依赖神经渲染器的单视图方法相比，我们的方法实现了更逼真的光与材质交互、精确的阴影和全局照明。此外，通过优化材质属性和照明，我们的方法可以执行各种任务，包括基于物理的材质编辑、对象插入和重新照明。我们还提出了一种材质透明度编辑方法，该方法无需全场景几何即可有效操作。与基于稳定扩散的方法相比，我们的方法基于经验结果提供了更强的可解释性和更真实的光折射。 et.al.|[2501.03717](http://arxiv.org/abs/2501.03717)|**[link](https://github.com/lez-s/materialist)**|
|**2025-01-07**|**ConcealGS: Concealing Invisible Copyright Information in 3D Gaussian Splatting**|随着三维重建技术的快速发展，三维数据的广泛分布已成为未来的趋势。虽然传统的视觉数据（如图像和视频）和基于NeRF的格式已经有了成熟的版权保护技术，但新兴的3D高斯散斑（3D-GS）格式的隐写技术尚未得到充分探索。为了解决这个问题，我们提出了ConcealGS，这是一种将隐式信息嵌入3D-GS的创新方法。通过引入基于3D-GS的知识蒸馏和梯度优化策略，ConcealGS克服了基于NeRF的模型的局限性，提高了隐式信息的鲁棒性和3D重建的质量。我们在各种潜在的应用场景中评估了ConcealGS，实验结果表明，ConcealGS不仅成功地恢复了隐式信息，而且对渲染质量几乎没有影响，为未来将不可见和可恢复的信息嵌入3D模型提供了一种新方法。 et.al.|[2501.03605](http://arxiv.org/abs/2501.03605)|**[link](https://github.com/zxk1212/concealgs)**|
|**2025-01-06**|**4D-CS: Exploiting Cluster Prior for 4D Spatio-Temporal LiDAR Semantic Segmentation**|激光雷达点的语义分割对自动驾驶和移动机器人系统具有重要价值。大多数方法探索多扫描的时空信息，以识别每个点的语义类和运动状态。然而，这些方法往往忽视了空间和时间上的分割一致性，这可能会导致同一对象内的点云被预测为不同的类别。为了解决这个问题，我们的核心思想是在多个帧上生成集群标签，这些标签可以反映对象的完整空间结构和时间信息。这些标签为我们的双分支网络4D-CS提供了明确的指导，该网络集成了基于点和基于簇的分支，以实现更一致的分割。具体来说，在基于点的分支中，我们利用历史知识通过多个视图的时间融合来丰富当前特征。在基于聚类的分支中，我们提出了一种新的策略来生成前景对象的聚类标签，并将其应用于收集逐点信息以导出聚类特征。然后，我们在多次扫描中合并相邻的聚类，以恢复由于遮挡而丢失的特征。最后，在点聚类融合阶段，我们自适应地融合来自两个分支的信息，以优化分割结果。大量实验证实了所提出方法的有效性，我们在SemanticKITTI和nuScenes数据集上的多扫描语义和运动对象分割方面取得了最先进的结果。该代码将在以下网址提供https://github.com/NEU-REAL/4D-CS.git. et.al.|[2501.02937](http://arxiv.org/abs/2501.02937)|null|
|**2025-01-07**|**AE-NeRF: Augmenting Event-Based Neural Radiance Fields for Non-ideal Conditions and Larger Scene**|与基于帧的方法相比，使用事件相机的计算神经形态成像具有显著的优势，例如最小的运动模糊、增强的时间分辨率和高动态范围。神经辐射场的多视图一致性与事件相机的独特优势相结合，促使最近的研究从移动事件相机捕获的数据中重建NeRF。虽然表现出令人印象深刻的性能，但现有的方法依赖于具有均匀和高质量事件序列以及精确相机姿态的理想条件，主要侧重于对象级重建，从而限制了它们的实际应用。在这项工作中，我们提出了AE NeRF来解决从非理想条件下学习基于事件的NeRF的挑战，包括非均匀事件序列、嘈杂的姿势和各种规模的场景。我们的方法利用事件流的密度，并结合基于事件的NeRF（e-NeRF）框架学习姿态校正模块，以便从不准确的相机姿态中进行稳健的3D重建。为了推广到更大的场景，我们提出了一种分层事件蒸馏方法，该方法使用了一个e-NeRF网络和一个香草e-NeRF网路来重新采样和优化重建过程。我们进一步提出了事件重建损失和时间损失，以提高重建场景的视图一致性。我们建立了一个全面的基准，包括模拟实际非理想条件的大规模场景，结合了合成和具有挑战性的现实世界事件数据集。实验结果表明，我们的方法在基于事件的3D重建方面取得了新的进展。 et.al.|[2501.02807](http://arxiv.org/abs/2501.02807)|null|
|**2025-01-06**|**Unsupervised Domain Adaptation for Occlusion Resilient Human Pose Estimation**|遮挡是对人体姿态估计算法的一个重大挑战，通常会导致不准确和解剖学上不可信的姿态。尽管当前的遮挡鲁棒人体姿态估计算法在现有数据集上表现出了令人印象深刻的性能，但它们的成功在很大程度上归功于监督训练和额外信息的可用性，如多视图或时间连续性。此外，这些算法在分布偏移下通常会出现性能下降。虽然现有的域自适应人体姿态估计算法解决了这一瓶颈，但当目标域图像被遮挡时，它们往往表现不佳，这在现实生活中很常见。为了应对这些挑战，我们提出了OR-POSE：用于遮挡弹性人类POSE估计的无监督域自适应。OR-POSE是一种创新的无监督域自适应算法，通过采用均值教师框架进行迭代伪标签细化，有效地减轻了域偏移并克服了遮挡挑战。此外，OR-POSE通过利用学习到的人体姿势先验来增强逼真的姿势预测，该先验在适应过程中结合了人体的解剖约束。最后，OR-POSE通过采用一种新的基于可见性的课程学习方法，避免了对严重遮挡图像生成的不准确伪标签的过拟合。这使得模型能够从具有相对较少遮挡的训练样本逐渐过渡到更具挑战性、严重遮挡的样本。广泛的实验表明，OR-POSE在挑战遮挡的人体姿态估计数据集上比现有的类似最先进的算法高出7%。 et.al.|[2501.02773](http://arxiv.org/abs/2501.02773)|null|
|**2025-01-03**|**JoyGen: Audio-Driven 3D Depth-Aware Talking-Face Video Editing**|人脸视频生成研究取得重大进展；然而，在基于输入音频编辑嘴唇形状时，精确的嘴唇音频同步和高视觉质量仍然具有挑战性。本文介绍了JoyGen，这是一种新颖的两阶段人脸生成框架，包括音频驱动的嘴唇运动生成和视觉外观合成。在第一阶段，3D重建模型和audio2motion模型分别预测身份和表达系数。接下来，通过将音频特征与面部深度图相结合，我们为面部生成中的精确嘴唇音频同步提供了全面的监督。此外，我们还构建了一个包含130小时高质量视频的中文人脸数据集。JoyGen在开源HDTF数据集和我们精心策划的数据集上进行了训练。实验结果表明，我们的方法实现了出色的嘴唇音频同步和视觉质量。 et.al.|[2501.01798](http://arxiv.org/abs/2501.01798)|**[link](https://github.com/JOY-MM/JoyGen)**|
|**2025-01-03**|**Laparoscopic Scene Analysis for Intraoperative Visualisation of Gamma Probe Signals in Minimally Invasive Cancer Surgery**|癌症在全球范围内仍然是一个重大的健康挑战，英国每两分钟就有一次新的诊断。手术是癌症的主要治疗选择之一。然而，由于缺乏可靠的术中可视化工具，外科医生依靠触觉和肉眼，有限地使用术前图像数据来直接指导癌组织和转移瘤的切除。如果癌症以正边缘切除，或其他关键结构受到无意影响，这会导致成本增加，并对患者造成伤害。因此，迫切需要更可靠和准确的微创手术术中可视化工具，以改善手术结果并加强患者护理。最近的小型癌症检测探针（即Lightpoint Medical有限公司开发的SENSEI）利用核制剂的癌症靶向能力，使用发射的伽马信号在手术中更准确地识别癌症。然而，使用这种探头带来了可视化挑战，因为探头是非成像的，与组织有气隙，这使得外科医生难以在组织表面上定位探头感应区域。从几何上讲，感测区域被定义为伽马探头轴和3D空间中组织表面之间的交点，但投影到2D腹腔镜图像上。因此，本文首先开发了工具跟踪、姿态估计和分割工具，然后是腹腔镜图像深度估计算法和3D重建方法。 et.al.|[2501.01752](http://arxiv.org/abs/2501.01752)|null|
|**2025-01-03**|**AR4D: Autoregressive 4D Generation from Monocular Videos**|生成模型的最新进展引发了人们对动态3D内容创建（即4D生成）的极大兴趣。现有的方法主要依赖于分数蒸馏采样（SDS）来推断新的视图视频，由于SDS的固有随机性，通常会导致多样性有限、时空不一致和提示对齐不佳等问题。为了解决这些问题，我们提出了AR4D，这是一种无SDS 4D生成的新范式。具体来说，我们的范式由三个阶段组成。首先，对于生成或捕获的单眼视频，我们首先利用预训练的专家模型来创建第一帧的3D表示，然后对其进行进一步微调以用作规范空间。随后，由于视频以自回归方式自然发生，我们建议根据前一帧的表示生成每一帧的3D表示，因为这种自回归生成方式可以促进更准确的几何和运动估计。同时，为了防止在此过程中过度拟合，我们引入了一种渐进式视图采样策略，利用预训练的大规模3D重建模型的先验。为了避免自回归生成引入的外观漂移，我们进一步引入了一个基于全局变形场和每个帧3D表示的几何形状的细化阶段。大量实验表明，AR4D可以在没有SDS的情况下实现最先进的4D生成，提供更大的多样性，提高时空一致性，并更好地与输入提示对齐。 et.al.|[2501.01722](http://arxiv.org/abs/2501.01722)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-01-10**|**Multi-subject Open-set Personalization in Video Generation**|视频个性化方法使我们能够合成具有特定概念的视频，如人、宠物和地点。然而，现有的方法通常只关注有限的领域，需要对每个主题进行耗时的优化，或者只支持一个主题。我们提出了Video Alchemist $-$ a视频模型，该模型具有内置的多主题、开放式个性化功能，适用于前景对象和背景，消除了耗时的测试时间优化的需要。我们的模型建立在一个新的扩散变换器模块上，该模块将每个条件参考图像及其相应的主题级文本提示与交叉注意力层融合在一起。开发如此庞大的模型面临两大挑战：数据集和评估。首先，由于参考图像和视频的配对数据集极难收集，我们将选定的视频帧作为参考图像进行采样，并合成目标视频的片段。然而，尽管模型可以很容易地对给定参考帧的训练视频进行去噪，但它们无法推广到新的上下文。为了缓解这个问题，我们设计了一种新的具有广泛图像增强的自动数据构建管道。其次，评估开放式视频个性化本身就是一个挑战。为了解决这个问题，我们引入了一个个性化基准，该基准侧重于准确的主题保真度，并支持多种个性化场景。最后，我们广泛的实验表明，我们的方法在定量和定性评估方面都明显优于现有的个性化方法。 et.al.|[2501.06187](http://arxiv.org/abs/2501.06187)|null|
|**2025-01-10**|**GenMol: A Drug Discovery Generalist with Discrete Diffusion**|药物发现是一个复杂的过程，涉及多个场景和阶段，如片段约束分子生成、命中生成和线索优化。然而，现有的分子生成模型只能解决其中一两种情况，缺乏解决药物发现管道各个方面的灵活性。在这篇论文中，我们提出了广义分子生成模型（GenMol），这是一个通用的框架，通过将离散扩散应用于基于序列附着的片段嵌入（SAFE）分子表示来解决这些局限性。GenMol通过非自回归双向并行解码生成SAFE序列，从而允许利用不依赖于特定令牌排序的分子上下文并提高计算效率。此外，在离散扩散框架下，我们引入了片段重造，这是一种通过用掩蔽标记替换片段并再生它们来优化分子的策略，从而能够有效地探索化学空间。GenMol在从头生成和片段约束生成方面明显优于之前基于SAFE表示训练的GPT模型，并在目标导向的命中生成和线索优化方面达到了最先进的性能。这些实验结果表明，GenMol可以解决广泛的药物发现任务，为分子设计提供了一种统一和通用的方法。 et.al.|[2501.06158](http://arxiv.org/abs/2501.06158)|null|
|**2025-01-10**|**From discrete-time policies to continuous-time diffusion samplers: Asymptotic equivalences and faster training**|我们研究了训练神经随机微分方程或扩散模型，以便在不获取目标样本的情况下从玻尔兹曼分布中采样的问题。现有的训练此类模型的方法使用可微模拟或非策略强化学习（RL）来强制生成和噪声过程的时间反转。我们证明了在无穷小离散化步长的限制下，目标族之间的等价性，将熵RL方法（GFlowNets）与连续时间对象（偏微分方程和路径空间度量）联系起来。我们进一步表明，在训练过程中适当选择粗时间离散化可以大大提高样本效率和时间局部目标的使用，在标准采样基准上实现具有竞争力的性能，同时降低计算成本。 et.al.|[2501.06148](http://arxiv.org/abs/2501.06148)|**[link](https://github.com/gfnorg/gfn-diffusion)**|
|**2025-01-10**|**Uniform local well-posedness and liviscid limit for the KdV-Burgers equation on $\mathbb{T}$**|本文研究了环面上Korteweg-de-Vries-Burgers方程的一致适定性和无粘极限问题，我们考虑KdV-Burgers方程$\partial_tu（t，x）+\partial_x^3u（t，x）-\varepsilon\partial_x^2u mathbb{R}^{+}\times\mathbb{1T}\rightarrow\mathbb{R}$是一个实值函数，我们证明了它在$H^s$中是均匀局部适定的，对于[0,1]$中的所有$\varepsilon\$，$s\geq为0$。此外，我们证明了存在一些$T>0$，这样对于任何$s\geq 0$，如果$\varepsilon$趋向于$0$，它的解在$C（[0，T]；H^s）$ 中收敛到KdV方程的解。 et.al.|[2501.06147](http://arxiv.org/abs/2501.06147)|null|
|**2025-01-10**|**Molecular Communication-Inspired Particle Collector-Transmitter (PaCoT) for Heavy Metal Removal from Human Circulatory System**|本研究提出了一种新型的分子通信（MC）启发的纳米机器——粒子收集器-发射器（PaCoT），用于从人体循环系统中去除有毒重金属。PaCoT收集这些有毒金属，并在它们到达关键器官之前将其传递到释放节点，如淋巴毛细血管。该设计结合了关键的物理参数，并通过粒子接收和释放机制进行操作。在被描述为配体-受体结合反应的接收过程中，PaCoT使用金属硫蛋白作为受体，重金属（如Zn、Pb、Cd）作为配体，并将其建模为连续时间马尔可夫过程（CTMP）。我们假设毒性条件（有毒（位-1），无毒（位-0））被编码为重金属分子的浓度。因此，我们认为MC通道（如人体循环系统）内的重金属浓度采用二元浓度移位键控（二元CSK）。特定重金属的浓度比被估计为推断毒性，即高比率表示毒性，低比率表示无毒性。毒性检测是通过在存在干扰物和各种重金属的情况下监测受体结合持续时间来实现的。在检测和收集有毒重金属后，PaCoT将其安全地保留在液体介质（如水）中，直至释放，采用两种机制：（1）单盘粘性微泵调节流速，（2）布朗运动促进扩散。通过MATLAB仿真评估PaCoT的性能，重点关注毒性检测方法的误码率（BEP）、PaCoT分子的释放时间和能耗。 et.al.|[2501.06092](http://arxiv.org/abs/2501.06092)|null|
|**2025-01-10**|**Simulation and modelling of convective mixing of carbon dioxide in geological formations**|我们在瑞利-达西数高达 $Ra=8\times10^4$的情况下对3D多孔介质中的对流进行了大规模数值模拟。为了研究地质构造中二氧化碳（CO$_2$）的对流混合，我们考虑了一个半无限域，其中CO$_2$浓度在顶部是恒定的，底部没有规定通量。对流从扩散主导阶段开始，过渡到对流驱动的溶质指形成，并在指到达底部边界和系统中浓度增加时以停堆阶段结束。对于Ra\ge 5\times10^3$，我们观察到一个恒定的通量状态，溶解通量稳定在0.019，比2D估计值高出约13%。在Ra$高的情况下，顶部边界呈现出分层流动结构，这与瑞利-达西对流相一致，推动了内部大型百万流明的形成。这些发现将溶质对流的见解扩展到3D和高Ra$，提高了预测地下长期CO$_2$ 动态的模型的可靠性。 et.al.|[2501.06090](http://arxiv.org/abs/2501.06090)|null|
|**2025-01-10**|**Variation of the low-mass end of the stellar initial mass function with redshift and metallicity**|我们报告了从20个辐射流体动力学模拟中获得的恒星质量函数，这些模拟涉及金属量为太阳值的3、1、1/10和1/100的5亿美元分子云中的星团形成，这些云受到宇宙微波背景辐射的水平，适合红移z=0、3、5、7和10时的恒星形成。计算包括扩散星际介质的热化学模型，并分别处理尘埃和气体温度。我们发现，随着红移和/或金属丰度的增加，获得的恒星质量分布变得越来越低。与典型的银河系初始质量函数相似的质量函数适用于当今的恒星形成（z=0），与金属丰度无关，也适用于所有红移高达z=10的最低金属丰度（1/100太阳），但对于金属丰度更高的恒星，随着金属丰度和红移的增加，褐矮星和低质量恒星的赤字更大。这些效应是由于宇宙微波背景辐射变暖，富金属气体在红移较高的情况下无法冷却到较低的温度。基于数值结果，我们提供了一个参数化，可用于改变恒星初始质量函数与红移和金属丰度的关系；这可用于星系形成的模拟。例如，与典型的银河系恒星初始质量函数相比，底部光质量函数降低了质光比，这可能会降低高红移星系的估计质量。 et.al.|[2501.06082](http://arxiv.org/abs/2501.06082)|null|
|**2025-01-10**|**Quantum Avalanches in $\mathbb{Z}_2$-preserving Interacting Ising Majorana Chain**|最近的数值工作揭示了有限系统尺寸和有限时间尺度上无序量子多体系统中多体局域（MBL）相的不稳定性。这种不稳定性源于发生在热力学极限的格里菲斯区域，该区域迅速热化并影响周围的典型MBL区域，将雪崩机制引入系统。在这里，我们考虑$\mathbb{Z}_2保持$ 的相互作用伊辛-马约拉纳链模型，该模型展示了一个更复杂的相图，其中遍历相出现在具有不同长程序特性的两个MBL相之间。我们计算了模型在扰动下与无限浴耦合时的动态特性，并通过最慢热化速率的缩放行为，我们发现了有限尺寸系统中的临界无序强度是如何受到雪崩机制的影响的。我们还采用了嵌入式包裹体模型，并利用每个自旋与人工格里菲斯区域之间互信息的时间演化来探测热气泡的扩散。我们观察到，在有限尺寸系统中，临界无序强度逐渐偏离中心。我们的工作表明，MBL顺磁相和MBL自旋玻璃相在有限尺寸下都是不稳定的。 et.al.|[2501.06064](http://arxiv.org/abs/2501.06064)|null|
|**2025-01-10**|**Overcoming the surface paradox: Buried perovskite quantum dots in wide-bandgap perovskite thin films**|胶体钙钛矿量子点（PQD）是按需量子、经典光电和光子器件的一个令人兴奋的平台。然而，它们的潜在成功受到其弱内在晶格键能和复杂表面化学引起的极端敏感性和低稳定性的限制。在这里，我们报告了一种在三维钙钛矿薄膜中埋入钙钛矿量子点（b-PQD）的新平台，该平台使用一步闪光退火制造，克服了胶体钙钛矿点中与表面相关的不稳定性。b-PQD表现出超亮和稳定的单点发射，分辨率限制线宽低于130μeV，光子反聚束（g^2（0）=0.1），无闪烁，光谱扩散受到抑制，光子计数率高达10^4/s，与单位量子产率一致。超尖锐线宽解析了激子精细结构（暗激子和三重态激子）及其在磁场下的动力学。此外，b-PQD可以电驱动发射线宽为1meV、光子反聚束（g^2（0）=0.4）的单光子。这些结果为下一代量子光通信和传感的片上低成本单光子源铺平了道路。 et.al.|[2501.06061](http://arxiv.org/abs/2501.06061)|null|
|**2025-01-10**|**Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction**|概率人体运动预测旨在根据过去的观测结果预测未来多种可能的运动。虽然目前的方法报告了高度的多样性和真实性，但它们通常会产生未被检测到的肢体拉伸和抖动的运动。为了解决这个问题，我们引入了SkeletonDiffusion，这是一种潜在的扩散模型，在其架构和训练中嵌入了对人体的显式归纳偏见。我们的模型是用一种新的非各向同性高斯扩散公式训练的，该公式与人体骨骼的自然运动结构相一致。结果表明，我们的方法优于传统的各向同性替代方案，能够始终如一地生成逼真的预测，同时避免肢体变形等伪影。此外，我们发现了常用多样性度量的一个局限性，这可能会无意中有利于在同一序列中产生不一致肢体长度的模型。SkeletonDiffusion在三个真实世界的数据集上设定了一个新的基准，在多个评估指标上超越了各种基线。访问我们的项目页面：https://ceveloper.github.io/publications/skeletondiffusion/ et.al.|[2501.06035](http://arxiv.org/abs/2501.06035)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-01-10**|**Nonlinear partial differential equations in neuroscience: from modelling to mathematical theory**|许多偏微分方程组已被提出作为大型神经元网络中复杂集体行为的简化表示。在这项调查中，我们简要讨论了它们的推导，然后回顾了为处理这些模型的独特特征而开发的数学方法，这些模型通常是非线性和非局部的。第一部分重点介绍抛物型福克-普朗克方程：非线性噪声泄漏积分和火神经元模型，PDE形式的随机神经场及其在网格单元中的应用，以及基于速率的决策模型。第二部分涉及双曲线输运方程，即自上次排放以来经过的时间模型和基于跳跃的泄漏积分和火灾模型。最后一部分介绍了一些动力学介观模型，特别关注动力学电压电导模型和FitzHugh-Nagumo动力学福克-普朗克系统。 et.al.|[2501.06015](http://arxiv.org/abs/2501.06015)|null|
|**2025-01-10**|**Locality-aware Gaussian Compression for Fast and High-quality Rendering**|我们提出了LocoGS，这是一种局部感知的3D高斯散斑（3DGS）框架，它利用3D高斯的空间相干性对体积场景进行紧凑建模。为此，我们首先分析了3D高斯属性的局部相干性，并提出了一种新的局部感知3D高斯表示，该表示使用具有最小存储要求的神经场表示对局部相干高斯属性进行有效编码。除了新颖的表示方法外，LocoGS还经过精心设计，添加了密集初始化、自适应球面谐波带宽方案和针对不同高斯属性的不同编码方案等附加组件，以最大限度地提高压缩性能。实验结果表明，对于代表性的真实世界3D数据集，我们的方法优于现有的紧凑高斯表示的渲染质量，同时实现了从54.6美元到96.6美元的压缩存储大小，以及从2.1美元到2.4美元的渲染速度。甚至我们的方法也证明了平均渲染速度比最先进的压缩方法高2.4倍，具有相当的压缩性能。 et.al.|[2501.05757](http://arxiv.org/abs/2501.05757)|null|
|**2025-01-08**|**KN-LIO: Geometric Kinematics and Neural Field Coupled LiDAR-Inertial Odometry**|激光雷达惯性测距（LIO）的最新进展推动了大量应用。然而，传统的LIO系统往往更侧重于定位而不是映射，映射主要由稀疏的几何元素组成，这对于下游任务来说并不理想。最近新兴的神经场技术在密集测绘方面具有巨大的潜力，但纯激光雷达测绘很难在高动态车辆上进行。为了缓解这一挑战，我们提出了一种新的解决方案，将几何运动学与神经场紧密耦合，以增强同时状态估计和密集映射能力。我们提出了半耦合和紧耦合的运动学神经LIO（KN-LIO）系统，该系统利用在线SDF解码和迭代误差状态卡尔曼滤波来融合激光和惯性数据。我们的KN-LIO最大限度地减少了信息丢失，提高了状态估计的准确性，同时也适应了异步多LiDAR输入。对各种高动态数据集的评估表明，我们的KN-LIO在姿态估计方面的性能与现有最先进的解决方案相当或更优，并且与纯基于LiDAR的方法相比，提供了更高的密集映射精度。相关代码和数据集将在https://**上提供。 et.al.|[2501.04263](http://arxiv.org/abs/2501.04263)|null|
|**2025-01-06**|**NeuroPMD: Neural Fields for Density Estimation on Product Manifolds**|我们提出了一种新的深度神经网络方法，用于在乘积黎曼流形域上进行密度估计。在我们的方法中，网络直接参数化未知密度函数，并使用惩罚最大似然框架进行训练，惩罚项使用流形微分算子形成。网络架构和估计算法经过精心设计，以应对高维积流形域的挑战，有效地减轻了限制传统核和基展开估计器的维数灾难，并克服了非专用神经网络方法遇到的收敛问题。广泛的模拟和对大脑结构连接数据的实际应用突显了我们的方法相对于竞争对手的明显优势。 et.al.|[2501.02994](http://arxiv.org/abs/2501.02994)|**[link](https://github.com/will-consagra/neuropmd)**|
|**2025-01-03**|**Fusion DeepONet: A Data-Efficient Neural Operator for Geometry-Dependent Hypersonic Flows on Arbitrary Grids**|设计再入飞行器需要准确预测其几何形状周围的高超音速流动。对这种流动的快速预测可以彻底改变车辆设计，特别是对于变形几何形状。我们评估了先进的神经算子模型，如深度算子网络（DeepONet）、参数条件U-Net、傅里叶神经算子（FNO）和MeshGraphNet，目的是解决在有限数据下学习依赖几何的高超音速流场的挑战。具体来说，我们比较了两种网格类型的这些模型的性能：均匀笛卡尔网格和不规则网格。为了训练这些模型，我们使用36个独特的椭圆几何体，使用高阶熵稳定的DGSEM求解器生成高保真模拟，强调了使用稀缺数据集的挑战。我们评估并比较了四种基于算子的模型在预测椭圆体周围高超音速流场方面的有效性。此外，我们开发了一个名为Fusion DeepONet的新框架，该框架利用了神经场概念，并在不同的几何结构中有效地进行了推广。尽管训练数据稀缺，Fusion DeepONet在均匀网格上的性能与参数条件U-Net相当，而在不规则、任意网格上的表现优于MeshGraphNet和vanilla DeepONnet。与U-Net、MeshGraphNet和FNO相比，Fusion DeepONet需要更少的可训练参数，使其计算效率更高。我们还使用奇异值分解分析了Fusion DeepONet模型的基函数。该分析表明，Fusion DeepONet能够有效地推广到看不见的解决方案，并适应不同的几何形状和网格点，证明了其在训练数据有限的情况下的鲁棒性。 et.al.|[2501.01934](http://arxiv.org/abs/2501.01934)|null|
|**2024-12-30**|**Hierarchical Pose Estimation and Mapping with Multi-Scale Neural Feature Fields**|机器人应用需要对场景有全面的了解。近年来，基于神经场的参数化整个环境的方法已经变得流行。由于其连续性和学习场景先验的能力，这些方法很有前景。然而，当处理未知的传感器姿态和连续测量时，在机器人中使用神经场变得具有挑战性。本文主要研究大规模神经隐式SLAM的传感器姿态估计问题。我们从概率的角度研究了隐式映射，并提出了具有相应神经网络架构的分层姿态估计。我们的方法非常适合大规模隐式映射表示。所提出的方法在连续的室外LiDAR扫描上运行，实现了精确的姿态估计，同时保持了短轨迹和长轨迹的稳定映射质量。我们在适合大规模重建的结构化稀疏隐式表示上构建了我们的方法，并使用KITTI和MaiCity数据集对其进行了评估。我们的方法在未知姿态的映射方面优于基线，并实现了最先进的定位精度。 et.al.|[2412.20976](http://arxiv.org/abs/2412.20976)|null|
|**2024-12-26**|**Humans as a Calibration Pattern: Dynamic 3D Scene Reconstruction from Unsynchronized and Uncalibrated Videos**|最近关于动态神经场重建的工作假设输入来自具有已知姿势的同步多视图视频。这些输入约束在现实世界的设置中经常得不到满足，使得这种方法不切实际。我们证明，如果视频捕捉到人体运动，则姿态未知的非同步视频可以生成动态神经场。人类是最常见的动态主体之一，其姿势可以使用最先进的方法进行估计。在有噪声的情况下，估计的人体形状和姿态参数为训练一致的动态神经表示的高度非凸和欠约束问题提供了一个不错的初始化。给定人类的姿势和形状序列，我们估计视频之间的时间偏移，然后通过分析3D关节位置进行相机姿势估计。然后，我们使用多分辨率脊训练动态NeRF，同时细化时间偏移和相机姿态。该设置仍然涉及优化许多参数，因此，我们引入了一种鲁棒的渐进学习策略来稳定该过程。实验表明，我们的方法在具有挑战性的条件下实现了精确的时空校准和高质量的场景重建。 et.al.|[2412.19089](http://arxiv.org/abs/2412.19089)|null|
|**2024-12-29**|**PartGen: Part-level 3D Generation and Reconstruction with Multi-View Diffusion Models**|文本或图像到3D生成器和3D扫描仪现在可以生成具有高质量形状和纹理的3D资产。这些资产通常由一个单一的融合表示组成，如隐式神经场、高斯混合或网格，没有任何有用的结构。然而，大多数应用程序和创意工作流程都要求资产由几个可以独立操作的有意义的部分组成。为了解决这一差距，我们引入了PartGen，这是一种新颖的方法，可以从文本、图像或非结构化3D对象生成由有意义的部分组成的3D对象。首先，给定生成或渲染的3D对象的多个视图，多视图扩散模型提取一组合理且视图一致的零件分割，将对象划分为零件。然后，第二个多视图扩散模型分别获取每个部分，填充遮挡，并通过将这些完成的视图馈送到3D重建网络来使用它们进行3D重建。这个完成过程考虑了整个对象的上下文，以确保各部分紧密结合。生成完成模型可以弥补因遮挡而丢失的信息；在极端情况下，它可以根据输入的3D资源产生完全不可见的部分的幻觉。我们在生成的和真实的3D资产上评估了我们的方法，并表明它在很大程度上优于分割和零件提取基线。我们还展示了3D零件编辑等下游应用程序。 et.al.|[2412.18608](http://arxiv.org/abs/2412.18608)|null|
|**2025-01-04**|**S-INF: Towards Realistic Indoor Scene Synthesis via Scene Implicit Neural Field**|基于学习的方法在3D室内场景合成（ISS）中越来越受欢迎，显示出优于传统基于优化的方法的性能。这些基于学习的方法通常使用生成模型在简单但明确的场景表示上对分布进行建模。然而，由于过于简单的显式表示忽略了详细信息，并且缺乏场景内多模态关系的指导，大多数基于学习的方法都难以生成具有逼真对象排列和风格的室内场景。本文介绍了一种新的室内场景合成方法——场景隐式神经场（S-INF），旨在学习多模态关系的有意义表示，以提高室内场景合成的真实感。S-INF假设场景布局通常与对象详细信息有关。它将多模态关系分解为场景布局关系和详细对象关系，然后通过隐式神经场（INF）将它们融合在一起。通过学习专门的场景布局关系并将其投影到S-INF中，我们实现了场景布局的真实生成。此外，S-INF通过可微分渲染捕获密集而详细的对象关系，确保对象之间的风格一致性。通过在基准3D-FRONT数据集上的广泛实验，我们证明了我们的方法在不同类型的ISS下始终达到最先进的性能。 et.al.|[2412.17561](http://arxiv.org/abs/2412.17561)|**[link](https://github.com/zixiliang/s-inf)**|
|**2024-12-22**|**HyperNet Fields: Efficiently Training Hypernetworks without Ground Truth by Learning Weight Trajectories**|为了有效地适应大型模型或训练神经表示的生成模型，超网络引起了人们的兴趣。虽然超级网络工作良好，但训练它们很麻烦，而且通常需要为每个样本进行地面实况优化的权重。然而，获得这些权重中的每一个都是一个需要训练的训练问题，例如，适应权重，甚至是超网络回归的整个神经场。在这项工作中，我们提出了一种训练超网络的方法，而不需要任何每个样本的地面真实值。我们的关键思想是学习一个超网络“场”，并估计网络权重训练的整个轨迹，而不是简单地估计其收敛状态。换句话说，我们向超网络引入了一个额外的输入，即收敛状态，这使它成为一个神经场，对任务网络的整个收敛路径进行建模。这样做的一个关键好处是，在任何收敛状态下，估计权重的梯度都必须与原始任务的梯度相匹配——仅此约束就足以训练超网络场。我们通过个性化图像生成和从图像和点云进行3D形状重建的任务来证明我们的方法的有效性，在没有任何样本地面真实性的情况下展示了具有竞争力的结果。 et.al.|[2412.17040](http://arxiv.org/abs/2412.17040)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

