---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.09.27
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-25**|**NAS-NeRF: Generative Neural Architecture Search for Neural Radiance Fields**|神经辐射场（NeRF）能够实现高质量的新视图合成，但其高得令人望而却步的计算复杂性限制了可部署性，尤其是在资源受限的平台上。为了实现NeRF的实际使用，质量调整对于降低计算复杂性至关重要，类似于视频游戏中的可调整图形设置。然而，尽管现有的解决方案努力提高效率，但无论场景复杂程度如何，它们都使用一刀切的架构，尽管相同的架构对于简单场景可能不必要地大，但对于复杂场景则不够。因此，随着NeRF越来越广泛地用于3D可视化，需要动态优化NeRF的神经网络组件，以实现计算复杂性和合成质量特定目标之间的平衡。为了解决这一差距，我们引入了NAS NeRF：一种生成神经架构搜索策略，通过优化复杂性和性能之间的权衡，同时遵守计算预算和最低合成质量的限制，专门针对每个场景生成NeRF架构。我们在Blender合成数据集上的实验表明，与基线NeRF相比，所提出的NAS NeRF在GPU上生成的架构可以小5.74 $\times$，FLOP少4.19$\times$，速度快1.93$\times]，而SSIM不会下降。此外，我们还表明，NAS NeRF还可以实现比基线NeRF小23$\times$、FLOP少22$\times$和快4.7$ \times\的架构，平均SSIM下降5.3\%。我们工作的源代码也可在https://saeejithnair.github.io/NAS-NeRF. et.al.|[2309.14293](http://arxiv.org/abs/2309.14293)|null|
|**2023-09-22**|**Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction**|隐式神经表示为动态场景重建和渲染开辟了新的途径。尽管如此，最先进的动态神经渲染方法在很大程度上依赖于这些隐含的表示，而这些表示往往难以准确捕捉场景中对象的复杂细节。此外，隐式方法难以在一般动态场景中实现实时渲染，限制了它们在各种任务中的使用。为了解决这些问题，我们提出了一种可变形的3D高斯散射方法，该方法使用显式3D高斯重建场景，并在具有变形场的规范空间中学习高斯，以对单目动态场景进行建模。我们还引入了一种没有额外开销的平滑训练机制，以减轻真实数据集中不准确姿态对时间插值任务平滑性的影响。通过差分高斯光栅化，可变形的三维高斯不仅可以获得更高的渲染质量，而且可以获得实时渲染速度。实验表明，我们的方法在渲染质量和速度方面都显著优于现有方法，非常适合于新视图合成、时间合成和实时渲染等任务。 et.al.|[2309.13101](http://arxiv.org/abs/2309.13101)|null|
|**2023-09-22**|**NeRRF: 3D Reconstruction and View Synthesis for Transparent and Specular Objects with Neural Refractive-Reflective Fields**|神经辐射场（NeRF）已经彻底改变了基于图像的视图合成领域。然而，NeRF使用直线光线，无法处理由折射和反射引起的复杂光路变化。这阻碍了NeRF成功合成透明或镜面物体，而这些物体在现实世界的机器人和A/VR应用中无处不在。本文介绍了折射反射场。以物体轮廓为输入，我们首先利用渐进编码的行进四面体来重建非朗伯物体的几何结构，然后使用菲涅耳项在统一的框架中对物体的折射和反射效应进行建模。同时，为了实现高效、有效的抗混叠，我们提出了一种虚拟锥超采样技术。我们在真实世界和合成数据集的不同形状、背景和菲涅耳项上对我们的方法进行了基准测试。我们还对各种编辑应用程序的渲染结果进行了定性和定量的基准测试，包括材质编辑、对象替换/插入和环境照明估计。代码和数据可在https://github.com/dawning77/NeRRF. et.al.|[2309.13039](http://arxiv.org/abs/2309.13039)|**[link](https://github.com/dawning77/nerrf)**|
|**2023-09-21**|**ORTexME: Occlusion-Robust Human Shape and Pose via Temporal Average Texture and Mesh Encoding**|在单目视频的3D人体形状和姿势估计中，用有限的标记数据训练的模型不能很好地推广到具有遮挡的视频，这在野生视频中很常见。最近的人类神经渲染方法专注于由现成的人形和姿势方法初始化的新颖视图合成，具有校正初始人形的潜力。然而，现有的方法存在一些缺点，例如，在处理遮挡时出错，对不准确的人体分割敏感，以及由于非正则化的不透明度场而导致的无效损失计算。为了解决这些问题，我们引入了ORTexME，这是一种遮挡鲁棒的时间方法，它利用来自输入视频的时间信息来更好地正则化被遮挡的身体部位。虽然我们的ORTexME是基于NeRF的，但为了确定NeRF射线采样的可靠区域，我们利用我们新颖的平均纹理学习方法来学习人的平均外观，并基于平均纹理推断面具。此外，为了指导NeRF中的不透明度场更新以抑制模糊和噪声，我们建议使用人体网格。定量评估表明，我们的方法在具有挑战性的多人3DPW数据集上实现了显著的改进，其中我们的方法实现了1.8P-MPJPE的误差降低。基于SOTA渲染的方法失败了，并在同一数据集上将错误扩大到5.6。 et.al.|[2309.12183](http://arxiv.org/abs/2309.12183)|null|
|**2023-09-21**|**Fast Satellite Tensorial Radiance Field for Multi-date Satellite Imagery of Large Size**|现有的卫星图像NeRF模型速度较慢，必须输入太阳信息，并且在处理大型卫星图像方面存在局限性。作为回应，我们提出了SatensoRF，它显著加快了整个过程，同时为大尺寸卫星图像使用了更少的参数。此外，我们观察到，在神经辐射场中，朗伯表面的普遍假设不符合植物和水生元素。与传统的基于分层MLP的场景表示相比，我们选择了一种针对颜色、体积密度和辅助变量的多尺度张量分解方法来对具有镜面颜色的光场进行建模。此外，为了纠正多日期图像中的不一致性，我们结合了总变化损失来恢复密度张量场，并将该问题视为去噪任务。为了验证我们的方法，我们使用空间网多视图数据集的子集对SatensoRF进行了评估，该数据集包括多日期和单日期多视图RGB图像。我们的结果清楚地表明，SatensoRF在新颖的视图合成性能方面超过了最先进的Sat-NeRF系列。值得注意的是，SatensoRF需要更少的参数进行训练，从而提高训练和推理速度，降低计算需求。 et.al.|[2309.11767](http://arxiv.org/abs/2309.11767)|null|
|**2023-09-20**|**GenLayNeRF: Generalizable Layered Representations with 3D Model Alignment for Multi-Human View Synthesis**|由于复杂的人与人之间的遮挡，多人场景的新视图合成（NVS）带来了挑战。分层表示通过将场景划分为多层辐射场来处理复杂性，然而，它们主要局限于逐场景优化，因此效率低下。可泛化的人体视图合成方法将预先拟合的三维人体网格与图像特征相结合以达到泛化，但它们主要是针对单个人体场景设计的。另一个缺点是依赖于用于3D身体模型的参数预拟合的多步骤优化技术，该3D身体模型在稀疏视图设置中与图像不对准，从而导致合成视图中的幻觉。在这项工作中，我们提出了GenLayNeRF，这是一种可推广的分层场景表示，用于多个人类主体的自由视点渲染，不需要每场景优化和非常稀疏的视图作为输入。我们将场景划分为由3D身体网格锚定的多个人体层。然后，我们通过一个新颖的端到端可训练模块确保身体模型与输入视图的像素级对齐，该模块执行迭代参数校正，并结合多视图特征融合，以产生对齐的3D模型。对于NVS，我们提取逐点图像对齐和人锚定的特征，这些特征使用自注意和交叉注意模块进行关联和融合。我们使用基于注意力的RGB融合模块将低级别的RGB值增强到特征中。为了评估我们的方法，我们构建了两个多人视角合成数据集；DeepMultiSyn和ZJU MultiHuman。结果表明，在没有测试时间优化的情况下，我们提出的方法优于可推广的和非人类的每场景NeRF方法，同时与分层的每场景方法不相上下。 et.al.|[2309.11627](http://arxiv.org/abs/2309.11627)|null|
|**2023-09-23**|**Light Field Diffusion for Single-View Novel View Synthesis**|单视图新视图合成，即基于单个参考图像从新视点生成图像的任务，是计算机视觉中一项重要但具有挑战性的任务。近年来，去噪扩散概率模型（DDPM）由于其强大的高保真度图像生成能力而在该领域流行起来。然而，当前基于扩散的方法直接依赖于相机姿态矩阵作为观看条件，全局地和隐含地引入3D约束。这些方法可能存在从不同角度生成的图像之间的不一致性，特别是在具有复杂纹理和结构的区域中。在这项工作中，我们提出了光场扩散（LFD），这是一种基于条件扩散的单视图新视图合成模型。与以前使用相机姿态矩阵的方法不同，LFD将相机视图信息转换为光场编码，并将其与参考图像相结合。这种设计在扩散模型中引入了局部像素约束，从而促进了更好的多视图一致性。在几个数据集上的实验表明，我们的LFD可以有效地生成高保真图像，即使在复杂的区域也能保持更好的3D一致性。我们的方法可以生成比基于NeRF的模型质量更高的图像，并且我们获得的样本质量与其他基于扩散的模型类似，但只有模型大小的三分之一。 et.al.|[2309.11525](http://arxiv.org/abs/2309.11525)|null|
|**2023-09-21**|**Controllable Dynamic Appearance for Neural 3D Portraits**|神经辐射场（NeRF）的最新进展使得通过控制头部姿势、面部表情和观看方向来重建和恢复动态人像场景成为可能。然而，训练这样的模型假设变形区域的光度一致性，例如，随着头部姿势和面部表情的变化，面部变形时必须均匀照明。即使在工作室环境中，视频各帧之间的这种光度一致性也很难保持，因此，创建的可重影神经肖像在重影过程中容易出现伪影。在这项工作中，我们提出了CoDyNeRF，这是一种能够在真实世界的捕捉条件下创建完全可控的3D肖像的系统。CoDyNeRF通过规范空间中的动态外观模型来学习近似照明相关效果，该模型以预测的表面法线、面部表情和头部姿势变形为条件。表面法线预测是使用3DMM法线来指导的，3DMM法线充当人类头部法线的粗略先验，其中由于头部姿势和面部表情变化引起的刚性和非刚性变形，很难直接预测法线。仅使用智能手机拍摄的受试者短视频进行训练，我们就展示了我们的方法在具有明确的头部姿势和表情控制以及逼真照明效果的人像场景的自由视图合成方面的有效性。项目页面可在此处找到：http://shahrukhathar.github.io/2023/08/22/CoDyNeRF.html et.al.|[2309.11009](http://arxiv.org/abs/2309.11009)|null|
|**2023-09-19**|**ReShader: View-Dependent Highlights for Single Image View-Synthesis**|近年来，由于3D场景表示和图像修复技术的快速发展，从单个图像进行的新颖视图合成已经取得了重大进展。虽然目前的方法能够合成几何一致的新视图，但它们往往不能正确处理视图相关的效果。具体来说，他们合成图像中的高光通常看起来粘在表面上，这使得新颖的视图不切实际。为了解决这个主要问题，我们进行了一项关键观察，即合成新视图的过程需要改变基于新相机的像素的阴影，并将它们移动到适当的位置。因此，我们建议将视图合成过程拆分为两个独立的任务，即像素重新加载和重新定位。在重影过程中，我们以单个图像为输入，并基于新型相机调整其明暗度。然后将该重新加载的图像用作现有视图合成方法的输入，以重新定位像素并产生最终的新颖视图图像。我们建议使用神经网络来执行重新加载，并生成一大组合成输入重新加载对来训练我们的网络。我们证明，我们的方法在各种现实世界场景中产生了具有逼真运动亮点的看似新颖的视图图像。 et.al.|[2309.10689](http://arxiv.org/abs/2309.10689)|null|
|**2023-09-19**|**Locally Stylized Neural Radiance Fields**|近年来，人们对将风格化应用于参考风格图像的3D场景，特别是应用于神经辐射场（NeRF）越来越感兴趣。虽然直接在NeRF上执行风格化可以保证在任意新颖视图上的外观一致性，但引导图案从风格图像转移到NeRF场景的不同部分是一个具有挑战性的问题。在这项工作中，我们提出了一个基于局部风格转移的NeRF风格化框架。特别是，我们使用哈希网格编码来学习外观和几何组件的嵌入，并表明哈希表定义的映射允许我们在一定程度上控制风格化。然后通过优化外观分支同时保持几何体分支固定来实现样式化。为了支持局部风格转移，我们提出了一种新的损失函数，该函数利用分割网络和二分匹配来建立风格图像和从体绘制中获得的内容图像之间的区域对应关系。我们的实验表明，我们的方法通过新的视图合成产生了合理的风格化结果，同时通过操纵和定制区域对应关系具有灵活的可控性。 et.al.|[2309.10684](http://arxiv.org/abs/2309.10684)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-25**|**A Novel Approach for Effective Multi-View Clustering with Information-Theoretic Perspective**|多视图集群（MVC）是一种流行的技术，用于使用各种数据源来提高集群性能。然而，现有的方法主要侧重于获取一致的信息，而往往忽略了跨多个视图的冗余问题。本研究提出了一种新的方法，称为充分多视图聚类（SUMVC），从信息论的角度考察了多视图聚类框架。我们提出的方法由两部分组成。首先，我们开发了一种简单可靠的多视图聚类方法SCMVC（简单一致多视图聚类），该方法采用变分分析来生成一致信息。其次，我们提出了一个充分的表示下界，以增强视图之间的一致性信息并最大限度地减少不必要的信息。所提出的SUMVC方法为多视图聚类问题提供了一种很有前途的解决方案，并为分析多视图数据提供了一个新的视角。为了验证我们模型的有效性，我们基于贝叶斯错误率进行了理论分析，并在多个多视图数据集上进行了实验，证明了SUMVC的优越性能。 et.al.|[2309.13989](http://arxiv.org/abs/2309.13989)|null|
|**2023-09-24**|**Federated Deep Multi-View Clustering with Global Self-Supervision**|联合多视图集群有可能从分布在多个设备上的数据中学习全局集群模型。在这种情况下，标签信息是未知的，必须保护数据隐私，这导致了两大挑战。首先，不同客户端上的视图通常具有特征异构性，挖掘它们互补的集群信息并非易事。其次，在分布式环境中存储和使用来自多个客户端的数据会导致多视图数据的不完整性。为了应对这些挑战，我们提出了一种新的联邦深度多视图聚类方法，该方法可以从多个客户端挖掘互补的集群结构，同时处理数据的不完整性和隐私问题。具体来说，在服务器环境中，我们提出了样本对齐和数据扩展技术来探索多个视图的互补集群结构。然后，服务器将全局原型和全局伪标签作为全局自监督信息分发给每个客户端。在客户端环境中，多个客户端使用全局自监督信息和深度自动编码器来学习特定于视图的集群分配和嵌入特征，然后将其上传到服务器以细化全局自监督的信息。最后，我们广泛的实验结果表明，我们提出的方法在解决分布式环境中不完整多视图数据的挑战方面表现出优异的性能。 et.al.|[2309.13697](http://arxiv.org/abs/2309.13697)|null|
|**2023-09-23**|**MP-MVS: Multi-Scale Windows PatchMatch and Planar Prior Multi-View Stereo**|在提高基于多视图立体（MVS）的3D重建的准确性方面已经取得了重大进展。然而，具有不稳定光度一致性的无纹理区域通常仍不完全重建。在本文中，我们提出了一种弹性和有效的多视图立体方法（MP-MVS）。我们设计了一个多尺度窗口PatchMatch（mPM）来获得可靠的无纹理区域深度。与其他多尺度方法相比，后者速度更快，可以很容易地扩展到基于PatchMatch的MVS方法。随后，我们通过将采样限制在遥远的区域来改进现有的棋盘采样方案，这可以有效地提高空间传播的效率，同时减少异常值的生成。最后，我们介绍并改进了ACMP的平面先验辅助PatchMatch。我们不依赖光度一致性，而是利用多视图之间的几何一致性信息来选择可靠的三角顶点。该策略可以获得更精确的平面先验模型来校正光度一致性测量。我们的方法已经在ETH3D高分辨率多视图基准上用几种最先进的方法进行了测试。结果表明，我们的方法可以达到最先进的水平。相关代码可访问https://github.com/RongxuanTan/MP-MVS. et.al.|[2309.13294](http://arxiv.org/abs/2309.13294)|**[link](https://github.com/rongxuantan/mp-mvs)**|
|**2023-09-22**|**NeRRF: 3D Reconstruction and View Synthesis for Transparent and Specular Objects with Neural Refractive-Reflective Fields**|神经辐射场（NeRF）已经彻底改变了基于图像的视图合成领域。然而，NeRF使用直线光线，无法处理由折射和反射引起的复杂光路变化。这阻碍了NeRF成功合成透明或镜面物体，而这些物体在现实世界的机器人和A/VR应用中无处不在。本文介绍了折射反射场。以物体轮廓为输入，我们首先利用渐进编码的行进四面体来重建非朗伯物体的几何结构，然后使用菲涅耳项在统一的框架中对物体的折射和反射效应进行建模。同时，为了实现高效、有效的抗混叠，我们提出了一种虚拟锥超采样技术。我们在真实世界和合成数据集的不同形状、背景和菲涅耳项上对我们的方法进行了基准测试。我们还对各种编辑应用程序的渲染结果进行了定性和定量的基准测试，包括材质编辑、对象替换/插入和环境照明估计。代码和数据可在https://github.com/dawning77/NeRRF. et.al.|[2309.13039](http://arxiv.org/abs/2309.13039)|**[link](https://github.com/dawning77/nerrf)**|
|**2023-09-22**|**Deep3DSketch+: Rapid 3D Modeling from Single Free-hand Sketches**|AR/VR的快速发展给3D内容带来了巨大的需求。虽然广泛使用的计算机辅助设计（CAD）方法需要耗时且劳动密集的建模过程，但基于草图的三维建模作为计算机与人交互的自然形式提供了一种潜在的解决方案。然而，草图的稀疏性和模糊性使得生成反映创作者想法的高保真度内容具有挑战性。通常需要从多个视图精确绘制或战略性分步绘制来应对挑战，但对新手用户来说并不友好。在这项工作中，我们介绍了一种新的端到端方法Deep3DSketch+，该方法只使用一个徒手草图进行三维建模，而无需输入多个草图或视图信息。具体而言，我们介绍了一种用于实时高效推理的轻量级生成网络，以及一种具有结构感知的对抗性训练方法，该方法使用笔划增强模块（SEM）来捕获结构信息，以便于学习逼真和精细的形状结构，从而实现高保真性能。大量的实验证明了我们的方法在合成和真实数据集上具有最先进的（SOTA）性能的有效性。 et.al.|[2309.13006](http://arxiv.org/abs/2309.13006)|null|
|**2023-09-25**|**Language-driven Object Fusion into Neural Radiance Fields with Pose-Conditioned Dataset Updates**|神经辐射场是一种新兴的渲染方法，它通过神经场景表示和体积渲染生成高质量的多视图一致图像。尽管基于神经辐射场的技术对于场景重建是稳健的，但它们添加或移除对象的能力仍然有限。本文提出了一种新的语言驱动方法，通过数据集更新实现具有神经辐射场的对象操作。具体而言，为了将由一组多视图图像表示的新前景对象插入背景辐射场，我们使用文本到图像的扩散模型来学习并生成组合图像，该组合图像将感兴趣的对象融合到视图之间的给定背景中。然后，这些组合图像用于细化背景辐射场，以便我们可以渲染包含对象和背景的视图一致的图像。为了确保视图的一致性，我们提出了一种数据集更新策略，该策略在将训练传播到剩余视图之前，优先考虑与已训练视图接近的相机视图的辐射场训练。我们表明，在相同的数据集更新策略下，我们可以使用文本到三维模型的数据以及对象移除来轻松地调整我们的对象插入方法。实验结果表明，我们的方法可以生成编辑场景的真实感图像，在三维重建和神经辐射场混合方面优于现有技术。 et.al.|[2309.11281](http://arxiv.org/abs/2309.11281)|**[link](https://github.com/kcshum/pose-conditioned-NeRF-object-fusion)**|
|**2023-09-19**|**PLVS: A SLAM System with Points, Lines, Volumetric Mapping, and 3D Incremental Segmentation**|本文介绍了PLVS：一个利用稀疏SLAM、体积映射和3D无监督增量分割的实时系统。PLVS代表点、线、体积映射和分割。它支持RGB-D和立体声相机，这些相机可以选择配备IMU。SLAM模块基于关键帧，提取并跟踪稀疏点和线段作为特征。体积映射相对于SLAM前端并行运行，并通过融合从关键帧反向投影的点云来生成探索环境的3D重建。PLVS支持并集成了不同的体积映射方法。我们使用一种新的重投影误差来对调整线段进行集束。该误差利用可用的深度信息来稳定线段端点的位置估计。在PLVS框架下，为RGB-D相机实现并集成了一种基于几何的增量分割方法。我们在一些公开的数据集上对PLVS框架进行了定性和定量评估。附录详细介绍了所采用的立体线三角测量方法，并对我们用于线误差项的雅可比矩阵进行了推导。该软件是开源的。 et.al.|[2309.10896](http://arxiv.org/abs/2309.10896)|**[link](https://github.com/luigifreda/plvs)**|
|**2023-09-19**|**SHOWMe: Benchmarking Object-agnostic Hand-Object 3D Reconstruction**|最近的手-物体交互数据集显示出有限的真实物体可变性，并且依赖于拟合MANO参数模型来获得真实的手形状。为了超越这些限制并推动进一步的研究，我们引入了SHOWMe数据集，该数据集由96个视频组成，用真实和详细的手对象3D纹理网格进行注释。根据最近的工作，我们考虑了一个刚性手对象场景，其中手相对于对象的姿势在整个视频序列中保持不变。这一假设使我们能够将亚毫米精度的地面实况3D扫描注册到SHOWMe中的图像序列中。尽管更简单，但这一假设在所需精度和细节水平很重要的应用中是有意义的，例如，人机协作中的对象移交、对象扫描或操作和接触点分析。重要的是，手对象系统的刚性允许使用由刚性配准步骤和多视图重建（MVR）部分组成的两阶段流水线来处理未知手持对象的基于视频的3D重建。我们仔细评估了这两个阶段的一组非平凡基线，并表明使用SfM工具箱或手部姿态估计器来恢复刚性变换和现成的MVR算法，可以实现有前景的对象不可知的3D手部对象重建。然而，这些方法对最初的相机姿态估计仍然敏感，由于物体上缺乏纹理或手的严重遮挡，这些估计可能不精确，这为重建留下了改进的空间。代码和数据集可在https://europe.naverlabs.com/research/showme et.al.|[2309.10748](http://arxiv.org/abs/2309.10748)|null|
|**2023-09-18**|**Improving Neural Indoor Surface Reconstruction with Mask-Guided Adaptive Consistency Constraints**|从2D图像重建3D场景一直是一项长期任务。最近的研究利用神经隐式表面作为3D重建的统一表示，而不是估计每帧深度图并将其融合到3D中。这些方法配备了数据驱动的预训练几何线索，表现出了良好的性能。然而，不准确的先验估计（这通常是不可避免的）可能导致次优重建质量，特别是在一些几何复杂的区域。在本文中，我们提出了一个两阶段的训练过程，解耦视图相关和视图无关的颜色，并利用两个新的一致性约束来提高细节重建性能，而不需要额外的先验。此外，我们引入了一个基本的掩码方案来自适应地影响监督约束的选择，从而提高自监督范式中的性能。在合成数据集和真实世界数据集上的实验表明，该方法能够减少先验估计误差的干扰，并实现具有丰富几何细节的高质量场景重建。 et.al.|[2309.09739](http://arxiv.org/abs/2309.09739)|null|
|**2023-09-18**|**Robust Geometry-Preserving Depth Estimation Using Differentiable Rendering**|在这项研究中，我们解决了从单目深度估计中恢复3D场景结构的挑战。虽然传统的深度估计方法利用标记的数据集来直接预测绝对深度，但最近的进展提倡混合数据集训练，增强了在不同场景中的泛化能力。然而，这种混合数据集训练只能产生未知规模和偏移的深度预测，阻碍了精确的3D重建。现有的解决方案需要额外的3D数据集或几何体完整的深度注释，这些限制了它们的通用性。在本文中，我们提出了一种学习框架，该框架训练模型来预测几何保持深度，而不需要额外的数据或注释。为了产生逼真的3D结构，我们渲染重建场景的新颖视图，并设计损失函数，以提高不同视图之间的深度估计一致性。全面的实验强调了我们框架卓越的泛化能力，在几个基准数据集上超越了现有的最先进的方法，而不需要利用额外的训练信息。此外，我们创新的损失函数使模型能够仅使用未标记的图像自主恢复特定领域的尺度和偏移系数。 et.al.|[2309.09724](http://arxiv.org/abs/2309.09724)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-25**|**Dataset Diffusion: Diffusion-based Synthetic Dataset Generation for Pixel-Level Semantic Segmentation**|为深度视觉模型准备训练数据是一项劳动密集型任务。为了解决这一问题，生成模型已成为生成合成数据的有效解决方案。当当前的生成模型产生图像级的类别标签时，我们提出了一种使用文本到图像生成模型稳定扩散（SD）生成像素级语义分割标签的新方法。通过利用SD的文本提示、交叉注意和自注意，我们介绍了三种新技术：\textit｛class prompt appending｝、\textit{class prompt cross-attention｝和\textit｝自注意幂运算。这些技术使我们能够生成与合成图像相对应的分割图。这些映射充当训练语义分割器的伪标签，消除了对劳动密集型逐像素注释的需要。为了解决伪标签中的缺陷，我们将不确定性区域纳入分割中，使我们能够忽略这些区域的损失。我们在两个数据集PASCAL VOC和MSCOCO上进行了评估，我们的方法显著优于并行工作。我们的基准测试和代码将在https://github.com/VinAIResearch/Dataset-Diffusion et.al.|[2309.14303](http://arxiv.org/abs/2309.14303)|null|
|**2023-09-25**|**Bayesian parameter estimation for characterising mobile ion vacancies in perovskite solar cells**|为了克服与钙钛矿太阳能电池的时间稳定性差相关的挑战，需要允许快速迭代制造和表征的方法，从而可以积极追求最佳的器件性能和稳定性。目前，确定表现不佳的原因既复杂又耗时，因此器件制造的优化本身就很慢。在这里，我们提出了一种仅从室温电流-电压（J-V）测量中对移动卤化物离子参数进行计算设备表征的方法，需要在基本计算资源上进行 $\sim 2$小时的计算。通过我们的方法，可以根据实验J-V测量结果对设备的物理参数进行反向建模。在漂移-扩散模型中，一组耦合的漂移-扩散偏微分方程不能显式反演，因此需要一种反演漂移-扩散模拟的方法。我们展示了贝叶斯参数估计（BPE）与漂移扩散钙钛矿太阳能电池模型相结合如何确定器件参数对J-V特性测量的性能的影响程度。我们的方法是通过研究特定制造的器件的移动卤化物离子对器件性能的影响程度来证明的。对于模拟和制造的器件，离子空位密度$N_0$和扩散系数$D_I$ 都被精确地表征。这一结果为通过发现哪些参数在细胞降解时对器件J-V曲线的影响最大来确定降解的起源开辟了可能性。 et.al.|[2309.14302](http://arxiv.org/abs/2309.14302)|null|
|**2023-09-25**|**A Multi-Frequency View of the Radio Phoenix in the Abell 85 Cluster**|无线电光是在合并和弛豫星团中发现的复杂的丝状散射无线电源。这些源的形成被认为是旧的活动星系核（AGN）等离子体在冲击波中的绝热压缩。以前对这些源的大多数光谱研究都局限于积分光谱指数，发现积分光谱指数非常陡峭，并且显示出弯曲的光谱。在这里，我们对阿贝尔85星团中的无线电凤凰进行了多频率调查。由于灵敏的高分辨率观测，我们发现了一些以前未被发现的精细丝状结构。我们制作了无线电凤凰号在148323700和1280MHz之间的分辨光谱指数图。细丝的方向以及光谱指数图上的梯度表明了冲击运动可能从东北到西南的方向。无线电凤凰号的综合光谱指数被发现非常陡峭，在700 MHz左右有一个中断，这表明化石电子的重新通电是最近的事。此外，发现细丝的光谱指数与非细丝区域相比不那么陡峭，这意味着细丝中的能量注入更大。在阿贝尔85星团的无线电凤凰中观察到的特征似乎支持绝热冲击压缩机制。 et.al.|[2309.14244](http://arxiv.org/abs/2309.14244)|null|
|**2023-09-25**|**Magneto-thermal evolution in the cores of adolescent neutron stars: The Grad-Shafranov equilibrium is never reached in the 'strong-coupling' regime**|在最近形成的中子星内部存在的高温下（ $T\gtrsim 5\times 10^｛8｝\，\text｛K｝$），其核心中的粒子处于“强耦合”状态，在这种状态下，碰撞力使它们表现为单一的、稳定分层的，因此是非正压流体。在这种情况下，轴对称的流磁准平衡态是可能的，它们只被约束为具有消失的方位洛伦兹力。在这种平衡中，粒子种类不处于化学（$\beta$）平衡，因此$\beta$decays（Urca反应）倾向于恢复化学平衡，引发改变磁场配置的流体运动。如果恒星在足够长的时间内保持高温，这种演化最终将导致化学平衡状态，在这种状态下，流体是正压的，磁场如果轴对称，则满足非线性Grad-Shafranov方程。在这项工作中，我们提出了一种将磁和热演化解耦的数值方案，首次能够在不同磁场强度和几何形状的情况下，在该方案中有效地进行长期磁热模拟。我们的结果表明，即使对于磁星强度场$\gtrsim 10^｛16｝\，\mathrm｛G｝$，磁演化对热演化的反馈也可以忽略不计。因此，当核心被动冷却时，Urca反应在恢复化学平衡方面很快变得低效，因此磁场变化很小，在这种情况下无法达到Grad-Shafranov平衡。因此，核心磁场的任何实质性演变都必须稍后在较冷的“弱耦合”状态下发生（$T\lesssim 5\乘以10^8\，\mathrm{K}$ ），在该状态下，Urca反应被有效冻结，双极扩散变得相关。 et.al.|[2309.14182](http://arxiv.org/abs/2309.14182)|null|
|**2023-09-25**|**Nonlinear Filtering of Classical and Quantum Spin Systems**|在本文中，我们考虑离散晶格和欧几里得空间中的经典和量子自旋系统，该系统由Hilbert空间中的无穷维随机扩散建模。对于这些模型，已知解的各种概念的存在性和唯一性、不变测度的存在性与唯一性以及到平衡的指数收敛性。我们为这类模型建立了非线性滤波问题，导出了Fujisaki Kallianpur Kunita和Zakai tye的非线性滤波方程，并证明了这些滤波方程的测度值解的存在性和唯一性。然后，我们建立了与滤波方程相关的半群的Feller性质和Markov性质，并证明了不变测度的存在性和唯一性。推导了非线性滤波器的误差协方差方程的演化过程。我们还导出了经典和量子自旋系统的Kallianpur和Karandikar有限加性白噪声公式的非线性滤波方程，并研究了测度值解的存在性和唯一性 et.al.|[2309.14143](http://arxiv.org/abs/2309.14143)|null|
|**2023-09-25**|**Non-equilibrium steady states of electrolyte interfaces**|利用Poisson-Nernst-Planck（PNP）理论研究了以非消失电流为特征的半无限准一维单价二元电解质溶液的非平衡稳态。导出了电场、电荷密度和数密度的精确解析表达式，这些表达式取决于电流密度作为参数。根据Grahame方程的非平衡版本，该方程将每横截面积的总空间电荷与电位降的相应贡献联系起来，导出了扩散层的电流相关微分电容。在消失电流的极限下，这些结果可以归结为Gouy-Chapman理论中的结果。结果表明，边界条件选择不当会导致负离子数密度PNP方程的非平衡稳态解。建立了一个关于表面电导率本构关系的充分必要的准则，使人们能够检测到这种非物理解。 et.al.|[2309.14126](http://arxiv.org/abs/2309.14126)|null|
|**2023-09-25**|**A Common Approach to Singular Perturbation and Homogenization II: Semilinear Elliptic Systems**|我们考虑了类型为 $$\mbox｛div｝\left（A（x/\varepsilon）\nabla u（x）\right）=b（x，u（x对于小的$\varepsilon>0$，我们证明了弱解$u=u_\varepsilion$的存在性以及它们对于$\|u-u_0\|_\infty\approxy0$的局部唯一性，其中$u_0$是齐化边值问题的给定非退化弱解，并且我们估计了$\|u_\varepsilon-u_0\|__\infty$对于$\varepilon\~0$的收敛到零的速率。我们的假设大致如下：映射$y\mapsto A（y）$是有界的、可测量的并且$\mathbb｛Z｝^2$是周期性的，映射$b（\cdot，u）$是有限的和可测量的，映射$b（x，\cdot）$是$C^1$光滑的，并且$\Omega$是$\mathbb{R｝^2$中的有界Lipschitz域。既不假定全局解的唯一性，也不假定$b（x，\cdot）$的增长限制，也不假设$W^｛2，2｝$ 的正则性，并且允许交叉扩散。证明的主要工具是隐函数定理类型的抽象结果，该类型在过去已应用于奇摄动非线性常微分方程、椭圆和抛物型偏微分方程，因此，它允许对奇摄动问题和均匀化问题的存在性、局部唯一性和误差估计采用通用方法。 et.al.|[2309.14108](http://arxiv.org/abs/2309.14108)|null|
|**2023-09-25**|**Bayesian inference of 3D densities of galactic HI and H2**|由于我们在银河系盘面上的有利位置，无法直接访问其3D结构。然而，了解空间分布，例如原子和分子氢气的空间分布，对于解释和模拟宇宙射线数据和扩散发射具有重要意义。使用新的贝叶斯推理技术，我们重建了银河系中原子和分子氢的三维密度以及（部分）银河系速度场。为了正则化无限多个自由度，并在数据缺失或不足的区域中获得信息，我们将气田的相关性结构纳入我们的先验中。这些重建的基础是21厘米排放线的HI4PI调查和Dame等人（2001）编制的CO调查的数据集。（ $1\rightarrow0$ ）旋转过渡以及可变气流模型。我们给出了初步估计的平均表面质量密度和对先前星系速度场假设的修正。未来，我们计划放宽对光学厚度的假设，并包括额外的数据，以进一步约束星系速度场或气体密度。 et.al.|[2309.14075](http://arxiv.org/abs/2309.14075)|null|
|**2023-09-25**|**Soft Mixture Denoising: Beyond the Expressive Bottleneck of Diffusion Models**|由于扩散模型在图像合成等许多任务中表现出了令人印象深刻的性能，因此最近的工作中有一种趋势，即（在某些假设下）证明这些模型具有强大的近似能力。在本文中，我们表明当前的扩散模型在反向去噪方面实际上存在表达瓶颈，并且现有理论保证所做的一些假设过于强大。基于这一发现，我们证明了扩散模型在局部去噪和全局近似中都存在无界误差。根据我们的理论研究，我们介绍了软混合去噪（SMD），这是一种高效的反向去噪模型。SMD不仅允许扩散模型在理论上很好地近似任何高斯混合分布，而且实现起来简单高效。我们在多个图像数据集上的实验表明，SMD显著改进了不同类型的扩散模型（例如，DDPM），特别是在很少向后迭代的情况下。 et.al.|[2309.14068](http://arxiv.org/abs/2309.14068)|null|
|**2023-09-25**|**Mixing as a correlated aggregation process**|混合描述了标量（如溶质浓度或流体温度）在流体流的搅拌作用下从初始非均匀状态演变为均匀状态的过程。混合最初是由于流体拉伸而形成标量片层，后来由于分子扩散而聚结。由于平流-扩散方程的线性，标量聚结可以看作是一个聚集过程。虽然随机聚集模型已被证明可以捕捉一系列湍流中的标量混合，但我们在这里证明，它们对大多数混沌流来说并不准确。特别是，我们发现聚集体中片层数量的空间分布与它们的伸长率高度相关，并且还受到混沌流产生的分形几何的影响。相关性的存在使得混合的效率不如完全随机的聚集过程，因为具有相似伸长率和标量水平的片层往往保持彼此隔离。基于这些观察结果，我们提出了一个相关聚合框架，该框架捕捉混沌流的渐近混合动力学，并基于流拉伸统计预测标量pdf的演化。我们证明了相关聚集是由单个指数唯一确定的，该指数量化了随机聚集事件的有效数量，并取决于流的分形维数。这些发现将聚合理论扩展到更大一类系统，这些系统与各种基本和应用的混合问题有关。 et.al.|[2309.14040](http://arxiv.org/abs/2309.14040)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-22**|**NOC: High-Quality Neural Object Cloning with 3D Lifting of Segment Anything**|随着神经领域的发展，从多视图输入重建目标物体的3D模型最近越来越受到社会的关注。现有的方法通常学习整个场景的神经场，而如何在飞行中重建用户指示的特定对象仍在探索之中。考虑到分段任意模型（SAM）在分割任何2D图像方面都显示出了有效性，本文提出了一种新的高质量3D对象重建方法——神经对象克隆（NOC），它从两个方面利用了神经场和SAM的优点。首先，为了将目标对象从场景中分离出来，我们提出了一种新的策略，将SAM的多视图2D分割掩模提升到一个统一的3D变化场中。然后，3D变化场被投影到2D空间中，并生成SAM的新提示。这个过程是迭代的，直到收敛，以将目标对象从场景中分离出来。然后，除了2D掩模之外，我们进一步将SAM编码器的2D特征提升到3D SAM场中，以提高目标对象的重建质量。NOC将SAM的2D掩模和特征提升到3D神经场中，用于高质量的目标对象重建。我们在几个基准数据集上进行了详细的实验，以证明我们的方法的优势。代码将被发布。 et.al.|[2309.12790](http://arxiv.org/abs/2309.12790)|null|
|**2023-09-15**|**Breathing New Life into 3D Assets with Generative Repainting**|基于扩散的文本到图像模型引发了视觉社区、艺术家和内容创作者的巨大关注。这些模型的广泛采用是由于世代质量的显著提高以及对各种模式的有效调节，而不仅仅是文本。然而，将这些2D模型的丰富生成先验提升到3D中是具有挑战性的。最近的工作提出了由扩散模型和神经场的纠缠提供动力的各种管道。我们探索了预训练的2D扩散模型和标准3D神经辐射场作为独立工具的威力，并展示了它们以非学习方式协同工作的能力。这种模块化具有易于部分升级的内在优势，这在这样一个快节奏的领域中成为了一个重要的特性。我们的管道接受任何遗留的可渲染几何体，如纹理或无纹理网格，协调2D生成细化和3D一致性强制工具之间的交互，并以多种格式输出绘制的输入几何体。我们对ShapeNetSem数据集中的广泛对象和类别进行了大规模研究，并从定性和定量两个方面展示了我们方法的优势。项目页面：https://www.obukhov.ai/repainting_3d_assets et.al.|[2309.08523](http://arxiv.org/abs/2309.08523)|**[link](https://github.com/kongdai123/repainting_3d_assets)**|
|**2023-09-14**|**Neural Field Representations of Articulated Objects for Robotic Manipulation Planning**|传统的操作规划方法依赖于环境的显式几何模型来将给定任务公式化为优化问题。然而，从原始传感器输入推断准确的模型本身就是一个难题，尤其是对于铰接物体（例如壁橱、抽屉）。在本文中，我们提出了一种关节对象的神经场表示（NFR），可以直接从图像中进行操作规划。具体来说，在拍摄了一个新的关节物体的几张照片后，我们可以向前模拟它可能的运动，因此，可以直接使用该神经模型进行轨迹优化规划。此外，这种表示可以用于形状重建、语义分割和图像渲染，这在训练和泛化过程中提供了强大的监督信号。我们表明，我们的模型仅在合成图像上训练，能够在模拟和真实图像中为同类看不见的物体提取有意义的表示。此外，我们证明了该表示能够直接从图像中对现实世界中的关节物体进行机器人操作。 et.al.|[2309.07620](http://arxiv.org/abs/2309.07620)|null|
|**2023-09-13**|**Generalizable Neural Fields as Partially Observed Neural Processes**|神经场将信号表示为由神经网络参数化的函数，是传统离散矢量或基于网格的表示的一种很有前途的替代方案。与离散表示相比，神经表示既能很好地扩展分辨率，又是连续的，并且可以是多次可微的。然而，给定我们想要表示的信号数据集，必须为每个信号优化单独的神经场是低效的，并且不能利用信号之间的共享信息或结构。现有的泛化方法将其视为元学习问题，并采用基于梯度的元学习来学习初始化，然后通过测试时间优化对初始化进行微调，或者学习超网络来产生神经场的权重。相反，我们提出了一种新的范式，将神经表征的大规模训练视为部分观察到的神经过程框架的一部分，并利用神经过程算法来解决这一任务。我们证明，这种方法优于最先进的基于梯度的元学习方法和超网络方法。 et.al.|[2309.06660](http://arxiv.org/abs/2309.06660)|null|
|**2023-09-08**|**Single View Refractive Index Tomography with Neural Fields**|折射率层析成像是一个反问题，我们试图从2D投影图像测量中重建场景的3D折射场。折射场本身是不可见的，而是影响光线在空间中传播时路径的连续弯曲。折射场出现在各种各样的科学应用中，从显微镜中的半透明细胞样本到弯曲来自遥远星系的光的暗物质场。这个问题带来了一个独特的挑战，因为折射场直接影响光的路径，使其恢复成为一个非线性问题。此外，与传统的层析成像相比，我们试图通过利用散射在整个介质中的光源的知识，仅从单个视点使用投影图像来恢复折射场。在这项工作中，我们介绍了一种使用基于坐标的神经网络对场景中潜在的连续折射场进行建模的方法。然后，我们使用射线三维空间曲率的显式建模来优化该网络的参数，通过综合分析方法重建折射场。通过在模拟中恢复折射场，并分析光源分布对恢复的影响，证明了我们方法的有效性。然后，我们在模拟暗物质映射问题上测试了我们的方法，在该问题中，我们恢复了真实模拟暗物质分布下的折射场。 et.al.|[2309.04437](http://arxiv.org/abs/2309.04437)|null|
|**2023-09-07**|**BluNF: Blueprint Neural Field**|神经辐射场（NeRF）彻底改变了场景新颖的视图合成，提供了视觉逼真、精确和稳健的隐式重建。虽然最近的方法允许NeRF编辑，例如对象删除、3D形状修改或材料特性操纵，但在这种编辑之前的手动注释使该过程变得乏味。此外，传统的2D交互工具缺乏对3D空间的准确感知，阻碍了对场景的精确操作和编辑。在本文中，我们介绍了一种新的方法，称为蓝图神经场（BluNF），以解决这些编辑问题。BluNF提供了一个强大且用户友好的2D蓝图，实现了直观的场景编辑。通过利用隐式神经表示，BluNF使用先前的语义和深度信息构建场景的蓝图。生成的蓝图可以轻松编辑和操作NeRF表示。我们通过直观的点击和更改机制展示了BluNF的可编辑性，实现了3D操作，如遮罩、外观修改和对象移除。我们的方法对视觉内容创作做出了重大贡献，为该领域的进一步研究铺平了道路。 et.al.|[2309.03933](http://arxiv.org/abs/2309.03933)|null|
|**2023-09-07**|**SimNP: Learning Self-Similarity Priors Between Neural Points**|用于3D对象重建的现有神经场表示要么（1）利用对象级表示，但由于对全局潜在代码的限制而遭受低质量细节，要么（2）能够完美地重建观测，但未能利用对象级先验知识来推断未观察到的区域。我们提出了一种学习类别级自相似性的方法SimNP，它通过将神经点辐射场与类别级自类似性表示相连接，结合了两个世界的优点。我们的贡献是双重的。（1） 我们利用相干点云的概念设计了第一个类别级别的神经点表示。由此产生的神经点辐射场为局部支持的对象区域存储了高级别的细节。（2） 我们了解了如何以无约束和无监督的方式在神经点之间共享信息，这允许在重建过程中根据给定的观测值导出对象的未观察区域。我们表明，SimNP在重建对称的看不见物体区域方面优于以前的方法，超过了建立在类别级或像素对齐辐射场上的方法，同时提供了实例之间的语义对应 et.al.|[2309.03809](http://arxiv.org/abs/2309.03809)|null|
|**2023-09-06**|**CoNeS: Conditional neural fields with shift modulation for multi-sequence MRI translation**|多序列磁共振成像（MRI）在现代临床研究和深度学习研究中都有广泛的应用。然而，在临床实践中，由于患者的不同图像采集协议或造影剂禁忌症，经常会出现一个或多个MRI序列缺失的情况，这限制了在多序列数据上训练的深度学习模型的使用。一种很有前途的方法是利用生成模型来合成缺失的序列，这可以作为替代获取。解决这一问题的最先进方法是基于卷积神经网络（CNN），该网络通常存在频谱偏差，导致高频精细细节的重建较差。在本文中，我们提出了具有移位调制的条件神经场（CoNeS），这是一种以体素坐标为输入并学习用于多序列MRI平移的目标图像的表示的模型。所提出的模型使用多层感知器（MLP）代替CNN作为像素到像素映射的解码器。因此，每个目标图像被表示为神经场，该神经场通过利用学习的潜码的移位调制而被调节在源图像上。在BraTS 2018和前庭神经鞘瘤患者的内部临床数据集上进行的实验表明，所提出的方法在视觉和定量上都优于最先进的多序列MRI翻译方法。此外，我们进行了光谱分析，表明CoNeS能够克服传统CNN模型中常见的光谱偏差问题。为了进一步评估合成图像在临床下游任务中的使用，我们在推理时使用合成图像测试了分割网络。 et.al.|[2309.03320](http://arxiv.org/abs/2309.03320)|**[link](https://github.com/cyjdswx/cones)**|
|**2023-09-06**|**ResFields: Residual Neural Fields for Spatiotemporal Signals**|神经场是一类被训练来表示高频信号的神经网络，近年来由于其在复杂三维数据建模方面的出色性能，特别是通过单个多层感知器（MLP）的大神经符号距离（SDFs）或辐射场（NeRFs），而受到了极大的关注。然而，尽管用MLP表示信号的能力和简单性很强，但由于MLP的容量有限，这些方法在建模大而复杂的时间信号时仍然面临挑战。在本文中，我们提出了一种有效的方法来解决这一限制，将时间残差层纳入神经场，称为ResFields，这是一类专门设计用于有效表示复杂时间信号的新型网络。我们对ResFields的性质进行了全面的分析，并提出了一种矩阵分解技术来减少可训练参数的数量并增强泛化能力。重要的是，我们的公式与现有技术无缝集成，并在各种具有挑战性的任务中持续改进结果：2D视频近似、通过时间SDF的动态形状建模和动态NeRF重建。最后，我们通过展示ResFields在从轻量级捕捉系统的稀疏感官输入捕捉动态3D场景方面的有效性，展示了它的实用性。 et.al.|[2309.03160](http://arxiv.org/abs/2309.03160)|**[link](https://github.com/markomih/ResFields)**|
|**2023-09-01**|**GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields**|开发能够在非结构化现实世界环境中通过视觉观察执行各种操作任务的代理是机器人技术中的一个长期问题。为了实现这一目标，机器人需要对场景的3D结构和语义有全面的了解。在这项工作中，我们提出了 $\textbf｛GNFactor｝$，一种用于多任务机器人操作的视觉行为克隆代理，具有$\textbf｛G｝$通用$\textbf｛N｝$eural功能$\textbf｛F｝$字段。GNFactor联合优化了作为重建模块的可推广神经场（GNF）和作为决策模块的感知转换器，利用了共享的深度3D体素表示。为了在3D中结合语义，重建模块利用视觉语言基础模型（$\textit｛例如｝$ ，Stable Diffusion）将丰富的语义信息提取到深度3D体素中。我们在3个真实机器人任务中评估了GNFactor，并在10个RLBench任务中进行了详细的消融，演示次数有限。我们观察到GNFactor在可见和不可见任务中比当前最先进的方法有了实质性的改进，证明了GNFactor强大的泛化能力。我们的项目网站是https://yanjieze.com/GNFactor/。 et.al.|[2308.16891](http://arxiv.org/abs/2308.16891)|**[link](https://github.com/YanjieZe/GNFactor)**|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

