---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.10.23
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-20**|**ManifoldNeRF: View-dependent Image Feature Supervision for Few-shot Neural Radiance Fields**|随着神经辐射场（NeRF）的出现，新的视图合成最近取得了重大进展。DietNeRF是NeRF的扩展，旨在通过为没有输入图像的未知视点引入新的损失函数，仅从少数图像中实现这一任务。损失函数假设预先训练的特征提取器应该输出相同的特征，即使输入图像是在不同的视点捕获的，因为图像包含相同的对象。然而，尽管这种假设是理想的，但在现实中，众所周知，随着视点的不断变化，特征向量也在不断变化。因此，这种假设可能会损害训练。为了避免这种有害的训练，我们提出了ManifoldNeRF，这是一种使用来自相邻已知视点的插值特征来监督未知视点的特征向量的方法。由于该方法通过插值特征为每个未知视点提供了适当的监督，因此体积表示比DietNeRF学习得更好。实验结果表明，在复杂场景下，该方法的性能优于其他方法。我们还对一组视点中的几个视点子集进行了实验，并为真实环境确定了一组有效的视点。这为实际应用程序提供了视点模式的基本策略。代码可在https://github.com/haganelego/ManifoldNeRF_BMVC2023 et.al.|[2310.13670](http://arxiv.org/abs/2310.13670)|null|
|**2023-10-19**|**Perceptual Assessment and Optimization of High Dynamic Range Image Rendering**|高动态范围（HDR）成像由于能够忠实地再现自然场景中的亮度水平而越来越受欢迎。因此，HDR图像质量评估（IQA）是至关重要的，但已被肤浅地处理。大多数现有的IQA模型都是针对低动态范围（LDR）图像开发和校准的，低动态范围图像已被证明与人类对HDR图像质量的感知相关性较差。在这项工作中，我们通过转移LDR IQA的最新进展，提出了一系列HDR IQA模型。我们方法的关键步骤是指定一个简单的反向显示模型，该模型将HDR图像分解为一组具有不同曝光的LDR图像，这些图像将由现有的LDR质量模型进行评估。然后，在简单的良好曝光度测量的帮助下，将每个曝光的局部质量分数聚合为每个曝光的全局质量分数，该全局质量分数将在曝光之间进一步加权，以获得总体质量分数。在评估LDR图像时，所提出的HDR质量模型优雅地降低到具有相同性能的原始LDR模型。在四个人类评级的HDR图像数据集上的实验表明，我们的HDR质量模型始终优于现有的IQA方法，包括HDR-VDP系列。此外，我们还展示了它们在HDR新视图合成的感知优化方面的优势。 et.al.|[2310.12877](http://arxiv.org/abs/2310.12877)|null|
|**2023-10-18**|**4K4D: Real-Time 4D View Synthesis at 4K Resolution**|本文以4K分辨率下动态三维场景的高保真度和实时视图合成为目标。最近，一些动态视图合成方法已经显示出令人印象深刻的渲染质量。然而，在渲染高分辨率图像时，它们的速度仍然有限。为了克服这个问题，我们提出了4K4D，这是一种支持硬件光栅化并实现前所未有的渲染速度的4D点云表示。我们的表示建立在4D特征网格上，这样点就可以自然正则化，并且可以进行稳健优化。此外，我们设计了一种新颖的混合外观模型，在保持效率的同时显著提高了渲染质量。此外，我们开发了一种可微分深度剥离算法，以有效地从RGB视频中学习所提出的模型。实验表明，使用RTX 4090 GPU，我们的表示可以在1080p分辨率的DNA渲染数据集上以超过400 FPS的速度渲染，在4K分辨率的ENeRF Outdoor数据集上可以以80 FPS的速度绘制，这比以前的方法快30倍，并达到了最先进的渲染质量。我们的项目页面可在https://zju3dv.github.io/4k4d/. et.al.|[2310.11448](http://arxiv.org/abs/2310.11448)|null|
|**2023-10-16**|**TOSS:High-quality Text-guided Novel View Synthesis from a Single Image**|在本文中，我们提出了TOSS，它将文本引入到仅从单个RGB图像进行新颖视图合成（NVS）的任务中。虽然Zero-1-3展示了令人印象深刻的零样本开集NVS功能，但它将NVS视为一个纯粹的图像到图像的转换问题。这种方法受到了单视图NVS具有挑战性的欠约束性质的影响：该过程缺乏明确的用户控制手段，并且经常导致令人难以置信的NVS生成。为了解决这一限制，TOSS使用文本作为高级语义信息来约束NVS解决方案空间。TOSS微调在大规模文本图像对上预先训练的文本到图像稳定扩散，并引入专门针对图像和相机姿势调节定制的模块，以及姿势正确性和精细细节保存的专门训练。进行了全面的实验，结果表明，我们提出的TOSS优于Zero-1-to-3，具有更合理、可控和多视角一致的NVS结果。我们通过全面的消融进一步支持这些结果，强调了引入的语义指导和架构设计的有效性和潜力。 et.al.|[2310.10644](http://arxiv.org/abs/2310.10644)|null|
|**2023-10-16**|**GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers**|由于变换器对输入标记的排列是等变的，因此对标记的位置信息进行编码对于许多任务是必要的。然而，由于现有的位置编码方案最初是为NLP任务设计的，因此它们对视觉任务的适用性是值得怀疑的，视觉任务通常在其数据中表现出不同的结构特性。我们认为，现有的位置编码方案对于3D视觉任务来说是次优的，因为它们不尊重其潜在的3D几何结构。基于这一假设，我们提出了一种几何感知注意力机制，该机制将令牌的几何结构编码为由查询和键值对之间的几何关系确定的相对变换。通过在稀疏宽基线多视图设置中对多个新视图合成（NVS）数据集进行评估，我们表明，我们的注意力（称为几何变换注意力（GTA））提高了最先进的基于变换器的NVS模型的学习效率和性能，而无需任何额外的学习参数和较小的计算开销。 et.al.|[2310.10375](http://arxiv.org/abs/2310.10375)|**[link](https://github.com/autonomousvision/gta)**|
|**2023-10-15**|**CBARF: Cascaded Bundle-Adjusting Neural Radiance Fields from Imperfect Camera Poses**|现有的体积神经渲染技术，如神经辐射场（NeRF），在输入图像的相机姿态不完美时，在合成高质量的新视图方面面临限制。为了解决这个问题，我们提出了一种新的3D重建框架，该框架能够同时优化相机姿态，称为CBARF（级联束调整NeRF）。简而言之，我们的框架以粗略到精细的方式优化相机姿势，然后根据校正后的姿势重建场景。观察到，相机姿态的初始化对束调整（BA）的性能有显著影响。因此，我们以不同的尺度级联多个BA模块，以逐步改善相机姿势。同时，我们制定了邻居替换策略，以进一步优化BA在每个阶段的结果。在这一步中，我们引入了一种新的标准来有效地识别估计不足的相机姿势。然后我们将它们替换为相邻相机的姿势，从而进一步消除相机姿势不准确的影响。一旦相机姿态得到优化，我们就使用密度体素网格在新视图中生成高质量的3D重建场景和图像。实验结果表明，我们的CBARF模型在姿态优化和新视图合成方面都达到了最先进的性能，尤其是在存在大的相机姿态噪声的情况下。 et.al.|[2310.09776](http://arxiv.org/abs/2310.09776)|null|
|**2023-10-12**|**Is Generalized Dynamic Novel View Synthesis from Monocular Videos Possible Today?**|从新颖的视角渲染单目视频中观察到的场景是一个具有挑战性的问题。对于静态场景，社区研究了在每个测试场景上进行优化的特定场景优化技术，以及只在测试场景上运行深网前向传递的通用技术。相反，对于动态场景，存在特定场景的优化技术，但据我们所知，目前还没有从给定的单目视频中合成动态新视图的通用方法。为了回答从单目视频中进行广义动态新视图合成在今天是否可行，我们基于现有技术建立了一个分析框架，并致力于广义方法。我们发现，在没有特定场景外观优化的情况下，伪广义过程是可能的，但需要几何和时间一致的深度估计。尽管没有特定场景的外观优化，但伪广义方法改进了一些特定场景的方法。 et.al.|[2310.08587](http://arxiv.org/abs/2310.08587)|null|
|**2023-10-12**|**Im4D: High-Fidelity and Real-Time Novel View Synthesis for Dynamic Scenes**|本文旨在解决多视图视频动态视图合成的挑战。关键的观察结果是，虽然以前的基于网格的方法提供了一致的渲染，但它们在捕捉复杂动态场景的外观细节方面做不到，在这个领域中，基于多视图图像的渲染方法表现出相反的特性。为了将两个世界中最好的结合起来，我们引入了Im4D，这是一种混合场景表示，由基于网格的几何表示和基于多视图图像的外观表示组成。具体而言，动态几何被编码为由时空特征平面和小型MLP网络组成的4D密度函数，该函数对场景结构进行全局建模，并促进渲染一致性。我们通过原始多视图视频和网络来表示场景外观，该网络学习从图像特征预测3D点的颜色，而不是完全用网络来记忆详细的外观，从而自然地使网络的学习变得更容易。我们的方法在五个动态视图合成数据集上进行了评估，包括DyNeRF、ZJU MoCap、NHR、DNA Rendering和ENeRF Outdoor数据集。结果表明，Im4D在渲染质量方面表现出最先进的性能，并且可以有效地进行训练，同时在单个RTX 3090 GPU上以79.8 FPS的速度实现512x512图像的实时渲染。 et.al.|[2310.08585](http://arxiv.org/abs/2310.08585)|null|
|**2023-10-12**|**SingleInsert: Inserting New Concepts from a Single Image into Text-to-Image Models for Flexible Editing**|文本到图像（T2I）模型的最新进展使得能够通过灵活的文本控制生成高质量的图像。为了利用现成的T2I模型中丰富的视觉先验，一系列方法试图将图像反转为与T2I模型的语义空间对齐的适当嵌入。然而，这些图像到文本（I2T）反转方法通常需要包含相同概念的多个源图像，或者难以解决编辑灵活性和视觉逼真度之间的不平衡问题。在这项工作中，我们指出在学习预期概念时，关键问题在于前景-背景纠缠，并提出了一种简单有效的单图像I2T反演基线，称为SingleInsert。SingleInsert采用两阶段方案。在第一阶段，我们调节学习的嵌入，使其集中在前景区域，而不与无关背景相关联。在第二阶段，我们对T2I模型进行了微调，以获得更好的视觉相似性，并设计了语义损失来防止语言漂移问题。利用所提出的技术，SingleInsert在单概念生成方面表现出色，视觉逼真度高，同时允许灵活编辑。此外，SingleInsert可以在不需要联合训练的情况下进行单图像新视图合成和多概念合成。为了便于评估，我们设计了一个编辑提示列表，并引入了一个名为编辑成功率（ESR）的指标来定量评估编辑灵活性。我们的项目页面是：https://jarrentwu1031.github.io/SingleInsert-web/ et.al.|[2310.08094](http://arxiv.org/abs/2310.08094)|null|
|**2023-10-12**|**Consistent123: Improve Consistency for One Image to 3D Object Synthesis**|大图像扩散模型能够实现具有高质量和优异的零样本能力的新颖视图合成。然而，这种基于图像到图像转换的模型不能保证视图的一致性，这限制了诸如3D重建和图像到3D生成之类的下游任务的性能。为了增强一致性，我们提出了Consistent123，通过结合额外的跨视图注意力层和共享的自注意机制，同时合成新的视图。所提出的注意力机制改善了所有合成视图之间的交互，以及条件视图和新视图之间的一致性。在采样阶段，这种架构支持在以固定长度进行训练的同时同时生成任意数量的视图。我们还引入了一种渐进的无分类器引导策略，以实现合成对象视图的纹理和几何之间的权衡。定性和定量实验表明，Consistent123在视图一致性方面大大优于基线。此外，我们展示了Consistent123在不同下游任务上的显著改进，显示了其在3D生成领域的巨大潜力。项目页面位于consistent-123.github.io。 et.al.|[2310.08092](http://arxiv.org/abs/2310.08092)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-20**|**Longer-range Contextualized Masked Autoencoder**|掩模图像建模（MIM）已成为一种很有前途的自监督学习（SSL）策略。MIM预训练通过随机掩蔽一些输入像素并从剩余的像素重建掩蔽的像素，有助于使用编码器-解码器框架来学习强大的表示。然而，由于编码器是用部分像素训练的，MIM预训练可能存在理解长程依赖性的能力低的问题。这种限制可能会阻碍其完全理解多个范围依赖性的能力，导致注意力图中突出显示的区域狭窄，从而可能导致准确性下降。为了减轻这种限制，我们提出了一个自监督学习框架，称为长距离上下文化屏蔽自动编码器（LC-MAE）。LC-MAE有效地利用了对视觉表示的全局上下文理解，同时减少了输入的空间冗余。我们的方法引导编码器从多个视图中的整个像素学习，同时也从稀疏像素学习局部表示。因此，LC-MAE学习了更多的判别表示，导致性能提高，在ImageNet-1K上使用ViT-B以0.6%p的增益实现84.2%的前1级精度。我们将成功归因于增强的预训练方法，奇异值谱和注意力分析证明了这一点。最后，LC-MAE在下游语义分割和细粒度视觉分类任务中实现了显著的性能提升；以及不同的稳健评估指标。我们的代码将公开。 et.al.|[2310.13593](http://arxiv.org/abs/2310.13593)|null|
|**2023-10-20**|**Single-view 3D reconstruction via inverse procedural modeling**|我们提出了一种通过逆过程建模进行三维重建的方法，并研究了该方法的两种变体。第一种选择是使用遗传算法对输入参数进行拟合。我们展示了我们在树模型（复杂对象）上的工作结果，其中重建是大多数现有方法无法处理的。第二种选择允许我们通过在模因算法、可微分渲染和可微分过程生成器中使用梯度来显著提高精度。在我们的工作中，我们看到了两个主要贡献。首先，我们提出了一种连接可微绘制和逆过程建模的方法。当有少量输入图像可用时（即使是单个图像），这为我们提供了一个比现有方法更准确地重建3D模型的机会。其次，我们将可微和不可微的过程生成器连接在一个框架中，这使我们能够将逆过程建模应用于相当复杂的生成器：当梯度可用时，重建是精确的，当梯度不可用时，重构是近似的，但总是高质量的，没有视觉伪影。 et.al.|[2310.13373](http://arxiv.org/abs/2310.13373)|null|
|**2023-10-20**|**UE4-NeRF:Neural Radiance Field for Real-Time Rendering of Large-Scale Scene**|神经辐射场（NeRF）是一种新的隐式三维重建方法，显示出巨大的潜力，越来越受到人们的关注。它能够仅从一组照片中重建3D场景。然而，它的实时渲染能力，特别是对于大规模场景的交互式实时渲染，仍然存在很大的局限性。为了应对这些挑战，在本文中，我们提出了一种名为UE4-NeRF的新型神经渲染系统，专门为大规模场景的实时渲染而设计。我们将每个大场景划分为不同的子NeRF。为了表示分割的独立场景，我们通过在场景内构建多个规则八面体来初始化多边形网格，并在训练过程中不断优化多边形面的顶点。从细节层次（LOD）技术中获得灵感，我们针对不同的观察层次训练了不同细节层次的网格。我们的方法与虚幻引擎4（UE4）中的光栅化流水线相结合，以高达43 FPS的帧速率实现了4K分辨率的大规模场景的实时渲染。UE4内的渲染也便于在后续阶段中进行场景编辑。此外，通过实验，我们已经证明我们的方法达到了与最先进的方法相当的渲染质量。项目页面：https://jamchaos.github.io/UE4-NeRF/. et.al.|[2310.13263](http://arxiv.org/abs/2310.13263)|null|
|**2023-10-19**|**Real space iterative reconstruction for vector tomography (RESIRE-V)**|层析成像对物理、生物和医学产生了重要影响。到目前为止，大多数断层摄影应用都集中在三维标量重建上。然而，在一些关键应用中，需要矢量层析成像来重建三维矢量场，例如电场和磁场。多年来，已经开发了几种矢量层析成像方法。在这里，我们介绍了用于矢量层析成像的REal空间迭代重建的数学基础和算法实现，称为RESIRE-V。RESIRE-V使用多个倾斜系列的投影，并在投影和3D重建之间迭代。每次迭代包括使用Radon变换的前向步骤和使用其转置的后向步骤，然后通过梯度下降更新对象。结合3D支撑约束，该算法迭代地最小化误差度量，该误差度量定义为测量投影和计算投影之间的差。该算法还可以用于细化倾斜角度并进一步改进3D重建。为了验证RESIRE-V，我们首先将其应用于3D磁化矢量场的模拟数据集，该数据集由两个正交倾斜序列组成，每个倾斜序列都有一个缺失的楔块。我们的定量分析表明，重建的磁化矢量场的三个分量与地面实况相一致。然后，我们使用RESIRE-V重建了由三个倾斜序列组成的铁磁超晶格的三维磁化矢量场。我们的三维矢量重建揭示了具有正电荷和负电荷的拓扑磁缺陷的存在。我们期望RESIRE-V可以作为一种通用的矢量层析成像方法被纳入不同的成像模式中。 et.al.|[2310.12513](http://arxiv.org/abs/2310.12513)|**[link](https://github.com/minhpham0309/resire-v)**|
|**2023-10-19**|**MTS-LOF: Medical Time-Series Representation Learning via Occlusion-Invariant Features**|医疗时间序列数据在医疗保健中不可或缺，为疾病诊断、治疗计划和患者管理提供重要见解。在先进传感器技术的推动下，数据复杂性呈指数级增长，这给数据标签带来了挑战。自我监督学习（SSL）已成为应对这些挑战的一种变革性方法，消除了对大量人工注释的需求。在本研究中，我们介绍了一种新的医学时间序列表示学习框架，称为MTS-LOF。MTS-LOF利用了对比学习和掩蔽自动编码器（MAE）方法的优势，为医学时间序列数据的表示学习提供了一种独特的方法。通过结合这些技术，MTS-LOF通过提供更复杂、上下文丰富的表示，增强了医疗保健应用的潜力。此外，MTS-LOF采用多掩蔽策略来促进遮挡不变特征学习。这种方法允许模型通过屏蔽部分数据来创建数据的多个视图。通过最小化这些屏蔽补丁和完全可见补丁的表示之间的差异，MTS-LOF学会了在医学时间序列数据集中捕获丰富的上下文信息。在不同的医学时间序列数据集上进行的实验结果证明了MTS-LOF优于其他方法。这些发现有望通过改进表征学习来显著增强医疗保健应用。此外，我们的工作深入研究了联合嵌入SSL和MAE技术的集成，揭示了医疗保健数据中时间和结构依赖性之间的复杂相互作用。这种理解至关重要，因为它使我们能够掌握医疗保健数据分析的复杂性。 et.al.|[2310.12451](http://arxiv.org/abs/2310.12451)|null|
|**2023-10-18**|**ShapeGraFormer: GraFormer-Based Network for Hand-Object Reconstruction from a Single Depth Map**|手对象操作的三维重建对于模拟人类动作是重要的。大多数处理具有挑战性的对象操作场景的方法都专注于孤立的手部重建，忽略了由于对象接触而产生的物理和运动学约束。一些方法通过联合重建3D手-对象交互来产生更真实的结果。然而，它们专注于粗略的姿态估计或依赖于已知的手和物体形状。我们提出了第一种从单个深度图重建逼真的3D手对象形状和姿势的方法。与之前的工作不同，我们基于体素的重建网络回归手和物体的顶点坐标，并重建更真实的交互。我们的管道还预测了体素化的手对象形状，具有与输入体素化深度的一对一映射。然后，我们利用最近的GraFormer网络和位置嵌入，从模板网格中重建形状，从而利用手和物体形状的图形特性。此外，我们还展示了添加另一个GraFormer组件的影响，该组件基于手与物体的交互来细化重建的形状，并能够重建更准确的物体形状。我们对HO-3D和DexYCB数据集进行了广泛的评估，并表明我们的方法在手部重建方面优于现有方法，并为物体产生了合理的重建 et.al.|[2310.11811](http://arxiv.org/abs/2310.11811)|null|
|**2023-10-17**|**Learning Neural Implicit through Volume Rendering with Attentive Depth Fusion Priors**|学习神经隐式表示在多视图图像的三维重建中取得了显著的性能。当前的方法使用体积渲染将隐式表示渲染为RGB或深度图像，这些图像由多视图地面实况监督。然而，每次渲染视图都会遇到孔的深度不完整以及深度监督对遮挡结构的不了解，这严重影响了通过体绘制进行几何推断的准确性。为了解决这个问题，我们建议通过具有注意深度融合先验的体绘制，从多视图RGBD图像中学习神经隐式表示。我们的先验允许神经网络从从可用于渲染的所有深度图像中融合的截断有符号距离函数（TSDF）中感知粗略的3D结构。TSDF能够访问一个深度图像上孔的缺失深度以及当前视图中不可见的遮挡部分。通过引入一种新的注意力机制，我们允许神经网络直接使用具有推断占用率的深度融合先验作为学习的内隐函数。在同步定位和映射（SLAM）的背景下，我们的注意力机制与表示整个场景的一次性融合TSDF或表示部分场景的增量融合TSDF一起工作。我们对广泛使用的基准测试（包括合成扫描和真实世界扫描）的评估表明，我们优于最新的神经隐式方法。项目页面：https://machineperceptionlab.github.io/Attentive_DF_Prior/ et.al.|[2310.11598](http://arxiv.org/abs/2310.11598)|null|
|**2023-10-17**|**Field Robot for High-throughput and High-resolution 3D Plant Phenotyping**|由于需要养活不断增长的世界人口，作物生产效率至关重要。为了支持育种和田间管理，需要测量植物表型的各种特征——手动进行时这是一个耗时的过程。我们提供了一个配备了多个激光和相机传感器的机器人平台，用于高通量、高分辨率的现场植物扫描。我们通过3D重建创建了植物的数字双胞胎。这允许估计表型性状，如叶面积、叶角度和株高。我们在真实的场地上验证了我们的系统，在那里我们重建了甜菜、大豆和玉米的精确点云和网格。 et.al.|[2310.11516](http://arxiv.org/abs/2310.11516)|null|
|**2023-10-17**|**Key Point-based Orientation Estimation of Strawberries for Robotic Fruit Picking**|选择性机器人收割是一种很有前途的技术解决方案，可以解决影响世界许多地区现代农业的劳动力短缺问题。为了实现准确高效的采摘过程，机器人收割机需要水果的精确位置和方向，以有效规划末端执行器的轨迹。当前用于估计水果方位的方法要么使用通常需要从多个视图进行配准的完整3D信息，要么依赖于需要难以获得参考方位的手动注释的完全监督学习技术。在本文中，我们介绍了一种新的基于关键点的水果方位估计方法，该方法可以直接从2D图像中预测3D方位。所提出的技术可以在没有全3D方向注释的情况下工作，但也可以利用这种信息来提高精度。我们在两个独立的草莓图像数据集上评估了我们的工作，这两个数据集是从真实世界的数据收集场景中获得的。我们提出的方法实现了最先进的性能，平均误差低至 $8^{\cir}$，与~\cite{wagner2021efficiency}中提出的先前工作相比，预测改进了$\sim30\%$。此外，我们的方法适用于快速推理时间为$\sim30$ ms的实时机器人应用。 et.al.|[2310.11333](http://arxiv.org/abs/2310.11333)|null|
|**2023-10-17**|**Learning Comprehensive Representations with Richer Self for Text-to-Image Person Re-Identification**|文本到图像的人重新识别（TIReID）基于查询文本检索具有相同身份的行人图像。然而，现有的TIReID方法通常将其视为一对一的图像-文本匹配问题，只关注视图中图像-文本对之间的关系。没有考虑在相同身份下跨视图的图像-文本对之间的多对多匹配，这是现有方法性能较差的主要原因之一。为此，我们提出了一个简单而有效的框架，称为LCR $^2$S，通过从一个新颖的角度学习两种模态的综合表示，对同一身份的多对多对应关系进行建模。我们利用同一身份下的其他图像（文本）为每个图像（文字）构建了一个支持集，并设计了一个多头注意力融合模块来融合图像（正文）及其支持集。由此产生的丰富的图像和文本特征融合了来自多个视图的信息，这些视图被对齐以训练具有多对多对应关系的“更丰富”的TIReID模型。由于支持集在推理过程中不可用，我们建议将“更丰富”的模型学习到的知识提取到一个轻量级模型中，以单个图像/文本作为输入进行推理。该轻量级模型专注于多视图信息的语义关联和推理，可以在只有单个视图输入的情况下生成包含多视图信息在内的综合表示，以在推理过程中进行准确的文本到图像检索。特别是，我们利用“更丰富”模型的模态内特征和模态间语义关系来监督轻量级模型继承其强大的能力。大量实验证明了LCR$^2$ S的有效性，它还在三个流行的TIReID数据集上实现了最先进的性能。 et.al.|[2310.11210](http://arxiv.org/abs/2310.11210)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-20**|**Achieving Single-Electron Sensitivity at Enhanced Speed in Fully-Depleted CCDs with Double-Gate MOSFETs**|我们介绍了一种基于双栅极MOSFET的全耗尽厚p沟道CCD的新型输出放大器。电荷放大器是专门设计和操作的n型MOSFET，用于耦合具有高电荷传输效率的完全耗尽CCD。CCD和MOSFET沟道之间的结耦合实现了高灵敏度，在一个像素电荷测量中显示了亚电子读出噪声。我们还展示了该设备的无损读出能力。通过对少量样本进行平均，可以在整个CCD像素阵列中实现每像素单电子和单光子计数。我们已经证明，在单采样和多采样模式下，完全耗尽的CCD读出比目前可用的浮动扩散和浮动栅极放大器具有更好的性能，其速度至少是浮动栅极放大器的六倍。 et.al.|[2310.13644](http://arxiv.org/abs/2310.13644)|null|
|**2023-10-20**|**Front propagation close to the onset of instability**|我们描述了在空间扩展系统中，当齐次平衡失去稳定性时产生的时空动力学。更准确地说，我们考虑反应扩散系统，只假设反应动力学在参数通过零时发生跨临界、鞍节点或超临界干叉分叉。我们构造了旅行锋解，该解描述了附近稳定状态对现在不稳定状态的入侵。我们证明了这些前沿在分岔点附近是边缘谱稳定的，这与前沿传播到不稳定状态的理论的最新进展一起，证明了这些锋面控制着不稳定状态局部扰动的动力学。我们的证明是基于函数分析工具来研究前沿的存在性和特征值问题的，这些前沿在自然重新缩放后变得奇异摄动。 et.al.|[2310.13602](http://arxiv.org/abs/2310.13602)|null|
|**2023-10-20**|**ScaleLong: Towards More Stable Training of Diffusion Model via Scaling Network Long Skip Connection**|在扩散模型中，UNet是最受欢迎的网络骨干，因为其连接远程网络块的长跳连接（LSCs）可以聚合远程信息并缓解消失梯度。不幸的是，UNet在扩散模型中经常受到不稳定训练的影响，这可以通过缩小其LSC系数来缓解。然而，对UNet在扩散模型中的不稳定性以及LSC标度的性能改进的理论理解仍然缺乏。为了解决这个问题，我们从理论上证明了UNet中LSCs的系数对UNet的前向和后向传播的稳定性和鲁棒性有很大影响。具体来说，UNet在任何层的隐藏特征和梯度都可以振荡，并且它们的振荡范围实际上很大，这解释了UNet训练的不稳定性。此外，UNet还可证明对扰动输入敏感，并预测远离期望输出的输出，从而产生振荡损耗和振荡梯度。此外，我们还观察到UNet的LSC系数缩放在隐藏特征和梯度的稳定性以及鲁棒性方面的理论优势。最后，受我们理论的启发，我们提出了一个有效的系数缩放框架ScaleLong，它对UNet中LSC的系数进行了缩放，更好地提高了UNet的训练稳定性。在四个著名数据集上的实验结果表明，我们的方法优于稳定训练，并在具有UNet或UViT骨干的不同扩散模型上产生约1.5倍的训练加速度。代码：https://github.com/sail-sg/ScaleLong et.al.|[2310.13545](http://arxiv.org/abs/2310.13545)|**[link](https://github.com/sail-sg/scalelong)**|
|**2023-10-20**|**Shedding Light on Low Surface Brightness Galaxies in Dark Energy Survey with Transformers**|低表面亮度星系（LSBG）被定义为比夜空更暗的星系，在理解星系演化和宇宙学模型方面发挥着至关重要的作用。鲁宾天文台遗产时空巡天（LSST）和欧几里得等即将到来的大规模巡天预计将观测数十亿个天文物体。在这种情况下，使用半自动方法来识别LSBG将是一个极具挑战性和耗时的过程，需要自动化或基于机器学习的方法来克服这一挑战。我们研究了变压器模型在从暗能量调查（DES）数据发布1的数据中分离LSBG和伪影中的使用。然后，使用转换器模型，我们从DES中搜索先前搜索可能遗漏的新LSBG。研究了新发现的LSBG的性质，并分析了DES中总LSBG样品的性质。我们在DES中发现了4083个新的LSBG，在DES中已知的LSBG基础上又增加了 $\sim17\%$。这也将DES中LSBG的数量密度增加到5.5 deg$^{-2}$ 。我们使用角度两点自相关函数对DES中的LSBG进行了聚类分析，发现LSBG比其高表面亮度对应物更强烈地聚类。我们将1310个LSBG与星系团联系起来，并确定其中317个是超扩散星系（UDG）。我们发现，与中心的LSBG相比，这些集群LSBG在集群边缘变得越来越蓝、越来越大。Transformer模型作为分析天文数据的最先进算法，有可能与卷积神经网络不相上下。 et.al.|[2310.13543](http://arxiv.org/abs/2310.13543)|null|
|**2023-10-20**|**Masses, Revised Radii, and a Third Planet Candidate in the "Inverted" Planetary System Around TOI-1266**|围绕M矮星运行的近距离行星的数量是由热驱动逃逸形成的，还是行星形成过程的直接结果？最近的一些实证结果有力地表明了后者。然而，TOI-1266行星系统的独特结构对行星形成和大气逃逸的模型提出了挑战，因为它似乎是大型次海王星的“倒置”结构（ $P_b=10.9$天，$R_{P，b}=2.62\pm 0.11\，\mathrm{R}_｛oplus｝$），其轨道位于系统较小行星的轨道内部（$P_c=18.8$天，$R_｛P，c｝=2.13\pm 0.12\，\mathrm{R}_｛\oplus｝$）。在这里，我们提出了基于新的TESS和扩散器辅助的地面凌日观测的修正行星半径，并使用HARPS-N的145个径向速度（RV）测量值（$M_｛p，b｝=4.23\pm 0.69\，\mathrm{M}_｛\oplus｝，M_｛p，c｝=2.88\pm 0.80\，\mathrm{M}_｛\oplus｝$）。我们的RV分析还揭示了第三颗候选行星（$P_d=32.3$days，$M_｛P，d｝\sin｛i｝=4.59^｛+0.96｝_｛-0.94｝\，\mathrm{M}_｛\oplus｝$），如果是真的，它将形成一个5:3周期比的链，尽管我们表明该系统可能不处于平均运动共振中。我们的结果表明，TOI-1266 b和c是M矮星周围已知的密度最低的亚海王星，可能表现出明显的气态陆地（$X_｛\mathrm｛env｝，b｝=5.5\pm 0.7$%）和富水世界（WMF$_c=59\pm 14$ %）的整体组成，这得到了流体动力学逃逸模型的支持。如果凌日行星的不同体积成分通过大气特征得到证实，那么该系统的独特结构将代表亚海王星形成模型的一个有趣的测试案例，例如在卵石陷阱中由内而外的行星形成。 et.al.|[2310.13496](http://arxiv.org/abs/2310.13496)|null|
|**2023-10-20**|**Well-posedness of diffusion-aggregation equations with bounded kernels and their mean-field approximations**|利用紧致收敛论和Moser迭代，在有界相互作用力核的整个空间上建立了由相互作用粒子系统产生的扩散-聚集方程的适定性和正则性。此外，我们证明了近似相互作用粒子系统和近似McKean Vlasov SDE之间具有任意代数率的概率的定量估计，这意味着相互作用粒子系的混沌传播。 et.al.|[2310.13463](http://arxiv.org/abs/2310.13463)|null|
|**2023-10-20**|**Malliavin differentiability of McKean-Vlasov SDEs with locally Lipschitz coefficients**|在这个小注释中，我们建立了具有漂移的McKean Vlasov随机微分方程（MV SDE）的Malliavin可微性，漂移满足局部Lipschitz假设和单侧Lipschitz-假设，并且假设扩散系数在其变量中是一致的Lipschiz。作为第二个贡献，我们研究了Malliavin可微性如何转移到与McKean Vlasov方程相关的相互作用粒子系统，再转移到它的极限方程。这一最终结果需要系数的空间可微性和测度可微性，并且由于对弱相互作用粒子系统的Malliavin导数的研究在文献中似乎是新颖的，因此它同时也是独立感兴趣的独立结果。 et.al.|[2310.13400](http://arxiv.org/abs/2310.13400)|null|
|**2023-10-20**|**Tetraquark bound states in constituent quark models: benchmark test calculations**|我们使用三种不同的少体方法研究了“真正的”四夸克束缚态：高斯展开法（GEM）、共振群法（RGM）和扩散蒙特卡罗（DMC）。所谓“真正的”四夸克态，我们指的是那些不涉及通过 $n\bar｛n｝$的产生和湮灭与传统介子混合的态，其中$n=u，d$。我们的计算是用两种类型的夸克模型进行的：以单胶子交换相互作用和约束相互作用为特征的纯组分夸克模型，以及以额外的单玻色子交换相互作用为补充的手性组分夸克模式。这项研究代表了对各种少体方法和夸克模型的全面基准测试。我们的发现揭示了GEM在四夸克束缚态方面优于目前的RGM和DMC方法。此外，我们观察到手性夸克模型有高估结合能的趋势。我们系统地探索了$J^P=0^+，1^+，2^+$的全重、三重、双重和单重四夸克态，总共包含150多个态。我们成功地识别了几个束缚态，包括$[cc\bar｛n｝\bar{n｝]_｛J^｛P｝=1^｛+｝｝^｛I=0｝$，$[bb\bar｛n｝\par｛n｝]_{J^{P｝=1 ^｛+｝｝^｛I=0｝$＝0^｛+｝、1^｛+｝｝^｛I=0｝$、$[cs\bar｛n｝\bar｛n}]_｛J^｛P｝＝0^｝｛I=0｝$和$ [bb\bar｛。 et.al.|[2310.13354](http://arxiv.org/abs/2310.13354)|null|
|**2023-10-20**|**Heat equation from a deterministic dynamics**|对于满足牛顿方程的纯确定性微观动力学，我们导出了在扩散时空标度下热能的热方程，该方程受到类似磁场的外部混沌力的扰动。 et.al.|[2310.13338](http://arxiv.org/abs/2310.13338)|null|
|**2023-10-20**|**A Critical Insight into Pretransitional Behavior and Dielectric Tunability of Relaxor Ceramics**|模型讨论的重点是弛豫陶瓷的独特性质与临界现象物理学和玻璃化转变物理学的基础之间的联系。它表明了单轴性对于在顺电铁电跃迁附近出现平均场特征的意义。相变前的波动，增加到晶粒尺寸，并导致晶粒间、随机、局部电场，被认为是弛豫陶瓷特性的原因。它们的影响产生了与弱不连续局部相变相关的伪旋节行为。新出现的模型重新定义了Burns温度和极性纳米区域PNR的含义。它相干地解释了介电常数随近顺电铁电跃迁的扩散最大值、甚至对中等电场的灵敏度、可调谐性和玻璃态动力学的变化。这些考虑与弛豫陶瓷复介电常数研究的实验结果相矛盾，弛豫陶瓷覆盖了从顺电到深铁电相的200K范围。畸变敏感和基于导数的分析揭示了在顺电相和顺电铁电转变的环境中对指数标度模式的偏好。这可能表明格里菲斯相位行为与随机局部影响干扰的平均场临界有关。对实验结果的讨论由弛豫时间变化和耦合能量损失分析补充。这些研究还导致了可调谐温度变化与标度关系的描述。 et.al.|[2310.13326](http://arxiv.org/abs/2310.13326)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-12**|**S4C: Self-Supervised Semantic Scene Completion with Neural Fields**|三维语义场景理解是计算机视觉中的一个基本挑战。它使移动代理能够自主规划和导航任意环境。SSC将这一挑战形式化为从场景的稀疏观测中联合估计密集的几何结构和语义信息。当前的SSC方法通常基于聚合的激光雷达扫描在3D地面实况上进行训练。这一过程依赖于特殊的传感器和手工注释，这些传感器和注释成本高昂且规模不大。为了克服这个问题，我们的工作提出了第一种称为S4C的SSC自监督方法，该方法不依赖于3D地面实况数据。我们提出的方法可以从单个图像重建场景，并且只依赖于训练期间从现成的图像分割网络生成的视频和伪分割地面实况。与使用离散体素网格的现有方法不同，我们将场景表示为隐式语义场。该公式允许查询相机截锥体内的任何点的占用率和语义类。我们的架构是通过基于渲染的自监督损失进行训练的。尽管如此，我们的方法实现了接近于完全监督的最先进方法的性能。此外，我们的方法表现出强大的泛化能力，可以为遥远的视点合成准确的分割图。 et.al.|[2310.07522](http://arxiv.org/abs/2310.07522)|null|
|**2023-10-07**|**HI-SLAM: Monocular Real-time Dense Mapping with Hybrid Implicit Fields**|在这封信中，我们提出了一个基于神经场的实时单目映射框架，用于精确和密集的同时定位和映射（SLAM）。最近的神经映射框架显示出有希望的结果，但依赖于RGB-D或姿势输入，或者无法实时运行。为了解决这些局限性，我们的方法将密集SLAM与神经隐式场相结合。具体来说，我们的密集SLAM方法运行并行跟踪和全局优化，而基于神经场的映射是基于最新的SLAM估计逐步构建的。为了有效地构造神经场，我们采用了多分辨率网格编码和符号距离函数（SDF）表示。这使我们能够始终保持地图的最新状态，并通过循环关闭立即适应全球更新。为了全局一致性，我们提出了一种有效的基于Sim（3）的姿态图束调整（PGBA）方法来运行在线闭环并减轻姿态和尺度漂移。为了进一步提高深度精度，我们结合了学习的单目深度先验。我们提出了一种新的深度和尺度联合调整（JDSA）模块来解决深度先验中固有的尺度模糊性。对合成和真实世界数据集的广泛评估验证了我们的方法在准确性和地图完整性方面优于现有方法，同时保持了实时性能。 et.al.|[2310.04787](http://arxiv.org/abs/2310.04787)|null|
|**2023-10-05**|**Variational Barycentric Coordinates**|我们提出了一种变分技术来优化广义重心坐标，与现有模型相比，该技术提供了额外的控制。先前的工作使用网格或闭式公式表示重心坐标，在实践中限制了目标函数的选择。相反，我们使用神经场直接参数化连续函数，该函数将多面体内部的任何坐标映射到其重心坐标。这个公式是通过我们对重心坐标的理论表征实现的，这使我们能够构建将有效坐标的整个函数类参数化的神经场。我们使用各种目标函数展示了我们模型的灵活性，包括多重光滑性和变形感知能量；作为补充，我们还提出了数学上合理的方法来测量和最小化目标，如不连续神经场的总变化。我们提供了一个实用的加速策略，对我们的算法进行了彻底的验证，并展示了几个应用。 et.al.|[2310.03861](http://arxiv.org/abs/2310.03861)|null|
|**2023-10-05**|**High-Degrees-of-Freedom Dynamic Neural Fields for Robot Self-Modeling and Motion Planning**|机器人自模型是机器人物理形态的任务不可知表示，在没有经典几何运动学模型的情况下，可用于运动规划任务。特别是，当后者难以设计或机器人的运动学发生意外变化时，人类自由的自我建模是真正自主智能体的必要特征。在这项工作中，我们利用神经场使机器人能够将其运动学自建模为仅从带有相机姿势和配置的2D图像中学习的神经隐式查询模型。这使得比依赖于深度图像或几何知识的现有方法具有更大的适用性。为此，除了课程数据采样策略外，我们还提出了一种新的基于编码器的神经密度场架构，用于高自由度（DOF）条件下的动态对象中心场景。在7自由度机器人测试装置中，学习的自模型实现了机器人工作空间尺寸2%的倒角-L2距离。作为一个示例性的下游应用程序，我们展示了该模型在运动规划任务中的能力。 et.al.|[2310.03624](http://arxiv.org/abs/2310.03624)|null|
|**2023-10-02**|**Neural Processing of Tri-Plane Hybrid Neural Fields**|在用于存储和通信3D数据的神经场的吸引人的特性的驱动下，直接处理它们以解决分类和零件分割等任务的问题已经出现，并在最近的工作中进行了研究。早期的方法使用由在整个数据集上训练的共享网络参数化的神经场，实现了良好的任务性能，但牺牲了重建质量。为了改进后者，后来的方法侧重于参数化为大型多层感知器（MLP）的单个神经场，然而，由于权重空间的高维性、固有的权重空间对称性和对随机初始化的敏感性，这些神经元场的处理具有挑战性。因此，结果明显不如通过处理显式表示（例如点云或网格）所获得的结果。与此同时，混合表示，特别是基于三平面的混合表示，已经成为实现神经场的一种更有效的替代方案，但其直接处理尚未得到研究。在本文中，我们证明了三平面离散数据结构编码了丰富的信息，标准的深度学习机器可以有效地处理这些信息。我们定义了一个广泛的基准，涵盖了一组不同的字段，如占用率、有符号/无符号距离，以及首次定义的辐射字段。在处理具有相同重建质量的字段时，我们实现的任务性能远远优于处理大型MLP的框架，并且首次几乎与处理显式表示的架构不相上下。 et.al.|[2310.01140](http://arxiv.org/abs/2310.01140)|null|
|**2023-09-27**|**Neural Acoustic Context Field: Rendering Realistic Room Impulse Response With Neural Fields**|房间脉冲响应（RIR）测量声音在环境中的传播，对于合成给定环境下的高保真音频至关重要。一些先前的工作已经提出将RIR表示为声音发射器和接收器位置的神经场函数。然而，这些方法没有充分考虑音频场景的声学特性，导致性能不令人满意。这封信提出了一种新的神经声学上下文场方法，称为NACF，通过利用多个声学上下文（如几何结构、材料特性和空间信息）来参数化音频场景。在RIR的独特性质，即时间不光滑性和单调能量衰减的驱动下，我们设计了一个时间相关模块和多尺度能量衰减准则。实验结果表明，NACF的性能显著优于现有的基于字段的方法。请访问我们的项目页面了解更多定性结果。 et.al.|[2309.15977](http://arxiv.org/abs/2309.15977)|null|
|**2023-09-27**|**SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations**|隐式神经表示（INR）或神经场已成为编码多媒体信号（如图像和辐射场）同时保持高质量的流行框架。最近，Instant NGP提出的可学习特征网格通过用特征向量的多分辨率查找表和更小的神经网络取代大型神经网络，在训练和INR采样方面实现了显著的加速。然而，这些功能网格是以大量内存消耗为代价的，这可能是存储和流应用程序的瓶颈。在这项工作中，我们提出了SHACIRA，这是一个简单而有效的任务无关框架，用于压缩这种特征网格，而不需要额外的事后修剪/量化阶段。我们用量化的潜在权重对特征网格进行重新参数化，并在潜在空间中应用熵正则化，以在各个领域实现高水平的压缩。在由图像、视频和辐射场组成的不同数据集上的定量和定性结果表明，我们的方法优于现有的INR方法，而不需要任何大型数据集或特定领域的启发式方法。我们的项目页面可在http://shacira.github.io。 et.al.|[2309.15848](http://arxiv.org/abs/2309.15848)|null|
|**2023-09-27**|**NeuRBF: A Neural Fields Representation with Adaptive Radial Basis Functions**|我们提出了一种新型的神经场，它使用一般的径向基来表示信号。现有技术的神经领域通常依赖于用于存储局部神经特征的基于网格的表示和用于在连续查询点处插值特征的N维线性核。它们的神经特征的空间位置固定在网格节点上，不能很好地适应目标信号。相反，我们的方法建立在具有灵活内核位置和形状的通用径向基上，这些径向基具有更高的空间自适应性，可以更紧密地拟合目标信号。为了进一步提高径向基函数的信道容量，我们建议将它们与多频率正弦函数组合。该技术将径向基扩展到不同频带的多个傅立叶径向基，而不需要额外的参数，便于细节的表示。此外，通过将自适应径向基与基于网格的径向基相结合，我们的混合组合继承了自适应性和插值平滑性。我们精心设计了加权方案，使径向基有效地适应不同类型的信号。我们在2D图像和3D符号距离场表示上的实验证明了我们的方法比现有技术更高的精度和紧凑性。当应用于神经辐射场重建时，我们的方法实现了最先进的渲染质量，模型大小小，训练速度相当。 et.al.|[2309.15426](http://arxiv.org/abs/2309.15426)|**[link](https://github.com/oppo-us-research/NeuRBF)**|
|**2023-09-29**|**3D Reconstruction with Generalizable Neural Fields using Scene Priors**|由于神经领域的最新进展，高保真3D场景重建得到了实质性的推进。然而，大多数现有的方法为每个单独的场景从头开始训练单独的网络。这是不可扩展的，效率低下，并且在视图有限的情况下无法产生良好的结果。虽然基于学习的多视图立体方法在一定程度上缓解了这一问题，但它们的多视图设置使其扩展和广泛应用的灵活性降低。相反，我们引入了结合场景先验（NFP）的训练可推广神经场。NFP网络将任何单视图RGB-D图像映射为带符号的距离和辐射值。在没有融合模块的情况下，可以通过合并体积空间中的各个帧来重建完整的场景，这提供了更好的灵活性。场景先验可以在大规模数据集上进行训练，从而能够快速适应具有较少视图的新场景的重建。NFP不仅展示了SOTA场景重建的性能和效率，而且还支持单图像新视图合成，这在神经领域还没有得到充分的探索。更多定性结果可在以下网站获得：https://oasisyang.github.io/neural-prior et.al.|[2309.15164](http://arxiv.org/abs/2309.15164)|null|
|**2023-09-22**|**NOC: High-Quality Neural Object Cloning with 3D Lifting of Segment Anything**|随着神经领域的发展，从多视图输入重建目标物体的3D模型最近越来越受到社会的关注。现有的方法通常学习整个场景的神经场，而如何在飞行中重建用户指示的特定对象仍在探索之中。考虑到分段任意模型（SAM）在分割任何2D图像方面都显示出了有效性，本文提出了一种新的高质量3D对象重建方法——神经对象克隆（NOC），它从两个方面利用了神经场和SAM的优点。首先，为了将目标对象从场景中分离出来，我们提出了一种新的策略，将SAM的多视图2D分割掩模提升到一个统一的3D变化场中。然后，3D变化场被投影到2D空间中，并生成SAM的新提示。这个过程是迭代的，直到收敛，以将目标对象从场景中分离出来。然后，除了2D掩模之外，我们进一步将SAM编码器的2D特征提升到3D SAM场中，以提高目标对象的重建质量。NOC将SAM的2D掩模和特征提升到3D神经场中，用于高质量的目标对象重建。我们在几个基准数据集上进行了详细的实验，以证明我们的方法的优势。代码将被发布。 et.al.|[2309.12790](http://arxiv.org/abs/2309.12790)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

