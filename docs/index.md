---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.03.18
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-03-15**|**GGRt: Towards Generalizable 3D Gaussians without Pose Priors in Real-Time**|本文提出了GGRt，这是一种可推广的新视图合成的新方法，它减轻了对真实相机姿态的需求、处理高分辨率图像的复杂性和漫长的优化过程，从而有助于增强3D高斯散射（3D-GS）在现实世界场景中的适用性。具体来说，我们设计了一个新的联合学习框架，该框架由迭代姿态优化网络（IPO Net）和可推广的三维高斯（G-3DG）模型组成。通过联合学习机制，所提出的框架可以从图像观测中固有地估计鲁棒的相对姿态信息，从而主要减轻对真实相机姿态的要求。此外，我们实现了一种延迟反向传播机制，该机制能够实现高分辨率的训练和推理，克服了以前方法的分辨率限制。为了提高速度和效率，我们进一步引入了一个渐进式高斯缓存模块，该模块在训练和推理过程中进行动态调整。作为第一个无姿势可推广的3D-GS框架，GGRt实现了 $\ge$5 FPS的推理和$\ge$ 100 FPS的实时渲染。通过广泛的实验，我们证明了我们的方法在推理速度和有效性方面优于现有的基于NeRF的无姿态技术。它还可以接近基于真实姿态的3D-GS方法。我们的贡献为将计算机视觉和计算机图形集成到实际应用中提供了重大飞跃，在LLFF、KITTI和Waymo Open数据集上提供了最先进的结果，并实现了沉浸式体验的实时渲染。 et.al.|[2403.10147](http://arxiv.org/abs/2403.10147)|null|
|**2024-03-14**|**The NeRFect Match: Exploring NeRF Features for Visual Localization**|在这项工作中，我们建议使用神经辐射场（NeRF）作为视觉定位的场景表示。最近，NeRF已被用于通过增强训练数据库、通过渲染图像提供辅助监督或作为迭代细化模块来增强姿态回归和场景坐标回归模型。我们通过探索NeRF的内部特征在建立精确的2D-3D定位匹配方面的潜力，扩展了其公认的优势——它能够提供具有逼真外观和精确几何形状的紧凑场景表示。为此，我们对通过视图合成获得的NeRF的内隐知识进行了全面的检查，以在各种条件下进行匹配。这包括探索不同的匹配网络架构，在多个层提取编码器特征，以及不同的训练配置。值得注意的是，我们引入了NeRFMatch，这是一种先进的2D-3D匹配功能，它利用了通过视图合成学习到的NeRF的内部知识。我们在基于结构的管道内，根据标准本地化基准对NeRFMatch进行评估，为剑桥地标的本地化性能树立了新的最先进水平。 et.al.|[2403.09577](http://arxiv.org/abs/2403.09577)|null|
|**2024-03-14**|**Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting**|3D高斯散射（3DGS）最近在实时新视图合成和3D重建方面表现出了令人印象深刻的能力。然而，3DGS在很大程度上依赖于从运动结构（SfM）方法导出的精确初始化。当使用随机初始化的点云进行训练时，3DGS无法保持其产生高质量图像的能力，PSNR的性能大幅下降4-5dB。通过在频域中对SfM初始化的广泛分析和对具有多个1D高斯的1D回归任务的分析，我们提出了一种新的优化策略RAIN-GS（放宽3D高斯散射的精确初始化约束），该策略成功地从随机点云中训练了3D高斯。我们通过在多个数据集上进行定量和定性比较，展示了我们策略的有效性，大大提高了所有环境中的性能。我们的项目页面和代码可以在https://ku-cvlab.github.io/RAIN-GS. et.al.|[2403.09413](http://arxiv.org/abs/2403.09413)|**[link](https://github.com/KU-CVLAB/RAIN-GS)**|
|**2024-03-12**|**Q-SLAM: Quadric Representations for Monocular SLAM**|Monocular SLAM长期以来一直在努力应对准确建模3D几何图形的挑战。基于神经辐射场（NeRF）的单目SLAM的最新进展显示出了前景，但这些方法通常侧重于新颖的视图合成，而不是精确的3D几何建模。这种关注导致NeRF应用（即新的视图合成）与SLAM的要求之间的显著脱节。我们发现，间隙是由NeRF中使用的体积表示产生的，这些表示通常是密集的和有噪声的。在这项研究中，我们提出了一种新的方法，通过二次曲面的透镜重新想象体积表示。我们假设大多数场景组件可以有效地表示为二次平面。利用这一假设，我们通过几个二次平面用数百万个立方体重塑体积表示，这导致在SLAM环境中对3D场景进行更准确和高效的建模。我们的方法包括两个关键步骤：首先，我们使用二次假设来增强从跟踪模块（例如Droid SLAM）获得的粗略深度估计。仅此步骤就显著提高了深度估计的准确性。其次，在随后的映射阶段，我们偏离了以前基于NeRF的SLAM方法，该方法在整个体积空间中分布采样点。相反，我们将采样点集中在二次平面周围，并使用一种新的二次分解变换器对它们进行聚合。此外，我们还介绍了一种端到端的联合优化策略，该策略将姿态估计与三维重建同步。 et.al.|[2403.08125](http://arxiv.org/abs/2403.08125)|null|
|**2024-03-12**|**Learning Generalizable Feature Fields for Mobile Manipulation**|移动操作中的一个悬而未决的问题是如何以统一的方式表示对象和场景，以便机器人既可以在环境中导航，也可以操作对象。后者需要在理解细粒度语义的同时捕获复杂的几何体，而前者则需要捕获继承到扩展物理规模的复杂性。在这项工作中，我们提出了GeFF（可泛化特征场），这是一个场景级的可泛化神经特征场，作为实时执行的导航和操纵的统一表示。为此，我们将生成新视图合成视为预训练任务，然后通过CLIP特征提取将生成的丰富场景先验与自然语言对齐。我们通过在配备机械手的四足机器人上部署GeFF来证明这种方法的有效性。当在动态场景中执行开放词汇移动操作时，我们评估了GeFF泛化到开放集对象的能力以及运行时间。 et.al.|[2403.07563](http://arxiv.org/abs/2403.07563)|null|
|**2024-03-13**|**DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization**|辐射场在从稀疏输入视图合成新视图方面表现出了令人印象深刻的性能，但主流方法的训练成本高，推理速度慢。本文介绍了DNGaussian，一种基于三维高斯辐射场的深度正则化框架，以低成本提供实时、高质量的少镜头新视图合成。我们的动机源于最近的3D高斯飞溅的高效表示和令人惊讶的质量，尽管当输入视图减少时，它会遇到几何退化。在高斯辐射场中，我们发现场景几何的这种退化主要与高斯基元的定位有关，并且可以通过深度约束来缓解。因此，我们提出了一种硬深度和软深度正则化，以在粗略的单目深度监督下恢复准确的场景几何体，同时保持细粒度的颜色外观。为了进一步细化详细的几何体重塑，我们引入了全局局部深度归一化，增强了对局部深度小变化的关注。在LLFF、DTU和Blender数据集上进行的大量实验表明，DNGaussian优于最先进的方法，实现了相当或更好的结果，显著降低了内存成本，减少了25美元的训练时间，渲染速度快了3000美元以上。 et.al.|[2403.06912](http://arxiv.org/abs/2403.06912)|**[link](https://github.com/fictionarry/dngaussian)**|
|**2024-03-11**|**FreGS: 3D Gaussian Splatting with Progressive Frequency Regularization**|三维高斯泼溅在实时新颖视图合成中取得了令人印象深刻的性能。然而，在高斯致密化过程中，它经常遭受过度重建，其中高方差图像区域仅被几个大高斯覆盖，导致渲染图像中的模糊和伪影。我们设计了一种渐进频率正则化（FreGS）技术来解决频率空间内的过重构问题。具体而言，FreGS通过利用傅立叶空间中的低通和高通滤波器可以容易地提取的低频到高频分量来执行从粗到细的高斯致密化。通过最小化渲染图像的频谱与相应的地面实况之间的差异，它实现了高质量的高斯致密化，并有效地缓解了高斯飞溅的过度重建。在多个广泛采用的基准上进行的实验（例如，Mip-NeRF360、Tanks and Temples和Deep Blending）表明，FreGS实现了卓越的新型视图合成，并始终优于最先进的视图合成。 et.al.|[2403.06908](http://arxiv.org/abs/2403.06908)|null|
|**2024-03-11**|**V3D: Video Diffusion Models are Effective 3D Generators**|3D自动生成最近引起了广泛关注。最近的方法大大加快了生成速度，但由于模型容量或3D数据有限，通常会生成不太详细的对象。受视频扩散模型最新进展的启发，我们引入了V3D，它利用预先训练的视频扩散模型的世界模拟能力来促进3D生成。为了充分释放视频扩散感知3D世界的潜力，我们进一步引入了几何一致性先验，并将视频扩散模型扩展到多视图一致的3D生成器中。得益于此，可以对最先进的视频扩散模型进行微调，以在给定单个图像的情况下生成围绕对象的360度轨道帧。通过我们量身定制的重建管道，我们可以在3分钟内生成高质量的网格或3D高斯。此外，我们的方法可以扩展到场景级的新视图合成，实现对稀疏输入视图的相机路径的精确控制。大量实验证明了该方法的优越性能，特别是在生成质量和多视图一致性方面。我们的代码可在https://github.com/heheyas/V3D et.al.|[2403.06738](http://arxiv.org/abs/2403.06738)|**[link](https://github.com/heheyas/v3d)**|
|**2024-03-11**|**Vosh: Voxel-Mesh Hybrid Representation for Real-Time View Synthesis**|神经辐射场（NeRF）已成为合成新颖视图的逼真图像的一种突出方法。虽然基于体素或网格的神经辐射表示分别提供了不同的优势，在渲染质量或速度方面都很出色，但每种方法在其他方面都有局限性。作为回应，我们提出了一种名为Vosh的开创性混合表示，在用于视图合成的混合渲染中无缝组合体素和网格组件。Vosh是通过优化NeRF的体素网格精心制作的，战略性地将选定的体素替换为网格。因此，它擅长通过网格组件快速渲染具有简单几何体和纹理的场景，同时通过利用体素组件在复杂区域实现高质量渲染。Vosh的灵活性通过调整混合比率的能力得到了展示，为用户提供了基于灵活使用控制渲染质量和速度之间平衡的能力。实验结果表明，我们的方法在渲染质量和速度之间实现了值得称赞的折衷，并且在移动设备上具有显著的实时性能。 et.al.|[2403.06505](http://arxiv.org/abs/2403.06505)|null|
|**2024-03-13**|**FSViewFusion: Few-Shots View Generation of Novel Objects**|自从NeRF出现以来，新颖的视图合成已经得到了巨大的发展。然而，Nerf模型在单个场景上过拟合，缺乏对分布外对象的泛化能力。最近，扩散模型在视图合成中引入泛化方面表现出了显著的性能。受这些进步的启发，我们探索了预训练的稳定扩散模型在没有显式3D先验的情况下进行视图合成的能力。具体来说，我们的方法基于个性化的文本到图像模型Dreambooth，因为它具有很强的能力，只需几次拍摄就可以适应特定的新颖对象。我们的研究揭示了两个有趣的发现。首先，我们观察到，与涉及对大量多视图数据进行微调扩散的更复杂的策略相比，Dreambooth可以学习视图的高级概念。其次，我们建立了一个观点的概念可以被解开并转移到一个新的对象上，而不考虑从中学习观点的原始对象的身份。受此启发，我们引入了一种学习策略FSViewFusion，该策略仅通过单个场景的一个图像样本继承特定视图，并使用低阶适配器将知识转移到从少数镜头中学习的新对象。通过广泛的实验，我们证明了我们的方法虽然简单，但在为野生图像生成可靠的视图样本方面是有效的。将发布代码和模型。 et.al.|[2403.06394](http://arxiv.org/abs/2403.06394)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-03-15**|**SCILLA: SurfaCe Implicit Learning for Large Urban Area, a volumetric hybrid solution**|神经隐式表面表示方法最近显示出令人印象深刻的3D重建结果。然而，现有的解决方案由于其庞大、无边界和高度细致的性质，难以重建城市户外场景。因此，为了实现精确的重建，需要额外的监督数据，如激光雷达、强几何先验和长的训练时间。为了解决这些问题，我们提出了SCILLA，这是一种新的混合隐式表面学习方法，用于从2D图像中重建大型驾驶场景。SCILLA的混合架构为两个独立的隐式场建模：一个用于体积密度，另一个用于到曲面的符号距离。为了准确地表示城市户外场景，我们引入了一种新的体绘制策略，该策略依赖于自监督概率密度估计来对表面附近的点进行采样，并逐步从体表示过渡到表面表示。与并行方法相比，我们的解决方案允许在不依赖场景中任何几何先验的情况下正确快速地初始化有符号距离场。通过在四个户外驾驶数据集上进行广泛的实验，我们表明SCILLA可以在各种城市场景中学习准确而详细的3D表面场景表示，同时与以前最先进的解决方案相比，训练速度快两倍。 et.al.|[2403.10344](http://arxiv.org/abs/2403.10344)|null|
|**2024-03-15**|**FDGaussian: Fast Gaussian Splatting from Single Image via Geometric-aware Diffusion Model**|由于可用信息有限，从单视图图像重建详细的3D对象仍然是一项具有挑战性的任务。在本文中，我们介绍了FDGaussian，一种用于单图像三维重建的新的两阶段框架。最近的方法通常利用预先训练的2D扩散模型来从输入图像生成看似合理的新视图，但它们遇到了多视图不一致或缺乏几何保真度的问题。为了克服这些挑战，我们提出了一种正交平面分解机制来从2D输入中提取3D几何特征，从而能够生成一致的多视图图像。此外，我们还进一步加速了最先进的高斯散射技术，该技术结合了对极的关注，以融合来自不同视点的图像。我们证明了FDGaussian在不同视图中生成具有高一致性的图像，并在定性和定量上重建高质量的3D对象。更多示例可在我们的网站上找到https://qjfeng.net/FDGaussian/. et.al.|[2403.10242](http://arxiv.org/abs/2403.10242)|null|
|**2024-03-15**|**Den-SOFT: Dense Space-Oriented Light Field DataseT for 6-DOF Immersive Experience**|我们构建了一个定制的移动多摄像头大空间密集光场捕捉系统，为各种场景提供了一系列高质量、足够密集的光场图像。我们的目标是为流行的3D场景重建算法的发展做出贡献，如IBRnet、NeRF和3D高斯分裂。更重要的是，收集到的数据集比现有数据集密度大得多，也可能激发面向空间的光场重建，这可能不同于以对象为中心的3D重建，以获得身临其境的VR/AR体验。我们总共使用了40台GoPro 10相机，拍摄了5k分辨率的图像。每个场景拍摄的照片数量不少于1000张，平均密度（单位球体内的视图数量）为134.68。同样值得注意的是，我们的系统能够有效地捕捉大型户外场景。针对目前缺乏大空间和密集光场数据集的问题，我们努力在数据捕获过程中纳入3D重建领域研究人员感兴趣的元素，如天空、反射、光和阴影。最后，我们在三种流行算法上验证了我们提供的数据集的有效性，并将重建的3DGS结果集成到Unity引擎中，展示了利用我们的数据集增强虚拟现实（VR）真实感和创建可行交互空间的潜力。数据集可在我们的项目网站上获得。 et.al.|[2403.09973](http://arxiv.org/abs/2403.09973)|null|
|**2024-03-14**|**MARVIS: Motion & Geometry Aware Real and Virtual Image Segmentation**|自主导航、三维重建和水面附近物体识别等任务在海洋机器人应用中至关重要。然而，由于动态扰动，例如来自随机空气-水界面的光反射和折射、不规则的液体流动和类似因素，这些挑战会导致感知和导航系统的潜在故障。传统的计算机视觉算法很难区分真实图像和虚拟图像区域，这使任务变得非常复杂。虚像区域是光线重定向形成的明显表示，通常通过反射或折射，在没有实际物理位置的情况下产生物体存在的错觉。这项工作提出了一种新的方法来分割真实和虚拟图像区域，利用合成图像与域不变信息、运动熵核和Epipolar几何一致性相结合。如果域发生变化，则不需要重新训练我们的分割网络。我们通过在两个不同的领域部署相同的分割网络来展示这一点：模拟和现实世界。通过创建模拟水面复杂性的逼真合成图像，我们为我们的网络（MARVIS）提供了细粒度的训练数据，以有效地区分真实图像和虚拟图像。通过运动和几何感知的设计选择以及全面的实验分析，我们在看不见的真实世界领域实现了最先进的真实虚拟图像分割性能，实现了超过78%的IoU和超过86%的F1分数，同时确保了较小的计算足迹。MARVIS在单个GPU（CPU核心）上提供超过43 FPS（8 FPS）的推理率。我们的代码和数据集可在此处获得https://github.com/jiayi-wu-umd/MARVIS. et.al.|[2403.09850](http://arxiv.org/abs/2403.09850)|null|
|**2024-03-14**|**Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting**|3D高斯散射（3DGS）最近在实时新视图合成和3D重建方面表现出了令人印象深刻的能力。然而，3DGS在很大程度上依赖于从运动结构（SfM）方法导出的精确初始化。当使用随机初始化的点云进行训练时，3DGS无法保持其产生高质量图像的能力，PSNR的性能大幅下降4-5dB。通过在频域中对SfM初始化的广泛分析和对具有多个1D高斯的1D回归任务的分析，我们提出了一种新的优化策略RAIN-GS（放宽3D高斯散射的精确初始化约束），该策略成功地从随机点云中训练了3D高斯。我们通过在多个数据集上进行定量和定性比较，展示了我们策略的有效性，大大提高了所有环境中的性能。我们的项目页面和代码可以在https://ku-cvlab.github.io/RAIN-GS. et.al.|[2403.09413](http://arxiv.org/abs/2403.09413)|**[link](https://github.com/KU-CVLAB/RAIN-GS)**|
|**2024-03-13**|**3DFIRES: Few Image 3D REconstruction for Scenes with Hidden Surface**|本文介绍了一种新的基于姿态图像的场景级三维重建系统3DFIRES。3DFIRES的设计只适用于一个视图，它重建了看不见的场景的完整几何体，包括隐藏的表面。使用多个视图输入，我们的方法可以在所有相机截头体内进行完全重建。我们的方法的一个关键特征是在特征级别融合多视图信息，从而实现连贯和全面的3D重建。我们在大规模真实场景数据集的非水密扫描上训练我们的系统。我们表明，它与仅使用一个输入的单视图重建方法的效果相匹配，并且在稀疏视图3D重建的定量和定性测量方面都超过了现有技术。 et.al.|[2403.08768](http://arxiv.org/abs/2403.08768)|null|
|**2024-03-13**|**Refractive COLMAP: Refractive Structure-from-Motion Revisited**|在本文中，我们提出了一个完整的折射运动结构（RSfM）框架，用于使用折射相机设置（用于平端口和圆顶端口水下外壳）进行水下3D重建。尽管在过去十年中在折射多视图几何方面取得了显著成就，但目前还没有一个强大、完整和公开的解决方案来解决这类任务，而且实际应用往往不得不通过针孔相机模型的固有（失真）参数来近似折射效应。为了填补这一空白，我们在最先进的开源SfM框架COLMAP中，在整个SfM过程中集成了折射考虑因素。对具有地面实况的合成生成但照片逼真的图像进行的数值模拟和重建结果验证了与空中重建相比，启用折射不会损害准确性或稳健性。最后，我们使用由近6000张图像组成的数据集展示了我们的方法在大规模折射场景中的能力。该实现以开源形式发布于：https://cau-git.rz.uni-kiel.de/inf-ag-koeser/colmap_underwater. et.al.|[2403.08640](http://arxiv.org/abs/2403.08640)|null|
|**2024-03-12**|**Q-SLAM: Quadric Representations for Monocular SLAM**|Monocular SLAM长期以来一直在努力应对准确建模3D几何图形的挑战。基于神经辐射场（NeRF）的单目SLAM的最新进展显示出了前景，但这些方法通常侧重于新颖的视图合成，而不是精确的3D几何建模。这种关注导致NeRF应用（即新的视图合成）与SLAM的要求之间的显著脱节。我们发现，间隙是由NeRF中使用的体积表示产生的，这些表示通常是密集的和有噪声的。在这项研究中，我们提出了一种新的方法，通过二次曲面的透镜重新想象体积表示。我们假设大多数场景组件可以有效地表示为二次平面。利用这一假设，我们通过几个二次平面用数百万个立方体重塑体积表示，这导致在SLAM环境中对3D场景进行更准确和高效的建模。我们的方法包括两个关键步骤：首先，我们使用二次假设来增强从跟踪模块（例如Droid SLAM）获得的粗略深度估计。仅此步骤就显著提高了深度估计的准确性。其次，在随后的映射阶段，我们偏离了以前基于NeRF的SLAM方法，该方法在整个体积空间中分布采样点。相反，我们将采样点集中在二次平面周围，并使用一种新的二次分解变换器对它们进行聚合。此外，我们还介绍了一种端到端的联合优化策略，该策略将姿态估计与三维重建同步。 et.al.|[2403.08125](http://arxiv.org/abs/2403.08125)|null|
|**2024-03-11**|**Bayesian Diffusion Models for 3D Shape Reconstruction**|我们提出了贝叶斯扩散模型（BDM），这是一种通过联合扩散过程将自上而下（先验）的信息与自下而上（数据驱动）的过程紧密耦合来执行有效贝叶斯推理的预测算法。我们展示了BDM在三维形状重建任务中的有效性。与在配对（监督）数据标签（如图像点云）数据集上训练的原型深度学习数据驱动方法相比，我们的BDM从独立标签（如点云）中引入了丰富的先验信息，以改进自下而上的3D重建。与推理需要显式先验和似然的标准贝叶斯框架不同，BDM通过与学习的梯度计算网络的耦合扩散过程来执行无缝信息融合。我们BDM的特点在于它能够参与自上而下和自下而上的过程的积极有效的信息交换和融合，其中每个过程本身就是一个扩散过程。我们在3D形状重建的合成基准和真实世界基准上展示了最先进的结果。 et.al.|[2403.06973](http://arxiv.org/abs/2403.06973)|null|
|**2024-03-08**|**DITTO: Dual and Integrated Latent Topologies for Implicit 3D Reconstruction**|我们提出了一种新的对偶和集成潜在拓扑（简称DITTO）概念，用于从噪声和稀疏点云中进行隐式三维重建。大多数现有的方法主要关注单个潜在类型，如点或网格潜在。相反，所提出的DITTO利用点和网格潜伏时间（即双重潜伏时间）来增强它们的强度、网格潜伏时间的稳定性和点潜伏时间的细节丰富能力。DITTO由双隐式编码器和集成隐式解码器组成。在双潜伏编码器中，双潜伏层是构成编码器的关键模块块，它并行地细化两个潜伏，保持它们不同的形状，并实现递归交互。值得注意的是，新提出的双潜伏层内的动态稀疏点变换器有效地细化了点潜伏。然后，集成隐式解码器系统地结合了这些精细的延迟，实现了高保真度的3D重建，并在对象和场景级数据集上超越了以前最先进的方法，尤其是在薄而详细的结构中。 et.al.|[2403.05005](http://arxiv.org/abs/2403.05005)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-03-15**|**Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation Guided by the Characteristic Dance Primitives**|我们提出了Lodge，一个能够在给定音乐的条件下生成超长舞蹈序列的网络。我们将Lodge设计为两阶段的从粗到细的扩散架构，并提出了具有显著表现力的特征舞蹈原语作为两个扩散模型之间的中间表示。第一阶段是全球扩散，重点是理解粗层次的乐舞关联和生产特征的舞蹈原语。相反，第二阶段是局部扩散，它在舞蹈原语和舞蹈规则的指导下并行生成详细的运动序列。此外，我们提出了一个脚部优化块来优化脚部和地面之间的接触，从而增强运动的物理逼真度。我们的方法可以并行生成超长的舞蹈序列，在全局舞蹈模式与局部运动质量和表现力之间取得平衡。大量实验验证了我们方法的有效性。 et.al.|[2403.10518](http://arxiv.org/abs/2403.10518)|**[link](https://github.com/li-ronghui/LODGE)**|
|**2024-03-15**|**Active transport of a passive colloid in a bath of run-and-tumble particles**|使用随机模拟和渐近理论分析了浸泡在非相互作用和非布朗运行和翻滚微游泳池中的被动胶体在二维中的分散，这两种方法都基于游泳胶体碰撞的最小模型，该模型仅以无摩擦空间相互作用为特征。我们估计了悬浮胶体与活性浴相互作用产生的有效长时间扩散率 $\mathcal{D}$ ，并阐明了其对活性水平（游泳者轨迹的持续长度）、胶体与游泳者的迁移率比和浴中游泳者数量密度的依赖性。我们还提出了一个胶体扩散率的半解析模型，该模型根据游泳者碰撞产生的胶体上的净波动主动力的方差和相关时间。在低游泳者密度、低流动率和高活动性的实验相关条件下，数值模拟和分析结果之间存在定量一致性。 et.al.|[2403.10508](http://arxiv.org/abs/2403.10508)|null|
|**2024-03-15**|**MusicHiFi: Fast High-Fidelity Stereo Vocoding**|基于扩散的音频和音乐生成模型通常通过构建音频的图像表示（例如，mel声谱图），然后使用相位重建模型或声码器将其转换为音频来生成音乐。然而，典型的声码器以较低的分辨率（例如16-24kHz）产生单声道音频，这限制了它们的有效性。我们提出了MusicHiFi——一种高效的高保真立体声声码器。我们的方法采用了三个生成对抗性网络（GANs）的级联，将低分辨率mel频谱图转换为音频，通过带宽扩展将上采样转换为高分辨率音频，并将上混合转换为立体声音频。与之前的工作相比，我们提出了1）用于级联的每个阶段的统一的基于GAN的生成器和鉴别器架构和训练过程，2）一个新的快速、接近下采样兼容的带宽扩展模块，以及3）一种新的快速下混兼容的单声道到立体声上混频器，确保在输出中保留单声道内容。我们使用客观和主观听力测试来评估我们的方法，发现与过去的工作相比，我们的方法产生了相当或更好的音频质量、更好的空间化控制和明显更快的推理速度https://MusicHiFi.github.io/web/. et.al.|[2403.10493](http://arxiv.org/abs/2403.10493)|null|
|**2024-03-15**|**New functional inequalities with applications to the arctan-fast diffusion equation**|在本文中，我们证明了一对新的Sobolev型非线性泛函不等式，类似于对数Sobolev不等式。特别地，其中一个不等式读作 $$\int_｛\mathbb｛S｝^1｝\arctan\left（\frac｛\partial_xu｝｛u｝\right）\partial_u\，dx\geq\arctan\left（\|u（t）\|_然后，将这些不等式用于非线性emph的研究{arctan}-fast扩散方程$$\partil_t u-\partil_x\arctan\left（\frac｛\partil_x u｝｛u｝\right）=0.$$ 对于这个高度非线性的偏微分方程，我们建立了一些适定性结果和定性性质。 et.al.|[2403.10458](http://arxiv.org/abs/2403.10458)|null|
|**2024-03-15**|**Variance sum rule: proofs and solvable models**|在更一般的条件下，我们导出了最近引入的方差和规则[I.Di Terlizzi等人，2024 Science 383 971]，该规则涉及非平衡稳态（NESS）中过阻尼Langevin系统的位移和力脉冲的方差。该公式允许将非平衡效应可视化为与正常扩散的方差总和的偏差 $2Dt$，其中$D$为扩散常数，$t$为时间。根据VSR，我们还推导了熵产生率$\sigma$的公式，与之前的结果不同，该公式涉及位置相关函数的二阶时间导数。这一新特征为在不测量力的情况下判别强非平衡状态提供了一个标准。然后，我们将我们的结果应用于三个解析求解的模型：随机切换陷阱、布朗涡旋和布朗回转器。最后，我们比较了已知和新的$\sigma$ 公式在过阻尼NESS中的优点和局限性。 et.al.|[2403.10442](http://arxiv.org/abs/2403.10442)|null|
|**2024-03-15**|**SculptDiff: Learning Robotic Clay Sculpting from Humans with Goal Conditioned Diffusion Policy**|由于状态估计、长期规划和预测物体在交互作用下如何变形的困难，操纵可变形物体仍然是机器人领域的一个挑战。这些挑战在3D可变形对象中最为明显。我们提出了SculptDiff，这是一种基于目标条件扩散的模仿学习框架，它与点云状态观测相结合，直接学习各种目标形状的粘土雕刻策略。据我们所知，这是第一个成功学习3D可变形对象操纵策略的真实世界方法。有关雕刻视频以及访问我们的数据集和硬件CAD模型的信息，请访问项目网站：https://sites.google.com/andrew.cmu.edu/imitation-sculpting/home et.al.|[2403.10401](http://arxiv.org/abs/2403.10401)|null|
|**2024-03-15**|**Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding**|在预训练的2D扩散模型日益普及的鼓舞下，利用分数蒸馏采样（SDS）生成图像到3D正在取得显著进展。大多数现有方法结合了来自2D扩散模型的新颖视图提升，2D扩散模型通常将参考图像作为条件，同时在参考视图处应用硬L2图像监督。然而，严重粘附于图像容易破坏2D扩散模型的归纳知识，导致频繁地产生平坦或失真的3D。在这项工作中，我们以一种新颖的视角重新审视了图像到3D，并提出了Isotropic3D，这是一种仅以图像CLIP嵌入为输入的图像到3D生成管道。各向同性3D允许通过仅依靠SDS损失来实现相对于方位角的各向同性优化。我们框架的核心在于两阶段扩散模型的微调。首先，我们通过用图像编码器代替文本编码器来微调文本到3D的扩散模型，通过该模型初步获得图像到图像的能力。其次，我们使用我们的显式多视图注意力（EMA）进行微调，该EMA将有噪声的多视图图像与无噪声的参考图像相结合作为显式条件。CLIP嵌入在整个过程中被发送到扩散模型，而参考图像在微调后被丢弃一次。因此，通过嵌入单个图像CLIP，Isotropic3D能够生成多视图相互一致的图像，并且与现有的图像到3D方法相比，能够生成内容更对称、更整洁、几何形状均匀、纹理丰富、失真更小的3D模型，同时在很大程度上保持与参考图像的相似性。项目页面位于https://isotropic3d.github.io/.代码和型号可在https://github.com/pkunliu/Isotropic3D. et.al.|[2403.10395](http://arxiv.org/abs/2403.10395)|**[link](https://github.com/pkunliu/isotropic3d)**|
|**2024-03-15**|**Denoising Task Difficulty-based Curriculum for Training Diffusion Models**|基于扩散的生成模型已经成为生成建模领域的强大工具。尽管对不同时间步长和噪声水平的去噪进行了广泛的研究，但关于去噪任务的相对困难，冲突仍然存在。虽然各种研究认为，较低的时间步长会带来更具挑战性的任务，但其他研究认为，较高的时间步长更难。为了解决这一冲突，我们的研究对任务难度进行了全面的检查，重点关注收敛行为和跨时间步长的连续概率分布之间的相对熵变化。我们的观测研究表明，在较早的时间步长去噪带来了挑战，其特征是收敛较慢和相对熵较高，这表明在这些较低的时间步长下任务难度增加。在这些观察的基础上，我们引入了一个从简单到困难的学习方案，借鉴课程学习，以加强扩散模型的训练过程。通过将时间步长或噪声水平组织成聚类，并按难度降序训练模型，我们促进了顺序感知训练机制，从更容易的去噪任务发展到更难的去噪工作，从而偏离了在所有时间步长同时训练扩散模型的传统方法。我们的方法通过利用课程学习的优势，提高了性能，加快了收敛速度，同时保持了与扩散训练技术现有改进的正交性。我们通过在图像生成任务中的全面实验验证了这些优势，包括无条件、类条件和文本到图像生成。 et.al.|[2403.10348](http://arxiv.org/abs/2403.10348)|null|
|**2024-03-15**|**Optimal Control of Stationary Doubly Diffusive Flows on Two and Three Dimensional Bounded Lipschitz Domains: Numerical Analysis**|在这项工作中，我们提出了基于最低阶Crouziex-Raviart有限元和分段常空间的完全非协调、局部精确无散度离散化，以研究[B\“urger，M’endez，Ruiz-Baier，SINUM（2019），57:1318-1343]中提出的平稳双扩散模型的最优控制.利用离散提升和不动点自变量讨论了离散不受控状态和伴随方程的适定性，并在最小正则性下严格推导了收敛结果。在我们最近的工作[Tushar，Khan，Mohan arXiv（2023）]的基础上，我们使用控制问题的二阶充分最优性条件证明了参考控制的局部最优性，并将其与优化然后离散化方法一起使用，以证明控制、状态和伴随变量的最优阶先验误差估计，直到解的正则性。使用原始-对偶有效集策略作为半光滑牛顿方法来计算最优控制，计算测试验证了预测的误差衰减率，并说明了所提出的方案在温盐循环问题的最优控制中的适用性。 et.al.|[2403.10282](http://arxiv.org/abs/2403.10282)|null|
|**2024-03-15**|**Towards Generalizable Deepfake Video Detection with Thumbnail Layout and Graph Reasoning**|深度伪造对社会和网络安全的威胁引起了公众的极大担忧，推动了深度伪造视频检测领域的加大力度。当前的视频级方法大多基于{3D-CNNs}，这导致了高的计算需求，尽管已经获得了良好的性能。本文介绍了一种非常简单但有效的策略——缩略图布局（TALL），它将视频剪辑转换为预定义的布局，以实现空间和时间依赖性的保留。该变换过程包括在每个帧内的相同位置顺序地掩蔽帧。然后，这些帧被调整大小为子帧，并被重新组织为预定布局，形成缩略图。TALL与模型无关，并且非常简单，只需要对代码进行最小的修改。此外，我们引入了图推理块（GRB）和语义一致性（SC）损失来加强TALL，最终形成TALL++。GRB增强了不同语义区域之间的交互，以捕获语义级别的不一致线索。语义一致性损失对语义特征施加了一致性约束，以提高模型的泛化能力。在数据集内、跨数据集、扩散生成图像检测和深度伪造生成方法识别上的大量实验表明，TALL++的结果超过或可与最先进的方法相媲美，证明了我们的方法对各种深度伪造检测问题的有效性。代码位于https://github.com/rainy-xu/TALL4Deepfake. et.al.|[2403.10261](http://arxiv.org/abs/2403.10261)|**[link](https://github.com/rainy-xu/tall4deepfake)**|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-03-15**|**NECA: Neural Customizable Human Avatar**|人类化身已经成为一种具有各种应用的新型3D资产。理想情况下，人类化身应该是完全可定制的，以适应不同的设置和环境。在这项工作中，我们介绍了NECA，这是一种能够从单目或稀疏视图视频中学习多功能人体表示的方法，能够在姿势、阴影、形状、照明和纹理等方面进行细粒度定制。我们方法的核心是在互补的对偶空间中表示人类，并预测几何、反照率、阴影以及外部照明的解开神经场，从中我们能够通过体积渲染获得具有高频细节的逼真渲染。大量的实验证明了我们的方法在真实感渲染以及各种编辑任务（如新颖的姿势合成和重新照明）方面优于最先进的方法。代码位于https://github.com/iSEE-Laboratory/NECA. et.al.|[2403.10335](http://arxiv.org/abs/2403.10335)|**[link](https://github.com/isee-laboratory/neca)**|
|**2024-03-13**|**Representing Anatomical Trees by Denoising Diffusion of Implicit Neural Fields**|解剖树在临床诊断和治疗计划中起着核心作用。然而，由于解剖树的拓扑结构和几何形状多变且复杂，因此准确地表示解剖树具有挑战性。使用医学成像捕获的表示树状结构的传统方法虽然对可视化血管和支气管网络非常宝贵，但在分辨率、灵活性和效率方面存在缺陷。最近，隐式神经表示（INRs）已经成为准确有效地表示形状的强大工具。我们提出了一种使用INR表示解剖树的新方法，同时还通过INR空间中的去噪扩散来捕捉一组树的分布。我们以任何所需的分辨率准确捕捉解剖树的复杂几何形状和拓扑结构。通过广泛的定性和定量评估，我们展示了高保真度树重建，具有任意分辨率但紧凑的存储，以及跨解剖部位和树复杂性的多功能性。 et.al.|[2403.08974](http://arxiv.org/abs/2403.08974)|**[link](https://github.com/sinashish/treediffusion)**|
|**2024-03-12**|**Scalable Spatiotemporal Prediction with Bayesian Neural Fields**|时空数据集由空间参考的时间序列组成，在许多科学和商业智能应用中无处不在，如空气污染监测、疾病跟踪和云需求预测。随着现代数据集的规模和复杂性不断增加，人们越来越需要新的统计方法，这些方法足够灵活，可以捕捉复杂的时空动态，并且可以扩展，可以处理大型预测问题。这项工作提出了贝叶斯神经场（BayesNF），这是一种用于推断时空域上丰富概率分布的域通用统计模型，可用于数据分析任务，包括预测、插值和变差法。BayesNF将一种用于高容量函数估计的新型深度神经网络架构与用于鲁棒不确定性量化的分层贝叶斯推理相结合。通过通过一系列平滑可微变换定义先验，使用通过随机梯度下降训练的变量学习代理对大规模数据进行后验推理。我们根据突出的统计和机器学习基线评估BayesNF，显示出在气候和公共卫生数据集的各种预测问题上的显著改进，这些数据集包含数万到数十万个测量值。该论文附有一个开源软件包(https://github.com/google/bayesnf)它易于使用，并与JAX机器学习平台上的现代GPU和TPU加速器兼容。 et.al.|[2403.07657](http://arxiv.org/abs/2403.07657)|**[link](https://github.com/google/bayesnf)**|
|**2024-03-11**|**SiLVR: Scalable Lidar-Visual Reconstruction with Neural Radiance Fields for Robotic Inspection**|我们提出了一种基于神经场的大规模重建系统，该系统融合激光雷达和视觉数据，生成几何精度高的高质量重建，并捕捉照片逼真的纹理。该系统采用了最先进的神经辐射场（NeRF）表示，还结合了激光雷达数据，这对深度和表面法线增加了强大的几何约束。我们利用实时激光雷达SLAM系统的轨迹来引导运动结构（SfM）过程，以显著减少计算时间，并提供对激光雷达深度损失至关重要的度量尺度。我们使用子映射将系统缩放到长轨迹上捕获的大规模环境。我们用多摄像头、激光雷达传感器套件的数据演示了重建系统，该套件安装在腿式机器人上，手持扫描600米的建筑场景，并安装在空中机器人上，测量多层模拟灾难现场建筑。网站https://ori-drs.github.io/projects/silvr/ et.al.|[2403.06877](http://arxiv.org/abs/2403.06877)|null|
|**2024-03-15**|**CoNFiLD: Conditional Neural Field Latent Diffusion Model Generating Spatiotemporal Turbulence**|本研究介绍了条件神经场潜在扩散（CoNFiLD）模型，这是一种新的生成学习框架，旨在快速模拟三维不规则域内混沌和湍流系统中复杂的时空动力学。传统的涡解析数值模拟，尽管提供了详细的流量预测，但由于其广泛的计算需求，遇到了很大的局限性，限制了其在更广泛的工程环境中的应用。相比之下，基于深度学习的代理模型有望提供高效、数据驱动的解决方案。然而，它们的有效性往往因依赖确定性框架而受到损害，而确定性框架在准确捕捉湍流的混沌和随机性质方面存在不足。CoNFiLD模型通过将条件神经场编码与潜在扩散过程协同集成来解决这些挑战，从而能够在不同条件下高效且稳健地生成时空湍流。利用贝叶斯条件采样，该模型可以无缝适应各种湍流生成场景，而无需再训练，涵盖从使用稀疏传感器测量的零样本全场流重建到超分辨率生成和时空流数据恢复的应用。已经对各种具有不规则几何形状的非均匀、各向异性湍流进行了全面的数值实验，以评估该模型的多功能性和有效性，展示了其在湍流生成和更广泛的时空动力学建模领域的变革潜力。 et.al.|[2403.05940](http://arxiv.org/abs/2403.05940)|null|
|**2024-03-09**|**Learned 3D volumetric recovery of clouds and its uncertainty for climate analysis**|气候预测和云物理的重大不确定性与浅层散射云的观测差距有关。应对这些挑战需要对其三维（3D）异质体积散射内容进行遥感。这就需要无源散射计算机断层扫描（CT）。我们设计了一个基于学习的模型（ProbeCT）来实现这种云的CT，基于有噪声的多视图星载图像。ProbeCT首次推断出每个3D位置的异质消光系数的后验概率分布。这产生了任意有价值的统计数据，例如，最可能灭绝的3D场及其不确定性。ProbeCT使用神经场表示，进行本质上实时的推理。ProbeCT通过一个新的基于物理的云体积场及其相应图像的标记多类数据库进行监督训练。为了改进分布外推理，我们通过差分渲染引入了自监督学习。我们在模拟和真实世界的数据中演示了该方法，并指出了3D恢复和不确定性与降水和可再生能源的相关性。 et.al.|[2403.05932](http://arxiv.org/abs/2403.05932)|null|
|**2024-03-06**|**ProxNF: Neural Field Proximal Training for High-Resolution 4D Dynamic Image Reconstruction**|精确的时空图像重建方法被广泛的生物医学研究领域所需要，但由于数据的不完整性和计算负担而面临挑战。数据不完整性源于增加帧速率和减少采集时间所需的欠采样，而计算负担则源于具有三维空间和扩展时间范围的高分辨率图像的内存占用。神经场是一类新兴的神经网络，充当时空对象的连续表示，以前已经引入它来通过将图像重建重新定义为估计网络参数的问题来解决这些动态成像问题。神经场可以通过利用这些时空对象中潜在的冗余来解决数据不完整和计算负担这两个挑战。这项工作提出了ProxNF，这是一种用于时空图像重建的新的神经场训练方法，利用近端分裂方法将涉及成像算子的计算与网络参数的更新分开。具体而言，ProxNF评估图像域中数据保真度项的（子采样）梯度，并使用完全监督学习方法来更新神经场参数。通过减少内存占用和评估成像算子的计算成本，所提出的ProxNF方法允许重建大的、高分辨率的时空图像。该方法在两项数值研究中得到了证明，这两项研究涉及解剖逼真的动态数值小鼠模型和肿瘤灌注的两室模型的虚拟动态对比增强光声计算机断层扫描成像。 et.al.|[2403.03860](http://arxiv.org/abs/2403.03860)|null|
|**2024-03-05**|**NRDF: Neural Riemannian Distance Fields for Learning Articulated Pose Priors**|忠实地为关节空间建模是一项关键任务，它可以恢复和生成逼真的姿势，而且仍然是一项臭名昭著的挑战。为此，我们引入了神经黎曼距离场（NRDF），这是一种数据驱动的先验，用于建模看似合理的关节空间，表示为高维乘积四元数空间中神经场的零级集。为了仅在正示例上训练NRDF，我们引入了一种新的采样算法，确保测地距离遵循所需的分布，从而产生一种原则性的距离场学习范式。然后，我们设计了一种投影算法，通过自适应步长黎曼优化器将任何随机姿态映射到水平集上，始终遵循关节旋转的乘积流形。NRDF可以通过反向传播和数学类比计算黎曼梯度，与最近的生成模型黎曼流匹配有关。我们在各种下游任务中，即姿态生成、基于图像的姿态估计和求解逆运动学，对照其他姿态先验对NRDF进行了全面评估，突出了NRDF的优越性能。除了人类，NRDF的多功能性还延伸到手和动物姿势，因为它可以有效地代表任何关节。 et.al.|[2403.03122](http://arxiv.org/abs/2403.03122)|null|
|**2024-03-04**|**MagicClay: Sculpting Meshes With Generative Neural Fields**|神经领域的最新发展为形状生成领域带来了非凡的能力，但它们缺乏关键的特性，例如增量控制，这是艺术作品的基本要求。另一方面，三角网格是大多数几何相关任务的选择，提供了高效和直观的控制，但不适用于神经优化。为了支持下游任务，现有技术通常提出两步方法，其中首先使用神经场生成形状，然后提取网格进行进一步处理。相反，在本文中，我们引入了一种混合方法，该方法保持网格和符号距离场（SDF）表示的一致性。使用这种表示，我们介绍了MagicClay——一种艺术家友好的工具，用于根据文本提示雕刻网格区域，同时保持其他区域不变。我们的框架仔细而有效地平衡了形状优化每一步中表示和正则化之间的一致性；依靠网格表示，我们展示了如何以更高的分辨率和更快的速度渲染SDF。此外，我们利用最近在可微网格重建方面的工作，在需要的地方自适应地分配网格中的三角形，如SDF所示。使用一个实现的原型，我们展示了与最先进的生成几何体相比的优越性，以及新颖的一致性控制，首次允许对同一网格进行基于提示的顺序编辑。 et.al.|[2403.02460](http://arxiv.org/abs/2403.02460)|null|
|**2024-03-04**|**Activity estimation via distributed measurements in an orientation sensitive neural fields model of the visual cortex**|本文在可观察性理论的框架下研究了初级视觉皮层（V1）内神经活动的在线估计。我们专注于对超体积活动建模的低维神经场，以描述V1中的活动。我们使用V1上的平均皮层活动作为测量。我们的贡献包括详细说明模型的可观察性奇点，并开发一种混合高增益观测器，该观测器在特定的激励条件下实现实际收敛，同时在生物相关性的情况下保持渐近收敛。该研究强调了模型的非线性性质与其可观测性之间的内在联系。我们还介绍了数值实验，强调了观测者的不同性质。 et.al.|[2403.01906](http://arxiv.org/abs/2403.01906)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

