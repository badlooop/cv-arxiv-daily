---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.10.16
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-12**|**Is Generalized Dynamic Novel View Synthesis from Monocular Videos Possible Today?**|从新颖的视角渲染单目视频中观察到的场景是一个具有挑战性的问题。对于静态场景，社区研究了在每个测试场景上进行优化的特定场景优化技术，以及只在测试场景上运行深网前向传递的通用技术。相反，对于动态场景，存在特定场景的优化技术，但据我们所知，目前还没有从给定的单目视频中合成动态新视图的通用方法。为了回答从单目视频中进行广义动态新视图合成在今天是否可行，我们基于现有技术建立了一个分析框架，并致力于广义方法。我们发现，在没有特定场景外观优化的情况下，伪广义过程是可能的，但需要几何和时间一致的深度估计。尽管没有特定场景的外观优化，但伪广义方法改进了一些特定场景的方法。 et.al.|[2310.08587](http://arxiv.org/abs/2310.08587)|null|
|**2023-10-12**|**Im4D: High-Fidelity and Real-Time Novel View Synthesis for Dynamic Scenes**|本文旨在解决多视图视频动态视图合成的挑战。关键的观察结果是，虽然以前的基于网格的方法提供了一致的渲染，但它们在捕捉复杂动态场景的外观细节方面做不到，在这个领域中，基于多视图图像的渲染方法表现出相反的特性。为了将两个世界中最好的结合起来，我们引入了Im4D，这是一种混合场景表示，由基于网格的几何表示和基于多视图图像的外观表示组成。具体而言，动态几何被编码为由时空特征平面和小型MLP网络组成的4D密度函数，该函数对场景结构进行全局建模，并促进渲染一致性。我们通过原始多视图视频和网络来表示场景外观，该网络学习从图像特征预测3D点的颜色，而不是完全用网络来记忆详细的外观，从而自然地使网络的学习变得更容易。我们的方法在五个动态视图合成数据集上进行了评估，包括DyNeRF、ZJU MoCap、NHR、DNA Rendering和ENeRF Outdoor数据集。结果表明，Im4D在渲染质量方面表现出最先进的性能，并且可以有效地进行训练，同时在单个RTX 3090 GPU上以79.8 FPS的速度实现512x512图像的实时渲染。 et.al.|[2310.08585](http://arxiv.org/abs/2310.08585)|null|
|**2023-10-12**|**SingleInsert: Inserting New Concepts from a Single Image into Text-to-Image Models for Flexible Editing**|文本到图像（T2I）模型的最新进展使得能够通过灵活的文本控制生成高质量的图像。为了利用现成的T2I模型中丰富的视觉先验，一系列方法试图将图像反转为与T2I模型的语义空间对齐的适当嵌入。然而，这些图像到文本（I2T）反转方法通常需要包含相同概念的多个源图像，或者难以解决编辑灵活性和视觉逼真度之间的不平衡问题。在这项工作中，我们指出在学习预期概念时，关键问题在于前景-背景纠缠，并提出了一种简单有效的单图像I2T反演基线，称为SingleInsert。SingleInsert采用两阶段方案。在第一阶段，我们调节学习的嵌入，使其集中在前景区域，而不与无关背景相关联。在第二阶段，我们对T2I模型进行了微调，以获得更好的视觉相似性，并设计了语义损失来防止语言漂移问题。利用所提出的技术，SingleInsert在单概念生成方面表现出色，视觉逼真度高，同时允许灵活编辑。此外，SingleInsert可以在不需要联合训练的情况下进行单图像新视图合成和多概念合成。为了便于评估，我们设计了一个编辑提示列表，并引入了一个名为编辑成功率（ESR）的指标来定量评估编辑灵活性。我们的项目页面是：https://jarrentwu1031.github.io/SingleInsert-web/ et.al.|[2310.08094](http://arxiv.org/abs/2310.08094)|null|
|**2023-10-12**|**Consistent123: Improve Consistency for One Image to 3D Object Synthesis**|大图像扩散模型能够实现具有高质量和优异的零样本能力的新颖视图合成。然而，这种基于图像到图像转换的模型不能保证视图的一致性，这限制了诸如3D重建和图像到3D生成之类的下游任务的性能。为了增强一致性，我们提出了Consistent123，通过结合额外的跨视图注意力层和共享的自注意机制，同时合成新的视图。所提出的注意力机制改善了所有合成视图之间的交互，以及条件视图和新视图之间的一致性。在采样阶段，这种架构支持在以固定长度进行训练的同时同时生成任意数量的视图。我们还引入了一种渐进的无分类器引导策略，以实现合成对象视图的纹理和几何之间的权衡。定性和定量实验表明，Consistent123在视图一致性方面大大优于基线。此外，我们展示了Consistent123在不同下游任务上的显著改进，显示了其在3D生成领域的巨大潜力。项目页面位于consistent-123.github.io。 et.al.|[2310.08092](http://arxiv.org/abs/2310.08092)|null|
|**2023-10-11**|**rpcPRF: Generalizable MPI Neural Radiance Field for Satellite Camera**|卫星图像的新视图合成具有广泛的实际应用。虽然神经辐射场的最新进展主要针对针孔相机，而卫星相机的模型通常需要足够的输入视图。本文提出了一种用于有理多项式相机（RPC）的基于多平面图像（MPI）的平面神经辐射场rpcPRF。与需要一个场景的足够视图的基于坐标的神经辐射场不同，我们的模型适用于单个或少量输入，并且在来自看不见的场景的图像上表现良好。为了实现跨场景的泛化，我们建议使用重投影监督来诱导预测的MPI来学习3D坐标和图像之间的正确几何结构。此外，我们通过引入辐射场的绘制技术，消除了基于深度多视点立体的方法对密集深度监督的严格要求。rpcPRF结合了隐式表示的优势和RPC模型的优势，在学习三维结构的同时捕捉连续的高度空间。给定RGB图像及其相应的RPC，端到端模型学习将新视图与新的RPC合成，并重建场景的海拔高度。当提供多个视图作为输入时，rpcPRF施加由额外视图提供的额外监督。在ZY-3的TLC数据集和WV-3的城市场景的SatMVS3D数据集上，对于单视图和多视图任务，rpcPRF在图像保真度、重建精度和效率方面显著优于最先进的基于nerf的方法。 et.al.|[2310.07179](http://arxiv.org/abs/2310.07179)|null|
|**2023-10-06**|**Improving Neural Radiance Field using Near-Surface Sampling with Point Cloud Generation**|神经辐射场（NeRF）是一种新兴的视图合成方法，它对三维空间中的点进行采样，并估计它们的存在和颜色概率。NeRF的缺点是它需要很长的训练时间，因为它对许多3D点进行采样。此外，如果从遮挡区域或在不太可能存在对象的空间中采样点，则NeRF的渲染质量可能会降低。这些问题可以通过估计3D场景的几何形状来解决。本文提出了一种近表面采样框架来提高NeRF的渲染质量。为此，所提出的方法使用训练集的深度图像来估计3D对象的表面，并且仅在那里执行采样。为了获得新视图的深度信息，本文提出了一种三维点云生成方法和一种简单的点云投影深度细化方法。实验结果表明，与原始的NeRF和最先进的基于深度的NeRF方法相比，所提出的近表面采样NeRF框架可以显著提高渲染质量。此外，使用所提出的近表面采样框架，可以显著加快NeRF模型的训练时间。 et.al.|[2310.04152](http://arxiv.org/abs/2310.04152)|null|
|**2023-10-06**|**ILSH: The Imperial Light-Stage Head Dataset for Human Head View Synthesis**|本文介绍了Imperial Light Stage Head（ILSH）数据集，这是一个新颖的Light Stage捕获的人头数据集，旨在支持人头的视图合成学术挑战。ILSH数据集旨在促进各种方法，如场景特定或通用神经渲染、多视图几何、3D视觉和计算机图形学，以进一步推动照片逼真的人类化身的开发。本文详细介绍了专门用于捕捉高分辨率（4K）人头图像的光台的设置，并描述了在收集高质量数据时应对挑战（预处理、道德问题）的过程。除了数据收集之外，我们还将数据集拆分为训练集、验证集和测试集。我们的目标是为这个新的数据集设计和支持一个公平视图综合挑战任务，以便在使用测试集时，如在使用验证集时，可以保持和预期类似的性能水平。ILSH数据集由52名受试者组成，这些受试者使用24台相机拍摄，所有82个光源都打开，共产生1248张特写头部图像、边界遮罩和相机姿势对。 et.al.|[2310.03952](http://arxiv.org/abs/2310.03952)|null|
|**2023-10-05**|**Drag View: Generalizable Novel View Synthesis with Unposed Imagery**|我们介绍了DragView，这是一个新颖的交互式框架，用于生成看不见的场景的新颖视图。DragView从单个源图像初始化新视图，渲染由一组稀疏的未聚焦多视图图像支持，所有这些图像都在一个前馈过程中无缝执行。我们的方法从用户通过本地相对坐标系拖动源视图开始。像素对齐特征是通过将采样的3D点沿着目标射线投影到源视图上而获得的。然后，我们结合了一个与视图相关的调制层，以在投影过程中有效地处理遮挡。此外，我们将核极注意力机制扩展到包括所有源像素，有助于聚合来自其他未聚焦视图的初始化坐标对齐点特征。最后，我们使用另一个变换器将射线特征解码为最终的像素强度。至关重要的是，我们的框架既不依赖于2D先验模型，也不依赖于对相机姿态的明确估计。在测试过程中，DragView展示了将其推广到训练中看不见的新场景的能力，还仅使用未渲染的支持图像，从而能够生成以灵活的相机轨迹为特征的照片逼真的新视图。在我们的实验中，我们将DragView的性能与最近在无姿态条件下运行的场景表示网络以及在噪声测试相机姿态下的可推广NeRF进行了全面比较。DragView在视图合成质量方面始终如一地展示了其卓越的性能，同时也更加用户友好。项目页面：https://zhiwenfan.github.io/DragView/. et.al.|[2310.03704](http://arxiv.org/abs/2310.03704)|null|
|**2023-10-05**|**Point-Based Radiance Fields for Controllable Human Motion Synthesis**|本文提出了一种新的基于静态点辐射场的精细变形可控人体运动合成方法。尽管以前的可编辑神经辐射场方法可以在新的视图合成上产生令人印象深刻的结果，并允许天真变形，但很少有算法可以实现复杂的三维人体编辑，如正向运动学。我们的方法利用显式点云来训练静态3D场景，并通过使用变形MLP对点云平移进行编码来应用变形。为了确保渲染结果与规范空间训练一致，我们使用SVD估计局部旋转，并将每点旋转插值到预训练辐射场的查询视图方向。大量实验表明，我们的方法在精细复杂变形方面可以显著优于最先进的方法，该方法可以推广到除人类之外的其他3D角色。 et.al.|[2310.03375](http://arxiv.org/abs/2310.03375)|**[link](https://github.com/dehezhang2/point_based_nerf_editing)**|
|**2023-10-04**|**Consistent-1-to-3: Consistent Image to 3D View Synthesis via Geometry-aware Diffusion Models**|从单个图像中进行零样本新视图合成（NVS）是三维对象理解中的一个基本问题。尽管最近利用预先训练的生成模型的方法可以从野外输入中合成高质量的新视图，但它们仍然难以在不同视图之间保持3D一致性。在本文中，我们提出了Consistent-1-to-3，这是一个显著缓解这一问题的生成框架。具体来说，我们将NVS任务分解为两个阶段：（i）将观察到的区域转换为新的视图，以及（ii）对看不见的区域产生幻觉。我们设计了一个场景表示转换器和视图条件扩散模型，分别用于执行这两个阶段。在模型内部，为了增强三维一致性，我们建议使用六面体引导注意力来结合几何约束，并使用多视图注意力来更好地聚合多视图信息。最后，我们设计了一个层次生成范式来生成长序列的一致视图，允许对所提供的对象图像进行全方位的360度观察。对多个数据集的定性和定量评估证明了所提出的机制相对于最先进方法的有效性。我们的项目页面位于https://jianglongye.com/consistent123/ et.al.|[2310.03020](http://arxiv.org/abs/2310.03020)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-12**|**Implicit Shape and Appearance Priors for Few-Shot Full Head Reconstruction**|使用基于坐标的神经表示的学习技术的最新进展在多视图3D重建任务中产生了显著的结果。然而，这些方法通常需要大量的输入视图（通常为几十个）和计算密集型优化过程来实现其有效性。在本文中，我们专门针对少镜头全3D头部重建问题来解决这些限制。我们通过将概率形状和外观先验结合到基于坐标的表示中来实现这一点，从而在仅处理少数输入图像（甚至低至单个图像）时实现更快的收敛和改进的泛化。在测试过程中，我们利用这一点，然后使用可微分渲染器来指导有符号距离函数的拟合过程。通过将统计先验与可并行的光线跟踪和动态缓存策略相结合，我们实现了一种高效准确的少镜头全3D头部重建方法。此外，我们扩展了H3DS数据集，该数据集现在包括60个高分辨率3D全头扫描及其相应的姿势图像和遮罩，我们将其用于评估目的。通过利用这个数据集，我们展示了我们的方法在几何重建中实现最先进结果的非凡能力，同时比以前的方法快一个数量级。 et.al.|[2310.08784](http://arxiv.org/abs/2310.08784)|null|
|**2023-10-13**|**PonderV2: Pave the Way for 3D Foundation Model with A Universal Pre-training Paradigm**|与众多的NLP和2D计算机视觉基础模型相比，学习一个稳健且高度通用的3D基础模型带来了更大的挑战。这主要是由于固有的数据可变性和下游任务的多样性。在本文中，我们介绍了一个全面的3D预训练框架，旨在促进高效的3D表示的获取，从而建立一条通往3D基础模型的途径。基于信息丰富的3D特征应该能够编码丰富的几何形状和外观线索，这些线索可以用来渲染逼真的图像，我们提出了一种新的通用范式，通过可微分神经渲染来学习点云表示，作为3D和2D世界之间的桥梁。我们通过将渲染图像与真实图像进行比较，在设计的体积神经渲染器中训练点云编码器。值得注意的是，我们的方法展示了将学习的3D编码器无缝集成到各种下游任务中。这些任务不仅包括3D检测和分割等高级别挑战，还包括3D重建和图像合成等低级别目标，涵盖室内和室外场景。此外，我们还说明了使用所提出的通用方法对2D主干进行预训练的能力，大大超过了传统的预训练方法。PonderV2首次在11个室内和室外基准上实现了最先进的性能。在各种情况下的持续改进表明了所提出方法的有效性。代码和型号将在https://github.com/OpenGVLab/PonderV2. et.al.|[2310.08586](http://arxiv.org/abs/2310.08586)|**[link](https://github.com/OpenGVLab/PonderV2)**|
|**2023-10-12**|**Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video**|自监督学习释放了将预训练扩展到数十亿张图像的潜力，因为注释是不必要的。但我们是否充分利用了数据？我们能节约多少？在这项工作中，我们试图通过作出两项贡献来回答这个问题。首先，我们调查了第一人称视频，并介绍了一个“徒步旅行”数据集。这些视频是高分辨率的，长达数小时，在一次不间断的拍摄中捕捉到，描绘了大量具有自然场景转换的物体和动作。它们是未标记和未评级的，因此对于自我监督来说是现实的，并且可以与人类的学习相比较。其次，我们介绍了一种新的自监督图像预训练方法，该方法专为从连续视频中学习而设计。现有的方法通常采用基于图像的预训练方法来合并更多的帧。相反，我们提倡一种“跟踪以学会识别”的方法。我们的方法称为DoRA，它使用转换器交叉注意力，以端到端的方式生成注意图，发现和tRAck对象。我们从轨迹中导出多个视图，并将它们用于经典的自监督蒸馏损失。使用我们的新方法，一个徒步旅行视频显著地成为ImageNet在几个图像和视频下游任务中的强大竞争对手。 et.al.|[2310.08584](http://arxiv.org/abs/2310.08584)|null|
|**2023-10-12**|**Consistent123: Improve Consistency for One Image to 3D Object Synthesis**|大图像扩散模型能够实现具有高质量和优异的零样本能力的新颖视图合成。然而，这种基于图像到图像转换的模型不能保证视图的一致性，这限制了诸如3D重建和图像到3D生成之类的下游任务的性能。为了增强一致性，我们提出了Consistent123，通过结合额外的跨视图注意力层和共享的自注意机制，同时合成新的视图。所提出的注意力机制改善了所有合成视图之间的交互，以及条件视图和新视图之间的一致性。在采样阶段，这种架构支持在以固定长度进行训练的同时同时生成任意数量的视图。我们还引入了一种渐进的无分类器引导策略，以实现合成对象视图的纹理和几何之间的权衡。定性和定量实验表明，Consistent123在视图一致性方面大大优于基线。此外，我们展示了Consistent123在不同下游任务上的显著改进，显示了其在3D生成领域的巨大潜力。项目页面位于consistent-123.github.io。 et.al.|[2310.08092](http://arxiv.org/abs/2310.08092)|null|
|**2023-10-12**|**RT-SRTS: Angle-Agnostic Real-Time Simultaneous 3D Reconstruction and Tumor Segmentation from Single X-Ray Projection**|放射治疗是肿瘤的主要治疗方法之一，但呼吸运动引起的器官运动限制了其准确性。近年来，单X射线投影三维成像作为解决这一问题的一种很有前途的方法受到了广泛的关注。然而，目前的方法只能在没有直接定位肿瘤的情况下重建3D图像，并且只能在固定角度成像中进行验证，无法完全满足放疗中运动控制的要求。在本研究中，我们提出了一种新的成像方法RT-SRTS，该方法基于多任务学习（MTL）将3D成像和肿瘤分割集成到一个网络中，并从任何角度的单个X射线投影中实现实时同步的3D重建和肿瘤分割。此外，我们提出了注意力增强校准器（AEC）和不确定区域细化（URE）模块来帮助特征提取和提高分割精度。我们对10例患者进行了评估，并将其与两种最先进的方法进行了比较。我们的方法不仅提供了卓越的3D重建，而且还展示了值得称赞的肿瘤分割结果。同时重建和分割可以在大约70ms内完成，明显快于实时肿瘤跟踪所需的时间阈值。AEC和URE的疗效也通过消融研究得到了验证。 et.al.|[2310.08080](http://arxiv.org/abs/2310.08080)|null|
|**2023-10-11**|**Orbital Polarimetric Tomography of a Flare Near the Sagittarius A* Supermassive Black Hole**|银河系中心的超大质量黑洞人马座A $^*$ 与其吸积盘之间的相互作用，偶尔会在X射线、红外和无线电中产生高能耀斑。观测到的耀斑的一种机制是在吸积盘中靠近事件视界形成致密明亮区域。了解这些耀斑可以为了解黑洞吸积过程提供一个窗口。尽管复杂的模拟预测了这些耀斑的形成，但它们的结构尚待观测恢复。在这里，我们展示了从2017年4月11日观测到的ALMA光曲线中恢复的轨道上发射耀斑的首次三维（3D）重建。我们的恢复结果显示，在大约6倍视界的距离处有致密的明亮区域。此外，我们的恢复表明，在低倾角轨道平面上顺时针旋转，这一结果与EHT和GRAVITY合作的先前研究一致。为了恢复这种发射结构，我们通过将神经3D表示（一种新兴的3D重建人工智能方法）与黑洞引力模型相结合，解决了一个高度不适定的层析成像问题。尽管恢复的3D结构受模型假设的影响，有时也很敏感，但在物理激励的选择下，我们发现我们的结果是稳定的，我们的方法在模拟数据上是成功的。我们预计，在未来，这种方法可以用于分析更丰富的时间序列数据，这些数据可以揭示黑洞和等离子体动力学的机制。 et.al.|[2310.07687](http://arxiv.org/abs/2310.07687)|null|
|**2023-10-11**|**rpcPRF: Generalizable MPI Neural Radiance Field for Satellite Camera**|卫星图像的新视图合成具有广泛的实际应用。虽然神经辐射场的最新进展主要针对针孔相机，而卫星相机的模型通常需要足够的输入视图。本文提出了一种用于有理多项式相机（RPC）的基于多平面图像（MPI）的平面神经辐射场rpcPRF。与需要一个场景的足够视图的基于坐标的神经辐射场不同，我们的模型适用于单个或少量输入，并且在来自看不见的场景的图像上表现良好。为了实现跨场景的泛化，我们建议使用重投影监督来诱导预测的MPI来学习3D坐标和图像之间的正确几何结构。此外，我们通过引入辐射场的绘制技术，消除了基于深度多视点立体的方法对密集深度监督的严格要求。rpcPRF结合了隐式表示的优势和RPC模型的优势，在学习三维结构的同时捕捉连续的高度空间。给定RGB图像及其相应的RPC，端到端模型学习将新视图与新的RPC合成，并重建场景的海拔高度。当提供多个视图作为输入时，rpcPRF施加由额外视图提供的额外监督。在ZY-3的TLC数据集和WV-3的城市场景的SatMVS3D数据集上，对于单视图和多视图任务，rpcPRF在图像保真度、重建精度和效率方面显著优于最先进的基于nerf的方法。 et.al.|[2310.07179](http://arxiv.org/abs/2310.07179)|null|
|**2023-10-10**|**SketchBodyNet: A Sketch-Driven Multi-faceted Decoder Network for 3D Human Reconstruction**|由于其对许多高级3D应用的基本支持，从2D图像重建3D人形最近受到了越来越多的关注。与自然图像相比，徒手草图更灵活地描绘各种形状，为三维人体重建提供了一种极具潜力和价值的方法。然而，这样的任务极具挑战性。草图的稀疏抽象特性给二维到三维重建已经很不适定的问题增加了严重的困难，如任意性、不准确和缺乏图像细节。尽管目前的方法在从单视图图像重建三维人体方面取得了巨大成功，但在徒手草图上效果不佳。在本文中，我们提出了一种新的草图驱动的多面解码器网络SketchBodyNet来解决这一任务。具体而言，该网络由一个主干和三个独立的注意力解码器分支组成，其中每个解码器中利用一个多头自注意力模块来获得增强的特征，然后是多层感知器。多面解码器的目的是分别预测相机、形状和姿态参数，然后将其与SMPL模型相关联，以重建相应的3D人体网格。在学习中，通过相机参数将现有的三维网格投影到具有关节的二维合成草图中，这些草图与徒手草图相结合以优化模型。为了验证我们的方法，我们收集了一个由大约26k个徒手草图及其相应的3D网格组成的大规模数据集，其中包含14个不同角度的人体各种姿势。大量的实验结果表明，我们的SketchBodyNet在从徒手草图重建三维人体网格方面取得了卓越的性能。 et.al.|[2310.06577](http://arxiv.org/abs/2310.06577)|null|
|**2023-10-08**|**Experiences with CAMRE: Single-Device Collaborative Adaptive Mixed Reality Environment**|在XR（扩展现实）中的协作过程中，用户通常在公共共享虚拟环境中共享虚拟对象并与之交互。具体来说，在混合现实（MR）中，用户之间的协作需要了解他们的位置、运动和对物理环境周围视觉场景的理解。否则，一个用户可以将一个重要的虚拟对象移动到被物理环境阻挡的位置。然而，即使对于单个物理环境，3D重建也需要很长时间，并且所产生的3D数据的大小通常非常大。此外，这些大量的3D数据需要很长时间才能流式传输到接收器，这使得对渲染场景的实时更新具有挑战性。此外，MR中的许多协作系统需要多个设备，这占用空间并使设置变得困难。为了应对这些挑战，在本文中，我们描述了一个名为协作自适应混合现实环境（CAMRE）的单设备系统。我们使用HoloLens 2设备的场景理解功能构建CAMRE，为每个连接的用户创建共享的MR虚拟环境，并使用Leader-Follower（s）范式进行演示：由于数据较小，重建和场景更新时间更快。因此，多个用户可以根据他们的物理位置和移动，从选定的Leader接收共享的、同步的、接近实时延迟的虚拟场景。我们还展示了CAMRE MR虚拟环境的其他扩展功能，如使用实时虚拟迷你地图的导航和用于处理自适应墙不透明度的X射线视觉。我们分享了几个实验结果，这些结果评估了CAMRE在共享虚拟对象和其他功能时的网络延迟方面的性能。 et.al.|[2310.04996](http://arxiv.org/abs/2310.04996)|null|
|**2023-10-06**|**Towards Non-contact 3D Ultrasound for Wrist Imaging**|目的：这项工作的目的是尝试在现有的护理点超声（POCUS）系统的基础上，以最小的复杂性实现非接触式徒手三维超声成像。方法：本研究提出了一种使用机械轨道进行非接触超声（US）扫描的新方法。因此，该方法将探针运动限制在线性平面上，以简化采集和3D重建过程。开发了一种利用美国研究平台和基于GPU的边缘设备进行美国3D体积重建的管道。结果：通过离体和体内实验证明了该方法的有效性。结论：所提出的方法具有可调节的视场能力、非接触式设计和低部署成本，而不会显著改变现有设置，这将为传统系统的升级打开大门，使其能够应用于广泛的3D US成像。意义：超声（US）成像是一种流行的临床成像方式，用于护理点床边成像，尤其是儿科人群的手腕/膝盖，因为其具有非侵入性和无辐射性。然而，在这种情况下，用2D US获得的组织结构的有限视图使诊断具有挑战性。为了克服这一点，开发了使用2D US图像及其方向/位置来重建3D体积的3D US成像。在三维重建中，以低成本精确估计美国探测器的位置一直是一项具有挑战性的任务。此外，US成像涉及接触，这会给儿科受试者在监测活骨折或开放性伤口时带来困难。为了克服这些挑战，本工作尝试了一种新颖的框架。 et.al.|[2310.04296](http://arxiv.org/abs/2310.04296)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-13**|**Driven transport of active particles through arrays of symmetric obstacles**|我们数值研究了过阻尼自行推进粒子通过二维圆形障碍物阵列的驱动传输。已经对两种类型的通道（通道I和通道II）进行了输运量化器（迁移率和扩散率）的详细分析，这两种通道分别对应于相对于阵列轴的平行和对角驱动。我们的模拟结果表明，障碍物阵列中的钉扎作用和脱钉过程的特征表现为过量的扩散峰或扩散率的突然下降，以及随着驱动幅度的变化而出现的迁移率的突然跳跃。潜在的脱毛机制和相关的阈值驱动强度在很大程度上取决于自推进的持续长度。对于低驱动强度，无论自推进参数和驱动方向如何，扩散率和机动性都会受到障碍物阵列的显著抑制。当自推进长度大于通道隔间尺寸时，传输量化器对旋转弛豫时间不敏感。具有对角驱动的运输具有依赖于自推进的负差移动性。主动粒子负微分迁移率的振幅比被动粒子大得多。本分析旨在了解细菌、病毒、Janus颗粒等活性物质在多孔介质中的驱动传输。 et.al.|[2310.09272](http://arxiv.org/abs/2310.09272)|null|
|**2023-10-13**|**Hypernymy Understanding Evaluation of Text-to-Image Models via WordNet Hierarchy**|由于质量的快速提高和大量的实际应用，文本到图像合成最近引起了广泛的关注。然而，文本到图像模型的语言理解能力仍然不太清楚，这使得很难推理出给定模型能够很好理解的即时公式。在这项工作中，我们测量了流行的文本到图像模型理解 $\textit{hypernymy}$ 或单词之间的“is-a”关系的能力。我们设计了两个基于WordNet语义层次结构和在ImageNet上预训练的现有图像分类器的自动度量。这些指标既能对文本到图像模型的语言能力进行广泛的定量比较，又能找到细粒度的定性差异，例如模型不知道的单词，因此很难绘制。我们全面评估了流行的文本到图像模型，包括GLIDE、潜在扩散和稳定扩散，展示了我们的指标如何更好地了解这些模型的各个优势和劣势。 et.al.|[2310.09247](http://arxiv.org/abs/2310.09247)|**[link](https://github.com/yandex-research/text-to-img-hypernymy)**|
|**2023-10-13**|**Unseen Image Synthesis with Diffusion Models**|虽然生成领域的当前趋势是向更大的模型和更多的广义域表示训练数据扩展，但我们在这项工作中走了相反的方向，在没有额外训练的情况下合成了看不见的域图像。我们通过在单域数据集上使用预训练和冻结的去噪扩散概率模型（DDPM）进行潜在采样和几何优化来实现这一点。我们的关键观察结果是，即使仅在单域图像上预训练的DDPM也已经具备了足够的表示能力，可以根据双向确定性扩散和去噪轨迹从反向潜在编码中重建任意图像。这促使我们研究来自去噪链上潜在空间中看不见的图像域的分布外（OOD）样本的统计和几何行为。值得注意的是，我们从理论和经验上表明，反向OOD样本也建立了与中间潜在空间中的原始In Domain（ID）样本不同的高斯，这使我们能够直接从中进行采样。不可见子空间的几何域特定和模型相关信息（例如，逐样本距离和角度）用于进一步优化来自估计的高斯先验的采样OOD潜在编码。我们在不同的数据集（AFHQ、CelebA HQ、LSUN Church和LSUN Bedroom）上使用预先训练的扩散模型（DDPM、iDDPM）进行了广泛的分析和实验，证明了这种新视角对探索和重新思考扩散模型的数据综合泛化能力的有效性。 et.al.|[2310.09213](http://arxiv.org/abs/2310.09213)|null|
|**2023-10-13**|**The effect of solar wind on the charged particles' diffusion coefficients**|高能带电粒子通过磁化等离子体的传输在行星际空间和天体物理学中普遍存在，重要的物理量是高能带电粒子的沿场和跨场空间扩散系数。本文研究了太阳风对粒子输运的影响。利用聚焦方程，我们得到了考虑太阳风效应的沿场和跨场扩散系数。在不同的条件下，研究了太阳风效应对扩散的相对重要性。结果表明，当高能带电粒子靠近太阳时，沿场扩散需要考虑太阳风效应。这些结果对于研究太阳附近高能带电粒子的输运过程具有重要意义。 et.al.|[2310.09211](http://arxiv.org/abs/2310.09211)|null|
|**2023-10-13**|**BIPP: An efficient HPC implementation of the Bluebild algorithm for radio astronomy**|Bluebild算法是射电天文学中一种新的图像合成技术，它利用采样和插值算子的理论对天空强度函数进行最小二乘估计。我们提出了用于无线电干涉成像的Bluebild算法的HPC实现：Bluebild imaging++（BIPP）。BIPP是一种球形成像器，利用功能PCA将天空分解为不同的能级。该库具有C++、C和Python的接口，设计时考虑到了无缝GPU加速。我们在即将到来的平方公里阵列天文台的模拟观测和低频阵列（LOFAR）望远镜的真实数据上评估了BIPP的准确性和性能。我们发现，BIPP提供了精确的宽场成像，而不需要w项近似，并且相对于干涉成像库CASA和WSClean具有可比的执行时间。此外，由于能级分解，使用BIPP生成的图像可以在任何清洁迭代之前揭示关于微弱和漫射结构的信息。BIPP的源代码已公开发布。 et.al.|[2310.09200](http://arxiv.org/abs/2310.09200)|null|
|**2023-10-13**|**SUPG-stabilized stabilization-free VEM: a numerical investigation**|我们数值研究了在平流主导区域中定义平流-扩散问题的无稳定虚拟单元（VEM）离散化的可能性。为此，我们考虑了该方案的SUPG稳定公式。将所提出的方法与标准VEM进行比较的数值测试表明，由于缺乏额外的任意稳定项（VEM格式的典型项），即在离散解中添加人工扩散，因此可以更好地近似边界层，特别是在低阶格式的情况下。 et.al.|[2310.09180](http://arxiv.org/abs/2310.09180)|null|
|**2023-10-13**|**Galactic Gamma-Ray Diffuse Emission at TeV energies with HAWC Data**|银河伽马射线扩散发射（GDE）是由宇宙射线（CR）、超相对论质子和电子发射的，与星际介质中的气体和电磁辐射场相互作用。在这里，我们使用高空水切伦科夫（HAWC）探测器收集的数据，对经度为 $l\in[43^\circ]$ 的银河平面区域的TeV扩散发射进行了分析。显示了TeV扩散发射的光谱、纵向和横向分布。辐射光谱与CR群体产生的发射光谱兼容，其“指数”与观测到的CR相似。与\texttt｛DRAGON｝\textit｛基本模型｝相比，HAWC-GDE通量高出约2倍。脉冲星风星云和TeV晕等未解决的来源可以解释过量发射的原因。最后，银河系CR通量与局部测量的CR通量的偏差可以额外解释预测的和测量的扩散通量之间的差异。 et.al.|[2310.09117](http://arxiv.org/abs/2310.09117)|null|
|**2023-10-13**|**From Maximum of Intervisit Times to Starving Random Walks**|最近，引入并分析了一种基本的可观测结果，以量化随机行走的探索：当行走已经访问了 $k$个不同的站点时，随机行走找到以前从未访问过的站点所需的时间$\tau_k$。在这里，我们解决$M_n$的统计的自然问题，$\tau_0，\dots，\tau_{n-1}$中持续时间最长的一个。该问题属于极值统计的活跃领域，其困难在于随机变量$\tau_k$既相关又非同分布。除了这个基本方面之外，我们还证明了$M_n$统计量的渐近确定在觅食理论中有明确的应用，并使我们能够解决开放$d$维饥饿随机行走问题，在该问题中，晶格的每个位置最初包含一个食物单元，在随机行走者访问时消耗，它在饥饿前可以在没有食物的情况下走$\mathcal{S}$ 步。不同性质的过程，包括规则扩散、异常扩散、无序介质和分形中的扩散，在相同的普遍性类别中具有共同的性质。 et.al.|[2310.09082](http://arxiv.org/abs/2310.09082)|null|
|**2023-10-13**|**Methods for Averaging Spectral Line Data**|理想的光谱平均方法取决于一个人的科学目标和关于一个人数据的可用信息。在平均值中包括低质量数据会降低信噪比（SNR），这可能需要优化方法或考虑不同的加权方案。在这里，我们探索了各种光谱平均方法。我们研究了在平均过程中使用三种加权方案：通过信号除以方差进行加权（“强度噪声加权”）、通过方差的倒数进行加权（”噪声加权“）和均匀加权。对于强度噪声加权，当对所有频谱进行平均时，SNR最大化，而对于噪声和均匀加权，我们发现对具有最高SNR的35-45%的频谱进行平均会产生最高SNR平均频谱。通过这种强度截止，具有噪声或均匀加权的平均频谱的强度约为强度噪声加权产生的频谱强度的95%。我们将我们的光谱平均方法应用于GBT扩散电离气体（GDIGS）氢-无线电复合线（RRL）数据，以确定离子丰度比y+，并讨论该方法的未来应用。 et.al.|[2310.09076](http://arxiv.org/abs/2310.09076)|null|
|**2023-10-13**|**Mechanisms of temperature-dependent thermal transport in amorphous silica from machine-learning molecular dynamics**|非晶二氧化硅（a-SiO $_2$）是一种基础无序材料，其热输运性质在各种应用中都很重要。为了准确地模拟a-SiO$_2$中热输运的经典分子动力学（MD）模拟中的原子间相互作用，我们在此开发了一个准确但高效的机器学习势模型，使我们能够生成与实验产生的样品非常相似的a-SiO$_2$样品。使用均匀非平衡MD方法和对经典MD结果的适当量子统计校正，在宽温度范围内获得了体相和190nm厚a-SiO_2$薄膜的热导率与实验的定量一致。为了询问不同温度下的热振动，我们计算了与横向声学（TA）和纵向声学（LA）集体振动相对应的电流相关函数。结果表明，在Ioffe-Regel交叉频率以下，声子作为定义明确的激发，仍然适用于a-SiO$_2$，并在低温下发挥主要作用，导致热导率随温度而增加。在高温区域，更多的声子被激发，伴随着更强烈的类液体扩散事件。我们将a-SiO$_2$高温范围内与温度无关的热导率归因于热传导中激发的声子散射和类液体扩散的协同参与。这些发现为a-SiO$_2$ 的热传输提供了物理见解，并有望应用于广泛的非晶材料。 et.al.|[2310.09062](http://arxiv.org/abs/2310.09062)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-12**|**S4C: Self-Supervised Semantic Scene Completion with Neural Fields**|三维语义场景理解是计算机视觉中的一个基本挑战。它使移动代理能够自主规划和导航任意环境。SSC将这一挑战形式化为从场景的稀疏观测中联合估计密集的几何结构和语义信息。当前的SSC方法通常基于聚合的激光雷达扫描在3D地面实况上进行训练。这一过程依赖于特殊的传感器和手工注释，这些传感器和注释成本高昂且规模不大。为了克服这个问题，我们的工作提出了第一种称为S4C的SSC自监督方法，该方法不依赖于3D地面实况数据。我们提出的方法可以从单个图像重建场景，并且只依赖于训练期间从现成的图像分割网络生成的视频和伪分割地面实况。与使用离散体素网格的现有方法不同，我们将场景表示为隐式语义场。该公式允许查询相机截锥体内的任何点的占用率和语义类。我们的架构是通过基于渲染的自监督损失进行训练的。尽管如此，我们的方法实现了接近于完全监督的最先进方法的性能。此外，我们的方法表现出强大的泛化能力，可以为遥远的视点合成准确的分割图。 et.al.|[2310.07522](http://arxiv.org/abs/2310.07522)|null|
|**2023-10-07**|**HI-SLAM: Monocular Real-time Dense Mapping with Hybrid Implicit Fields**|在这封信中，我们提出了一个基于神经场的实时单目映射框架，用于精确和密集的同时定位和映射（SLAM）。最近的神经映射框架显示出有希望的结果，但依赖于RGB-D或姿势输入，或者无法实时运行。为了解决这些局限性，我们的方法将密集SLAM与神经隐式场相结合。具体来说，我们的密集SLAM方法运行并行跟踪和全局优化，而基于神经场的映射是基于最新的SLAM估计逐步构建的。为了有效地构造神经场，我们采用了多分辨率网格编码和符号距离函数（SDF）表示。这使我们能够始终保持地图的最新状态，并通过循环关闭立即适应全球更新。为了全局一致性，我们提出了一种有效的基于Sim（3）的姿态图束调整（PGBA）方法来运行在线闭环并减轻姿态和尺度漂移。为了进一步提高深度精度，我们结合了学习的单目深度先验。我们提出了一种新的深度和尺度联合调整（JDSA）模块来解决深度先验中固有的尺度模糊性。对合成和真实世界数据集的广泛评估验证了我们的方法在准确性和地图完整性方面优于现有方法，同时保持了实时性能。 et.al.|[2310.04787](http://arxiv.org/abs/2310.04787)|null|
|**2023-10-05**|**Variational Barycentric Coordinates**|我们提出了一种变分技术来优化广义重心坐标，与现有模型相比，该技术提供了额外的控制。先前的工作使用网格或闭式公式表示重心坐标，在实践中限制了目标函数的选择。相反，我们使用神经场直接参数化连续函数，该函数将多面体内部的任何坐标映射到其重心坐标。这个公式是通过我们对重心坐标的理论表征实现的，这使我们能够构建将有效坐标的整个函数类参数化的神经场。我们使用各种目标函数展示了我们模型的灵活性，包括多重光滑性和变形感知能量；作为补充，我们还提出了数学上合理的方法来测量和最小化目标，如不连续神经场的总变化。我们提供了一个实用的加速策略，对我们的算法进行了彻底的验证，并展示了几个应用。 et.al.|[2310.03861](http://arxiv.org/abs/2310.03861)|null|
|**2023-10-05**|**High-Degrees-of-Freedom Dynamic Neural Fields for Robot Self-Modeling and Motion Planning**|机器人自模型是机器人物理形态的任务不可知表示，在没有经典几何运动学模型的情况下，可用于运动规划任务。特别是，当后者难以设计或机器人的运动学发生意外变化时，人类自由的自我建模是真正自主智能体的必要特征。在这项工作中，我们利用神经场使机器人能够将其运动学自建模为仅从带有相机姿势和配置的2D图像中学习的神经隐式查询模型。这使得比依赖于深度图像或几何知识的现有方法具有更大的适用性。为此，除了课程数据采样策略外，我们还提出了一种新的基于编码器的神经密度场架构，用于高自由度（DOF）条件下的动态对象中心场景。在7自由度机器人测试装置中，学习的自模型实现了机器人工作空间尺寸2%的倒角-L2距离。作为一个示例性的下游应用程序，我们展示了该模型在运动规划任务中的能力。 et.al.|[2310.03624](http://arxiv.org/abs/2310.03624)|null|
|**2023-10-02**|**Neural Processing of Tri-Plane Hybrid Neural Fields**|在用于存储和通信3D数据的神经场的吸引人的特性的驱动下，直接处理它们以解决分类和零件分割等任务的问题已经出现，并在最近的工作中进行了研究。早期的方法使用由在整个数据集上训练的共享网络参数化的神经场，实现了良好的任务性能，但牺牲了重建质量。为了改进后者，后来的方法侧重于参数化为大型多层感知器（MLP）的单个神经场，然而，由于权重空间的高维性、固有的权重空间对称性和对随机初始化的敏感性，这些神经元场的处理具有挑战性。因此，结果明显不如通过处理显式表示（例如点云或网格）所获得的结果。与此同时，混合表示，特别是基于三平面的混合表示，已经成为实现神经场的一种更有效的替代方案，但其直接处理尚未得到研究。在本文中，我们证明了三平面离散数据结构编码了丰富的信息，标准的深度学习机器可以有效地处理这些信息。我们定义了一个广泛的基准，涵盖了一组不同的字段，如占用率、有符号/无符号距离，以及首次定义的辐射字段。在处理具有相同重建质量的字段时，我们实现的任务性能远远优于处理大型MLP的框架，并且首次几乎与处理显式表示的架构不相上下。 et.al.|[2310.01140](http://arxiv.org/abs/2310.01140)|null|
|**2023-09-27**|**Neural Acoustic Context Field: Rendering Realistic Room Impulse Response With Neural Fields**|房间脉冲响应（RIR）测量声音在环境中的传播，对于合成给定环境下的高保真音频至关重要。一些先前的工作已经提出将RIR表示为声音发射器和接收器位置的神经场函数。然而，这些方法没有充分考虑音频场景的声学特性，导致性能不令人满意。这封信提出了一种新的神经声学上下文场方法，称为NACF，通过利用多个声学上下文（如几何结构、材料特性和空间信息）来参数化音频场景。在RIR的独特性质，即时间不光滑性和单调能量衰减的驱动下，我们设计了一个时间相关模块和多尺度能量衰减准则。实验结果表明，NACF的性能显著优于现有的基于字段的方法。请访问我们的项目页面了解更多定性结果。 et.al.|[2309.15977](http://arxiv.org/abs/2309.15977)|null|
|**2023-09-27**|**SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations**|隐式神经表示（INR）或神经场已成为编码多媒体信号（如图像和辐射场）同时保持高质量的流行框架。最近，Instant NGP提出的可学习特征网格通过用特征向量的多分辨率查找表和更小的神经网络取代大型神经网络，在训练和INR采样方面实现了显著的加速。然而，这些功能网格是以大量内存消耗为代价的，这可能是存储和流应用程序的瓶颈。在这项工作中，我们提出了SHACIRA，这是一个简单而有效的任务无关框架，用于压缩这种特征网格，而不需要额外的事后修剪/量化阶段。我们用量化的潜在权重对特征网格进行重新参数化，并在潜在空间中应用熵正则化，以在各个领域实现高水平的压缩。在由图像、视频和辐射场组成的不同数据集上的定量和定性结果表明，我们的方法优于现有的INR方法，而不需要任何大型数据集或特定领域的启发式方法。我们的项目页面可在http://shacira.github.io。 et.al.|[2309.15848](http://arxiv.org/abs/2309.15848)|null|
|**2023-09-27**|**NeuRBF: A Neural Fields Representation with Adaptive Radial Basis Functions**|我们提出了一种新型的神经场，它使用一般的径向基来表示信号。现有技术的神经领域通常依赖于用于存储局部神经特征的基于网格的表示和用于在连续查询点处插值特征的N维线性核。它们的神经特征的空间位置固定在网格节点上，不能很好地适应目标信号。相反，我们的方法建立在具有灵活内核位置和形状的通用径向基上，这些径向基具有更高的空间自适应性，可以更紧密地拟合目标信号。为了进一步提高径向基函数的信道容量，我们建议将它们与多频率正弦函数组合。该技术将径向基扩展到不同频带的多个傅立叶径向基，而不需要额外的参数，便于细节的表示。此外，通过将自适应径向基与基于网格的径向基相结合，我们的混合组合继承了自适应性和插值平滑性。我们精心设计了加权方案，使径向基有效地适应不同类型的信号。我们在2D图像和3D符号距离场表示上的实验证明了我们的方法比现有技术更高的精度和紧凑性。当应用于神经辐射场重建时，我们的方法实现了最先进的渲染质量，模型大小小，训练速度相当。 et.al.|[2309.15426](http://arxiv.org/abs/2309.15426)|**[link](https://github.com/oppo-us-research/NeuRBF)**|
|**2023-09-29**|**3D Reconstruction with Generalizable Neural Fields using Scene Priors**|由于神经领域的最新进展，高保真3D场景重建得到了实质性的推进。然而，大多数现有的方法为每个单独的场景从头开始训练单独的网络。这是不可扩展的，效率低下，并且在视图有限的情况下无法产生良好的结果。虽然基于学习的多视图立体方法在一定程度上缓解了这一问题，但它们的多视图设置使其扩展和广泛应用的灵活性降低。相反，我们引入了结合场景先验（NFP）的训练可推广神经场。NFP网络将任何单视图RGB-D图像映射为带符号的距离和辐射值。在没有融合模块的情况下，可以通过合并体积空间中的各个帧来重建完整的场景，这提供了更好的灵活性。场景先验可以在大规模数据集上进行训练，从而能够快速适应具有较少视图的新场景的重建。NFP不仅展示了SOTA场景重建的性能和效率，而且还支持单图像新视图合成，这在神经领域还没有得到充分的探索。更多定性结果可在以下网站获得：https://oasisyang.github.io/neural-prior et.al.|[2309.15164](http://arxiv.org/abs/2309.15164)|null|
|**2023-09-22**|**NOC: High-Quality Neural Object Cloning with 3D Lifting of Segment Anything**|随着神经领域的发展，从多视图输入重建目标物体的3D模型最近越来越受到社会的关注。现有的方法通常学习整个场景的神经场，而如何在飞行中重建用户指示的特定对象仍在探索之中。考虑到分段任意模型（SAM）在分割任何2D图像方面都显示出了有效性，本文提出了一种新的高质量3D对象重建方法——神经对象克隆（NOC），它从两个方面利用了神经场和SAM的优点。首先，为了将目标对象从场景中分离出来，我们提出了一种新的策略，将SAM的多视图2D分割掩模提升到一个统一的3D变化场中。然后，3D变化场被投影到2D空间中，并生成SAM的新提示。这个过程是迭代的，直到收敛，以将目标对象从场景中分离出来。然后，除了2D掩模之外，我们进一步将SAM编码器的2D特征提升到3D SAM场中，以提高目标对象的重建质量。NOC将SAM的2D掩模和特征提升到3D神经场中，用于高质量的目标对象重建。我们在几个基准数据集上进行了详细的实验，以证明我们的方法的优势。代码将被发布。 et.al.|[2309.12790](http://arxiv.org/abs/2309.12790)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

