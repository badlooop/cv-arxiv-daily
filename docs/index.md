---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.03.19
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-03-18**|**Just Add $100 More: Augmenting NeRF-based Pseudo-LiDAR Point Cloud for Resolving Class-imbalance Problem**|典型的基于激光雷达的3D对象检测模型是以有监督的方式与真实世界的数据收集一起训练的，这通常是不平衡的（或长尾的）。为了解决这个问题，通常使用通过从数据库中采样地面实况（GT）激光雷达点并将其粘贴到感兴趣的场景来增强少数类示例，但挑战仍然存在：定位GT样本的灵活性和样本多样性有限。在这项工作中，我们建议利用伪激光雷达点云（以低成本），该点云是从捕捉小类微缩模型或真实世界对象的环绕视图的视频中生成的。我们的方法被称为伪地面实况增强（PGT-Aug），由三个主要步骤组成：（i）使用2D到3D视图合成模型的体积3D实例重建，（ii）使用激光雷达强度估计的物体级域对齐，以及（iii）根据地面和地图信息的混合上下文感知放置方法。我们通过在三个流行的基准（即nuScenes、KITTI和Lyft）上进行的大量实验中的性能改进，证明了我们方法的优越性和通用性，特别是对于不同激光雷达配置捕获的具有大域间隙的数据集。我们的代码和数据将在发布后公开。 et.al.|[2403.11573](http://arxiv.org/abs/2403.11573)|null|
|**2024-03-18**|**Diffusion Models are Geometry Critics: Single Image 3D Editing Using Pre-Trained Diffusion Priors**|我们提出了一种新颖的图像编辑技术，可以对单个图像进行3D操作，如对象旋转和平移。现有的3D感知图像编辑方法通常依赖于合成的多视图数据集来训练专门的模型，从而限制了它们在具有明显更多样的布局和风格的开放域图像上的有效性。相反，我们的方法直接利用了在广泛的文本-图像对上训练的强大的图像扩散模型，从而保持了它们非凡的泛化能力。这一目标是通过开发一种迭代的新视图合成和几何对齐算法来实现的。该算法利用扩散模型有两个目的：它们通过使用估计的深度图预测所选对象的新视图来提供外观先验，并且它们通过校正采样视图中3D形状的错位来充当几何批评家。我们的方法可以生成高质量的3D感知图像编辑，具有大的视点变换和与输入图像的高外观和形状一致性，突破了单图像3D感知编辑的可能范围。 et.al.|[2403.11503](http://arxiv.org/abs/2403.11503)|null|
|**2024-03-18**|**Bridging 3D Gaussian and Mesh for Freeview Video Rendering**|这只是GauMesh的预览版本。最近，基于基元的渲染已被证明在解决从2D图像建模和渲染3D动态场景的问题方面取得了令人信服的结果。尽管如此，在小说视角综合的背景下，每一种原语在表现能力方面都有其固有的缺陷。利用网格来描述模糊几何是很困难的。同时，基于点的飞溅（例如，3D高斯飞溅）方法通常会在具有平滑几何形状和清晰纹理的区域中产生伪影或模糊像素。因此，很难，甚至不是不可能，用单一类型的图元来表示复杂而动态的场景。为此，我们提出了一种新的方法，GauMesh，来桥接3D高斯和Mesh，用于动态场景的建模和渲染。给定一系列跟踪网格作为初始化，我们的目标是同时优化网格几何体、颜色纹理、不透明度贴图、一组3D高斯和变形场。在特定的时间，我们基于网格和3D高斯光栅化的合并和重新排序的z缓冲区，对RGB和不透明度值执行 $\alpha$ 混合。这将生成最终渲染，该渲染由地面实况图像进行监督。实验表明，我们的方法采用了适当类型的基元来表示动态场景的不同部分，并且在定量和定性比较方面都优于所有基线方法，而不会损失渲染速度。 et.al.|[2403.11453](http://arxiv.org/abs/2403.11453)|null|
|**2024-03-17**|**GeoGaussian: Geometry-aware Gaussian Splatting for Scene Rendering**|在高斯飞溅优化过程中，如果不刻意保留场景的结构，尤其是在墙、天花板和家具表面等无纹理区域，场景的几何体可能会逐渐退化。这种退化显著影响了与训练数据中的视点显著偏离的新视图的渲染质量。为了缓解这个问题，我们提出了一种称为GeoGaussian的新方法。基于从点云观察到的平滑连接区域，该方法引入了一种新的管道来初始化与表面对齐的薄高斯，通过精心设计的致密化策略，可以将特性传递给新一代。最后，管道确保通过具有明确几何约束的约束优化过程来维护场景的几何体和纹理。得益于所提出的架构，增强了三维高斯的生成能力，尤其是在结构化区域。我们提出的管道在新视图合成和几何重建方面实现了最先进的性能，在公共数据集上进行了定性和定量评估。 et.al.|[2403.11324](http://arxiv.org/abs/2403.11324)|null|
|**2024-03-17**|**Recent Advances in 3D Gaussian Splatting**|三维高斯散射（3DGS）的出现大大加快了新视图合成的绘制速度。与神经辐射场（NeRF）等用位置和视点条件神经网络表示3D场景的神经隐式表示不同，3D高斯散射利用一组高斯椭球来对场景进行建模，因此可以通过将高斯椭球光栅化为图像来实现高效渲染。除了快速渲染速度外，3D高斯飞溅的显式表示还方便了动态重建、几何编辑和物理模拟等编辑任务。考虑到该领域的快速变化和越来越多的工作，我们对最近的3D高斯飞溅方法进行了文献综述，按功能大致可分为3D重建、3D编辑和其他下游应用。为了更好地理解这一技术，还介绍了传统的基于点的绘制方法和三维高斯散射的绘制公式。这项调查旨在帮助初学者快速进入该领域，并为经验丰富的研究人员提供全面的概述，这可以刺激3D高斯飞溅表示的未来发展。 et.al.|[2403.11134](http://arxiv.org/abs/2403.11134)|null|
|**2024-03-16**|**Ctrl123: Consistent Novel View Synthesis via Closed-Loop Transcription**|大图像扩散模型在新视图合成（NVS）中已经证明了零样本能力。然而，现有的基于扩散的NVS方法很难生成与相应的地面实况姿态和外观准确一致的新视图，即使在训练集中也是如此。这因此限制了下游任务的性能，例如图像到多视图的生成和3D重建。我们意识到，这种不一致性很大程度上是由于在扩散训练中很难直接执行准确的姿势和外观对齐，这主要是由Zero123等现有方法完成的。为了解决这个问题，我们提出了Ctrl123，这是一种基于闭环转录的NVS扩散方法，它在姿态敏感特征空间中强制生成的视图和地面实况之间的对齐。我们的大量实验证明了Ctrl123在NVS和3D重建任务上的有效性，与现有方法相比，在多视角一致性和姿态一致性方面都取得了显著改进。 et.al.|[2403.10953](http://arxiv.org/abs/2403.10953)|null|
|**2024-03-16**|**HourglassNeRF: Casting an Hourglass as a Bundle of Rays for Few-shot Neural Rendering**|神经辐射场（NeRF）的最新进展增强了其新视图合成的能力，但其对密集多视图训练图像的依赖带来了实际挑战。针对这一问题，我们提出了HourglassNeRF，这是一种有效的基于正则化的方法，具有新颖的沙漏铸造策略。我们提出的沙漏被概念化为原始输入射线与其对应反射射线之间区域内的一束附加射线，通过集成位置编码（IPE）对圆锥台进行特征化。这种设计扩展了看不见的视图的覆盖范围，并实现了基于目标像素照片一致性的自适应高频正则化。此外，我们提出了基于朗伯假设的亮度一致性正则化，已知该正则化对于在少镜头设置下训练一组增强射线是有效的。利用朗伯曲面的固有特性，无论视角如何，它都能保持一致的亮度，我们假设我们提出的沙漏是翻转的漫反射光线的集合，并增强原始输入光线与其对应沙漏之间的亮度一致性，从而实现更具物理基础的训练框架和性能改进。我们的HourglassNeRF优于其基线，并在多个具有清晰渲染精细细节的基准上取得了有竞争力的结果。代码将可用。 et.al.|[2403.10906](http://arxiv.org/abs/2403.10906)|null|
|**2024-03-16**|**MSI-NeRF: Linking Omni-Depth with View Synthesis through Multi-Sphere Image aided Generalizable Neural Radiance Field**|使用鱼眼相机进行全景观察在机器人感知、重建和远程操作中具有重要意义。然而，传统方法合成的全景图像缺乏深度信息，在虚拟现实应用中只能提供三自由度（3DoF）旋转渲染。为了充分保留和利用原始鱼眼相机中的视差信息，我们引入了MSI NeRF，它结合了深度学习全向深度估计和新颖的视图渲染。我们首先通过对输入图像的特征提取和扭曲来构建一个多球体图像作为成本体。然后分别由几何解码器和外观解码器对其进行处理。与直接回归深度图的方法不同，我们进一步使用空间点和插值的3D特征向量作为输入来构建隐式辐射场。这样，我们可以同时实现全向深度估计和6DoF视图合成。我们的方法是以半自我监督的方式进行训练的。它不需要目标视图图像，仅使用深度数据进行监督。我们的网络具有仅使用四幅图像就能有效重建未知场景的泛化能力。实验结果表明，我们的方法在深度估计和新的视图合成任务方面优于现有方法。 et.al.|[2403.10840](http://arxiv.org/abs/2403.10840)|null|
|**2024-03-15**|**GGRt: Towards Generalizable 3D Gaussians without Pose Priors in Real-Time**|本文提出了GGRt，这是一种可推广的新视图合成的新方法，它减轻了对真实相机姿态的需求、处理高分辨率图像的复杂性和漫长的优化过程，从而有助于增强3D高斯散射（3D-GS）在现实世界场景中的适用性。具体来说，我们设计了一个新的联合学习框架，该框架由迭代姿态优化网络（IPO Net）和可推广的三维高斯（G-3DG）模型组成。通过联合学习机制，所提出的框架可以从图像观测中固有地估计鲁棒的相对姿态信息，从而主要减轻对真实相机姿态的要求。此外，我们实现了一种延迟反向传播机制，该机制能够实现高分辨率的训练和推理，克服了以前方法的分辨率限制。为了提高速度和效率，我们进一步引入了一个渐进式高斯缓存模块，该模块在训练和推理过程中进行动态调整。作为第一个无姿势可推广的3D-GS框架，GGRt实现了 $\ge$5 FPS的推理和$\ge$ 100 FPS的实时渲染。通过广泛的实验，我们证明了我们的方法在推理速度和有效性方面优于现有的基于NeRF的无姿态技术。它还可以接近基于真实姿态的3D-GS方法。我们的贡献为将计算机视觉和计算机图形集成到实际应用中提供了重大飞跃，在LLFF、KITTI和Waymo Open数据集上提供了最先进的结果，并实现了沉浸式体验的实时渲染。 et.al.|[2403.10147](http://arxiv.org/abs/2403.10147)|null|
|**2024-03-14**|**The NeRFect Match: Exploring NeRF Features for Visual Localization**|在这项工作中，我们建议使用神经辐射场（NeRF）作为视觉定位的场景表示。最近，NeRF已被用于通过增强训练数据库、通过渲染图像提供辅助监督或作为迭代细化模块来增强姿态回归和场景坐标回归模型。我们通过探索NeRF的内部特征在建立精确的2D-3D定位匹配方面的潜力，扩展了其公认的优势——它能够提供具有逼真外观和精确几何形状的紧凑场景表示。为此，我们对通过视图合成获得的NeRF的内隐知识进行了全面的检查，以在各种条件下进行匹配。这包括探索不同的匹配网络架构，在多个层提取编码器特征，以及不同的训练配置。值得注意的是，我们引入了NeRFMatch，这是一种先进的2D-3D匹配功能，它利用了通过视图合成学习到的NeRF的内部知识。我们在基于结构的管道内，根据标准本地化基准对NeRFMatch进行评估，为剑桥地标的本地化性能树立了新的最先进水平。 et.al.|[2403.09577](http://arxiv.org/abs/2403.09577)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-03-18**|**Fed3DGS: Scalable 3D Gaussian Splatting with Federated Learning**|在这项工作中，我们提出了Fed3DGS，这是一种基于联邦学习的三维高斯飞溅（3DGS）的可扩展三维重建框架。现有的城市规模重建方法通常采用集中式方法，将所有数据收集在中央服务器中并重建场景。这种方法阻碍了可扩展性，因为它给服务器带来了沉重的负载，并且在城市规模之外重建场景时需要大量的数据存储。为了追求更具可扩展性的3D重建，我们提出了一种具有3DGS的联合学习框架，这是一种去中心化的框架，可以在数百万客户端上使用分布式计算资源。我们为3DGS量身定制了一种基于蒸馏的模型更新方案，并引入了在具有联合学习的3D重建场景中处理非IID数据的外观建模。我们在几个大型基准上模拟了我们的方法，我们的方法展示了与集中式方法相当的渲染图像质量。此外，我们还用不同季节收集的数据模拟了我们的方法，证明了我们的框架可以反映场景的变化，我们的外观建模可以捕捉季节变化引起的变化。 et.al.|[2403.11460](http://arxiv.org/abs/2403.11460)|**[link](https://github.com/densoitlab/fed3dgs)**|
|**2024-03-18**|**BAGS: Building Animatable Gaussian Splatting from a Monocular Video with Diffusion Priors**|可动画三维重建在各个领域都有重要的应用，主要依靠艺术家的手工创作。最近，一些研究已经成功地从单眼视频中构建了可动画化的3D模型。然而，这些方法需要对输入视频中的对象进行足够的视图覆盖，并且通常需要大量的时间和计算成本来进行训练和渲染。这种限制限制了实际应用。在这项工作中，我们提出了一种从具有扩散先验的单目视频中构建可动画化的3D高斯飞溅的方法。3D高斯表示显著加速了训练和渲染过程，并且扩散先验允许该方法学习具有有限视点的3D模型。我们还提出了刚性正则化来提高先验的利用率。我们对各种真实世界的视频进行了广泛的评估，证明了与当前最先进的方法相比，其优越的性能。 et.al.|[2403.11427](http://arxiv.org/abs/2403.11427)|null|
|**2024-03-17**|**Creating Seamless 3D Maps Using Radiance Fields**|希望从2D输入图像创建3D对象模型和3D地图，用于诸如导航、虚拟旅游和城市规划之类的应用。创建3D地图的传统方法（如摄影测量）需要大量的图像和里程计。此外，传统方法在反射表面和镜面反射方面存在困难；场景中的windows和chrome可能会出现问题。Google Road View是一个熟悉的应用程序，它使用传统方法将2D输入图像的集合融合到3D地图的幻觉中。但是，Google Road View不会创建实际的三维对象模型，而只是视图的集合。这项工作的目标是使用更新的技术创建实际的3D对象模型。神经辐射场（NeRF[1]）已成为一种潜在的解决方案，提供了制作更精确、更复杂的3D地图的能力。高斯散射[4]是另一种当代技术。这项研究将神经辐射场与高斯散射进行了比较，并描述了它们的一些内部工作原理。我们的主要贡献是改进3D重建模型的结果的方法。我们的结果表明，高斯散射优于NeRF技术。 et.al.|[2403.11364](http://arxiv.org/abs/2403.11364)|null|
|**2024-03-17**|**Recent Advances in 3D Gaussian Splatting**|三维高斯散射（3DGS）的出现大大加快了新视图合成的绘制速度。与神经辐射场（NeRF）等用位置和视点条件神经网络表示3D场景的神经隐式表示不同，3D高斯散射利用一组高斯椭球来对场景进行建模，因此可以通过将高斯椭球光栅化为图像来实现高效渲染。除了快速渲染速度外，3D高斯飞溅的显式表示还方便了动态重建、几何编辑和物理模拟等编辑任务。考虑到该领域的快速变化和越来越多的工作，我们对最近的3D高斯飞溅方法进行了文献综述，按功能大致可分为3D重建、3D编辑和其他下游应用。为了更好地理解这一技术，还介绍了传统的基于点的绘制方法和三维高斯散射的绘制公式。这项调查旨在帮助初学者快速进入该领域，并为经验丰富的研究人员提供全面的概述，这可以刺激3D高斯飞溅表示的未来发展。 et.al.|[2403.11134](http://arxiv.org/abs/2403.11134)|null|
|**2024-03-17**|**Omni-Recon: Towards General-Purpose Neural Radiance Fields for Versatile 3D Applications**|最近在神经辐射场（NeRF）方面的突破引发了将其集成到现实世界3D应用中的巨大需求。然而，不同的3D应用程序所需的各种功能往往需要具有各种管道的不同NeRF模型，这导致每个目标任务的NeRF训练繁琐，试错实验繁琐。从新兴基础模型的泛化能力和适应性中汲取灵感，我们的工作旨在开发一种通用的NeRF，用于处理各种3D任务。我们通过提出一种称为Omni-Recon的框架来实现这一点，该框架能够（1）可推广的3D重建和零样本多任务场景理解，以及（2）对各种下游3D应用（如实时渲染和场景编辑）的适应性。我们的关键见解是，基于图像的渲染管道具有准确的几何结构和外观估计，可以将2D图像特征提升到3D图像特征中，从而以可推广的方式将广泛探索的2D任务扩展到3D世界。具体而言，我们的Omni-Recon采用了一个通用的NeRF模型，该模型使用基于图像的渲染，具有两个解耦的分支：一个是基于复杂变换器的分支，它逐步融合几何和外观特征，以实现精确的几何估计，另一个是用于预测源视图混合权重的轻量级分支。该设计实现了最先进的（SOTA）可推广的3D表面重建质量，混合权重可在不同任务中重复使用，用于零样本多任务场景理解。此外，它可以在将复杂的几何分支烘焙成网格后实现实时渲染，快速适应以实现SOTA可推广的3D理解性能，并与2D扩散模型无缝集成，用于文本引导的3D编辑。 et.al.|[2403.11131](http://arxiv.org/abs/2403.11131)|null|
|**2024-03-16**|**Ctrl123: Consistent Novel View Synthesis via Closed-Loop Transcription**|大图像扩散模型在新视图合成（NVS）中已经证明了零样本能力。然而，现有的基于扩散的NVS方法很难生成与相应的地面实况姿态和外观准确一致的新视图，即使在训练集中也是如此。这因此限制了下游任务的性能，例如图像到多视图的生成和3D重建。我们意识到，这种不一致性很大程度上是由于在扩散训练中很难直接执行准确的姿势和外观对齐，这主要是由Zero123等现有方法完成的。为了解决这个问题，我们提出了Ctrl123，这是一种基于闭环转录的NVS扩散方法，它在姿态敏感特征空间中强制生成的视图和地面实况之间的对齐。我们的大量实验证明了Ctrl123在NVS和3D重建任务上的有效性，与现有方法相比，在多视角一致性和姿态一致性方面都取得了显著改进。 et.al.|[2403.10953](http://arxiv.org/abs/2403.10953)|null|
|**2024-03-16**|**MicroDiffusion: Implicit Representation-Guided Diffusion for 3D Reconstruction from Limited 2D Microscopy Projections**|使用无衍射光束的体积光学显微镜通过将3D体积轴向投影到2D图像上来实现3D体积的快速成像，但缺乏关键的深度信息。为了解决这一问题，我们引入了MicroDiffusion，这是一种开创性的工具，可从有限的2D投影中实现高质量、深度分辨率的3D体积重建。虽然现有的隐式神经表示（INR）模型经常产生不完整的输出，并且去噪扩散概率模型（DDPM）擅长捕捉细节，但我们的方法将INR的结构一致性与DDPM的精细细节增强能力相结合。我们预训练INR模型，将2D轴向投影图像转换为初步的3D体积。该预训练的INR通过INR输出和噪声输入之间的线性插值，作为全局先验指导DDPM的生成过程。该策略利用结构化的3D信息丰富了扩散过程，增强了局部2D图像中的细节并减少了噪声。通过在最接近的2D投影上调节扩散模型，MicroDiffusion大大提高了3D重建的保真度，以无与伦比的图像质量和结构保真度超过了INR和标准DDPM输出。我们的代码和数据集可在https://github.com/UCSC-VLAA/MicroDiffusion. et.al.|[2403.10815](http://arxiv.org/abs/2403.10815)|**[link](https://github.com/ucsc-vlaa/microdiffusion)**|
|**2024-03-15**|**NeuralOCT: Airway OCT Analysis via Neural Fields**|光学相干断层扫描（OCT）是眼科中一种流行的模式，也用于血管内。我们对这项工作的兴趣是在婴儿和儿童气道异常的背景下进行OCT，其中OCT的高分辨率和无辐射的事实很重要。气道OCT的目标是提供气道几何形状的准确估计（2D和3D），以评估气道异常，如声门下狭窄。我们提出 $\texttt｛NeuralOCT｝$，这是一种基于学习的方法来处理气道OCT图像。具体而言，$\texttt｛NeuralOCT｝$通过稳健地桥接两个步骤从OCT扫描中提取3D几何形状：通过2D分割提取点云和通过神经场从点云中重建3D。我们的实验表明，$\texttt｛NeuralOCT｝$ 可以产生准确而稳健的3D气道重建，平均A线误差小于70微米。我们的代码将在GitHub上提供。 et.al.|[2403.10622](http://arxiv.org/abs/2403.10622)|null|
|**2024-03-15**|**SCILLA: SurfaCe Implicit Learning for Large Urban Area, a volumetric hybrid solution**|神经隐式表面表示方法最近显示出令人印象深刻的3D重建结果。然而，现有的解决方案由于其庞大、无边界和高度细致的性质，难以重建城市户外场景。因此，为了实现精确的重建，需要额外的监督数据，如激光雷达、强几何先验和长的训练时间。为了解决这些问题，我们提出了SCILLA，这是一种新的混合隐式表面学习方法，用于从2D图像中重建大型驾驶场景。SCILLA的混合架构为两个独立的隐式场建模：一个用于体积密度，另一个用于到曲面的符号距离。为了准确地表示城市户外场景，我们引入了一种新的体绘制策略，该策略依赖于自监督概率密度估计来对表面附近的点进行采样，并逐步从体表示过渡到表面表示。与并行方法相比，我们的解决方案允许在不依赖场景中任何几何先验的情况下正确快速地初始化有符号距离场。通过在四个户外驾驶数据集上进行广泛的实验，我们表明SCILLA可以在各种城市场景中学习准确而详细的3D表面场景表示，同时与以前最先进的解决方案相比，训练速度快两倍。 et.al.|[2403.10344](http://arxiv.org/abs/2403.10344)|null|
|**2024-03-15**|**FDGaussian: Fast Gaussian Splatting from Single Image via Geometric-aware Diffusion Model**|由于可用信息有限，从单视图图像重建详细的3D对象仍然是一项具有挑战性的任务。在本文中，我们介绍了FDGaussian，一种用于单图像三维重建的新的两阶段框架。最近的方法通常利用预先训练的2D扩散模型来从输入图像生成看似合理的新视图，但它们遇到了多视图不一致或缺乏几何保真度的问题。为了克服这些挑战，我们提出了一种正交平面分解机制来从2D输入中提取3D几何特征，从而能够生成一致的多视图图像。此外，我们还进一步加速了最先进的高斯散射技术，该技术结合了对极的关注，以融合来自不同视点的图像。我们证明了FDGaussian在不同视图中生成具有高一致性的图像，并在定性和定量上重建高质量的3D对象。更多示例可在我们的网站上找到https://qjfeng.net/FDGaussian/. et.al.|[2403.10242](http://arxiv.org/abs/2403.10242)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-03-18**|**Generalized Multi-Source Inference for Text Conditioned Music Diffusion Models**|多源扩散模型（MSDM）允许作曲音乐生成任务：生成一组连贯的音源，创建伴奏，并执行音源分离。尽管它们具有多功能性，但它们需要估计来源的联合分布，需要预先分离的音乐数据（这是很少可用的），并在训练时固定来源的数量和类型。本文将MSDM推广到以文本嵌入为条件的任意时域扩散模型。这些模型不需要分离的数据，因为它们是在混合物上训练的，可以参数化任意数量的源，并允许丰富的语义控制。我们提出了一种推理程序，能够连贯地生成音源和伴奏。此外，我们还采用MSDM的Dirac分离器来执行源分离。我们对在Slakh2100和MTG Jamendo上训练的扩散模型进行了实验，在轻松的数据设置中展示了竞争性的生成和分离结果。 et.al.|[2403.11706](http://arxiv.org/abs/2403.11706)|**[link](https://github.com/gladia-research-group/gmsdi)**|
|**2024-03-18**|**Urban Scene Diffusion through Semantic Occupancy Map**|生成无边界三维场景对于大规模场景理解和模拟至关重要。与自然景观不同，城市景观由各种复杂的人造物体和结构组成，如道路、交通标志、车辆和建筑物。要创建逼真而详细的城市场景，关键是要准确地表示底层对象的几何结构和语义，而不仅仅是它们的视觉外观。在这项工作中，我们提出了UrbanDiffusion，这是一个以鸟瞰图为条件的3D扩散模型，并以语义占用图的形式生成具有几何和语义的城市场景。我们的模型引入了一种新的范式，该范式学习潜在空间内场景级结构的数据分布，并进一步使合成场景能够扩展到任意尺度。在真实世界的驾驶数据集上进行训练后，我们的模型可以生成广泛的不同城市场景，给定保持集的BEV地图，也可以推广到驾驶模拟器的合成地图。我们进一步展示了它在场景图像合成中的应用，并将预训练的图像生成器作为先验。 et.al.|[2403.11697](http://arxiv.org/abs/2403.11697)|null|
|**2024-03-18**|**Narrow absorption lines from intervening material in supernovae I. Measurements and temporal evolution**|附近超新星（SN）光谱中的窄吸收特征是对视线中缓慢移动物质的有力诊断：它们被广泛用于推断宿主星系的尘埃灭绝，还可以用于探测起源于SN祖恒星并存在于爆炸附近的星周物质。尽管这些方法被广泛使用，但很少有研究检查描述窄线的方法的偏差，也没有多少统计分析存在。这是我们对不同分辨率的SN光谱的窄线进行统计分析的系列论文中的第一篇。我们开发了一种强大的自动化方法来测量SNe视线中介入材料的窄吸收线的等效宽度（EW）和速度，包括Na I D、Ca II H&K、K I和扩散星际带（DIBs）。我们通过模拟不同的信噪比、光谱分辨率、狭缝大小和方向，仔细研究了文献中异质光谱中的系统偏差，并介绍了使用低分辨率和中分辨率光谱研究这些谱线的实际能力和局限性。特别是，我们发现，低分辨率光谱中窄线等效宽度的测量在很大程度上受到SN喷出物演化的宽P-Cygni剖面的影响，无论是核心坍塌还是Ia-SNe型，都会引起明显的明显演化。因此，我们提出了一种简单的方法来检测和排除这些情况，以获得更稳健和可靠的测量结果。最后，在考虑了所有可能的影响后，我们分析了附近SNe大样本中狭窄特征的时间演变，以检测其EW随时间的任何可能变化。我们在所有SN类型的大样本中没有发现窄线特征的时间演变 et.al.|[2403.11677](http://arxiv.org/abs/2403.11677)|null|
|**2024-03-18**|**Binary Noise for Binary Tasks: Masked Bernoulli Diffusion for Unsupervised Anomaly Detection**|用于图像生成的去噪扩散模型的高性能为其在无监督医学异常检测中的应用铺平了道路。由于基于扩散的方法需要大量的GPU内存并且采样时间长，我们提出了一种基于潜在伯努利扩散模型的快速无监督异常检测方法。我们首先应用自动编码器将输入图像压缩为二进制潜在表示。接下来，将遵循伯努利噪声调度的扩散模型应用于该潜在空间，并对其进行训练，以从扰动的潜在表示中恢复二进制潜在表示。该扩散模型的二进制性质使我们能够识别潜在空间中的条目，这些条目在去噪过程中很有可能翻转其二进制代码，这表明数据分布不均。我们提出了一种基于这些概率的掩蔽算法，该算法提高了异常检测分数。与其他基于扩散的无监督异常检测算法相比，我们实现了最先进的性能，同时显著减少了采样时间和内存消耗。代码位于https://github.com/JuliaWolleb/Anomaly_berdiff. et.al.|[2403.11667](http://arxiv.org/abs/2403.11667)|null|
|**2024-03-18**|**Diffusion-Based Environment-Aware Trajectory Prediction**|预测交通参与者未来轨迹的能力对于自动驾驶汽车的安全高效运行至关重要。本文提出了一种基于扩散的多智能体轨迹预测生成模型。该模型能够捕捉交通参与者和环境之间的复杂互动，准确地学习数据的多模式性质。在真实世界交通场景的大规模数据集上评估了该方法的有效性，表明我们的模型在预测精度方面优于几种公认的方法。通过在模型输出上加入差分运动约束，我们说明我们的模型能够生成一组不同的现实未来轨迹。通过使用感知交互的引导信号，我们进一步证明了该模型可以用于预测不太合作的代理的行为，强调了其在不确定交通条件下的实际适用性。 et.al.|[2403.11643](http://arxiv.org/abs/2403.11643)|null|
|**2024-03-18**|**Arc2Face: A Foundation Model of Human Faces**|本文提出了一种基于身份条件的人脸基础模型Arc2Face，该模型在对人脸进行ArcFace嵌入的情况下，可以生成各种逼真的照片图像，其人脸相似度比现有模型高。尽管之前曾试图将人脸识别特征解码为详细图像，但我们发现常见的高分辨率数据集（如FFHQ）缺乏足够的身份来重建任何受试者。为此，我们仔细地对WebFace42M数据库的很大一部分进行了上采样，这是用于人脸识别（FR）的最大公共数据集。Arc2Face建立在预先训练的稳定扩散模型的基础上，但仅以ID向量为条件，使其适应ID到面的生成任务。与最近将ID与文本嵌入相结合以实现文本到图像模型的零样本个性化的工作不同，我们强调FR功能的紧凑性，它可以完全捕捉人脸的本质，而不是手工制作的提示。至关重要的是，文本增强模型很难将身份和文本解耦，通常需要对给定的人脸进行一些描述才能获得令人满意的相似性。然而，Arc2Face只需要ArcFace的判别功能来指导生成，为ID一致性至关重要的大量任务提供强大的先验。例如，我们在模型的合成图像上训练FR模型，并实现了优于现有合成数据集的性能。 et.al.|[2403.11641](http://arxiv.org/abs/2403.11641)|null|
|**2024-03-18**|**Quasinormal Modes of Near-Extremal Electric and Magnetic Black Branes**|规范重力对偶为研究强耦合非阿贝尔等离子体在热力学平衡附近和远离热力学平衡的行为提供了一个稳健的数学框架。 AdS5/CF4对应关系允许将非零温度下的强耦合 $\mathcal{N}$=4超对称杨-米尔斯（SYM）等离子体描述为双AdS5黑膜几何形状。我们以$\mathcal{N}$ =4SYM等离子体中远离平衡的同质各向同性为例，证明了伪谱方法在求解对偶爱因斯坦场方程中的应用。使用这个框架，我们还计算了在空间动量消失的情况下，电（Reissner-Nordstrom）和磁荷AdS5黑膜的准正规模。对于这两种类型的黑色膜，分析了这些QNM的近极值行为。 et.al.|[2403.11640](http://arxiv.org/abs/2403.11640)|null|
|**2024-03-18**|**LoRA-Composer: Leveraging Low-Rank Adaptation for Multi-Concept Customization in Training-Free Diffusion Models**|定制生成技术显著地促进了跨不同上下文的特定概念的合成。多概念定制成为这一领域中具有挑战性的任务。现有的方法通常依赖于训练多个LoRA的低秩自适应（LoRA）融合矩阵，以将各种概念合并到单个图像中。然而，我们发现这种简单的方法面临两个主要挑战：1）概念混淆，当模型不能保持不同的个体特征时发生；2）概念消失，当模型无法生成预期的主题时发生。为了解决这些问题，我们引入了LoRA Composer，这是一个无需训练的框架，旨在无缝集成多个LoRA，从而增强生成图像中不同概念之间的和谐。LoRA Composer通过概念注入约束解决概念消失问题，通过扩展的交叉注意力机制增强概念可见性。为了克服概念混淆，引入了概念隔离约束，改进了自注意计算。此外，提出了潜在的重新初始化，以有效地刺激指定区域内的概念特异性潜在。我们的广泛测试显示，与标准基线相比，LoRA Composer的性能显著增强，尤其是在消除了基于图像的条件（如精明的边缘或姿态估计）时。代码发布于https://github.com/Young98CN/LoRA创作者 et.al.|[2403.11627](http://arxiv.org/abs/2403.11627)|**[link](https://github.com/young98cn/lora_composer)**|
|**2024-03-18**|**CRS-Diff: Controllable Generative Remote Sensing Foundation Model**|扩散模型的出现彻底改变了图像生成领域，为在各种应用中创建高质量、高分辨率图像提供了新的方法。然而，这些模型生成特定领域图像，特别是遥感图像的潜力在很大程度上尚未开发。RS图像以其高分辨率、广泛覆盖和丰富的信息内容而闻名，这带来了一般扩散模型可能无法充分解决的新挑战。本文提出了CRS Diff，这是一个专门为生成遥感图像而定制的开创性扩散建模框架，它利用了扩散模型的固有优势，同时集成了先进的控制机制，以确保图像不仅在视觉上清晰，而且富含地理和时间信息。该模型集成了全局和局部控制输入，实现了发电条件的精确组合，以完善发电过程。对CRS Diff的综合评估表明，与以前的方法相比，在图像质量和多样性方面，它在单一条件和多种条件下生成RS图像的能力优越。 et.al.|[2403.11614](http://arxiv.org/abs/2403.11614)|null|
|**2024-03-18**|**Inverse Coefficient Problem for One-Dimensional Subdiffusion with Data on Disjoint Sets in Time**|在这项工作中，我们研究了一维次扩散模型的反系数问题，该问题涉及时间上的Caputo分数导数。反问题是从一对横向柯西数据中确定两个系数和多个参数（区间的阶数和长度）。横向柯西数据是在具有单个激励的时间上的不相交集合上给出的，并且测量是在位于激励支持之外的时间序列上进行的。我们证明了不同侧Cauchy数据的两个唯一性结果。该分析基于解的表示、观测的分析性和Sini[35]提出的逆Sturm-Liouville理论的改进版本。我们的结果充分利用了分数扩散的记忆效应，实现了模型中系数的唯一恢复。还提供了几个数值实验来补充分析。 et.al.|[2403.11599](http://arxiv.org/abs/2403.11599)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-03-15**|**NeuralOCT: Airway OCT Analysis via Neural Fields**|光学相干断层扫描（OCT）是眼科中一种流行的模式，也用于血管内。我们对这项工作的兴趣是在婴儿和儿童气道异常的背景下进行OCT，其中OCT的高分辨率和无辐射的事实很重要。气道OCT的目标是提供气道几何形状的准确估计（2D和3D），以评估气道异常，如声门下狭窄。我们提出 $\texttt｛NeuralOCT｝$，这是一种基于学习的方法来处理气道OCT图像。具体而言，$\texttt｛NeuralOCT｝$通过稳健地桥接两个步骤从OCT扫描中提取3D几何形状：通过2D分割提取点云和通过神经场从点云中重建3D。我们的实验表明，$\texttt｛NeuralOCT｝$ 可以产生准确而稳健的3D气道重建，平均A线误差小于70微米。我们的代码将在GitHub上提供。 et.al.|[2403.10622](http://arxiv.org/abs/2403.10622)|null|
|**2024-03-15**|**NECA: Neural Customizable Human Avatar**|人类化身已经成为一种具有各种应用的新型3D资产。理想情况下，人类化身应该是完全可定制的，以适应不同的设置和环境。在这项工作中，我们介绍了NECA，这是一种能够从单目或稀疏视图视频中学习多功能人体表示的方法，能够在姿势、阴影、形状、照明和纹理等方面进行细粒度定制。我们方法的核心是在互补的对偶空间中表示人类，并预测几何、反照率、阴影以及外部照明的解开神经场，从中我们能够通过体积渲染获得具有高频细节的逼真渲染。大量的实验证明了我们的方法在真实感渲染以及各种编辑任务（如新颖的姿势合成和重新照明）方面优于最先进的方法。代码位于https://github.com/iSEE-Laboratory/NECA. et.al.|[2403.10335](http://arxiv.org/abs/2403.10335)|**[link](https://github.com/isee-laboratory/neca)**|
|**2024-03-13**|**Representing Anatomical Trees by Denoising Diffusion of Implicit Neural Fields**|解剖树在临床诊断和治疗计划中起着核心作用。然而，由于解剖树的拓扑结构和几何形状多变且复杂，因此准确地表示解剖树具有挑战性。使用医学成像捕获的表示树状结构的传统方法虽然对可视化血管和支气管网络非常宝贵，但在分辨率、灵活性和效率方面存在缺陷。最近，隐式神经表示（INRs）已经成为准确有效地表示形状的强大工具。我们提出了一种使用INR表示解剖树的新方法，同时还通过INR空间中的去噪扩散来捕捉一组树的分布。我们以任何所需的分辨率准确捕捉解剖树的复杂几何形状和拓扑结构。通过广泛的定性和定量评估，我们展示了高保真度树重建，具有任意分辨率但紧凑的存储，以及跨解剖部位和树复杂性的多功能性。 et.al.|[2403.08974](http://arxiv.org/abs/2403.08974)|**[link](https://github.com/sinashish/treediffusion)**|
|**2024-03-12**|**Scalable Spatiotemporal Prediction with Bayesian Neural Fields**|时空数据集由空间参考的时间序列组成，在许多科学和商业智能应用中无处不在，如空气污染监测、疾病跟踪和云需求预测。随着现代数据集的规模和复杂性不断增加，人们越来越需要新的统计方法，这些方法足够灵活，可以捕捉复杂的时空动态，并且可以扩展，可以处理大型预测问题。这项工作提出了贝叶斯神经场（BayesNF），这是一种用于推断时空域上丰富概率分布的域通用统计模型，可用于数据分析任务，包括预测、插值和变差法。BayesNF将一种用于高容量函数估计的新型深度神经网络架构与用于鲁棒不确定性量化的分层贝叶斯推理相结合。通过通过一系列平滑可微变换定义先验，使用通过随机梯度下降训练的变量学习代理对大规模数据进行后验推理。我们根据突出的统计和机器学习基线评估BayesNF，显示出在气候和公共卫生数据集的各种预测问题上的显著改进，这些数据集包含数万到数十万个测量值。该论文附有一个开源软件包(https://github.com/google/bayesnf)它易于使用，并与JAX机器学习平台上的现代GPU和TPU加速器兼容。 et.al.|[2403.07657](http://arxiv.org/abs/2403.07657)|**[link](https://github.com/google/bayesnf)**|
|**2024-03-11**|**SiLVR: Scalable Lidar-Visual Reconstruction with Neural Radiance Fields for Robotic Inspection**|我们提出了一种基于神经场的大规模重建系统，该系统融合激光雷达和视觉数据，生成几何精度高的高质量重建，并捕捉照片逼真的纹理。该系统采用了最先进的神经辐射场（NeRF）表示，还结合了激光雷达数据，这对深度和表面法线增加了强大的几何约束。我们利用实时激光雷达SLAM系统的轨迹来引导运动结构（SfM）过程，以显著减少计算时间，并提供对激光雷达深度损失至关重要的度量尺度。我们使用子映射将系统缩放到长轨迹上捕获的大规模环境。我们用多摄像头、激光雷达传感器套件的数据演示了重建系统，该套件安装在腿式机器人上，手持扫描600米的建筑场景，并安装在空中机器人上，测量多层模拟灾难现场建筑。网站https://ori-drs.github.io/projects/silvr/ et.al.|[2403.06877](http://arxiv.org/abs/2403.06877)|null|
|**2024-03-15**|**CoNFiLD: Conditional Neural Field Latent Diffusion Model Generating Spatiotemporal Turbulence**|本研究介绍了条件神经场潜在扩散（CoNFiLD）模型，这是一种新的生成学习框架，旨在快速模拟三维不规则域内混沌和湍流系统中复杂的时空动力学。传统的涡解析数值模拟，尽管提供了详细的流量预测，但由于其广泛的计算需求，遇到了很大的局限性，限制了其在更广泛的工程环境中的应用。相比之下，基于深度学习的代理模型有望提供高效、数据驱动的解决方案。然而，它们的有效性往往因依赖确定性框架而受到损害，而确定性框架在准确捕捉湍流的混沌和随机性质方面存在不足。CoNFiLD模型通过将条件神经场编码与潜在扩散过程协同集成来解决这些挑战，从而能够在不同条件下高效且稳健地生成时空湍流。利用贝叶斯条件采样，该模型可以无缝适应各种湍流生成场景，而无需再训练，涵盖从使用稀疏传感器测量的零样本全场流重建到超分辨率生成和时空流数据恢复的应用。已经对各种具有不规则几何形状的非均匀、各向异性湍流进行了全面的数值实验，以评估该模型的多功能性和有效性，展示了其在湍流生成和更广泛的时空动力学建模领域的变革潜力。 et.al.|[2403.05940](http://arxiv.org/abs/2403.05940)|null|
|**2024-03-09**|**Learned 3D volumetric recovery of clouds and its uncertainty for climate analysis**|气候预测和云物理的重大不确定性与浅层散射云的观测差距有关。应对这些挑战需要对其三维（3D）异质体积散射内容进行遥感。这就需要无源散射计算机断层扫描（CT）。我们设计了一个基于学习的模型（ProbeCT）来实现这种云的CT，基于有噪声的多视图星载图像。ProbeCT首次推断出每个3D位置的异质消光系数的后验概率分布。这产生了任意有价值的统计数据，例如，最可能灭绝的3D场及其不确定性。ProbeCT使用神经场表示，进行本质上实时的推理。ProbeCT通过一个新的基于物理的云体积场及其相应图像的标记多类数据库进行监督训练。为了改进分布外推理，我们通过差分渲染引入了自监督学习。我们在模拟和真实世界的数据中演示了该方法，并指出了3D恢复和不确定性与降水和可再生能源的相关性。 et.al.|[2403.05932](http://arxiv.org/abs/2403.05932)|null|
|**2024-03-06**|**ProxNF: Neural Field Proximal Training for High-Resolution 4D Dynamic Image Reconstruction**|精确的时空图像重建方法被广泛的生物医学研究领域所需要，但由于数据的不完整性和计算负担而面临挑战。数据不完整性源于增加帧速率和减少采集时间所需的欠采样，而计算负担则源于具有三维空间和扩展时间范围的高分辨率图像的内存占用。神经场是一类新兴的神经网络，充当时空对象的连续表示，以前已经引入它来通过将图像重建重新定义为估计网络参数的问题来解决这些动态成像问题。神经场可以通过利用这些时空对象中潜在的冗余来解决数据不完整和计算负担这两个挑战。这项工作提出了ProxNF，这是一种用于时空图像重建的新的神经场训练方法，利用近端分裂方法将涉及成像算子的计算与网络参数的更新分开。具体而言，ProxNF评估图像域中数据保真度项的（子采样）梯度，并使用完全监督学习方法来更新神经场参数。通过减少内存占用和评估成像算子的计算成本，所提出的ProxNF方法允许重建大的、高分辨率的时空图像。该方法在两项数值研究中得到了证明，这两项研究涉及解剖逼真的动态数值小鼠模型和肿瘤灌注的两室模型的虚拟动态对比增强光声计算机断层扫描成像。 et.al.|[2403.03860](http://arxiv.org/abs/2403.03860)|null|
|**2024-03-05**|**NRDF: Neural Riemannian Distance Fields for Learning Articulated Pose Priors**|忠实地为关节空间建模是一项关键任务，它可以恢复和生成逼真的姿势，而且仍然是一项臭名昭著的挑战。为此，我们引入了神经黎曼距离场（NRDF），这是一种数据驱动的先验，用于建模看似合理的关节空间，表示为高维乘积四元数空间中神经场的零级集。为了仅在正示例上训练NRDF，我们引入了一种新的采样算法，确保测地距离遵循所需的分布，从而产生一种原则性的距离场学习范式。然后，我们设计了一种投影算法，通过自适应步长黎曼优化器将任何随机姿态映射到水平集上，始终遵循关节旋转的乘积流形。NRDF可以通过反向传播和数学类比计算黎曼梯度，与最近的生成模型黎曼流匹配有关。我们在各种下游任务中，即姿态生成、基于图像的姿态估计和求解逆运动学，对照其他姿态先验对NRDF进行了全面评估，突出了NRDF的优越性能。除了人类，NRDF的多功能性还延伸到手和动物姿势，因为它可以有效地代表任何关节。 et.al.|[2403.03122](http://arxiv.org/abs/2403.03122)|null|
|**2024-03-04**|**MagicClay: Sculpting Meshes With Generative Neural Fields**|神经领域的最新发展为形状生成领域带来了非凡的能力，但它们缺乏关键的特性，例如增量控制，这是艺术作品的基本要求。另一方面，三角网格是大多数几何相关任务的选择，提供了高效和直观的控制，但不适合神经优化。为了支持下游任务，现有技术通常提出两步方法，其中首先使用神经场生成形状，然后提取网格进行进一步处理。相反，在本文中，我们引入了一种混合方法，该方法保持网格和符号距离场（SDF）表示的一致性。使用这种表示，我们介绍了MagicClay——一种艺术家友好的工具，用于根据文本提示雕刻网格区域，同时保持其他区域不变。我们的框架仔细而有效地平衡了形状优化每一步中表示和正则化之间的一致性；依靠网格表示，我们展示了如何以更高的分辨率和更快的速度渲染SDF。此外，我们利用最近在可微网格重建方面的工作，在需要的地方自适应地分配网格中的三角形，如SDF所示。使用一个实现的原型，我们展示了与最先进的生成几何体相比的优越性，以及新颖的一致性控制，首次允许对同一网格进行基于提示的顺序编辑。 et.al.|[2403.02460](http://arxiv.org/abs/2403.02460)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

