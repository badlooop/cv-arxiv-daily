---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.05.12
> Usage instructions: [here](./docs/README.md#usage)

## Video Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-05**|**Learning 3D Persistent Embodied World Models**|模拟未来行动对世界影响的能力是智能化身代理的关键能力，使代理能够预测其行动的影响并相应地制定计划。虽然现有的大量工作已经探索了如何使用视频模型构建这样的世界模型，但它们本质上往往是近视的，对当前观察到的图像没有捕捉到的场景没有任何记忆，这使得代理无法在部分观察到场景的许多部分的复杂环境中制定一致的长期计划。我们引入了一种新的持久化实体世界模型，该模型具有对先前生成内容的显式记忆，能够实现更一致的长期模拟。在生成期间，我们的视频扩散模型预测了代理未来观测的RGB-D视频。然后，这一代被聚合成环境的持久3D地图。通过在这个3D空间地图上调节视频模型，我们说明了这如何使视频世界模型能够忠实地模拟世界上可见和不可见的部分。最后，我们说明了这种世界模型在下游具体应用中的有效性，实现了有效的规划和政策学习。 et.al.|[2505.05495](http://arxiv.org/abs/2505.05495)|null|
|**2025-05-08**|**SVAD: From Single Image to 3D Avatar via Synthetic Data Generation with Video Diffusion and Data Augmentation**|由于从单个视点重建完整3D信息的固有困难，从单个图像创建高质量的可动画化3D人类化身仍然是计算机视觉中的一个重大挑战。目前的方法面临着一个明显的局限性：3D高斯散斑（3DGS）方法可以产生高质量的结果，但需要多个视图或视频序列，而视频扩散模型可以从单个图像生成动画，但难以保持一致性和身份。我们提出了SVAD，这是一种通过利用现有技术的互补优势来解决这些局限性的新方法。我们的方法通过视频扩散生成合成训练数据，用身份保存和图像恢复模块对其进行增强，并利用这些精炼的数据来训练3DGS化身。综合评估表明，SVAD在保持身份一致性和新姿势和视点的精细细节方面优于最先进的（SOTA）单图像方法，同时实现了实时渲染功能。通过我们的数据增强管道，我们克服了传统3DGS方法通常需要的对密集单目或多视图训练数据的依赖。广泛的定量、定性比较表明，我们的方法在多个指标上与基线模型相比取得了卓越的性能。通过有效地将扩散模型的生成能力与3DGS的高质量结果和渲染效率相结合，我们的工作建立了一种从单个图像输入生成高保真化身的新方法。 et.al.|[2505.05475](http://arxiv.org/abs/2505.05475)|**[link](https://github.com/yc4ny/SVAD)**|
|**2025-05-08**|**T2VTextBench: A Human Evaluation Benchmark for Textual Control in Video Generation Models**|得益于可扩展深度架构和大规模预训练的最新进展，文本到视频生成在制作各种风格的高保真、遵循指令的内容方面取得了前所未有的能力，使其能够应用于广告、娱乐和教育领域。然而，这些模型呈现精确屏幕文本（如字幕或数学公式）的能力在很大程度上尚未经过测试，这对需要精确文本准确性的应用程序构成了重大挑战。在这项工作中，我们介绍了T2VTextBench，这是第一个专门用于评估文本到视频模型中屏幕文本保真度和时间一致性的人类评估基准。我们的提示套件将复杂的文本字符串与动态场景变化集成在一起，测试每个模型在帧间保持详细指令的能力。我们评估了十个最先进的系统，从开源解决方案到商业产品，发现大多数系统都难以生成清晰、一致的文本。这些结果突显了当前视频生成器的一个关键差距，并为未来旨在增强视频合成中文本操作的研究提供了明确的方向。 et.al.|[2505.04946](http://arxiv.org/abs/2505.04946)|null|
|**2025-05-08**|**HunyuanCustom: A Multimodal-Driven Architecture for Customized Video Generation**|定制视频生成旨在在灵活的用户定义条件下生成具有特定主题的视频，但现有方法往往难以实现身份一致性和有限的输入模式。本文中，我们提出了HunyuanCustom，这是一个多模态定制视频生成框架，强调主题一致性，同时支持图像、音频、视频和文本条件。基于HunyuanVideo，我们的模型首先通过引入基于LLaVA的文本图像融合模块来增强多模态理解，以及利用时间连接来增强跨帧身份特征的图像ID增强模块，从而解决了图像文本条件生成任务。为了实现音频和视频条件生成，我们进一步提出了特定于模态的条件注入机制：一个通过空间交叉注意力实现分层对齐的AudioNet模块，以及一个通过基于patchify的特征对齐网络集成潜在压缩条件视频的视频驱动注入模块。在单主题和多主题场景上的广泛实验表明，HunyuanCustom在ID一致性、真实性和文本视频对齐方面明显优于最先进的开源和闭源方法。此外，我们验证了其在下游任务中的鲁棒性，包括音频和视频驱动的定制视频生成。我们的研究结果强调了多模态条件反射和身份保持策略在推进可控视频生成方面的有效性。所有代码和型号均可在https://hunyuancustom.github.io. et.al.|[2505.04512](http://arxiv.org/abs/2505.04512)|null|
|**2025-05-06**|**Real-Time Person Image Synthesis Using a Flow Matching Model**|姿势引导人物图像合成（PGPIS）生成基于目标姿势和源图像的逼真人物图像。这项任务在各种现实世界的应用中起着关键作用，如手语视频生成、AR/VR、游戏和直播。在这些场景中，实时PGPIS对于提供即时视觉反馈和保持用户沉浸感至关重要。然而，由于从各种动态的人体姿势合成高保真图像的复杂性，实现实时性能仍然是一个重大挑战。最近基于扩散的方法在PGPIS中显示出令人印象深刻的图像质量，但它们缓慢的采样速度阻碍了在时间敏感应用中的部署。这种延迟在实时广播期间生成手语视频等需要快速图像更新的任务中尤其成问题。因此，开发一个快速可靠的PGPIS模型是实现实时交互系统的关键一步。为了应对这一挑战，我们提出了一种基于流匹配（FM）的生成模型。我们的方法能够实现更快、更稳定、更高效的训练和采样。此外，所提出的模型支持条件生成，可以在潜在空间中运行，使其特别适用于速度和质量都至关重要的实时PGPIS应用。我们在PGPIS任务中广泛使用的DeepFashion数据集上评估了我们提出的方法，即使用流匹配模型（RPFM）进行实时人物图像合成。我们的结果表明，RPFM实现了近乎实时的采样速度，同时保持了与最先进模型相当的性能。我们的方法在生成图像精度略有下降的情况下，将生成速度提高了一倍以上，从而确保了实时性能。 et.al.|[2505.03562](http://arxiv.org/abs/2505.03562)|null|
|**2025-05-06**|**Transformers for Learning on Noisy and Task-Level Manifolds: Approximation and Generalization Insights**|Transformer是大型语言和视频生成模型的基础架构，如GPT、BERT、SORA及其后续模型。实证研究表明，现实世界的数据和学习任务表现出低维结构，以及一些噪声或测量误差。变压器的性能往往取决于数据/任务的内在维度，尽管对变压器的理论理解在很大程度上尚未得到探索。这项工作通过分析涉及流形上噪声输入数据的回归任务的变压器性能，奠定了理论基础。具体来说，输入数据位于流形的管状邻域内，而地面真值函数取决于噪声数据在流形上的投影。我们证明了近似和泛化误差，这些误差在很大程度上取决于流形的内在维数。我们的结果表明，即使输入数据受到高维噪声的干扰，变换器也可以在学习任务中利用低复杂度的结构。我们的新证明技术通过变换器构建基本算术运算的表示，这可能具有独立的意义。 et.al.|[2505.03205](http://arxiv.org/abs/2505.03205)|null|
|**2025-05-04**|**DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization**|通过关注身份和运动一致性，使用预训练的大规模模型进行定制的文本到视频生成最近引起了人们的广泛关注。现有作品通常遵循孤立的定制范式，其中主体身份或运动动力学是专门定制的。然而，这种范式完全忽略了身份和运动之间的内在相互约束和协同相互依赖性，导致身份-运动冲突在整个生成过程中系统地退化。为了解决这个问题，我们引入了DualReal，这是一个新的框架，它采用自适应联合训练来协同构建维度之间的相互依赖关系。具体来说，DualReal由两个单元组成：（1）双感知自适应动态选择一个训练阶段（即身份或运动），在冻结维度先验的指导下学习当前信息，并采用正则化策略避免知识泄漏；（2）StageBlender控制器利用去噪阶段和扩散变换器深度，以自适应粒度引导不同维度，避免各个阶段的冲突，最终实现身份和运动模式的无损融合。我们构建了一个比现有方法更全面的基准。实验结果表明，DualReal平均将CLIP-I和DINO-I指标提高了21.7%和31.8%，并在几乎所有运动质量指标上都取得了最佳性能。 et.al.|[2505.02192](http://arxiv.org/abs/2505.02192)|null|
|**2025-05-03**|**PosePilot: Steering Camera Pose for Generative World Models with Self-supervised Depth**|自动驾驶（AD）系统的最新进展突显了世界模型在普通和具有挑战性的驾驶条件下实现稳健和通用性能的潜力。然而，一个关键的挑战仍然存在：精确灵活的相机姿态控制，这对于精确的视点变换和场景动态的真实模拟至关重要。在本文中，我们介绍了PosePilot，这是一个轻量级但功能强大的框架，可显著增强生成世界模型中的相机姿态可控性。从自我监督深度估计中汲取灵感，PosePilot利用运动原理的结构，在相机姿态和视频生成之间建立紧密耦合。具体来说，我们结合了自我监督的深度和姿态读数，使模型能够直接从视频序列中推断深度和相对相机运动。这些输出驱动姿态感知帧扭曲，由光度扭曲损失引导，该损失加强了合成帧之间的几何一致性。为了进一步优化相机姿态估计，我们引入了反向扭曲步骤和姿态回归损失，提高了视点精度和适应性。对自动驾驶和一般领域视频数据集的广泛实验表明，PosePilot显著增强了基于扩散和自回归世界模型的结构理解和运动推理。通过使用自我监督的深度控制相机姿态，PosePilot为姿态可控性设定了一个新的基准，在生成世界模型中实现了物理上一致、可靠的视点合成。 et.al.|[2505.01729](http://arxiv.org/abs/2505.01729)|null|
|**2025-05-02**|**VideoHallu: Evaluating and Mitigating Multi-modal Hallucinations for Synthetic Videos**|基于基础模型的合成视频生成因其真实性和广泛的应用而受到关注。虽然这些模型产生了高质量的帧，但它们往往不尊重常识和物理定律，导致内容异常。现有的指标，如VideoScore，强调一般质量，但忽略了此类违规行为，缺乏可解释性。一种更具洞察力的方法是使用多模态大型语言模型（MLLM）作为可解释的评估器，如FactScore所示。然而，MLLM检测合成视频中异常的能力仍有待探索。为了解决这个问题，我们引入了VideoHallu，这是一个基准测试，它包含来自Veo2、Sora和Kling等模型的合成视频，并与专家设计的QA任务相结合，这些任务可以通过人类层面的推理来解决。我们评估了几种SoTA MLLM，包括GPT-4o、Gemini-2.5-Pro、Qwen-2.5-VL以及Video-R1和VideoChat-R1等较新型号。尽管在MVBench和MovieChat上表现强劲，但这些模型在合成环境中的基本常识和物理任务上仍然会产生幻觉，突显了幻觉的挑战。我们使用组相对策略优化（GRPO）在真实和合成常识/物理数据上进一步微调SoTA MLLM。结果表明，特别是通过反例积分，MLLM的推理能力得到了显著提高。我们的数据可在https://github.com/zli12321/VideoHallu. et.al.|[2505.01481](http://arxiv.org/abs/2505.01481)|**[link](https://github.com/zli12321/videohallu)**|
|**2025-05-02**|**VIDSTAMP: A Temporally-Aware Watermark for Ownership and Integrity in Video Diffusion Models**|视频传播模型的迅速崛起使得生成高度逼真和时间连贯的视频成为可能，这引发了人们对内容真实性、来源和滥用的严重担忧。现有的水印方法，无论是被动的、事后的还是基于图像技术的，通常都难以承受特定于视频的操作，如帧插入、丢弃或重新排序，并且通常会降低视觉质量。在这项工作中，我们引入了VIDSPAMP，这是一种水印框架，它将每帧或每段消息直接嵌入到时间感知视频扩散模型的潜在空间中。通过两级流水线对模型的解码器进行微调，首先在静态图像数据集上促进空间消息分离，然后在合成视频序列上恢复时间一致性，VIDSPAMP学会了嵌入高容量、灵活的水印，同时将感知影响降到最低。利用3D卷积和时间注意力等架构组件，我们的方法不会产生额外的推理成本，并且提供了比现有方法更好的感知质量，同时对常见的失真和篡改保持了相当的鲁棒性。VIDSPAMP在每个视频中嵌入768位（每帧48位），比特准确率为95.0%，实现了-166.65的对数P值（越低越好），并保持了0.836的视频质量得分，与无标记输出（0.838）相当，在容量质量权衡方面超越了现有方法。代码：代码：\url{https://github.com/SPIN-UMass/VidStamp} et.al.|[2505.01406](http://arxiv.org/abs/2505.01406)|**[link](https://github.com/spin-umass/vidstamp)**|

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-09**|**RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects**|现代3D重建和新颖的视图合成方法在具有不透明朗伯对象的场景中表现出了很强的性能。然而，大多数假设光路是直的，因此无法正确处理折射和反射材料。此外，专门针对这些效应的数据集有限，阻碍了评估性能和开发合适技术的努力。在这项工作中，我们引入了一个合成的RefRef数据集和基准，用于从姿态图像中重建具有折射和反射物体的场景。我们的数据集有50个不同复杂度的对象，从单材质凸形到多材质非凸形，每个对象都放置在三种不同的背景类型中，从而产生150个场景。我们还提出了一种预言方法，在给定物体几何形状和折射率的情况下，计算神经渲染的精确光路，并在此基础上提出了一个避免这些假设的方法。我们将这些方法与几种最先进的方法进行了比较，并表明所有方法都明显落后于oracle，突显了任务和数据集的挑战。 et.al.|[2505.05848](http://arxiv.org/abs/2505.05848)|null|
|**2025-05-08**|**UltraGauss: Ultrafast Gaussian Reconstruction of 3D Ultrasound Volumes**|超声成像因其安全性、可负担性和实时性而被广泛使用，但其二维解释高度依赖于操作员，导致可变性和认知需求增加。2D到3D重建通过提供标准化的体积视图来缓解这些挑战，但现有的方法通常计算成本高、内存密集或与超声物理不兼容。我们介绍了UltraGauss：第一个超声专用高斯散斑框架，将视图合成技术扩展到超声波传播。与传统的基于透视的溅射不同，UltraGauss在3D中模拟探头平面交点，与声像形成对齐。我们推导了一种用于GPU并行化的高效光栅化边界公式，并引入了数值稳定的协方差参数化，提高了计算效率和重建精度。在真实的临床超声数据上，UltraGauss在5分钟内实现了最先进的重建，并在单个GPU上在20分钟内达到0.99 SSIM。一项对专家临床医生的调查证实，UltraGauss的重建是竞争方法中最现实的。我们的CUDA实施将在发布后发布。 et.al.|[2505.05643](http://arxiv.org/abs/2505.05643)|null|
|**2025-05-08**|**Steepest Descent Density Control for Compact 3D Gaussian Splatting**|3D高斯散斑（3DGS）已成为实时、高分辨率新颖视图合成的强大技术。通过将场景表示为高斯基元的混合，3DGS利用GPU光栅化管道进行高效的渲染和重建。为了优化场景覆盖并捕捉精细细节，3DGS采用致密化算法来生成额外的点。然而，这一过程通常会导致冗余的点云，从而导致内存使用过度、性能下降和大量存储需求，给资源受限的设备上的部署带来了重大挑战。为了解决这一局限性，我们提出了一个理论框架，该框架揭开了3DGS中密度控制的神秘面纱并加以改进。我们的分析表明，分裂对于逃离鞍点至关重要。通过优化理论方法，我们建立了致密化的必要条件，确定了子高斯数的最小值，确定了最佳参数更新方向，并为归一化弹簧不透明度提供了解析解。基于这些见解，我们引入了SteepGS，它结合了最陡密度控制，这是一种原则性的策略，可以在保持紧凑点云的同时最大限度地减少损失。SteepGS在不影响渲染质量的情况下实现了高斯点减少约50%，显著提高了效率和可扩展性。 et.al.|[2505.05587](http://arxiv.org/abs/2505.05587)|null|
|**2025-05-07**|**SGCR: Spherical Gaussians for Efficient 3D Curve Reconstruction**|神经渲染技术在生成逼真的3D场景方面取得了重大进展。最新的3D高斯散点技术实现了高质量的新颖视图合成以及快速的渲染速度。然而，尽管3D高斯算子具有明确的原始表示，但它们在定义精确的3D几何结构方面缺乏熟练程度。这是因为高斯的属性主要是通过其各向异性来定制和微调的，以渲染各种2D图像。为了为高效的3D重建铺平道路，我们提出了球面高斯，这是一种简单有效的3D几何边界表示方法，我们可以从一组校准的多视图图像中直接重建3D特征曲线。球面高斯从网格初始化开始进行优化，具有基于视图的渲染损失，其中在特定视图处渲染2D边缘图，然后将其与从相应图像中提取的地面真实边缘图进行比较，而不需要任何3D指导或监督。考虑到球面高斯作为鲁棒边缘表示的媒介，我们进一步引入了一种新的基于优化的算法SGCR，可以直接从对齐的球面高斯中提取精确的参数曲线。我们证明，SGCR在3D边缘重建方面优于现有的最先进方法，同时具有很高的效率。 et.al.|[2505.04668](http://arxiv.org/abs/2505.04668)|null|
|**2025-05-07**|**GSsplat: Generalizable Semantic Gaussian Splatting for Novel-view Synthesis in 3D Scenes**|从多个角度对看不见的场景进行语义合成对于3D场景理解的研究至关重要。当前的方法能够通过重建可推广的神经辐射场来渲染新的视图图像和语义图。然而，它们在速度和分割性能方面经常受到限制。我们提出了一种可推广的语义高斯散点方法（GSsplat），用于高效的新视图合成。我们的模型从一次输入中预测场景自适应高斯分布的位置和属性，取代了传统场景特定高斯散布的密集化和修剪过程。在多任务框架中，设计了一个混合网络来提取颜色和语义信息，并预测高斯参数。为了增强高斯模型的空间感知以实现高质量渲染，我们提出了一种基于组的监督的偏移学习模块和一种具有空间单元聚合的点级交互模块。当使用不同数量的多视图输入进行评估时，GSsplat以最快的速度实现了最先进的语义合成性能。 et.al.|[2505.04659](http://arxiv.org/abs/2505.04659)|null|
|**2025-05-04**|**SparSplat: Fast Multi-View Reconstruction with Generalizable 2D Gaussian Splatting**|通过多视图立体重建（MVS）和新颖视图合成（NVS）从场景中恢复3D信息本身就具有挑战性，特别是在涉及稀疏视图设置的场景中。3D高斯散斑（3DGS）的出现实现了实时、逼真的NVS。在此之后，2D高斯散斑（2DGS）利用透视精确的2D高斯基元光栅化在渲染过程中实现了精确的几何表示，在保持实时性能的同时改善了3D场景重建。最近的方法在基于MVS的可推广学习框架内使用3DGS来回归3D高斯参数，从而解决了稀疏实时NVS的问题。我们的工作通过共同解决可推广稀疏3D重建和NVS的挑战来扩展这一研究领域，并成功地完成了这两项任务。我们提出了一种基于MVS的学习管道，该管道以前馈方式回归2DGS表面元素参数，以从稀疏视图图像中执行3D形状重建和NVS。我们进一步表明，我们的可推广管道可以从预先存在的基础多视图深度视觉特征中受益。由此产生的模型在DTU稀疏3D重建基准上获得了最先进的结果，包括倒角距离到地面真实度，以及最先进的NVS。它还展示了对BlendMVS和Tanks and Temples数据集的强大泛化能力。我们注意到，我们的模型在基于隐式表示的体绘制的前馈稀疏视图重建方面优于现有技术，同时提供了近2个数量级的推理速度。 et.al.|[2505.02175](http://arxiv.org/abs/2505.02175)|null|
|**2025-05-02**|**High Dynamic Range Novel View Synthesis with Single Exposure**|高动态范围新视图合成（HDR-NVS）旨在从低动态范围（LDR）图像中建立3D场景HDR模型。通常，采用多重曝光LDR图像来捕获场景中更宽范围的亮度水平，因为单个LDR图像不能同时表示最亮和最暗的区域。虽然有效，但这种多重曝光HDR-NVS方法存在重大局限性，包括易受运动伪影（如重影和模糊）的影响，捕获和存储成本高。为了克服这些挑战，我们首次引入了单次曝光HDR-NVS问题，在训练过程中只有单次曝光LDR图像可用。我们进一步介绍了一种新方法Mono-HDR 3D，它具有由LDR图像形成原理制定的两个专用模块，一个用于将LDR颜色转换为HDR对应物，另一个用于把HDR图像转换为LDR格式，从而在闭环中实现无监督学习。作为一种元算法，我们的方法可以与现有的NVS模型无缝集成。大量实验表明，Mono-HR-3D明显优于之前的方法。源代码将会发布。 et.al.|[2505.01212](http://arxiv.org/abs/2505.01212)|null|
|**2025-04-29**|**Unconstrained Large-scale 3D Reconstruction and Rendering across Altitudes**|制作逼真、可导航的3D现场模型需要大量精心收集的图像，而救灾或执法的第一响应者往往无法获得这些图像。现实世界的挑战包括图像数量有限、异构的无电源相机、不一致的照明以及从不同高度收集的图像的极端视点差异。为了促进旨在解决这些挑战的研究，我们开发了第一个基于多个校准的地面、安全级别和机载摄像头的3D重建和新型视图合成的公共基准数据集。我们展示了构成现实世界挑战的数据集，独立评估了无电源相机的校准和新颖渲染视图的质量，使用最新的实践方法展示了基线性能，并确定了进一步研究的挑战。 et.al.|[2505.00734](http://arxiv.org/abs/2505.00734)|null|
|**2025-05-01**|**RayZer: A Self-supervised Large View Synthesis Model**|我们介绍了RayZer，这是一种自我监督的多视图3D视觉模型，在没有任何3D监督（即相机姿态和场景几何形状）的情况下进行训练，同时表现出新兴的3D意识。具体来说，RayZer将未经基础和校准的图像作为输入，恢复相机参数，重建场景表示，并合成新的视图。在训练过程中，RayZer仅依靠其自我预测的相机姿态来渲染目标视图，消除了对任何地面实况相机注释的需要，并允许RayZer通过2D图像监控进行训练。RayZer的新兴3D意识归因于两个关键因素。首先，我们设计了一个自监督框架，通过解纠缠相机和场景表示来实现输入图像的3D感知自动编码。其次，我们设计了一个基于变换器的模型，其中唯一的3D先验是光线结构，同时连接相机、像素和场景。RayZer展示了与在训练和测试中依赖姿势注释的“oracle”方法相当甚至更优的新颖视图合成性能。项目：https://hwjiang1510.github.io/RayZer/ et.al.|[2505.00702](http://arxiv.org/abs/2505.00702)|null|
|**2025-04-29**|**TesserAct: Learning 4D Embodied World Models**|本文提出了一种学习新的4D实体世界模型的有效方法，该模型预测了3D场景随时间的动态演变，以响应实体代理的动作，提供了空间和时间的一致性。我们建议通过RGB-DN（RGB、深度和法线）视频训练来学习4D世界模型。这不仅超越了传统的2D模型，将详细的形状、配置和时间变化纳入其预测中，而且使我们能够有效地学习具体代理的精确逆动态模型。具体来说，我们首先利用现成的模型，利用深度和正常信息扩展现有的机器人操纵视频数据集。接下来，我们在此带注释的数据集上微调视频生成模型，该模型联合预测每帧的RGB-DN（RGB、深度和法线）。然后，我们提出了一种算法，可以将生成的RGB、深度和法线视频直接转换为高质量的4D世界场景。我们的方法确保了来自具体场景的4D场景预测的时间和空间一致性，为具体环境实现了新颖的视图合成，并促进了策略学习，其性能明显优于先前基于视频的世界模型。 et.al.|[2504.20995](http://arxiv.org/abs/2504.20995)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-09**|**VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction**|Next Best View（NBV）算法旨在使用最少的资源、时间或捕获次数来获取一组最佳图像，以实现场景的高效3D重建。现有的方法通常依赖于先前的场景知识或额外的图像捕获，并经常制定最大化覆盖范围的策略。然而，对于许多具有复杂几何形状和自遮挡的真实场景，覆盖最大化并不能直接带来更好的重建质量。本文提出了视图自检网络（VIN）和VIN-NBV策略，该网络经过训练可以直接预测视图的重建质量改进。一种基于贪婪顺序采样的策略，在每个采集步骤，我们对多个查询视图进行采样，并选择VIN预测改进得分最高的视图。我们设计VIN来执行基于先前采集的重建的3D感知特征化，并为每个查询视图创建一个可以解码为改进分数的特征。然后，我们使用模仿学习来训练VIN，以预测重建改进分数。我们发现，在采集次数或运动时间受到限制的情况下，VIN-NBV在覆盖最大化基线上将重建质量提高了约30%。 et.al.|[2505.06219](http://arxiv.org/abs/2505.06219)|null|
|**2025-05-09**|**RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects**|现代3D重建和新颖的视图合成方法在具有不透明朗伯对象的场景中表现出了很强的性能。然而，大多数假设光路是直的，因此无法正确处理折射和反射材料。此外，专门针对这些效应的数据集有限，阻碍了评估性能和开发合适技术的努力。在这项工作中，我们引入了一个合成的RefRef数据集和基准，用于从姿态图像中重建具有折射和反射物体的场景。我们的数据集有50个不同复杂度的对象，从单材质凸形到多材质非凸形，每个对象都放置在三种不同的背景类型中，从而产生150个场景。我们还提出了一种预言方法，在给定物体几何形状和折射率的情况下，计算神经渲染的精确光路，并在此基础上提出了一个避免这些假设的方法。我们将这些方法与几种最先进的方法进行了比较，并表明所有方法都明显落后于oracle，突显了任务和数据集的挑战。 et.al.|[2505.05848](http://arxiv.org/abs/2505.05848)|null|
|**2025-05-08**|**The Moon's Many Faces: A Single Unified Transformer for Multimodal Lunar Reconstruction**|多模态学习是跨多个学科的新兴研究课题，但很少应用于行星科学。在这篇文章中，我们发现反射率参数估计和基于图像的月球图像3D重建可以被表述为一个多模态学习问题。我们提出了一种单一的、统一的变换器架构，该架构经过训练，可以学习多个源之间的共享表示，如灰度图像、数字高程模型、表面法线和反照率图。该架构支持从任何输入模态到任何目标模态的灵活转换。从灰度图像预测DEM和反照率图同时解决了行星表面的3D重建任务，并解开了光度参数和高度信息。我们的结果表明，我们的基础模型在这四种模式中学习了物理上合理的关系。未来添加更多的输入模式将实现光度归一化和共配准等任务。 et.al.|[2505.05644](http://arxiv.org/abs/2505.05644)|null|
|**2025-05-08**|**UltraGauss: Ultrafast Gaussian Reconstruction of 3D Ultrasound Volumes**|超声成像因其安全性、可负担性和实时性而被广泛使用，但其二维解释高度依赖于操作员，导致可变性和认知需求增加。2D到3D重建通过提供标准化的体积视图来缓解这些挑战，但现有的方法通常计算成本高、内存密集或与超声物理不兼容。我们介绍了UltraGauss：第一个超声专用高斯散斑框架，将视图合成技术扩展到超声波传播。与传统的基于透视的溅射不同，UltraGauss在3D中模拟探头平面交点，与声像形成对齐。我们推导了一种用于GPU并行化的高效光栅化边界公式，并引入了数值稳定的协方差参数化，提高了计算效率和重建精度。在真实的临床超声数据上，UltraGauss在5分钟内实现了最先进的重建，并在单个GPU上在20分钟内达到0.99 SSIM。一项对专家临床医生的调查证实，UltraGauss的重建是竞争方法中最现实的。我们的CUDA实施将在发布后发布。 et.al.|[2505.05643](http://arxiv.org/abs/2505.05643)|null|
|**2025-05-08**|**SVAD: From Single Image to 3D Avatar via Synthetic Data Generation with Video Diffusion and Data Augmentation**|由于从单个视点重建完整3D信息的固有困难，从单个图像创建高质量的可动画化3D人类化身仍然是计算机视觉中的一个重大挑战。目前的方法面临着一个明显的局限性：3D高斯散斑（3DGS）方法可以产生高质量的结果，但需要多个视图或视频序列，而视频扩散模型可以从单个图像生成动画，但难以保持一致性和身份。我们提出了SVAD，这是一种通过利用现有技术的互补优势来解决这些局限性的新方法。我们的方法通过视频扩散生成合成训练数据，用身份保存和图像恢复模块对其进行增强，并利用这些精炼的数据来训练3DGS化身。综合评估表明，SVAD在保持身份一致性和新姿势和视点的精细细节方面优于最先进的（SOTA）单图像方法，同时实现了实时渲染功能。通过我们的数据增强管道，我们克服了传统3DGS方法通常需要的对密集单目或多视图训练数据的依赖。广泛的定量、定性比较表明，我们的方法在多个指标上与基线模型相比取得了卓越的性能。通过有效地将扩散模型的生成能力与3DGS的高质量结果和渲染效率相结合，我们的工作建立了一种从单个图像输入生成高保真化身的新方法。 et.al.|[2505.05475](http://arxiv.org/abs/2505.05475)|**[link](https://github.com/yc4ny/SVAD)**|
|**2025-05-08**|**Time of the Flight of the Gaussians: Optimizing Depth Indirectly in Dynamic Radiance Fields**|我们提出了一种使用原始传感器样本从单目连续波飞行时间（C-ToF）相机重建动态场景的方法，该方法的精度与神经体积方法相似或更好，速度快100倍。从单个视点快速实现高保真动态3D重建是计算机视觉领域的一个重大挑战。在C-ToF辐射场重建中，感兴趣的深度属性不是直接测量的，这带来了额外的挑战。当使用基于基元的快速场景表示（如3D高斯飞溅）时，这个问题对优化有很大的影响，但被低估了，3D高斯飞溅通常用于多视图数据以产生令人满意的结果，否则在优化中很脆弱。我们在优化中引入了两种启发式方法，以提高高斯表示的场景几何的准确性。实验结果表明，我们的方法在约束的C-ToF传感条件下产生了精确的重建，包括摆动棒球棒等快速运动。https://visual.cs.brown.edu/gftorf et.al.|[2505.05356](http://arxiv.org/abs/2505.05356)|null|
|**2025-05-08**|**Divide-and-Conquer: Cold-Start Bundle Recommendation via Mixture of Diffusion Experts**|冷启动捆绑包推荐侧重于对信息不足的新捆绑包进行建模，以提供建议。高级捆绑包推荐模型通常在捆绑包和项目级别从多个视图（例如交互视图）学习捆绑包表示。因此，由于双层多视图复杂性，捆绑包的冷启动问题比传统项目更具挑战性。本文提出了一种新的混合扩散专家（MoDiffE）框架，该框架采用分而治之策略进行冷启动包推荐，并遵循三个步骤：（1）划分：将包冷启动问题按级别和视图顺序划分为独立但相似的子问题，这可以概括为先验嵌入模型中特征缺失包的表示不佳。（2）征服：除了从根本上提供嵌入式表示的先前嵌入模型外，我们引入了一种基于扩散的方法来统一解决所有子问题，该方法使用扩散模型直接生成扩散表示，而不依赖于特定特征。（3）组合：采用冷感知分层专家混合（MoE）来组合子问题的结果，以获得最终建议，其中每个视图的两个模型都作为专家，并以多层方式自适应地融合到不同的包中。此外，MoDiffE采用了多级解耦训练管道，并引入了冷启动门控增强方法，以实现冷束门控训练。通过对三个真实世界数据集的广泛实验，我们证明MoDiffE在处理冷启动包推荐方面明显优于现有解决方案。它在以下方面实现了高达0.1027的绝对增益Recall@20在冷启动场景中，所有捆绑场景的相对改善率高达47.43%。 et.al.|[2505.05035](http://arxiv.org/abs/2505.05035)|null|
|**2025-05-08**|**Advanced 3D Imaging Approach to TSV/TGV Metrology and Inspection Using Only Optical Microscopy**|本文介绍了一种通过检测硅和玻璃的创新方法，该方法将混合场显微镜与光度立体相结合。传统的光学显微镜技术通常仅限于表面检查，难以有效地可视化硅和玻璃通孔的内部结构。通过利用各种光照条件进行3D重建，所提出的方法克服了这些局限性。通过将光度立体与传统光学显微镜相结合，所提出的方法不仅提高了检测微尺度缺陷的能力，而且提供了深度和边缘异常的详细可视化，这些异常通常在传统光学显微镜检查中是不可见的。实验结果表明，所提出的方法有效地捕捉了复杂的表面细节和内部结构。重建模型和实际测量值之间的定量比较表明，所提出的方法能够通过检测过程显著改善硅和玻璃。因此，所提出的方法在保持高精度和可重复性的同时实现了更高的成本效益，表明通过检测技术在硅和玻璃方面取得了实质性的进步 et.al.|[2505.04913](http://arxiv.org/abs/2505.04913)|null|
|**2025-05-07**|**Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation**|视觉以其在操纵中的应用而闻名，特别是使用视觉伺服。为了使其坚固耐用，需要多个摄像头来扩大视野。这在计算上具有挑战性。合并多个视图并使用Q-learning可以设计更有效的表示和优化样本效率。部署这样的解决方案可能很昂贵。为了缓解这一问题，我们引入了一种合并与去纠缠（MAD）算法，该算法有效地合并视图以提高采样效率，同时增加单视图功能以允许轻量级部署并确保稳健的策略。我们使用Meta World和ManiSkill3展示了我们的方法的效率和鲁棒性。有关项目网站和代码，请参阅https://aalmuzairee.github.io/mad et.al.|[2505.04619](http://arxiv.org/abs/2505.04619)|null|
|**2025-05-08**|**TetWeave: Isosurface Extraction using On-The-Fly Delaunay Tetrahedral Grids for Gradient-Based Mesh Optimization**|我们介绍了TetWeave，这是一种用于基于梯度的网格优化的新型等值面表示，它联合优化了用于行进四面体的四面体网格的放置，以及每个点处的新型方向符号距离。TetWeave通过Delaunay三角剖分动态构建四面体网格，与预定义网格相比具有更高的灵活性。提取的网格保证水密、双流形和无交叉。TetWeave的灵活性使重采样策略成为可能，该策略在重建误差较高的地方放置新的点，并允许在不影响重建误差的情况下促进网格公平性。这导致了高质量、自适应的网格，需要最少的内存使用和很少的参数来优化。因此，TetWeave相对于输出网格的顶点数表现出近乎线性的内存缩放，这是对预定义网格的实质性改进。我们展示了TetWeave在计算机图形学和视觉领域广泛的挑战性任务中的适用性，如多视图3D重建、网格压缩和几何纹理生成。 et.al.|[2505.04590](http://arxiv.org/abs/2505.04590)|**[link](https://github.com/AlexandreBinninger/TetWeave)**|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-09**|**Long time behaviour of Mean Field Games with fractional diffusion**|本文研究了具有分数扩散的平均场博弈系统的长时间行为，对参与者的个体动力学由独立跳跃过程驱动并通过漂移项控制的情况进行了建模，同时受到外部场的限制，以确保遍历性。在全局Lipschitz、局部一致凸哈密顿量和弱耦合成本满足Lasry-Lions单调性条件的情况下，我们证明了 $（0，T）$中的平均场博弈问题存在唯一解$（u_T，m_T）$，并且我们证明，如果$T$足够大，$（u-T，m_ T）$ 满足所谓的收费公路性质，即它在任何成比例的长中间时间内都指数接近（唯一）平稳遍历状态。 et.al.|[2505.06183](http://arxiv.org/abs/2505.06183)|null|
|**2025-05-09**|**DiffLocks: Generating 3D Hair from a Single Image using Diffusion Models**|我们解决了从单个图像生成3D头发几何形状的任务，由于发型的多样性和缺乏成对的图像到3D头发数据，这是一项具有挑战性的任务。以前的方法主要是在合成数据上进行训练，并通过使用低维中间表示（如引导线和头皮级嵌入）来处理有限数量的此类数据，这些表示需要后处理来解码、上采样和增加真实感。这些方法无法重建详细的头发，难以处理卷发，或者仅限于处理少数发型。为了克服这些局限性，我们提出了DiffLocks，这是一种新颖的框架，可以直接从单个图像中详细重建各种发型。首先，我们通过自动化创建迄今为止最大的合成头发数据集来解决缺乏3D头发数据的问题，该数据集包含40K种发型。其次，我们利用合成头发数据集来学习一个图像条件扩散变换器模型，该模型从单个正面图像中生成精确的3D线条。通过使用预训练的图像骨干，我们的方法可以推广到野外图像，尽管只在合成数据上训练。我们的扩散模型预测头皮纹理图，其中图中的任何点都包含单个发束的潜在代码。这些代码直接解码为3D链，无需后处理技术。代表单个发束，而不是引导发束，使转换器能够模拟复杂发型的详细空间结构。有了这个，DiffLocks可以首次从单张图像中恢复高度卷曲的头发，比如非洲发型。数据和代码可在https://radualexandru.github.io/difflocks/ et.al.|[2505.06166](http://arxiv.org/abs/2505.06166)|null|
|**2025-05-09**|**A sample of ionised Fe line-emitting X-ray sources in the inner Galactic disc**|先前的研究表明，银河系的漫射X射线发射是由未解决的点源组成的，主要是mCV。然而，与漫射X射线发射相比，附近的mCV具有低得多的6.7keV线等效宽度（ $rm EW_{6.7}$）。因此，尚未解决的X射线发射的主要原因尚不清楚。我们使用XMM-Newton对银河系内部盘的观测，在6.5-7keV波段共检测到859个源，其中72个源在6.7keV处显示出明显的铁线发射。这72个源的光谱指数$\Gamma$的分布是双峰的，峰值分别为$\Gamma=0.5\pm0.4$和$1.8\pm0.3$，表明存在两个源群。软X射线源的EW_{6.7}$比硬X射线源大得多。此外，32个硬源中有18个与先前已知的CV相关联。我们将样本中的CV候选者确定为光谱指数$\Gamma<1.25$的候选者。线比、2-10keV的光度和之前对自旋周期的检测表明，这些硬源中的大多数是mCV。先前识别和候选CV的组合样本的$rm EW_{6.7}$线的分布平均值为<$rm EW_{6.7}$>$=415\pm39$eV。此外，我们计算了不同通量组在6.5-7keV带中检测到的所有源的堆叠光谱，我们在硬源的堆叠谱中发现了证据，表明$rm EW_1{6.7}}随着通量的减小而增加。软X射线源具有<$\rm EW_{6.7}$>$=1.1\pm0.1$keV。我们确定了与活动恒星、年轻恒星物体和RS-CVn型活动双星相关的30个软源中的13个。我们的CV候选样本的<$\rm EW_{6.7}$>是500 pc内mCV中发现的典型$\rm EW_{6.7}$的两倍多，我们的CV候选者样本的<$\rm EW_{6.7}$>接近银河系漫射X射线发射的$\ rm EW_{0.7}$ 值。 et.al.|[2505.06164](http://arxiv.org/abs/2505.06164)|null|
|**2025-05-09**|**Control of encounter kinetics by chemically active droplets**|生物分子凝聚物在生命物质的空间组织中起着至关重要的作用。这些由液液相分离产生的无膜细胞器在远离热力学平衡的情况下运行，其大小和稳定性受到非平衡化学反应的影响。虽然冷凝物通常被认为是增强分子相遇的优化纳米反应器，但由于扩散阻碍和非特异性冷凝物中的随机捕获等竞争效应，它们对反应动力学的实际影响尚不清楚。在这项研究中，我们开发了一个化学活性液滴的微观随机模型，该模型结合了反应驱动的蛋白质相互作用调节。利用布朗动力学模拟，我们研究了蛋白质相互作用和与自由能库的主动耦合如何影响相分离、分子输运和反应动力学。我们证明了化学驱动的强度控制着表面动力学，产生了调节双分子反应速率的通量。将活性乳液与均相体系进行比较，我们发现冷凝物可以加速或减速分子相遇。我们的研究结果为生物分子冷凝物作为细胞内反应动力学潜在调节因子的作用提供了关键见解。 et.al.|[2505.06153](http://arxiv.org/abs/2505.06153)|null|
|**2025-05-09**|**Photovoltaic Defect Image Generator with Boundary Alignment Smoothing Constraint for Domain Shift Mitigation**|光伏电池的精确缺陷检测对于确保智能光伏制造系统的质量和效率至关重要。然而，丰富缺陷数据的稀缺性给有效的模型训练带来了巨大挑战。虽然现有的方法已经探索了生成模型来增强数据集，但它们往往存在不稳定、多样性有限和领域转移的问题。为了解决这些问题，我们提出了PDIG，一种基于稳定扩散（SD）的光伏缺陷图像生成器。PDIG利用从大规模数据集中学习到的强先验知识，在有限的数据下提高发电质量。具体来说，我们引入了一个语义概念嵌入（SCE）模块，该模块结合了文本条件先验来捕获缺陷类型与其外观之间的关系概念。为了进一步丰富领域分布，我们设计了一种轻量级工业风格适配器（LISA），通过交叉解纠缠注意力将工业缺陷特征注入SD模型。在推理过程中，我们提出了一个文本图像双空间约束（TIDSC）模块，通过位置一致性和空间平滑对齐来提高生成图像的质量。大量实验表明，与最先进的方法相比，PDIG具有更高的真实感和多样性。具体来说，我们的方法将Frechet Inception Distance（FID）比次优方法提高了19.16分，并显著提高了下游缺陷检测任务的性能。 et.al.|[2505.06117](http://arxiv.org/abs/2505.06117)|null|
|**2025-05-09**|**Deep Diffusion Maps**|机器学习领域的一个基本问题是降维。降维方法可以对抗所谓的维数灾难，可视化高维数据，并提高存储和处理大型数据集的效率。最著名的非线性降维方法之一是扩散图。然而，尽管扩散图和许多其他基于核矩阵谱分解的流形学习方法具有优点，但它们都有缺点，例如无法将它们应用于初始集之外的数据、计算复杂性以及大型数据集的高内存成本。在这项工作中，我们建议通过采用深度学习来缓解这些问题。具体来说，提供了一种新的扩散图嵌入公式，作为解决某个无约束最小化问题的方案，并在此基础上提供了一个成本函数来训练神经网络，该网络在训练样本内外计算扩散图嵌入，而不需要执行任何谱分解。这种方法的能力在不同的数据集上进行了比较，包括真实数据集和合成数据集，与扩散图和Nystrom方法的能力进行了比较。 et.al.|[2505.06087](http://arxiv.org/abs/2505.06087)|**[link](https://github.com/sgh14/deep-diffusion-maps)**|
|**2025-05-09**|**Neutron scattering studies of complex lattice dynamics in energy materials**|晶格动力学在理解尖端能源材料的物理机制方面起着至关重要的作用。许多优秀的能量材料具有复杂的多子晶格结构，晶格动力学复杂，其潜在机制难以理解。中子散射技术以其高能量和动量分辨率而闻名，是同时表征材料结构和复杂晶格动力学的强大工具。近年来，中子散射技术为能量材料的研究做出了重大贡献，揭示了它们的物理机制。本文详细介绍了能量材料研究中常用的几种中子散射技术，包括中子衍射、全中子散射、准弹性和非弹性中子散射。然后，回顾了近年来以中子散射为主要表征方法在能量材料领域取得的一些重要研究进展，包括超离子热电材料的超低晶格热导率、固态电解质的离子扩散机理、压热材料的塑性晶体相变和组态熵变、光伏材料的晶格非谐性和电荷输运，以及磁热材料的一阶磁结构相变。在这些复杂的能量转换和存储材料中，晶格动力学不是独立工作的，它们在宏观物理性质中的作用总是通过与其他自由度（如子晶格、电荷、自旋等）的相关性或相互耦合来实现的。通过这些典型例子，本文可以为进一步探索和理解能量材料和晶格动力学提供参考。 et.al.|[2505.06076](http://arxiv.org/abs/2505.06076)|null|
|**2025-05-09**|**Noise-Consistent Siamese-Diffusion for Medical Image Synthesis and Segmentation**|深度学习已经彻底改变了医学图像分割，但它的全部潜力仍然受到注释数据集不足的限制。虽然扩散模型已成为生成合成图像掩模对以增强这些数据集的有前景的方法，但矛盾的是，它们也面临着旨在缓解的数据稀缺挑战。传统的仅掩模模型由于无法充分捕捉形态的复杂性而经常产生低保真度图像，这可能会严重损害分割模型的鲁棒性和可靠性。为了缓解这一局限性，我们引入了暹罗扩散，这是一种由掩模扩散和图像扩散组成的新型双分量模型。在训练过程中，在这些组件之间引入噪声一致性损失，以提高参数空间中掩模扩散的形态保真度。在采样过程中，只使用掩模扩散，确保多样性和可扩展性。综合实验证明了我们方法的优越性。Siamese Diffusion在Polyps上使SANet的mDice和mIoU分别提高了3.6%和4.4%，而在ISIC2018上，UNet分别提高了1.52%和1.64%。代码可以在GitHub上找到。 et.al.|[2505.06068](http://arxiv.org/abs/2505.06068)|**[link](https://github.com/qiukunpeng/siamese-diffusion)**|
|**2025-05-09**|**Omni-Temporal Theory and Simulation of Hydrodynamic Dispersion using Fourier Transformation**|流体动力学弥散决定了具有强速度梯度流动的各种化学、地质和生物系统中溶质混合的程度和表观扩散通量。虽然已建立的分散理论捕捉到了扩散、流动和反应速率之间的瞬态相互作用，但在流动的特征时间尺度大大超过孔隙尺度扩散的情况下，通常采用长期近似。在这里，我们引入了一种基于频率的理论来模拟通过多孔介质的全时色散，该多孔介质同时捕获色散的快分量和慢分量。为了建立这一理论，我们形式化地对傅里叶变换的溶质孔尺度平流扩散方程进行体积平均，并获得周期性晶胞的放大输运系数：弥散张量、平流抑制向量和反应速率系数。这些系数双重充当传递函数，将某些输出与频域中的输入量相关联，从而能够使用傅里叶逆变换预测放大的时间动态。通过推导平行板间和圆管内泊肃叶流情况下色散系数的解析表达式，证明了它们的实用性。这种全时理论为非活性平行板之间的快速溶质脉冲产生了突破曲线，与直接数值模拟（DNS）预测的溶质传播速率一致，而传统的渐近理论则高估了几个数量级。溶质峰值幅度与DNS的偏差被证明是由溶质反向扩散到入口平面以及入口区域效应引起的，这可以通过闭合变量b的非周期性变化来证明。 et.al.|[2505.06063](http://arxiv.org/abs/2505.06063)|null|
|**2025-05-09**|**Towards Better Cephalometric Landmark Detection with Diffusion Data Generation**|头影测量标志物检测对于正畸诊断和治疗计划至关重要。然而，数据收集中样本的稀缺以及手动注释所需的大量工作严重阻碍了不同数据集的可用性。这种局限性限制了基于深度学习的检测方法的有效性，特别是基于大规模视觉模型的检测方法。为了应对这些挑战，我们开发了一种创新的数据生成方法，能够在没有人为干预的情况下生成各种头影测量X射线图像以及相应的注释。为了实现这一目标，我们的方法首先使用解剖先验构建新的头影测量界标注释。然后，我们使用基于扩散的生成器来创建与这些注释紧密对应的逼真X射线图像。为了在生产具有不同属性的样本时实现精确控制，我们引入了一种新的快速头影测量X射线图像数据集。该数据集包括真实的头影测量X射线图像和描述图像的详细医学文本提示。通过利用这些详细的提示，我们的方法改进了生成过程，以控制不同的样式和属性。在大量、多样化的生成数据的推动下，我们将大规模视觉检测模型引入头影测量界标检测任务中，以提高准确性。实验结果表明，使用生成的数据进行训练可以显著提高性能。与不使用生成数据的方法相比，我们的方法将成功检测率（SDR）提高了6.5%，达到了显著的82.2%。所有代码和数据均可在以下网址获得：https://um-lab.github.io/cepha-generation et.al.|[2505.06055](http://arxiv.org/abs/2505.06055)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-30**|**Neural Co-Optimization of Structural Topology, Manufacturable Layers, and Path Orientations for Fiber-Reinforced Composites**|我们提出了一种基于神经网络的计算框架，用于同时优化结构拓扑、弯曲层和路径方向，以在确保可制造性的同时实现纤维增强热塑性复合材料的强各向异性强度。我们的框架采用三个隐式神经场来表示几何形状、层序列和纤维取向。这使得设计和可制造性目标（如各向异性强度、结构体积、机器运动控制、层曲率和层厚度）能够直接公式化为一个集成和可微分的优化过程。通过将这些目标作为损失函数，该框架确保了所得复合材料具有优化的机械强度，同时保持了其在不同硬件平台上基于长丝的多轴3D打印的可制造性。物理实验表明，与具有顺序优化结构和制造顺序的复合材料相比，我们的协同优化方法产生的复合材料的破坏载荷可以提高33.1%。 et.al.|[2505.03779](http://arxiv.org/abs/2505.03779)|null|
|**2025-05-05**|**A New Perspective To Understanding Multi-resolution Hash Encoding For Neural Fields**|Instant NGP是近年来最先进的神经场架构。其令人难以置信的信号拟合能力通常归因于其多分辨率哈希网格结构，并在许多后续工作中得到了使用和改进。然而，目前尚不清楚这种哈希网格结构如何以及为什么能够如此大幅度地提高神经网络的能力。对哈希网格缺乏原则性的理解也意味着，伴随Instant NGP的大量超参数只能通过经验进行调整，而没有太多的启发式方法。为了直观地解释哈希网格的工作原理，我们提出了一种新的视角，即域操作。这一视角提供了一种全新的解释，即特征网格如何学习目标信号，并通过人工创建多个预先存在的线性段来提高神经场的表现力。我们对精心构建的一维信号进行了大量实验，以实证支持我们的主张，并辅助我们的说明。虽然我们的分析主要集中在一维信号上，但我们表明这个想法可以推广到更高的维度。 et.al.|[2505.03042](http://arxiv.org/abs/2505.03042)|null|
|**2025-04-27**|**HumMorph: Generalized Dynamic Human Neural Fields from Few Views**|我们介绍了HumMorph，这是一种新的广义方法，用于在显式姿态控制下对动态人体进行自由视点渲染。HumMorph以任意姿势渲染给定几个观察到的视图（从一个开始）的任何指定姿势的人类演员。我们的方法能够实现快速推理，因为它只依赖于通过模型的前馈传递。我们首先在规范T姿势中构建演员的粗略表示，该表示结合了来自个体部分观察的视觉特征，并使用学习到的先验知识填充缺失的信息。粗表示由直接从观察到的视图中提取的细粒度像素对齐特征补充，这些特征提供了高分辨率的外观信息。我们证明，当只有一个输入视图可用时，HumMorph与最先进的技术具有竞争力，但是，在仅进行2次单目观察的情况下，我们可以获得明显更好的视觉质量。此外，之前的广义方法假设可以使用同步的多相机设置获得精确的身体形状和姿势参数。相比之下，我们考虑了一种更实际的场景，其中这些身体参数直接从观察到的视图中进行噪声估计。我们的实验结果表明，我们的架构对噪声参数中的误差更具鲁棒性，在这种情况下明显优于最新技术。 et.al.|[2504.19390](http://arxiv.org/abs/2504.19390)|null|
|**2025-04-24**|**Geometry aware inference of steady state PDEs using Equivariant Neural Fields representations**|神经场的最新进展使学习神经算子的强大离散不变方法成为可能，这些算子在一般几何上近似偏微分方程（PDE）的解。基于这些发展，我们引入了enf2enf，这是一种基于最近提出的等变神经场架构的编码器-解码器方法，用于预测具有非参数化几何变异性的稳态偏微分方程。在enf2enf中，输入几何被编码为潜在的点云嵌入，这些嵌入固有地保留了几何基础并捕获了局部现象。然后将得到的表示与全局参数相结合，并直接解码为连续的输出场，从而有效地对几何和物理之间的耦合进行建模。通过利用局部性和平移不变性的归纳偏差，我们的方法能够捕捉精细尺度的物理特征以及复杂的形状变化，从而增强泛化能力和物理顺应性。对高保真空气动力学数据集、超弹性材料基准和多元素翼型几何形状的广泛实验表明，与最先进的基于图、操作员学习和神经场的方法相比，所提出的模型具有更优越或更具竞争力的性能。值得注意的是，我们的方法支持实时推理和零样本超分辨率，能够在低分辨率网格上进行高效训练，同时保持全尺寸离散化的高精度。 et.al.|[2504.18591](http://arxiv.org/abs/2504.18591)|null|
|**2025-04-28**|**Physics-Driven Neural Compensation For Electrical Impedance Tomography**|电阻抗断层成像（EIT）提供了一种非侵入性的便携式成像方式，在医疗和工业应用中具有巨大的潜力。尽管EIT具有优势，但它遇到了两个主要挑战：其逆问题的不适定性质和空间可变、位置相关的灵敏度分布。传统的基于模型的方法通过正则化来减轻病态性，但忽略了灵敏度的可变性，而监督深度学习方法需要大量的训练数据，缺乏泛化能力。神经领域的最新发展引入了用于图像重建的隐式正则化技术，但这些方法通常忽略了EIT背后的物理原理，从而限制了它们的有效性。在这项研究中，我们提出了PhyNC（物理驱动神经补偿），这是一个无监督的深度学习框架，结合了EIT的物理原理。PhyNC通过动态地将神经表征能力分配给灵敏度较低的区域，确保准确和平衡的电导率重建，解决了不适定逆问题和灵敏度分布问题。对模拟和实验数据的广泛评估表明，PhyNC在细节保存和抗伪影方面优于现有方法，特别是在低灵敏度区域。我们的方法增强了EIT重建的鲁棒性，并提供了一个灵活的框架，可以适应具有类似挑战的其他成像方式。 et.al.|[2504.18067](http://arxiv.org/abs/2504.18067)|null|
|**2025-04-23**|**Spot solutions to a neural field equation on oblate spheroids**|理解神经场中激发模式的动力学是神经科学的一个重要课题。神经场方程是描述相互作用神经元的激发动力学以进行理论分析的数学模型。尽管许多神经场方程的分析都集中在神经元相互作用对平面的影响上，但在对大脑等器官进行建模时，动力学的几何约束也是一个有吸引力的话题。本文报道了在球体作为模型曲面上定义的神经场方程中的模式动力学。我们将点解视为局部模式，并讨论曲面的几何特性如何改变它们的特性。为了分析具有小展平的球体上的斑点模式，我们首先在球面上构造精确的静止斑点解，并揭示它们的稳定性。然后，我们扩展了分析，以证明球状情况下驻点解的存在性和稳定性。我们的一个理论结果是推导了扁球体极点处定域的驻点解的稳定性判据。该标准决定了点解是保持在极点还是移动。最后，我们进行了数值模拟，根据我们的理论预测讨论了点解的动力学。我们的结果表明，点解的动力学取决于曲面和神经相互作用的协调。 et.al.|[2504.16342](http://arxiv.org/abs/2504.16342)|null|
|**2025-04-22**|**Low-Rank Adaptation of Neural Fields**|处理视觉数据通常涉及微小的调整或变化序列，例如图像滤波、表面平滑和视频存储。虽然现有的图形技术，如法线映射和视频压缩，利用冗余来有效地对这种小变化进行编码，但对神经场（NF）的小变化（视觉或物理功能的神经网络参数化）进行编码的问题却很少受到关注。我们提出了一种使用低秩自适应（LoRA）更新神经场的参数高效策略。LoRA是一种来自参数高效微调LLM社区的方法，它以最小的计算开销对预训练模型进行小更新编码。我们使LoRA适应特定于实例的神经场，避免了对大型预训练模型的需求，从而产生了适用于低计算硬件的流水线。我们通过图像滤波、视频压缩和几何编辑的实验验证了我们的方法，证明了它在表示神经场更新方面的有效性和通用性。 et.al.|[2504.15933](http://arxiv.org/abs/2504.15933)|null|
|**2025-04-21**|**Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields**|弱引力透镜是星系形状的轻微扭曲，主要是由宇宙中暗物质的引力效应引起的。在我们的工作中，我们试图从2D望远镜图像中反转弱透镜信号，以重建宇宙暗物质场的3D图。虽然反演通常会产生暗物质场的二维投影，但暗物质分布的精确三维图对于定位感兴趣的结构和测试我们宇宙的理论至关重要。然而，3D反演带来了重大挑战。首先，与依赖于多个视点的标准3D重建不同，在这种情况下，图像仅从单个视点观察。通过观察整个体积中的星系发射器是如何被透镜化的，可以部分解决这一挑战。然而，这导致了第二个挑战：无透镜星系的形状和确切位置是未知的，只能在非常大的不确定性下进行估计。这引入了大量的噪声，几乎完全淹没了透镜信号。以前的方法通过对卷中的结构施加强有力的假设来解决这个问题。相反，我们提出了一种使用引力约束神经场来灵活模拟连续物质分布的方法。我们采用综合分析方法，通过完全可微的物理正向模型优化神经网络的权重，以再现图像测量中存在的透镜信号。我们展示了我们的模拟方法，包括模拟即将到来的望远镜调查数据的暗物质分布的真实模拟测量。我们的结果表明，我们的方法不仅可以超越以前的方法，而且重要的是还能够恢复潜在的令人惊讶的暗物质结构。 et.al.|[2504.15262](http://arxiv.org/abs/2504.15262)|null|
|**2025-04-20**|**Efficient Implicit Neural Compression of Point Clouds via Learnable Activation in Latent Space**|隐式神经表示（INR），也称为神经场，已成为深度学习中的一种强大范式，使用基于坐标的神经网络对连续空间场进行参数化。在本文中，我们提出了\textbf{PICO}，这是一个基于INR的静态点云压缩框架。与主流的编码器-解码器范式不同，我们将点云压缩任务分解为两个单独的阶段：几何压缩和属性压缩，每个阶段都有不同的INR优化目标。受Kolmogorov-Arnold网络（KANs）的启发，我们引入了一种新的网络架构\textbf{LeAFNet}，它利用潜在空间中的可学习激活函数来更好地近似目标信号的隐函数。通过将点云压缩重新表述为神经参数压缩，我们通过量化和熵编码进一步提高了压缩效率。实验结果表明，\textbf{LeAFNet}在基于INR的点云压缩中优于传统的MLP。此外，与当前的MPEG点云压缩标准相比，\textbf{PICO}实现了卓越的几何压缩性能，D1 PSNR平均提高了4.92 $dB。在联合几何和属性压缩方面，我们的方法表现出了极具竞争力的结果，平均PCQM增益为2.7美元乘以10^{-3}$ 。 et.al.|[2504.14471](http://arxiv.org/abs/2504.14471)|null|
|**2025-04-17**|**Radial Basis Function Techniques for Neural Field Models on Surfaces**|我们提出了一种使用径向基函数（RBF）插值和求积求解曲面上神经场方程的数值框架。神经场模型描述了宏观大脑活动的演变，但建模研究往往忽视了弯曲皮质区域的复杂几何形状。传统的数值方法，如有限元或谱方法，在计算上可能很昂贵，并且在不规则域上实现具有挑战性。相比之下，基于RBF的方法提供了一种灵活的替代方案，通过提供插值和正交方案，以高阶精度有效地处理任意几何形状。我们首先为一般曲面上的神经场模型开发了一个基于RBF的插值投影框架。详细推导了平面和曲面域的求积法，确保了高阶精度和稳定性，因为它们取决于RBF超参数（基函数、增广多项式和模板大小）。通过数值实验，我们证明了我们的方法的收敛性，突出了它在灵活性和准确性方面优于传统方法。最后，我们阐述了复杂表面上时空活动的数值模拟，说明了该方法捕捉复杂波传播模式的能力。 et.al.|[2504.13379](http://arxiv.org/abs/2504.13379)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

