---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.06.27
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-26**|**MultiDiff: Consistent Novel View Synthesis from a Single Image**|我们介绍了MultiDiff，这是一种从单个RGB图像中对场景进行一致新颖视图合成的新方法。从单个参考图像合成新视图的任务是自然造成的，因为对未观察到的区域存在多种看似合理的解释。为了解决这个问题，我们以单目深度预测器和视频扩散模型的形式结合了强先验。单目深度使我们能够根据目标视图的扭曲参考图像来调整模型，从而提高几何稳定性。视频扩散先验为3D场景提供了强大的代理，允许模型学习生成图像之间的连续和像素精确的对应关系。与依赖于易于漂移和误差累积的自回归图像生成的方法不同，MultiDiff联合合成一系列帧，从而产生高质量和多视图一致的结果——即使是对于具有大相机移动的长期场景生成，同时将推理时间减少一个数量级。为了进一步提高一致性和图像质量，我们引入了一种新颖的结构化噪声分布。我们的实验结果表明，MultiDiff在具有挑战性的真实世界数据集RealEstate10K和ScanNet上优于最先进的方法。最后，我们的模型自然支持多视图一致性编辑，而无需进一步调整。 et.al.|[2406.18524](http://arxiv.org/abs/2406.18524)|null|
|**2024-06-26**|**XLD: A Cross-Lane Dataset for Benchmarking Novel Driving View Synthesis**|彻底测试自动驾驶系统对于追求安全的自动驾驶汽车至关重要。这就需要创建超出现实世界数据安全收集范围的安全关键场景，因为其中许多场景在公共道路上很少发生。然而，大多数现有NVS方法的评估依赖于对来自训练数据的图像帧的零星采样，使用度量将渲染图像与真实图像进行比较。遗憾的是，该评估协议不能满足闭环仿真的实际要求。具体而言，真正的应用程序需要渲染超出原始轨迹的新颖视图（如跨车道视图）的能力，而这些视图在现实世界中很难捕捉。为了解决这一问题，本文提出了一种专门为自动驾驶模拟设计的新型驾驶视图合成数据集和基准。该数据集是独特的，因为它包括通过偏离训练轨迹1-4米而捕获的测试图像。它包括六个序列，包括不同的时间和天气条件。每个序列包含450个训练图像、150个测试图像以及它们对应的相机姿态和固有参数。利用这一新颖的数据集，我们建立了第一个现实的基准，用于在仅前置和多摄像头设置下评估现有的NVS方法。实验结果强调了当前方法中存在的显著差距，揭示了它们不足以满足跨车道或闭环模拟的苛刻先决条件。我们的数据集在项目页面上公开发布：https://3d-aigc.github.io/XLD/. et.al.|[2406.18360](http://arxiv.org/abs/2406.18360)|null|
|**2024-06-26**|**VDG: Vision-Only Dynamic Gaussian for Driving Simulation**|动态高斯飞溅已经在新颖的视图中带来了令人印象深刻的场景重建和图像合成进展。然而，现有的方法在很大程度上依赖于预先计算的姿态和通过运动结构（SfM）算法或昂贵的传感器进行的高斯初始化。本文首次通过将自监督VO集成到我们的无姿态动态高斯方法（VDG）中来解决这个问题，以促进姿态和深度初始化以及静态动态分解。此外，与无姿态动态视图合成方法相比，VDG可以仅使用RGB图像输入，以更快的速度和更大的场景构建动态场景。我们通过大量的定量和定性实验证明了我们的方法的稳健性。与最先进的动态视图合成方法相比，我们的结果显示出良好的性能。其他视频和源代码将发布在我们的项目页面上https://3d-aigc.github.io/VDG. et.al.|[2406.18198](http://arxiv.org/abs/2406.18198)|null|
|**2024-06-26**|**View-Invariant Pixelwise Anomaly Detection in Multi-object Scenes with Adaptive View Synthesis**|基础设施资产的检查和监控通常需要识别随着时间的推移定期拍摄的场景中的视觉异常。手动或使用机器人（如无人机）在不同时间点从同一场景收集的图像通常不会完全对齐。有监督的分割方法可以用于识别已知问题，但当出现未知异常时，需要无监督的异常检测方法。当前的无监督像素级异常检测方法主要是针对相机位置已知且恒定的工业环境开发的。然而，我们发现这些方法不能推广到图像没有完全对齐的情况。我们将两组不完全对齐的图像之间的无监督异常检测问题称为场景异常检测（Scene AD）。我们提出了一种称为OmniAD的新型网络来解决场景AD问题。具体来说，我们改进了异常检测方法反向蒸馏，以实现像素级异常检测性能提高40%。提出了两种新的数据增强策略，利用新颖的视图合成和相机定位来提高泛化能力，进一步证明了网络的性能得到了改善。我们在新的数据集ToyCity上验证了我们的方法，ToyCity是第一个具有多个对象的场景广告数据集，以及在已建立的以单个对象为中心的数据集MAD上验证了定性和定量结果。https://drags99.github.io/OmniAD/ et.al.|[2406.18012](http://arxiv.org/abs/2406.18012)|null|
|**2024-06-25**|**NerfBaselines: Consistent and Reproducible Evaluation of Novel View Synthesis Methods**|新颖的视图合成是许多应用中的一个重要问题，包括AR/VR、游戏和机器人模拟。随着神经辐射场（NeRF）和3D高斯散射（3DGS）方法的快速发展，由于使用不同评估协议的方法、难以安装和使用的代码库以及不能很好地推广到新的3D场景的方法，跟踪当前技术状态（SoTA）变得越来越困难。我们的实验支持了这一说法，表明各种方法的评估协议之间的微小差异可能导致报告的指标不一致。为了解决这些问题，我们提出了一个名为NerfBaselines的框架，它简化了各种方法的安装，提供了一致的基准测试工具，并确保了可重复性。我们通过复制原始论文中报告的数字来实验验证我们的实现。为了进一步提高可访问性，我们发布了一个网络平台，在标准基准上对常用方法进行比较。网状物https://jkulhanek.com/nerfbaselines et.al.|[2406.17345](http://arxiv.org/abs/2406.17345)|null|
|**2024-06-24**|**Reducing the Memory Footprint of 3D Gaussian Splatting**|3D高斯飞溅为新颖的视图合成提供了卓越的视觉质量，具有快速训练和实时渲染；不幸的是，这种方法对存储和传输的内存要求非常高。我们首先分析了原因，确定了可以减少存储的三个主要区域：用于表示场景的3D高斯基元的数量、用于表示方向辐射的球面谐波的系数数量以及存储高斯基元属性所需的精度。我们提出了每一个问题的解决方案。首先，我们提出了一种高效的、具有分辨率意识的原始修剪方法，将原始计数减少一半。其次，我们引入了一种自适应调整方法来选择用于表示每个高斯基元的方向辐射的系数数量，最后引入了一个基于码本的量化方法，以及用于进一步减少内存的半浮点表示。总之，这三个组件使我们测试的标准数据集的磁盘总大小减少了27，同时渲染速度加快了1.7。我们在标准数据集上演示了我们的方法，并展示了在移动设备上使用该方法时，我们的解决方案如何显著缩短下载时间。 et.al.|[2406.17074](http://arxiv.org/abs/2406.17074)|null|
|**2024-06-24**|**Articulate your NeRF: Unsupervised articulated object modeling via conditional view synthesis**|我们提出了一种新的无监督方法来学习具有刚性零件的关节对象的姿态和零件分割。给定一个物体在不同关节状态下的两个观察结果，我们的方法通过使用第一个观察结果的隐式模型来学习物体零件的几何形状和外观，从第二个观察结果中提取零件分割和关节，同时呈现后一个观察结果。此外，为了解决零件分割和连接联合优化的复杂性，我们提出了一种基于体素网格的初始化策略和解耦优化程序。与先前的无监督工作相比，我们的模型获得了显著更好的性能，并推广到具有多个部分的对象，同时它可以有效地从少数视图进行后期观察。 et.al.|[2406.16623](http://arxiv.org/abs/2406.16623)|null|
|**2024-06-24**|**Crowd-Sourced NeRF: Collecting Data from Production Vehicles for 3D Street View Reconstruction**|最近，神经辐射场（NeRF）在新的视图合成中取得了令人印象深刻的结果。Block NeRF展示了利用NeRF构建大城市规模模型的能力。对于大规模建模，需要大量的图像数据。从专门设计的数据采集车上采集图像无法支持大规模应用。如何获取大量高质量的数据仍然是一个悬而未决的问题。注意到汽车行业拥有大量的图像数据，众包是大规模数据收集的便捷方式。在本文中，我们提出了一个众包框架，该框架利用生产车辆捕获的大量数据来使用NeRF模型重建场景。这种方法解决了大规模重建的关键问题，即数据来自哪里以及如何使用它们。首先，对众包海量数据进行过滤，以消除冗余，并在时间和空间上保持平衡分布。然后执行来自运动模块的结构来细化相机姿态。最后，使用图像以及姿势来训练某个块中的NeRF模型。我们强调，我们提出了一个综合框架，集成了多个模块，包括数据选择、稀疏3D重建、序列外观嵌入、地表深度监测和遮挡完成。完整的系统能够从众包数据中有效地处理和重建高质量的3D场景。进行了大量的定量和定性实验来验证我们的系统的性能。此外，我们提出了一个名为“第一视角导航”的应用程序，该应用程序利用NeRF模型生成3D街景，并用合成视频引导驾驶员。 et.al.|[2406.16289](http://arxiv.org/abs/2406.16289)|null|
|**2024-06-23**|**LiveScene: Language Embedding Interactive Radiance Fields for Physical Scene Rendering and Control**|本文旨在通过将交互式对象重构从单一对象层次扩展到复杂场景层次，推动物理世界交互式场景重构的进展。为此，我们首先构建了一个模拟和一个真实场景级的物理交互数据集，该数据集包含28个场景，每个场景具有多个交互对象。此外，为了准确地建模复杂场景中多个对象的交互运动，我们提出了LiveScene，这是第一个场景级语言嵌入的交互式神经辐射场，可以有效地重建和控制复杂场景中的多个交互对象。LiveScene引入了一种高效的因子分解，将交互式场景分解为多个局部可变形场，以单独重构单个交互式对象，实现了对复杂场景中多个交互式对象的首次精确独立控制。此外，我们引入了一种感知交互的语言嵌入方法，该方法生成不同的语言嵌入，以在不同的交互状态下定位各个交互对象，从而能够使用自然语言任意控制交互对象。最后，我们在构建的数据集OminiSim和InterReal上评估LiveScene，这些数据集具有各种模拟和真实世界的复杂场景。大量的实验结果表明，该方法实现了SOTA新的视图合成和语言基础性能，在CoNeRF Synthetic、OminiSim#通道和InterReal#通道数据集上的PSNR分别超过现有方法+9.89、+1.30和+1.99，在OminiSim上的mIOU分别超过了现有方法+65.12。项目页面：\ href{https://livescenes.github.io}{https://livescenes.github.io}. et.al.|[2406.16038](http://arxiv.org/abs/2406.16038)|null|
|**2024-06-21**|**Taming 3DGS: High-Quality Radiance Fields with Limited Resources**|三维高斯散点（3DGS）以其快速、可解释和高保真的渲染方式改变了新的视图合成，但其资源需求限制了其可用性。特别是在受约束的设备上，由于模型的过度内存消耗，训练性能会迅速下降，而且往往无法完成。该方法与不确定数量的高斯收敛——其中许多是冗余的——这使得渲染变得不必要地慢，并阻止了它在期望固定大小输入的下游任务中的使用。为了解决这些问题，我们在预算内解决训练和渲染3DGS模型的挑战。我们使用了一种有指导的、纯粹建设性的致密化过程，将致密化引向高斯，从而提高重建质量。模型大小以可控的方式不断增加，以达到精确的预算，使用基于分数的高斯密度和测量其贡献的训练时间先验。我们进一步解决了训练速度障碍：在仔细分析3DGS的原始管道后，我们导出了用于梯度计算和属性更新的更快、数值等效的解决方案，包括用于高效反向传播的替代并行化。我们还提出了在适当的情况下保持质量的近似值，以进一步减少训练时间。总之，这些增强功能提供了一个强健、可扩展的解决方案，减少了训练时间，降低了计算和内存需求，并具有高质量。我们的评估表明，在预算设置中，我们使用3DGS获得了有竞争力的质量指标，同时实现了模型大小和训练时间的4-5倍减少。有了更慷慨的预算，我们的衡量质量超过了他们。这些进步为受限环境（例如移动设备）中的新型视图合成打开了大门。 et.al.|[2406.15643](http://arxiv.org/abs/2406.15643)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-26**|**On Scaling Up 3D Gaussian Splatting Training**|三维高斯散射（3DGS）以其优越的视觉质量和渲染速度在三维重建中越来越受欢迎。然而，3DGS训练目前发生在单个GPU上，由于内存限制，限制了其处理高分辨率和大规模3D重建任务的能力。我们介绍了Grendel，这是一个分布式系统，旨在划分3DGS参数并在多个GPU之间并行计算。由于每个高斯影响渲染像素的一个小的动态子集，Grendel采用稀疏的全对全通信将必要的高斯传输到像素分区，并执行动态负载平衡。与一次使用一个相机视图图像进行训练的现有3DGS系统不同，Grendel支持使用多个视图进行批量训练。我们探索了各种优化超参数缩放策略，发现一个简单的sqrt（批量大小）缩放规则是非常有效的。使用大规模、高分辨率场景的评估表明，Grendel通过在多个GPU上放大3DGS参数来提高渲染质量。在Rubble数据集上，我们通过在16个GPU上分布4040万高斯实现了27.28的测试PSNR，而在单个GPU上使用1120万高斯实现的PSNR为26.28。Grendel是一个开源项目，位于：https://github.com/nyu-systems/Grendel-GS et.al.|[2406.18533](http://arxiv.org/abs/2406.18533)|**[link](https://github.com/nyu-systems/grendel-gs)**|
|**2024-06-26**|**Repeat and Concatenate: 2D to 3D Image Translation with 3D to 3D Generative Modeling**|本文研究了一种具有直接技术的2D到3D图像转换方法，使相关的2D X射线到3D CT类重建成为可能。我们观察到，现有的方法在潜在空间中集成多个2D视图的信息，在潜在编码过程中会丢失有价值的信号信息。相反，我们只是简单地重复2D视图并将其连接到更高的通道3D体积中，并将3D重建挑战作为一个简单的3D到3D生成建模问题来解决，从而避开了几个复杂的建模问题。这种方法使重建的3D体积能够保留来自2D输入的有价值的信息，这些信息在Swin UNETR主干中的信道状态之间传递。我们的方法应用了神经最优传输，它快速稳定地进行训练，有效地集成了多个视图中的信号信息，而不需要精确对齐；它产生了即使在有限的训练之后也高度忠实于2D视图的非塌陷重建。我们在单个数据集上训练了我们的模型，并评估了其在六个数据集（包括分布外样本）上的泛化能力，从而展示了定性和定量的相关结果。 et.al.|[2406.18422](http://arxiv.org/abs/2406.18422)|null|
|**2024-06-26**|**GS-Octree: Octree-based 3D Gaussian Splatting for Robust Object-level 3D Reconstruction Under Strong Lighting**|3D高斯散射技术显著推进了多视图图像辐射场的构建，实现了实时渲染。虽然基于点的光栅化有效地减少了渲染的计算需求，但它往往难以准确重建目标对象的几何结构，尤其是在强光下。为了应对这一挑战，我们引入了一种新的方法，将基于八叉树的隐式曲面表示与高斯飞溅相结合。我们的方法包括四个阶段。最初，它通过体积渲染重建有符号距离场（SDF）和辐射场，并将它们编码在低分辨率八叉树中。初始SDF表示目标对象的粗略几何图形。随后，它引入了3D高斯作为附加自由度，这些自由度由SDF引导。在第三阶段，优化的高斯进一步提高了SDF的精度，与第一阶段获得的初始SDF相比，可以恢复更精细的几何细节。最后，它采用了精细的SDF，通过飞溅进一步优化3D高斯，消除了对视觉外观贡献不大的高斯。实验结果表明，我们的方法利用了具有SDF的3D高斯分布，重建了更精确的几何体，特别是在具有由强光引起的镜面高光的图像中。 et.al.|[2406.18199](http://arxiv.org/abs/2406.18199)|null|
|**2024-06-25**|**Unified Auto-Encoding with Masked Diffusion**|在成功的生成和自我监督表示学习模型的核心，都有一个包含某种形式的图像腐败的重建目标。扩散模型通过预定的高斯破坏过程来实现这种方法，而掩蔽的自动编码器模型则通过掩蔽图像的块来实现。尽管它们的方法不同，但它们方法的潜在相似性为能够同时执行去噪任务的自动编码器提供了一条很有前途的途径。我们提出了一个统一的自监督目标，称为统一掩蔽扩散（UMD），它将基于补丁和基于噪声的破坏技术结合在一个单独的自动编码框架内。具体而言，UMD通过在扩散噪声调度中引入额外的无噪声、高掩蔽表示步骤来修改扩散变换器（DiT）训练过程，并将掩蔽和噪声的混合图像用于后续的时间步长。通过集成对扩散建模和预测屏蔽补丁令牌有用的特征，UMD在下游生成和表示学习任务中实现了强大的性能，包括线性探测和类条件生成。这是在不需要大量数据扩充、多视图或额外编码器的情况下实现的。此外，UMD在总训练时间上提高了先前基于扩散的方法的计算效率。我们在发布代码https://github.com/philippe-eecs/small-vision. et.al.|[2406.17688](http://arxiv.org/abs/2406.17688)|null|
|**2024-06-25**|**Test-Time Generative Augmentation for Medical Image Segmentation**|在本文中，我们提出了一种在测试期间增强医学图像分割的新方法。我们主张使用高级域微调生成模型（GM），例如稳定扩散（SD）来增加测试时间，而不是在输入测试图像上使用手工制作的变换或函数来创建多个视图以增加测试时间。考虑到GM已经被训练来理解和封装全面的领域数据知识，它在表示数据特征和分布方面优于分割模型。因此，通过将GM集成到测试时间扩充中，我们可以有效地生成给定测试样本的多个视图，与样本的内容和外观特征以及相关的局部数据分布保持一致。与传统的手工转换相比，这种方法使增强过程更具适应性和弹性。在三个医学图像分割任务（九个数据集）上进行的综合实验证明了所提出的TTGA在增强分割结果方面的有效性和多功能性。此外，TTGA显著提高了像素误差估计，从而有助于部署更可靠的分割系统。代码将在以下位置发布：https://github.com/maxiao0234/TTGA. et.al.|[2406.17608](http://arxiv.org/abs/2406.17608)|**[link](https://github.com/maxiao0234/ttga)**|
|**2024-06-25**|**SyncNoise: Geometrically Consistent Noise Prediction for Text-based 3D Scene Editing**|基于文本的二维扩散模型在图像生成和编辑方面表现出了令人印象深刻的能力。同时，2D扩散模型也表现出用于3D编辑任务的巨大潜力。然而，如何在多个视点之间实现一致的编辑仍然是一个挑战。虽然迭代数据集更新方法能够实现全局一致性，但它存在收敛缓慢和纹理过度平滑的问题。我们提出了SyncNoise，这是一种新颖的几何引导的多视图一致性噪声编辑方法，用于高保真3D场景编辑。SyncNoise使用2D扩散模型同步编辑多个视图，同时强制多视图噪声预测保持几何一致，从而确保语义结构和低频外观的全局一致性。为了进一步增强高频细节的局部一致性，我们设置了一组锚视图，并通过跨视图重投影将它们传播到相邻的帧。为了提高多视图对应的可靠性，我们在训练过程中引入了深度监督，以增强精确几何形状的重建。我们的方法通过增强噪声和像素级别的几何一致性，在尊重文本指令的情况下，特别是在具有复杂纹理的场景中，实现了高质量的3D编辑结果。 et.al.|[2406.17396](http://arxiv.org/abs/2406.17396)|null|
|**2024-06-24**|**Crowd-Sourced NeRF: Collecting Data from Production Vehicles for 3D Street View Reconstruction**|最近，神经辐射场（NeRF）在新的视图合成中取得了令人印象深刻的结果。Block NeRF展示了利用NeRF构建大城市规模模型的能力。对于大规模建模，需要大量的图像数据。从专门设计的数据采集车上采集图像无法支持大规模应用。如何获取大量高质量的数据仍然是一个悬而未决的问题。注意到汽车行业拥有大量的图像数据，众包是大规模数据收集的便捷方式。在本文中，我们提出了一个众包框架，该框架利用生产车辆捕获的大量数据来使用NeRF模型重建场景。这种方法解决了大规模重建的关键问题，即数据来自哪里以及如何使用它们。首先，对众包海量数据进行过滤，以消除冗余，并在时间和空间上保持平衡分布。然后执行来自运动模块的结构来细化相机姿态。最后，使用图像以及姿势来训练某个块中的NeRF模型。我们强调，我们提出了一个综合框架，集成了多个模块，包括数据选择、稀疏3D重建、序列外观嵌入、地表深度监测和遮挡完成。完整的系统能够从众包数据中有效地处理和重建高质量的3D场景。进行了大量的定量和定性实验来验证我们的系统的性能。此外，我们提出了一个名为“第一视角导航”的应用程序，该应用程序利用NeRF模型生成3D街景，并用合成视频引导驾驶员。 et.al.|[2406.16289](http://arxiv.org/abs/2406.16289)|null|
|**2024-06-23**|**MLPHand: Real Time Multi-View 3D Hand Mesh Reconstruction via MLP Modeling**|多视图手部网格重建是虚拟现实和人机交互应用中的一项关键任务，但它仍然是一项艰巨的挑战。尽管现有的多视角手部重建方法实现了显著的准确性，但它们通常会带来巨大的计算负担，阻碍实时推理。为此，我们提出了MLPHand，这是一种用于实时多视图单手重建的新方法。MLP-Hand由两个主要模块组成：（1）一个基于MLP的轻量级Skeleton2Mesh模型，可有效地从手部骨骼中恢复手部网格；（2）一个多视图几何特征融合预测模块，可利用来自多个视图的详细几何信息增强Skeleton4Mesh模型。在三个广泛使用的数据集上的实验表明，MLPHand可以将计算复杂度降低90%，同时实现与现有最先进基线相当的重建精度。 et.al.|[2406.16137](http://arxiv.org/abs/2406.16137)|null|
|**2024-06-23**|**Learning with Noisy Ground Truth: From 2D Classification to 3D Reconstruction**|深度神经网络在数据密集型计算机视觉应用中取得了巨大成功，而这种成功在很大程度上依赖于大量干净的数据。在现实世界中，有时很难获得干净的数据。例如，在图像分类和分割任务中，数百万个样本的精确注释通常非常昂贵和耗时。在3D静态场景重建任务中，大多数与NeRF相关的方法都需要对静态场景进行基本假设（例如，一致的照明条件和持久的物体位置），这在现实世界的场景中经常被违反。为了解决这些问题，带噪声地面实况学习（LNGT）已成为一种有效的学习方法，并显示出巨大的潜力。在这项简短的调查中，我们提出了一个正式的定义，将LNGT-LNGT的分析统一到不同机器学习任务（分类和回归）的背景下。基于这一定义，我们提出了一种新的分类法，根据机器学习的基本定义，根据误差分解对现有工作进行分类。此外，我们对记忆效应进行了深入分析，并对未来从2D分类到3D重建的潜在研究机会进行了深入讨论，希望为后续研究提供指导。 et.al.|[2406.15982](http://arxiv.org/abs/2406.15982)|null|
|**2024-06-22**|**psPRF:Pansharpening Planar Neural Radiance Field for Generalized 3D Reconstruction Satellite Imagery**|目前大多数卫星NeRF变体都是针对一个特定场景设计的，无法推广到新的几何结构。此外，RGB图像需要平移锐化作为独立的预处理步骤。本文介绍了psPRF，这是一种平面神经辐射场，用于使用有理多项式相机（RPC）从卫星传感器获得的成对低分辨率RGB（LR-RGB）和高分辨率全色（HR-PAN）图像。为了从LR-RGB和HR-PAN图像中捕获跨模态先验，对于Unet形结构，我们将编码器与显式频谱到空间卷积（SSConv）相适应，以增强多模态表示能力。为了支持psRPF跨场景的泛化能力，我们采用了投影损失来确保强大的几何自监督。使用多场景WorldView-3 LR-RGB和HR-PAN对对所提出的方法进行了评估，并实现了最先进的性能。 et.al.|[2406.15707](http://arxiv.org/abs/2406.15707)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-26**|**MultiDiff: Consistent Novel View Synthesis from a Single Image**|我们介绍了MultiDiff，这是一种从单个RGB图像中对场景进行一致新颖视图合成的新方法。从单个参考图像合成新视图的任务是自然造成的，因为对未观察到的区域存在多种看似合理的解释。为了解决这个问题，我们以单目深度预测器和视频扩散模型的形式结合了强先验。单目深度使我们能够根据目标视图的扭曲参考图像来调整模型，从而提高几何稳定性。视频扩散先验为3D场景提供了强大的代理，允许模型学习生成图像之间的连续和像素精确的对应关系。与依赖于易于漂移和误差累积的自回归图像生成的方法不同，MultiDiff联合合成一系列帧，从而产生高质量和多视图一致的结果——即使是对于具有大相机移动的长期场景生成，同时将推理时间减少一个数量级。为了进一步提高一致性和图像质量，我们引入了一种新颖的结构化噪声分布。我们的实验结果表明，MultiDiff在具有挑战性的真实世界数据集RealEstate10K和ScanNet上优于最先进的方法。最后，我们的模型自然支持多视图一致性编辑，而无需进一步调整。 et.al.|[2406.18524](http://arxiv.org/abs/2406.18524)|null|
|**2024-06-26**|**Denoising as Adaptation: Noise-Space Domain Adaptation for Image Restoration**|尽管基于深度学习的图像恢复方法已经取得了重大进展，但由于在合成数据上进行训练造成了巨大的领域差距，它们在对真实世界场景的泛化方面仍然存在局限性。现有的方法通过改进数据合成管道、估计退化核、采用深度内部学习以及执行域自适应和正则化来解决这个问题。先前的领域自适应方法试图通过在特征或像素空间中学习领域不变知识来弥合领域差距。然而，这些技术往往难以在稳定紧凑的框架内扩展到低级别的视觉任务。在本文中，我们证明了使用扩散模型通过噪声空间进行域自适应是可能的。特别是，通过利用多步骤去噪过程如何受到辅助条件输入影响的独特特性，我们从噪声预测中获得有意义的梯度，以逐步将合成数据和真实世界数据的恢复结果与共同的干净分布对齐。我们将这种方法称为自适应去噪。为了防止训练中出现捷径，我们提出了有用的技术，如通道洗牌和残差交换对比学习。在去噪、去模糊和去噪三个经典图像恢复任务上的实验结果证明了该方法的有效性。代码将在以下位置发布：https://github.com/KangLiao929/Noise-DA/. et.al.|[2406.18516](http://arxiv.org/abs/2406.18516)|**[link](https://github.com/kangliao929/noise-da)**|
|**2024-06-26**|**Ground states of a nonlocal variational problem and Thomas-Fermi limit for the Choquard equation**|我们研究了一个Gagliardo-Nirenberg型不等式 $$\iint_｛\mathbb｛R｝^N\times\mathbb｛R｛^N｝\frac｛|u（x）|^p\，|u（y）|^p｝｛x-y|^{N-\alpha}｝dx\，dy\le C\Big（\int_｛\ mathbb R｝^ N｝|u|^2 dx\Big）^｛p\theta｝\Big 1-\theta）/q}，$$，其涉及具有$0<\alpha<N$、$p>\frac{N+\alpha}{N}$、$q>\frac{2Np}{N+\aalpha}$和$\theta=\frac｛（N+\alpha）q-2Np}｛Np（q-2）}$的非局部Riesz能量。对于$p=2$，在过去的几十年里，已经结合Keller-Segel扩散-聚集模型研究了等效问题。这里考虑的一般情况$p\neq2$出现在具有局部排斥的Choquard方程的Thomas Fermi极限域的研究中。我们为上述插值不等式的有效性建立了参数的最优范围，讨论了非负最大化器的存在性和定性性质，并在一些特殊情况下估计了最优常数。对于$p=2$，已知最大化器是H\“较老的连续且紧支持在球上。我们证明了对于$p<2$，最大化器为支持在$\mathbb｛R｝^N$上的光滑函数，而对于$p>2$ ，最大值器由球的特征函数和支持在同一球上的非恒定不增H\”较老连续函数组成。我们使用最大化器的这些定性性质来建立具有局部排斥的Choquard方程的Thomas Fermi近似的有效性。通过大量实例对结果进行了数值验证。 et.al.|[2406.18472](http://arxiv.org/abs/2406.18472)|null|
|**2024-06-26**|**DiffuseHigh: Training-free Progressive High-Resolution Image Synthesis through Structure Guidance**|最近大规模生成模型的激增刺激了计算机视觉领域的广阔发展。特别是，文本到图像的扩散模型由于其高保真图像生成的潜力，已在不同领域得到广泛采用。尽管如此，现有的大规模扩散模型仅限于生成高达1K分辨率的图像，这远远不能满足当代商业应用的需求。直接对更高分辨率的图像进行采样通常会产生受伪影（如对象重复和扭曲形状）影响的结果。解决上述问题通常需要在更高分辨率的数据集上训练或微调模型。然而，由于难以收集大规模高分辨率内容和大量计算资源，这项工作带来了巨大的挑战。虽然之前的几项工作已经提出了替代方案，但它们往往无法产生令人信服的结果。在这项工作中，我们探索了扩散模型在更高分辨率下的生成能力，超过了其原始能力，并提出了一种新的渐进方法，该方法充分利用生成的低分辨率图像来指导更高分辨率图像的生成。我们的方法消除了对额外训练或微调的需要，这显著降低了计算成本的负担。大量的实验和结果验证了我们方法的有效性和有效性。 et.al.|[2406.18459](http://arxiv.org/abs/2406.18459)|null|
|**2024-06-26**|**How to Achieve High Spatial Resolution in Organic Optobioelectronic Devices?**|生物细胞的光激活局部刺激和传感为微创生物电子界面提供了巨大的潜力。有机半导体由于其光电特性和生物相容性，是实现这种转导的一类很有前途的材料。在这里，我们研究了哪些材料特性是保持光学激发局部化所必需的。这对于具有高空间分辨率的单细胞转导至关重要。作为模型系统，我们使用由小分子半导体H2Pc和PTCDI制成的用于细胞刺激的有机光电容器。我们用光电压显微镜测量研究了局域光学激发的空间加宽。我们的实验数据与建模相结合表明，由于激发的加宽而导致的分辨率损失与异质结处产生的电荷载流子的有效扩散长度直接相关。通过额外的瞬态光电压测量，我们发现H2Pc/PTCDI异质结由于电荷载流子沿着异质结的小迁移率而提供λ=1.5+/-0.1um的小扩散长度。相反，用PEDOT:PSS层覆盖异质结提高了光电容器性能，但由于更长的寿命和更高的载流子迁移率，载流子扩散长度增加到λ=7.0+/-0.3um。此外，我们介绍了电化学光电流显微镜实验，以证明在现实的水操作条件下pn结的微米分辨率。这项工作为控制激发和转导谱的物理机制提供了有价值的见解，并为未来的有机半导体结提供了设计原则，旨在实现高效率和高空间分辨率。 et.al.|[2406.18447](http://arxiv.org/abs/2406.18447)|null|
|**2024-06-26**|**Towards diffusion models for large-scale sea-ice modelling**|我们朝着无条件生成多元和北极宽海冰状态的扩散模型迈出了第一步。虽然目标是通过在潜在空间中的扩散来降低计算成本，但潜在扩散模型也提供了将物理知识集成到生成过程中的可能性。我们根据数据空间中具有截尾高斯分布的海冰物理来定制潜在扩散模型，以生成遵循建模变量物理边界的数据。我们的潜在扩散模型达到了与在数据空间中训练的扩散模型相似的分数，但它们平滑了由潜在映射引起的生成场。虽然强制物理边界不能减少平滑度，但它可以改善边缘冰区的表现。因此，对于大规模地球系统建模，如果能够解决平滑的重大障碍，那么与数据空间中的扩散相比，潜在扩散模型可以具有许多优势。 et.al.|[2406.18417](http://arxiv.org/abs/2406.18417)|null|
|**2024-06-26**|**From Majority to Minority: A Diffusion-based Augmentation for Underrepresented Groups in Skin Lesion Analysis**|基于人工智能的诊断已经证明皮肤科医生在分类皮肤癌症方面的表现。然而，当对训练集中缺乏足够代表性的少数群体的数据进行测试时，这种系统容易表现不佳。尽管数据收集和注释提供了促进少数群体的最佳手段，但这些过程既昂贵又耗时。先前的工作表明，来自多数群体的数据可以作为有价值的信息来源，补充少数群体诊断工具的培训。在这项工作中，我们提出了一个有效的基于扩散的增强框架，该框架最大限度地利用来自多数群体的丰富信息，使少数群体受益。以不同皮肤类型的群体为例研究，我们的结果表明，即使这些目标群体的参考数据很少或根本没有参考数据，所提出的框架也可以生成合成图像，改善少数群体的诊断结果。我们工作的实际价值在医学影像分析中是显而易见的，在医学影像学分析中，由于代表性不足，某些群体的诊断不足仍然是一个问题。 et.al.|[2406.18375](http://arxiv.org/abs/2406.18375)|null|
|**2024-06-26**|**Stable Diffusion Segmentation for Biomedical Images with Single-step Reverse Process**|扩散模型已经证明了它们在各种生成任务中的有效性。然而，当应用于医学图像分割时，这些模型会遇到一些挑战，包括巨大的资源和时间要求。它们还需要多步骤反向过程和多个样本来产生可靠的预测。为了应对这些挑战，我们引入了第一个基于稳定扩散（SD）的潜在扩散分割模型，称为SDSeg。SDSeg结合了一种直接的潜在估计策略，以促进单步反向过程，并利用潜在融合级联来消除对多个样本的必要性。大量实验表明，SDSeg在五个具有不同成像模式的基准数据集上超越了现有的最先进方法。值得注意的是，SDSeg能够通过单独的反向步骤和样本生成稳定的预测，这体现了模型名称所暗示的稳定性。代码位于https://github.com/lin-tianyu/Stable-Diffusion-Seg et.al.|[2406.18361](http://arxiv.org/abs/2406.18361)|**[link](https://github.com/lin-tianyu/stable-diffusion-seg)**|
|**2024-06-26**|**Convergence to equilibrium for a degenerate three species reaction-diffusion system**|在这项工作中，我们研究了三种物质的反应扩散系统。系统中的非线性来自于潜在的化学反应。我们的主要目标是了解当存在退化时，这个反应扩散系统的解的长时间行为。更准确地说，我们处理其中一个扩散系数消失而另两个扩散系数保持正的情况。我们证明了均衡型结果的收敛性。在我们的所有结果中，衰变估计中出现的常数是明确的。 et.al.|[2406.18339](http://arxiv.org/abs/2406.18339)|null|
|**2024-06-26**|**Molecular Diffusion Models with Virtual Receptors**|在过去的几年里，基于结构的药物设计（SBDD）的机器学习方法已经被证明是非常丰富的。特别是，基于扩散的SBDD方法显示出巨大的前景。我们提出了一种技术，它在两个关键方面扩展了这种扩散方法。首先，我们解决了药物分子和靶标/受体之间的大小差异，这使得学习更具挑战性，推理更慢。我们通过虚拟受体的概念来做到这一点，虚拟受体是受体的压缩版本；它的学习是为了保留原始受体结构信息的关键方面，同时尊重相关的组等变性。其次，我们引入了最初用于蛋白质折叠的蛋白质语言嵌入。我们通过实验证明了虚拟受体和蛋白质嵌入的贡献：在实践中，它们既能带来更好的性能，又能显著加快计算速度。 et.al.|[2406.18330](http://arxiv.org/abs/2406.18330)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-25**|**Masked Generative Extractor for Synergistic Representation and 3D Generation of Point Clouds**|在2D图像生成建模和表示学习领域，掩模生成编码器（MAGE）已经证明了生成建模与表示学习之间的协同潜力。受此启发，我们提出了Point MAGE，将这一概念扩展到点云数据。具体而言，该框架首先利用矢量量化变分自动编码器（VQVAE）来重建3D形状的神经场表示，从而学习点块的离散语义特征。随后，通过将掩蔽模型与可变掩蔽比相结合，我们实现了生成和表示学习的同步训练。此外，我们的框架与现有的点云自监督学习（SSL）模型无缝集成，从而提高了它们的性能。我们广泛评估了Point MAGE的表示学习和生成能力。在形状分类任务中，Point MAGE在ModelNet40数据集上的准确率为94.2%，在ScanObjectNN数据集上达到92.9%（+1.3%）。此外，它在少量镜头学习和零件分割任务中实现了最先进的性能。实验结果还证实，点MAGE可以在无条件和有条件的设置中生成详细和高质量的3D形状。 et.al.|[2406.17342](http://arxiv.org/abs/2406.17342)|null|
|**2024-06-17**|**DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features**|我们提出了DistilleNeRF，这是一种自监督学习框架，解决了在自动驾驶中从有限的2D观测中理解3D环境的挑战。我们的方法是一个可推广的前馈模型，它从稀疏的单帧多视图相机输入中预测丰富的神经场景表示，并通过可微分渲染进行自监督训练，以重建RGB、深度或特征图像。我们的第一个见解是通过生成密集的深度和虚拟相机目标进行训练，利用每场景优化的神经辐射场（NeRF），从而帮助我们的模型从稀疏的非重叠图像输入中学习3D几何。其次，为了学习语义丰富的3D表示，我们建议从预先训练的2D基础模型（如CLIP或DINOv2）中提取特征，从而实现各种下游任务，而不需要昂贵的3D人工注释。为了利用这两个见解，我们引入了一种新的模型架构，该架构具有两级提升-飞溅-拍摄编码器和参数化稀疏分层体素表示。在NuScenes数据集上的实验结果表明，DistilleNeRF在场景重建、新视图合成和深度估计方面显著优于现有的可比自监督方法；并且它允许竞争性的零样本3D语义占用预测，以及通过提取的基础模型特征来理解开放世界场景。演示和代码将在https://distillnerf.github.io/. et.al.|[2406.12095](http://arxiv.org/abs/2406.12095)|null|
|**2024-06-18**|**Effective Rank Analysis and Regularization for Enhanced 3D Gaussian Splatting**|从多视图图像中进行三维重建是计算机视觉和图形学的基本挑战之一。近年来，三维高斯散射（3DGS）已经成为一种很有前途的技术，能够实时渲染和高质量的三维重建。该方法利用了三维高斯表示和基于瓦片的飞溅技术，绕过了昂贵的神经场查询。尽管3DGS具有潜力，但由于高斯收敛为具有一个主导方差的各向异性高斯，3DGS仍面临挑战，包括针状伪影、次优几何结构和不准确法线。我们建议使用有效秩分析来检查3D高斯基元的形状统计，并识别高斯确实收敛为有效秩为1的针状形状。为了解决这个问题，我们引入了有效秩作为正则化，它约束高斯的结构。我们的新正则化方法增强了法线和几何重建，同时减少了针状伪影。该方法可以作为附加模块集成到其他3DGS变体中，在不影响视觉逼真度的情况下提高其质量。 et.al.|[2406.11672](http://arxiv.org/abs/2406.11672)|null|
|**2024-06-13**|**Well-posedness and regularity of solutions to neural field problems with dendritic processing**|我们研究了最近提出的神经场模型的解决方案，在该模型中，树突被建模为源自体细胞层的垂直纤维的连续体。由于电压通过具有非局部源的电缆方程沿树枝状方向传播，因此该模型具有各向异性扩散算子以及突触耦合的积分项。因此，相应的柯西问题与经典的神经场方程明显不同。我们证明了问题的弱公式允许一个唯一的解，嵌入估计类似于非线性局部反应扩散方程的嵌入估计。我们的分析依赖于无扩散问题的扰动弱解，即标准神经场，迄今为止尚未对其弱问题进行研究。我们找到了有扩散和无扩散问题的严格渐近估计，并证明了这两个模型的解在有限时间间隔上在适当的范数下保持接近。我们提供了微扰结果的数值证据。 et.al.|[2406.09222](http://arxiv.org/abs/2406.09222)|null|
|**2024-06-13**|**Preserving Identity with Variational Score for General-purpose 3D Editing**|我们提出了Piva（用变分分数蒸馏保持同一性），这是一种新的基于优化的方法，用于编辑基于扩散模型的图像和3D模型。具体来说，我们的方法受到了最近提出的2D图像编辑方法——德尔塔去噪分数（DDS）的启发。我们指出了DDS在二维和三维编辑中的局限性，这会导致细节丢失和过饱和。为了解决这一问题，我们提出了一个额外的分数提取术语，以强制执行身份保护。这导致了更稳定的编辑过程，逐步优化NeRF模型以匹配目标提示，同时保留关键的输入特征。我们证明了我们的方法在零样本图像和神经场编辑中的有效性。我们的方法成功地改变了视觉属性，添加了微妙和实质性的结构元素，转换了形状，并在标准的2D和3D编辑基准上取得了有竞争力的结果。此外，我们的方法没有施加任何约束，如掩蔽或预训练，使其与广泛的预训练扩散模型兼容。这允许进行多功能编辑，而不需要神经场到网格的转换，提供更用户友好的体验。 et.al.|[2406.08953](http://arxiv.org/abs/2406.08953)|null|
|**2024-06-12**|**Category-level Neural Field for Reconstruction of Partially Observed Objects in Indoor Environment**|通过各种成功案例，神经隐式表示在三维重建中引起了人们的关注。对于进一步的应用，如场景理解或编辑，一些作品已经显示出在对象组成重建方面的进展。尽管它们在观测区域具有优越的性能，但在重建部分观测到的对象时，它们的性能仍然有限。为了更好地处理这个问题，我们引入了类别级神经场，该神经场在场景中属于同一类别的对象之间学习有意义的公共3D信息。我们的主要想法是根据观察到的形状对对象进行子分类，以便更好地训练类别级模型。然后，我们利用神经场，通过选择基于射线的不确定性选择的代表性对象并与之对齐，来执行配准部分观测对象的挑战性任务。在模拟和真实世界数据集上的实验表明，我们的方法改进了几个类别的未观察零件的重建。 et.al.|[2406.08176](http://arxiv.org/abs/2406.08176)|**[link](https://github.com/Taekbum/category-nerf-reconstruction-official)**|
|**2024-06-12**|**OpenObj: Open-Vocabulary Object-Level Neural Radiance Fields with Fine-Grained Understanding**|近年来，人们对由视觉语言模型（VLM）促进的开放词汇三维场景重建产生了浓厚的兴趣，VLM在开放集检索中展示了非凡的能力。然而，现有的方法面临一些局限性：它们要么专注于学习逐点特征，导致语义理解模糊，要么只处理对象级重建，从而忽略对象内部的复杂细节。为了应对这些挑战，我们引入了OpenObj，这是一种创新的方法，用于构建具有细粒度理解的开放词汇表对象级神经辐射场（NeRF）。从本质上讲，OpenObj建立了一个健壮的框架，用于在对象级别进行高效和严密的场景建模和理解。此外，我们将零件级特征融入神经领域，从而实现物体内部的细致入微的表示。这种方法捕获对象级实例，同时保持细粒度的理解。在多个数据集上的结果表明，OpenObj在零样本语义分割和检索任务中取得了优异的性能。此外，OpenObj支持多尺度的真实世界机器人任务，包括全局移动和局部操纵。 et.al.|[2406.08009](http://arxiv.org/abs/2406.08009)|**[link](https://github.com/BIT-DYN/OpenObj)**|
|**2024-06-11**|**Image Neural Field Diffusion Models**|扩散模型在对复杂数据分布建模方面表现出了令人印象深刻的能力，与GANs相比具有几个关键优势，例如稳定的训练、更好地覆盖训练分布的模式，以及在没有额外训练的情况下解决反问题的能力。然而，大多数扩散模型学习固定分辨率图像的分布。我们建议通过在图像神经场上训练扩散模型来学习连续图像的分布，该模型可以以任何分辨率渲染，并显示出其相对于固定分辨率模型的优势。为了实现这一点，一个关键的挑战是获得一个代表真实感图像神经场的潜在空间。受最近几项技术的启发，我们提出了一种简单有效的方法，但有一些关键的变化，使图像神经场具有真实感。我们的方法可以用于将现有的潜在扩散自动编码器转换为图像神经场自动编码器。我们证明，图像神经场扩散模型可以使用混合分辨率图像数据集进行训练，优于固定分辨率扩散模型和超分辨率模型，并且可以有效地解决不同尺度条件下的逆问题。 et.al.|[2406.07480](http://arxiv.org/abs/2406.07480)|null|
|**2024-06-10**|**Space-Time Continuous PDE Forecasting using Equivariant Neural Fields**|最近，条件神经场（NeF）通过将解学习为条件NeF的潜在空间中的流，已成为偏微分方程的强大建模范式。尽管受益于NeFs的有利特性，如网格不可知性和时空连续动力学建模，但这种方法限制了将PDE的已知约束强加给解决方案的能力，例如对称性或边界条件，有利于建模的灵活性。相反，我们提出了一种基于时空连续NeF的求解框架，该框架通过在潜在空间中保留几何信息，尊重PDE的已知对称性。我们表明，将解建模为感兴趣组 $G$ 上的点云流，可以提高泛化和数据效率。我们验证了我们的框架很容易推广到看不见的空间和时间位置，以及初始条件的几何变换——在其他基于NeF的PDE预测方法失败的地方——并在一些具有挑战性的几何结构中超过基线进行改进。 et.al.|[2406.06660](http://arxiv.org/abs/2406.06660)|null|
|**2024-06-11**|**LOP-Field: Brain-inspired Layout-Object-Position Fields for Robotic Scene Understanding**|空间认知使动物具有非常高效的导航能力，这在很大程度上取决于对空间环境的场景级理解。最近，人们发现，大鼠大脑嗅后皮层的神经群体比场景中的物体更能强烈地适应空间布局。受局部场景中空间布局表示的启发，我们提出了实现布局对象位置（LOP）关联的LOP域，以对机器人场景理解的层次表示进行建模。在基础模型和隐式场景表示的支持下，神经场被实现为机器人的场景存储器，存储具有位置、对象和布局信息的场景的可查询表示。为了验证所建立的LOP关联，对该模型进行了测试，以使用定量指标从3D位置推断区域信息，实现了超过88%的平均准确度。还表明，与最先进的定位方法相比，所提出的使用区域信息的方法可以在文本和RGB输入的情况下实现改进的对象和视图定位结果。 et.al.|[2406.05985](http://arxiv.org/abs/2406.05985)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

