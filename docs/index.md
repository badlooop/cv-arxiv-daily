---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.09.04
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-08-31**|**Efficient Multi-View Graph Clustering with Local and Global Structure Preservation**|基于锚点的多视图图聚类（AMVGC）由于其高效性和跨多个视图捕获互补结构信息的能力而受到广泛关注。直观地说，高质量的锚图对AMVGC的成功起着至关重要的作用。然而，现有的AMVGC方法只考虑单个结构信息，即局部或全局结构，这为学习任务提供了足够的信息。具体地说，过于分散的全局结构导致学习锚不能很好地描述集群划分。相反，具有不适当相似性度量的局部结构会导致潜在的不准确锚分配，最终导致次优聚类性能。为了解决这个问题，我们提出了一种新的基于锚点的多视图图聚类框架，称为具有局部和全局结构保护的高效多视图图集群（EMVGC-LG）。具体而言，设计了一个具有理论保障的统一框架，以获取本地和全球信息。此外，EMVGC-LG还联合优化了锚点构建和图学习，以提高聚类质量。此外，EMVGC-LG继承了现有AMVGC方法在样本数量方面的线性复杂性，这是时间经济的，并且可以很好地随数据大小扩展。大量的实验证明了我们提出的方法的有效性和效率。 et.al.|[2309.00024](http://arxiv.org/abs/2309.00024)|**[link](https://github.com/wy1019/emvgc-lg)**|
|**2023-08-24**|**Improving NeRF Quality by Progressive Camera Placement for Unrestricted Navigation in Complex Environments**|神经辐射场（NeRF）极大地改进了用于渲染的新型视图合成和3D重建。NeRF在以对象为中心的重建方面取得了令人印象深刻的结果，但在复杂环境（房间、房屋等）中使用自由视点导航的新颖视图合成的质量往往存在问题。虽然算法改进对新视图合成的质量起着重要作用，但在这项工作中，我们表明，由于优化NeRF本质上是一个数据驱动的过程，因此高质量的数据对重建的最终质量起着根本作用。因此，关键是要选择数据样本——在这种情况下是相机——以最终使优化收敛到一个允许高质量自由视点导航的解决方案。我们的主要贡献是一种算法，该算法有效地提出了新的相机位置，可以在最小的假设下提高视觉质量。我们的解决方案可以用于任何NeRF模型，并且优于基线和类似工作。 et.al.|[2309.00014](http://arxiv.org/abs/2309.00014)|null|
|**2023-08-30**|**Autonomous damage assessment of structural columns using low-cost micro aerial vehicles and multi-view computer vision**|结构柱是建筑和桥梁的重要承载构件。柱损坏的早期检测对于评估剩余性能和防止系统级崩溃非常重要。本研究提出了一种创新的基于端到端微型飞行器（MAV）的方法来自动扫描和检查立柱。首先，提出了一种基于MAV的图像自动采集方法。MAV被编程为感应结构柱及其周围环境。在导航过程中，MAV首先检测并接近结构柱。然后，它开始收集每个检测到的列周围多个视点的图像数据。其次，收集的图像将用于评估损坏类型和损坏位置。第三，将通过融合多个摄像机视图的评估结果来确定结构柱的损伤状态。在本研究中，选择钢筋混凝土（RC）柱来证明该方法的有效性。实验结果表明，所提出的基于MAV的检测方法可以有效地从多个视角采集图像，并准确评估RC柱的临界损伤。该方法提高了检查期间的自主权水平。此外，评估结果比现有的2D视觉方法更全面。所提出的检查方法的概念可以扩展到其他结构柱，如桥墩。 et.al.|[2308.16278](http://arxiv.org/abs/2308.16278)|null|
|**2023-08-30**|**Learning Structure-from-Motion with Graph Attention Networks**|在本文中，我们通过使用图注意力网络来解决从运动中学习结构（SfM）的问题。SfM是一个经典的计算机视觉问题，通过迭代最小化重投影误差来解决，称为束调整（BA），从良好的初始化开始。为了获得对BA足够好的初始化，传统方法依赖于一系列子问题（如成对姿态估计、姿态平均或三角测量），这些子问题提供了一个初始解决方案，然后可以使用BA进行细化。在这项工作中，我们通过学习一个模型来替换这些子问题，该模型将在多个视图中检测到的2D关键点作为输入，并输出相应的相机姿势和3D关键点坐标。我们的模型利用图神经网络来学习SfM特定的基元，并表明它可以用于新的和看不见的序列的重建的快速推理。实验结果表明，所提出的模型优于竞争的基于学习的方法，并在具有较低运行时间的同时挑战了COLMAP。 et.al.|[2308.15984](http://arxiv.org/abs/2308.15984)|null|
|**2023-08-29**|**3D-MuPPET: 3D Multi-Pigeon Pose Estimation and Tracking**|动物姿势跟踪的无标记方法最近得到了发展，但在3D中跟踪大型动物群体的框架和基准仍然缺乏。为了克服文献中的这一空白，我们提出了3D MuPPET，这是一个使用多个视图以交互式速度估计和跟踪多达10只鸽子的3D姿势的框架。我们训练姿势估计器来推断多只鸽子的2D关键点和边界框，然后将关键点三角化为3D。对于对应匹配，我们首先将2D检测与第一帧中的全局身份动态匹配，然后使用2D跟踪器来维护后续帧中跨视图的对应关系。对于均方根误差（RMSE）和正确关键点百分比（PCK），我们实现了与现有技术的3D姿态估计器相当的精度。我们还展示了一个新颖的用例，其中我们的模型用单个鸽子的数据训练，在包含多只鸽子的数据上提供了可比较的结果。这可以简化向新物种的领域转移，因为注释单个动物数据比注释多动物数据劳动密集度低。此外，我们对3D MuPPET的推理速度进行了基准测试，在2D中高达10fps，在3D中高达1.5fps，并进行了定量跟踪评估，这产生了令人鼓舞的结果。最后，我们展示了3D MuPPET在自然环境中也能工作，而无需对附加注释进行模型微调。据我们所知，我们是第一个提出适用于室内和室外环境的2D/3D姿势和轨迹跟踪框架的公司。 et.al.|[2308.15316](http://arxiv.org/abs/2308.15316)|null|
|**2023-08-29**|**Pose-Free Neural Radiance Fields via Implicit Pose Regularization**|无姿态神经辐射场（NeRF）旨在用未经处理的多视图图像训练NeRF，近年来取得了令人印象深刻的成功。大多数现有工作共享一个管道，首先用渲染图像训练粗略的姿态估计器，然后联合优化估计的姿态和神经辐射场。然而，由于姿态估计器仅用渲染图像进行训练，由于真实图像和渲染图像之间的域间隙，姿态估计通常对真实图像有偏差或不准确，导致真实图像的姿态估计鲁棒性差，并且在联合优化中存在进一步的局部最小值。我们设计了IR NeRF，这是一种创新的无姿态NeRF，它引入了隐式姿态正则化来改进未聚焦真实图像的姿态估计器，并提高了真实图像姿态估计的鲁棒性。通过特定场景的2D图像的集合，IR NeRF构建了一个场景码本，该场景码本存储场景特征，并隐式地捕捉特定场景的姿势分布作为先验。因此，根据只有当2D真实图像的估计姿势位于姿势分布内时才可以从场景码本很好地重建2D真实图像这一原理，可以利用场景先验来提高姿势估计的鲁棒性。大量实验表明，IR NeRF实现了卓越的新视图合成，并在多个合成和真实数据集上始终优于最先进的视图合成。 et.al.|[2308.15049](http://arxiv.org/abs/2308.15049)|null|
|**2023-08-28**|**CLNeRF: Continual Learning Meets NeRF**|新颖的视图合成旨在呈现给定一组校准图像的看不见的视图。在实际应用中，场景的覆盖范围、外观或几何结构可能会随着时间的推移而变化，不断捕捉新的图像。有效地整合这种持续的变化是一个公开的挑战。标准NeRF基准测试仅涉及场景覆盖范围的扩展。为了研究其他实际的场景变化，我们提出了一个新的数据集，即跨时间世界（WAT），由外观和几何结构随时间变化的场景组成。我们还提出了一种简单而有效的方法CLNeRF，它将连续学习（CL）引入到神经辐射场（NeRF）中。CLNeRF结合了生成回放和即时神经图形原件（NGP）架构，以有效防止灾难性遗忘，并在新数据到达时有效更新模型。我们还向NGP添加了可训练的外观和几何嵌入，允许单个紧凑模型处理复杂的场景变化。在不需要存储历史图像的情况下，在变化场景的多次扫描上顺序训练的CLNeRF与在一次所有扫描上训练的上界模型性能相当。与其他CL基线相比，CLNeRF在标准基准和WAT上的表现要好得多。源代码和WAT数据集可在https://github.com/IntelLabs/CLNeRF.视频演示可在以下网址获得：https://youtu.be/nLRt6OoDGq0?si=8yD6k-8MMBJInQP et.al.|[2308.14816](http://arxiv.org/abs/2308.14816)|**[link](https://github.com/intellabs/clnerf)**|
|**2023-08-28**|**Flexible Techniques for Differentiable Rendering with 3D Gaussians**|快速、可靠的形状重建是许多计算机视觉应用中的重要组成部分。Neural Radiance Fields证明，真实感的新视图合成是触手可及的，但受到真实场景和对象快速重建性能要求的限制。最近的一些方法建立在替代形状表示的基础上，特别是3D高斯。我们开发了这些渲染器的扩展，例如集成可微分光流、导出防水网格和渲染每光线法线。此外，我们还展示了最近的两种方法是如何相互操作的。这些重建快速、稳健，并且可以在GPU或CPU上轻松执行。有关代码和可视化示例，请参见https://leonidk.github.io/fmb-plus et.al.|[2308.14737](http://arxiv.org/abs/2308.14737)|null|
|**2023-08-27**|**Depth self-supervision for single image novel view synthesis**|在本文中，我们解决了在给定单个帧作为输入的情况下从任意视点生成新图像的问题。虽然在这种设置中操作的现有方法旨在预测目标视图深度图以指导合成，但在没有明确监督此类任务的情况下，我们共同优化了新视图合成和深度估计的框架，以最大限度地释放两者之间的协同作用。具体地，以自监督的方式训练共享深度解码器，以预测在源视图和目标视图中一致的深度图。我们的结果证明了我们的方法在解决这两项任务的挑战方面的有效性，这两项工作允许生成更高质量的图像，并为目标视点提供更准确的深度。 et.al.|[2308.14108](http://arxiv.org/abs/2308.14108)|**[link](https://github.com/johnminelli/twowaysynth)**|
|**2023-08-27**|**Sparse3D: Distilling Multiview-Consistent Diffusion for Object Reconstruction from Sparse Views**|从极其稀疏的视图重建3D对象是一个长期存在且具有挑战性的问题。虽然最近的技术使用图像扩散模型来在新视点生成看似合理的图像，或者使用分数蒸馏采样（SDS）将预先训练的扩散先验提取到3D表示中，但这些方法通常难以同时实现新视点合成（NVS）和几何体的高质量、一致和详细的结果。在这项工作中，我们提出了Sparse3D，这是一种为稀疏视图输入量身定制的新型3D重建方法。我们的方法从多视点一致扩散模型中提取鲁棒先验，以细化神经辐射场。具体来说，我们使用了一个控制器，该控制器利用输入视图中的核线特征，引导预先训练的扩散模型，如稳定扩散，以生成与输入保持3D一致性的新视图图像。通过利用强大的图像扩散模型中的2D先验，我们的集成模型即使在面对开放世界对象时也能始终如一地提供高质量的结果。为了解决传统SDS引入的模糊性，我们引入了类别分数蒸馏采样（C-SDS）来增强细节。我们在CO3DV2上进行了实验，这是一个真实世界对象的多视图数据集。定量和定性评估都表明，我们的方法在NVS和几何重建方面优于以往最先进的工作。 et.al.|[2308.14078](http://arxiv.org/abs/2308.14078)|null|
|**2023-08-25**|**ReST: A Reconfigurable Spatial-Temporal Graph Model for Multi-Camera Multi-Object Tracking**|多摄像机多目标跟踪（MC-MOT）利用来自多个视图的信息来更好地处理遮挡和拥挤场景的问题。最近，使用基于图的方法来解决跟踪问题变得非常流行。然而，当前许多基于图的方法不能有效地利用关于空间和时间一致性的信息。相反，它们依赖于单摄像头跟踪器作为输入，这很容易出现碎片和ID切换错误。在本文中，我们提出了一种新的可重构图模型，该模型首先在空间上关联摄像机上所有检测到的对象，然后将其重新配置为用于时间关联的时间图。这种两阶段关联方法使我们能够提取强大的空间和时间感知特征，并解决碎片化轨迹的问题。此外，我们的模型是为在线跟踪而设计的，适用于现实世界中的应用。实验结果表明，所提出的图模型能够提取更多的判别特征用于对象跟踪，并且我们的模型在几个公共数据集上达到了最先进的性能。 et.al.|[2308.13229](http://arxiv.org/abs/2308.13229)|**[link](https://github.com/chengche6230/rest)**|
|**2023-08-24**|**NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes**|最近的隐式神经表示在新的视图合成中显示出了很好的结果。然而，现有的方法需要从许多视图进行昂贵的每场景优化，因此限制了它们在真实世界的无边界城市环境中的应用，在这些环境中，从极少数视图观察到感兴趣的对象或背景。为了缓解这一挑战，我们引入了一种名为NeO360的新方法，用于户外场景稀疏视图合成的神经场。NeO 360是一种可推广的方法，它从单个或几个摆出姿势的RGB图像重建360｛\deg｝场景。我们方法的本质是捕捉复杂的真实世界户外3D场景的分布，并使用可以从任何世界点查询的混合图像条件三平面表示。我们的表示结合了基于体素和鸟瞰图（BEV）的最佳表示，比每种表示都更有效、更具表现力。NeO 360的表示使我们能够从大量无界3D场景中学习，同时在推理过程中从一张图像中提供对新视图和新场景的可推广性。我们在所提出的具有挑战性的360｛\deg｝无界数据集NeRDS 360上演示了我们的方法，并表明NeO 360在新视图合成方面优于最先进的可推广方法，同时还提供编辑和合成功能。项目页面：https://zubair-irshad.github.io/projects/neo360.html et.al.|[2308.12967](http://arxiv.org/abs/2308.12967)|**[link](https://github.com/zubair-irshad/NeO-360)**|
|**2023-08-24**|**Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis**|静息状态功能性MRI（rs-fMRI）越来越多地用于多部位研究，以帮助神经系统疾病分析。现有研究通常存在由站点效应（如扫描仪/协议的差异）引起的显著跨站点/领域数据异质性。已经提出了许多方法来减少源域和目标域之间的fMRI异质性，这在很大程度上依赖于源数据的可用性。但是，由于多站点研究中的隐私问题和/或数据存储负担，获取源数据具有挑战性。为此，我们设计了一个用于fMRI分析的无源协作域自适应（SCDA）框架，其中只有预训练的源模型和未标记的目标数据是可访问的。具体而言，开发了一种用于目标fMRI分析的多视角特征富集方法（MFE），该方法由多个协作分支组成，用于从多个视图动态捕获未标记目标数据的fMRI特征。每个分支都有一个数据馈送模块、一个时空特征编码器和一个类预测器。设计了相互一致性约束，以鼓励从这些分支生成的相同输入的潜在特征的成对一致性，用于鲁棒表示学习。为了在没有源数据的情况下促进有效的跨领域知识转移，我们使用预训练的源模型的参数初始化MFE。我们还介绍了一种无监督预训练策略，使用来自三个大型辅助数据库的3806个未标记的fMRI，旨在获得通用特征编码器。在三个公共数据集和一个私人数据集上的实验结果证明了我们的方法在交叉扫描和交叉研究预测任务中的有效性。在大规模rs fMRI数据上预训练的模型已经向公众发布。 et.al.|[2308.12495](http://arxiv.org/abs/2308.12495)|**[link](https://github.com/yqfang9199/scda)**|
|**2023-08-23**|**ARF-Plus: Controlling Perceptual Factors in Artistic Radiance Fields for 3D Scene Stylization**|辐射场风格转移是一个新兴的领域，由于神经辐射场在三维重建和视图合成中的出色表现，作为三维场景风格化的一种手段，它最近受到了欢迎。我们强调了在辐射场风格转移方面的研究空白，即缺乏足够的感知可控性，这是由2D图像风格转移中的现有概念所驱动的。在本文中，我们提出了ARF Plus，一个对感知因素提供可管理控制的3D神经风格转移框架，以系统地探索3D场景风格化中的感知可控性。提出了四种不同类型的控制——颜色保持控制、（风格模式）比例控制、空间（选择性风格化区域）控制和深度增强控制——并将其集成到该框架中。来自真实世界数据集的定量和定性结果表明，在对3D场景进行风格化时，我们的ARF Plus框架中的四种类型的控件成功地实现了相应的感知控件。这些技术适用于单个样式输入以及场景中多个样式的同时应用。这开启了一个无限可能性的领域，允许对风格化效果进行定制修改，并灵活融合不同风格的优势，最终能够在3D场景中创造新颖而引人注目的风格效果。 et.al.|[2308.12452](http://arxiv.org/abs/2308.12452)|null|
|**2023-08-24**|**A Visualization System for Hexahedral Mesh Quality Study**|在本文中，我们介绍了一种新的三维十六进制网格视觉分析系统，该系统通过聚合字形强调质量较差的区域，突出重叠元素，并以三种形式提供详细的边界误差检查。通过支持多视图的多级分析，我们的系统有效地评估了各种网格模型，并比较了六面体网格的网格生成和优化算法的性能。 et.al.|[2308.12158](http://arxiv.org/abs/2308.12158)|null|
|**2023-08-22**|**Enhancing NeRF akin to Enhancing LLMs: Generalizable NeRF Transformer with Mixture-of-View-Experts**|跨场景可推广的NeRF模型可以直接合成看不见场景的新视图，已成为NeRF领域的一个新焦点。现有的几种尝试依赖于越来越端到端的“神经化”架构，即用变压器等高性能神经网络取代场景表示和/或渲染模块，并将新颖的视图合成转化为前馈推理管道。虽然这些前馈“神经化”架构仍然不能很好地开箱即用地适应不同的场景，但我们建议将它们与来自大型语言模型（LLM）的强大的专家混合（MoE）思想联系起来，该思想通过在更大的整体模型容量和灵活的每实例专业化之间进行平衡，展示了卓越的泛化能力。从最近一种名为GNT的可推广NeRF架构开始，我们首先证明了MoE可以巧妙地插入以增强模型。我们进一步定制了共享的永久专家和几何体感知的一致性损失，以分别增强跨场景一致性和空间平滑性，这对于可推广的视图合成至关重要。我们提出的模型被称为GNT with Mixture-of-View-Experts（GNT-MOVE），在转移到看不见的场景时，实验显示了最先进的结果，表明在零样本和少拍摄设置中都有更好的跨场景泛化。我们的代码可在https://github.com/VITA-Group/GNT-MOVE. et.al.|[2308.11793](http://arxiv.org/abs/2308.11793)|**[link](https://github.com/vita-group/gnt-move)**|
|**2023-08-22**|**IT3D: Improved Text-to-3D Generation with Explicit View Synthesis**|从强大的大型文本到图像扩散模型（LDM）中提取知识，推动了文本到3D技术的最新进展。尽管如此，现有的文本到3D方法经常会遇到诸如过度饱和、细节不足和不切实际的输出等挑战。这项研究提出了一种新的策略，利用显式合成的多视图图像来解决这些问题。我们的方法涉及利用LDM授权的图像到图像管道，以基于粗略3D模型的渲染生成高质量的图像。尽管生成的图像在很大程度上缓解了上述问题，但由于大扩散模型固有的生成性质，诸如视图不一致和显著的内容差异等挑战仍然存在，这给有效利用这些图像带来了巨大的困难。为了克服这一障碍，我们主张将鉴别器与新的扩散GAN双重训练策略相结合，以指导3D模型的训练。对于合并的鉴别器，合成的多视图图像被视为真实数据，而优化的3D模型的渲染则充当假数据。我们进行了一系列全面的实验，证明了我们的方法相对于基线方法的有效性。 et.al.|[2308.11473](http://arxiv.org/abs/2308.11473)|**[link](https://github.com/buaacyw/it3d-text-to-3d)**|
|**2023-08-22**|**ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes**|我们展示了ScanNet++，这是一个大规模的数据集，将室内场景的高质量和商品级几何图形和颜色的捕捉结合在一起。每个场景都是用亚毫米分辨率的高端激光扫描仪拍摄的，还有来自单反相机的3300万像素图像和来自iPhone的RGB-D流。场景重建进一步用开放的语义词汇表进行注释，明确注释标签模糊场景以进行全面的语义理解。ScanNet++为新视图合成提供了一个新的现实世界基准，既有高质量的RGB捕获，也有重要的商品级图像，此外还有一个全面封装多样和模糊语义标记场景的3D语义场景理解新基准。目前，ScanNet++包含460个场景、28万张单反图像和370多万个iPhone RGBD帧。 et.al.|[2308.11417](http://arxiv.org/abs/2308.11417)|null|
|**2023-08-22**|**Enhancing Interpretable Object Abstraction via Clustering-based Slot Initialization**|使用槽的以对象为中心的表示显示了从合成场景中的低级感知特征向高效、灵活和可解释的抽象的发展。当前的方法随机化时隙的初始状态，然后进行迭代细化。正如我们在本文中所展示的，随机时隙初始化显著影响最终时隙预测的准确性。此外，当前的方法需要来自数据的先验知识的预定数量的时隙，这限制了在现实世界中的适用性。在我们的工作中，我们使用以感知输入特征为条件的聚类算法来初始化槽表示。这需要体系结构中的一个附加层来初始化给定已识别集群的插槽。我们设计了该层的置换不变和置换等变版本，以实现聚类后的可交换槽表示。此外，我们使用均值偏移聚类来自动识别给定场景的槽数。我们评估了我们在各种数据集的对象发现和新视图合成任务上的方法。结果表明，我们的方法始终优于先前的工作，尤其是在复杂场景下。 et.al.|[2308.11369](http://arxiv.org/abs/2308.11369)|null|
|**2023-08-22**|**Novel-view Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views**|在沉浸式通信中，手与物体的交互理解和几乎没有解决的新颖视角合成是非常需要的，而由于手的高度变形和手与物体之间的严重遮挡，这是具有挑战性的。在本文中，我们提出了一种用于稀疏视图中手-物体交互的神经渲染和姿态估计系统，该系统还可以实现3D手-物体的交互编辑。我们分享了最近场景理解工作的灵感，该工作表明，预先建立的特定场景模型可以显著改善和解锁视觉任务，尤其是在输入稀疏的情况下，并将其扩展到动态手-物交互场景中，并提出分两个阶段解决问题。我们首先在离线阶段使用神经表示分别学习手和物体的形状和外观先验知识。在在线阶段，我们设计了一个基于渲染的联合模型拟合框架，以了解手与对象的动态交互与预先构建的手与对象模型以及交互先验，从而克服了手与对象之间的渗透和分离问题，并实现了新的视图合成。为了在一个序列中的手-物体交互过程中获得稳定的接触，我们提出了一个稳定的接触损失，以使接触区域一致。实验表明，我们的方法优于最先进的方法。项目网页中提供了代码和数据集https://iscas3dv.github.io/HO-NeRF. et.al.|[2308.11198](http://arxiv.org/abs/2308.11198)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-01**|**Dense Voxel 3D Reconstruction Using a Monocular Event Camera**|事件摄像机是受生物系统启发，专门捕捉亮度变化的传感器。与传统的基于帧的相机相比，这些新兴相机具有许多优势，包括高动态范围、高帧率和极低功耗。由于这些优势，事件摄像机越来越多地应用于各个领域，如帧插值、语义分割、里程计和SLAM。然而，它们在VR应用的3D重建中的应用还没有得到充分的探索。该领域以前的方法主要集中在通过深度图估计进行三维重建。产生密集3D重建的方法通常需要多个相机，而利用单个事件相机的方法只能产生半密集的结果。可以产生密集3D重建的其他单相机方法依赖于创建管道，该管道结合了上述方法或其他现有的运动结构（SfM）或多视图立体（MVS）方法。在本文中，我们提出了一种仅使用单个事件相机来解决密集三维重建的新方法。据我们所知，我们的工作是这方面的第一次尝试。我们的初步结果表明，所提出的方法可以直接产生视觉上可区分的密集三维重建，而不需要像现有方法那样使用管道。此外，我们还使用事件相机模拟器创建了一个合成数据集，其中包含39739$的对象扫描。该数据集将有助于加速该领域的其他相关研究。 et.al.|[2309.00385](http://arxiv.org/abs/2309.00385)|null|
|**2023-09-01**|**On the Localization of Ultrasound Image Slices within Point Distribution Models**|甲状腺疾病最常见的诊断方法是使用高分辨率超声（US）。纵向结节追踪是监测甲状腺病理形态变化的关键诊断方案。然而，由于维持器官的心理3D重建的固有挑战，这项任务给临床医生带来了巨大的认知负荷。因此，我们提出了一个在3D形状表示中自动定位US图像切片的框架，以简化如何进行这种超声诊断。我们提出的方法通过对比度量学习，学习US图像块和个人甲状腺形状的3D表面之间的共同潜在嵌入空间，或统计形状模型（SSM）形式的统计聚合。使用跨模态配准和Procrustes分析，我们利用模型中的特征将US切片配准为甲状腺形状的3D网格表示。我们证明了我们的多模态配准框架可以在患者特定器官的3D表面拓扑结构和SSM的平均形状上定位图像。实验结果表明，在患者特定的3D解剖结构上，切片位置可以在距离地面实况切片位置平均1.2毫米和SSM平均4.6毫米的范围内预测，这证明了其在超声采集期间对切片定位的有用性。代码公开：\href{https://github.com/vuenc/slice-to-shape}{https://github.com/vuenc/slice-to-shape} et.al.|[2309.00372](http://arxiv.org/abs/2309.00372)|null|
|**2023-08-24**|**Improving NeRF Quality by Progressive Camera Placement for Unrestricted Navigation in Complex Environments**|神经辐射场（NeRF）极大地改进了用于渲染的新型视图合成和3D重建。NeRF在以对象为中心的重建方面取得了令人印象深刻的结果，但在复杂环境（房间、房屋等）中使用自由视点导航的新颖视图合成的质量往往存在问题。虽然算法改进对新视图合成的质量起着重要作用，但在这项工作中，我们表明，由于优化NeRF本质上是一个数据驱动的过程，因此高质量的数据对重建的最终质量起着根本作用。因此，关键是要选择数据样本——在这种情况下是相机——以最终使优化收敛到一个允许高质量自由视点导航的解决方案。我们的主要贡献是一种算法，该算法有效地提出了新的相机位置，可以在最小的假设下提高视觉质量。我们的解决方案可以用于任何NeRF模型，并且优于基线和类似工作。 et.al.|[2309.00014](http://arxiv.org/abs/2309.00014)|null|
|**2023-08-29**|**Intensity correlation holography for remote phase sensing and 3D imaging**|全息是一种通过与参考波的干涉组合来测量光学信号波前的既定技术。传统上，全息图的积分时间受到干涉仪相干时间的限制，因此制备远程物体的全息图具有挑战性，尤其是使用弱照明。在这里，我们通过使用强度相关干涉测量法来规避这一限制。尽管单个全息图的曝光时间必须短于干涉仪相干时间，但我们表明，任何数量的随机相移全息图都可以组合成单个强度相关全息图。在原理验证实验中，我们使用该技术在弱照明和无主动相位稳定的情况下，对距离约3m的物体进行相位成像和3D重建。 et.al.|[2308.15619](http://arxiv.org/abs/2308.15619)|null|
|**2023-08-28**|**R3D3: Dense 3D Reconstruction of Dynamic Scenes from Multiple Cameras**|密集的三维重建和自我运动估计是自动驾驶和机器人技术的关键挑战。与当今部署的复杂、多模态系统相比，多摄像头系统提供了一种更简单、低成本的替代方案。然而，基于相机的复杂动态场景的3D重建已被证明是极其困难的，因为现有的解决方案往往会产生不完整或不连贯的结果。我们提出了R3D3，一种用于密集3D重建和自我运动估计的多摄像机系统。我们的方法在利用来自多个相机的时空信息的几何估计和单目深度细化之间迭代。我们集成了多相机特征相关性和密集束调整算子，以产生稳健的几何深度和姿态估计。为了改进几何深度不可靠的重建，例如对于移动对象或低纹理区域，我们通过深度细化网络引入了可学习的场景先验。我们展示了这种设计能够对具有挑战性的动态户外环境进行密集、一致的3D重建。因此，我们在DDAD和NuScenes基准上实现了最先进的密集深度预测。 et.al.|[2308.14713](http://arxiv.org/abs/2308.14713)|null|
|**2023-08-27**|**Sparse3D: Distilling Multiview-Consistent Diffusion for Object Reconstruction from Sparse Views**|从极其稀疏的视图重建3D对象是一个长期存在且具有挑战性的问题。虽然最近的技术使用图像扩散模型来在新视点生成看似合理的图像，或者使用分数蒸馏采样（SDS）将预先训练的扩散先验提取到3D表示中，但这些方法通常难以同时实现新视点合成（NVS）和几何体的高质量、一致和详细的结果。在这项工作中，我们提出了Sparse3D，这是一种为稀疏视图输入量身定制的新型3D重建方法。我们的方法从多视点一致扩散模型中提取鲁棒先验，以细化神经辐射场。具体来说，我们使用了一个控制器，该控制器利用输入视图中的核线特征，引导预先训练的扩散模型，如稳定扩散，以生成与输入保持3D一致性的新视图图像。通过利用强大的图像扩散模型中的2D先验，我们的集成模型即使在面对开放世界对象时也能始终如一地提供高质量的结果。为了解决传统SDS引入的模糊性，我们引入了类别分数蒸馏采样（C-SDS）来增强细节。我们在CO3DV2上进行了实验，这是一个真实世界对象的多视图数据集。定量和定性评估都表明，我们的方法在NVS和几何重建方面优于以往最先进的工作。 et.al.|[2308.14078](http://arxiv.org/abs/2308.14078)|null|
|**2023-08-27**|**Multi-plane denoising diffusion-based dimensionality expansion for 2D-to-3D reconstruction of microstructures with harmonized sampling**|获得可靠的微观结构数据集是借助集成计算材料工程（ICME）方法进行材料系统设计的关键一步。然而，由于高实验成本或技术限制，获得三维（3D）微观结构数据集通常具有挑战性，而获得二维（2D）显微照片相对更容易。为了解决这个问题，本研究提出了一种使用基于扩散的生成模型（DGM）进行微观结构二维到三维重建的新框架，称为Micro3Diff。具体而言，这种方法仅需要预先训练的DGM来生成2D样本，并且维度扩展（2D到3D）仅在生成过程（即反向扩散过程）中发生。所提出的框架结合了一个称为多平面去噪扩散的新概念，该概念将来自不同平面的噪声样本（即潜在变量）转换为数据结构，同时保持3D空间中的空间连通性。此外，还开发了一个协调的采样过程，以解决在维度扩展过程中DGM的反向马尔可夫链的可能偏差。结合起来，我们证明了Micro3Diff在重建具有连接切片的3D样本方面的可行性，这些切片在形态学上与原始2D图像保持等效。为了验证Micro3Diff的性能，重建了各种类型的微观结构（合成和实验观察），并对生成的样品的质量进行了定性和定量评估。成功的重建结果激发了Micro3Diff在即将到来的ICME应用中的潜在应用，同时在理解和操纵DGM的潜在空间方面取得了突破。 et.al.|[2308.14035](http://arxiv.org/abs/2308.14035)|null|
|**2023-08-26**|**HoloPOCUS: Portable Mixed-Reality 3D Ultrasound Tracking, Reconstruction and Overlay**|超声（US）成像为手术指导和诊断成像提供了一种安全、易用的解决方案。传统2D US用于介入引导的有效使用需要丰富的经验来将图像平面投影到患者身上，并且诊断中的图像解释存在高的用户内和用户间可变性。3D US重建允许更一致的诊断和解释，但现有的解决方案在设备和实时导航的适用性方面受到限制。为了解决这些问题，我们提出了HoloPOCUS——一种混合现实的US系统（MR-US），它在护理点环境中将丰富的US信息覆盖在用户的视觉上。HoloPOCUS扩展了现有的MR-US方法，不仅将US平面放置在用户的视野中，还包括3D重建和投影，可以帮助使用传统探针进行程序指导。我们验证了一个跟踪管道，该管道与现有的MR-US工作相比具有更高的准确性。此外，通过幻影任务进行的用户研究表明，当使用我们提出的方法时，导航持续时间显著改善。 et.al.|[2308.13823](http://arxiv.org/abs/2308.13823)|null|
|**2023-08-25**|**Textureless Deformable Surface Reconstruction with Invisible Markers**|重建和跟踪很少或没有纹理的可变形表面一直是一个挑战。从根本上说，这些挑战源于无纹理表面缺乏建立跨图像对应的特征。在这项工作中，我们提出了一种新型的标记，以主动丰富物体的表面特征，从而简化三维表面重建和对应跟踪。我们的标记是由荧光染料制成的，只有在紫外线下才能看到，在正常的照明条件下是看不见的。利用这些标记，我们设计了一个多摄像头系统，以时间复用的方式捕捉紫外线和可见光下的表面变形。在紫外线下，物体上的标记会出现，以丰富其表面纹理，从而实现高质量的3D形状重建和跟踪。在可见光下，标记变得不可见，使我们能够捕捉到物体原始的未受影响的外观。我们在各种具有挑战性的场景中进行实验，包括手势、面部表情、挥舞布料和手物交互。在所有这些情况下，我们证明了我们的系统能够产生稳健、高质量的3D重建和跟踪。 et.al.|[2308.13678](http://arxiv.org/abs/2308.13678)|null|
|**2023-08-23**|**ARF-Plus: Controlling Perceptual Factors in Artistic Radiance Fields for 3D Scene Stylization**|辐射场风格转移是一个新兴的领域，由于神经辐射场在三维重建和视图合成中的出色表现，作为三维场景风格化的一种手段，它最近受到了欢迎。我们强调了在辐射场风格转移方面的研究空白，即缺乏足够的感知可控性，这是由2D图像风格转移中的现有概念所驱动的。在本文中，我们提出了ARF Plus，一个对感知因素提供可管理控制的3D神经风格转移框架，以系统地探索3D场景风格化中的感知可控性。提出了四种不同类型的控制——颜色保持控制、（风格模式）比例控制、空间（选择性风格化区域）控制和深度增强控制——并将其集成到该框架中。来自真实世界数据集的定量和定性结果表明，在对3D场景进行风格化时，我们的ARF Plus框架中的四种类型的控件成功地实现了相应的感知控件。这些技术适用于单个样式输入以及场景中多个样式的同时应用。这开启了一个无限可能性的领域，允许对风格化效果进行定制修改，并灵活融合不同风格的优势，最终能够在3D场景中创造新颖而引人注目的风格效果。 et.al.|[2308.12452](http://arxiv.org/abs/2308.12452)|null|
|**2023-08-21**|**Coordinate Quantized Neural Implicit Representations for Multi-view Reconstruction**|近年来，在从多视图图像中学习用于三维重建的神经隐式表示方面取得了巨大进展。作为补充坐标的额外输入，使用正弦函数作为位置编码在利用基于坐标的神经网络揭示高频细节方面发挥着关键作用。然而，高频位置编码使优化不稳定，这导致了有噪声的重建和空空间中的伪影。为了在一般意义上解决这个问题，我们引入了学习具有量化坐标的神经隐式表示，这减少了优化过程中该领域的不确定性和模糊性。代替连续坐标，我们使用量化坐标之间的最近插值将连续坐标离散为离散坐标，这些量化坐标是通过以极高分辨率离散场而获得的。我们使用离散坐标及其位置编码来通过体积渲染学习隐式函数。这显著减少了采样空间中的变化，并对来自不同视图的光线的交点触发了更多的多视图一致性约束，从而能够以更有效的方式推断隐式函数。我们的量化坐标不会带来任何计算负担，并且可以无缝地使用最新的方法。我们根据广泛使用的基准进行的评估表明，我们优于最先进的基准。我们的代码可在https://github.com/MachinePerceptionLab/CQ-NIR. et.al.|[2308.11025](http://arxiv.org/abs/2308.11025)|**[link](https://github.com/machineperceptionlab/cq-nir)**|
|**2023-08-19**|**Root Pose Decomposition Towards Generic Non-rigid 3D Reconstruction with Monocular Videos**|这项工作专注于基于单目RGB视频序列的非刚性物体的3D重建。具体来说，我们的目标是为通用对象类别和随意捕捉的场景构建高保真度模型。为此，我们不假设对象的已知根姿势，也不使用特定类别的模板或密集姿势先验。我们的根姿势分解（RPD）方法的关键思想是保持每帧根姿势变换，同时通过局部变换建立密集场来校正根姿势。局部变换的优化是通过对规范空间的点配准来执行的。我们还将RPD应用于具有对象遮挡和个体差异的多对象场景。因此，RPD允许对包含具有大变形、复杂运动模式、遮挡和不同个体的尺度多样性的对象的复杂场景进行非刚性3D重建。这样的管道可能会扩展到野外的各种物体。我们的实验表明，RPD在具有挑战性的DAVIS、OVIS和AMA数据集上超越了最先进的方法。 et.al.|[2308.10089](http://arxiv.org/abs/2308.10089)|null|
|**2023-08-19**|**TSAR-MVS: Textureless-aware Segmentation and Correlative Refinement Guided Multi-View Stereo**|由于图像之间缺乏可靠的像素对应关系，无纹理区域的重建长期以来一直是MVS中具有挑战性的问题。在本文中，我们提出了无纹理感知分割和相关细化引导的多视图立体（TSAR-MVS），这是一种通过滤波、细化和分割有效解决三维重建中无纹理区域带来的挑战的新方法。首先，我们实现了联合假设滤波，这是一种将置信度估计器与视差不连续检测器相结合的技术，以消除不正确的深度估计。其次，为了以置信深度扩展像素，我们引入了一种迭代相关细化策略，该策略利用RANSAC生成超像素，然后是中值滤波器，以扩大准确确定的像素的影响。最后，我们提出了一种无纹理感知分割方法，该方法利用边缘检测和线检测来准确识别要使用3D平面拟合的大的无纹理区域。在大量数据集上的实验表明，我们的方法显著优于大多数非学习方法，并且在保留精细细节的同时，对无纹理区域表现出鲁棒性。 et.al.|[2308.09990](http://arxiv.org/abs/2308.09990)|null|
|**2023-08-19**|**A Theory of Topological Derivatives for Inverse Rendering of Geometry**|我们介绍了一个可微曲面演化的理论框架，该框架允许通过使用拓扑导数对图像泛函进行变分优化来实现离散拓扑变化。虽然先前的几何体反向渲染方法依赖于拓扑变化的轮廓梯度，但这种信号是稀疏的。相反，我们的理论推导了拓扑导数，这些导数将消失空穴和相位的引入与图像强度的变化联系起来。因此，我们能够以空穴或相成核的形式实现可微分的形状扰动。我们通过优化2D中的闭合曲线和3D中的曲面来验证所提出的理论，以深入了解当前方法的局限性，并实现改进的应用，如图像矢量化、从文本提示生成矢量图形、形状模糊图的单图像重建和多视图3D重建。 et.al.|[2308.09865](http://arxiv.org/abs/2308.09865)|null|
|**2023-08-18**|**On the three-dimensional relation between the coronal dimming, erupting filament and CME. Case study of the 28 October 2021 X1.0 event**|我们研究了太阳轨道飞行器、STEREO-A、SDO和SOHO从多个角度观测到的2021年10月28日X1.0耀斑/CME事件中，变暗区域的时空演化与细丝喷发和CME传播的主导方向之间的关系。我们提出了一种通过跟踪其面积演变来估计主调光方向的方法，并通过计算每个像素的球体表面积来强调其精确估计。为了确定早期通量绳的传播方向，我们通过分级圆柱壳建模（GCS）和细丝的连接点对CME进行了三维重建。调光最初呈放射状扩展，后来向东南移动。喷发细丝在太阳表面上重建的高度演化的正交投影位于主要变暗增长的扇区中，而GCS重建的内部的正交投影与总变暗区域对齐。灯丝在约180 Mm的高度达到约250 km/s的最大速度。其运动方向从径向强烈倾斜（向东64 $^\circ$，向南32$^\icrc$）。CME和细丝腿之间在3D方向上的50$^\circ$ 差异与重建确定的CME半宽度密切对应，这表明重建的细丝与CME体的相关腿之间存在潜在关系。我们的发现强调，变暗增长的主导传播反映了太阳大气中喷发磁结构（细丝）的方向，尽管细丝的演化与全球CME膨胀的方向没有直接关系。整体变暗形态与CME重建的内部非常相似，验证了使用变暗观测来深入了解CME方向。 et.al.|[2308.09815](http://arxiv.org/abs/2308.09815)|null|
|**2023-08-18**|**A deep learning approach for the 3D reconstruction of dust density and temperature in star-forming regions**|目的：我们介绍了一种新的深度学习方法，用于从单个恒星形成云核心（<0.2pc）的多波长尘埃发射观测中重建三维尘埃密度和温度分布。方法：我们通过使用POLARIS辐射传输代码处理云工厂模拟的云芯来构建训练数据集，以产生12至1300 $\mu$m之间23个波长的合成尘埃发射观测值。我们通过沿着单个视线重建云结构来简化任务，并为此目的训练条件可逆神经网络（cNN）。cNN属于归一化流方法组，能够预测目标灰尘特性的完全后验分布。我们测试了不同的cNN设置，从包括所有23个波长的场景到仅在7个波长进行观测的更现实的有限情况。我们在综合测试数据上评估了这些模型的预测性能。结果：我们报道了23个波长的cNN模型的良好重建性能，在$\log（n_{dust}/m^{-3}）$中实现了约1.8%的中值绝对相对误差，在$\log（T_{dust}/K）$中获得了约1%的中值绝对绝对相对误差。我们确定了在密度范围的低端高估和在密度和温度的高端低估的趋势，这可能与训练数据中的偏差有关。将覆盖范围限制为仅七个波长的组合，我们仍然发现令人满意的性能，在$\log（n_{dust}/m^{-3}）$和$\lod（T_{dust}/K）$ 中，平均绝对相对误差约为3.3%和2.5%。结论：这项概念验证研究表明，在现实的观测约束下，基于cNN的灰尘密度和温度三维重建方法非常有前景，甚至是可行的。 et.al.|[2308.09657](http://arxiv.org/abs/2308.09657)|null|
|**2023-08-18**|**O^2-Recon: Completing 3D Reconstruction of Occluded Objects in the Scene with a Pre-trained 2D Diffusion Model**|遮挡是RGB-D视频三维重建中的一个常见问题，通常会阻碍对象的完整重建，并带来持续的问题。在本文中，我们提出了一种新的框架，通过基于2D扩散的绘画模型来重建物体隐藏部分的完整表面。具体来说，我们利用预先训练的扩散模型来填充2D图像的隐藏区域。然后，我们在绘制的图像中使用这些来优化用于3D重建的每个实例的神经隐式表面表示。由于制作这一过程所需的彩绘面具很棘手，我们采用了一种“人在环”的策略，只需要很少的人参与就可以制作出高质量的面具。此外，物体的某些部分可能被完全隐藏，因为视频通常是从有限的视角拍摄的。为了确保恢复这些不可见区域，我们开发了一种级联网络架构，用于预测有符号距离场，利用位置编码的不同频带并保持整体平滑。除了常用的渲染损失、Eikonal损失和轮廓损失外，我们还采用了基于CLIP的语义一致性损失来从看不见的相机角度引导曲面。在ScanNet场景上的实验表明，我们提出的框架在场景级RGB-D视频的对象级重建中实现了最先进的准确性和完整性。 et.al.|[2308.09591](http://arxiv.org/abs/2308.09591)|null|
|**2023-08-18**|**DMCVR: Morphology-Guided Diffusion Model for 3D Cardiac Volume Reconstruction**|通过电影磁共振成像（cMRI）进行精确的3D心脏重建对于改善心血管疾病诊断和了解心脏运动至关重要。然而，目前在临床环境中使用的基于心脏MRI的重建技术是2D的，通过平面的分辨率有限，导致重建的心脏体积质量低。为了从稀疏的2D图像堆栈中更好地重建3D心脏体积，我们提出了一种用于3D心脏体积重建的形态学引导扩散模型DMCVR，该模型综合了高分辨率2D图像和相应的3D重建体积。我们的方法优于以前的方法，因为它将心脏形态限制在生成模型上，消除了潜在代码耗时的迭代优化过程，并提高了生成质量。所学习的潜在空间为重建3D心脏形状提供了具有高度可解释价值的每个2D cMRI切片的全局语义、局部心脏形态和细节。我们的实验表明，DMCVR在二维生成和三维重建性能等方面都非常有效。有了DMCVR，我们可以制作高分辨率的3D心脏MRI重建，超越了目前的技术。我们提出的框架在提高心脏病诊断和治疗计划的准确性方面具有巨大潜力。代码可访问https://github.com/hexiaoxiao-cs/DMCVR. et.al.|[2308.09223](http://arxiv.org/abs/2308.09223)|**[link](https://github.com/hexiaoxiao-cs/dmcvr)**|
|**2023-08-17**|**A Fusion of Variational Distribution Priors and Saliency Map Replay for Continual 3D Reconstruction**|单图像三维重建是一项研究挑战，重点是从单视图图像中预测三维物体形状。这项任务需要大量的数据采集来预测形状的可见部分和遮挡部分。此外，基于学习的方法面临着为所有可能的类创建综合训练数据集的困难。为此，我们提出了一种基于连续学习的3D重建方法，其中我们的目标是使用变分先验设计一个模型，即使在对新类进行训练后，该模型仍然可以合理地重建以前看到的类。变分先验表示抽象形状和战斗遗忘，而显著性映射则以较少的内存使用来保留对象属性。由于存储大量训练数据的资源限制，这一点至关重要。此外，我们引入了基于显著性地图的体验回放，以捕捉全局和不同的对象特征。与已建立的方法相比，全面的实验在定量和定性方面都显示出有竞争力的结果。 et.al.|[2308.08812](http://arxiv.org/abs/2308.08812)|null|
|**2023-08-17**|**Long-Range Grouping Transformer for Multi-View 3D Reconstruction**|如今，变压器网络在许多计算机视觉任务中表现出了优越的性能。在遵循这种范式的多视图3D重建算法中，当面对大量视图输入时，自注意处理必须处理复杂的图像标记，包括大量信息。信息内容的诅咒导致了模型学习的极端困难。为了缓解这个问题，最近的方法压缩了表示每个视图的令牌编号，或者放弃了来自不同视图的令牌之间的注意力操作。显然，它们会对性能产生负面影响。因此，我们提出了基于分治原则的长程分组注意力（LGA）。来自所有视图的令牌都被分组以进行单独的注意力操作。每组中的标记都是从所有视图中采样的，并且可以为驻留的视图提供宏表示。不同群体之间的多样性保证了特征学习的丰富性。可以建立一种有效且高效的编码器，该编码器使用LGA连接视图间特征，并使用标准自注意层提取视图内特征。此外，还设计了一种新颖的渐进上采样解码器，用于相对高分辨率的体素生成。在此基础上，我们构建了一个强大的基于变压器的网络，称为LRGT。在ShapeNet上的实验结果验证了我们的方法在多视图重建中达到了SOTA的精度。代码将在https://github.com/LiyingCV/Long-Range-Grouping-Transformer. et.al.|[2308.08724](http://arxiv.org/abs/2308.08724)|**[link](https://github.com/liyingcv/long-range-grouping-transformer)**|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-01**|**Iterative Multi-granular Image Editing using Diffusion Models**|文本引导图像合成的最新进展极大地改变了创造性专业人员生成艺术和美学上令人愉悦的视觉资产的方式。为了充分支持这种创造性的努力，这个过程应该具备以下能力：1）迭代地编辑世代，2）控制所需变化的空间范围（全局、局部或介于两者之间的任何变化）。我们将这种实用的问题设置形式化为迭代多粒度编辑。虽然用于图像合成和编辑的基于扩散的模型已经取得了实质性进展，但它们都是一次性的（即，没有迭代编辑能力），并且不会自然产生多粒度控制（即，覆盖从局部到全局编辑的全谱）。为了克服这些缺点，我们提出了EMILIE：迭代多粒度图像编辑器。EMILIE引入了一种新的潜在迭代策略，该策略重新利用预先训练的扩散模型来促进迭代编辑。这由用于多粒度控制的梯度控制操作来补充。我们引入了一个新的基准数据集来评估我们新提出的设置。我们针对最近最先进的方法进行了详尽的定量和定性评估，以适应我们的任务，从而达到EMILIE的勇气。我们希望我们的工作将引起人们对这一新确定的、务实的问题设置的关注。 et.al.|[2309.00613](http://arxiv.org/abs/2309.00613)|null|
|**2023-09-01**|**Presentation of some elementary properties of Segal-Bargmann space and of unitary Segal-Bargmann transform with applications**|在这项工作中，我们给出了Segal-Bargmann空间的一些基本性质和酉Segal-Bargmann变换的一些性质，并将其应用于由扩散问题或Regeon场论引起的微分算子。 et.al.|[2309.00566](http://arxiv.org/abs/2309.00566)|null|
|**2023-09-01**|**Diffusion limited aggregation, resetting and large deviations of Brownian motion**|分形生长模型通常考虑颗粒在介质中扩散，并且在第一次接触时不可逆地粘附在形成的聚集体上。众所周知的扩散限制聚集（DLA）模型及其推广表明，分形维数对粒子随机运动的性质很敏感。在这里，我们研究了有限寿命布朗粒子形成的结构，即在规定时间内被约束以找到聚集体的粒子，否则这些粒子将被移除。这种运动可以通过具有随机重置的扩散来建模，这是近年来被广泛研究的一类过程。在较短的使用寿命限制内，极少数颗粒能够到达聚集体。因此，生长是由非典型布朗轨迹控制的，根据大偏差原理，这些轨迹几乎是直线移动的。在 $d$维度中，骨料的分形维数从DLA值开始下降，并趋于1，而不是像弹道骨料预期的那样增加到$d$ 。在零寿命极限中，我们恢复了R.Jullien很久以前提出的“尖端聚合”的非平凡模型[J.Phys.A:Math.Gen.192129（1986）]。 et.al.|[2309.00560](http://arxiv.org/abs/2309.00560)|null|
|**2023-09-01**|**Relativistic hydrodynamic fluctuations from an effective action: causality, stability, and the information current**|因果关系是延迟格林函数在相对论的所有惯性系中保持延迟的必要条件，这确保了波动的耗散是洛伦兹不变的概念。对于通过Schwinger-Keldysh形式引入的具有随机波动的一阶BDNK理论，我们表明，强加因果关系和稳定性会导致流体动力学波动的相关函数，这些函数仅在小频率和波数下显示出预期的物理性质，即在一阶方法的预期有效范围内。对于使用信息流构建的Israel和Stewart类型的二阶理论，使得熵产生总是非负的，使用Martin Siggia-Rose方法提出了一个随机公式，其中施加因果关系和稳定性会导致具有所需性质的相关器。我们还展示了如何通过这样的行动来确定格林的职能。我们确定了 $\mathbb｛Z｝_2$ 对称性，类似于Kubo Martin Schwinger对称性，在该对称性下，Martin Siggia-Rose作用是不变的。这种改进的Kubo-Martin-Schwinger对称性为流体动力学系统的有效作用公式提供了新的指导，该系统的动力学不完全受守恒定律的约束。此外，这种对称性确保了详细平衡原理在协变方式下是有效的。我们使用新的对称性来进一步阐明Schwinger Keldysh和Martin Siggia Rose方法之间的联系，在相对论流体力学的二阶理论中建立了这些描述之间的精确联系。最后，利用修正后的Kubo-Martin-Schwinger对称性确定了在一般流体动力学框架下以色列-斯图尔特理论中描述扩散的相应作用。 et.al.|[2309.00512](http://arxiv.org/abs/2309.00512)|null|
|**2023-09-01**|**Schwinger-Keldysh effective field theory for stable and causal relativistic hydrodynamics**|我们构造了稳定的因果有效场论（EFTs）来描述相对论扩散和相对论流体力学中的统计涨落。这些EFT是完全非线性的，包括与背景源的耦合，使我们能够计算包括统计波动影响在内的n点时间有序相关函数。我们构造的EFT分别受到相对论扩散的Maxwell Cattaneo模型和相对论流体力学的M uller Israel Stewart模型的启发，并使用Martin Siggia Rose和Schwinger Keldysh形式推导对称性，这确保了理论中的n点相关函数和相互作用满足适当的波动耗散定理。由于这些EFT通常允许不受低能红外对称性固定的紫外线扇区，我们发现它们同时允许动态KMS对称性的多重实现。我们还评论了在最近提出的相对论流体力学的稳定和因果Bemfica Disconzi-Noronha Kovtun模型中包含统计波动的某些障碍。 et.al.|[2309.00511](http://arxiv.org/abs/2309.00511)|null|
|**2023-09-01**|**How heat propagates in `non-Fermi liquid' $^3$He**|在朗道的费米液体中，传输由准粒子之间的散射控制。正常液体$^3$He符合此图，但仅当T$<0.02$T$_F$时。在这里，我们观察到与标准行为的偏差伴随着费米子-费米子散射时间下降到普朗克时间$\frac｛\hbar｝｛k_BT｝$以下。这种量子液体的热扩散率受基本物理常数和早期在经典液体中观察到的最小值的限制。这意味着液体的集体激发（声音模式）正在携带热量。我们认为，如果热量由2k$_F$流体动力学声音模式携带，那么热导率的振幅和迄今为止无法解释的$T^{1/2}$ 温度依赖性都可以在没有其他可调节参数的情况下找到解释。 et.al.|[2309.00502](http://arxiv.org/abs/2309.00502)|null|
|**2023-09-01**|**VideoGen: A Reference-Guided Latent Diffusion Approach for High Definition Text-to-Video Generation**|在本文中，我们提出了VideoGen，这是一种文本到视频的生成方法，它可以使用参考引导的潜在扩散生成具有高帧保真度和强时间一致性的高清晰度视频。我们利用现成的文本到图像生成模型，例如Stable Diffusion，从文本提示生成具有高内容质量的图像，作为指导视频生成的参考图像。然后，我们引入了一个以参考图像和文本提示为条件的高效级联潜在扩散模块，用于生成潜在视频表示，然后是基于流的时间上采样步骤，以提高时间分辨率。最后，我们通过增强的视频解码器将潜在的视频表示映射到高清晰度视频中。在训练过程中，我们使用地面实况视频的第一帧作为参考图像来训练级联的潜在扩散模块。我们的方法的主要特点包括：文本到图像模型生成的参考图像提高了视觉逼真度；以它为条件，使扩散模型更加关注视频动力学的学习；并且视频解码器在未标记的视频数据上进行训练，从而受益于高质量的容易获得的视频。VideoGen在定性和定量评估方面开创了文本到视频生成的新技术。 et.al.|[2309.00398](http://arxiv.org/abs/2309.00398)|null|
|**2023-09-01**|**Bayesian estimation and reconstruction of marine surface contaminant dispersion**|向海洋环境排放有害物质对公众健康和生态系统都构成重大风险。在此类事件中，必须准确估计来源的释放强度，并根据收集的测量结果重建物质的时空分布。在这项研究中，我们提出了一个综合评估框架来应对这一挑战，该框架可以与传感器网络或移动传感器一起用于环境监测。我们采用基本对流-扩散偏微分方程（PDE）来表示非均匀流场中物理量的一般色散。使用动态瞬态有限元法（FEM）将PDE模型在空间上离散为线性状态空间模型，从而可以将时变色散的表征纳入从传感器测量推断模型状态的问题中。我们还考虑了不完美的传感现象，包括在使用传感器网络时经常遇到的漏检和信号量化。这种复杂的传感器过程将非线性引入贝叶斯估计过程。Rao-Blackellised粒子滤波器（RBPF）被设计为通过利用状态空间模型的线性结构来提供有效的解决方案，而测量模型的非线性可以通过粒子的蒙特卡罗近似来处理。通过模拟波罗的海漏油事件和真实的海洋流量数据，验证了所提出的框架。结果表明，在存在不完美测量的情况下，所开发的时空离散模型和估计方案是有效的。此外，还讨论了参数选择过程，并进行了一些比较研究，以说明所提出的算法与现有方法相比的优势。 et.al.|[2309.00369](http://arxiv.org/abs/2309.00369)|null|
|**2023-09-01**|**Fast Diffusion EM: a diffusion model for blind inverse problems with application to deconvolution**|使用扩散模型来求解逆问题是一个日益增长的研究领域。目前的方法假设退化是已知的，并在恢复质量和多样性方面提供了令人印象深刻的结果。在这项工作中，我们利用这些模型的效率来联合估计退化模型的恢复图像和未知参数。特别地，我们设计了一种基于众所周知的期望最小化（EM）估计方法和扩散模型的算法。我们的方法在使用从扩散模型中提取的样本来近似逆问题的预期对数似然性和估计未知模型参数的最大化步骤之间交替。对于最大化步骤，我们还引入了一种新的基于即插即用去噪器的模糊核正则化。扩散模型运行时间很长，因此我们提供了算法的快速版本。与其他最先进的方法相比，在盲图像去模糊方面的大量实验证明了我们的方法的有效性。 et.al.|[2309.00287](http://arxiv.org/abs/2309.00287)|null|
|**2023-09-01**|**Data-driven Topology Optimization of Channel Flow Problems**|典型的拓扑优化方法需要复杂的迭代计算，无法满足快速计算应用的要求。研究神经网络是为了减少计算优化结果的时间，然而，流体拓扑优化的数据驱动方法很少被讨论。本文旨在介绍一种神经网络结构，该结构避免了耗时的迭代过程，并对Stokes流的拓扑优化具有较强的泛化能力。对已经成功用于固体结构优化问题的不同神经网络方法进行了变异，并针对流体拓扑优化情况进行了检验，包括卷积神经网络（CNN）、条件生成对抗性网络（cGAN）和去噪扩散隐式模型（DDIM）。将所提出的神经网络方法应用于Stokes流的通道流拓扑优化问题。结果表明，我们提出的方法具有较高的像素精度，与传统方法相比，我们的执行时间平均减少了663倍。 et.al.|[2309.00278](http://arxiv.org/abs/2309.00278)|null|
|**2023-09-01**|**DiffuGen: Adaptable Approach for Generating Labeled Image Datasets using Stable Diffusion Models**|生成高质量的标记图像数据集对于训练计算机视觉领域中准确和稳健的机器学习模型至关重要。然而，手动标记真实图像的过程通常耗时且成本高昂。为了解决与数据集生成相关的这些挑战，我们引入了“DiffuGen”，这是一种简单且适应性强的方法，它利用稳定扩散模型的力量来高效地创建标记图像数据集。通过利用稳定的扩散模型，我们的方法不仅确保了生成数据集的质量，而且为标签生成提供了一个通用的解决方案。在本文中，我们介绍了DiffuGen背后的方法，它将扩散模型的能力与两种不同的标记技术相结合：无监督和有监督。与众不同的是，DiffuGen采用了即时模板生成自适应图像和文本反转，以增强扩散模型的功能。 et.al.|[2309.00248](http://arxiv.org/abs/2309.00248)|**[link](https://github.com/mshenoda/diffugen)**|
|**2023-09-01**|**Analytic shock-fronted solutions to a reaction-diffusion equation with negative diffusivity**|反应扩散方程（RDE）根据扩散和净局部变化对密度场 $u（\vec{x}，t）$的时空演化进行建模。通常，对于$u$的所有值，扩散率都是正的，这会导致密度分散。然而，具有负扩散率的RDE可以模拟聚集，这在某些情况下是优选的行为。在本文中，我们考虑一个具有二次扩散率$D（u）=（u-a）（u-b）$的非线性RDE，它对$u\In（a，b）$是负的。我们使用非经典对称性来构造时间相关的解析后退、碰撞波和后退行波解。这些解最初是多值的，我们通过插入冲击将它们转换为单值解。我们检验了这些解析解的性质，包括它们的类Stefan边界条件，并进行了相平面分析。我们还研究了$u=0$和$u=1$常解的谱稳定性，并证明了对于某些$a$和$b$ ，后退行波是谱稳定的。此外，我们引入了一种新的冲击条件，其中扩散率和通量在整个冲击中是连续的。对于关于零点中点对称的扩散率，这种条件恢复了众所周知的等面积规则，但对于非对称扩散率，它会导致不同的冲击位置。 et.al.|[2309.00204](http://arxiv.org/abs/2309.00204)|null|
|**2023-09-01**|**Diffusion Model with Clustering-based Conditioning for Food Image Generation**|基于图像的饮食评估是一种有效而准确的解决方案，用于记录和分析营养摄入，使用用餐场合图像作为输入。基于深度学习的技术通常用于执行图像分析，如食物分类、分割和份量估计，这些分析依赖于大量带有注释的食物图像进行训练。然而，这种数据依赖性对现实世界的应用构成了重大障碍，因为获取大量、多样化和平衡的食物图像可能具有挑战性。一个潜在的解决方案是使用合成食物图像进行数据增强。尽管现有工作已经探索了使用基于生成对抗性网络（GAN）的结构进行生成，但合成食品图像的质量仍然较差。此外，虽然基于扩散的生成模型在一般图像生成任务中显示出了有希望的结果，但由于类内差异很大，食物图像的生成可能具有挑战性。在本文中，我们研究了基于条件扩散模型的合成食品图像的生成，并提出了一个有效的基于聚类的训练框架ClusDiff，用于生成高质量和有代表性的食品图像。该方法在Food-101数据集上进行了评估，与现有的图像生成工作相比，其性能有所提高。我们还证明，ClusDiff生成的合成食物图像可以帮助解决使用VFN-LT数据集进行长尾食物分类时的严重类别不平衡问题。 et.al.|[2309.00199](http://arxiv.org/abs/2309.00199)|null|
|**2023-09-01**|**Breakdown of the drift-diffusion model for transverse spin transport in a disordered Pt film**|用非平衡格林函数方法计算了平面内电流作用下无序Pt薄膜的自旋积累和自旋电流分布。在样本的块状区域，这种方法捕捉到了其他计算中发现的固有自旋霍尔效应。在表面附近，结果显示了与广泛使用的自旋扩散模型结果的定性差异，即使在修改边界条件以试图解释这些差异时也是如此。一个不同之处在于，横向自旋输运的有效自旋扩散长度与其纵向对应长度显著不同，而是与平均自由程相似。由于与纵向自旋输运相比，输运机制的差异，该特征对于通过本征自旋霍尔机制产生的自旋电流来说可能是通用的。Pt膜中的轨道积累仅在表面附近显著，并且只有在存在自旋-轨道耦合的情况下才有小的成分渗透到本体中，这是由自旋积累引起的二次效应。 et.al.|[2309.00183](http://arxiv.org/abs/2309.00183)|null|
|**2023-08-31**|**BuilDiff: 3D Building Shape Generation using Single-Image Conditional Point Cloud Diffusion Models**|具有低数据采集成本的3D建筑生成，例如单图像到3D，变得越来越重要。然而，现有的单图像到三维建筑创作作品大多局限于具有特定视角的图像，因此很难缩放到实际案例中常见的普通视图图像。为了填补这一空白，我们提出了一种新的3D建筑形状生成方法，该方法利用点云扩散模型和图像调节方案，展示了对输入图像的灵活性。通过配合两个条件扩散模型，并在去噪过程中引入正则化策略，我们的方法能够在保持整体结构的同时对建筑屋顶进行综合。我们在两个新构建的数据集上验证了我们的框架，大量实验表明，我们的方法在建筑生成质量方面优于以前的工作。 et.al.|[2309.00158](http://arxiv.org/abs/2309.00158)|null|
|**2023-08-31**|**Conformation and dynamics of partially active linear polymers**|我们对分离的部分活性聚合物进行了数值模拟，这些聚合物被其一部分单体驱动而脱离平衡。我们证明，如果活性珠都聚集在一个连续的区块中，那么沿着链的部分的位置决定了系统的构象和动力学性质。值得注意的是，仅通过改变活性嵌段的位置，就可以将聚合物的扩散系数从{活性-类调节为被动-类}。此外，在特殊情况下，可以通过降低总体聚合物活性来实现扩散的增强。我们的发现可能有助于对活性生物物理系统（如丝状细菌或蠕虫）进行建模。 et.al.|[2309.00122](http://arxiv.org/abs/2309.00122)|null|
|**2023-08-31**|**The low-LET radiation contribution to the tumor dose in diffusing alpha-emitters radiation therapy**|扩散α发射体放射治疗（alpha DaRT）使α粒子能够用于治疗实体瘤。它使用携带少量uCi Ra-224的间隙源，旨在释放其短命的子代，这些子代发射α粒子、β粒子、俄歇粒子以及转换电子、x射线和伽马射线。这些原子在源周围扩散，形成一个直径为几毫米的致命高剂量区域。以前的研究只关注α剂量。这项工作解决了单源和多源晶格中由散射原子和源表面原子贡献的电子和光子。这允许评估低LET对剂量的贡献，并证明周围健康组织的保留。使用蒙特卡罗代码计算剂量。我们将简单线源的结果与全模拟的结果进行了比较，全模拟实现了真实的源几何结构和扩散原子的扩散。我们考虑两种极端情况：低扩散和高Pb-212泄漏，以及高扩散和低泄漏。源晶格中的低LET剂量是通过单源贡献的叠加来计算的。我们发现，对于以4mm间距排列的六边形晶格中携带3uCi/cm Ra-224的源，两种情况下源之间的最小低LET剂量为18-30Gy，并且由β贡献主导。低LET剂量在距晶格3mm处降至5Gy以下。对于临床相关距离（2-4mm）上的总低LET剂量，线源近似的准确性为15%。对于3uCi/cm Ra-224来源，低LET剂量的贡献可以将细胞存活率降低高达2-3个数量级。将源活性增加5倍可以使低LET剂量达到治疗水平，从而导致自增强配置，并可能增加晶格间距。 et.al.|[2309.00067](http://arxiv.org/abs/2309.00067)|null|
|**2023-08-31**|**Robust Variational Physics-Informed Neural Networks**|我们引入了变分物理知情神经网络（RVPINN）的鲁棒版本来近似偏微分方程（PDE）的解。我们从问题的一个弱Petrov-Galerkin公式开始，选择一个离散的测试空间，并定义一个二次损失函数，如在VPINNs中。而在VPINN中，损失取决于给定测试空间的选定基函数，在此，我们基于离散对偶范数中的残差来最小化损失，该残差与测试空间对测试基函数的选择无关。我们证明了这种损失是能量范数中真实误差的可靠和有效的估计量。所提出的损失函数需要计算Gram矩阵逆，类似于传统的残差最小化方法。为了验证我们的理论发现，我们在一个空间维度上测试了我们的算法在几个平流主导的扩散问题中的性能和稳健性。我们得出结论，RVPINN是一种稳健的方法。 et.al.|[2308.16910](http://arxiv.org/abs/2308.16910)|null|
|**2023-08-31**|**InterDiff: Generating 3D Human-Object Interactions with Physics-Informed Diffusion**|本文提出了一项预测三维人机交互（HOI）的新任务。大多数现有的HOI合成研究缺乏与动态对象的全面全身交互，例如，通常仅限于操纵小对象或静态对象。我们的任务更具挑战性，因为它需要建模各种形状的动态对象，捕捉全身运动，并确保物理有效的交互。为此，我们提出了InterDiff，该框架包括两个关键步骤：（i）交互扩散，其中我们利用扩散模型对未来人机交互的分布进行编码；（ii）相互作用校正，其中我们引入了一个基于物理的预测器来校正扩散步骤中的去噪HOI。我们的关键见解是注入先验知识，即参考中关于接触点的交互遵循一个简单的模式，并且很容易预测。在多个人机交互数据集上的实验证明了我们的方法在这项任务中的有效性，能够产生逼真、生动和显著的长期3D HOI预测。 et.al.|[2308.16905](http://arxiv.org/abs/2308.16905)|**[link](https://github.com/Sirui-Xu/InterDiff)**|
|**2023-09-01**|**GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields**|开发能够在非结构化现实世界环境中通过视觉观察执行各种操作任务的代理是机器人技术中的一个长期问题。为了实现这一目标，机器人需要对场景的3D结构和语义有全面的了解。在这项工作中，我们提出了 $\textbf｛GNFactor｝$，一种用于多任务机器人操作的视觉行为克隆代理，具有$\textbf｛G｝$通用$\textbf｛N｝$eural功能$\textbf｛F｝$字段。GNFactor联合优化了作为重建模块的可推广神经场（GNF）和作为决策模块的感知转换器，利用了共享的深度3D体素表示。为了在3D中结合语义，重建模块利用视觉语言基础模型（$\textit｛例如｝$ ，Stable Diffusion）将丰富的语义信息提取到深度3D体素中。我们在3个真实机器人任务中评估了GNFactor，并在10个RLBench任务中进行了详细的消融，演示次数有限。我们观察到GNFactor在可见和不可见任务中比当前最先进的方法有了实质性的改进，证明了GNFactor强大的泛化能力。我们的项目网站是https://yanjieze.com/GNFactor/。 et.al.|[2308.16891](http://arxiv.org/abs/2308.16891)|**[link](https://github.com/YanjieZe/GNFactor)**|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-01**|**GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields**|开发能够在非结构化现实世界环境中通过视觉观察执行各种操作任务的代理是机器人技术中的一个长期问题。为了实现这一目标，机器人需要对场景的3D结构和语义有全面的了解。在这项工作中，我们提出了 $\textbf｛GNFactor｝$，一种用于多任务机器人操作的视觉行为克隆代理，具有$\textbf｛G｝$通用$\textbf｛N｝$eural功能$\textbf｛F｝$字段。GNFactor联合优化了作为重建模块的可推广神经场（GNF）和作为决策模块的感知转换器，利用了共享的深度3D体素表示。为了在3D中结合语义，重建模块利用视觉语言基础模型（$\textit｛例如｝$ ，Stable Diffusion）将丰富的语义信息提取到深度3D体素中。我们在3个真实机器人任务中评估了GNFactor，并在10个RLBench任务中进行了详细的消融，演示次数有限。我们观察到GNFactor在可见和不可见任务中比当前最先进的方法有了实质性的改进，证明了GNFactor强大的泛化能力。我们的项目网站是https://yanjieze.com/GNFactor/。 et.al.|[2308.16891](http://arxiv.org/abs/2308.16891)|**[link](https://github.com/YanjieZe/GNFactor)**|
|**2023-08-30**|**Active Neural Mapping**|我们用不断学习的神经场景表示来解决主动映射的问题，即主动神经映射。关键在于通过有效的代理移动积极找到要探索的目标空间，从而最大限度地减少在以前看不见的环境中飞行中的地图不确定性。在本文中，我们检验了连续学习神经场的权重空间，并从经验上表明，神经变异性，即对随机权重扰动的预测鲁棒性，可以直接用于测量神经映射的瞬时不确定性。结合神经映射中继承的连续几何信息，可以引导agent找到一条可遍历的路径，以逐渐获得环境知识。我们首次提出了一种用于在线场景重建的具有基于坐标的隐式神经表示的主动映射系统。在视觉逼真的Gibson和Matterport3D环境中的实验证明了所提出方法的有效性。 et.al.|[2308.16246](http://arxiv.org/abs/2308.16246)|null|
|**2023-08-29**|**Canonical Factors for Hybrid Neural Fields**|因子特征量提供了一种简单的方法来构建更紧凑、高效和可积分的神经场，但也引入了对真实世界数据不一定有益的偏差。在这项工作中，我们（1）描述了这些架构对轴对准信号的不希望有的偏差——它们可能导致高达2 PSNR的辐射场重建差异——以及（2）探索了学习一组规范化变换如何通过消除这些偏差来改进表示。我们在二维模型问题中证明，同时学习这些变换和场景外观是成功的，效率大大提高。我们使用图像、符号距离和辐射场重建任务验证了最终的架构，我们称之为TILTED，在这些任务中，我们观察到了质量、稳健性、紧凑性和运行时间方面的改进。结果表明，TILTED可以实现比基线大2倍的能力，同时突出神经场评估程序的弱点。 et.al.|[2308.15461](http://arxiv.org/abs/2308.15461)|null|
|**2023-08-30**|**NSF: Neural Surface Fields for Human Modeling from Monocular Depth**|从单眼相机获得个性化的3D可动画化化身在游戏、虚拟试穿、动画和VR/XR等领域有几个现实世界的应用。然而，从这种稀疏的数据中建模动态和细粒度的服装变形是非常具有挑战性的。现有的从深度数据建模3D人类的方法在计算效率、网格一致性以及分辨率和拓扑结构的灵活性方面具有局限性。例如，使用隐式函数重建形状和每帧提取显式网格在计算上是昂贵的，并且不能确保跨帧的连贯网格。此外，在具有离散表面的预先设计的人类模板上预测每个顶点的变形在分辨率和拓扑结构上缺乏灵活性。为了克服这些局限性，我们提出了一种新的方法“关键特征：神经表面场”，用于从单目深度对穿着3D衣服的人类进行建模。NSF仅在基面上定义了一个神经场，该神经场对连续和灵活的位移场进行建模。NSF可以适应不同分辨率和拓扑结构的基面，而无需在推理时进行重新训练。与现有方法相比，我们的方法在保持网格一致性的同时消除了昂贵的每帧表面提取，并且能够在不重新训练的情况下重建任意分辨率的网格。为了促进这方面的研究，我们在项目页面上发布了我们的代码：https://yuxuan-xue.com/nsf. et.al.|[2308.14847](http://arxiv.org/abs/2308.14847)|null|
|**2023-08-28**|**A Transformer-Conditioned Neural Fields Pipeline with Polar Coordinate Representation for Astronomical Radio Interferometric Data Reconstruction**|在射电天文学中，能见度数据是对射电望远镜波信号的测量，被转换成图像，用于观测遥远的天体。然而，由于信号稀疏性和其他因素，这些结果图像通常包含真实源和伪影。获得更干净图像的一种方法是在成像之前将样本重建成致密的形式。不幸的是，现有的可见性重建方法可能会错过频率数据的一些分量，因此模糊的对象边缘和持久的伪影仍然存在于图像中。此外，由于数据偏斜，在不规则可见性样本上的计算开销很高。为了解决这些问题，我们提出了PolarRec，这是一种干涉能见度数据的重建方法，它由具有极坐标表示的变压器条件神经场管道组成。这种表示与望远镜在地球自转时观察天体区域的方式相匹配。我们进一步提出了径向频率损失函数，使用极坐标系中的径向坐标与频率信息进行关联，以帮助重建完整的可见性。我们还根据极坐标系中的角坐标对可见性采样点进行分组，并使用分组作为随后使用Transformer编码器进行编码的粒度。因此，我们的方法可以有效地捕捉可见性数据的固有特征。我们的实验表明，PolarRec通过忠实地重建可见性域中的所有频率分量，显著提高了成像结果，同时显著降低了计算成本。 et.al.|[2308.14610](http://arxiv.org/abs/2308.14610)|null|
|**2023-08-24**|**NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes**|最近的隐式神经表示在新的视图合成中显示出了很好的结果。然而，现有的方法需要从许多视图进行昂贵的每场景优化，因此限制了它们在真实世界的无边界城市环境中的应用，在这些环境中，从极少数视图观察到感兴趣的对象或背景。为了缓解这一挑战，我们引入了一种名为NeO360的新方法，用于户外场景稀疏视图合成的神经场。NeO 360是一种可推广的方法，它从单个或几个摆出姿势的RGB图像重建360｛\deg｝场景。我们方法的本质是捕捉复杂的真实世界户外3D场景的分布，并使用可以从任何世界点查询的混合图像条件三平面表示。我们的表示结合了基于体素和鸟瞰图（BEV）的最佳表示，比每种表示都更有效、更具表现力。NeO 360的表示使我们能够从大量无界3D场景中学习，同时在推理过程中从一张图像中提供对新视图和新场景的可推广性。我们在所提出的具有挑战性的360｛\deg｝无界数据集NeRDS 360上演示了我们的方法，并表明NeO 360在新视图合成方面优于最先进的可推广方法，同时还提供编辑和合成功能。项目页面：https://zubair-irshad.github.io/projects/neo360.html et.al.|[2308.12967](http://arxiv.org/abs/2308.12967)|**[link](https://github.com/zubair-irshad/NeO-360)**|
|**2023-08-23**|**Semantic-Aware Implicit Template Learning via Part Deformation Consistency**|学习隐式模板作为神经场最近在无监督形状对应方面表现出了令人印象深刻的性能。尽管取得了成功，但我们观察到，目前仅依赖几何信息的方法往往会在具有高结构可变性的通用物体形状中学习次优变形。在本文中，我们强调了零件变形一致性的重要性，并提出了一个语义感知的隐式模板学习框架，以实现语义上合理的变形。通过利用自监督特征提取器的语义先验，我们建议使用新的语义感知变形代码进行局部条件调节，并对零件变形、全局变形和全局缩放进行变形一致性正则化。我们的大量实验证明了所提出的方法在各种任务中优于基线：关键点转移、零件标签转移和纹理转移。更有趣的是，我们的框架在更具挑战性的环境下显示出更大的性能提升。我们还提供了定性分析来验证语义感知变形的有效性。代码可在https://github.com/mlvlab/PDC. et.al.|[2308.11916](http://arxiv.org/abs/2308.11916)|null|
|**2023-08-22**|**Approaching human 3D shape perception with neurally mappable models**|人类毫不费力地推断出物体的三维形状。这种能力的基础是什么计算？尽管已经提出了各种计算模型，但它们都没有捕捉到人类在不同视点之间匹配物体形状的能力。在这里，我们询问是否以及如何缩小这一差距。我们从一类相对新颖的计算模型3D神经场开始，它通过深度神经网络（DNN）中的合成封装了经典分析的基本原理。首先，我们发现3D光场网络（3D-LFN）支持与人类完全一致的3D匹配判断，用于类别内比较、强调标准DNN模型的3D失败情况的对抗性定义比较，以及用于无类别结构的算法生成形状的对抗性定义比较。然后，我们通过一系列计算实验研究了3D-LFN实现人类对齐性能的能力来源。在训练过程中暴露于物体的多个视角和多视角学习目标是模型-人对齐背后的主要因素；当使用多视图目标进行训练时，即使是传统的DNN架构也更接近人类行为。最后，我们发现，虽然用多视图学习目标训练的模型能够部分推广到新的对象类别，但它们不能达到人类的一致性。这项工作为理解可神经映射的计算架构中的人形推断提供了基础，并突出了未来工作的重要问题。 et.al.|[2308.11300](http://arxiv.org/abs/2308.11300)|null|
|**2023-08-21**|**Canonical Cortical Field Theories**|我们根据场论，使用放置在皮层表面2D晶格上的神经单元来表征神经元活动的动力学。分析神经元单元的电活动，目的是推导出一个具有简单功能形式的神经场模型，该模型仍然能够预测或重现经验发现。使用神经质量对每个神经单元进行建模，并在连续极限中导出伴随的场论。场论包括耦合的（真实的）克莱因-戈登场，其中模型的预测属于实验结果的范围。这些预测包括从皮层测量的电活动频谱，该频谱是使用能量对神经场本征函数的平分得出的。此外，神经场模型在一组参数内对用于建模每个神经元质量的动力学系统是不变的。具体而言，拓扑等效的动力学系统在连接到晶格中时产生相同的神经场模型；这表明所导出的场可以被解读为典型的皮层场论。我们专门研究了为传入信息的编码（或表示）提供结构的非分散场。进一步阐述随后的神经场理论，包括分散力的影响，对于理解皮层对信息的处理可能具有重要意义。 et.al.|[2308.10645](http://arxiv.org/abs/2308.10645)|null|
|**2023-08-14**|**S3IM: Stochastic Structural SIMilarity and Its Unreasonable Effectiveness for Neural Fields**|最近，神经辐射场（NeRF）通过学习仅使用姿态RGB图像的隐式表示，在渲染给定场景的新视图图像方面取得了巨大成功。NeRF和相关的神经场方法（例如，神经表面表示）通常优化逐点损失并进行逐点预测，其中一个数据点对应于一个像素。不幸的是，这一研究未能使用对远处像素的集体监督，尽管已知图像或场景中的像素可以提供丰富的结构信息。据我们所知，我们是第一个通过一种新的随机结构相似性（S3IM）损失为NeRF和相关神经场方法设计非局部多重训练范式的人，该损失将多个数据点作为一个整体处理，而不是独立处理多个输入。我们的大量实验证明了S3IM在几乎免费改进NeRF和神经表面表示方面的不合理有效性。质量度量的改进对于那些相对困难的任务可能特别显著：例如，TensoRF和DVGO在八个新的视图合成任务中的测试MSE损失意外下降了90%以上；在八个表面重建任务中，NeuS的198%F分数增益和64%的倒角$L_。此外，即使在稀疏输入、损坏图像和动态场景的情况下，S3IM也始终是稳健的。 et.al.|[2308.07032](http://arxiv.org/abs/2308.07032)|**[link](https://github.com/madaoer/s3im_nerf)**|
|**2023-08-11**|**Zero-shot Text-driven Physically Interpretable Face Editing**|本文提出了一种基于任意文本提示的人脸编辑新方法，该方法具有物理可解释性。与以前基于GAN反转的人脸编辑方法（操纵GAN的潜在空间）或基于扩散的方法（将图像操纵建模为反向扩散过程）不同，我们将人脸编辑过程视为在人脸图像上施加矢量流场，表示每个图像像素的空间坐标和颜色的偏移。在上述提出的范式下，我们用两种方式表示矢量流场：1）用光栅化张量显式表示流矢量，2）通过利用隐式神经表示的最新进展，将流矢量隐式参数化为连续、平滑和分辨率不可知的神经场。在预先训练的对比语言图像预训练（CLIP）模型的指导下，通过最大化编辑后的图像和文本提示之间的相关性，迭代优化流向量。我们还提出了一种基于学习的一次性人脸编辑框架，该框架快速且适用于任何文本提示输入。我们的方法还可以灵活地扩展到实时视频人脸编辑。与最先进的文本驱动的人脸编辑方法相比，我们的方法可以生成具有高身份一致性和图像质量的物理可解释的人脸编辑结果。我们的代码将公开。 et.al.|[2308.05976](http://arxiv.org/abs/2308.05976)|null|
|**2023-08-07**|**Explicifying Neural Implicit Fields for Efficient Dynamic Human Avatar Modeling via a Neural Explicit Surface**|本文提出了一种通过神经显式表面（NES）来解释隐式神经场来有效地建模动态人类的技术。在根据稀疏观测对动态3D内容进行建模以及有效地表示复杂的几何形状和外观方面，隐式神经场比传统的显式表示具有优势。然而，由于在体积渲染过程中需要密集采样，在3D空间中定义的隐式神经场的渲染成本很高。此外，当对稀疏3D空间进行建模时，可以进一步优化它们的存储效率。为了克服这些问题，本文提出利用神经显式曲面（NES）来显式表示隐式神经场，以提高记忆和计算效率。为了实现这一点，本文利用隐式和显式方法的优势，在NES的隐式神经场和显式渲染接口之间创建了一个完全可微分的转换。这种转换能够使用隐式方法有效地训练混合表示，并通过将显式渲染接口与新提出的基于光栅化的神经渲染器集成来实现高效渲染，该神经渲染器对于与显式表面的初始光线交互只产生一次纹理颜色查询，从而提高推理效率。NES在2D空间中描述了具有姿态相关神经隐式表面变形场的动态人体几何结构及其动态神经纹理，这是传统3D方法的一种更具记忆效率的替代方法，减少了冗余和计算负载。综合实验表明，NES的性能与以前的3D方法类似，大大提高了渲染速度，降低了内存成本。 et.al.|[2308.05112](http://arxiv.org/abs/2308.05112)|null|
|**2023-08-15**|**Neural Field Movement Primitives for Joint Modelling of Scenes and Motions**|本文提出了一种新的从演示中学习（LfD）方法，该方法使用神经场来高效准确地学习新技能。它通过利用共享嵌入以生成的方式学习场景和运动表示来实现这一点。我们的方法将每个专家演示平滑地映射到场景运动嵌入，并学习对它们进行建模，而不需要手工制作的任务参数或大型数据集。它通过强制场景和运动生成相对于嵌入空间的变化是平滑的来实现数据效率。在推理时，我们的方法可以使用测试时间优化来检索场景运动嵌入，并为新场景生成精确的运动轨迹。所提出的方法是通用的，可以使用图像、3D形状和任何其他可以使用神经场建模的场景表示。此外，它还可以生成末端效应器位置和基于关节角度的轨迹。我们的方法是在需要精确运动轨迹生成的任务上进行评估的，其中基本任务参数化是基于对象位置和几何场景变化的。实验结果表明，该方法优于基线方法，可推广到新的场景中。此外，在真实世界的实验中，我们表明我们的方法可以成功地对多值轨迹进行建模，它对推理时引入的干扰对象是鲁棒的，并且它可以生成6D运动。 et.al.|[2308.05040](http://arxiv.org/abs/2308.05040)|null|
|**2023-08-10**|**InstantAvatar: Efficient 3D Head Reconstruction via Surface Rendering**|通过可微分表面或体积渲染来优化神经场以表示单个场景，从而获得了全头部重建的最新进展。虽然这些技术达到了前所未有的精度，但由于需要昂贵的优化过程，它们需要几分钟甚至几个小时。在这项工作中，我们介绍了InstantAvatar，一种在商品硬件上几秒钟内从几张图像（减少到一张）中恢复全头头像的方法。为了加快重建过程，我们首次提出了一种将体素网格神经场表示与曲面渲染器相结合的系统。值得注意的是，这两种技术的天真组合会导致不稳定的优化，无法收敛到有效的解决方案。为了克服这一限制，我们提出了一种新的统计模型，该模型使用基于体素网格的架构来学习3D头部符号距离函数上的先验分布。该现有模型的使用，与其他设计选择相结合，形成了一个系统，该系统以与现有技术相当的精度实现3D头部重建，速度提高了100倍。 et.al.|[2308.04868](http://arxiv.org/abs/2308.04868)|null|
|**2023-08-07**|**DNFOMP: Dynamic Neural Field Optimal Motion Planner for Navigation of Autonomous Robots in Cluttered Environment**|动态变化环境中的运动规划是自动驾驶中最复杂的挑战之一。除了驾驶舒适性和速度限制外，安全性也是一项至关重要的要求。虽然经典的基于采样、基于网格和基于优化的规划方法可以生成平滑而短的路径，但它们通常不考虑环境的动力学。一些技术确实考虑了这一点，但它们依赖于在旅途中更新环境，而不是明确考虑动态，这不适合自动驾驶。为了解决这一问题，我们提出了一种基于神经场最优运动规划器（NFOMP）的新方法，该方法在归一化曲率和尖端数量方面优于最先进的方法。我们的方法将先前已知的移动障碍物嵌入到神经场碰撞模型中，以考虑环境的动力学。我们还通过在轨迹损失函数中添加拉格朗日乘子，引入了轨迹的时间剖面和非线性速度约束。我们使用BeamNG.tech驾驶模拟器，将我们的方法应用于解决城市环境中的最优运动规划问题。一辆自动驾驶汽车在三个城市场景中驾驶生成的轨迹，同时与障碍车共享道路。我们的评估表明，乘客能立即体验到的最大加速度为-7.5 m/s ^2，89.6%的驾驶时间用于加速度低于3.5 m/s ^2的正常驾驶。驾驶风格的特点是，轻轨交通风格和适度驾驶风格分别占驾驶时间的46.0%和31.4%。 et.al.|[2308.03539](http://arxiv.org/abs/2308.03539)|null|
|**2023-08-04**|**DTF-Net: Category-Level Pose Estimation and Shape Reconstruction via Deformable Template Field**|从RGB深度图像对估计开放世界场景中物体的6D姿态和重建物体的3D形状是具有挑战性的。许多现有的方法依赖于学习与特定模板相对应的几何特征，而忽略同一类别中对象之间的形状变化和姿态差异。因此，在复杂环境中处理看不见的对象实例时，这些方法表现不佳。相比之下，其他方法旨在通过利用归一化的几何结构先验来实现类别级别的估计和重建，但基于静态先验的重建难以应对大量的类内变化。为了解决这些问题，我们提出了DTF-Net，这是一种基于对象类别的隐式神经场的姿态估计和形状重建的新框架。在DTF-Net中，我们设计了一个可变形模板域来表示一般类别的形状潜在特征和类别内的几何变形特征。该字段建立连续的形状对应关系，将类别模板变形为任意观察到的实例，以完成形状重建。我们引入了一个姿态回归模块，该模块共享来自场的变形特征和模板代码，以估计场景中每个对象的精确6D姿态。我们集成了一个多模态表示提取模块来提取对象特征和语义掩码，从而实现端到端推理。此外，在训练过程中，我们实现了形状不变的训练策略和视点采样方法，以进一步增强模型提取物体姿态特征的能力。在REAL275和CAMERA25数据集上进行的大量实验证明了DTF-Net在合成场景和真实场景中的优越性。此外，我们还证明了DTF-Net可以有效地支持真实机械臂的抓取任务。 et.al.|[2308.02239](http://arxiv.org/abs/2308.02239)|null|
|**2023-08-03**|**NeuroSwarm: Multi-Agent Neural 3D Scene Reconstruction and Segmentation with UAV for Optimal Navigation of Quadruped Robot**|四足机器人具有独特的能力，可以调整自己的身体和步幅高度，在杂乱的环境中导航。尽管如此，这些机器人要想在现实世界中充分发挥其潜力，就需要了解其环境和障碍物的几何形状。我们提出了一种新的多智能体机器人系统，该系统融合了尖端技术。所提出的解决方案具有3D神经重建算法，该算法能够在静态和半静态环境中对四足机器人进行导航。环境的先前区域也根据四足机器人通过它们的能力进行分割。此外，我们还开发了一种自适应神经场最优运动规划器（ANFOMP），该规划器同时考虑了二维空间中的碰撞概率和障碍物高度。我们的新导航和映射方法使四足机器人能够调整自己的高度和行为，在拱门下导航，并穿过较小尺寸的障碍物。多智能体映射操作已被证明是高度准确的，障碍物重建精度为82%。此外，四足机器人可以利用3D障碍物信息和ANFOMP系统进行导航，从而使路径长度减少33.3%，导航时间减少70%。 et.al.|[2308.01725](http://arxiv.org/abs/2308.01725)|**[link](https://github.com/iana-zhura/neuroswarm)**|
|**2023-07-31**|**DiVA-360: The Dynamic Visuo-Audio Dataset for Immersive Neural Fields**|神经领域的进步使得能够高保真地捕捉静态和动态场景的形状和外观。然而，由于算法挑战和缺乏大规模的真实世界数据集，它们的能力落后于像素或网格等表示所提供的能力。我们用DiVA-360解决了数据集的局限性，DiVA-36是一个真实世界的360动态视觉音频数据集，具有关于表级场景的同步多模式视觉、音频和文本信息。它包含46个动态场景、30个静态场景和95个静态对象，跨越11个类别，使用一个新的硬件系统捕获，该系统使用53个120 FPS的RGB相机和6个麦克风，总共获得8.6M图像帧和1360 s的动态数据。我们提供了所有场景的详细文本描述、前景背景分割遮罩、静态对象的特定类别3D姿势对齐，以及用于比较的指标。我们的数据、硬件和软件以及代码可在https://diva360.github.io/. et.al.|[2307.16897](http://arxiv.org/abs/2307.16897)|null|
|**2023-07-25**|**INFINITY: Neural Field Modeling for Reynolds-Averaged Navier-Stokes Equations**|对于数值设计来说，开发高效准确的替代模型至关重要。它们使我们能够近似复杂的物理现象，从而减少直接数值模拟的计算负担。我们提出了INFINITY，这是一种利用隐式神经表征（INRs）来应对这一挑战的深度学习模型。我们的框架将几何信息和物理场编码为紧凑表示，并学习它们之间的映射来推断物理场。我们使用翼型设计优化问题作为示例任务，并在具有挑战性的AirfRANS数据集上评估我们的方法，该数据集与现实世界的工业用例非常相似。实验结果表明，我们的框架通过准确推断整个体积和表面的物理场，实现了最先进的性能。此外，我们还证明了它在设计探索和形状优化等环境中的适用性：我们的模型可以在遵守方程的同时正确预测阻力和升力系数。 et.al.|[2307.13538](http://arxiv.org/abs/2307.13538)|null|
|**2023-08-24**|**Strivec: Sparse Tri-Vector Radiance Fields**|我们提出了Strivec，这是一种新的神经表示，它将3D场景建模为具有稀疏分布和紧凑因子分解的局部张量特征网格的辐射场。在最近的工作TensoRF之后，我们的方法利用张量分解来对张量网格进行建模。与使用全局张量并专注于向量矩阵分解的TensoRF不同，我们建议使用局部张量云，并应用经典的CANDECOMP/PARAFAC（CP）分解将每个张量分解为三个向量，这些向量表示沿空间轴的局部特征分布，并对局部神经场进行紧凑编码。我们还应用多尺度张量网格来发现几何和外观的共性，并在多个局部尺度上利用三向量分解来利用空间相干性。通过聚集来自所有尺度上的多个局部张量的神经特征来回归最终的辐射场特性。我们的三向量张量稀疏地分布在实际场景表面周围，这是通过利用3D场景的稀疏性进行快速粗略重建发现的。我们证明，我们的模型可以实现更好的渲染质量，同时使用比以前的方法（包括TensoRF和Instant NGP）更少的参数。 et.al.|[2307.13226](http://arxiv.org/abs/2307.13226)|**[link](https://github.com/zerg-overmind/strivec)**|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

