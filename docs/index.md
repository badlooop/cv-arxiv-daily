---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.09.12
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-11**|**FlowIBR: Leveraging Pre-Training for Efficient Neural Image-Based Rendering of Dynamic Scenes**|我们介绍了一种用于动态场景的单目新颖视图合成的新方法。现有技术已经显示出令人印象深刻的渲染质量，但倾向于在不利用先验知识的情况下专注于单个场景内的优化。这种限制主要归因于缺乏可用于训练的动态场景数据集以及场景动力学的多样性。我们的方法FlowIBR通过集成基于神经图像的渲染方法来规避这些问题，该方法在广泛可用的静态场景的大型语料库上进行了预训练，并具有每个场景优化的场景流场。利用该流场，我们弯曲摄影机光线以抵消场景动力学，从而将动态场景呈现为渲染网络的静态场景。所提出的方法将每个场景的优化时间减少了一个数量级，实现了与现有方法相当的结果——所有这些都在单个消费级GPU上。 et.al.|[2309.05418](http://arxiv.org/abs/2309.05418)|null|
|**2023-09-11**|**Towards Viewpoint Robustness in Bird's Eye View Segmentation**|自动驾驶汽车（AV）要求用于感知的神经网络对不同的视点具有鲁棒性，如果它们要部署在许多类型的车辆上，而不需要为每种车辆重复数据收集和标记的成本。AV公司通常专注于从不同的场景和地点收集数据，但由于成本原因，不关注摄像机设备配置。因此，大多数震源组中只存在少量的钻机变体。在本文中，我们研究了AV感知模型如何受到摄像机视点变化的影响，并提出了一种在不重复数据收集和标记的情况下跨车辆类型缩放它们的方法。使用鸟瞰图（BEV）分割作为一项激励任务，我们通过大量实验发现，现有的感知模型对相机视点的变化非常敏感。当使用来自一个相机装备的数据进行训练时，在推断时相机的俯仰、偏航、深度或高度的微小变化会导致性能大幅下降。我们引入了一种新的视图合成技术，并使用它将收集的数据转换为目标钻机的视点，使我们能够为不同的目标钻机训练BEV分割模型，而无需任何额外的数据收集或标记成本。为了分析观点变化的影响，我们利用合成数据来缓解其他差距（内容、ISP等）。然后，我们的方法在真实数据上进行训练，并在合成数据上进行评估，从而能够对不同的目标钻机进行评估。我们发布所有数据以供未来工作使用。我们的方法能够回收部署到新钻机时损失的IoU的平均14.7%。 et.al.|[2309.05192](http://arxiv.org/abs/2309.05192)|null|
|**2023-09-10**|**SC-NeRF: Self-Correcting Neural Radiance Field with Sparse Views**|在最近的研究中，神经辐射场的泛化在新的视图合成任务中得到了广泛的探索。然而，现有的方法仅限于对象和室内场景。在这项工作中，我们将泛化任务扩展到户外场景，仅在对象级数据集上进行训练。这种方法提出了两个挑战。首先，训练和测试场景之间的显著分布变化导致渲染结果中出现黑色伪影。其次，室外场景中的视点变化会导致渲染图像中出现重影或区域丢失。为了应对这些挑战，我们提出了一个基于多头注意力机制的几何校正模块和外观校正模块。我们将渲染深度标准化，并将其与光方向组合，作为注意力机制中的查询。我们的网络有效地纠正了户外场景中不同的场景结构和几何特征，从物体层面很好地推广到看不见的户外场景。此外，我们使用外观校正模块来校正外观特征，防止由于视点更改而导致的渲染伪影，如空白边界和重影。通过结合这些模块，我们的方法成功地解决了户外场景泛化的挑战，产生了高质量的渲染结果。当在四个数据集（Blender、DTU、LLFF、Spaces）上进行评估时，我们的网络优于以前的方法。值得注意的是，与MVSNeRF相比，我们的网络将Spaces户外场景的平均PSNR从19.369提高到25.989，SSIM从0.838提高到0.889，并将LPIPS从0.265降低到0.224。 et.al.|[2309.05028](http://arxiv.org/abs/2309.05028)|null|
|**2023-09-07**|**SimpleNeRF: Regularizing Sparse Input Neural Radiance Fields with Simpler Solutions**|神经辐射场（NeRF）在场景的真实感自由视图渲染中表现出令人印象深刻的性能。然而，NeRF需要对给定场景中的图像进行密集采样，并且当只有稀疏的视图集可用时，其性能会显著下降。研究人员发现，监督NeRF估计的深度有助于用更少的视图有效地训练它。深度监督是使用经典方法或在大型数据集上预先训练的神经网络来获得的。前者可能只提供稀疏的监督，而后者可能存在泛化问题。与早期的方法不同，我们试图通过设计增强模型并将其与NeRF一起训练来学习深度监督。我们设计了增强模型，通过探索位置编码和视图相关辐射在训练少镜头NeRF中的作用，鼓励更简单的解决方案。由这些更简单的模型估计的深度用于监督NeRF深度估计。由于增强模型在某些区域可能不准确，我们设计了一种机制，只选择可靠的深度估计进行监督。最后，我们在NeRF的粗糙和精细多层感知器之间添加了一致性损失，以确保更好地利用分层采样。通过采用上述正则化，我们在两个流行的数据集上实现了最先进的视图合成性能。我们模型的源代码可以在我们的项目页面上找到：https://nagabhushansn95.github.io/publications/2023/SimpleNeRF.html et.al.|[2309.03955](http://arxiv.org/abs/2309.03955)|null|
|**2023-09-07**|**BluNF: Blueprint Neural Field**|神经辐射场（NeRF）彻底改变了场景新颖的视图合成，提供了视觉逼真、精确和稳健的隐式重建。虽然最近的方法允许NeRF编辑，例如对象删除、3D形状修改或材料特性操纵，但在这种编辑之前的手动注释使该过程变得乏味。此外，传统的2D交互工具缺乏对3D空间的准确感知，阻碍了对场景的精确操作和编辑。在本文中，我们介绍了一种新的方法，称为蓝图神经场（BluNF），以解决这些编辑问题。BluNF提供了一个强大且用户友好的2D蓝图，实现了直观的场景编辑。通过利用隐式神经表示，BluNF使用先前的语义和深度信息构建场景的蓝图。生成的蓝图可以轻松编辑和操作NeRF表示。我们通过直观的点击和更改机制展示了BluNF的可编辑性，实现了3D操作，如遮罩、外观修改和对象移除。我们的方法对视觉内容创作做出了重大贡献，为该领域的进一步研究铺平了道路。 et.al.|[2309.03933](http://arxiv.org/abs/2309.03933)|null|
|**2023-09-07**|**SyncDreamer: Generating Multiview-consistent Images from a Single-view Image**|在本文中，我们提出了一种新的扩散模型，称为，从单视图图像生成多视图一致图像。最近的工作Zero123使用预先训练的大规模2D扩散模型，展示了从物体的单视图图像生成看似新颖的视图的能力。然而，为生成的图像保持几何图形和颜色的一致性仍然是一个挑战。为了解决这个问题，我们提出了一种同步多视点扩散模型，该模型对多视点图像的联合概率分布进行建模，从而能够在单个反向过程中生成多视点一致图像。SyncDreamer通过3D感知特征注意力机制在反向过程的每一步同步所有生成图像的中间状态，该机制将不同视图中的相应特征关联起来。实验表明，SyncDreamer生成的图像在不同视图之间具有高度一致性，因此非常适合各种3D生成任务，如新颖的视图合成、文本到3D和图像到3D。 et.al.|[2309.03453](http://arxiv.org/abs/2309.03453)|null|
|**2023-09-06**|**Bayes' Rays: Uncertainty Quantification for Neural Radiance Fields**|神经辐射场（NeRF）在视图合成和深度估计等应用中显示出了前景，但从多视图图像中学习面临着固有的不确定性。目前量化它们的方法要么是启发式的，要么是计算要求很高的。我们引入了BayesRays，这是一个事后框架，用于在不修改训练过程的情况下评估任何预先训练的NeRF中的不确定性。我们的方法使用空间扰动和贝叶斯拉普拉斯近似来建立体积不确定性场。我们从统计角度推导了我们的算法，并在关键指标和应用中展示了其卓越的性能。其他结果可在：https://bayesrays.github.io. et.al.|[2309.03185](http://arxiv.org/abs/2309.03185)|null|
|**2023-09-05**|**TiAVox: Time-aware Attenuation Voxels for Sparse-view 4D DSA Reconstruction**|四维数字减影血管造影（4D DSA）在许多医学疾病的诊断中起着至关重要的作用，如动静脉畸形（AVM）和动静脉瘘（AVF）。尽管4D DSA的重建具有重要的应用价值，但它需要大量的视图来有效地模拟复杂的血管和放射造影流，从而意味着显著的辐射剂量。为了解决这个高辐射问题，我们提出了一种用于稀疏视图4D DSA重建的时间感知衰减体素（TiAVox）方法，为高质量的4D成像铺平了道路。此外，可以从重建的4D DSA图像生成2D和3D DSA成像结果。TiAVox引入了4D衰减体素网格，从空间和时间维度反映衰减特性。它通过最小化渲染图像和稀疏2D DSA图像之间的差异来进行优化。在没有任何神经网络参与的情况下，TiAVox享有特定的物理可解释性。每个可学习体素的参数表示衰减系数。我们在临床和模拟数据集上验证了TiAVox方法，在临床来源的数据集上仅使用30个视图，就实现了31.23的新视图合成峰值信噪比（PSNR），而传统的Feldkamp-Davis-Kress方法需要133个视图。类似地，在合成数据集中只有10个视图的情况下，TiAVox对于新视图合成产生了34.32的PSNR，对于3D重建产生了41.40的PSNR。我们还进行了消融研究，以证实TiAVox的主要成分。该代码将公开提供。 et.al.|[2309.02318](http://arxiv.org/abs/2309.02318)|null|
|**2023-09-06**|**Instant Continual Learning of Neural Radiance Fields**|神经辐射场（NeRFs）已成为一种有效的视图合成和三维场景重建方法。然而，传统的训练方法需要在场景优化期间访问所有训练视图。在连续学习场景中，这种假设可能是禁止的，在这种场景中，以顺序的方式获取新数据，并且需要NeRF的连续更新，如在汽车或遥感应用中。当在这样一个持续的环境中天真地训练时，传统的场景表示框架会遭受灾难性的遗忘，在对新数据进行训练后，先前学习的知识会被破坏。先前使用NeRF缓解遗忘的工作存在重建质量低和延迟高的问题，这使得它们在现实世界中的应用不切实际。我们提出了一个用于训练NeRF的持续学习框架，该框架利用了基于回放的方法与显-隐混合场景表示相结合。当在连续环境中训练时，我们的方法在重建质量方面优于以前的方法，同时具有更快一个数量级的额外好处。 et.al.|[2309.01811](http://arxiv.org/abs/2309.01811)|null|
|**2023-09-04**|**EMR-MSF: Self-Supervised Recurrent Monocular Scene Flow Exploiting Ego-Motion Rigidity**|自监督单目场景流估计旨在从两个时间连续的单目图像中理解3D结构和3D运动，由于其简单经济的传感器设置而受到越来越多的关注。然而，当前方法的准确性受到网络架构效率较低和缺乏正则化运动刚度的瓶颈的影响。在本文中，我们借鉴了监督学习范围下网络架构设计的优势，提出了一个名为EMR-MSF的高级模型。我们通过精心构建的自我运动聚合模块进一步施加了显式和鲁棒的几何约束，其中提出了刚性软掩模来过滤动态区域，以便使用静态区域进行稳定的自我运动估计。此外，我们提出了运动一致性损失和掩码正则化损失，以充分利用静态区域。集成了几种有效的训练策略，包括梯度分离技术和增强的视图合成过程，以获得更好的表现。我们提出的方法在很大程度上优于以前的自监督工作，并赶上了监督方法的性能。在KITTI场景流基准上，我们的方法将最先进的自监督单目方法的SF all指标提高了44%，并在包括深度和视觉里程计在内的子任务以及其他自监督单任务或多任务方法中表现出优异的性能。 et.al.|[2309.01296](http://arxiv.org/abs/2309.01296)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-11**|**A survey on real-time 3D scene reconstruction with SLAM methods in embedded systems**|同时定位和映射（SLAM）的3D重建是无人机、服务机器人和移动AR/VR设备等运输系统领域的一个重要课题。与点云表示相比，基于网格和体素的3D重建对于高级功能特别有用，如避障或与物理环境的交互。本文介绍了在资源受限的硬件平台上实现基于视觉的三维场景重建流水线。实时性能、内存管理和低功耗对嵌入式系统至关重要。描述了从传感器到3D重建的传统SLAM管道，包括深度学习的潜在用途。详细介绍了在资源有限的情况下执行高级功能的情况。最近的系统提出了具有不同粒度的3D重建方法的嵌入式实现。实时定位和重建所需的精度和资源消耗之间的权衡是本文确定和讨论的开放研究问题之一。 et.al.|[2309.05349](http://arxiv.org/abs/2309.05349)|null|
|**2023-09-09**|**Cryo-Electron Ptychography: Applications and Potential in Biological Characterisation**|显然需要发展表征技术，提供生物学中结构-功能关系的详细信息。使用电子显微镜在保持宽视场的同时实现高分辨率仍然是一个挑战，特别是对于辐射敏感样品，其中保持结构完整性所需的信噪比受到低电子注量的限制。在这篇综述中，我们探索了低温电子ptychography作为一种在低通量条件下表征生物系统的替代方法的潜力。使用这种方法，增加了来自多个感兴趣采样区域的信息含量，有可能使用比传统冷冻电子显微镜所需更少的粒子进行3D重建。这对于难以获得均匀单粒子分布的系统实现更高的分辨率是重要的。我们讨论了这种方法在单粒子分析和异构大型物体应用中的进展、局限性和未来发展的潜在领域。 et.al.|[2309.04881](http://arxiv.org/abs/2309.04881)|null|
|**2023-09-07**|**A Food Package Recognition and Sorting System Based on Structured Light and Deep Learning**|基于视觉算法的机械臂抓取系统是一种可以应用于各种场景的机械臂系统。它使用算法自动识别目标的位置，并引导机械臂抓取目标，这比可教的机械臂抓取系统具有更灵活的特点。然而，对于一些食品包装来说，其透明包装或反射材料给视觉算法的识别带来了挑战，传统的视觉算法无法实现这些包装的高精度。此外，在机械臂抓取过程中，在z轴高度上的定位仍然需要手动设置参数，这可能会导致错误。基于上述两个问题，我们使用深度学习算法和结构光三维重建技术设计了一个食品包装分拣系统。使用预先训练好的MASK-R-CNN模型识别图像中物体的类别并获得其二维坐标，然后使用结构光三维重建技术计算其三维坐标，最后经过坐标系转换来引导机械臂进行抓取。经过测试表明，该方法可以实现对不同种类食品包装的全自动识别和抓取，具有较高的精度。使用这种方法，可以帮助食品制造商降低生产成本，提高生产效率。 et.al.|[2309.03704](http://arxiv.org/abs/2309.03704)|null|
|**2023-09-06**|**SADIR: Shape-Aware Diffusion Models for 3D Image Reconstruction**|从有限数量的2D图像重建3D图像一直是计算机视觉和图像分析中的一个长期挑战。虽然基于深度学习的方法在这一领域取得了令人印象深刻的性能，但现有的深度网络往往无法有效利用图像中呈现的对象的形状结构。因此，重建对象的拓扑结构可能无法很好地保存，导致不同部分之间存在诸如不连续性、孔洞或不匹配连接之类的伪影。在本文中，我们提出了一种基于扩散模型的三维图像重建形状感知网络，称为SADIR，以解决这些问题。与之前主要依赖图像强度的空间相关性进行3D重建的方法不同，我们的模型利用从训练数据中学习的形状先验来指导重建过程。为了实现这一点，我们开发了一个联合学习网络，该网络可以同时学习变形模型下的平均形状。然后，每个重建的图像被认为是平均形状的变形变体。我们在大脑和心脏磁共振成像（MRI）上验证了我们的模型SADIR。实验结果表明，我们的方法优于基线，具有更低的重建误差和更好地保留图像中物体的形状结构。 et.al.|[2309.03335](http://arxiv.org/abs/2309.03335)|null|
|**2023-09-06**|**Sparse 3D Reconstruction via Object-Centric Ray Sampling**|我们提出了一种新的方法，用于从360度校准的摄像机设备捕获的稀疏视图集重建3D对象。我们通过使用基于MLP的神经表示和三角形网格的混合模型来表示物体表面。我们工作中的一个关键贡献是一种新的以对象为中心的神经表示采样方案，其中光线在所有视图中共享。这有效地集中并减少了在每次迭代时用于更新神经模型的样本数量。此采样方案依赖于网格表示，以确保样本沿其法线良好分布。然后通过可微分渲染器有效地执行渲染。我们证明，这种采样方案可以更有效地训练神经表示，不需要对分割掩模进行额外监督，可以进行最先进的3D重建，并且可以在谷歌的扫描对象、坦克和寺庙以及MVMC汽车数据集上使用稀疏视图。 et.al.|[2309.03008](http://arxiv.org/abs/2309.03008)|null|
|**2023-09-06**|**Multi-log grasping using reinforcement learning and virtual visual servoing**|我们探索了使用强化学习和虚拟视觉伺服进行自动转发的多日志抓取。森林过程的自动化是一个重大挑战，由于非结构化和恶劣的户外环境，许多关于机器人控制的技术带来了不同的挑战。抓取多个原木涉及动力学和路径规划问题，其中抓斗、原木、地形和障碍物之间的交互需要视觉信息。为了解决这些挑战，我们将图像分割与起重机控制分离，并利用虚拟相机从3D重建数据中提供图像流。我们使用笛卡尔控制来简化域转移。由于原木桩是静态的，使用桩及其周围环境的3D重建进行视觉伺服相当于使用真实的相机数据直到抓取点。这放宽了图像分割挑战的计算资源和时间限制，并允许在原木堆未被遮挡的情况下收集数据。缺点是在抓取过程中缺乏信息。我们证明了这个问题是可以控制的，并且提供了一种代理，该代理在从具有挑战性的2-5根原木堆中挑选一根或几根原木时成功率为95%。 et.al.|[2309.02997](http://arxiv.org/abs/2309.02997)|null|
|**2023-09-06**|**Designing Situated Dashboards: Challenges and Opportunities**|情境可视化是一个新兴领域，它将可视化、增强现实、人机交互和物联网等多个领域结合在一起，以支持无处不在的世界中的人类数据活动。同样，仪表板广泛用于通过多个视图简化复杂数据。然而，仪表板仅适用于桌面设置，并且需要视觉策略来支持情境性。我们提出了基于AR的定位仪表盘的概念，并介绍了在与专家的访谈中提出的设计考虑因素和挑战。这些挑战旨在为促进定位仪表板的有效设计和创作提供方向和机会。 et.al.|[2309.02945](http://arxiv.org/abs/2309.02945)|null|
|**2023-09-06**|**LightNeuS: Neural Surface Reconstruction in Endoscopy using Illumination Decline**|我们提出了一种从单目内窥镜获取的图像序列进行3D重建的新方法。它基于两个关键的见解。首先，腔内腔是不透水的，这一特性是通过用符号距离函数对其进行建模而自然实现的。其次，场景照明是可变的。它来自内窥镜的光源，并随着与表面距离平方的倒数而衰减。为了利用这些见解，我们建立在NeuS之上，NeuS是一种神经隐式表面重建技术，具有从多个视图学习外观和SDF表面模型的卓越能力，但目前仅限于具有静态照明的场景。为了消除这一限制并利用像素亮度和深度之间的关系，我们修改了NeuS架构以明确说明这一点，并引入了内窥镜相机和光源的校准光度模型。我们的方法是第一个产生完整结肠切片的防水重建。我们在幻影图像上展示了卓越的准确性。值得注意的是，防水先验与光照下降相结合，可以以可接受的精度完成表面看不见部分的重建，为癌症筛查探索的自动质量评估铺平道路，测量观察到的粘膜的全球百分比。 et.al.|[2309.02777](http://arxiv.org/abs/2309.02777)|null|
|**2023-09-05**|**GO-SLAM: Global Optimization for Consistent 3D Instant Reconstruction**|最近，神经隐式表示在密集同时定位和映射（SLAM）方面取得了令人信服的结果，但在相机跟踪和重建中存在误差积累和失真。有目的地，我们提出了GO-SLAM，这是一种基于深度学习的密集视觉SLAM框架，用于实时全局优化姿态和三维重建。鲁棒姿态估计是其核心，由有效的闭环和在线全束调整支持，通过利用输入帧完整历史的学习全局几何来优化每帧。同时，我们动态更新隐式和连续曲面表示，以确保三维重建的全局一致性。在各种合成和真实世界数据集上的结果表明，GO-SLAM在跟踪鲁棒性和重建精度方面优于最先进的方法。此外，GO-SLAM是通用的，可以与单眼、立体声和RGB-D输入一起运行。 et.al.|[2309.02436](http://arxiv.org/abs/2309.02436)|**[link](https://github.com/youmi-zym/go-slam)**|
|**2023-09-05**|**Doppelgangers: Learning to Disambiguate Images of Similar Structures**|我们考虑的视觉消歧任务是确定一对视觉相似的图像是否描绘了相同或不同的3D表面（例如，对称建筑的相同或相反侧）。两张图像观察到不同但在视觉上相似的3D表面，这对人类来说可能很难区分，也可能导致3D重建算法产生错误的结果。我们提出了一种基于学习的视觉消歧方法，将其表述为图像对的二元分类任务。为此，我们为这个问题引入了一个新的数据集，即Doppelgangers，它包括具有基本事实标签的相似结构的图像对。我们还设计了一种网络架构，将局部关键点和匹配的空间分布作为输入，从而能够更好地对局部和全局线索进行推理。我们的评估表明，我们的方法可以在困难的情况下区分虚幻的匹配，并可以集成到SfM管道中，以产生正确的、消除歧义的3D重建。有关我们的代码、数据集和更多结果，请参阅我们的项目页面：http://doppelgangers-3d.github.io/. et.al.|[2309.02420](http://arxiv.org/abs/2309.02420)|**[link](https://github.com/RuojinCai/Doppelgangers)**|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-11**|**Diffusion-Guided Reconstruction of Everyday Hand-Object Interaction Clips**|我们处理的任务是从短视频剪辑中重建手与物体的互动。给定输入视频，我们的方法将3D推理作为每视频优化，并恢复对象形状的神经3D表示，以及时变运动和手关节。虽然输入视频自然地提供了一些多视图提示来指导3D推断，但由于遮挡和有限的视点变化，这些提示本身是不够的。为了获得精确的3D，我们用通用的数据驱动先验来增强多视图信号，以指导重建。具体来说，我们学习了一个扩散网络来对基于手部配置和类别标签的对象的（几何）渲染的条件分布进行建模，并将其作为先验来指导重建场景的新视图渲染。我们在6个对象类别中对我们的以自我为中心的视频方法进行了实证评估，并观察到与之前的单视图和多视图方法相比有了显著改进。最后，我们展示了我们的系统从YouTube上重建任意片段的能力，显示了第一人称和第三人称的互动。 et.al.|[2309.05663](http://arxiv.org/abs/2309.05663)|null|
|**2023-09-11**|**Anisotropic Diffusion Stencils: From Simple Derivations over Stability Estimates to ResNet Implementations**|具有扩散张量的各向异性扩散过程在图像分析、物理和工程中都很重要。然而，它们的数值近似对耗散伪像和旋转不变性的偏差有很大影响。在这项工作中，我们研究了一大类在3 x 3模板上的有限差分离散化。我们通过将二维各向异性扩散分解为四个一维扩散来推导它。生成的模具类包含一个自由参数，并涵盖了广泛的现有离散化。它包括Weickert等人（2013）的完整模板家族，并表明它们的两个参数包含冗余。此外，我们在对应于模板的矩阵的谱范数上建立了一个界。这给出了时间步长限制，保证了欧几里得范数中显式方案的稳定性。我们的定向拆分还允许将显式方案非常自然地转换为ResNet块。使用神经网络库可以在GPU上实现简单高效的并行实现。 et.al.|[2309.05575](http://arxiv.org/abs/2309.05575)|null|
|**2023-09-11**|**PAI-Diffusion: Constructing and Serving a Family of Open Chinese Diffusion Models for Text-to-image Synthesis on the Cloud**|汉语的文本到图像合成由于其庞大的词汇量和复杂的字符关系而带来了独特的挑战。虽然现有的扩散模型在从文本描述生成图像方面显示出了前景，但它们往往忽略了特定领域的上下文，在处理汉语时缺乏稳健性。本文介绍了PAI Diffusion，一个解决这些局限性的综合框架。PAI-Diffusion结合了通用和特定领域的中文扩散模型，能够生成与上下文相关的图像。它探索了使用LoRA和ControlNet进行细粒度图像风格转换和图像编辑的潜力，使用户能够增强对图像生成的控制。此外，PAI Diffusion与阿里云的人工智能机器学习平台无缝集成，提供可访问和可扩展的解决方案。所有的中国扩散模型检查点、LoRA和ControlNets，包括特定领域的检查点，都是公开的。用户友好的中文WebUI和diffusers-api弹性推理工具包也是开源的，进一步促进了PAI Diffusion模型在各种环境中的轻松部署，使其成为中文文本到图像合成的宝贵资源。 et.al.|[2309.05534](http://arxiv.org/abs/2309.05534)|null|
|**2023-09-11**|**NExT-GPT: Any-to-Any Multimodal LLM**|尽管最近多模式大型语言模型（MM-LLM）取得了令人兴奋的进展，但它们大多受制于仅输入端多模式理解的限制，而无法以多种模式生成内容。由于我们人类总是通过各种方式感知世界并与人交流，开发能够以任何方式接受和传递内容的任意对任意MM-LM对人类级人工智能至关重要。为了填补这一空白，我们提出了一个端到端通用任意对任意MM-LLM系统，即NExT GPT。我们将LLM与多模式适配器和不同的扩散解码器连接起来，使NExT GPT能够感知文本、图像、视频和音频的任意组合中的输入并生成输出。通过利用现有训练有素的高性能编码器和解码器，NExT GPT只使用某些投影层的少量参数（1%）进行调整，这不仅有利于低成本的训练，还有利于方便地扩展到更潜在的模式。此外，我们引入了模态切换指令调整（MosIT），并为MosIT手动策划了一个高质量的数据集，在此基础上，NExT GPT能够进行复杂的跨模态语义理解和内容生成。总的来说，我们的研究展示了构建一种能够建模通用模式的人工智能代理的前景，为社区中更多类似人类的人工智能研究铺平了道路。 et.al.|[2309.05519](http://arxiv.org/abs/2309.05519)|null|
|**2023-09-11**|**Median Surface Brightness Profiles of Lyman- $α$ Haloes in the MUSE Extremely Deep Field**|我们通过在MUSE极深场（MXDF）中堆叠155个光谱确认的Ly$\alpha$发射器（LAE），给出了恒星形成星系周围弥漫Ly$\aalpha$光晕（LAHs）的中位表面亮度分布，其中Ly$\albha$亮度中位约为10^｛41.1｝erg\，s^｛-1｝｝$。在校正了我们在数据立方体中识别的系统表面亮度偏移后，我们检测到延伸到270 kpc距离的Ly$\alpha$发射。Ly$\alpha$表面亮度分布中值在内部20kpc处显示出幂律下降，并且在较大距离处可能呈现平坦趋势。对于具有不同Ly$\alpha$亮度的LAE，这种形状是相似的，但表面亮度分布的归一化随着亮度的增加而增加。在大于50kpc的距离处，我们观察到相邻LAH的强烈重叠，并且Ly$\alpha$表面亮度由附近LAE的LAH主导。当与4<z<5和5<z<6的样本进行比较时，我们没有发现观察到的Ly$\alpha$ 剖面红移演化的明确证据。我们的结果与这样一种情况一致，即LAH的内部20kpc由中心星系的恒星形成提供动力，而半径50kpc以外的LAH由周围星系的光子主导。 et.al.|[2309.05513](http://arxiv.org/abs/2309.05513)|null|
|**2023-09-11**|**Diffusion-Based Co-Speech Gesture Generation Using Joint Text and Audio Representation**|本文描述了为GENEA（化身代理的非言语行为的生成和评估）挑战2023开发的系统。我们的解决方案建立在现有的基于扩散的运动合成模型之上。我们提出了一个对比语音和运动预训练（CSMP）模块，该模块学习语音和手势的联合嵌入，目的是学习这些模态之间的语义耦合。CSMP模块的输出被用作基于扩散的手势合成模型中的条件信号，以便实现语义感知的协同语音手势生成。在提交的参赛作品中，我们的参赛作品获得了最高的人像和最高的言语得体度。这表明，我们的系统是一种很有前途的方法，可以在具有语义的代理中实现类人的协同语音手势。 et.al.|[2309.05455](http://arxiv.org/abs/2309.05455)|null|
|**2023-09-11**|**Treatment-aware Diffusion Probabilistic Model for Longitudinal MRI Generation and Diffuse Glioma Growth Prediction**|弥漫性胶质瘤是一种在大脑中广泛生长的恶性脑肿瘤。肿瘤细胞和正常组织之间复杂的相互作用，以及经常遇到的治疗诱导的变化，使神经胶质瘤肿瘤生长建模具有挑战性。在这篇论文中，我们提出了一种新的端到端网络，它能够生成未来的肿瘤掩模，以及不同治疗计划下肿瘤在未来任何时间点的真实MRI。我们的模型建立在前沿的扩散概率模型和深度分割神经网络之上。我们扩展了扩散模型，将连续的多参数MRI和治疗信息作为条件输入，以指导生成扩散过程。这使我们能够估计任何给定时间点的肿瘤生长。我们使用真实世界的术后纵向MRI数据训练模型，其中神经胶质瘤肿瘤生长轨迹表示为随时间变化的肿瘤分割图。该模型在一系列任务中表现出了良好的性能，包括用肿瘤掩模生成高质量的合成MRI、时间序列肿瘤分割和不确定性估计。结合治疗意识生成的MRI，具有不确定性估计的肿瘤生长预测可以为临床决策提供有用的信息。 et.al.|[2309.05406](http://arxiv.org/abs/2309.05406)|null|
|**2023-09-11**|**Anomalous Hall effect in ultraclean electronic channels**|我们发展了具有二维电子气的超清洁通道中的反常霍尔效应理论。在超清洁系统中，由于静态无序和声子引起的电子平均自由程被认为比沟道宽度大得多。电子动量弛豫和电导率主要由通道边缘的扩散散射和电子-电子碰撞决定，这使得电子的磁输运非常不平凡。反常的霍尔电场和霍尔电压是由于电子的偏斜散射、侧跳和由于自旋-轨道耦合而出现的反常速度效应而产生的。我们研究了弹道和流体动力学传输机制，这些机制取决于电子-电子平均自由程和通道宽度之间的关系。导出了反常霍尔场和电压的紧致解析表达式。我们证明，在弹道和流体动力学状态下，由于杂质或声子，通道主体中的电子动量弛豫是反常霍尔效应所必需的，而正常霍尔效应和电导率是由于电子-电子碰撞和通道边缘散射处的动量弛豫而出现的。 et.al.|[2309.05401](http://arxiv.org/abs/2309.05401)|null|
|**2023-09-11**|**Large time behaviour of the 2D thermally non-diffusive Boussinesq equations with Navier-slip boundary conditions**|本文的目的是用Lipschitz连续二阶导数研究有界域中没有热扩散和Navier滑移边界条件的浮力驱动流体的大时间波动。在证明了经典解的全局适定性和正则性之后，我们研究了它们的大时间渐近性。具体地，我们证明，在适当的规范中，解收敛于流体静力平衡。此外，当温度是高度的增加仿射函数时，即温度是垂直稳定分层时，我们证明了流体静力平衡的线性稳定性。这项工作的灵感来自[Doe+18]中关于自由滑动边界条件的结果。 et.al.|[2309.05400](http://arxiv.org/abs/2309.05400)|null|
|**2023-09-11**|**Influence of protostellar outflows on star and protoplanetary disk formation in a massive star-forming clump**|上下文由于磁场的存在，原恒星喷流或外流是吸积到原恒星上的自然结果。预计它们将在恒星和原行星盘的形成中发挥重要作用。目标。我们的目的是确定恒星形成团中外流对恒星和原行星盘形成的影响。方法。使用RAMSES，我们首次对具有双极扩散、辐射传输（包括原恒星的辐射反馈和原恒星外流）的大质量恒星形成团块进行了磁流体动力学计算，同时系统地解析了圆盘尺度。我们将其与没有资金外流的模型进行比较。后果我们发现原恒星外流对恒星和圆盘的形成都有重大影响。它们为星团提供了额外的湍流和磁性支持，典型的速度为10公里/秒，影响了星盘温度，并降低了原恒星的吸积率。虽然它们促进了更多的恒星种群，但我们没有发现它们控制着恒星IMF的质量尺度。然而，我们发现它们对恒星IMF的高质量端和形状有影响。结论。原恒星外流似乎对恒星和盘的形成都有重大影响，因此应该纳入恒星形成环境的现实模拟中。 et.al.|[2309.05397](http://arxiv.org/abs/2309.05397)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-08**|**Single View Refractive Index Tomography with Neural Fields**|折射率层析成像是一个反问题，我们试图从2D投影图像测量中重建场景的3D折射场。折射场本身是不可见的，而是影响光线在空间中传播时路径的连续弯曲。折射场出现在各种各样的科学应用中，从显微镜中的半透明细胞样本到弯曲来自遥远星系的光的暗物质场。这个问题带来了一个独特的挑战，因为折射场直接影响光的路径，使其恢复成为一个非线性问题。此外，与传统的层析成像相比，我们试图通过利用散射在整个介质中的光源的知识，仅从单个视点使用投影图像来恢复折射场。在这项工作中，我们介绍了一种使用基于坐标的神经网络对场景中潜在的连续折射场进行建模的方法。然后，我们使用射线三维空间曲率的显式建模来优化该网络的参数，通过综合分析方法重建折射场。通过在模拟中恢复折射场，并分析光源分布对恢复的影响，证明了我们方法的有效性。然后，我们在模拟暗物质映射问题上测试了我们的方法，在该问题中，我们恢复了真实模拟暗物质分布下的折射场。 et.al.|[2309.04437](http://arxiv.org/abs/2309.04437)|null|
|**2023-09-07**|**BluNF: Blueprint Neural Field**|神经辐射场（NeRF）彻底改变了场景新颖的视图合成，提供了视觉逼真、精确和稳健的隐式重建。虽然最近的方法允许NeRF编辑，例如对象删除、3D形状修改或材料特性操纵，但在这种编辑之前的手动注释使该过程变得乏味。此外，传统的2D交互工具缺乏对3D空间的准确感知，阻碍了对场景的精确操作和编辑。在本文中，我们介绍了一种新的方法，称为蓝图神经场（BluNF），以解决这些编辑问题。BluNF提供了一个强大且用户友好的2D蓝图，实现了直观的场景编辑。通过利用隐式神经表示，BluNF使用先前的语义和深度信息构建场景的蓝图。生成的蓝图可以轻松编辑和操作NeRF表示。我们通过直观的点击和更改机制展示了BluNF的可编辑性，实现了3D操作，如遮罩、外观修改和对象移除。我们的方法对视觉内容创作做出了重大贡献，为该领域的进一步研究铺平了道路。 et.al.|[2309.03933](http://arxiv.org/abs/2309.03933)|null|
|**2023-09-07**|**SimNP: Learning Self-Similarity Priors Between Neural Points**|用于3D对象重建的现有神经场表示要么（1）利用对象级表示，但由于对全局潜在代码的限制而遭受低质量细节，要么（2）能够完美地重建观测，但未能利用对象级先验知识来推断未观察到的区域。我们提出了一种学习类别级自相似性的方法SimNP，它通过将神经点辐射场与类别级自类似性表示相连接，结合了两个世界的优点。我们的贡献是双重的。（1） 我们利用相干点云的概念设计了第一个类别级别的神经点表示。由此产生的神经点辐射场为局部支持的对象区域存储了高级别的细节。（2） 我们了解了如何以无约束和无监督的方式在神经点之间共享信息，这允许在重建过程中根据给定的观测值导出对象的未观察区域。我们表明，SimNP在重建对称的看不见物体区域方面优于以前的方法，超过了建立在类别级或像素对齐辐射场上的方法，同时提供了实例之间的语义对应 et.al.|[2309.03809](http://arxiv.org/abs/2309.03809)|null|
|**2023-09-06**|**CoNeS: Conditional neural fields with shift modulation for multi-sequence MRI translation**|多序列磁共振成像（MRI）在现代临床研究和深度学习研究中都有广泛的应用。然而，在临床实践中，由于患者的不同图像采集协议或造影剂禁忌症，经常会出现一个或多个MRI序列缺失的情况，这限制了在多序列数据上训练的深度学习模型的使用。一种很有前途的方法是利用生成模型来合成缺失的序列，这可以作为替代获取。解决这一问题的最先进方法是基于卷积神经网络（CNN），该网络通常存在频谱偏差，导致高频精细细节的重建较差。在本文中，我们提出了具有移位调制的条件神经场（CoNeS），这是一种以体素坐标为输入并学习用于多序列MRI平移的目标图像的表示的模型。所提出的模型使用多层感知器（MLP）代替CNN作为像素到像素映射的解码器。因此，每个目标图像被表示为神经场，该神经场通过利用学习的潜码的移位调制而被调节在源图像上。在BraTS 2018和前庭神经鞘瘤患者的内部临床数据集上进行的实验表明，所提出的方法在视觉和定量上都优于最先进的多序列MRI翻译方法。此外，我们进行了光谱分析，表明CoNeS能够克服传统CNN模型中常见的光谱偏差问题。为了进一步评估合成图像在临床下游任务中的使用，我们在推理时使用合成图像测试了分割网络。 et.al.|[2309.03320](http://arxiv.org/abs/2309.03320)|**[link](https://github.com/cyjdswx/cones)**|
|**2023-09-06**|**ResFields: Residual Neural Fields for Spatiotemporal Signals**|神经场是一类被训练来表示高频信号的神经网络，近年来由于其在复杂三维数据建模方面的出色性能，特别是通过单个多层感知器（MLP）的大神经符号距离（SDFs）或辐射场（NeRFs），而受到了极大的关注。然而，尽管用MLP表示信号的能力和简单性很强，但由于MLP的容量有限，这些方法在建模大而复杂的时间信号时仍然面临挑战。在本文中，我们提出了一种有效的方法来解决这一限制，将时间残差层纳入神经场，称为ResFields，这是一类专门设计用于有效表示复杂时间信号的新型网络。我们对ResFields的性质进行了全面的分析，并提出了一种矩阵分解技术来减少可训练参数的数量并增强泛化能力。重要的是，我们的公式与现有技术无缝集成，并在各种具有挑战性的任务中持续改进结果：2D视频近似、通过时间SDF的动态形状建模和动态NeRF重建。最后，我们通过展示ResFields在从轻量级捕捉系统的稀疏感官输入捕捉动态3D场景方面的有效性，展示了它的实用性。 et.al.|[2309.03160](http://arxiv.org/abs/2309.03160)|**[link](https://github.com/markomih/ResFields)**|
|**2023-09-01**|**GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields**|开发能够在非结构化现实世界环境中通过视觉观察执行各种操作任务的代理是机器人技术中的一个长期问题。为了实现这一目标，机器人需要对场景的3D结构和语义有全面的了解。在这项工作中，我们提出了 $\textbf｛GNFactor｝$，一种用于多任务机器人操作的视觉行为克隆代理，具有$\textbf｛G｝$通用$\textbf｛N｝$eural功能$\textbf｛F｝$字段。GNFactor联合优化了作为重建模块的可推广神经场（GNF）和作为决策模块的感知转换器，利用了共享的深度3D体素表示。为了在3D中结合语义，重建模块利用视觉语言基础模型（$\textit｛例如｝$ ，Stable Diffusion）将丰富的语义信息提取到深度3D体素中。我们在3个真实机器人任务中评估了GNFactor，并在10个RLBench任务中进行了详细的消融，演示次数有限。我们观察到GNFactor在可见和不可见任务中比当前最先进的方法有了实质性的改进，证明了GNFactor强大的泛化能力。我们的项目网站是https://yanjieze.com/GNFactor/。 et.al.|[2308.16891](http://arxiv.org/abs/2308.16891)|**[link](https://github.com/YanjieZe/GNFactor)**|
|**2023-08-30**|**Active Neural Mapping**|我们用不断学习的神经场景表示来解决主动映射的问题，即主动神经映射。关键在于通过有效的代理移动积极找到要探索的目标空间，从而最大限度地减少在以前看不见的环境中飞行中的地图不确定性。在本文中，我们检验了连续学习神经场的权重空间，并从经验上表明，神经变异性，即对随机权重扰动的预测鲁棒性，可以直接用于测量神经映射的瞬时不确定性。结合神经映射中继承的连续几何信息，可以引导agent找到一条可遍历的路径，以逐渐获得环境知识。我们首次提出了一种用于在线场景重建的具有基于坐标的隐式神经表示的主动映射系统。在视觉逼真的Gibson和Matterport3D环境中的实验证明了所提出方法的有效性。 et.al.|[2308.16246](http://arxiv.org/abs/2308.16246)|null|
|**2023-08-29**|**Canonical Factors for Hybrid Neural Fields**|因子特征量提供了一种简单的方法来构建更紧凑、高效和可积分的神经场，但也引入了对真实世界数据不一定有益的偏差。在这项工作中，我们（1）描述了这些架构对轴对准信号的不希望有的偏差——它们可能导致高达2 PSNR的辐射场重建差异——以及（2）探索了学习一组规范化变换如何通过消除这些偏差来改进表示。我们在二维模型问题中证明，同时学习这些变换和场景外观是成功的，效率大大提高。我们使用图像、符号距离和辐射场重建任务验证了最终的架构，我们称之为TILTED，在这些任务中，我们观察到了质量、稳健性、紧凑性和运行时间方面的改进。结果表明，TILTED可以实现比基线大2倍的能力，同时突出神经场评估程序的弱点。 et.al.|[2308.15461](http://arxiv.org/abs/2308.15461)|null|
|**2023-08-30**|**NSF: Neural Surface Fields for Human Modeling from Monocular Depth**|从单眼相机获得个性化的3D可动画化化身在游戏、虚拟试穿、动画和VR/XR等领域有几个现实世界的应用。然而，从这种稀疏的数据中建模动态和细粒度的服装变形是非常具有挑战性的。现有的从深度数据建模3D人类的方法在计算效率、网格一致性以及分辨率和拓扑结构的灵活性方面具有局限性。例如，使用隐式函数重建形状和每帧提取显式网格在计算上是昂贵的，并且不能确保跨帧的连贯网格。此外，在具有离散表面的预先设计的人类模板上预测每个顶点的变形在分辨率和拓扑结构上缺乏灵活性。为了克服这些局限性，我们提出了一种新的方法“关键特征：神经表面场”，用于从单目深度对穿着3D衣服的人类进行建模。NSF仅在基面上定义了一个神经场，该神经场对连续和灵活的位移场进行建模。NSF可以适应不同分辨率和拓扑结构的基面，而无需在推理时进行重新训练。与现有方法相比，我们的方法在保持网格一致性的同时消除了昂贵的每帧表面提取，并且能够在不重新训练的情况下重建任意分辨率的网格。为了促进这方面的研究，我们在项目页面上发布了我们的代码：https://yuxuan-xue.com/nsf. et.al.|[2308.14847](http://arxiv.org/abs/2308.14847)|null|
|**2023-08-28**|**A Transformer-Conditioned Neural Fields Pipeline with Polar Coordinate Representation for Astronomical Radio Interferometric Data Reconstruction**|在射电天文学中，能见度数据是对射电望远镜波信号的测量，被转换成图像，用于观测遥远的天体。然而，由于信号稀疏性和其他因素，这些结果图像通常包含真实源和伪影。获得更干净图像的一种方法是在成像之前将样本重建成致密的形式。不幸的是，现有的可见性重建方法可能会错过频率数据的一些分量，因此模糊的对象边缘和持久的伪影仍然存在于图像中。此外，由于数据偏斜，在不规则可见性样本上的计算开销很高。为了解决这些问题，我们提出了PolarRec，这是一种干涉能见度数据的重建方法，它由具有极坐标表示的变压器条件神经场管道组成。这种表示与望远镜在地球自转时观察天体区域的方式相匹配。我们进一步提出了径向频率损失函数，使用极坐标系中的径向坐标与频率信息进行关联，以帮助重建完整的可见性。我们还根据极坐标系中的角坐标对可见性采样点进行分组，并使用分组作为随后使用Transformer编码器进行编码的粒度。因此，我们的方法可以有效地捕捉可见性数据的固有特征。我们的实验表明，PolarRec通过忠实地重建可见性域中的所有频率分量，显著提高了成像结果，同时显著降低了计算成本。 et.al.|[2308.14610](http://arxiv.org/abs/2308.14610)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

