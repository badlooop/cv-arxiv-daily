---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.10.29
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-27**|**Normal-GS: 3D Gaussian Splatting with Normal-Involved Rendering**|渲染和重建是计算机视觉和图形学中的一个长期课题。同时实现高渲染质量和精确的几何图形是一个挑战。3D高斯散斑（3DGS）的最新进展实现了实时速度的高保真新颖视图合成。然而，3D高斯基元的噪声和离散特性阻碍了精确的表面估计。由于基于3DGS的方法中法向量和渲染管道之间的根本脱节，之前对3D高斯法线进行正则化的尝试往往会降低渲染质量。因此，我们引入了Normal GS，这是一种将法向量集成到3DGS渲染管道中的新方法。核心思想是使用基于物理的渲染方程对法线和入射光之间的相互作用进行建模。我们的方法将表面颜色重新参数化为法线和设计的集成方向照明矢量（IDIV）的乘积。为了优化内存使用并简化优化，我们采用基于锚点的3DGS来隐式编码本地共享的IDIV。此外，Normal GS利用优化的法线和集成方向编码（IDE）来精确地模拟镜面反射效果，从而提高渲染质量和曲面法线精度。大量实验表明，Normal GS在获得准确的表面法线并保持实时渲染性能的同时，实现了接近最先进的视觉质量。 et.al.|[2410.20593](http://arxiv.org/abs/2410.20593)|null|
|**2024-10-27**|**GUMBEL-NERF: Representing Unseen Objects as Part-Compositional Neural Radiance Fields**|我们提出了Gumbel-NeRF，这是一种混合了专家（MoE）神经辐射场（NeRF）模型和事后专家选择机制的模型，用于合成看不见物体的新视图。先前的研究表明，MoE结构提供了由许多对象组成的给定大规模场景的高质量表示。然而，我们观察到，当应用于从一个/几个镜头输入对看不见的物体进行新颖的视图合成的任务时，这种MoE-NeRF模型通常会在专家边界附近产生低质量的表示。我们发现，这种恶化主要是由预见专家选择机制引起的，这可能会在专家边界附近的物体形状中留下不自然的不连续性。Gumbel-NeRF采用事后专家选择机制，即使在专家边界附近，也能保证密度场的连续性。使用SRN汽车数据集的实验证明了Gumbel-NeRF在各种图像质量指标方面优于基线。 et.al.|[2410.20306](http://arxiv.org/abs/2410.20306)|null|
|**2024-10-25**|**Evaluation of strategies for efficient rate-distortion NeRF streaming**|神经辐射场（NeRF）通过从稀疏的图像集实现高度逼真和详细的场景重建，彻底改变了3D视觉表示领域。NeRF使用体积函数表示法，将3D点映射到其相应的颜色和不透明度，从而允许从任意视点进行逼真的视图合成。尽管取得了进步，但由于涉及大量数据，NeRF内容的高效流式传输仍然是一个重大挑战。本文研究了两种NeRF流媒体策略的率失真性能：基于像素的流媒体和基于神经网络（NN）参数的流媒体。在前者中，图像被编码并随后在整个网络中传输，而在后者中，相应的NeRF模型参数被编码并传输。这项工作还强调了复杂性和性能之间的权衡，表明基于NN参数的策略通常具有更高的效率，使其适用于一对多的流媒体场景。 et.al.|[2410.19459](http://arxiv.org/abs/2410.19459)|null|
|**2024-10-24**|**Where Am I and What Will I See: An Auto-Regressive Model for Spatial Localization and View Prediction**|空间智能是机器在空间和时间的三维空间中感知、推理和行动的能力。大规模自回归模型的最新进展在各种推理任务中表现出了显著的能力。然而，这些模型经常在空间推理的基本方面遇到困难，特别是在回答“我在哪里？”和“我会看到什么？”等问题时。虽然已经进行了一些尝试，但现有的方法通常将它们视为单独的任务，未能捕捉到它们相互关联的性质。在本文中，我们提出了生成空间变换器（GST），这是一种新型的自回归框架，可以同时解决空间定位和视图预测问题。我们的模型同时从单个图像中估计相机姿态，并从新的相机姿态预测视图，有效地弥合了空间感知和视觉预测之间的差距。所提出的创新相机标记化方法使模型能够以自回归的方式学习2D投影的联合分布及其相应的空间视角。这种统一的训练范式表明，姿态估计和新颖视图合成的联合优化首次提高了这两项任务的性能，突出了空间感知和视觉预测之间的内在关系。 et.al.|[2410.18962](http://arxiv.org/abs/2410.18962)|null|
|**2024-10-27**|**Binocular-Guided 3D Gaussian Splatting with View Consistency for Sparse View Synthesis**|稀疏输入的新颖视图合成是3D计算机视觉中一项至关重要但具有挑战性的任务。之前的方法探索了使用神经先验（如深度先验）作为额外监督的3D高斯散斑，与基于NeRF的方法相比，显示出有前景的质量和效率。然而，来自2D预训练模型的神经先验通常是嘈杂和模糊的，这很难精确地指导辐射场的学习。在本文中，我们提出了一种新的方法，通过高斯散斑从稀疏视图合成新视图，该方法不需要外部先验作为监督。我们的关键思想在于探索通过视差引导图像扭曲构建的每对双目图像之间的双目立体一致性所固有的自我监督。为此，我们还引入了高斯不透明度约束，该约束使高斯位置正则化，避免了高斯冗余，以提高从稀疏视图推断3D高斯的鲁棒性和效率。在LLFF、DTU和Blender数据集上进行的广泛实验表明，我们的方法明显优于最先进的方法。 et.al.|[2410.18822](http://arxiv.org/abs/2410.18822)|null|
|**2024-10-23**|**FreeVS: Generative View Synthesis on Free Driving Trajectory**|现有的基于重建的新型驾驶场景视图合成方法侧重于沿自我车辆记录的轨迹合成相机视图。当视点偏离记录的轨迹，相机光线未经训练时，它们的图像渲染性能将严重下降。我们提出了FreeVS，这是一种新颖的完全生成方法，可以在真实驾驶场景中合成自由新轨迹上的相机视图。为了控制生成结果与真实场景的3D一致性和视点姿态的准确性，我们提出了视图先验的伪图像表示来控制生成过程。视点变换模拟应用于伪图像，以模拟相机在每个方向上的运动。一旦经过训练，FreeVS可以应用于任何验证序列，而无需对新轨迹进行重建过程和合成视图。此外，我们提出了两个针对驾驶场景量身定制的具有挑战性的新基准，即新颖的相机合成和新颖的轨迹合成，强调视点的自由度。鉴于新轨迹上没有地面真实图像，我们还建议用3D感知模型评估新轨迹上合成的图像的一致性。在Waymo开放数据集上的实验表明，FreeVS在记录的轨迹和新的轨迹上都具有很强的图像合成性能。项目页面：https://freevs24.github.io/ et.al.|[2410.18079](http://arxiv.org/abs/2410.18079)|null|
|**2024-10-23**|**VR-Splatting: Foveated Radiance Field Rendering via 3D Gaussian Splatting and Neural Points**|新视图合成（NVS）的最新进展，特别是神经辐射场（NeRF）和高斯溅射（3DGS），在真实感场景渲染方面取得了令人印象深刻的结果。这些技术在虚拟旅游和隐形传态中具有巨大的应用潜力，其中沉浸式真实感至关重要。然而，由于延迟和计算限制，虚拟现实（VR）系统的高性能需求给直接利用如此快速的渲染3DGS等场景表示带来了挑战。在本文中，我们提出了中心凹渲染作为解决这些障碍的有前景的解决方案。我们分析了最先进的NVS方法的渲染性能和与人类视觉系统的兼容性。我们的方法为虚拟现实引入了一种新的中心凹渲染方法，该方法利用了中心凹区域神经点渲染的清晰、详细的输出，并与周边视觉的3DGS平滑渲染相融合。我们的评估证实，与标准的VR就绪3DGS配置相比，我们的方法提高了感知的清晰度和细节丰富性。我们的系统满足了实时VR交互的必要性能要求，最终增强了用户的沉浸式体验。项目页面：https://lfranke.github.io/vr_splatting et.al.|[2410.17932](http://arxiv.org/abs/2410.17932)|null|
|**2024-10-23**|**Few-shot NeRF by Adaptive Rendering Loss Regularization**|稀疏输入的新型视图合成对神经辐射场（NeRF）提出了巨大挑战。最近的工作表明，位置编码（PE）的频率正则化可以在少镜头NeRF中取得有前景的结果。在这项工作中，我们发现PE的频率正则化和渲染损失之间存在不一致。这使得很少拍摄的NeRF无法合成更高质量的新颖视图。为了减轻这种不一致性，我们提出了针对少镜头NeRF的自适应渲染损失正则化，称为AR NeRF。具体来说，我们提出了一种两阶段渲染监督和一种自适应渲染损失权重学习策略，以对齐PE和2D像素监督之间的频率关系。通过这种方式，AR NeRF可以在早期训练阶段更好地学习全局结构，并在整个训练过程中自适应地学习局部细节。广泛的实验表明，我们的AR NeRF在不同的数据集上实现了最先进的性能，包括对象级和复杂场景。 et.al.|[2410.17839](http://arxiv.org/abs/2410.17839)|null|
|**2024-10-22**|**SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes**|我们提出了SpectroMotion，这是一种将3D高斯散斑（3DGS）与基于物理的渲染（PBR）和变形场相结合的新方法，用于重建动态镜面场景。以前将3DGS扩展到动态场景建模的方法很难准确地表示镜面反射表面。我们的方法通过引入残差校正技术来解决这一局限性，该技术用于在变形过程中进行精确的表面法线计算，并辅以适应时变照明条件的可变形环境贴图。我们实施了一种从粗到细的训练策略，显著增强了场景几何和镜面颜色预测。我们证明，我们的模型在包含动态镜面对象的场景的视图合成方面优于现有的方法，并且它是唯一能够合成逼真的真实世界动态镜面场景的3DGS方法，在渲染复杂、动态和镜面场景方面优于最先进的方法。 et.al.|[2410.17249](http://arxiv.org/abs/2410.17249)|null|
|**2024-10-22**|**LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias**|我们提出了大视图合成模型（LVSM），这是一种基于变换器的新方法，用于从稀疏视图输入中进行可扩展和可推广的新视图合成。我们介绍了两种架构：（1）编码器-解码器LVSM，它将输入图像令牌编码为固定数量的1D潜在令牌，作为完全学习的场景表示，并从中解码出新的视图图像；以及（2）仅解码器LVSM，它直接将输入图像映射到新的视图输出，完全消除了中间场景表示。这两种模型都绕过了以前方法中使用的3D感应偏差——从3D表示（如NeRF、3DGS）到网络设计（如极线投影、平面扫描）——用完全数据驱动的方法解决了新颖的视图合成问题。虽然编码器-解码器模型由于其独立的潜在表示而提供了更快的推断，但仅解码器的LVSM实现了卓越的质量、可扩展性和零样本泛化，比以前最先进的方法高1.5至3.5 dB PSNR。对多个数据集的综合评估表明，这两种LVSM变体都达到了最先进的新颖视图合成质量。值得注意的是，即使计算资源减少（1-2个GPU），我们的模型也超越了所有以前的方法。请访问我们的网站了解更多详情：https://haian-jin.github.io/projects/LVSM/ . et.al.|[2410.17242](http://arxiv.org/abs/2410.17242)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-28**|**IndraEye: Infrared Electro-Optical UAV-based Perception Dataset for Robust Downstream Tasks**|深度神经网络（DNN）在电光（EO）相机捕获的光线充足的图像上训练时表现出了卓越的性能，这些图像提供了丰富的纹理细节。然而，在航空感知等关键应用中，DNN必须在所有条件下保持一致的可靠性，包括低光照场景，在这些场景中，光电摄像机往往难以捕捉到足够的细节。此外，由于不同高度和倾斜角度的尺度变化，基于无人机的空中目标检测面临着重大挑战，增加了另一层复杂性。现有的方法通常只解决域偏移时的照明变化或样式变化，但在空间感知中，相关性偏移也会影响DNN性能。本文介绍了IndraEye数据集，这是一个为各种任务设计的多传感器（EO-IR）数据集。它包括5612张图像，145666个实例，涵盖了印度次大陆的多个视角、高度、七种背景和一天中的不同时间。该数据集开辟了几个研究机会，如多模态学习、对象检测和分割的领域自适应，以及探索传感器特定的优缺点。IndraEye旨在通过支持开发更强大、更准确的空中感知系统来推进该领域的发展，特别是在具有挑战性的条件下。IndraEye数据集以对象检测和语义分割任务为基准。数据集和源代码可在https://bit.ly/indraeye. et.al.|[2410.20953](http://arxiv.org/abs/2410.20953)|null|
|**2024-10-28**|**ODGS: 3D Scene Reconstruction from Omnidirectional Images with 3D Gaussian Splattings**|全向（或360度）图像越来越多地用于3D应用，因为它们允许用单个图像渲染整个场景。基于神经辐射场的现有作品在以自我为中心的视频上展示了成功的3D重建质量，但它们的训练和渲染时间很长。最近，3D高斯散斑因其快速优化和实时渲染而受到关注。然而，由于两个图像域之间的光学特性不同，直接使用透视光栅化器对全向图像进行处理会导致严重失真。在这项工作中，我们提出了ODGS，这是一种用于全向图像的新型光栅化流水线，具有几何解释功能。对于每个高斯分布，我们定义一个与单位球体接触的切平面，该切平面垂直于朝向高斯中心的光线。然后，我们利用透视相机光栅化器将高斯投影到相应的切平面上。投影的高斯图像被转换并组合成全向图像，从而完成全向光栅化过程。这种解释揭示了所提出的管道中的隐含假设，我们通过数学证明进行了验证。整个光栅化过程使用CUDA并行化，实现了比基于NeRF的方法快100倍的优化和渲染速度。我们的综合实验通过在各种数据集上提供最佳的重建和感知质量，突显了ODGS的优越性。此外，漫游数据集的结果表明，即使在重建大型3D场景时，ODGS也能有效地恢复精细细节。源代码可以在我们的项目页面上找到(https://github.com/esw0116/ODGS). et.al.|[2410.20686](http://arxiv.org/abs/2410.20686)|null|
|**2024-10-27**|**Neural rendering enables dynamic tomography**|中断X射线计算机断层扫描（X-CT）一直是观察实验过程中材料变形的常用方法。虽然这种方法对于准静态实验是有效的，但在不可中断的动态实验中，永远不可能重建完整的三维断层扫描。在这项工作中，我们提出神经渲染工具可用于推动范式转变，以在动态事件中实现三维重建。首先，我们得出理论结果来支持投影角度的选择。通过合成和实验数据的结合，我们证明神经辐射场可以比传统的重建方法更有效地重建感兴趣的数据模态。最后，我们开发了一个基于样条的变形场时空模型，并证明该模型可以在现实实验中重建晶格样本的时空变形。 et.al.|[2410.20558](http://arxiv.org/abs/2410.20558)|null|
|**2024-10-26**|**Neural Fields in Robotics: A Survey**|神经场已经成为计算机视觉和机器人技术中3D场景表示的一种变革性方法，能够从姿势的2D数据中准确推断几何、3D语义和动力学。利用可微分渲染，神经场包括连续隐式和显式神经表示，实现了高保真3D重建、多模态传感器数据的集成和新视点的生成。这项调查探讨了它们在机器人技术中的应用，强调了它们在增强感知、规划和控制方面的潜力。它们的紧凑性、内存效率和可微性，以及与基础模型和生成模型的无缝集成，使其成为实时应用的理想选择，提高了机器人的适应性和决策能力。本文基于200多篇论文，对机器人中的神经场进行了全面的回顾，对各个领域的应用进行了分类，并评估了它们的优势和局限性。首先，我们介绍了四个关键的神经场框架：占用网络、有符号距离场、神经辐射场和高斯散斑。其次，我们详细介绍了神经场在五个主要机器人领域的应用：姿态估计、操纵、导航、物理和自动驾驶，重点介绍了关键工作，并讨论了要点和公开挑战。最后，我们概述了神经场在机器人技术中的局限性，并为未来的研究提出了有前景的方向。项目页面：https://robonerf.github.io et.al.|[2410.20220](http://arxiv.org/abs/2410.20220)|null|
|**2024-10-26**|**SCube: Instant Large-Scale Scene Reconstruction using VoxSplats**|我们提出了SCube，这是一种从稀疏的姿态图像集重建大规模3D场景（几何、外观和语义）的新方法。我们的方法使用一种新的表示VoxSplat对重建的场景进行编码，VoxSplaat是一组在高分辨率稀疏体素支架上支持的3D高斯分布。为了从图像中重建VoxSplat，我们采用了一个以输入图像为条件的分层体素潜在扩散模型，然后是一个前馈外观预测模型。扩散模型以从粗到细的方式逐步生成高分辨率网格，外观网络预测每个体素内的一组高斯分布。从少至3个不重叠的输入图像中，SCube可以在20秒内生成数百万个高斯图像，其1024^3的体素网格跨越数百米。过去从图像中重建场景的工作要么依赖于每个场景的优化，无法从输入视图中重建场景（因此需要密集的视图覆盖作为输入），要么利用基于低分辨率模型的几何先验，这会产生模糊的结果。相比之下，SCube利用高分辨率稀疏网络，从很少的视图中产生清晰的输出。我们展示了SCube与使用Waymo自动驾驶数据集进行3D重建的现有技术相比的优越性，并展示了其应用，如LiDAR模拟和文本到场景生成。 et.al.|[2410.20030](http://arxiv.org/abs/2410.20030)|null|
|**2024-10-25**|**Tracking and triangulating firefly flashes in field recordings**|从自然图像中的其他明亮特征中识别萤火虫闪光是复杂的。我提供了一个训练数据集和经过训练的神经网络，用于可靠的闪光分类。训练集由数千个裁剪图像（补丁）组成，这些图像是通过手动标记从萤火虫在自然栖息地的视频记录中提取的。与仅依赖强度阈值的传统方法相比，训练好的网络在区分闪光与其他光源方面似乎更可靠。这种稳健的跟踪技术为从立体360度视频中重建闪光事件提供了一种新的无需校准的3D重建方法，我在这里也介绍了这种方法。 et.al.|[2410.19932](http://arxiv.org/abs/2410.19932)|null|
|**2024-10-24**|**Large Spatial Model: End-to-end Unposed Images to Semantic 3D**|从有限数量的图像重建和理解3D结构是计算机视觉中一个公认的问题。传统方法通常将此任务分解为多个子任务，每个子任务都需要在不同数据表示之间进行复杂的转换。例如，通过运动结构（SfM）进行密集重建涉及将图像转换为关键点、优化相机参数和估计结构。之后，需要精确的稀疏重建来进行进一步的密集建模，随后将其输入到特定任务的神经网络中。这种多步骤的过程导致了相当长的处理时间和工程复杂性的增加。在这项工作中，我们提出了大空间模型（LSM），它将未经处理的RGB图像直接处理成语义辐射场。LSM在单个前馈操作中同时估计几何、外观和语义，并且可以通过在新的视点与语言交互来生成通用的标签图。LSM利用基于Transformer的架构，通过像素对齐的点图集成全局几何。为了增强空间属性回归，我们将局部上下文聚合与多尺度融合相结合，提高了精细局部细节的准确性。为了解决标记的3D语义数据的稀缺性并实现自然语言驱动的场景操纵，我们将一个预先训练的基于2D语言的分割模型整合到一个3D一致的语义特征字段中。然后，一个高效的解码器将一组语义各向异性高斯分布参数化，从而促进有监督的端到端学习。在各种任务中的广泛实验表明，LSM直接从无基图像中统一了多个3D视觉任务，首次实现了实时语义3D重建。 et.al.|[2410.18956](http://arxiv.org/abs/2410.18956)|null|
|**2024-10-24**|**A Cranial-Feature-Based Registration Scheme for Robotic Micromanipulation Using a Microscopic Stereo Camera System**|生物标本在大小和形状上表现出显著的变化，对自主机器人操作提出了挑战。我们专注于鼠标头骨窗口创建任务来说明这些挑战。该研究引入了一种由深度感知线性模型增强的微观立体相机系统（MSCS）。除此之外，还为部分暴露的小鼠颅骨表面开发了一种精确的配准方案，采用基于CNN的约束和彩色配准策略。这些方法与MSCS集成，用于机器人微操作任务。MSCS在台阶高度实验中测得的精度高达0.10 mm，在3D重建中的实时性能为30 FPS。该配准方案证明了其精度，在105个连续帧上以1.60 FPS的平均速度测试了1.13 mm的平移误差和3.38 mm的旋转误差。本研究介绍了MSCS和一种新的配准方案在提高科学和手术环境中机器人微操作的精度和准确性方面的应用。这里提出的创新提供了处理显微操作挑战的自动化方法，为显微手术和科学研究各个领域更准确、更高效、侵入性更小的手术铺平了道路。 et.al.|[2410.18630](http://arxiv.org/abs/2410.18630)|null|
|**2024-10-22**|**SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes**|我们提出了SpectroMotion，这是一种将3D高斯散斑（3DGS）与基于物理的渲染（PBR）和变形场相结合的新方法，用于重建动态镜面场景。以前将3DGS扩展到动态场景建模的方法很难准确地表示镜面反射表面。我们的方法通过引入残差校正技术来解决这一局限性，该技术用于在变形过程中进行精确的表面法线计算，并辅以适应时变照明条件的可变形环境贴图。我们实施了一种从粗到细的训练策略，显著增强了场景几何和镜面颜色预测。我们证明，我们的模型在包含动态镜面对象的场景的视图合成方面优于现有的方法，并且它是唯一能够合成逼真的真实世界动态镜面场景的3DGS方法，在渲染复杂、动态和镜面场景方面优于最先进的方法。 et.al.|[2410.17249](http://arxiv.org/abs/2410.17249)|null|
|**2024-10-22**|**E-3DGS: Gaussian Splatting with Exposure and Motion Events**|从最佳条件下捕获的图像中估计神经辐射场（NeRF）在视觉界得到了广泛的探索。然而，机器人应用经常面临运动模糊、照明不足和计算开销高等挑战，这些挑战对导航、检查和场景可视化等下游任务产生了不利影响。为了应对这些挑战，我们提出了E-3DGS，这是一种基于事件的新方法，将事件划分为运动（来自相机或物体运动）和曝光（来自相机曝光），使用前者来处理快速运动的场景，使用后者来重建灰度图像，以进行基于事件的3D高斯散斑（3DGS）的高质量训练和优化。我们介绍了一种将3DGS与曝光事件相结合的新方法，用于高质量重建显式场景表示。我们的多功能框架可以单独操作运动事件进行3D重建，使用曝光事件提高质量，或者采用混合模式，通过优化初始曝光事件和高速运动事件来平衡质量和有效性。我们还介绍了EME-3D，这是一个真实世界的3D数据集，包含曝光事件、运动事件、相机校准参数和稀疏点云。我们的方法比基于事件的NeRF更快，重建质量更好，同时比使用单个事件传感器组合事件和RGB数据的NeRF方法更具成本效益。通过结合运动和曝光事件，E-3DGS为基于事件的3D重建设定了新的基准，在具有挑战性的条件下和较低的硬件需求下具有强大的性能。源代码和数据集将在https://github.com/MasterHow/E-3DGS. et.al.|[2410.16995](http://arxiv.org/abs/2410.16995)|**[link](https://github.com/masterhow/e-3dgs)**|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-28**|**On Inductive Biases That Enable Generalization of Diffusion Transformers**|最近研究使用基于UNet的去噪器对扩散模型进行泛化的工作揭示了可以通过几何自适应调和基表示的归纳偏差。然而，在实践中，最近的去噪网络通常基于变换器，例如扩散变换器（DiT）。这就提出了一个问题：基于变压器的去噪网络是否表现出也可以通过几何自适应谐波基表示的感应偏差？令我们惊讶的是，我们发现事实并非如此。这种差异促使我们寻找可以在DiT模型中实现良好泛化的归纳偏差。通过研究DiT的关键注意力模块，我们发现注意力图的局部性与泛化密切相关。为了验证这一发现，我们通过限制DiT的注意力窗口来修改DiT的泛化。我们将局部注意力窗口注入DiT，并观察到泛化能力的提高。此外，我们实证发现，这些局部注意力窗口的位置和有效注意力大小都是关键因素。CelebrA、ImageNet和LSUN数据集的实验结果表明，在训练数据较少的情况下，加强DiT的归纳偏差可以提高泛化能力和生成质量。源代码将在论文发表后公开发布。项目页面：dit-generation.github.io/。 et.al.|[2410.21273](http://arxiv.org/abs/2410.21273)|null|
|**2024-10-28**|**One-Step Diffusion Policy: Fast Visuomotor Policies via Diffusion Distillation**|扩散模型因其在生成任务中的成功而受到称赞，正越来越多地应用于机器人技术，在行为克隆方面表现出色。然而，由于迭代去噪步骤导致的缓慢生成过程对资源受限的机器人设置和动态变化环境中的实时应用提出了挑战。在本文中，我们介绍了一步扩散策略（OneDP），这是一种将预先训练的扩散策略中的知识提取到单步动作生成器中的新方法，显著加快了机器人控制任务的响应时间。我们通过最小化扩散链上的Kullback-Leibler（KL）分歧，确保蒸馏生成器与原始策略分布紧密一致，只需要2-10美元的额外预训练成本即可实现收敛。我们使用Franka机器人在6个具有挑战性的模拟任务和4个自行设计的现实世界任务中评估了OneDP。结果表明，OneDP不仅实现了最先进的成功率，而且在推理速度方面也有了一个数量级的提高，将动作预测频率从1.5 Hz提高到62 Hz，为动态和计算受限的机器人应用奠定了潜力。我们在以下网址共享项目页面https://research.nvidia.com/labs/dir/onedp/. et.al.|[2410.21257](http://arxiv.org/abs/2410.21257)|null|
|**2024-10-28**|**On learning higher-order cumulants in diffusion models**|为了分析扩散模型如何学习高斯模型之外的相关性，我们研究了高阶累积量或连接n点函数在正向和反向过程中的行为。我们根据初始数据的分布和正向过程的性质，推导了矩和累积量生成泛函的显式表达式。分析表明，在正向过程中，高阶累积量在没有漂移的模型中是守恒的，例如方差扩展方案，因此正向过程的终点保持了非平凡的相关性。我们证明，由于这些相关性是在得分函数中编码的，因此高阶累积量是在反向过程中学习的，即使从正常先验开始也是如此。我们在具有非零累积量的精确可解玩具模型和标量晶格场论中证实了我们的分析结果。 et.al.|[2410.21212](http://arxiv.org/abs/2410.21212)|null|
|**2024-10-28**|**Trajectory Flow Matching with Applications to Clinical Time Series Modeling**|随机和不规则采样时间序列的建模是一个具有挑战性的问题，在广泛的应用中，特别是在医学领域。神经随机微分方程（Neural SDE）是解决这一问题的一种有吸引力的建模技术，它利用神经网络将SDE的漂移和扩散项参数化。然而，目前用于训练神经SDE的算法需要通过SDE动力学进行反向传播，这极大地限制了它们的可扩展性和稳定性。为了解决这个问题，我们提出了轨迹流匹配（TFM），它以无模拟的方式训练神经SDE，绕过动力学中的反向传播。TFM利用了从生成建模到时间序列建模的流匹配技术。在这项工作中，我们首先建立了TFM学习时间序列数据的必要条件。接下来，我们提出了一种提高训练稳定性的重参数化技巧。最后，我们将TFM应用于临床时间序列设置，在三个临床时间序列数据集上展示了在绝对性能和不确定性预测方面的改进性能。 et.al.|[2410.21154](http://arxiv.org/abs/2410.21154)|**[link](https://github.com/nzhangx/trajectoryflowmatching)**|
|**2024-10-28**|**Extrapolating Prospective Glaucoma Fundus Images through Diffusion Model in Irregular Longitudinal Sequences**|利用纵向数据集预测青光眼进展为支持早期治疗干预提供了一种令人信服的方法。该领域的主要方法主要集中在从纵向数据集中直接预测青光眼分期标签上。然而，这些方法可能无法充分概括疾病的微妙发展轨迹。为了提高医生的诊断敏锐度，我们提出了一种新的基于扩散的模型，通过从现有的患者纵向眼底图像中推断来预测前瞻性图像。本研究中描述的方法独特地利用图像序列作为输入。随后，采用时间对齐掩模来选择特定年份进行图像生成。在训练阶段，时间对齐掩模解决了纵向图像序列采样中不规则时间间隔的问题。此外，我们利用随机屏蔽序列中的帧的策略来建立地面真相。这种方法有助于网络在整个学习阶段不断获取有关序列之间内部关系的知识。此外，引入文本标签有助于对序列中生成的图像进行分类。所进行的实验的实证结果表明，我们提出的模型不仅有效地生成了纵向数据，而且显著提高了下游分类任务的精度。 et.al.|[2410.21130](http://arxiv.org/abs/2410.21130)|null|
|**2024-10-28**|**Tree-Wasserstein Distance for High Dimensional Data with a Latent Feature Hierarchy**|在高维数据样本之间找到有意义的距离是一项重要的科学任务。为此，我们提出了一种新的树Wasserstein距离（TWD），用于高维数据，具有两个关键方面。首先，我们的TWD是专门为具有潜在特征层次的数据设计的，即特征位于层次空间中，这与通常关注在双曲空间中嵌入样本的做法形成鲜明对比。其次，虽然TWD的传统用途是加速Wasserstein距离的计算，但我们使用其固有的树作为学习潜在特征层次的手段。我们的方法的关键思想是使用扩散几何将特征嵌入到多尺度双曲空间中，然后通过在双曲嵌入和树之间建立类比来提出一种新的树解码方法。我们证明了基于数据观测计算的TWD可证明地恢复了用潜在特征层次定义的TWD，并且其计算是高效和可扩展的。我们展示了所提出的TWD在应用于单词文档和单细胞RNA测序数据集方面的有用性，展示了它相对于现有的TWD和基于预训练模型的方法的优势。 et.al.|[2410.21107](http://arxiv.org/abs/2410.21107)|null|
|**2024-10-28**|**Shallow Diffuse: Robust and Invisible Watermarking through Low-Dimensional Subspaces in Diffusion Models**|从传播模型中广泛使用人工智能生成的内容，引发了人们对错误信息和侵犯版权的严重担忧。水印是识别这些人工智能生成的图像并防止其被滥用的关键技术。本文介绍了一种新的水印技术——浅扩散，它将鲁棒且不可见的水印嵌入到扩散模型输出中。与在整个扩散采样过程中集成水印的现有方法不同，浅扩散通过利用图像生成过程中低维子空间的存在来解耦这些步骤。该方法确保水印的大部分位于该子空间的零空间中，有效地将其与图像生成过程分离。我们的理论和实证分析表明，这种解耦策略大大提高了数据生成的一致性和水印的可检测性。广泛的实验进一步验证了我们的浅扩散在鲁棒性和一致性方面优于现有的水印方法。这些代码将于https://github.com/liwd190019/Shallow-Diffuse. et.al.|[2410.21088](http://arxiv.org/abs/2410.21088)|**[link](https://github.com/liwd190019/shallow-diffuse)**|
|**2024-10-28**|**Confined active particles with spatially dependent Lorentz force: an odd twist to the "best Fokker-Planck approximation"**|我们推导出了所谓的“最佳福克-普朗克近似”（BFPA）的一个版本，用于描述任意空间维度中相互作用的活性奥恩斯坦-乌伦贝克粒子（AOUP）的空间特性。在此过程中，我们还考虑了洛伦兹力在空间相关磁场中作用于带电粒子的奇数扩散贡献，并遵守过阻尼极限。虽然BFPA本身并没有被证明是广泛有用的，但我们的一般方法允许推导出Fox近似的适当推广，我们通过推导构型概率分布（或有效势）的解析表达式来表征外部势中单个活性粒子的稳态行为。与计算机模拟一致，我们的理论预测洛伦兹力会降低有效引力，从而降低在排斥壁附近找到活性粒子的概率。即使对于非均匀磁场，我们的理论发现也提供了有用的定性见解，特别是关于积聚区域的位置。 et.al.|[2410.21087](http://arxiv.org/abs/2410.21087)|null|
|**2024-10-28**|**Federated Time Series Generation on Feature and Temporally Misaligned Data**|分布式时间序列数据对联邦学习提出了挑战，因为客户端通常具有不同的特征集，并且时间步长不一致。现有的联邦时间序列模型受到跨客户端完美时间或特征对齐假设的限制。在本文中，我们提出了FedTDD，这是一种新的联邦时间序列扩散模型，可以在客户端之间联合学习合成器。FedTDD的核心是一个新颖的数据蒸馏和聚合框架，通过输入未对齐的时间步和特征来调和客户端之间的差异。与传统的联邦学习相比，FedTDD通过交换本地合成输出而不是模型参数来学习客户端时间序列之间的相关性。协调器通过交换合成数据，利用来自客户的共享知识，迭代地改进全球蒸馏器网络。随着时间的推移，蒸馏器变得越来越精细，它随后提高了客户局部特征估计的质量，允许每个客户使用最新、更准确的蒸馏器来改进其对缺失数据的局部插补。在五个数据集上的实验结果证明了FedTDD与集中式训练相比的有效性，以及共享合成输出以转移本地时间序列知识的有效性。值得注意的是，FedTDD在上下文FID和相关性得分方面分别比本地培训提高了79.4%和62.8%。 et.al.|[2410.21072](http://arxiv.org/abs/2410.21072)|null|
|**2024-10-28**|**Kandinsky 3: Text-to-Image Synthesis for Multifunctional Generative Framework**|文本到图像（T2I）扩散模型在引入图像处理方法方面很受欢迎，如编辑、图像融合、修复等。同时，图像到视频（I2V）和文本到视频（T2V）模型也建立在T2I模型之上。我们提出了康定斯基3，这是一种基于潜在扩散的新型T2I模型，实现了高质量和照片级真实感。新架构的关键特征是其适应多种类型生成任务的简单性和效率。我们为各种应用扩展了基本的T2I模型，并创建了一个多功能生成系统，包括文本引导的修复/外绘、图像融合、文本图像融合、图像变化生成、I2V和T2V生成。我们还提出了T2I模型的简化版本，在不降低图像质量的情况下，通过4个反向过程步骤评估推理，速度是基础模型的3倍。我们部署了一个用户友好的演示系统，其中所有功能都可以在公共领域进行测试。此外，我们还发布了康定斯基3和扩展模型的源代码和检查点。人工评估显示，康定斯基3是开源生成系统中质量得分最高的系统之一。 et.al.|[2410.21061](http://arxiv.org/abs/2410.21061)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-26**|**Neural Fields in Robotics: A Survey**|神经场已经成为计算机视觉和机器人技术中3D场景表示的一种变革性方法，能够从姿势的2D数据中准确推断几何、3D语义和动力学。利用可微分渲染，神经场包括连续隐式和显式神经表示，实现了高保真3D重建、多模态传感器数据的集成和新视点的生成。这项调查探讨了它们在机器人技术中的应用，强调了它们在增强感知、规划和控制方面的潜力。它们的紧凑性、内存效率和可微性，以及与基础模型和生成模型的无缝集成，使其成为实时应用的理想选择，提高了机器人的适应性和决策能力。本文基于200多篇论文，对机器人中的神经场进行了全面的回顾，对各个领域的应用进行了分类，并评估了它们的优势和局限性。首先，我们介绍了四个关键的神经场框架：占用网络、有符号距离场、神经辐射场和高斯散斑。其次，我们详细介绍了神经场在五个主要机器人领域的应用：姿态估计、操纵、导航、物理和自动驾驶，重点介绍了关键工作，并讨论了要点和公开挑战。最后，我们概述了神经场在机器人技术中的局限性，并为未来的研究提出了有前景的方向。项目页面：https://robonerf.github.io et.al.|[2410.20220](http://arxiv.org/abs/2410.20220)|null|
|**2024-10-24**|**3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation**|多视图图像扩散模型显著推进了开放域3D对象生成。然而，大多数现有模型依赖于缺乏固有3D偏差的2D网络架构，导致几何一致性受损。为了应对这一挑战，我们引入了3D Adapter，这是一个插件模块，旨在将3D几何感知注入预训练的图像扩散模型中。我们方法的核心是3D反馈增强的思想：对于采样循环中的每个去噪步骤，3D Adapter将中间的多视图特征解码为连贯的3D表示，然后对渲染的RGBD视图进行重新编码，通过特征添加来增强预训练的基础模型。我们研究了3D Adapter的两种变体：一种是基于高斯飞溅的快速前馈版本，另一种是利用神经场和网格的通用无训练版本。我们广泛的实验表明，3D Adapter不仅大大提高了文本到多视图模型（如Instant3D和Zero123++）的几何质量，而且还使用纯文本到图像的稳定扩散实现了高质量的3D生成。此外，我们通过在文本到3D、图像到3D、文本到纹理和文本到化身任务中呈现高质量的结果，展示了3D适配器的广泛应用潜力。 et.al.|[2410.18974](http://arxiv.org/abs/2410.18974)|**[link](https://github.com/Lakonik/MVEdit)**|
|**2024-10-22**|**Cortical Dynamics of Neural-Connectivity Fields**|皮质组织的宏观研究揭示了振荡活动的普遍性，这反映了神经相互作用的微调。本研究通过将广义振荡动力学纳入先前关于保守或半保守神经场动力学的工作中，扩展了神经场理论。先前的研究在很大程度上假设了神经单元之间的各向同性连接；然而，这项研究表明，广泛的各向异性和波动连接仍然可以维持振荡。使用拉格朗日场方法，我们研究了不同类型的连接、它们的动力学以及与神经场的潜在相互作用。基于这一理论基础，我们推导出了一个框架，该框架通过连接场的概念将Hebbian和非Hebbian学习（即可塑性）纳入神经场的研究中。 et.al.|[2410.16852](http://arxiv.org/abs/2410.16852)|null|
|**2024-10-15**|**Deep vectorised operators for pulsatile hemodynamics estimation in coronary arteries from a steady-state prior**|心血管血流动力学场为冠状动脉疾病提供了有价值的医学决策标志。计算流体动力学（CFD）是体内准确、无创评估这些量的金标准。在这项工作中，我们提出了一种基于机器学习的时间高效替代模型，用于基于稳态先验估计脉动血流动力学。我们引入了深度矢量化算子，这是一种用于在无限维函数空间上进行离散化独立学习的建模框架。基础神经结构是一个以血流动力学边界条件为条件的神经场。重要的是，我们展示了如何将逐点动作的要求放宽到置换等变，从而产生一系列可以通过消息传递和自我关注层进行参数化的模型。我们在从冠状动脉计算机断层扫描血管造影（CCTA）中提取的74条狭窄冠状动脉的数据集上评估了我们的方法，并将患者特异性脉动CFD模拟作为基本事实。我们证明，我们的模型能够准确估计脉动速度和压力，同时不受源域重新采样的影响（离散化独立性）。这表明，深度矢量化算子是冠状动脉及其他动脉心血管血流动力学估计的强大建模工具。 et.al.|[2410.11920](http://arxiv.org/abs/2410.11920)|null|
|**2024-10-07**|**Fast Training of Sinusoidal Neural Fields via Scaling Initialization**|神经场是一种新兴的范式，它将数据表示为由神经网络参数化的连续函数。尽管有许多优点，但神经场通常具有较高的训练成本，这阻碍了更广泛的采用。在本文中，我们关注一个流行的神经场家族，称为正弦神经场（SNF），并研究如何初始化它以最大限度地提高训练速度。我们发现，基于信号传播原理设计的SNF标准初始化方案是次优的。特别是，我们证明，通过简单地将每个权重（最后一层除外）乘以一个常数，我们可以将SNF训练加速10 $\times$。这种方法被称为$\textit{weight scaling}$ ，在各种数据域上持续提供显著的加速，使SNF的训练速度比最近提出的架构更快。为了理解为什么权重缩放效果良好，我们进行了广泛的理论和实证分析，结果表明，权重缩放不仅有效地解决了频谱偏差，而且具有良好的优化轨迹。 et.al.|[2410.04779](http://arxiv.org/abs/2410.04779)|null|
|**2024-10-04**|**End-to-End Reaction Field Energy Modeling via Deep Learning based Voxel-to-voxel Transform**|在计算生物化学和生物物理学中，理解静电相互作用的作用对于阐明生物分子的结构、动力学和功能至关重要。泊松-玻尔兹曼（PB）方程是通过描述带电分子内部和周围的静电势来模拟这些相互作用的基础工具。然而，由于生物分子表面的复杂性和需要考虑可移动离子，求解PB方程带来了重大的计算挑战。虽然求解PB方程的传统数值方法是准确的，但它们的计算成本很高，并且随着系统规模的增加而扩展性较差。为了应对这些挑战，我们引入了PBNeF，这是一种新的机器学习方法，灵感来自基于神经网络的偏微分方程求解器的最新进展。我们的方法将PB方程的输入和边界静电条件转化为可学习的体素表示，使神经场变换器能够预测PB解，进而预测反应场势能。大量实验表明，与传统的PB求解器相比，PBNeF的速度提高了100倍以上，同时保持了与广义玻恩（GB）模型相当的精度。 et.al.|[2410.03927](http://arxiv.org/abs/2410.03927)|null|
|**2024-10-08**|**DressRecon: Freeform 4D Human Reconstruction from Monocular Video**|我们提出了一种从单目视频中重建时间一致的人体模型的方法，重点是极其宽松的衣服或手持物体的交互。之前在人体重建方面的工作要么局限于没有物体交互的紧身衣服，要么需要校准的多视图捕捉或个性化的模板扫描，而大规模收集这些数据成本很高。我们对高质量但灵活的重建的关键见解是，将关于关节体形状的通用人类先验（从大规模训练数据中学习）与视频特定的关节“骨骼袋”变形（通过测试时间优化适合单个视频）仔细结合。我们通过学习一个神经隐式模型来实现这一点，该模型将身体和衣服的变形作为单独的运动模型层来解开。为了捕捉服装的微妙几何形状，我们在优化过程中利用了基于图像的先验，如人体姿势、表面法线和光流。由此产生的神经场可以提取到时间一致的网格中，或进一步优化为显式3D高斯分布，以实现高保真交互式渲染。在具有高度挑战性的服装变形和物体交互的数据集上，DressReston可以产生比现有技术更高保真的3D重建。项目页面：https://jefftan969.github.io/dressrecon/ et.al.|[2409.20563](http://arxiv.org/abs/2409.20563)|null|
|**2024-09-25**|**TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans**|我们介绍了一种新的框架，该框架从单眼视频中学习全身说话的人的动态神经辐射场（NeRF）。之前的工作只代表身体姿势或面部。然而，人类通过全身进行交流，结合身体姿势、手势和面部表情。在这项工作中，我们提出了TalkinNeRF，这是一个基于NeRF的统一网络，代表了整体4D人体运动。给定一个受试者的单眼视频，我们学习身体、面部和手的相应模块，这些模块结合在一起生成最终结果。为了捕捉复杂的手指关节，我们学习了手的额外变形场。我们的多身份表示能够同时训练多个科目，以及在完全看不见的姿势下进行强大的动画。只要输入一段短视频，它也可以推广到新的身份。我们展示了最先进的性能，用于为全身说话的人类制作动画，具有精细的手部发音和面部表情。 et.al.|[2409.16666](http://arxiv.org/abs/2409.16666)|null|
|**2024-09-24**|**Generative 3D Cardiac Shape Modelling for In-Silico Trials**|我们提出了一种深度学习方法，基于将形状表示为神经有符号距离场的零级集，对合成主动脉形状进行建模和生成，该方法受一系列可训练的嵌入向量的约束，并对每个形状的几何特征进行编码。通过使神经场在采样表面点上消失并强制其空间梯度具有单位范数，在从CT图像重建的主动脉根部网格数据集上训练网络。实证结果表明，我们的模型可以高保真地表示主动脉形状。此外，通过从学习到的嵌入向量中采样，我们可以生成类似于真实患者解剖结构的新形状，可用于计算机模拟试验。 et.al.|[2409.16058](http://arxiv.org/abs/2409.16058)|null|
|**2024-09-21**|**MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors**|由于缺乏几何指导和不完美的视图相关2D先验，从单眼图像中精确重建密集和语义注释的3D网格仍然是一项具有挑战性的任务。尽管我们已经见证了隐式神经场景表示的最新进展，能够简单地从多视图图像中进行精确的2D渲染，但很少有研究仅使用单眼先验来解决3D场景理解问题。在本文中，我们提出了MOSE，这是一种神经场语义重建方法，可以将推断的图像级噪声先验提升到3D，在3D和2D空间中产生精确的语义和几何。我们方法的关键动机是利用通用类不可知的分段掩码作为指导，在训练过程中促进渲染语义的局部一致性。在语义的帮助下，我们进一步将平滑正则化应用于无纹理区域，以获得更好的几何质量，从而实现几何和语义的互惠互利。在ScanNet数据集上的实验表明，我们的MOSE在3D语义分割、2D语义分割和3D表面重建任务的所有指标上都优于相关基线。 et.al.|[2409.14019](http://arxiv.org/abs/2409.14019)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

