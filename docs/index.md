---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.09.27
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-25**|**NAS-NeRF: Generative Neural Architecture Search for Neural Radiance Fields**|神经辐射场（NeRF）能够实现高质量的新视图合成，但其高得令人望而却步的计算复杂性限制了可部署性，尤其是在资源受限的平台上。为了实现NeRF的实际使用，质量调整对于降低计算复杂性至关重要，类似于视频游戏中的可调整图形设置。然而，尽管现有的解决方案努力提高效率，但无论场景复杂程度如何，它们都使用一刀切的架构，尽管相同的架构对于简单场景可能不必要地大，但对于复杂场景则不够。因此，随着NeRF越来越广泛地用于3D可视化，需要动态优化NeRF的神经网络组件，以实现计算复杂性和合成质量特定目标之间的平衡。为了解决这一差距，我们引入了NAS NeRF：一种生成神经架构搜索策略，通过优化复杂性和性能之间的权衡，同时遵守计算预算和最低合成质量的限制，专门针对每个场景生成NeRF架构。我们在Blender合成数据集上的实验表明，与基线NeRF相比，所提出的NAS NeRF在GPU上生成的架构可以小5.74 $\times$，FLOP少4.19$\times$，速度快1.93$\times]，而SSIM不会下降。此外，我们还表明，NAS NeRF还可以实现比基线NeRF小23$\times$、FLOP少22$\times$和快4.7$ \times\的架构，平均SSIM下降5.3\%。我们工作的源代码也可在https://saeejithnair.github.io/NAS-NeRF. et.al.|[2309.14293](http://arxiv.org/abs/2309.14293)|null|
|**2023-09-22**|**Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction**|隐式神经表示为动态场景重建和渲染开辟了新的途径。尽管如此，最先进的动态神经渲染方法在很大程度上依赖于这些隐含的表示，而这些表示往往难以准确捕捉场景中对象的复杂细节。此外，隐式方法难以在一般动态场景中实现实时渲染，限制了它们在各种任务中的使用。为了解决这些问题，我们提出了一种可变形的3D高斯散射方法，该方法使用显式3D高斯重建场景，并在具有变形场的规范空间中学习高斯，以对单目动态场景进行建模。我们还引入了一种没有额外开销的平滑训练机制，以减轻真实数据集中不准确姿态对时间插值任务平滑性的影响。通过差分高斯光栅化，可变形的三维高斯不仅可以获得更高的渲染质量，而且可以获得实时渲染速度。实验表明，我们的方法在渲染质量和速度方面都显著优于现有方法，非常适合于新视图合成、时间合成和实时渲染等任务。 et.al.|[2309.13101](http://arxiv.org/abs/2309.13101)|null|
|**2023-09-22**|**NeRRF: 3D Reconstruction and View Synthesis for Transparent and Specular Objects with Neural Refractive-Reflective Fields**|神经辐射场（NeRF）已经彻底改变了基于图像的视图合成领域。然而，NeRF使用直线光线，无法处理由折射和反射引起的复杂光路变化。这阻碍了NeRF成功合成透明或镜面物体，而这些物体在现实世界的机器人和A/VR应用中无处不在。本文介绍了折射反射场。以物体轮廓为输入，我们首先利用渐进编码的行进四面体来重建非朗伯物体的几何结构，然后使用菲涅耳项在统一的框架中对物体的折射和反射效应进行建模。同时，为了实现高效、有效的抗混叠，我们提出了一种虚拟锥超采样技术。我们在真实世界和合成数据集的不同形状、背景和菲涅耳项上对我们的方法进行了基准测试。我们还对各种编辑应用程序的渲染结果进行了定性和定量的基准测试，包括材质编辑、对象替换/插入和环境照明估计。代码和数据可在https://github.com/dawning77/NeRRF. et.al.|[2309.13039](http://arxiv.org/abs/2309.13039)|**[link](https://github.com/dawning77/nerrf)**|
|**2023-09-21**|**ORTexME: Occlusion-Robust Human Shape and Pose via Temporal Average Texture and Mesh Encoding**|在单目视频的3D人体形状和姿势估计中，用有限的标记数据训练的模型不能很好地推广到具有遮挡的视频，这在野生视频中很常见。最近的人类神经渲染方法专注于由现成的人形和姿势方法初始化的新颖视图合成，具有校正初始人形的潜力。然而，现有的方法存在一些缺点，例如，在处理遮挡时出错，对不准确的人体分割敏感，以及由于非正则化的不透明度场而导致的无效损失计算。为了解决这些问题，我们引入了ORTexME，这是一种遮挡鲁棒的时间方法，它利用来自输入视频的时间信息来更好地正则化被遮挡的身体部位。虽然我们的ORTexME是基于NeRF的，但为了确定NeRF射线采样的可靠区域，我们利用我们新颖的平均纹理学习方法来学习人的平均外观，并基于平均纹理推断面具。此外，为了指导NeRF中的不透明度场更新以抑制模糊和噪声，我们建议使用人体网格。定量评估表明，我们的方法在具有挑战性的多人3DPW数据集上实现了显著的改进，其中我们的方法实现了1.8P-MPJPE的误差降低。基于SOTA渲染的方法失败了，并在同一数据集上将错误扩大到5.6。 et.al.|[2309.12183](http://arxiv.org/abs/2309.12183)|null|
|**2023-09-21**|**Fast Satellite Tensorial Radiance Field for Multi-date Satellite Imagery of Large Size**|现有的卫星图像NeRF模型速度较慢，必须输入太阳信息，并且在处理大型卫星图像方面存在局限性。作为回应，我们提出了SatensoRF，它显著加快了整个过程，同时为大尺寸卫星图像使用了更少的参数。此外，我们观察到，在神经辐射场中，朗伯表面的普遍假设不符合植物和水生元素。与传统的基于分层MLP的场景表示相比，我们选择了一种针对颜色、体积密度和辅助变量的多尺度张量分解方法来对具有镜面颜色的光场进行建模。此外，为了纠正多日期图像中的不一致性，我们结合了总变化损失来恢复密度张量场，并将该问题视为去噪任务。为了验证我们的方法，我们使用空间网多视图数据集的子集对SatensoRF进行了评估，该数据集包括多日期和单日期多视图RGB图像。我们的结果清楚地表明，SatensoRF在新颖的视图合成性能方面超过了最先进的Sat-NeRF系列。值得注意的是，SatensoRF需要更少的参数进行训练，从而提高训练和推理速度，降低计算需求。 et.al.|[2309.11767](http://arxiv.org/abs/2309.11767)|null|
|**2023-09-20**|**GenLayNeRF: Generalizable Layered Representations with 3D Model Alignment for Multi-Human View Synthesis**|由于复杂的人与人之间的遮挡，多人场景的新视图合成（NVS）带来了挑战。分层表示通过将场景划分为多层辐射场来处理复杂性，然而，它们主要局限于逐场景优化，因此效率低下。可泛化的人体视图合成方法将预先拟合的三维人体网格与图像特征相结合以达到泛化，但它们主要是针对单个人体场景设计的。另一个缺点是依赖于用于3D身体模型的参数预拟合的多步骤优化技术，该3D身体模型在稀疏视图设置中与图像不对准，从而导致合成视图中的幻觉。在这项工作中，我们提出了GenLayNeRF，这是一种可推广的分层场景表示，用于多个人类主体的自由视点渲染，不需要每场景优化和非常稀疏的视图作为输入。我们将场景划分为由3D身体网格锚定的多个人体层。然后，我们通过一个新颖的端到端可训练模块确保身体模型与输入视图的像素级对齐，该模块执行迭代参数校正，并结合多视图特征融合，以产生对齐的3D模型。对于NVS，我们提取逐点图像对齐和人锚定的特征，这些特征使用自注意和交叉注意模块进行关联和融合。我们使用基于注意力的RGB融合模块将低级别的RGB值增强到特征中。为了评估我们的方法，我们构建了两个多人视角合成数据集；DeepMultiSyn和ZJU MultiHuman。结果表明，在没有测试时间优化的情况下，我们提出的方法优于可推广的和非人类的每场景NeRF方法，同时与分层的每场景方法不相上下。 et.al.|[2309.11627](http://arxiv.org/abs/2309.11627)|null|
|**2023-09-23**|**Light Field Diffusion for Single-View Novel View Synthesis**|单视图新视图合成，即基于单个参考图像从新视点生成图像的任务，是计算机视觉中一项重要但具有挑战性的任务。近年来，去噪扩散概率模型（DDPM）由于其强大的高保真度图像生成能力而在该领域流行起来。然而，当前基于扩散的方法直接依赖于相机姿态矩阵作为观看条件，全局地和隐含地引入3D约束。这些方法可能存在从不同角度生成的图像之间的不一致性，特别是在具有复杂纹理和结构的区域中。在这项工作中，我们提出了光场扩散（LFD），这是一种基于条件扩散的单视图新视图合成模型。与以前使用相机姿态矩阵的方法不同，LFD将相机视图信息转换为光场编码，并将其与参考图像相结合。这种设计在扩散模型中引入了局部像素约束，从而促进了更好的多视图一致性。在几个数据集上的实验表明，我们的LFD可以有效地生成高保真图像，即使在复杂的区域也能保持更好的3D一致性。我们的方法可以生成比基于NeRF的模型质量更高的图像，并且我们获得的样本质量与其他基于扩散的模型类似，但只有模型大小的三分之一。 et.al.|[2309.11525](http://arxiv.org/abs/2309.11525)|null|
|**2023-09-21**|**Controllable Dynamic Appearance for Neural 3D Portraits**|神经辐射场（NeRF）的最新进展使得通过控制头部姿势、面部表情和观看方向来重建和恢复动态人像场景成为可能。然而，训练这样的模型假设变形区域的光度一致性，例如，随着头部姿势和面部表情的变化，面部变形时必须均匀照明。即使在工作室环境中，视频各帧之间的这种光度一致性也很难保持，因此，创建的可重影神经肖像在重影过程中容易出现伪影。在这项工作中，我们提出了CoDyNeRF，这是一种能够在真实世界的捕捉条件下创建完全可控的3D肖像的系统。CoDyNeRF通过规范空间中的动态外观模型来学习近似照明相关效果，该模型以预测的表面法线、面部表情和头部姿势变形为条件。表面法线预测是使用3DMM法线来指导的，3DMM法线充当人类头部法线的粗略先验，其中由于头部姿势和面部表情变化引起的刚性和非刚性变形，很难直接预测法线。仅使用智能手机拍摄的受试者短视频进行训练，我们就展示了我们的方法在具有明确的头部姿势和表情控制以及逼真照明效果的人像场景的自由视图合成方面的有效性。项目页面可在此处找到：http://shahrukhathar.github.io/2023/08/22/CoDyNeRF.html et.al.|[2309.11009](http://arxiv.org/abs/2309.11009)|null|
|**2023-09-19**|**ReShader: View-Dependent Highlights for Single Image View-Synthesis**|近年来，由于3D场景表示和图像修复技术的快速发展，从单个图像进行的新颖视图合成已经取得了重大进展。虽然目前的方法能够合成几何一致的新视图，但它们往往不能正确处理视图相关的效果。具体来说，他们合成图像中的高光通常看起来粘在表面上，这使得新颖的视图不切实际。为了解决这个主要问题，我们进行了一项关键观察，即合成新视图的过程需要改变基于新相机的像素的阴影，并将它们移动到适当的位置。因此，我们建议将视图合成过程拆分为两个独立的任务，即像素重新加载和重新定位。在重影过程中，我们以单个图像为输入，并基于新型相机调整其明暗度。然后将该重新加载的图像用作现有视图合成方法的输入，以重新定位像素并产生最终的新颖视图图像。我们建议使用神经网络来执行重新加载，并生成一大组合成输入重新加载对来训练我们的网络。我们证明，我们的方法在各种现实世界场景中产生了具有逼真运动亮点的看似新颖的视图图像。 et.al.|[2309.10689](http://arxiv.org/abs/2309.10689)|null|
|**2023-09-19**|**Locally Stylized Neural Radiance Fields**|近年来，人们对将风格化应用于参考风格图像的3D场景，特别是应用于神经辐射场（NeRF）越来越感兴趣。虽然直接在NeRF上执行风格化可以保证在任意新颖视图上的外观一致性，但引导图案从风格图像转移到NeRF场景的不同部分是一个具有挑战性的问题。在这项工作中，我们提出了一个基于局部风格转移的NeRF风格化框架。特别是，我们使用哈希网格编码来学习外观和几何组件的嵌入，并表明哈希表定义的映射允许我们在一定程度上控制风格化。然后通过优化外观分支同时保持几何体分支固定来实现样式化。为了支持局部风格转移，我们提出了一种新的损失函数，该函数利用分割网络和二分匹配来建立风格图像和从体绘制中获得的内容图像之间的区域对应关系。我们的实验表明，我们的方法通过新的视图合成产生了合理的风格化结果，同时通过操纵和定制区域对应关系具有灵活的可控性。 et.al.|[2309.10684](http://arxiv.org/abs/2309.10684)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-26**|**PHRIT: Parametric Hand Representation with Implicit Template**|我们提出了PHRIT，这是一种使用隐式模板进行参数化手网格建模的新方法，它结合了参数化网格和隐式表示的优点。我们的方法使用带符号距离场（SDF）和基于零件的形状先验来表示可变形的手部形状，利用变形场来执行变形。该模型通过以无限分辨率变形规范模板来提供高效的高保真手部重建。此外，它是完全可微的，并且可以很容易地用于手建模，因为它可以由骨架和形状潜在代码驱动。我们在多个下游任务上对PHRIT进行了评估，包括骨骼驱动的手部重建、点云形状和单视图3D重建，证明了我们的方法以最先进的性能实现了逼真和身临其境的手部建模。 et.al.|[2309.14916](http://arxiv.org/abs/2309.14916)|null|
|**2023-09-26**|**Unsupervised Reconstruction of 3D Human Pose Interactions From 2D Poses Alone**|由于单目图像中的视角模糊性，当前的无监督2D-3D人体姿态估计（HPE）方法在多人场景中不起作用。因此，我们提出了第一项研究，仅从2D姿势研究无监督多人2D-3D HPE的可行性，重点是重建人类互动。为了解决视角模糊的问题，我们通过预测摄像机相对于受试者骨盆的仰角来扩展先前的工作。这使我们能够将预测的姿势旋转到与地平面齐平的位置，同时获得个体之间3D垂直偏移的估计值。我们的方法包括独立地将每个受试者的2D姿势提升到3D，然后将它们组合到共享的3D坐标系中。然后，在缩放之前，将姿势旋转并偏移预测的仰角。这本身就使我们能够检索到他们姿势的精确3D重建。我们在CHI3D数据集上展示了我们的结果，介绍了它在无监督2D-3D姿态估计中的应用，以及三种新的定量指标，并为未来的研究建立了基准。 et.al.|[2309.14865](http://arxiv.org/abs/2309.14865)|null|
|**2023-09-26**|**Three-dimensional Tracking of a Large Number of High Dynamic Objects from Multiple Views using Current Statistical Model**|从多个视图对多个对象进行三维跟踪有着广泛的应用，特别是在需要研究对象精确轨迹的生物集群行为研究中。然而，当物体彼此相似、频繁机动和大量聚集时，存在显著的时空关联不确定性。针对这种多视图多目标三维跟踪场景，在贝叶斯跟踪的同时重构框架下，提出了一种基于统计模型的卡尔曼粒子滤波器（CSKPF）方法。CSKPF算法通过当前统计模型预测对象的状态，估计对象的状态协方差对重要粒子采样效率的影响，并通过卡尔曼滤波器抑制测量噪声。仿真实验证明，与现有的基于恒速的粒子滤波器（CVPF）方法相比，CSKPF方法可以提高跟踪的完整性、连续性和精度。对果蝇集群的实际实验也证实了CSKPF方法的有效性。 et.al.|[2309.14820](http://arxiv.org/abs/2309.14820)|null|
|**2023-09-26**|**3D Density-Gradient based Edge Detection on Neural Radiance Fields (NeRFs) for Geometric Reconstruction**|从神经辐射场（NeRF）生成几何三维重建是一个非常有趣的问题。然而，基于密度值的准确和完整的重建是具有挑战性的。网络输出取决于输入数据、NeRF网络配置和超参数。因此，密度值的直接使用，例如通过全局密度阈值的过滤，通常需要经验调查。在密度从非物体区域增加到物体区域的假设下，相对值的密度梯度的利用是明显的。由于密度表示与位置相关的参数，因此可以各向异性地处理它，因此对体素化3D密度场的处理是合理的。在这方面，我们处理基于密度梯度的几何3D重建，而梯度来自一阶和二阶导数的3D边缘检测滤波器，即Sobel、Canny和拉普拉斯高斯。梯度依赖于所有方向上的相对相邻密度值，因此与绝对大小无关。因此，梯度滤波器能够提取宽密度范围的边缘，几乎独立于假设和经验调查。我们的方法证明了在物体表面以高几何精度和显著的物体完整性实现几何三维重建的能力。值得注意的是，Canny滤波器有效地消除了间隙，提供了均匀的点密度，并在整个场景的正确性和完整性之间取得了良好的平衡。 et.al.|[2309.14800](http://arxiv.org/abs/2309.14800)|null|
|**2023-09-24**|**Deep learning based workflow for accelerated industrial X-ray Computed Tomography**|X射线计算机断层扫描（XCT）是对添加制造的金属部件进行高分辨率无损表征的重要工具。金属部件的XCT重建可能具有束硬化伪影，如杯状和条纹，这使得对缺陷和缺陷的可靠检测具有挑战性。此外，基于使用分析重建算法的传统工作流程需要大量投影才能准确表征，这导致测量时间更长，并阻碍了XCT用于在线检测。在本文中，我们介绍了一种新的工作流程，该工作流程基于使用两个神经网络，从单一材料金属零件的稀疏视图XCT扫描中获得高质量的加速重建。第一个网络使用完全连接的层实现，有助于减少BH在投影数据中的影响，而无需任何校准或了解组件材料。第二个网络是卷积神经网络，它将低质量的分析三维重建映射为高质量的重建。使用实验数据，我们证明了我们的方法在几种合金中稳健地推广，并适用于一系列稀疏性水平，而无需重新训练网络，从而实现准确快速的工业XCT检查。 et.al.|[2309.14371](http://arxiv.org/abs/2309.14371)|null|
|**2023-09-25**|**A Novel Approach for Effective Multi-View Clustering with Information-Theoretic Perspective**|多视图集群（MVC）是一种流行的技术，用于使用各种数据源来提高集群性能。然而，现有的方法主要侧重于获取一致的信息，而往往忽略了跨多个视图的冗余问题。本研究提出了一种新的方法，称为充分多视图聚类（SUMVC），从信息论的角度考察了多视图聚类框架。我们提出的方法由两部分组成。首先，我们开发了一种简单可靠的多视图聚类方法SCMVC（简单一致多视图聚类），该方法采用变分分析来生成一致信息。其次，我们提出了一个充分的表示下界，以增强视图之间的一致性信息并最大限度地减少不必要的信息。所提出的SUMVC方法为多视图聚类问题提供了一种很有前途的解决方案，并为分析多视图数据提供了一个新的视角。为了验证我们模型的有效性，我们基于贝叶斯错误率进行了理论分析，并在多个多视图数据集上进行了实验，证明了SUMVC的优越性能。 et.al.|[2309.13989](http://arxiv.org/abs/2309.13989)|null|
|**2023-09-24**|**Federated Deep Multi-View Clustering with Global Self-Supervision**|联合多视图集群有可能从分布在多个设备上的数据中学习全局集群模型。在这种情况下，标签信息是未知的，必须保护数据隐私，这导致了两大挑战。首先，不同客户端上的视图通常具有特征异构性，挖掘它们互补的集群信息并非易事。其次，在分布式环境中存储和使用来自多个客户端的数据会导致多视图数据的不完整性。为了应对这些挑战，我们提出了一种新的联邦深度多视图聚类方法，该方法可以从多个客户端挖掘互补的集群结构，同时处理数据的不完整性和隐私问题。具体来说，在服务器环境中，我们提出了样本对齐和数据扩展技术来探索多个视图的互补集群结构。然后，服务器将全局原型和全局伪标签作为全局自监督信息分发给每个客户端。在客户端环境中，多个客户端使用全局自监督信息和深度自动编码器来学习特定于视图的集群分配和嵌入特征，然后将其上传到服务器以细化全局自监督的信息。最后，我们广泛的实验结果表明，我们提出的方法在解决分布式环境中不完整多视图数据的挑战方面表现出优异的性能。 et.al.|[2309.13697](http://arxiv.org/abs/2309.13697)|null|
|**2023-09-23**|**MP-MVS: Multi-Scale Windows PatchMatch and Planar Prior Multi-View Stereo**|在提高基于多视图立体（MVS）的3D重建的准确性方面已经取得了重大进展。然而，具有不稳定光度一致性的无纹理区域通常仍不完全重建。在本文中，我们提出了一种弹性和有效的多视图立体方法（MP-MVS）。我们设计了一个多尺度窗口PatchMatch（mPM）来获得可靠的无纹理区域深度。与其他多尺度方法相比，后者速度更快，可以很容易地扩展到基于PatchMatch的MVS方法。随后，我们通过将采样限制在遥远的区域来改进现有的棋盘采样方案，这可以有效地提高空间传播的效率，同时减少异常值的生成。最后，我们介绍并改进了ACMP的平面先验辅助PatchMatch。我们不依赖光度一致性，而是利用多视图之间的几何一致性信息来选择可靠的三角顶点。该策略可以获得更精确的平面先验模型来校正光度一致性测量。我们的方法已经在ETH3D高分辨率多视图基准上用几种最先进的方法进行了测试。结果表明，我们的方法可以达到最先进的水平。相关代码可访问https://github.com/RongxuanTan/MP-MVS. et.al.|[2309.13294](http://arxiv.org/abs/2309.13294)|**[link](https://github.com/rongxuantan/mp-mvs)**|
|**2023-09-22**|**NeRRF: 3D Reconstruction and View Synthesis for Transparent and Specular Objects with Neural Refractive-Reflective Fields**|神经辐射场（NeRF）已经彻底改变了基于图像的视图合成领域。然而，NeRF使用直线光线，无法处理由折射和反射引起的复杂光路变化。这阻碍了NeRF成功合成透明或镜面物体，而这些物体在现实世界的机器人和A/VR应用中无处不在。本文介绍了折射反射场。以物体轮廓为输入，我们首先利用渐进编码的行进四面体来重建非朗伯物体的几何结构，然后使用菲涅耳项在统一的框架中对物体的折射和反射效应进行建模。同时，为了实现高效、有效的抗混叠，我们提出了一种虚拟锥超采样技术。我们在真实世界和合成数据集的不同形状、背景和菲涅耳项上对我们的方法进行了基准测试。我们还对各种编辑应用程序的渲染结果进行了定性和定量的基准测试，包括材质编辑、对象替换/插入和环境照明估计。代码和数据可在https://github.com/dawning77/NeRRF. et.al.|[2309.13039](http://arxiv.org/abs/2309.13039)|**[link](https://github.com/dawning77/nerrf)**|
|**2023-09-22**|**Deep3DSketch+: Rapid 3D Modeling from Single Free-hand Sketches**|AR/VR的快速发展给3D内容带来了巨大的需求。虽然广泛使用的计算机辅助设计（CAD）方法需要耗时且劳动密集的建模过程，但基于草图的三维建模作为计算机与人交互的自然形式提供了一种潜在的解决方案。然而，草图的稀疏性和模糊性使得生成反映创作者想法的高保真度内容具有挑战性。通常需要从多个视图精确绘制或战略性分步绘制来应对挑战，但对新手用户来说并不友好。在这项工作中，我们介绍了一种新的端到端方法Deep3DSketch+，该方法只使用一个徒手草图进行三维建模，而无需输入多个草图或视图信息。具体而言，我们介绍了一种用于实时高效推理的轻量级生成网络，以及一种具有结构感知的对抗性训练方法，该方法使用笔划增强模块（SEM）来捕获结构信息，以便于学习逼真和精细的形状结构，从而实现高保真性能。大量的实验证明了我们的方法在合成和真实数据集上具有最先进的（SOTA）性能的有效性。 et.al.|[2309.13006](http://arxiv.org/abs/2309.13006)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-26**|**Generating Visual Scenes from Touch**|一项新兴的工作试图通过触摸产生看似合理的图像。然而，现有的方法只解决视觉触觉合成问题的狭窄方面，并且明显落后于其他领域的跨模态合成方法的质量。我们利用潜在扩散的最新进展，创建了一个从触觉信号合成图像的模型（反之亦然），并将其应用于许多视觉触觉合成任务。使用该模型，我们在触觉驱动的风格化问题上显著优于先前的工作，即操纵图像以匹配触摸信号，并且我们是第一个在没有关于场景的额外信息来源的情况下成功地从触摸生成图像的人。我们还成功地使用我们的模型来解决两个新的合成问题：生成不包含触摸传感器或握着它的手的图像，以及根据图像的反射率和触摸来估计图像的阴影。 et.al.|[2309.15117](http://arxiv.org/abs/2309.15117)|null|
|**2023-09-26**|**Solutions with positive components to quasilinear parabolic systems**|我们得到了一般拟线性抛物型问题begin{方程*}\partial_tu^k=\sum_{i，j=1}^nA_{ij}（t，x，u）\partial^2_{x_ix_j}解存在唯一性的充分条件！u^k+\sum_｛i=1｝^n b_i（t，x，u，\partial_xu）\partial_｛x_i｝u^k+\，c^k（t，x，u，\partial_x u），\\u^k（0，x）=\varphi^k（x），\\u ^k（t，\，\cdot\，）=0，\quad\text｛on｝\partial\mathbb F，k=1,2，\dots，m，\quad x\ in \mathbb F，\；t> 0.\end｛方程*｝这里， $\mathbb F$是有界域或$\mathbbR^n$；在后一种情况下，我们忽略边界条件。我们将我们的结果应用于研究具有扩散的Lotka-Volterra竞争模型的分量非负解的存在性和渐近性。特别地，我们展示了系数在空间和时间上变化的2-类Lotka-Volterra模型的解的收敛性，如$t\to+\infty$ ，到相关椭圆问题的解。 et.al.|[2309.15114](http://arxiv.org/abs/2309.15114)|null|
|**2023-09-26**|**LAVIE: High-Quality Video Generation with Cascaded Latent Diffusion Models**|这项工作旨在通过利用预先训练的文本到图像（T2I）模型作为基础，学习高质量的文本到视频（T2V）生成模型。同时a）完成视觉逼真和时间连贯视频的合成，同时b）保持预训练的T2I模型的强大创造性生成特性，这是一项非常理想但具有挑战性的任务。为此，我们提出了一种集成视频生成框架LaVie，它在级联的视频潜在扩散模型上运行，包括基础T2V模型、时间插值模型和视频超分辨率模型。我们的关键见解有两个方面：1）我们揭示了简单的时间自注意的结合，再加上旋转位置编码，充分捕捉了视频数据中固有的时间相关性。2） 此外，我们验证了联合图像视频微调过程在产生高质量和创造性结果方面发挥着关键作用。为了提高LaVie的性能，我们提供了一个名为Vimeo25M的全面而多样的视频数据集，由2500万个文本视频对组成，优先考虑质量、多样性和美学吸引力。大量实验表明，LaVie在数量和质量上都达到了最先进的性能。此外，我们还展示了预先训练的LaVie模型在各种长视频生成和个性化视频合成应用中的多功能性。 et.al.|[2309.15103](http://arxiv.org/abs/2309.15103)|null|
|**2023-09-26**|**The ATM implied skew in the ADO-Heston model**|在本文中，类似于[P.Carr，A.Itkin，2019]，我们构造了粗糙类赫斯顿波动率模型的另一个马尔可夫近似——ADO-Heston模型。该模型的特征函数（CF）是在风险中性和真实度量下导出的，它是一个不稳定的三维PDE，一些系数是时间 $t$和赫斯特指数$H$的函数。为了复制市场隐含偏斜的已知行为，我们对风险的市场价格进行了明智的选择，然后找到了日志价格和ATM隐含偏斜的CF的闭合形式表达式。基于所提供的例子，我们声称ADO-Heston模型（它是一个纯扩散模型，但具有方差过程的随机均值回归速度，或粗糙Heston模型的Markovian近似）能够（近似地）在小$T$下再现香草隐含偏斜的已知行为。我们得出结论，我们的隐含波动率偏斜曲线$｛\cal S｝（T）\ propto a（H）T^｛b\cdot（H-1/2）｝，\，b=const$的行为与自$b\ne 1$以来的粗略波动率模型中的行为并不完全相同，但似乎对于$T$的所有实际值来说都足够接近。因此，所提出的马尔可夫模型能够复制相应的粗略波动率模型的一些性质。对前向启动选项进行了类似的分析，我们发现，当$t\到s$时，任何$s>t$ 的前向启动期权的ATM隐含偏斜都可能爆炸。然而，这一结果与[E.Alos，D.G.Lorite，2021]的观察结果相矛盾，即马尔可夫近似无法捕捉这种行为，因此仍然是哪个更接近现实的问题。 et.al.|[2309.15044](http://arxiv.org/abs/2309.15044)|null|
|**2023-09-26**|**Asymptotic freeness in tracial ultraproducts**|我们证明了迹超积von Neumann代数的新的渐近自由度结果。特别地，我们证明了当 $M=M_1\ast M_2$是von Neumann代数的无迹积，$u1\In\mathscr u（M_1）$，$u2\In\math scr u）（M_2）$是Haar酉元时，相对交换子$\｛u1\｝'\cap M^｛\mathcal u｝$和$\{u2\｝'\cap M^{\mathcal u}$在超积$M^{/mathcal u}$中是自由独立的。我们的证明依赖于Mei-Ricard关于迹合并自由积von Neumann代数中某些傅立叶乘子的$\算子名称｛L｝^p$-有界性（对于所有$1<p<+\infty$）的结果[MR16]。我们导出了两个应用程序。首先，我们获得了tracil合并自由产物的一般吸收结果，该结果恢复了以前的几个最大可适性/伽玛吸收结果。其次，我们证明了一个新的提升定理，该定理与我们的渐近自由度结果和Chifan-Ioana Kunnawalkam Elayavalli的最近构造[CIKE22]相结合，提供了不具有性质Gamma并且不初等等价于扩散迹von Neumann代数的任何自由积的${\rmII_1}$ 因子的第一个例子。 et.al.|[2309.15029](http://arxiv.org/abs/2309.15029)|null|
|**2023-09-26**|**FEC: Three Finetuning-free Methods to Enhance Consistency for Real Image Editing**|文本条件图像编辑是最近出现的一项非常有用的任务，具有不可估量的潜力。目前大多数的真实图像编辑方法首先需要完成图像的重建，然后在重建的基础上通过各种方法进行编辑。大多数方法使用DDIM反演进行重建，然而，DDIM反演往往无法保证重建性能，即无法产生保留原始图像内容的结果。为了解决重建失败的问题，我们提出了FEC，它由三种采样方法组成，每种方法都针对不同的编辑类型和设置而设计。我们的三种FEC方法在图像编辑任务中实现了两个重要目标：1）确保重建成功，即采样以获得保留原始真实图像纹理和特征的生成结果。2） 这些采样方法可以与许多编辑方法相结合，极大地提高了这些编辑方法完成各种编辑任务的性能。此外，我们的采样方法都不需要对扩散模型进行微调，也不需要在大规模数据集上进行耗时的训练。因此，可以显著降低时间成本以及计算机存储器和计算的使用。 et.al.|[2309.14934](http://arxiv.org/abs/2309.14934)|null|
|**2023-09-26**|**ITEM3D: Illumination-Aware Directional Texture Editing for 3D Models**|纹理编辑是三维建模中的一项关键任务，它允许用户自动操纵三维模型的表面材质。然而，3D模型固有的复杂性和模糊的文本描述导致了这项任务的挑战。为了应对这一挑战，我们提出了ITEM3D，这是一种用于根据文本提示自动编辑3D对象的照明感知模型。ITEM3D利用扩散模型和可微分渲染，将渲染图像作为文本和3D表示的桥梁，并进一步优化解纠缠的纹理和环境图。以前的方法采用绝对编辑方向，即分数蒸馏采样（SDS）作为优化目标，不幸的是，这导致了嘈杂的外观和文本不一致。为了解决文本歧义带来的问题，我们引入了一个相对编辑方向，一个由源文本和目标文本之间的噪声差异定义的优化目标，以释放文本和图像之间的语义歧义。此外，我们在优化过程中逐渐调整方向，以进一步解决纹理域中的意外偏差。定性和定量实验表明，我们的ITEM3D在各种三维物体上都优于最先进的方法。我们还执行文本引导的重新照明，以显示对照明的明确控制。 et.al.|[2309.14872](http://arxiv.org/abs/2309.14872)|null|
|**2023-09-26**|**Navigating Text-To-Image Customization:From LyCORIS Fine-Tuning to Model Evaluation**|文本到图像生成模型因其从文本提示生成高保真图像的能力而受到极大关注。其中，Stable Diffusion是这个快速增长的领域中领先的开源模型。然而，微调这些模型的复杂性带来了从新方法集成到系统评估的多重挑战。针对这些问题，本文介绍了LyCORIS（Lora beYond Conventional methods，Other Rank adaptation Implementations for Stable diffusion）[https://github.com/KohakuBlueleaf/LyCORIS]，一个开源库，为稳定扩散提供了广泛的微调方法选择。此外，我们还为各种微调技术的系统评估提供了一个全面的框架。该框架采用了一套不同的指标，深入研究了微调的多个方面，包括超参数调整和不同概念类别的不同提示类型的评估。通过这种全面的方法，我们的工作为微调参数的细微影响提供了重要的见解，弥合了最先进的研究和实际应用之间的差距。 et.al.|[2309.14859](http://arxiv.org/abs/2309.14859)|**[link](https://github.com/kohakublueleaf/lycoris)**|
|**2023-09-26**|**On a class of solvable stationary non equilibrium states for mass exchange models**|我们考虑在每个站点上具有任意正质量的模型族，并与最近的邻居站点随机交换任意质量。我们仅限于扩散模型的情况。我们确定了一类可逆模型，其乘积不变测度是已知的，并且满足梯度条件，这样我们就可以显式地计算与扩散流体动力学重定标相关的输运系数。基于宏观波动理论，我们认为，仅根据输运系数和边界源的细节，就可以通过求解Hamilton-Jacobi方程来计算平稳非平衡状态的大偏差率函数。因此，我们能够识别一类具有传输系数的模型，对于该模型，Hamilton-Jacobi方程确实可以求解。我们在广义零范围模型的情况下给出了一个完整的刻画，并讨论了其他几种情况。对于广义零范围模型，我们确定了一类离散模型，其模平凡扩展与\cite{FG}中讨论的类一致，以及一类连续动力学，其与\cite｛FFG｝中的类一致。通过讨论，我们得到了求解CC中离散方程的可逆厌世过程的完整特征。 et.al.|[2309.14836](http://arxiv.org/abs/2309.14836)|null|
|**2023-09-26**|**Identifying and abating copper foil impurities to optimize graphene growth**|铜箔杂质阻碍了通过化学气相沉积（CVD）大规模生产高质量石墨烯。在这里，我们对CVD工艺后铜表面这些不可避免的污染物的来源进行了彻底的研究。我们确定了杂质的两个不同来源。第一种类型是本征杂质，源于铜箔的制造过程，在任何高温处理之前已经存在于表面，或者埋在大量铜箔中。在高温处理过程中，埋入的杂质向铜表面扩散并沉淀。第二个来源是外部的：石英管产生的二氧化硅污染也沉淀在铜上。通过对铜箔样品进行适当的限制，外来二氧化硅污染的问题很容易得到解决。固有杂质更难去除，因为它们看起来分散在整个箔中。然而，事实证明，电抛光在显著减少该问题方面特别有效。 et.al.|[2309.14811](http://arxiv.org/abs/2309.14811)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-22**|**NOC: High-Quality Neural Object Cloning with 3D Lifting of Segment Anything**|随着神经领域的发展，从多视图输入重建目标物体的3D模型最近越来越受到社会的关注。现有的方法通常学习整个场景的神经场，而如何在飞行中重建用户指示的特定对象仍在探索之中。考虑到分段任意模型（SAM）在分割任何2D图像方面都显示出了有效性，本文提出了一种新的高质量3D对象重建方法——神经对象克隆（NOC），它从两个方面利用了神经场和SAM的优点。首先，为了将目标对象从场景中分离出来，我们提出了一种新的策略，将SAM的多视图2D分割掩模提升到一个统一的3D变化场中。然后，3D变化场被投影到2D空间中，并生成SAM的新提示。这个过程是迭代的，直到收敛，以将目标对象从场景中分离出来。然后，除了2D掩模之外，我们进一步将SAM编码器的2D特征提升到3D SAM场中，以提高目标对象的重建质量。NOC将SAM的2D掩模和特征提升到3D神经场中，用于高质量的目标对象重建。我们在几个基准数据集上进行了详细的实验，以证明我们的方法的优势。代码将被发布。 et.al.|[2309.12790](http://arxiv.org/abs/2309.12790)|null|
|**2023-09-15**|**Breathing New Life into 3D Assets with Generative Repainting**|基于扩散的文本到图像模型引发了视觉社区、艺术家和内容创作者的巨大关注。这些模型的广泛采用是由于世代质量的显著提高以及对各种模式的有效调节，而不仅仅是文本。然而，将这些2D模型的丰富生成先验提升到3D中是具有挑战性的。最近的工作提出了由扩散模型和神经场的纠缠提供动力的各种管道。我们探索了预训练的2D扩散模型和标准3D神经辐射场作为独立工具的威力，并展示了它们以非学习方式协同工作的能力。这种模块化具有易于部分升级的内在优势，这在这样一个快节奏的领域中成为了一个重要的特性。我们的管道接受任何遗留的可渲染几何体，如纹理或无纹理网格，协调2D生成细化和3D一致性强制工具之间的交互，并以多种格式输出绘制的输入几何体。我们对ShapeNetSem数据集中的广泛对象和类别进行了大规模研究，并从定性和定量两个方面展示了我们方法的优势。项目页面：https://www.obukhov.ai/repainting_3d_assets et.al.|[2309.08523](http://arxiv.org/abs/2309.08523)|**[link](https://github.com/kongdai123/repainting_3d_assets)**|
|**2023-09-14**|**Neural Field Representations of Articulated Objects for Robotic Manipulation Planning**|传统的操作规划方法依赖于环境的显式几何模型来将给定任务公式化为优化问题。然而，从原始传感器输入推断准确的模型本身就是一个难题，尤其是对于铰接物体（例如壁橱、抽屉）。在本文中，我们提出了一种关节对象的神经场表示（NFR），可以直接从图像中进行操作规划。具体来说，在拍摄了一个新的关节物体的几张照片后，我们可以向前模拟它可能的运动，因此，可以直接使用该神经模型进行轨迹优化规划。此外，这种表示可以用于形状重建、语义分割和图像渲染，这在训练和泛化过程中提供了强大的监督信号。我们表明，我们的模型仅在合成图像上训练，能够在模拟和真实图像中为同类看不见的物体提取有意义的表示。此外，我们证明了该表示能够直接从图像中对现实世界中的关节物体进行机器人操作。 et.al.|[2309.07620](http://arxiv.org/abs/2309.07620)|null|
|**2023-09-13**|**Generalizable Neural Fields as Partially Observed Neural Processes**|神经场将信号表示为由神经网络参数化的函数，是传统离散矢量或基于网格的表示的一种很有前途的替代方案。与离散表示相比，神经表示既能很好地扩展分辨率，又是连续的，并且可以是多次可微的。然而，给定我们想要表示的信号数据集，必须为每个信号优化单独的神经场是低效的，并且不能利用信号之间的共享信息或结构。现有的泛化方法将其视为元学习问题，并采用基于梯度的元学习来学习初始化，然后通过测试时间优化对初始化进行微调，或者学习超网络来产生神经场的权重。相反，我们提出了一种新的范式，将神经表征的大规模训练视为部分观察到的神经过程框架的一部分，并利用神经过程算法来解决这一任务。我们证明，这种方法优于最先进的基于梯度的元学习方法和超网络方法。 et.al.|[2309.06660](http://arxiv.org/abs/2309.06660)|null|
|**2023-09-08**|**Single View Refractive Index Tomography with Neural Fields**|折射率层析成像是一个反问题，我们试图从2D投影图像测量中重建场景的3D折射场。折射场本身是不可见的，而是影响光线在空间中传播时路径的连续弯曲。折射场出现在各种各样的科学应用中，从显微镜中的半透明细胞样本到弯曲来自遥远星系的光的暗物质场。这个问题带来了一个独特的挑战，因为折射场直接影响光的路径，使其恢复成为一个非线性问题。此外，与传统的层析成像相比，我们试图通过利用散射在整个介质中的光源的知识，仅从单个视点使用投影图像来恢复折射场。在这项工作中，我们介绍了一种使用基于坐标的神经网络对场景中潜在的连续折射场进行建模的方法。然后，我们使用射线三维空间曲率的显式建模来优化该网络的参数，通过综合分析方法重建折射场。通过在模拟中恢复折射场，并分析光源分布对恢复的影响，证明了我们方法的有效性。然后，我们在模拟暗物质映射问题上测试了我们的方法，在该问题中，我们恢复了真实模拟暗物质分布下的折射场。 et.al.|[2309.04437](http://arxiv.org/abs/2309.04437)|null|
|**2023-09-07**|**BluNF: Blueprint Neural Field**|神经辐射场（NeRF）彻底改变了场景新颖的视图合成，提供了视觉逼真、精确和稳健的隐式重建。虽然最近的方法允许NeRF编辑，例如对象删除、3D形状修改或材料特性操纵，但在这种编辑之前的手动注释使该过程变得乏味。此外，传统的2D交互工具缺乏对3D空间的准确感知，阻碍了对场景的精确操作和编辑。在本文中，我们介绍了一种新的方法，称为蓝图神经场（BluNF），以解决这些编辑问题。BluNF提供了一个强大且用户友好的2D蓝图，实现了直观的场景编辑。通过利用隐式神经表示，BluNF使用先前的语义和深度信息构建场景的蓝图。生成的蓝图可以轻松编辑和操作NeRF表示。我们通过直观的点击和更改机制展示了BluNF的可编辑性，实现了3D操作，如遮罩、外观修改和对象移除。我们的方法对视觉内容创作做出了重大贡献，为该领域的进一步研究铺平了道路。 et.al.|[2309.03933](http://arxiv.org/abs/2309.03933)|null|
|**2023-09-07**|**SimNP: Learning Self-Similarity Priors Between Neural Points**|用于3D对象重建的现有神经场表示要么（1）利用对象级表示，但由于对全局潜在代码的限制而遭受低质量细节，要么（2）能够完美地重建观测，但未能利用对象级先验知识来推断未观察到的区域。我们提出了一种学习类别级自相似性的方法SimNP，它通过将神经点辐射场与类别级自类似性表示相连接，结合了两个世界的优点。我们的贡献是双重的。（1） 我们利用相干点云的概念设计了第一个类别级别的神经点表示。由此产生的神经点辐射场为局部支持的对象区域存储了高级别的细节。（2） 我们了解了如何以无约束和无监督的方式在神经点之间共享信息，这允许在重建过程中根据给定的观测值导出对象的未观察区域。我们表明，SimNP在重建对称的看不见物体区域方面优于以前的方法，超过了建立在类别级或像素对齐辐射场上的方法，同时提供了实例之间的语义对应 et.al.|[2309.03809](http://arxiv.org/abs/2309.03809)|null|
|**2023-09-06**|**CoNeS: Conditional neural fields with shift modulation for multi-sequence MRI translation**|多序列磁共振成像（MRI）在现代临床研究和深度学习研究中都有广泛的应用。然而，在临床实践中，由于患者的不同图像采集协议或造影剂禁忌症，经常会出现一个或多个MRI序列缺失的情况，这限制了在多序列数据上训练的深度学习模型的使用。一种很有前途的方法是利用生成模型来合成缺失的序列，这可以作为替代获取。解决这一问题的最先进方法是基于卷积神经网络（CNN），该网络通常存在频谱偏差，导致高频精细细节的重建较差。在本文中，我们提出了具有移位调制的条件神经场（CoNeS），这是一种以体素坐标为输入并学习用于多序列MRI平移的目标图像的表示的模型。所提出的模型使用多层感知器（MLP）代替CNN作为像素到像素映射的解码器。因此，每个目标图像被表示为神经场，该神经场通过利用学习的潜码的移位调制而被调节在源图像上。在BraTS 2018和前庭神经鞘瘤患者的内部临床数据集上进行的实验表明，所提出的方法在视觉和定量上都优于最先进的多序列MRI翻译方法。此外，我们进行了光谱分析，表明CoNeS能够克服传统CNN模型中常见的光谱偏差问题。为了进一步评估合成图像在临床下游任务中的使用，我们在推理时使用合成图像测试了分割网络。 et.al.|[2309.03320](http://arxiv.org/abs/2309.03320)|**[link](https://github.com/cyjdswx/cones)**|
|**2023-09-06**|**ResFields: Residual Neural Fields for Spatiotemporal Signals**|神经场是一类被训练来表示高频信号的神经网络，近年来由于其在复杂三维数据建模方面的出色性能，特别是通过单个多层感知器（MLP）的大神经符号距离（SDFs）或辐射场（NeRFs），而受到了极大的关注。然而，尽管用MLP表示信号的能力和简单性很强，但由于MLP的容量有限，这些方法在建模大而复杂的时间信号时仍然面临挑战。在本文中，我们提出了一种有效的方法来解决这一限制，将时间残差层纳入神经场，称为ResFields，这是一类专门设计用于有效表示复杂时间信号的新型网络。我们对ResFields的性质进行了全面的分析，并提出了一种矩阵分解技术来减少可训练参数的数量并增强泛化能力。重要的是，我们的公式与现有技术无缝集成，并在各种具有挑战性的任务中持续改进结果：2D视频近似、通过时间SDF的动态形状建模和动态NeRF重建。最后，我们通过展示ResFields在从轻量级捕捉系统的稀疏感官输入捕捉动态3D场景方面的有效性，展示了它的实用性。 et.al.|[2309.03160](http://arxiv.org/abs/2309.03160)|**[link](https://github.com/markomih/ResFields)**|
|**2023-09-01**|**GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields**|开发能够在非结构化现实世界环境中通过视觉观察执行各种操作任务的代理是机器人技术中的一个长期问题。为了实现这一目标，机器人需要对场景的3D结构和语义有全面的了解。在这项工作中，我们提出了 $\textbf｛GNFactor｝$，一种用于多任务机器人操作的视觉行为克隆代理，具有$\textbf｛G｝$通用$\textbf｛N｝$eural功能$\textbf｛F｝$字段。GNFactor联合优化了作为重建模块的可推广神经场（GNF）和作为决策模块的感知转换器，利用了共享的深度3D体素表示。为了在3D中结合语义，重建模块利用视觉语言基础模型（$\textit｛例如｝$ ，Stable Diffusion）将丰富的语义信息提取到深度3D体素中。我们在3个真实机器人任务中评估了GNFactor，并在10个RLBench任务中进行了详细的消融，演示次数有限。我们观察到GNFactor在可见和不可见任务中比当前最先进的方法有了实质性的改进，证明了GNFactor强大的泛化能力。我们的项目网站是https://yanjieze.com/GNFactor/。 et.al.|[2308.16891](http://arxiv.org/abs/2308.16891)|**[link](https://github.com/YanjieZe/GNFactor)**|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

