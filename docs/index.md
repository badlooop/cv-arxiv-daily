---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.10.30
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-29**|**PF3plat: Pose-Free Feed-Forward 3D Gaussian Splatting**|我们考虑了在单个前馈中从非聚焦图像合成新视图的问题。我们的框架利用了3DGS的快速、可扩展性和高质量的3D重建和视图合成功能，我们进一步扩展了它，提供了一种实用的解决方案，放宽了常见的假设，如密集的图像视图、精确的相机姿态和大量的图像重叠。我们通过识别和解决使用像素对齐的3DGS所带来的独特挑战来实现这一目标：不同视图中未对齐的3D高斯分布会导致噪声或稀疏梯度，从而破坏训练的稳定性并阻碍收敛，尤其是在不满足上述假设的情况下。为了减轻这种情况，我们采用预训练的单目深度估计和视觉对应模型来实现3D高斯的粗略对齐。然后，我们引入了轻量级、可学习的模块，从粗对准中细化深度和姿态估计，提高了3D重建的质量和新颖的视图合成。此外，利用精细估计来估计几何置信度得分，该得分评估3D高斯中心的可靠性，并相应地调节高斯参数的预测。对大规模真实世界数据集的广泛评估表明，PF3plat在所有基准测试中都达到了新的最先进水平，并得到了验证我们设计选择的全面消融研究的支持。 et.al.|[2410.22128](http://arxiv.org/abs/2410.22128)|null|
|**2024-10-29**|**ActiveSplat: High-Fidelity Scene Reconstruction through Active Gaussian Splatting**|我们提出了ActivePlat，这是一个利用高斯飞溅的自主高保真重建系统。该系统利用高效逼真的渲染，为在线映射、视点选择和路径规划建立了一个统一的框架。ActivePlat的关键是一种混合地图表示，它集成了关于环境的密集信息和工作空间的稀疏抽象。因此，该系统利用稀疏拓扑进行高效的视点采样和路径规划，同时利用视图相关的密集预测进行视点选择，以有希望的准确性和完整性促进高效决策。在预算有限的情况下，采用基于拓扑图的分层规划策略来减少重复轨迹并提高局部粒度，确保通过逼真的视图合成进行高保真重建。广泛的实验和消融研究验证了所提出方法在重建精度、数据覆盖率和勘探效率方面的有效性。项目页面：https://li-yuetao.github.io/ActiveSplat/. et.al.|[2410.21955](http://arxiv.org/abs/2410.21955)|null|
|**2024-10-25**|**ArCSEM: Artistic Colorization of SEM Images via Gaussian Splatting**|扫描电子显微镜（SEM）因其分析微观物体表面结构的能力而广为人知，能够捕获高度详细但仅灰度的图像。为了创建更具表现力和逼真的插图，这些图像通常由艺术家在图像编辑软件的支持下手动着色。当扫描对象的多个图像需要着色时，这项任务变得非常费力。我们建议通过使用微观场景的底层3D结构将颜色信息从一个彩色视图传播到所有捕获的图像来促进这一过程。我们探索了几种场景表示技术，实现了SEM场景的高质量彩色新颖视图合成。与之前的工作相比，在获取3D表示时不涉及人工干预或标签。这使艺术家能够为序列的单个或几个视图着色，并自动检索全彩色的场景或视频。项目页面：https://ronly2460.github.io/ArCSEM et.al.|[2410.21310](http://arxiv.org/abs/2410.21310)|null|
|**2024-10-27**|**Normal-GS: 3D Gaussian Splatting with Normal-Involved Rendering**|渲染和重建是计算机视觉和图形学中的一个长期课题。同时实现高渲染质量和精确的几何图形是一个挑战。3D高斯散斑（3DGS）的最新进展实现了实时速度的高保真新颖视图合成。然而，3D高斯基元的噪声和离散特性阻碍了精确的表面估计。由于基于3DGS的方法中法向量和渲染管道之间的根本脱节，之前对3D高斯法线进行正则化的尝试往往会降低渲染质量。因此，我们引入了Normal GS，这是一种将法向量集成到3DGS渲染管道中的新方法。核心思想是使用基于物理的渲染方程对法线和入射光之间的相互作用进行建模。我们的方法将表面颜色重新参数化为法线和设计的集成方向照明矢量（IDIV）的乘积。为了优化内存使用并简化优化，我们采用基于锚点的3DGS来隐式编码本地共享的IDIV。此外，Normal GS利用优化的法线和集成方向编码（IDE）来精确地模拟镜面反射效果，从而提高渲染质量和曲面法线精度。大量实验表明，Normal GS在获得准确的表面法线并保持实时渲染性能的同时，实现了接近最先进的视觉质量。 et.al.|[2410.20593](http://arxiv.org/abs/2410.20593)|null|
|**2024-10-27**|**GUMBEL-NERF: Representing Unseen Objects as Part-Compositional Neural Radiance Fields**|我们提出了Gumbel-NeRF，这是一种混合了专家（MoE）神经辐射场（NeRF）模型和事后专家选择机制的模型，用于合成看不见物体的新视图。先前的研究表明，MoE结构提供了由许多对象组成的给定大规模场景的高质量表示。然而，我们观察到，当应用于从一个/几个镜头输入对看不见的物体进行新颖的视图合成的任务时，这种MoE-NeRF模型通常会在专家边界附近产生低质量的表示。我们发现，这种恶化主要是由预见专家选择机制引起的，这可能会在专家边界附近的物体形状中留下不自然的不连续性。Gumbel-NeRF采用事后专家选择机制，即使在专家边界附近，也能保证密度场的连续性。使用SRN汽车数据集的实验证明了Gumbel-NeRF在各种图像质量指标方面优于基线。 et.al.|[2410.20306](http://arxiv.org/abs/2410.20306)|null|
|**2024-10-25**|**Evaluation of strategies for efficient rate-distortion NeRF streaming**|神经辐射场（NeRF）通过从稀疏的图像集实现高度逼真和详细的场景重建，彻底改变了3D视觉表示领域。NeRF使用体积函数表示法，将3D点映射到其相应的颜色和不透明度，从而允许从任意视点进行逼真的视图合成。尽管取得了进步，但由于涉及大量数据，NeRF内容的高效流式传输仍然是一个重大挑战。本文研究了两种NeRF流媒体策略的率失真性能：基于像素的流媒体和基于神经网络（NN）参数的流媒体。在前者中，图像被编码并随后在整个网络中传输，而在后者中，相应的NeRF模型参数被编码并传输。这项工作还强调了复杂性和性能之间的权衡，表明基于NN参数的策略通常具有更高的效率，使其适用于一对多的流媒体场景。 et.al.|[2410.19459](http://arxiv.org/abs/2410.19459)|null|
|**2024-10-24**|**Where Am I and What Will I See: An Auto-Regressive Model for Spatial Localization and View Prediction**|空间智能是机器在空间和时间的三维空间中感知、推理和行动的能力。大规模自回归模型的最新进展在各种推理任务中表现出了显著的能力。然而，这些模型经常在空间推理的基本方面遇到困难，特别是在回答“我在哪里？”和“我会看到什么？”等问题时。虽然已经进行了一些尝试，但现有的方法通常将它们视为单独的任务，未能捕捉到它们相互关联的性质。在本文中，我们提出了生成空间变换器（GST），这是一种新型的自回归框架，可以同时解决空间定位和视图预测问题。我们的模型同时从单个图像中估计相机姿态，并从新的相机姿态预测视图，有效地弥合了空间感知和视觉预测之间的差距。所提出的创新相机标记化方法使模型能够以自回归的方式学习2D投影的联合分布及其相应的空间视角。这种统一的训练范式表明，姿态估计和新颖视图合成的联合优化首次提高了这两项任务的性能，突出了空间感知和视觉预测之间的内在关系。 et.al.|[2410.18962](http://arxiv.org/abs/2410.18962)|null|
|**2024-10-27**|**Binocular-Guided 3D Gaussian Splatting with View Consistency for Sparse View Synthesis**|稀疏输入的新颖视图合成是3D计算机视觉中一项至关重要但具有挑战性的任务。之前的方法探索了使用神经先验（如深度先验）作为额外监督的3D高斯散斑，与基于NeRF的方法相比，显示出有前景的质量和效率。然而，来自2D预训练模型的神经先验通常是嘈杂和模糊的，这很难精确地指导辐射场的学习。在本文中，我们提出了一种新的方法，通过高斯散斑从稀疏视图合成新视图，该方法不需要外部先验作为监督。我们的关键思想在于探索通过视差引导图像扭曲构建的每对双目图像之间的双目立体一致性所固有的自我监督。为此，我们还引入了高斯不透明度约束，该约束使高斯位置正则化，避免了高斯冗余，以提高从稀疏视图推断3D高斯的鲁棒性和效率。在LLFF、DTU和Blender数据集上进行的广泛实验表明，我们的方法明显优于最先进的方法。 et.al.|[2410.18822](http://arxiv.org/abs/2410.18822)|null|
|**2024-10-23**|**FreeVS: Generative View Synthesis on Free Driving Trajectory**|现有的基于重建的新型驾驶场景视图合成方法侧重于沿自我车辆记录的轨迹合成相机视图。当视点偏离记录的轨迹，相机光线未经训练时，它们的图像渲染性能将严重下降。我们提出了FreeVS，这是一种新颖的完全生成方法，可以在真实驾驶场景中合成自由新轨迹上的相机视图。为了控制生成结果与真实场景的3D一致性和视点姿态的准确性，我们提出了视图先验的伪图像表示来控制生成过程。视点变换模拟应用于伪图像，以模拟相机在每个方向上的运动。一旦经过训练，FreeVS可以应用于任何验证序列，而无需对新轨迹进行重建过程和合成视图。此外，我们提出了两个针对驾驶场景量身定制的具有挑战性的新基准，即新颖的相机合成和新颖的轨迹合成，强调视点的自由度。鉴于新轨迹上没有地面真实图像，我们还建议用3D感知模型评估新轨迹上合成的图像的一致性。在Waymo开放数据集上的实验表明，FreeVS在记录的轨迹和新的轨迹上都具有很强的图像合成性能。项目页面：https://freevs24.github.io/ et.al.|[2410.18079](http://arxiv.org/abs/2410.18079)|null|
|**2024-10-23**|**VR-Splatting: Foveated Radiance Field Rendering via 3D Gaussian Splatting and Neural Points**|新视图合成（NVS）的最新进展，特别是神经辐射场（NeRF）和高斯溅射（3DGS），在真实感场景渲染方面取得了令人印象深刻的结果。这些技术在虚拟旅游和隐形传态中具有巨大的应用潜力，其中沉浸式真实感至关重要。然而，由于延迟和计算限制，虚拟现实（VR）系统的高性能需求给直接利用如此快速的渲染3DGS等场景表示带来了挑战。在本文中，我们提出了中心凹渲染作为解决这些障碍的有前景的解决方案。我们分析了最先进的NVS方法的渲染性能和与人类视觉系统的兼容性。我们的方法为虚拟现实引入了一种新的中心凹渲染方法，该方法利用了中心凹区域神经点渲染的清晰、详细的输出，并与周边视觉的3DGS平滑渲染相融合。我们的评估证实，与标准的VR就绪3DGS配置相比，我们的方法提高了感知的清晰度和细节丰富性。我们的系统满足了实时VR交互的必要性能要求，最终增强了用户的沉浸式体验。项目页面：https://lfranke.github.io/vr_splatting et.al.|[2410.17932](http://arxiv.org/abs/2410.17932)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-29**|**Guide3D: A Bi-planar X-ray Dataset for 3D Shape Reconstruction**|血管内手术工具重建是推进血管内工具导航的重要因素，是血管内手术的重要步骤。然而，缺乏公开可用的数据集严重限制了新型机器学习方法的开发和验证。此外，由于需要双平面扫描仪等专用设备，之前的大多数研究都采用了单平面荧光镜技术，因此只能从单一视角捕获数据，大大限制了重建精度。为了弥合这一差距，我们引入了Guide3D，这是一个用于3D重建的双平面X射线数据集。该数据集代表了在现实环境中捕获的高分辨率双平面手动注释荧光镜透视视频的集合。在反映临床环境的模拟环境中验证我们的数据集，证实了它对现实世界应用的适用性。此外，我们提出了一个新的导石形状预测基准，作为未来工作的有力基准。Guide3D不仅通过提供一个推进分割和3D重建技术的平台来满足基本需求，而且有助于开发更准确、更有效的血管内手术干预措施。我们的项目可在https://airvlab.github.io/guide3d/. et.al.|[2410.22224](http://arxiv.org/abs/2410.22224)|null|
|**2024-10-29**|**PF3plat: Pose-Free Feed-Forward 3D Gaussian Splatting**|我们考虑了在单个前馈中从非聚焦图像合成新视图的问题。我们的框架利用了3DGS的快速、可扩展性和高质量的3D重建和视图合成功能，我们进一步扩展了它，提供了一种实用的解决方案，放宽了常见的假设，如密集的图像视图、精确的相机姿态和大量的图像重叠。我们通过识别和解决使用像素对齐的3DGS所带来的独特挑战来实现这一目标：不同视图中未对齐的3D高斯分布会导致噪声或稀疏梯度，从而破坏训练的稳定性并阻碍收敛，尤其是在不满足上述假设的情况下。为了减轻这种情况，我们采用预训练的单目深度估计和视觉对应模型来实现3D高斯的粗略对齐。然后，我们引入了轻量级、可学习的模块，从粗对准中细化深度和姿态估计，提高了3D重建的质量和新颖的视图合成。此外，利用精细估计来估计几何置信度得分，该得分评估3D高斯中心的可靠性，并相应地调节高斯参数的预测。对大规模真实世界数据集的广泛评估表明，PF3plat在所有基准测试中都达到了新的最先进水平，并得到了验证我们设计选择的全面消融研究的支持。 et.al.|[2410.22128](http://arxiv.org/abs/2410.22128)|null|
|**2024-10-29**|**PrefPaint: Aligning Image Inpainting Diffusion Model with Human Preference**|本文首次尝试通过强化学习框架将图像修复的扩散模型与人类美学标准对齐，显著提高了修复图像的质量和视觉吸引力。具体来说，我们没有直接用成对的图像来测量差异，而是用我们构建的数据集训练了一个奖励模型，该数据集由近51000张标注了人类偏好的图像组成。然后，我们采用强化学习过程来微调预训练的图像修复扩散模型的分布，以获得更高的回报。此外，我们从理论上推导了奖励模型误差的上限，这说明了在整个强化对齐过程中奖励估计的潜在置信度，从而促进了精确的正则化。对修复比较和下游任务（如图像扩展和3D重建）的广泛实验证明了我们方法的有效性，与最先进的方法相比，修复图像与人类偏好的对齐有了显著改善。这项研究不仅推进了图像修复领域的发展，还为基于建模奖励准确性将人类偏好纳入生成模型的迭代细化提供了一个框架，对视觉驱动的人工智能应用程序的设计具有广泛的意义。我们的代码和数据集可在以下网址公开获取https://prefpaint.github.io. et.al.|[2410.21966](http://arxiv.org/abs/2410.21966)|null|
|**2024-10-29**|**SS3DM: Benchmarking Street-View Surface Reconstruction with a Synthetic 3D Mesh Dataset**|为街景场景重建精确的3D表面对于数字娱乐和自动驾驶模拟等应用至关重要。然而，现有的街景数据集，包括KITTI、Waymo和nuScenes，只提供嘈杂的激光雷达点作为重建表面几何评估的地面真实数据。这些几何地面真理通常缺乏评估曲面位置所需的精度，也不提供评估曲面法线的数据。为了克服这些挑战，我们引入了SS3DM数据集，其中包括precist\textbf{S}ynthetic\textbf{S}treet-view\textbf{3D}\textbf{M}esh从CARLA模拟器导出的模型。这些网格模型有助于精确的位置评估，并包括用于评估表面法线的法线向量。为了在真实的驾驶场景中模拟输入数据以进行3D重建，我们在不同的室外场景中虚拟驾驶一辆配备了六个RGB摄像头和五个LiDAR传感器的车辆。利用这一数据集，我们为最先进的表面重建方法建立了一个基准，对相关挑战进行了全面评估。如需更多信息，请访问我们的主页https://ss3dm.top. et.al.|[2410.21739](http://arxiv.org/abs/2410.21739)|null|
|**2024-10-28**|**IndraEye: Infrared Electro-Optical UAV-based Perception Dataset for Robust Downstream Tasks**|深度神经网络（DNN）在电光（EO）相机捕获的光线充足的图像上训练时表现出了卓越的性能，这些图像提供了丰富的纹理细节。然而，在航空感知等关键应用中，DNN必须在所有条件下保持一致的可靠性，包括低光照场景，在这些场景中，光电摄像机往往难以捕捉到足够的细节。此外，由于不同高度和倾斜角度的尺度变化，基于无人机的空中目标检测面临着重大挑战，增加了另一层复杂性。现有的方法通常只解决域偏移时的照明变化或样式变化，但在空间感知中，相关性偏移也会影响DNN性能。本文介绍了IndraEye数据集，这是一个为各种任务设计的多传感器（EO-IR）数据集。它包括5612张图像，145666个实例，涵盖了印度次大陆的多个视角、高度、七种背景和一天中的不同时间。该数据集开辟了几个研究机会，如多模态学习、对象检测和分割的领域自适应，以及探索传感器特定的优缺点。IndraEye旨在通过支持开发更强大、更准确的空中感知系统来推进该领域的发展，特别是在具有挑战性的条件下。IndraEye数据集以对象检测和语义分割任务为基准。数据集和源代码可在https://bit.ly/indraeye. et.al.|[2410.20953](http://arxiv.org/abs/2410.20953)|null|
|**2024-10-28**|**ODGS: 3D Scene Reconstruction from Omnidirectional Images with 3D Gaussian Splattings**|全向（或360度）图像越来越多地用于3D应用，因为它们允许用单个图像渲染整个场景。基于神经辐射场的现有作品在以自我为中心的视频上展示了成功的3D重建质量，但它们的训练和渲染时间很长。最近，3D高斯散斑因其快速优化和实时渲染而受到关注。然而，由于两个图像域之间的光学特性不同，直接使用透视光栅化器对全向图像进行处理会导致严重失真。在这项工作中，我们提出了ODGS，这是一种用于全向图像的新型光栅化流水线，具有几何解释功能。对于每个高斯分布，我们定义一个与单位球体接触的切平面，该切平面垂直于朝向高斯中心的光线。然后，我们利用透视相机光栅化器将高斯投影到相应的切平面上。投影的高斯图像被转换并组合成全向图像，从而完成全向光栅化过程。这种解释揭示了所提出的管道中的隐含假设，我们通过数学证明进行了验证。整个光栅化过程使用CUDA并行化，实现了比基于NeRF的方法快100倍的优化和渲染速度。我们的综合实验通过在各种数据集上提供最佳的重建和感知质量，突显了ODGS的优越性。此外，漫游数据集的结果表明，即使在重建大型3D场景时，ODGS也能有效地恢复精细细节。源代码可以在我们的项目页面上找到(https://github.com/esw0116/ODGS). et.al.|[2410.20686](http://arxiv.org/abs/2410.20686)|null|
|**2024-10-27**|**Neural rendering enables dynamic tomography**|中断X射线计算机断层扫描（X-CT）一直是观察实验过程中材料变形的常用方法。虽然这种方法对于准静态实验是有效的，但在不可中断的动态实验中，永远不可能重建完整的三维断层扫描。在这项工作中，我们提出神经渲染工具可用于推动范式转变，以在动态事件中实现三维重建。首先，我们得出理论结果来支持投影角度的选择。通过合成和实验数据的结合，我们证明神经辐射场可以比传统的重建方法更有效地重建感兴趣的数据模态。最后，我们开发了一个基于样条的变形场时空模型，并证明该模型可以在现实实验中重建晶格样本的时空变形。 et.al.|[2410.20558](http://arxiv.org/abs/2410.20558)|null|
|**2024-10-26**|**Neural Fields in Robotics: A Survey**|神经场已经成为计算机视觉和机器人技术中3D场景表示的一种变革性方法，能够从姿势的2D数据中准确推断几何、3D语义和动力学。利用可微分渲染，神经场包括连续隐式和显式神经表示，实现了高保真3D重建、多模态传感器数据的集成和新视点的生成。这项调查探讨了它们在机器人技术中的应用，强调了它们在增强感知、规划和控制方面的潜力。它们的紧凑性、内存效率和可微性，以及与基础模型和生成模型的无缝集成，使其成为实时应用的理想选择，提高了机器人的适应性和决策能力。本文基于200多篇论文，对机器人中的神经场进行了全面的回顾，对各个领域的应用进行了分类，并评估了它们的优势和局限性。首先，我们介绍了四个关键的神经场框架：占用网络、有符号距离场、神经辐射场和高斯散斑。其次，我们详细介绍了神经场在五个主要机器人领域的应用：姿态估计、操纵、导航、物理和自动驾驶，重点介绍了关键工作，并讨论了要点和公开挑战。最后，我们概述了神经场在机器人技术中的局限性，并为未来的研究提出了有前景的方向。项目页面：https://robonerf.github.io et.al.|[2410.20220](http://arxiv.org/abs/2410.20220)|null|
|**2024-10-26**|**SCube: Instant Large-Scale Scene Reconstruction using VoxSplats**|我们提出了SCube，这是一种从稀疏的姿态图像集重建大规模3D场景（几何、外观和语义）的新方法。我们的方法使用一种新的表示VoxSplat对重建的场景进行编码，VoxSplaat是一组在高分辨率稀疏体素支架上支持的3D高斯分布。为了从图像中重建VoxSplat，我们采用了一个以输入图像为条件的分层体素潜在扩散模型，然后是一个前馈外观预测模型。扩散模型以从粗到细的方式逐步生成高分辨率网格，外观网络预测每个体素内的一组高斯分布。从少至3个不重叠的输入图像中，SCube可以在20秒内生成数百万个高斯图像，其1024^3的体素网格跨越数百米。过去从图像中重建场景的工作要么依赖于每个场景的优化，无法从输入视图中重建场景（因此需要密集的视图覆盖作为输入），要么利用基于低分辨率模型的几何先验，这会产生模糊的结果。相比之下，SCube利用高分辨率稀疏网络，从很少的视图中产生清晰的输出。我们展示了SCube与使用Waymo自动驾驶数据集进行3D重建的现有技术相比的优越性，并展示了其应用，如LiDAR模拟和文本到场景生成。 et.al.|[2410.20030](http://arxiv.org/abs/2410.20030)|null|
|**2024-10-25**|**Tracking and triangulating firefly flashes in field recordings**|从自然图像中的其他明亮特征中识别萤火虫闪光是复杂的。我提供了一个训练数据集和经过训练的神经网络，用于可靠的闪光分类。训练集由数千个裁剪图像（补丁）组成，这些图像是通过手动标记从萤火虫在自然栖息地的视频记录中提取的。与仅依赖强度阈值的传统方法相比，训练好的网络在区分闪光与其他光源方面似乎更可靠。这种稳健的跟踪技术为从立体360度视频中重建闪光事件提供了一种新的无需校准的3D重建方法，我在这里也介绍了这种方法。 et.al.|[2410.19932](http://arxiv.org/abs/2410.19932)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-29**|**Driving forces in cell migration and pattern formation in a soft tissue**|我们通过适当的耗散原理描述了软组织中的细胞扩散，特别关注力、物质和微力平衡定律的耦合。为此，我们根据自由能的特征，将我们的框架转换为一个多层次的示意图，包括运动学和动力学。我们首先制定了一个力平衡定律，其中力场和应力场被定义为速度场及其梯度的幂共轭量，然后我们给出了一个物种摩尔平衡定律，以及化学势测试场，作为物种浓度变化率的幂共轭值，最后是一个微力平衡定律。该框架的主要特征是化学势的本构表达式，该表达式分为一个由自由能的均匀凸部分导出的项和一个引起旋节分解的主动外部化学势。化学势的活性部分根据细胞浓度给出表达式，类似于[Oster，Murray和Harris，J.Embryol.Exp.Morph.78（1983）]中定义的表达式，其中它用于表征细胞运动诱导的向上细胞扩散。此外，我们还展示了外部矢量场如何将扩散过程引导到不同的极限平稳模式，该矢量场作为浓度梯度变化率的幂共轭量进入微力平衡定律。该矢量场可能模拟表征迁移细胞与周围组织相互作用的任何方向线索或偏差。 et.al.|[2410.22273](http://arxiv.org/abs/2410.22273)|null|
|**2024-10-29**|**Surface reconstruction from point cloud using a semi-Lagrangian scheme with local interpolator**|我们提出了一种水平集方法，在不假设点之间的连接已知的情况下，从点云中重建未知曲面。我们考虑一个具有曲率约束的变分公式，该公式最小化了由曲面与点云的距离加权的表面积。更精确地说，我们求解了一个等效的平流扩散方程，该方程控制着由水平集函数隐式描述的初始表面的演化。在所有可能的表示中，我们的目标是至少在重建表面附近计算带符号的距离函数。近似解的数值方法基于半拉格朗日方案，其主要新颖之处在于它与局部插值器而不是全局插值器耦合，目的是节省计算成本。特别是，我们采用多线性插值器和加权基本无振荡插值器来提高重建的准确性。特别关注方法的定位和并行运行的快速算法的开发，从而实现更快的重建，从而有机会轻松提高分辨率。还提出了点云数据的预处理，以设置该方法的参数。给出了二维和三维的数值测试，以评估近似解的质量和算法在计算时间方面的效率。 et.al.|[2410.22205](http://arxiv.org/abs/2410.22205)|null|
|**2024-10-29**|**Confinement of relativistic particles in the vicinity of accelerators: a key for understanding the anomalies in secondary cosmic rays**|最近的宇宙射线（CR）测量揭示了次级CR的意外异常，即与所谓的标准银河CR范式关于初级（加速）CR与星际气体相互作用产物的成分和能谱的预测存在偏差：（i）反粒子（正电子和反质子），（ii）（Li，Be，B）族轻元素，以及（iii）扩散伽马射线。我们认为，新的测量结果仍然可以在标准CR范式内得到解释，但有一个额外的假设，即CR在其生命周期的很大一部分时间都在其形成位点附近度过。如果CR在这些局部区域的传播速度比在星际介质（ISM）中慢，则可以实现后者。假设在银河系CR的主要贡献者附近，CR的平均能量无关“克重”为0.7-rm g/cm^2 $，人们可以自洽地解释DAMPE对B/C比的新测量和LHAASO对漫射超高能伽马射线的新测量，涉及最少数量的模型参数：星际介质中的能量相关“克重”约为8（E/10\GeV）^{-0.55}~\rm g/cm^2}$，以及平均CR加速度（源E）谱$rm Q（E）\propto E^{-2.3}$ 。 et.al.|[2410.22199](http://arxiv.org/abs/2410.22199)|null|
|**2024-10-29**|**An alternating low-rank projection approach for partial differential equations with random inputs**|众所周知，标准随机伽略金方法在求解具有随机输入的偏微分方程（PDE）时面临挑战。这些挑战通常归因于所需的大量物理基函数和随机基函数。因此，选择有效的基函数来适当降低物理和随机近似空间的维数变得至关重要。在这项研究中，我们的重点是与广义多项式混沌（gPC）相关的随机伽略金近似。我们深入研究了准矩阵的低秩近似，其列表示解的gPC展开式中的系数。我们对该拟矩阵的奇异值分解（SVD）进行了研究，提出了一种确定所需精度所需秩的策略。随后，我们引入了一种同时低秩投影方法和一种交替低秩投影法来计算具有随机输入的偏微分方程解的低秩近似值。数值结果证明了我们提出的方法对扩散和亥姆霍兹问题的有效性。 et.al.|[2410.22183](http://arxiv.org/abs/2410.22183)|null|
|**2024-10-29**|**Capacity Control is an Effective Memorization Mitigation Mechanism in Text-Conditional Diffusion Models**|在这项工作中，我们提出了令人信服的证据，表明在微调过程中控制模型容量可以有效地减轻扩散模型中的记忆。具体来说，我们证明，与传统的完全微调方法相比，在预训练微调范式中采用参数高效微调（PEFT）可以显著减少记忆。我们的实验利用了MIMIC数据集，该数据集包括胸部X射线的图像文本对及其相应的报告。通过一系列记忆和发电质量指标评估的结果表明，PEFT不仅减少了记忆，而且提高了下游发电质量。此外，PEFT方法可以与现有的记忆缓解技术无缝结合，以进一步改进。我们的实验代码可在以下网址获得：https://github.com/Raman1121/Diffusion_Memorization_HPO et.al.|[2410.22149](http://arxiv.org/abs/2410.22149)|**[link](https://github.com/raman1121/diffusion_memorization_hpo)**|
|**2024-10-29**|**Averaging principle for multiscale controlled jump diffusions and associated nonlocal HJB equations**|本文研究了一类具有α稳定噪声的两时间尺度随机控制系统的平均原理。还考虑了非局部Hamilton-Jacobi-Bellman（HJB）方程的相关奇异摄动问题。我们通过对快速分量的遍历度量进行平均，构建了原始多尺度随机控制问题的有效随机控制问题和相关的有效HJB方程。我们用两种方法证明了值函数的收敛性。利用概率方法，我们通过证明受控跳跃扩散的弱平均原理，证明了原始多尺度随机控制系统的值函数收敛到有效随机控制系统。利用偏微分方程方法，我们研究了具有奇异扰动的相关非局部HJB方程的粘性解的值函数。然后，我们使用扰动测试函数方法证明了收敛性。 et.al.|[2410.22141](http://arxiv.org/abs/2410.22141)|null|
|**2024-10-29**|**Thermodynamic uncertainty relation for systems with active Ornstein--Uhlenbeck particles**|热力学不确定性关系（TUR）描述了热力学成本和可观测波动幅度之间的权衡关系。虽然已经为各种非平衡系统建立了TUR，但它们对受有源噪声影响的系统的适用性在很大程度上仍未得到探索。在这里，我们给出了具有活性Ornstein-Uhlenbeck粒子（AOUP）的系统的TUR的显式表达式。我们的研究结果表明，主动噪声对TUR表达式中与热力学成本相关的术语进行了修改。改变的热力学成本不仅包括传统的熵产生，还包括主动噪声引起的能耗。我们研究了这种TUR作为自由空间中恒定力驱动的有源噪声系统中异常扩散程度的准确估计的能力。通过引入收缩概率密度函数的概念，我们推导出了适合该系统的稳态TUR。此外，通过采用新的缩放参数，我们进一步增强和优化了TUR界限。我们的结果表明，主动噪声往往会阻碍对异常扩散程度的准确估计。我们的研究为探索在活跃环境中运行的生物系统的波动性质提供了一种系统的方法。 et.al.|[2410.22126](http://arxiv.org/abs/2410.22126)|null|
|**2024-10-29**|**TractShapeNet: Efficient Multi-Shape Learning with 3D Tractography Point Clouds**|脑成像研究表明，弥散MRI纤维束成像几何形状描述符可以为研究大脑的白质通路及其与大脑功能的关系提供信息。在这项工作中，我们研究了利用深度学习模型计算大脑白质连接形状测量的可能性。我们介绍了一个新的框架TractShapeNet，它利用纤维束成像的点云表示来计算五个形状度量：长度、跨度、体积、总表面积和不规则性。我们在包括1065名健康年轻人的大型数据集上评估了该方法的性能。形状度量计算的实验表明，我们提出的TractShapeNet在皮尔逊相关系数和归一化误差度量方面都优于其他基于点云的神经网络模型。我们将推理运行时的结果与传统的形状计算工具DSI Studio进行了比较。我们的研究结果表明，深度学习方法能够实现更快、更高效的形状测量计算。我们还对两个下游语言认知预测任务进行了实验，结果表明，TractShapeNet的形状测量结果与DSI Studio计算的结果相似。我们的代码将在以下网址提供：https://github.com/SlicerDMRI/TractShapeNet. et.al.|[2410.22099](http://arxiv.org/abs/2410.22099)|null|
|**2024-10-29**|**Generalized arcsine laws for a sluggish random walker with subdiffusive growth**|我们研究了一个具有次扩散增长的简单一维迟缓随机游走模型。在连续流体动力学极限下，该模型对应于一个粒子在一条线上扩散，其扩散常数D（x）=|x|^{-\alpha}与空间相关，漂移势U（x）=|x|^{-\alpha}，其中\alpha\geq 0对模型进行参数化。对于\alpha=0，它减少到标准扩散，而对于\alpha>0，它导致缓慢的次扩散动力学，在后期，距离缩放为x\sim t^{\mu}，\mu=1/（\alpha+2）\leq 1/2。在本文中，我们精确计算了从原点开始的持续时间为T的迟缓步行者的三个可观测值的全概率分布：（i）占用时间T_+表示在原点正侧花费的时间，（ii）T之前通过原点的最后一次通过时间T_{\rm l}，以及（iii）步行者在原点正侧向最大位移的时间T_M。我们证明，当\alpha=0时，所有三个分布都是相同的，并表现出著名的L’vy反正弦定律，但当\alpha>0时，它们会变得彼此不同，并且具有依赖于\alpha的非平凡形状。这将L’vy关于正态扩散（α=0）的三个反正弦定律推广到具有一般α为0的次扩散迟缓步行者模型。数值模拟与我们的分析预测非常吻合。 et.al.|[2410.22097](http://arxiv.org/abs/2410.22097)|null|
|**2024-10-29**|**Variational inference for pile-up removal at hadron colliders with diffusion models**|在本文中，我们提出了一种使用扩散模型的变分推理来消除pp相互作用堆积的新方法，称为Vipr。代替使用分类方法来识别哪些粒子来自主要碰撞，而是训练生成模型来预测去除堆积的硬散射粒子射流的成分。这导致了对整个后硬散射射流成分的估计，这在清除堆积物的背景下尚未得到探索。我们评估了Vipr在模拟的带有堆积污染的事件中的射流样本中的性能。Vipr在预测各种堆积场景下硬散射射流的子结构方面优于SoftDrop。 et.al.|[2410.22074](http://arxiv.org/abs/2410.22074)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-26**|**Neural Fields in Robotics: A Survey**|神经场已经成为计算机视觉和机器人技术中3D场景表示的一种变革性方法，能够从姿势的2D数据中准确推断几何、3D语义和动力学。利用可微分渲染，神经场包括连续隐式和显式神经表示，实现了高保真3D重建、多模态传感器数据的集成和新视点的生成。这项调查探讨了它们在机器人技术中的应用，强调了它们在增强感知、规划和控制方面的潜力。它们的紧凑性、内存效率和可微性，以及与基础模型和生成模型的无缝集成，使其成为实时应用的理想选择，提高了机器人的适应性和决策能力。本文基于200多篇论文，对机器人中的神经场进行了全面的回顾，对各个领域的应用进行了分类，并评估了它们的优势和局限性。首先，我们介绍了四个关键的神经场框架：占用网络、有符号距离场、神经辐射场和高斯散斑。其次，我们详细介绍了神经场在五个主要机器人领域的应用：姿态估计、操纵、导航、物理和自动驾驶，重点介绍了关键工作，并讨论了要点和公开挑战。最后，我们概述了神经场在机器人技术中的局限性，并为未来的研究提出了有前景的方向。项目页面：https://robonerf.github.io et.al.|[2410.20220](http://arxiv.org/abs/2410.20220)|null|
|**2024-10-24**|**3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation**|多视图图像扩散模型显著推进了开放域3D对象生成。然而，大多数现有模型依赖于缺乏固有3D偏差的2D网络架构，导致几何一致性受损。为了应对这一挑战，我们引入了3D Adapter，这是一个插件模块，旨在将3D几何感知注入预训练的图像扩散模型中。我们方法的核心是3D反馈增强的思想：对于采样循环中的每个去噪步骤，3D Adapter将中间的多视图特征解码为连贯的3D表示，然后对渲染的RGBD视图进行重新编码，通过特征添加来增强预训练的基础模型。我们研究了3D Adapter的两种变体：一种是基于高斯飞溅的快速前馈版本，另一种是利用神经场和网格的通用无训练版本。我们广泛的实验表明，3D Adapter不仅大大提高了文本到多视图模型（如Instant3D和Zero123++）的几何质量，而且还使用纯文本到图像的稳定扩散实现了高质量的3D生成。此外，我们通过在文本到3D、图像到3D、文本到纹理和文本到化身任务中呈现高质量的结果，展示了3D适配器的广泛应用潜力。 et.al.|[2410.18974](http://arxiv.org/abs/2410.18974)|**[link](https://github.com/Lakonik/MVEdit)**|
|**2024-10-22**|**Cortical Dynamics of Neural-Connectivity Fields**|皮质组织的宏观研究揭示了振荡活动的普遍性，这反映了神经相互作用的微调。本研究通过将广义振荡动力学纳入先前关于保守或半保守神经场动力学的工作中，扩展了神经场理论。先前的研究在很大程度上假设了神经单元之间的各向同性连接；然而，这项研究表明，广泛的各向异性和波动连接仍然可以维持振荡。使用拉格朗日场方法，我们研究了不同类型的连接、它们的动力学以及与神经场的潜在相互作用。基于这一理论基础，我们推导出了一个框架，该框架通过连接场的概念将Hebbian和非Hebbian学习（即可塑性）纳入神经场的研究中。 et.al.|[2410.16852](http://arxiv.org/abs/2410.16852)|null|
|**2024-10-15**|**Deep vectorised operators for pulsatile hemodynamics estimation in coronary arteries from a steady-state prior**|心血管血流动力学场为冠状动脉疾病提供了有价值的医学决策标志。计算流体动力学（CFD）是体内准确、无创评估这些量的金标准。在这项工作中，我们提出了一种基于机器学习的时间高效替代模型，用于基于稳态先验估计脉动血流动力学。我们引入了深度矢量化算子，这是一种用于在无限维函数空间上进行离散化独立学习的建模框架。基础神经结构是一个以血流动力学边界条件为条件的神经场。重要的是，我们展示了如何将逐点动作的要求放宽到置换等变，从而产生一系列可以通过消息传递和自我关注层进行参数化的模型。我们在从冠状动脉计算机断层扫描血管造影（CCTA）中提取的74条狭窄冠状动脉的数据集上评估了我们的方法，并将患者特异性脉动CFD模拟作为基本事实。我们证明，我们的模型能够准确估计脉动速度和压力，同时不受源域重新采样的影响（离散化独立性）。这表明，深度矢量化算子是冠状动脉及其他动脉心血管血流动力学估计的强大建模工具。 et.al.|[2410.11920](http://arxiv.org/abs/2410.11920)|null|
|**2024-10-07**|**Fast Training of Sinusoidal Neural Fields via Scaling Initialization**|神经场是一种新兴的范式，它将数据表示为由神经网络参数化的连续函数。尽管有许多优点，但神经场通常具有较高的训练成本，这阻碍了更广泛的采用。在本文中，我们关注一个流行的神经场家族，称为正弦神经场（SNF），并研究如何初始化它以最大限度地提高训练速度。我们发现，基于信号传播原理设计的SNF标准初始化方案是次优的。特别是，我们证明，通过简单地将每个权重（最后一层除外）乘以一个常数，我们可以将SNF训练加速10 $\times$。这种方法被称为$\textit{weight scaling}$ ，在各种数据域上持续提供显著的加速，使SNF的训练速度比最近提出的架构更快。为了理解为什么权重缩放效果良好，我们进行了广泛的理论和实证分析，结果表明，权重缩放不仅有效地解决了频谱偏差，而且具有良好的优化轨迹。 et.al.|[2410.04779](http://arxiv.org/abs/2410.04779)|null|
|**2024-10-04**|**End-to-End Reaction Field Energy Modeling via Deep Learning based Voxel-to-voxel Transform**|在计算生物化学和生物物理学中，理解静电相互作用的作用对于阐明生物分子的结构、动力学和功能至关重要。泊松-玻尔兹曼（PB）方程是通过描述带电分子内部和周围的静电势来模拟这些相互作用的基础工具。然而，由于生物分子表面的复杂性和需要考虑可移动离子，求解PB方程带来了重大的计算挑战。虽然求解PB方程的传统数值方法是准确的，但它们的计算成本很高，并且随着系统规模的增加而扩展性较差。为了应对这些挑战，我们引入了PBNeF，这是一种新的机器学习方法，灵感来自基于神经网络的偏微分方程求解器的最新进展。我们的方法将PB方程的输入和边界静电条件转化为可学习的体素表示，使神经场变换器能够预测PB解，进而预测反应场势能。大量实验表明，与传统的PB求解器相比，PBNeF的速度提高了100倍以上，同时保持了与广义玻恩（GB）模型相当的精度。 et.al.|[2410.03927](http://arxiv.org/abs/2410.03927)|null|
|**2024-10-08**|**DressRecon: Freeform 4D Human Reconstruction from Monocular Video**|我们提出了一种从单目视频中重建时间一致的人体模型的方法，重点是极其宽松的衣服或手持物体的交互。之前在人体重建方面的工作要么局限于没有物体交互的紧身衣服，要么需要校准的多视图捕捉或个性化的模板扫描，而大规模收集这些数据成本很高。我们对高质量但灵活的重建的关键见解是，将关于关节体形状的通用人类先验（从大规模训练数据中学习）与视频特定的关节“骨骼袋”变形（通过测试时间优化适合单个视频）仔细结合。我们通过学习一个神经隐式模型来实现这一点，该模型将身体和衣服的变形作为单独的运动模型层来解开。为了捕捉服装的微妙几何形状，我们在优化过程中利用了基于图像的先验，如人体姿势、表面法线和光流。由此产生的神经场可以提取到时间一致的网格中，或进一步优化为显式3D高斯分布，以实现高保真交互式渲染。在具有高度挑战性的服装变形和物体交互的数据集上，DressReston可以产生比现有技术更高保真的3D重建。项目页面：https://jefftan969.github.io/dressrecon/ et.al.|[2409.20563](http://arxiv.org/abs/2409.20563)|null|
|**2024-09-25**|**TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans**|我们介绍了一种新的框架，该框架从单眼视频中学习全身说话的人的动态神经辐射场（NeRF）。之前的工作只代表身体姿势或面部。然而，人类通过全身进行交流，结合身体姿势、手势和面部表情。在这项工作中，我们提出了TalkinNeRF，这是一个基于NeRF的统一网络，代表了整体4D人体运动。给定一个受试者的单眼视频，我们学习身体、面部和手的相应模块，这些模块结合在一起生成最终结果。为了捕捉复杂的手指关节，我们学习了手的额外变形场。我们的多身份表示能够同时训练多个科目，以及在完全看不见的姿势下进行强大的动画。只要输入一段短视频，它也可以推广到新的身份。我们展示了最先进的性能，用于为全身说话的人类制作动画，具有精细的手部发音和面部表情。 et.al.|[2409.16666](http://arxiv.org/abs/2409.16666)|null|
|**2024-09-24**|**Generative 3D Cardiac Shape Modelling for In-Silico Trials**|我们提出了一种深度学习方法，基于将形状表示为神经有符号距离场的零级集，对合成主动脉形状进行建模和生成，该方法受一系列可训练的嵌入向量的约束，并对每个形状的几何特征进行编码。通过使神经场在采样表面点上消失并强制其空间梯度具有单位范数，在从CT图像重建的主动脉根部网格数据集上训练网络。实证结果表明，我们的模型可以高保真地表示主动脉形状。此外，通过从学习到的嵌入向量中采样，我们可以生成类似于真实患者解剖结构的新形状，可用于计算机模拟试验。 et.al.|[2409.16058](http://arxiv.org/abs/2409.16058)|null|
|**2024-09-21**|**MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors**|由于缺乏几何指导和不完美的视图相关2D先验，从单眼图像中精确重建密集和语义注释的3D网格仍然是一项具有挑战性的任务。尽管我们已经见证了隐式神经场景表示的最新进展，能够简单地从多视图图像中进行精确的2D渲染，但很少有研究仅使用单眼先验来解决3D场景理解问题。在本文中，我们提出了MOSE，这是一种神经场语义重建方法，可以将推断的图像级噪声先验提升到3D，在3D和2D空间中产生精确的语义和几何。我们方法的关键动机是利用通用类不可知的分段掩码作为指导，在训练过程中促进渲染语义的局部一致性。在语义的帮助下，我们进一步将平滑正则化应用于无纹理区域，以获得更好的几何质量，从而实现几何和语义的互惠互利。在ScanNet数据集上的实验表明，我们的MOSE在3D语义分割、2D语义分割和3D表面重建任务的所有指标上都优于相关基线。 et.al.|[2409.14019](http://arxiv.org/abs/2409.14019)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

