---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.10.31
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-29**|**DynPoint: Dynamic Neural Point For View Synthesis**|神经辐射场的引入极大地提高了单目视频视图合成的有效性。然而，现有算法在处理不受控制或冗长的场景时面临困难，并且需要针对每个新场景的大量训练时间。为了解决这些限制，我们提出了DynPoint，这是一种算法，旨在促进无约束单眼视频的新视图的快速合成。DynPoint不是将整个场景信息编码为潜在表示，而是专注于预测相邻帧之间的显式3D对应关系，以实现信息聚合。具体地，这种对应预测是通过估计帧之间一致的深度和场景流信息来实现的。随后，通过构建分层神经点云，利用所获取的对应关系将信息从多个参考帧聚合到目标帧。所得到的框架使得能够对目标帧的期望视图进行快速且准确的视图合成。所获得的实验结果表明，与先前的方法相比，我们提出的方法大大加快了训练时间，通常是一个数量级，同时产生了可比的结果。此外，我们的方法在处理长持续时间视频时表现出强大的鲁棒性，而无需学习视频内容的规范表示。 et.al.|[2310.18999](http://arxiv.org/abs/2310.18999)|null|
|**2023-10-27**|**ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Real Image**|我们介绍了一种3D感知扩散模型ZeroNVS，用于野外场景的单图像新颖视图合成。虽然现有的方法是为具有遮罩背景的单个对象设计的，但我们提出了新的技术来解决具有复杂背景的野外多对象场景带来的挑战。具体来说，我们在捕捉以对象为中心、室内和室外场景的混合数据源上训练生成先验。为了解决深度尺度模糊等数据混合问题，我们提出了一种新的相机条件参数化和归一化方案。此外，我们观察到，在360度场景的提取过程中，分数提取采样（SDS）倾向于截断复杂背景的分布，并提出了“SDS锚定”来提高合成新视图的多样性。我们的模型在零样本设置中的DTU数据集上的LPIPS中设置了新的最先进的结果，甚至优于专门在DTU上训练的方法。我们进一步将具有挑战性的Mip-NeRF 360数据集作为单图像新视图合成的新基准，并在该设置中展示了强大的性能。我们的代码和数据位于http://kylesargent.github.io/zeronvs/ et.al.|[2310.17994](http://arxiv.org/abs/2310.17994)|null|
|**2023-10-27**|**Reconstructive Latent-Space Neural Radiance Fields for Efficient 3D Scene Representations**|神经辐射场（NeRF）已被证明是强大的3D表示，能够对复杂场景进行高质量的新颖视图合成。虽然NeRF已经应用于图形、视觉和机器人，但渲染速度慢和特有的视觉伪影问题阻碍了在许多用例中的采用。在这项工作中，我们研究了将自动编码器（AE）与NeRF相结合，其中潜在特征（而不是颜色）被渲染，然后进行卷积解码。由此产生的潜在空间NeRF可以产生比标准颜色空间NeRF质量更高的新颖视图，因为AE可以校正某些视觉伪影，同时渲染速度快三倍以上。我们的工作与提高NeRF效率的其他技术正交。此外，我们可以通过缩小AE架构来控制效率和图像质量之间的权衡，在性能下降很小的情况下实现13倍以上的渲染速度。我们希望我们的方法能够为下游任务形成高效但高保真的3D场景表示的基础，尤其是在保持可微性很有用的情况下，就像在许多需要持续学习的机器人场景中一样。 et.al.|[2310.17880](http://arxiv.org/abs/2310.17880)|null|
|**2023-10-26**|**LightSpeed: Light and Fast Neural Light Fields on Mobile Devices**|由于计算能力和存储空间有限，移动设备上的实时新视图图像合成是令人望而却步的。在移动设备上使用体积渲染方法（如NeRF及其衍生物）是不合适的，因为体积渲染的计算成本很高。另一方面，神经光场表示的最新进展在移动设备上显示出了有希望的实时视图合成结果。神经光场方法学习从光线表示到像素颜色的直接映射。光线表示的当前选择是分层光线采样或Plucker坐标，忽略了经典的光板（双平面）表示，这是在光场视图之间插值的首选表示。在这项工作中，我们发现使用光板表示是学习神经光场的有效表示。更重要的是，它是一种较低维的光线表示，使我们能够使用训练和渲染速度明显更快的特征网格来学习4D光线空间。尽管主要是为正面视图设计的，但我们表明，光板表示可以使用分而治之的策略进一步扩展到非正面场景。与以前的光场方法相比，我们的方法提供了卓越的渲染质量，并显著改善了渲染质量和速度之间的平衡。 et.al.|[2310.16832](http://arxiv.org/abs/2310.16832)|**[link](https://github.com/lightspeed-r2l/lightspeed)**|
|**2023-10-28**|**PERF: Panoramic Neural Radiance Field from a Single Panorama**|神经辐射场（NeRF）在给定多视点图像的新视点合成方面取得了实质性进展。最近，一些工作试图从具有3D先验的单个图像中训练NeRF。它们主要关注具有少量遮挡的有限视场，这极大地限制了它们在具有大尺寸遮挡的真实世界360度全景场景中的可扩展性。在本文中，我们提出了PERF，这是一种360度新颖的视图合成框架，它从单个全景训练全景神经辐射场。值得注意的是，PERF允许在复杂场景中进行3D漫游，而无需昂贵且乏味的图像采集。为了实现这一目标，我们提出了一种新的协作RGBD修复方法和一种渐进的修复和擦除方法，以将360度2D场景提升为3D场景。具体而言，我们首先预测全景深度图作为给定单个全景的初始化，并使用体绘制重建可见的3D区域。然后，我们在NeRF中引入了一种协作的RGBD修复方法，用于从随机视图中完成RGB图像和深度图，该方法源自RGB稳定扩散模型和单目深度估计器。最后，我们介绍了一种修复和擦除策略，以避免新采样视图和参考视图之间的几何不一致。这两个组件在统一的优化框架中集成到NeRF的学习中，并取得了有希望的结果。在Replica和野外新数据集PERF上进行的大量实验证明了我们的PERF优于最先进的方法。我们的PERF可以广泛用于真实世界的应用，如全景到3D、文本到3D和3D场景风格化应用。项目页面和代码可在https://perf-project.github.io/和https://github.com/perf-project/PeRF. et.al.|[2310.16831](http://arxiv.org/abs/2310.16831)|**[link](https://github.com/perf-project/PeRF)**|
|**2023-10-25**|**Open-NeRF: Towards Open Vocabulary NeRF Decomposition**|在本文中，我们解决了从开放词汇中将神经辐射场（NeRF）分解为对象的挑战，这是三维重建和视图合成中对象操作的关键任务。当前的NeRF分解技术涉及处理开放词汇查询的灵活性和3D分割的准确性之间的权衡。我们提出了开放词汇嵌入式神经辐射场（Open NeRF），它利用了大规模现成的分割模型，如Segment Anything Model（SAM），并引入了一种具有分层嵌入的集成和提取范式，以实现开放词汇查询的灵活性和3D分割的准确性。Open NeRF首先利用大规模基础模型从不同的角度生成分层2D掩模方案。然后，通过跟踪方法将这些建议对齐，并将其集成在3D空间中，随后将其提取到3D领域中。这一过程确保了从不同角度对对象的一致识别和粒度，即使在涉及遮挡和模糊特征的具有挑战性的场景中也是如此。我们的实验结果表明，在开放词汇场景中，所提出的Open NeRF优于最先进的方法，如LERF\cite{LERF}和FFD\cite{FFD}。Open NeRF为NeRF分解提供了一个很有前途的解决方案，以开放词汇查询为指导，在开放世界3D场景中实现机器人和视觉语言交互的新应用。 et.al.|[2310.16383](http://arxiv.org/abs/2310.16383)|null|
|**2023-10-24**|**iNVS: Repurposing Diffusion Inpainters for Novel View Synthesis**|我们提出了一种从单一源图像生成一致新颖视图的方法。我们的方法侧重于最大限度地重用源图像中的可见像素。为了实现这一点，我们使用单目深度估计器，将可见像素从源视图转移到目标视图。从预先训练的2D修复扩散模型开始，我们在大规模Ob厌恶数据集上训练我们的方法来学习3D对象先验。在训练时，我们使用了一种基于核线的新型掩蔽机制来进一步提高我们的方法的质量。这使得我们的框架能够对各种对象执行零样本新颖的视图合成。我们在三个具有挑战性的数据集上评估了我们框架的零样本能力：谷歌扫描对象、光线跟踪多视图和3D中的常见对象。查看我们的网页了解更多详细信息：https://yashkant.github.io/invs/ et.al.|[2310.16167](http://arxiv.org/abs/2310.16167)|null|
|**2023-10-23**|**Relit-NeuLF: Efficient Relighting and Novel View Synthesis via Neural 4D Light Field**|在本文中，我们解决了在光源数量有限的情况下，从多视图图像中同时重新照明和合成复杂场景的新视图的问题。我们提出了一种称为Relit NeuLF的分析综合方法。继最近的神经4D光场网络（NeuLF）之后，Relit NeuLF首先利用两平面光场表示来参数化4D坐标系中的每条光线，从而实现高效的学习和推理。然后，我们以自监督的方式恢复三维场景的空间变化双向反射率分布函数（SVBRDF）。DecomposeNet学习将每条光线映射到其SVBRDF组件：反照率、法线和粗糙度。基于分解的BRDF分量和条件光方向，RenderNet学习合成光线的颜色。为了自我监督SVBRDF分解，我们鼓励使用微平面模型使预测的光线颜色接近基于物理的渲染结果。综合实验表明，该方法在合成数据和真实人脸数据上都是有效的，并且优于最先进的结果。我们在GitHub上公开发布了我们的代码。你可以在这里找到它：https://github.com/oppo-us-research/RelitNeuLF et.al.|[2310.14642](http://arxiv.org/abs/2310.14642)|**[link](https://github.com/oppo-us-research/relitneulf)**|
|**2023-10-23**|**VQ-NeRF: Vector Quantization Enhances Implicit Neural Representations**|隐式神经表示的最新进展有助于高保真度的表面重建和真实感的新视图合成。然而，这些方法中固有的计算复杂性是一个巨大的障碍，限制了实际应用中可达到的帧速率和分辨率。针对这一困境，我们提出了VQ-NeRF，这是一种通过矢量量化增强隐式神经表示的有效管道。我们的方法的本质包括将NeRF的采样空间减少到较低的分辨率，然后使用预训练的VAE解码器将其恢复到原始大小，从而有效地缓解渲染过程中遇到的采样时间瓶颈。尽管码本提供了代表性的特征，但由于高压缩率，重建场景的精细纹理细节仍然具有挑战性。为了克服这一限制，我们设计了一种创新的多尺度NeRF采样方案，该方案在压缩和原始尺度上同时优化NeRF模型，以增强网络保存精细细节的能力。此外，我们引入了语义损失函数，以提高三维重建的几何保真度和语义连贯性。大量实验证明了我们的模型在实现渲染质量和效率之间的最佳权衡方面的有效性。对DTU、BlendMVS和H3DS数据集的评估证实了我们方法的卓越性能。 et.al.|[2310.14487](http://arxiv.org/abs/2310.14487)|null|
|**2023-10-20**|**ManifoldNeRF: View-dependent Image Feature Supervision for Few-shot Neural Radiance Fields**|随着神经辐射场（NeRF）的出现，新的视图合成最近取得了重大进展。DietNeRF是NeRF的扩展，旨在通过为没有输入图像的未知视点引入新的损失函数，仅从少数图像中实现这一任务。损失函数假设预先训练的特征提取器应该输出相同的特征，即使输入图像是在不同的视点捕获的，因为图像包含相同的对象。然而，尽管这种假设是理想的，但在现实中，众所周知，随着视点的不断变化，特征向量也在不断变化。因此，这种假设可能会损害训练。为了避免这种有害的训练，我们提出了ManifoldNeRF，这是一种使用来自相邻已知视点的插值特征来监督未知视点的特征向量的方法。由于该方法通过插值特征为每个未知视点提供了适当的监督，因此体积表示比DietNeRF学习得更好。实验结果表明，在复杂场景下，该方法的性能优于其他方法。我们还对一组视点中的几个视点子集进行了实验，并为真实环境确定了一组有效的视点。这为实际应用程序提供了视点模式的基本策略。代码可在https://github.com/haganelego/ManifoldNeRF_BMVC2023 et.al.|[2310.13670](http://arxiv.org/abs/2310.13670)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-29**|**3DMiner: Discovering Shapes from Large-Scale Unannotated Image Datasets**|我们介绍了3DMiner——一种从具有挑战性的大规模未标记图像数据集中挖掘3D形状的管道。与其他无监督的3D重建方法不同，我们假设，在一个足够大的数据集中，必须存在形状相似但背景、纹理和视点不同的对象图像。我们的方法利用学习自监督图像表示的最新进展，对具有几何相似形状的图像进行聚类，并找到它们之间的常见图像对应关系。然后，我们利用这些对应关系来获得粗略的相机估计，作为束调整的初始化。最后，对于每个图像聚类，我们应用渐进束调整重建方法来学习表示底层形状的神经占据场。我们表明，该程序对之前步骤中引入的几种类型的错误（例如，错误的相机姿势、包含不同形状的图像等）是稳健的，使我们能够获得野外图像的形状和姿势注释。当使用Pix3D椅子的图像时，我们的方法能够在定量和定性方面产生比最先进的无监督3D重建技术更好的结果。此外，我们还展示了3DMiner如何通过重建LAION-5B数据集中图像中的形状来应用于野外数据。项目页面：https://ttchengab.github.io/3dminerOfficial et.al.|[2310.19188](http://arxiv.org/abs/2310.19188)|null|
|**2023-10-29**|**Towards Generalized Multi-stage Clustering: Multi-view Self-distillation**|现有的多阶段聚类方法从多个视图中独立地学习显著特征，然后执行聚类任务。特别是，多视图集群（MVC）在多视图或多模式场景中引起了很多关注。MVC旨在从多个视图中探索通用语义和伪标签，并以自监督的方式进行聚类。然而，受噪声数据和特征学习不足的限制，这种聚类范式会产生过于自信的伪标签，错误地引导模型产生不准确的预测。因此，希望有一种方法可以在多阶段聚类中纠正这种伪标签错误行为，以避免偏差累积。为了缓解过度自信的伪标签的影响，提高模型的泛化能力，本文提出了一种新的多阶段深度MVC框架，引入多视图自蒸馏（DistilMVC）来提取标签分布的暗知识。具体来说，在不同层次的特征子空间中，我们通过对比学习来探索多个视图的共同语义，并通过最大化视图之间的相互信息来获得伪标签。此外，教师网络负责将伪标签提取到暗知识中，监督学生网络并提高其预测能力以增强鲁棒性。在真实世界的多视图数据集上进行的大量实验表明，我们的方法比最先进的方法具有更好的聚类性能。 et.al.|[2310.18890](http://arxiv.org/abs/2310.18890)|null|
|**2023-10-27**|**Understanding the effect of curvature on the magnetization reversal of three-dimensional nanohelices**|理解三维（3D）纳米结构中几何结构和磁性之间的相互作用对于理解畴壁（DW）形成和钉扎的基本物理具有重要意义。在这里，我们使用聚焦电子束诱导沉积来制备具有随高度增加的螺旋曲率的磁性纳米螺旋。利用电子断层扫描和洛伦兹透射电子显微镜，我们重建了纳米螺旋的三维结构和磁化强度。然后从断层图像重建中量化纳米螺旋的表面曲率、螺旋曲率和扭转。此外，通过使用实验三维重建作为微磁模拟的输入，我们可以揭示表面和螺旋曲率对磁反转机制的影响。因此，我们可以将3D纳米螺旋的磁性行为与其实验结构直接关联起来。这些结果证明了如何利用纳米螺旋中几何形状的控制来稳定DW和控制纳米结构对所施加磁场的响应。 et.al.|[2310.18456](http://arxiv.org/abs/2310.18456)|null|
|**2023-10-25**|**Open-NeRF: Towards Open Vocabulary NeRF Decomposition**|在本文中，我们解决了从开放词汇中将神经辐射场（NeRF）分解为对象的挑战，这是三维重建和视图合成中对象操作的关键任务。当前的NeRF分解技术涉及处理开放词汇查询的灵活性和3D分割的准确性之间的权衡。我们提出了开放词汇嵌入式神经辐射场（Open NeRF），它利用了大规模现成的分割模型，如Segment Anything Model（SAM），并引入了一种具有分层嵌入的集成和提取范式，以实现开放词汇查询的灵活性和3D分割的准确性。Open NeRF首先利用大规模基础模型从不同的角度生成分层2D掩模方案。然后，通过跟踪方法将这些建议对齐，并将其集成在3D空间中，随后将其提取到3D领域中。这一过程确保了从不同角度对对象的一致识别和粒度，即使在涉及遮挡和模糊特征的具有挑战性的场景中也是如此。我们的实验结果表明，在开放词汇场景中，所提出的Open NeRF优于最先进的方法，如LERF\cite{LERF}和FFD\cite{FFD}。Open NeRF为NeRF分解提供了一个很有前途的解决方案，以开放词汇查询为指导，在开放世界3D场景中实现机器人和视觉语言交互的新应用。 et.al.|[2310.16383](http://arxiv.org/abs/2310.16383)|null|
|**2023-10-23**|**Novel-View Acoustic Synthesis from 3D Reconstructed Rooms**|我们研究了将盲音频记录与3D场景信息相结合用于新视图声学合成的好处。给定2-4个麦克风的音频记录以及包含多个未知声源的场景的3D几何形状和材料，我们估计场景中任何地方的声音。我们确定了新观点声学合成的主要挑战是声源定位、分离和去混响。虽然天真地训练端到端网络无法产生高质量的结果，但我们表明，结合从3D重建房间中导出的房间脉冲响应（RIR）使同一网络能够联合处理这些任务。我们的方法优于为单个任务设计的现有方法，证明了它在利用3D视觉信息方面的有效性。在对Matterport3D NVAS数据集的模拟研究中，我们的模型在源定位方面实现了近乎完美的精度，在源分离和去混响方面实现了26.44dB的PSNR和14.23dB的SDR，在新视图声学合成方面实现了25.55dB的PSNR和14.20dB的SDR。代码、预训练模型和视频结果可在项目网页上获得(https://github.com/apple/ml-nvas3d)。 et.al.|[2310.15130](http://arxiv.org/abs/2310.15130)|**[link](https://github.com/apple/ml-nvas3d)**|
|**2023-10-23**|**Interaction-Driven Active 3D Reconstruction with Object Interiors**|我们介绍了一种主动三维重建方法，该方法集成了视觉感知、机器人-物体交互和三维扫描，以恢复目标三维物体的外部和内部，即未暴露的几何形状。与主动视觉中专注于优化相机视点以更好地研究环境的其他工作不同，我们重建的主要特征是分析目标物体各个部分的相互作用性，以及机器人随后进行的部分操作，以实现对遮挡区域的扫描。因此，在完整的几何结构采集的基础上，获得了对目标物体的部分关节的理解。我们的方法由一个内置RGBD传感器的Fetch机器人完全自动操作。它在交互分析和交互驱动的重建之间迭代，一次扫描和重建检测到的可移动零件，其中关节零件检测和网格重建都由神经网络执行。在最后一步中，重建所有剩余的非铰接部件，包括通过先前部件操作暴露并随后扫描的所有内部结构，以完成采集。我们通过定性和定量评估、消融研究、与替代方案的比较以及在真实环境中的实验来证明我们的方法的性能。 et.al.|[2310.14700](http://arxiv.org/abs/2310.14700)|null|
|**2023-10-23**|**VQ-NeRF: Vector Quantization Enhances Implicit Neural Representations**|隐式神经表示的最新进展有助于高保真度的表面重建和真实感的新视图合成。然而，这些方法中固有的计算复杂性是一个巨大的障碍，限制了实际应用中可达到的帧速率和分辨率。针对这一困境，我们提出了VQ-NeRF，这是一种通过矢量量化增强隐式神经表示的有效管道。我们的方法的本质包括将NeRF的采样空间减少到较低的分辨率，然后使用预训练的VAE解码器将其恢复到原始大小，从而有效地缓解渲染过程中遇到的采样时间瓶颈。尽管码本提供了代表性的特征，但由于高压缩率，重建场景的精细纹理细节仍然具有挑战性。为了克服这一限制，我们设计了一种创新的多尺度NeRF采样方案，该方案在压缩和原始尺度上同时优化NeRF模型，以增强网络保存精细细节的能力。此外，我们引入了语义损失函数，以提高三维重建的几何保真度和语义连贯性。大量实验证明了我们的模型在实现渲染质量和效率之间的最佳权衡方面的有效性。对DTU、BlendMVS和H3DS数据集的评估证实了我们方法的卓越性能。 et.al.|[2310.14487](http://arxiv.org/abs/2310.14487)|null|
|**2023-10-22**|**A Quantitative Evaluation of Dense 3D Reconstruction of Sinus Anatomy from Monocular Endoscopic Video**|根据内窥镜视频生成准确的3D重建是对鼻窦解剖结构和手术结果进行纵向无辐射分析的一种很有前途的途径。已经提出了几种单目重建方法，通过从运动类型算法中检索具有结构的相对相机姿态并融合单目深度估计，产生视觉上令人愉快的3D解剖结构。然而，由于底层算法和内窥镜场景的复杂特性，重建管道可能表现不佳或意外失败。此外，获取医疗数据带来了额外的挑战，在定量基准测试这些模型、了解故障案例和确定有助于其准确性的关键组件方面存在困难。在这项工作中，我们对一种自监督的鼻窦重建方法进行了定量分析，该方法使用内窥镜序列与从9个离体标本中采集的光学跟踪和高分辨率计算机断层扫描相结合。我们的结果表明，生成的重建与解剖结构高度一致，在重建和CT分割之间产生0.91mm的平均点到网格误差。然而，在与内窥镜跟踪和导航相关的点对点匹配场景中，我们发现平均目标配准误差为6.58 mm。我们发现，姿态和深度估计的不准确度对该误差的贡献相同，轨迹较短的局部一致序列会产生更准确的重建。这些结果表明，实现相对相机姿态和估计深度与解剖结构之间的全局一致性至关重要。通过这样做，我们可以确保管道的所有组成部分之间的适当协同作用，以改进重建，从而促进这项创新技术的临床应用。 et.al.|[2310.14364](http://arxiv.org/abs/2310.14364)|null|
|**2023-10-20**|**Longer-range Contextualized Masked Autoencoder**|掩模图像建模（MIM）已成为一种很有前途的自监督学习（SSL）策略。MIM预训练通过随机掩蔽一些输入像素并从剩余的像素重建掩蔽的像素，有助于使用编码器-解码器框架来学习强大的表示。然而，由于编码器是用部分像素训练的，MIM预训练可能存在理解长程依赖性的能力低的问题。这种限制可能会阻碍其完全理解多个范围依赖性的能力，导致注意力图中突出显示的区域狭窄，从而可能导致准确性下降。为了减轻这种限制，我们提出了一个自监督学习框架，称为长距离上下文化屏蔽自动编码器（LC-MAE）。LC-MAE有效地利用了对视觉表示的全局上下文理解，同时减少了输入的空间冗余。我们的方法引导编码器从多个视图中的整个像素学习，同时也从稀疏像素学习局部表示。因此，LC-MAE学习了更多的判别表示，导致性能提高，在ImageNet-1K上使用ViT-B以0.6%p的增益实现84.2%的前1级精度。我们将成功归因于增强的预训练方法，奇异值谱和注意力分析证明了这一点。最后，LC-MAE在下游语义分割和细粒度视觉分类任务中实现了显著的性能提升；以及不同的稳健评估指标。我们的代码将公开。 et.al.|[2310.13593](http://arxiv.org/abs/2310.13593)|null|
|**2023-10-20**|**Single-view 3D reconstruction via inverse procedural modeling**|我们提出了一种通过逆过程建模进行三维重建的方法，并研究了该方法的两种变体。第一种选择是使用遗传算法对输入参数进行拟合。我们展示了我们在树模型（复杂对象）上的工作结果，其中重建是大多数现有方法无法处理的。第二种选择允许我们通过在模因算法、可微分渲染和可微分过程生成器中使用梯度来显著提高精度。在我们的工作中，我们看到了两个主要贡献。首先，我们提出了一种连接可微绘制和逆过程建模的方法。当有少量输入图像可用时（即使是单个图像），这为我们提供了一个比现有方法更准确地重建3D模型的机会。其次，我们将可微和不可微的过程生成器连接在一个框架中，这使我们能够将逆过程建模应用于相当复杂的生成器：当梯度可用时，重建是精确的，当梯度不可用时，重构是近似的，但总是高质量的，没有视觉伪影。 et.al.|[2310.13373](http://arxiv.org/abs/2310.13373)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-29**|**JEN-1 Composer: A Unified Framework for High-Fidelity Multi-Track Music Generation**|随着生成人工智能的快速发展，文本到音乐的合成任务已成为音乐生成的一个有希望的方向。然而，对多轨道生成的细粒度控制仍然是一个悬而未决的挑战。现有的模型表现出强大的原始生成能力，但缺乏创作单独曲目并以可控的方式组合它们的灵活性，这与人类作曲家的典型工作流程不同。为了解决这个问题，我们提出了JEN-1 Composer，这是一个统一的框架，可以通过单个模型对多音轨音乐上的边际、条件和联合分布进行有效建模。JEN-1 Composer框架显示出无缝结合任何基于扩散的音乐生成系统的能力，\textit｛例如｝JEN-1，增强了其多音轨音乐生成的能力。我们引入了一种课程培训策略，旨在逐步指导该模型从单轨迹生成向多轨迹组合的灵活生成过渡。在推断过程中，用户能够迭代地生成和选择符合他们偏好的音乐曲目，随后按照所提出的人工智能联合创作工作流逐步创建整个音乐作品。定量和定性评估表明，在可控和高保真的多音轨音乐合成方面，表现最先进。提出的JEN-1作曲家代表着在交互式人工智能促进的音乐创作和作曲方面的重大进步。Demos将在https://jenmusic.ai/audio-demos. et.al.|[2310.19180](http://arxiv.org/abs/2310.19180)|null|
|**2023-10-29**|**Linear optical properties of organic microcavity polaritons with non-Markovian Quantum State Diffusion**|腔模和激子到极化子态的混合以及到振动模的耦合决定了微腔中有机半导体的线性光学性质。在本文中，我们使用Holstein Tavis Cummings模型来计算这种系统的折射率，然后使用传递矩阵方法来确定线性光学性质。我们首先提取了模型中激子的参数，从拟合到实验测量的2，7-双[9,9-二（4-甲基苯基）-芴-2-基]-9，9-二（4-乙基苯基）芴（TDAF）分子薄膜的吸收。然后，我们通过在模型中加入色散微腔模式来计算这种薄膜在金属包层微腔系统中的反射率。我们使用非马尔可夫量子态扩散来计算仅演化为单个状态向量的模型系统的磁化率。在小角度（ $\leq30^\circ$ ）的估计误差条内，计算出的下极性子和上极性子的位置和高度与实验一致。对于较大的角度，极化激元共振的位置在估计误差内。 et.al.|[2310.19162](http://arxiv.org/abs/2310.19162)|null|
|**2023-10-29**|**Learning to Follow Object-Centric Image Editing Instructions Faithfully**|自然语言指令是一个强大的界面，用于编辑文本到图像扩散模型的输出。然而，需要解决几个挑战：1）规范性不足（需要对指令的隐含含义建模）2）基础性（需要定位必须执行编辑的地方），3）忠实性（需要保留不受编辑指令影响的图像元素）。目前专注于使用自然语言指令进行图像编辑的方法依赖于自动生成的成对数据，如我们的调查所示，这些数据是嘈杂的，有时是荒谬的，加剧了上述问题。在分割、思维链提示和视觉问答方面的最新进展的基础上，我们显著提高了配对数据的质量。此外，我们通过突出显示图像中需要根据指令更改的部分来增强监督信号。根据改进的数据进行微调的模型能够比最先进的基线更好地执行细粒度的以对象为中心的编辑，从而缓解上述问题，如自动和人工评估所示。此外，我们的模型能够推广到训练中看不见的领域，例如视觉隐喻。 et.al.|[2310.19145](http://arxiv.org/abs/2310.19145)|**[link](https://github.com/tuhinjubcse/faithfuledits_emnlp2023)**|
|**2023-10-29**|**Backward and Forward Inference in Interacting Independent-Cascade Processes: A Scalable and Convergent Message-Passing Approach**|我们研究了在网络上同时传播的两个扩散过程的过去和未来演变的估计问题。具体来说，给定一个已知的网络 $G=（V，\overright箭头｛E｝）$和一个（可能有噪声）快照$\mathcal{O}_n$，我们希望确定网络初始状态的后验分布及其节点的感染时间。这些分布有助于找到流行病和谣言的源节点$\textit｛向后推断｝$，并估计一组固定源节点$\textit｛向前推断｝美元的传播。为了模拟这两个过程之间的相互作用，我们研究了独立级联（IC）模型的扩展，其中，当一个节点感染其中一个过程时，它对另一个过程的易感性会发生变化。首先，我们导出网络初始状态和观测快照$\mathcal的精确联合概率{O}_n$ 。然后，使用因子图机制、因子图变换和广义分配律，我们导出了一种基于置信传播（BP）的算法，该算法可扩展到大型网络，并且可以收敛于任意拓扑的图（可能会牺牲近似精度）。 et.al.|[2310.19138](http://arxiv.org/abs/2310.19138)|null|
|**2023-10-29**|**Quest for the golden ratio universality class**|利用模式耦合理论，以闭形式给出了一维驱动系统中守恒模式的所有允许的动力学普适性类的条件，作为稳定电流及其导数的函数。从寻找黄金比例普适性类的角度出发，利用Onsager型宏观电流对称性，先验地排除了一些微观模型族的存在。在守恒量的平均密度相等的情况下，只有当电流在守恒密度的交换下是反对称的，并且这些密度是相关的，才可能出现金模，但在对称情况下，在等密度下，一个模总是扩散的，第二个模可能是Kardar Parisi Zhang（KPZ）、改进的KPZ，3/2-L'evy，也可能是扩散的。我们还证明了模式耦合理论对有噪声的谐振子链的预测是准确的。 et.al.|[2310.19116](http://arxiv.org/abs/2310.19116)|null|
|**2023-10-29**|**Bespoke Solvers for Generative Flow Models**|基于扩散或流动的模型是强大的生成范式，众所周知，它们很难采样，因为样本被定义为高维常微分方程或随机微分方程（ODEs/SDE）的解，需要大量的函数求值（NFE）才能很好地逼近。现有的缓解昂贵采样过程的方法包括模型蒸馏和设计专用的ODE求解器。然而，蒸馏的训练成本很高，有时会降低质量，而专用的溶解器仍然需要相对较大的NFE来生产高质量的样品。在本文中，我们介绍了“定制解算器”，这是一种新的框架，用于构建定制的ODE解算器，以适应给定的预训练流模型的ODE。我们的方法优化了阶数一致且参数高效的求解器（例如，具有80个可学习参数），训练时间约为训练预训练模型所需GPU时间的1%，与专用求解器相比，显著提高了近似和生成质量。例如，CIFAR10模型的定制解算器生成的样本的Fr’echet起始距离（FID）为2.73，具有10个NFE，并且对于仅具有20个NFE的该模型，该解算器获得了地面实况（GT）FID（2.59）的1%。在更具挑战性的ImageNet-64 $\times$ 64上，Bespoke以2.2 FID和10 NFE进行采样，并在20 NFE的GT FID（1.71）的2%以内。 et.al.|[2310.19075](http://arxiv.org/abs/2310.19075)|null|
|**2023-10-29**|**Machine Learning for the identification of phase-transitions in interacting agent-based systems**|推导降阶模型的闭合形式分析表达式，并明智地选择导致它们的闭合，长期以来一直是研究基于代理的模型（ABM）的相位和噪声诱导跃迁的策略。在本文中，我们提出了一个数据驱动的框架，该框架使用比传统闭式模型更少的变量，在平均场极限中精确定位ABM的相变。为此，我们使用流形学习算法扩散映射来识别一组简约的数据驱动潜变量，并证明它们与ABM的预期理论阶数参数一一对应。然后，我们利用深度学习框架来获得数据驱动坐标的保角重参数化，在我们的例子中，这有助于识别这些坐标中的单参数相关ODE。我们通过受数值积分方案（正向欧拉）启发的残差神经网络来识别这种ODE。然后，我们使用通过奇对称变换启用的已识别ODE来构建显示相变的分岔图。 et.al.|[2310.19039](http://arxiv.org/abs/2310.19039)|null|
|**2023-10-29**|**Controllable Group Choreography using Contrastive Diffusion**|音乐驱动的集体编舞带来了相当大的挑战，但在广泛的工业应用中具有巨大的潜力。能够产生与音乐相一致的同步且具有视觉吸引力的群舞动作，为娱乐、广告和虚拟表演等许多领域开辟了机会。然而，最近的大多数作品都无法产生高保真的长期运动，或者无法实现可控的体验。在这项工作中，我们旨在通过有效管理集体舞蹈编排的一致性和多样性来满足对高质量和可定制的集体舞蹈生成的需求。特别是，我们利用基于扩散的生成方法来实现灵活数量的舞者和长期群舞的合成，同时确保与输入音乐的连贯性。最后，我们引入了一种群体对比扩散（GCD）策略来增强舞者与其群体之间的联系，通过分类器引导采样技术来控制合成群体动画的一致性或多样性水平。通过深入的实验和评估，我们证明了我们的方法在产生视觉上迷人和一致的群舞动作方面的有效性。实验结果表明，我们的方法能够达到所需的一致性和多样性水平，同时保持生成的团体编排的整体质量。 et.al.|[2310.18986](http://arxiv.org/abs/2310.18986)|null|
|**2023-10-29**|**Homogenization of diffusions on the lattice ${\mathbf Z}^d$ with periodic drift coefficients; Application of logarithmic Sobolev inequality**|研究了具有周期漂移系数的以${\mathbf Z}^d$ 为索引的无穷维扩散过程的均匀化问题。应用基于对数Sobolev不等式的无穷维扩散过程的一致遍历定理，证明了从状态空间中几乎每个任意点开始的过程相对于不变测度的均匀化性质。这一结果也被解释为具有随机系数的无限维扩散的均匀化问题的解，该问题本质上类似于有限维中的已知问题。 et.al.|[2310.18973](http://arxiv.org/abs/2310.18973)|null|
|**2023-10-29**|**Adversarial Examples Are Not Real Features**|对抗性例子的存在多年来一直是个谜，引起了人们的极大兴趣。\citet｛ilyas2019adversarial｝的一个著名理论从数据的角度解释了对抗性漏洞，该理论表明，可以从对抗性示例中提取非鲁棒特征，并且这些特征单独用于分类。然而，这种解释仍然非常违背直觉，因为非鲁棒特征对人类来说大多是噪声特征。在本文中，我们通过整合多种学习范式，从更大的背景下重新审视这一理论。值得注意的是，我们发现，与它们在监督学习下的良好有用性相反，当转移到其他自监督学习范式时，非鲁棒特征的有用性较差，如对比学习、掩蔽图像建模和扩散模型。它揭示了非鲁棒特征并不像在这些范式之间具有良好可转移性的鲁棒或自然特征那样有用。同时，对于鲁棒性，我们还表明，在AutoAttack下，来自鲁棒特征的自然训练编码器在很大程度上是不鲁棒的。我们的跨范式检查表明，非鲁棒性特征并不是真正有用的，而是更像是范式上的捷径，仅凭鲁棒性特征可能不足以实现可靠的模型鲁棒性。代码位于\url{https://github.com/PKU-ML/AdvNotRealFeatures}。 et.al.|[2310.18936](http://arxiv.org/abs/2310.18936)|**[link](https://github.com/pku-ml/advnotrealfeatures)**|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-24**|**LiCROM: Linear-Subspace Continuous Reduced Order Modeling with Neural Fields**|线性降阶建模（ROM）通过使用简化的运动学表示来近似系统的行为，从而简化了复杂的模拟。通常，ROM在使用特定空间离散化创建的输入模拟上进行训练，然后用于使用相同的离散化加速模拟。这种离散化依赖性是有限制的。独立于特定的离散化将提供在训练数据中混合和匹配网格分辨率、连通性和类型（四面体、六面体）的灵活性；以在训练过程中看不到的新颖离散化来加速模拟；以及加速在时间上或参数化地改变离散化的自适应模拟。我们提出了一种灵活的、独立于离散化的降阶建模方法。与传统ROM一样，我们将配置表示为位移场的线性组合。与传统的ROM不同，我们的位移场是从参考域上的每个点到相应位移矢量的连续映射；这些映射被表示为隐式神经场。使用线性连续ROM（LiCROM），我们的训练集可以包括经历多个加载条件的多个几何体，与它们的离散化无关。这为降阶建模的新应用打开了大门。我们现在可以加速在运行时修改几何体的模拟，例如通过切割、打孔，甚至交换整个网格。我们还可以加速对训练中看不见的几何形状的模拟。我们演示了一次性泛化，在单个几何体上进行训练，然后模拟各种看不见的几何体。 et.al.|[2310.15907](http://arxiv.org/abs/2310.15907)|null|
|**2023-10-12**|**S4C: Self-Supervised Semantic Scene Completion with Neural Fields**|三维语义场景理解是计算机视觉中的一个基本挑战。它使移动代理能够自主规划和导航任意环境。SSC将这一挑战形式化为从场景的稀疏观测中联合估计密集的几何结构和语义信息。当前的SSC方法通常基于聚合的激光雷达扫描在3D地面实况上进行训练。这一过程依赖于特殊的传感器和手工注释，这些传感器和注释成本高昂且规模不大。为了克服这个问题，我们的工作提出了第一种称为S4C的SSC自监督方法，该方法不依赖于3D地面实况数据。我们提出的方法可以从单个图像重建场景，并且只依赖于训练期间从现成的图像分割网络生成的视频和伪分割地面实况。与使用离散体素网格的现有方法不同，我们将场景表示为隐式语义场。该公式允许查询相机截锥体内的任何点的占用率和语义类。我们的架构是通过基于渲染的自监督损失进行训练的。尽管如此，我们的方法实现了接近于完全监督的最先进方法的性能。此外，我们的方法表现出强大的泛化能力，可以为遥远的视点合成准确的分割图。 et.al.|[2310.07522](http://arxiv.org/abs/2310.07522)|null|
|**2023-10-07**|**HI-SLAM: Monocular Real-time Dense Mapping with Hybrid Implicit Fields**|在这封信中，我们提出了一个基于神经场的实时单目映射框架，用于精确和密集的同时定位和映射（SLAM）。最近的神经映射框架显示出有希望的结果，但依赖于RGB-D或姿势输入，或者无法实时运行。为了解决这些局限性，我们的方法将密集SLAM与神经隐式场相结合。具体来说，我们的密集SLAM方法运行并行跟踪和全局优化，而基于神经场的映射是基于最新的SLAM估计逐步构建的。为了有效地构造神经场，我们采用了多分辨率网格编码和符号距离函数（SDF）表示。这使我们能够始终保持地图的最新状态，并通过循环关闭立即适应全球更新。为了全局一致性，我们提出了一种有效的基于Sim（3）的姿态图束调整（PGBA）方法来运行在线闭环并减轻姿态和尺度漂移。为了进一步提高深度精度，我们结合了学习的单目深度先验。我们提出了一种新的深度和尺度联合调整（JDSA）模块来解决深度先验中固有的尺度模糊性。对合成和真实世界数据集的广泛评估验证了我们的方法在准确性和地图完整性方面优于现有方法，同时保持了实时性能。 et.al.|[2310.04787](http://arxiv.org/abs/2310.04787)|null|
|**2023-10-05**|**Variational Barycentric Coordinates**|我们提出了一种变分技术来优化广义重心坐标，与现有模型相比，该技术提供了额外的控制。先前的工作使用网格或闭式公式表示重心坐标，在实践中限制了目标函数的选择。相反，我们使用神经场直接参数化连续函数，该函数将多面体内部的任何坐标映射到其重心坐标。这个公式是通过我们对重心坐标的理论表征实现的，这使我们能够构建将有效坐标的整个函数类参数化的神经场。我们使用各种目标函数展示了我们模型的灵活性，包括多重光滑性和变形感知能量；作为补充，我们还提出了数学上合理的方法来测量和最小化目标，如不连续神经场的总变化。我们提供了一个实用的加速策略，对我们的算法进行了彻底的验证，并展示了几个应用。 et.al.|[2310.03861](http://arxiv.org/abs/2310.03861)|null|
|**2023-10-05**|**High-Degrees-of-Freedom Dynamic Neural Fields for Robot Self-Modeling and Motion Planning**|机器人自模型是机器人物理形态的任务不可知表示，在没有经典几何运动学模型的情况下，可用于运动规划任务。特别是，当后者难以设计或机器人的运动学发生意外变化时，人类自由的自我建模是真正自主智能体的必要特征。在这项工作中，我们利用神经场使机器人能够将其运动学自建模为仅从带有相机姿势和配置的2D图像中学习的神经隐式查询模型。这使得比依赖于深度图像或几何知识的现有方法具有更大的适用性。为此，除了课程数据采样策略外，我们还提出了一种新的基于编码器的神经密度场架构，用于高自由度（DOF）条件下的动态对象中心场景。在7自由度机器人测试装置中，学习的自模型实现了机器人工作空间尺寸2%的倒角-L2距离。作为一个示例性的下游应用程序，我们展示了该模型在运动规划任务中的能力。 et.al.|[2310.03624](http://arxiv.org/abs/2310.03624)|null|
|**2023-10-02**|**Neural Processing of Tri-Plane Hybrid Neural Fields**|在用于存储和通信3D数据的神经场的吸引人的特性的驱动下，直接处理它们以解决分类和零件分割等任务的问题已经出现，并在最近的工作中进行了研究。早期的方法使用由在整个数据集上训练的共享网络参数化的神经场，实现了良好的任务性能，但牺牲了重建质量。为了改进后者，后来的方法侧重于参数化为大型多层感知器（MLP）的单个神经场，然而，由于权重空间的高维性、固有的权重空间对称性和对随机初始化的敏感性，这些神经元场的处理具有挑战性。因此，结果明显不如通过处理显式表示（例如点云或网格）所获得的结果。与此同时，混合表示，特别是基于三平面的混合表示，已经成为实现神经场的一种更有效的替代方案，但其直接处理尚未得到研究。在本文中，我们证明了三平面离散数据结构编码了丰富的信息，标准的深度学习机器可以有效地处理这些信息。我们定义了一个广泛的基准，涵盖了一组不同的字段，如占用率、有符号/无符号距离，以及首次定义的辐射字段。在处理具有相同重建质量的字段时，我们实现的任务性能远远优于处理大型MLP的框架，并且首次几乎与处理显式表示的架构不相上下。 et.al.|[2310.01140](http://arxiv.org/abs/2310.01140)|**[link](https://github.com/CVLAB-Unibo/triplane_processing)**|
|**2023-09-27**|**Neural Acoustic Context Field: Rendering Realistic Room Impulse Response With Neural Fields**|房间脉冲响应（RIR）测量声音在环境中的传播，对于合成给定环境下的高保真音频至关重要。一些先前的工作已经提出将RIR表示为声音发射器和接收器位置的神经场函数。然而，这些方法没有充分考虑音频场景的声学特性，导致性能不令人满意。这封信提出了一种新的神经声学上下文场方法，称为NACF，通过利用多个声学上下文（如几何结构、材料特性和空间信息）来参数化音频场景。在RIR的独特性质，即时间不光滑性和单调能量衰减的驱动下，我们设计了一个时间相关模块和多尺度能量衰减准则。实验结果表明，NACF的性能显著优于现有的基于字段的方法。请访问我们的项目页面了解更多定性结果。 et.al.|[2309.15977](http://arxiv.org/abs/2309.15977)|null|
|**2023-09-27**|**SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations**|隐式神经表示（INR）或神经场已成为编码多媒体信号（如图像和辐射场）同时保持高质量的流行框架。最近，Instant NGP提出的可学习特征网格通过用特征向量的多分辨率查找表和更小的神经网络取代大型神经网络，在训练和INR采样方面实现了显著的加速。然而，这些功能网格是以大量内存消耗为代价的，这可能是存储和流应用程序的瓶颈。在这项工作中，我们提出了SHACIRA，这是一个简单而有效的任务无关框架，用于压缩这种特征网格，而不需要额外的事后修剪/量化阶段。我们用量化的潜在权重对特征网格进行重新参数化，并在潜在空间中应用熵正则化，以在各个领域实现高水平的压缩。在由图像、视频和辐射场组成的不同数据集上的定量和定性结果表明，我们的方法优于现有的INR方法，而不需要任何大型数据集或特定领域的启发式方法。我们的项目页面可在http://shacira.github.io。 et.al.|[2309.15848](http://arxiv.org/abs/2309.15848)|null|
|**2023-09-27**|**NeuRBF: A Neural Fields Representation with Adaptive Radial Basis Functions**|我们提出了一种新型的神经场，它使用一般的径向基来表示信号。现有技术的神经领域通常依赖于用于存储局部神经特征的基于网格的表示和用于在连续查询点处插值特征的N维线性核。它们的神经特征的空间位置固定在网格节点上，不能很好地适应目标信号。相反，我们的方法建立在具有灵活内核位置和形状的通用径向基上，这些径向基具有更高的空间自适应性，可以更紧密地拟合目标信号。为了进一步提高径向基函数的信道容量，我们建议将它们与多频率正弦函数组合。该技术将径向基扩展到不同频带的多个傅立叶径向基，而不需要额外的参数，便于细节的表示。此外，通过将自适应径向基与基于网格的径向基相结合，我们的混合组合继承了自适应性和插值平滑性。我们精心设计了加权方案，使径向基有效地适应不同类型的信号。我们在2D图像和3D符号距离场表示上的实验证明了我们的方法比现有技术更高的精度和紧凑性。当应用于神经辐射场重建时，我们的方法实现了最先进的渲染质量，模型大小小，训练速度相当。 et.al.|[2309.15426](http://arxiv.org/abs/2309.15426)|**[link](https://github.com/oppo-us-research/NeuRBF)**|
|**2023-09-29**|**3D Reconstruction with Generalizable Neural Fields using Scene Priors**|由于神经领域的最新进展，高保真3D场景重建得到了实质性的推进。然而，大多数现有的方法为每个单独的场景从头开始训练单独的网络。这是不可扩展的，效率低下，并且在视图有限的情况下无法产生良好的结果。虽然基于学习的多视图立体方法在一定程度上缓解了这一问题，但它们的多视图设置使其扩展和广泛应用的灵活性降低。相反，我们引入了结合场景先验（NFP）的训练可推广神经场。NFP网络将任何单视图RGB-D图像映射为带符号的距离和辐射值。在没有融合模块的情况下，可以通过合并体积空间中的各个帧来重建完整的场景，这提供了更好的灵活性。场景先验可以在大规模数据集上进行训练，从而能够快速适应具有较少视图的新场景的重建。NFP不仅展示了SOTA场景重建的性能和效率，而且还支持单图像新视图合成，这在神经领域还没有得到充分的探索。更多定性结果可在以下网站获得：https://oasisyang.github.io/neural-prior et.al.|[2309.15164](http://arxiv.org/abs/2309.15164)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

