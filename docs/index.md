---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2026.02.04
> Usage instructions: [here](./docs/README.md#usage)

## Video Diffusion

- **2026-02-03** **3D-Aware Implicit Motion Control for View-Adaptive Human Video Generation** [2602.03796](http://arxiv.org/abs/2602.03796)
  > 视频生成中现有的人体运动控制方法通常依赖 2D 姿势或显式 3D 参数模型（例如 SMPL）作为控制信号。然而，2D 将运动严格绑定到驾驶视点，从而妨碍了新颖的视图合成。显式 3D 模型虽然在结构上信息丰富，但存在固有的不准确性（例如，深度模糊性和不准确的动态），当用作强约束时，会覆盖大型视频生成器强大的内在 3D 感知能力。在这项工作中，我们从 3D 感知的角度重新审视运动控制，提倡一种隐式的、与视图无关的运动表示，它自然地与生成器的空间先验对齐，而不是依赖于外部重建的约束。我们引入了 3DiMo，它联合训练运动编码器和预先训练的视频生成器，将驱动帧提取为紧凑的、与视图无关的运动标记，并通过交叉注意力进行语义注入。为了培养 3D 意识，我们通过丰富视图的监督（即单视图、多视图和移动摄像机视频）进行训练，强制不同视点之间的运动一致性。此外，我们使用辅助几何监督，仅利用 SMPL 进行早期初始化，并退火至零，使模型能够从外部 3D 指导过渡到从数据和生成器先验中学习真正的 3D 空间运动理解。实验证实，3DiMo 通过灵活的文本驱动摄像头控制忠实地再现了驾驶动作，在运动保真度和视觉质量方面都显着超越了现有方法。

- **2026-02-03** **BridgeV2W: Bridging Video Generation Models to Embodied World Models via Embodiment Masks** [2602.03793](http://arxiv.org/abs/2602.03793)
  > 具身世界模型已成为机器人技术中一个有前途的范例，其中大多数利用大规模互联网视频或预训练的视频生成模型来丰富视觉和运动先验。然而，它们仍然面临关键挑战：坐标空间动作和像素空间视频之间的不对准、对相机视点的敏感性以及跨实施例的非统一架构。为此，我们提出了 BridgeV2W，它将坐标空间动作转换为根据 URDF 和相机参数渲染的像素对齐的实施例掩模。然后，这些掩模通过 ControlNet 风格的路径注入到预训练的视频生成模型中，该路径将动作控制信号与预测视频对齐，添加特定于视图的调节以适应相机视点，并在各个实施例中生成统一的世界模型架构。为了减轻对静态背景的过度拟合，BridgeV2W 进一步引入了基于流的运动损失，专注于学习动态和任务相关区域。在单臂 (DROID) 和双臂 (AgiBot-G1) 数据集上进行的实验涵盖了具有未见过的视点和场景的多样化且具有挑战性的条件，结果表明，与之前最先进的方法相比，BridgeV2W 提高了视频生成质量。我们进一步展示了 BridgeV2W 在下游现实世界任务中的潜力，包括政策评估和目标条件规划。更多结果可以在我们的项目网站 https://BridgeV2W.github.io 上找到。

- **2026-02-03** **How do people watch AI-generated videos of physical scenes?** [2602.03374](http://arxiv.org/abs/2602.03374)
  > 人工智能生成的真实视频在媒体平台上日益盛行，事实与虚构之间的界限日益模糊，削弱了公众的信任。了解人们如何观看人工智能生成的视频，为改进人工智能检测和指导视频生成的进步提供了以人为本的视角。然而，现有研究尚未调查人类对人工智能生成的物理场景视频的注视行为。在这里，我们收集并分析了 40 名参与者在视频理解和 AI 检测任务中的眼球运动，这些任务涉及现实世界和 AI 生成的视频的混合。我们发现，鉴于人工智能生成的视频具有高度真实性，注视行为较少受视频的实际真实性驱动，而更多地受观看者对其真实性的感知所驱动。我们的结果表明，仅仅意识到潜在的人工智能生成可能会将媒体消费从被动观看转变为主动寻找异常现象。

- **2026-02-03** **InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation** [2602.03242](http://arxiv.org/abs/2602.03242)
  > 自动驾驶依赖于经过高质量、大规模多视图驾驶视频训练的稳健模型。虽然世界模型为生成逼真的驾驶视频提供了一种经济高效的解决方案，但它们很难保持实例级的时间一致性和空间几何保真度。为了应对这些挑战，我们提出了 InstaDrive，这是一种新颖的框架，它通过两个关键的进步来增强驾驶视频的真实感：(1) Instance Flow Guider，它跨帧提取和传播实例特征以强制时间一致性，随着时间的推移保留实例身份。 (2) 空间几何对齐器，它改进了空间推理，确保精确的实例定位，并显式地建模遮挡层次结构。通过整合这些实例感知机制，InstaDrive 实现了最先进的视频生成质量，并增强了 nuScenes 数据集上的下游自动驾驶任务。此外，我们利用 CARLA 的自动驾驶仪以程序和随机方式模拟跨不同地图和区域的罕见但安全关键的驾驶场景，从而为自动驾驶系统提供严格的安全评估。我们的项目页面是https://shanpoyang654.github.io/InstaDrive/page.html。

- **2026-02-03** **ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask** [2602.03213](http://arxiv.org/abs/2602.03213)
  > 自动驾驶依赖于在大规模、高质量多视图驾驶视频上训练的强大模型。尽管世界模型为生成真实驾驶数据提供了一种经济高效的解决方案，但它们经常遭受身份漂移的困扰，即由于缺乏实例级时间约束，同一对象在不同帧之间改变其外观或类别。我们引入了 ConsisDrive，这是一种身份保护的驾驶世界模型，旨在在实例级别强制执行时间一致性。我们的框架包含两个关键组成部分：（1）实例掩码注意力，它在注意力块中应用实例身份掩码和轨迹掩码，以确保视觉标记仅与跨空间和时间维度的相应实例特征交互，从而保持对象身份一致性； (2) 实例掩蔽损失，通过概率实例掩蔽自适应地强调前景区域，减少背景噪声，同时保持整体场景保真度。通过集成这些机制，ConsisDrive 实现了最先进的驾驶视频生成质量，并在 nuScenes 数据集上展示了下游自动驾驶任务的显着改进。我们的项目页面是https://shanpoyang654.github.io/ConsisDrive/page.html。

- **2026-02-03** **Quant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantization** [2602.02958](http://arxiv.org/abs/2602.02958)
  > 尽管自回归视频扩散取得了快速进展，但一个新兴的系统算法瓶颈限制了可部署性和生成能力：KV 缓存。在自回归视频生成模型中，KV 缓存随着生成历史而增长，并迅速占据 GPU 内存，通常超过 30 GB，从而阻碍了在广泛可用的硬件上的部署。更关键的是，有限的 KV 缓存预算限制了有效的工作内存，直接降低了身份、布局和运动的长期一致性。为了应对这一挑战，我们提出了 Quant VideoGen (QVG)，这是一种用于自回归视频扩散模型的免训练 KV 缓存量化框架。 QVG 通过语义感知平滑来利用视频时空冗余，产生低幅度、量化友好的残差。它还引入了渐进残差量化，这是一种从粗到细的多级方案，可减少量化误差，同时实现平滑的质量内存权衡。在 LongCat Video、HY WorldPlay 和 Self Forcing 基准测试中，QVG 在质量和内存效率之间建立了新的帕累托前沿，将 KV 缓存内存减少多达 7.0 倍，端到端延迟开销低于 4%，同时在生成质量方面始终优于现有基准。

- **2026-02-02** **Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation** [2602.02214](http://arxiv.org/abs/2602.02214)
  > 为了实现实时交互式视频生成，当前的方法将预训练的双向视频扩散模型提炼为少步自回归（AR）模型，当完全注意力被因果注意力取代时，面临着架构差距。然而，现有的方法在理论上并不能弥合这一差距。他们通过 ODE 蒸馏来初始化 AR 学生，这需要帧级注入性，其中每个噪声帧必须映射到 AR 教师的 PF-ODE 下的唯一干净帧。从双向教师中提取 AR 学生违反了此条件，从而阻止了教师流程图的恢复，而是引入了条件期望解决方案，从而降低了性能。为了解决这个问题，我们提出因果强迫，它使用 AR 教师进行 ODE 初始化，从而弥合架构差距。实证结果表明，我们的方法在所有指标上都优于所有基线，在动态度上超过 SOTA 自强迫 19.3%，在 VisionReward 上超过 8.7%，在指令跟随上超过 16.7%。项目页面和代码：\href{https://thu-ml.github.io/CausalForcing.github.io/}{https://thu-ml.github.io/CausalForcing.github.io/}

- **2026-02-02** **FSVideo: Fast Speed Video Diffusion Model in a Highly-Compressed Latent Space** [2602.02092](http://arxiv.org/abs/2602.02092)
  > 我们介绍 FSVideo，一种基于高速转换器的图像到视频 (I2V) 扩散框架。我们的框架基于以下关键组件：1.）具有高度压缩潜在空间（ $64\times64\times4$ 时空下采样率）的新视频自动编码器，实现有竞争力的重建质量； 2.) 扩散变压器 (DIT) 架构，采用新的层内存设计，以增强 DIT 内的层间信息流和上下文重用，以及 3.) 通过几步 DIT 上采样器的多分辨率生成策略，以提高视频保真度。我们的最终模型包含一个 14B DIT 基础模型和一个 14B DIT 上采样器，与其他流行的开源模型相比，其性能具有竞争力，同时速度快了一个数量级。我们在本报告中讨论了我们的模型设计以及培训策略。

- **2026-02-02** **Grounding Generated Videos in Feasible Plans via World Models** [2602.01960](http://arxiv.org/abs/2602.01960)
  > 大规模视频生成模型已经显示出作为零镜头视觉规划器的新兴功能，但视频生成的计划经常违反时间一致性和物理约束，导致映射到可执行动作时失败。为了解决这个问题，我们提出了基于世界模型的视频计划（GVP-WM），这是一种使用学习的动作条件世界模型将视频生成的计划转化为可行的动作序列的规划方法。在测试时，GVP-WM 首先根据初始观察和目标观察生成视频计划，然后通过视频引导的潜在搭配将视频引导投影到多种动态可行的潜在轨迹上。特别是，我们将基础制定为目标条件潜在空间轨迹优化问题，在世界模型动态下联合优化潜在状态和动作，同时保持与视频生成计划的语义对齐。根据经验，GVP-WM 从零镜头图像到视频生成的运动模糊视频中恢复了可行的长期计划，这些视频违反了导航和操作模拟任务的物理约束。

- **2026-02-02** **GPD: Guided Progressive Distillation for Fast and High-Quality Video Generation** [2602.01814](http://arxiv.org/abs/2602.01814)
  > 扩散模型在视频生成方面取得了显着的成功；然而，去噪过程的高计算成本仍然是一个主要瓶颈。现有方法在减少扩散步骤数量方面表现出了希望，但在应用于视频生成时，它们常常会出现质量显着下降的问题。我们提出了引导渐进蒸馏（GPD），这是一个加速扩散过程以快速生成高质量视频的框架。 GPD 引入了一种新颖的训练策略，其中教师模型逐步引导学生模型以更大的步长进行操作。该框架由两个关键组件组成：（1）在线生成的训练目标，可降低优化难度，同时提高计算效率；（2）潜在空间中的频域约束，可促进细粒度细节和时间动态的保存。应用于 Wan2.1 模型时，GPD 将采样步骤数从 48 个减少到 6 个，同时在 VBench 上保持有竞争力的视觉质量。与现有的蒸馏方法相比，GPD 在管道简单和质量保存方面都表现出明显的优势。

- **2026-02-02** **Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention** [2602.01801](http://arxiv.org/abs/2602.01801)
  > 自回归视频扩散模型支持流式生成，为长格式合成、视频世界模型和交互式神经游戏引擎打开了大门。然而，它们的核心注意力层成为推理时的主要瓶颈：随着生成的进展，KV 缓存不断增长，导致延迟增加和 GPU 内存不断增加，这反过来又限制了可用的时间上下文并损害了远程一致性。在这项工作中，我们研究了自回归视频扩散中的冗余，并确定了三个持久源：跨帧的近乎重复的缓存键、缓慢演变的（主要是语义的）查询/键，这使得许多注意力计算变得冗余，以及长提示上的交叉注意力，其中每帧只有一小部分标记很重要。基于这些观察，我们提出了一个用于自回归扩散的统一的、免训练的注意力框架：TempCache 通过时间对应来压缩 KV 缓存以限制缓存增长； AnnCA 通过使用快速近似最近邻 (ANN) 匹配选择与帧相关的提示标记来加速交叉注意力； AnnSA 通过将每个查询限制为语义匹配的键（也使用轻量级 ANN）来稀疏自注意力。这些模块共同减少了注意力、计算和记忆，并且与现有的自回归扩散主干和世界模型兼容。实验证明，端到端加速高达 x5--x10，同时保持几乎相同的视觉质量，最重要的是，在长期部署过程中保持稳定的吞吐量和几乎恒定的峰值 GPU 内存使用量，而之前的方法会逐渐减慢速度并受到内存使用量增加的影响。

- **2026-02-02** **FastPhysGS: Accelerating Physics-based Dynamic 3DGS Simulation via Interior Completion and Adaptive Optimization** [2602.01723](http://arxiv.org/abs/2602.01723)
  > 将 3D 高斯溅射 (3DGS) 扩展到 4D 物理模拟仍然具有挑战性。基于质点方法（MPM），现有方法要么依赖于手动参数调整，要么从视频扩散模型中提取动力学，限制了泛化和优化效率。最近使用 LLM/VLM 的尝试遇到了文本/图像到 3D 感知差距，产生不稳定的物理行为。此外，他们经常忽略 3DGS 的表面结构，导致难以置信的运动。我们提出了 FastPhysGS，这是一种基于物理的动态 3DGS 模拟的快速而强大的框架：(1) 实例感知粒子填充 (IPF) 和蒙特卡罗重要性采样 (MCIS)，可有效填充内部粒子，同时保持几何保真度； (2) 双向图解耦优化 (BGDO)，一种自适应策略，可快速优化 VLM 预测的材料参数。实验表明，FastPhysGS 仅使用 7 GB 运行时内存即可在 1 分钟内实现高保真物理模拟，其性能优于先前的工作，具有广泛的潜在应用。

- **2026-02-02** **PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards** [2602.01624](http://arxiv.org/abs/2602.01624)
  > 文本到视频 (T2V) 生成旨在合成具有高视觉质量和时间一致性的视频，这些视频在语义上与输入文本一致。基于奖励的后期训练已成为提高生成视频的质量和语义对齐的有前途的方向。然而，最近的方法要么依赖于大规模的人类偏好注释，要么对预先训练的视觉语言模型中未对齐的嵌入进行操作，导致可扩展性有限或监督不理想。我们提出了 $\texttt{PISCES}$，这是一种无注释的训练后算法，它通过新颖的双最优传输 (OT) 对齐奖励模块解决了这些限制。为了使奖励信号与人类判断保持一致，$\texttt{PISCES}$ 使用 OT 在分布式和离散令牌级别上桥接文本和视频嵌入，使奖励监督能够实现两个目标：(i) 与分布式 OT 一致的质量奖励，捕获整体视觉质量和时间连贯性； (ii) 离散令牌级 OT 对齐语义奖励，强制文本和视频令牌之间的语义、时空对应。据我们所知，$\texttt{PISCES}$ 是第一个通过 OT 视角改进生成后训练中无注释奖励监督的项目。短视频和长视频生成的实验表明，$\texttt{PISCES}$ 在质量和语义分数方面均优于 VBench 上基于注释和无注释的方法，人类偏好研究进一步验证了其有效性。我们证明了双 OT 对齐奖励模块与多种优化范例兼容，包括直接反向传播和强化学习微调。

- **2026-02-02** **Omni-Judge: Can Omni-LLMs Serve as Human-Aligned Judges for Text-Conditioned Audio-Video Generation?** [2602.01623](http://arxiv.org/abs/2602.01623)
  > Sora 2 和 Veo 3 等最先进的文本到视频生成模型现在可以直接从文本提示生成具有同步音频的高保真视频，标志着多模式生成的新里程碑。然而，评估这种三模式输出仍然是一个尚未解决的挑战。人工评估可靠，但成本高昂且难以扩展，而 FVD、CLAP 和 ViCLIP 等传统自动指标则侧重于孤立的模态对，难以处理复杂的提示，并且可解释性有限。全模态大语言模型（omni-LLM）提供了一种有前途的替代方案：它们自然地处理音频、视频和文本，支持丰富的推理，并提供可解释的思想链反馈。受此推动，我们推出了 Omni-Judge，这是一项评估全向法学硕士是否可以充当文本调节音频视频生成的人类法官的研究。在九个感知和对齐指标中，Omni-Judge 实现了与传统指标相当的相关性，并在语义要求较高的任务上表现出色，例如音频文本对齐、视频文本对齐和音频视频文本一致性。由于时间分辨率有限，它在高 FPS 感知指标（包括视频质量和音视频同步）上表现不佳。 Omni-Judge 提供可解释的解释，揭示语义或物理不一致之处，从而实现实际的下游用途，例如基于反馈的细化。我们的研究结果强调了全位法学硕士作为多模式生成的统一评估者的潜力和当前局限性。

- **2026-02-02** **Making Avatars Interact: Towards Text-Driven Human-Object Interaction for Controllable Talking Avatars** [2602.01538](http://arxiv.org/abs/2602.01538)
  > 生成会说话的头像是视频生成中的一项基本任务。尽管现有方法可以通过简单的人体动作生成全身说话的化身，但将此任务扩展到接地人与物体交互（GHOI）仍然是一个开放的挑战，要求化身与周围的物体执行文本对齐的交互。这一挑战源于对环境感知的需求和 GHOI 一代的控制质量困境。为了解决这个问题，我们提出了一种新颖的双流框架 InteractAvatar，它将感知和规划与视频合成解耦，以实现基础的人机交互。利用检测来增强环境感知，我们引入了感知和交互模块（PIM）来生成文本对齐的交互动作。此外，还提出了音频交互感知生成模块（AIM）来合成执行对象交互的生动的说话化身。借助专门设计的运动到视频对齐器，PIM 和 AIM 共享相似的网络结构，并能够并行共同生成运动和合理的视频，有效缓解控制质量困境。最后，我们建立了一个基准 GroundedInter，用于评估 GHOI 视频生成。大量的实验和比较证明了我们的方法在为说话的化身生成接地的人机交互方面的有效性。项目页面：https://interactavatar.github.io

- **2026-02-01** **MTC-VAE: Multi-Level Temporal Compression with Content Awareness** [2602.01340](http://arxiv.org/abs/2602.01340)
  > 潜在视频扩散模型 (LVDM) 依靠变分自动编码器 (VAE) 将视频压缩为紧凑的潜在表示。对于连续变分自动编码器（VAE），需要实现更高的压缩率；然而，当添加额外的采样层而不扩展隐藏通道的维度时，效率显着下降。在本文中，我们提出了一种将固定压缩率 VAE 转换为支持多级时间压缩的模型的技术，提供了一种简单且最小的微调方法来抵消压缩率提高时的性能下降。此外，我们研究了不同的压缩级别如何影响具有不同特征的视频片段的模型性能，为我们提出的方法的有效性提供了经验证据。我们还研究了多级时间压缩 VAE 与基于扩散的生成模型 DiT 的集成，强调了这些框架内成功的并发训练和兼容性。这项研究说明了多级时间压缩的潜在用途。

- **2026-02-01** **FlowCast: Trajectory Forecasting for Scalable Zero-Cost Speculative Flow Matching** [2602.01329](http://arxiv.org/abs/2602.01329)
  > 流匹配 (FM) 最近已成为高质量视觉生成的强大方法。然而，由于大量的去噪步骤，它们的推理速度极其缓慢，限制了它们在实时或交互式应用程序中的潜在使用。现有的加速方法，如蒸馏、截断或一致性训练，要么会降低质量，要么需要昂贵的再训练成本，要么缺乏泛化性。我们提出了 FlowCast，这是一种无需训练的推测生成框架，它利用 FM 模型经过训练以保持恒定速度这一事实来加速推理。 FlowCast 通过推断当前速度来推测未来速度，而不会产生额外的时间成本，如果它在均方误差阈值内，则接受它。这种恒速预测允许积极跳过稳定区域中的冗余步骤，同时保持复杂区域中的精度。 FlowCast 是一个即插即用框架，可与任何 FM 模型无缝集成，无需辅助网络。我们还提出了理论分析，并限制了推测轨迹和完整 FM 轨迹之间的最坏情况偏差。实证评估表明，FlowCast 在图像生成、视频生成和编辑任务方面实现了 $>2.5\times$ 加速，优于现有基线，与标准完整生成相比，没有质量损失。

- **2026-01-31** **MTAVG-Bench: A Comprehensive Benchmark for Evaluating Multi-Talker Dialogue-Centric Audio-Video Generation** [2602.00607](http://arxiv.org/abs/2602.00607)
  > 文本转音频视频 (T2AV) 生成技术的最新进展使模型能够通过多方对话合成视听视频。然而，现有的评估基准仍然主要是针对人类录制的视频或单扬声器设置而设计的。因此，无法有效捕获和分析生成的多人对话视频中出现的潜在错误，例如身份漂移、不自然的转弯转换和视听错位。为了解决这个问题，我们引入了 MTAVG-Bench，这是一个评估视听多说话人对话生成的基准。 MTAVG-Bench 通过半自动管道构建，其中使用多个流行模型和精心设计的提示生成 1.8k 个视频，产生 2.4k 个手动注释的 QA 对。该基准测试从四个层面评估多说话人对话的生成：视听信号保真度、时间属性一致性、社交互动和电影表达。我们在 MTAVG-Bench 上对 12 个专有和开源全向型号进行了基准测试，其中 Gemini 3 Pro 实现了最强的整体性能，而领先的开源型号在信号保真度和一致性方面仍然具有竞争力。总体而言，MTAVG-Bench 能够进行细粒度的故障分析，以进行严格的模型比较和有针对性的视频生成细化。

- **2026-01-30** **VideoGPA: Distilling Geometry Priors for 3D-Consistent Video Generation** [2601.23286](http://arxiv.org/abs/2601.23286)
  > 虽然最近的视频扩散模型 (VDM) 产生了令人印象深刻的视觉效果，但它们从根本上难以保持 3D 结构一致性，常常导致对象变形或空间漂移。我们假设这些失败的出现是因为标准去噪目标缺乏对几何一致性的明确激励。为了解决这个问题，我们引入了 VideoGPA（视频几何偏好对齐），这是一种数据高效的自我监督框架，利用几何基础模型自动导出密集偏好信号，通过直接偏好优化 (DPO) 指导 VDM。这种方法有效地将生成分布引导至固有的 3D 一致性，而不需要人工注释。 VideoGPA 使用最小偏好对显着增强了时间稳定性、物理合理性和运动连贯性，在广泛的实验中始终优于最先进的基线。

- **2026-01-29** **VMonarch: Efficient Video Diffusion Transformers with Structured Attention** [2601.22275](http://arxiv.org/abs/2601.22275)
  > 注意力机制的二次复杂度严重限制了视频扩散变压器（DiT）的上下文可扩展性。我们发现视频 DiT 中表现出的高度稀疏的时空注意力模式可以自然地用 Monarch 矩阵表示。它是一类具有灵活稀疏性的结构化矩阵，通过交替最小化算法实现次二次关注。因此，我们提出了 VMonarch，这是一种针对视频 DiT 的新型注意机制，它能够利用结构化 Monarch 矩阵对动态稀疏模式进行有效计算。首先，我们采用时空 Monarch 分解来明确捕获视频数据的帧内和帧间相关性。其次，我们引入了一种重新计算策略，以减轻 Monarch 矩阵交替最小化过程中因不稳定性而产生的伪影。第三，我们提出了一种融合到 FlashAttention 中的新型在线熵算法，可以实现长序列的快速 Monarch 矩阵更新。大量实验表明，VMonarch 经过最少的调整后，在 VBench 上实现了可比或更高的生成质量，以充分关注。它克服了视频 DiT 中的注意力瓶颈，将注意力 FLOP 减少了 17.5 倍，并且在长视频的注意力计算中实现了超过 5 倍的加速，在稀疏度为 90% 的情况下超越了最先进的稀疏注意力方法。

- **2026-01-29** **JUST-DUB-IT: Video Dubbing via Joint Audio-Visual Diffusion** [2601.22143](http://arxiv.org/abs/2601.22143)
  > 经过预先训练以联合生成声音和视觉内容的视听基础模型最近显示出前所未有的多模式生成和编辑建模能力，为下游任务开辟了新的机会。在这些任务中，视频配音可以从这些先验中受益匪浅，但大多数现有解决方案仍然依赖于复杂的、特定于任务的管道，而这些管道在现实环境中举步维艰。在这项工作中，我们引入了一种单模型方法，该方法通过轻量级 LoRA 采用基础音视频扩散模型进行视频到视频配音。 LoRA 使模型能够根据输入音频-视频进行调节，同时联合生成翻译后的音频和同步的面部运动。为了训练这个 LoRA，我们利用生成模型本身来合成同一说话者的配对多语言视频。具体来说，我们在单个剪辑中生成带有语言切换的多语言视频，然后修复每一半的面部和音频以匹配另一半的语言。通过利用视听模型丰富的生成先验，我们的方法保留了说话者身份和唇形同步，同时对复杂的运动和现实世界的动态保持鲁棒性。我们证明，与现有的配音流程相比，我们的方法可以生成高质量的配音视频，具有更高的视觉保真度、口型同步和鲁棒性。

- **2026-01-29** **EditYourself: Audio-Driven Generation and Manipulation of Talking Head Videos with Diffusion Transformers** [2601.22127](http://arxiv.org/abs/2601.22127)
  > 当前的生成视频模型擅长根据文本和图像提示生成新颖的内容，但在编辑现有预先录制的视频时留下了关键的空白，其中对口语脚本的微小更改需要保留运动、时间连贯性、说话者身份和准确的唇形同步。我们推出了 EditYourself，这是一个基于 DiT 的音频驱动视频到视频 (V2V) 编辑框架，可以对头部说话视频进行基于转录的修改，包括无缝添加、删除和重新定时视觉语音内容。 EditYourself 以通用视频扩散模型为基础，通过音频调节和区域感知、以编辑为重点的培训扩展增强了其 V2V 功能。这可以通过时空修复实现精确的口型同步和对现有表演的时间连贯重组，包括在新添加的片段中合成真实的人体运动，同时在长时间内保持视觉保真度和身份一致性。这项工作代表了生成视频模型作为专业视频后期制作实用工具的基础性一步。

- **2026-01-29** **Learning Transient Convective Heat Transfer with Geometry Aware World Models** [2601.22086](http://arxiv.org/abs/2601.22086)
  > 偏微分方程 (PDE) 模拟是工程和物理学的基础，但对于实时应用来说，计算量往往过高。虽然生成式人工智能为代理建模提供了一种有前景的途径，但标准视频生成架构缺乏物理模拟所需的特定控制和数据兼容性。本文介绍了一种几何感知世界模型架构，该架构源自视频生成架构（LongVideoGAN），旨在学习瞬态物理。我们引入了两个关键的架构元素：（1）结合全局物理参数和局部几何掩模的双重调节机制，以及（2）支持任意通道尺寸的架构适应，超越标准 RGB 约束。我们在二维瞬态计算流体动力学 (CFD) 问题上评估了这种方法，该问题涉及浮力驱动流与固体结构中热流耦合的对流换热。我们证明，条件模型成功地再现了训练数据的复杂时间动态和空间相关性。此外，我们评估了模型对未见过的几何配置的泛化能力，强调了其受控模拟合成的潜力以及当前分布外样本空间精度的限制。

- **2026-01-30** **Where Do the Joules Go? Diagnosing Inference Energy Consumption** [2601.22076](http://arxiv.org/abs/2601.22076)
  > 能源现在是一种重要的 ML 计算资源。虽然测量能耗和观察趋势是有价值的第一步，但准确理解和诊断出现这些差异的原因对于优化至关重要。为此，我们首先在 NVIDIA H100 和 B200 GPU 上使用 46 个模型、7 个任务和 1,858 种不同配置，对生成式 AI 领域的推理时间和能量进行大规模测量研究。我们的实证研究结果存在数量级的差异：LLM 任务类型可能会导致 25 $\times$ 的能量差异，视频生成有时会消耗超过 100$\times$ 图像的能量，而 GPU 利用率差异可能会导致 3--5$\times$ 的能量差异。根据我们的观察，我们提出了一个框架来推理控制时间和能源消耗的基本机制。本质上，时间和能量是由内存和利用率等潜在指标决定的，而这些指标又受到算法、软件和硬件层的各种因素的影响。我们的框架还直接扩展到每瓦吞吐量，这是功率受限的数据中心的一个关键指标。

- **2026-01-29** **Zero-Shot Video Restoration and Enhancement with Assistance of Video Diffusion Models** [2601.21922](http://arxiv.org/abs/2601.21922)
  > 尽管基于扩散的零样本图像恢复和增强方法取得了巨大成功，但将其应用于视频恢复或增强会导致严重的时间闪烁。在本文中，我们提出了第一个框架，利用快速发展的视频扩散模型来协助基于图像的方法保持更多的时间一致性，以实现零镜头视频恢复和增强。我们提出同源潜在融合、异质潜在融合和基于 COT 的融合比率策略，以利用同源和异质文本到视频扩散模型来补充图像方法。此外，我们提出时间强化后处理，以利用图像到视频扩散模型进一步提高时间一致性。我们的方法无需训练，可应用于任何基于扩散的图像恢复和增强方法。实验结果证明了该方法的优越性。

- **2026-01-29** **Past- and Future-Informed KV Cache Policy with Salience Estimation in Autoregressive Video Diffusion** [2601.21896](http://arxiv.org/abs/2601.21896)
  > 视频生成对于数字媒体创作至关重要，自回归视频生成的最新进展显着提高了实时视频合成的效率。然而，现有方法通常依赖于启发式 KV 缓存策略，该策略忽略了长期视频生成中令牌重要性的差异。这会导致关键时空信息的丢失以及冗余、无效缓存的积累，从而降低视频生成质量和效率。为了解决这个限制，我们首先观察到视频生成的代币贡献具有高度的时间异质性，因此提出了一种新颖的过去和未来通知的 KV 缓存策略（PaFu-KV）。具体来说，PaFu-KV 引入了一个从双向教师中提取的轻量级显着性估计头来估计显着性分数，允许 KV 缓存保留信息丰富的标记，同时丢弃不太相关的标记。该策略通过缩小 KV 缓存容量并减少推理时的内存占用，实现更好的质量效率权衡。对基准的大量实验表明，我们的方法保留了高保真视频生成质量，同时能够加速推理，从而实现更高效的长视野视频生成。我们的代码将在论文接受后发布。

- **2026-01-29** **MPF-Net: Exposing High-Fidelity AI-Generated Video Forgeries via Hierarchical Manifold Deviation and Micro-Temporal Fluctuations** [2601.21408](http://arxiv.org/abs/2601.21408)
  > 随着Veo和Wan等视频生成模型的快速进步，合成内容的视觉质量已经达到了宏观语义错误和时间不一致不再突出的水平。然而，这并不意味着真品和尖端高保真假货之间的区别是无迹可寻的。我们认为人工智能生成的视频本质上是流形拟合过程的产物，而不是物理记录。因此，AI视频中连续相邻帧残差的像素组成逻辑表现出结构化和同质的特征。我们将这种现象称为“流形投影波动”(MPF)。在这种见解的驱动下，我们提出了一个分层双路径框架，该框架作为顺序过滤过程运行。第一个是静态流形偏差分支，利用大规模视觉基础模型 (VFM) 的精细感知边界来捕获偏离自然现实世界流形（流形外）的残余空间异常或物理违规。对于成功驻留在流形上并逃避空间检测的剩余高保真视频，我们引入了微时间波动分支作为辅助细粒度过滤器。通过分析即使在视觉上完美的序列中仍然存在的结构化 MPF，我们的框架可以确保伪造品被暴露，无论它们是否表现为全局现实世界的流形偏差或微妙的计算指纹。

- **2026-01-29** **WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models** [2601.21282](http://arxiv.org/abs/2601.21282)
  > 生成基础模型（通常被称为“世界模型”）的最新进展激发了人们将其应用于机器人规划和自主系统训练等关键任务的兴趣。为了实现可靠的部署，这些模型必须表现出高物理保真度，准确模拟现实世界的动态。然而，现有的基于物理的视频基准测试存在纠缠问题，其中单个测试同时评估多个物理定律和概念，从根本上限制了它们的诊断能力。我们推出了 WorldBench，这是一种新颖的基于视频的基准测试，专为特定于概念的、解开的评估而设计，使我们能够一次严格隔离和评估对单个物理概念或定律的理解。为了使 WorldBench 更全面，我们设计了两个不同级别的基准：1) 使用物体持久性或尺度/视角等概念来评估直观的物理理解，2) 对低级物理常数和材料属性（例如摩擦系数或流体粘度）进行评估。当在 WorldBench 上评估基于 SOTA 视频的世界模型时，我们发现特定物理概念中的特定失败模式，所有测试的模型都缺乏生成可靠的现实世界交互所需的物理一致性。通过针对具体概念的评估，WorldBench 提供了一个更加细致和可扩展的框架，用于严格评估视频生成和世界模型的物理推理能力，为更强大和更通用的世界模型驱动学习铺平道路。


## 3D

- **2026-02-03** **EventNeuS: 3D Mesh Reconstruction from a Single Event Camera** [2602.03847](http://arxiv.org/abs/2602.03847)
  > 在许多场景中，事件摄像机为 RGB 摄像机提供了相当好的替代方案。虽然最近有基于事件的新颖视图合成的工作，但密集 3D 网格重建仍然很少被探索，并且现有的基于事件的技术在 3D 重建精度方面受到严重限制。为了解决这个限制，我们提出了 EventNeuS，这是一种自监督神经模型，用于从单目颜色事件流中学习 3D 表示。我们的方法首次将 3D 符号距离函数和密度场学习与基于事件的监督相结合。此外，我们将球谐编码引入到我们的模型中，以增强对视图相关效果的处理。 EventNeuS 的性能显着优于现有方法，与之前的最佳方法相比，倒角距离平均降低了 34%，平均绝对误差平均降低了 31%。

- **2026-02-03** **AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations** [2602.03828](http://arxiv.org/abs/2602.03828)
  > 高质量的科学插图对于有效传达复杂的科学和技术概念至关重要，但其手工创作仍然是学术界和工业界公认的瓶颈。我们推出了FigureBench，这是第一个从长篇科学文本生成科学插图的大型基准。它包含 3,300 个高质量的科学文本-图形对，涵盖科学论文、调查、博客和教科书中的各种文本到插图任务。此外，我们提出了 AutoFigure，这是第一个基于长篇科学文本自动生成高质量科学插图的代理框架。具体来说，在渲染最终结果之前，AutoFigure 会进行广泛的思考、重组和验证，以生成结构合理且美观的布局，输出既结构完整又美观的科学插图。利用FigureBench 的高质量数据，我们进行了大量实验，以根据各种基线方法测试 AutoFigure 的性能。结果表明，AutoFigure 始终超越所有基线方法，生成可供出版的科学插图。代码、数据集和huggingface空间发布于https://github.com/ResearAI/AutoFigure。

- **2026-02-03** **3D-Aware Implicit Motion Control for View-Adaptive Human Video Generation** [2602.03796](http://arxiv.org/abs/2602.03796)
  > 视频生成中现有的人体运动控制方法通常依赖 2D 姿势或显式 3D 参数模型（例如 SMPL）作为控制信号。然而，2D 将运动严格绑定到驾驶视点，从而妨碍了新颖的视图合成。显式 3D 模型虽然在结构上信息丰富，但存在固有的不准确性（例如，深度模糊性和不准确的动态），当用作强约束时，会覆盖大型视频生成器强大的内在 3D 感知能力。在这项工作中，我们从 3D 感知的角度重新审视运动控制，提倡一种隐式的、与视图无关的运动表示，它自然地与生成器的空间先验对齐，而不是依赖于外部重建的约束。我们引入了 3DiMo，它联合训练运动编码器和预先训练的视频生成器，将驱动帧提取为紧凑的、与视图无关的运动标记，并通过交叉注意力进行语义注入。为了培养 3D 意识，我们通过丰富视图的监督（即单视图、多视图和移动摄像机视频）进行训练，强制不同视点之间的运动一致性。此外，我们使用辅助几何监督，仅利用 SMPL 进行早期初始化，并退火至零，使模型能够从外部 3D 指导过渡到从数据和生成器先验中学习真正的 3D 空间运动理解。实验证实，3DiMo 通过灵活的文本驱动摄像头控制忠实地再现了驾驶动作，在运动保真度和视觉质量方面都显着超越了现有方法。

- **2026-02-03** **BridgeV2W: Bridging Video Generation Models to Embodied World Models via Embodiment Masks** [2602.03793](http://arxiv.org/abs/2602.03793)
  > 具身世界模型已成为机器人技术中一个有前途的范例，其中大多数利用大规模互联网视频或预训练的视频生成模型来丰富视觉和运动先验。然而，它们仍然面临关键挑战：坐标空间动作和像素空间视频之间的不对准、对相机视点的敏感性以及跨实施例的非统一架构。为此，我们提出了 BridgeV2W，它将坐标空间动作转换为根据 URDF 和相机参数渲染的像素对齐的实施例掩模。然后，这些掩模通过 ControlNet 风格的路径注入到预训练的视频生成模型中，该路径将动作控制信号与预测视频对齐，添加特定于视图的调节以适应相机视点，并在各个实施例中生成统一的世界模型架构。为了减轻对静态背景的过度拟合，BridgeV2W 进一步引入了基于流的运动损失，专注于学习动态和任务相关区域。在单臂 (DROID) 和双臂 (AgiBot-G1) 数据集上进行的实验涵盖了具有未见过的视点和场景的多样化且具有挑战性的条件，结果表明，与之前最先进的方法相比，BridgeV2W 提高了视频生成质量。我们进一步展示了 BridgeV2W 在下游现实世界任务中的潜力，包括政策评估和目标条件规划。更多结果可以在我们的项目网站 https://BridgeV2W.github.io 上找到。

- **2026-02-03** **A High-order piecewise field-aligned triangular finite element method for electromagnetic gyrokinetic particle simulations of tokamak plasmas with open field lines** [2602.03759](http://arxiv.org/abs/2602.03759)
  > 开发并实现了一种高阶分段场对齐三角形有限元方法，用于具有开场线的托卡马克等离子体的全局电磁回旋粒子内模拟。该方法将局部场对齐的有限元基函数与柱坐标中的非结构化 $C^{1}$ 三角网格相结合，从而能够在大幅减少计算量的情况下进行全体积模拟，同时避免与全局场对齐坐标相关的网格畸变以及转向等离子体分界线处的相关奇点。该公式与 $δf$ 和 full-$f$ 模型兼容，并采用混合变量表示以及广义回拉方案来控制电磁模拟中的数值抵消。该方法在 TRIMEG-C1 代码中实现，并使用 TCV-X21 配置的线性和非线性电磁仿真进行演示。结果表明，该方法准确地捕获了电磁离子温度梯度和动力学气球模式物理的关键特征，包括模拟中的分界线区域，从而为现实托卡马克几何结构中的全体积电磁回旋运动模拟提供了一个强大的框架。

- **2026-02-03** **Transformation front kinetics in deformable ferromagnets** [2602.03745](http://arxiv.org/abs/2602.03745)
  > 诸如磁性形状记忆合金之类的材料在材料的磁化强度和机械变形之间具有内在的耦合。这些材料还经历结构相变，相边界分隔不同的相，并且相边界的动力学受磁场和机械应力控制。还有许多其他材料揭示了类似的现象，例如磁性钙钛矿。为了在连续尺度上模拟可变形磁性材料中相界的传播，需要三个要素：一组具有耦合磁和机械自由度的体行为控制方程、相界速度对控制因素的依赖性以及可靠的计算方法。相界速度的表达式通常在连续介质热力学设置内获得，其中导出由于相界传播而产生的熵，这给出了相界动力学的热力学驱动力。对于可变形铁磁体，所有三个要素（体积行为、界面动力学和计算方法）都已得到探索，但仍存在许多限制。本文重点讨论一般磁力机械环境中转变前沿热力学驱动力的推导，采用磁力学转变前沿的切割有限元方法，无需修改有限元网格即可极其有效地处理传播界面，并将所取得的进展应用于磁性形状记忆合金磁力学的定性建模。

- **2026-02-03** **Constraining cosmological simulations with peculiar velocities: a forward-modeling approach** [2602.03699](http://arxiv.org/abs/2602.03699)
  > 数值模拟是破译引力动力学的关键工具。然而，它们无法在空间上重现我们观察到的宇宙，从而将观察与模拟之间的比较限制在统计水平。对于在单一环境中观察到的稀有、微弱或经过深入研究的附近物体来说，这是一个很大的问题。在随机模拟中恢复这种环境的计算成本是令人望而却步的。   我们提出了 Hamlet-PM，这种方法能够限制宇宙学模拟的初始条件，从而产生可以直接与本地宇宙的观测结果进行比较的演化数值宇宙：约束模拟。   我们的方法根据后期奇特速度的稀疏和噪声测量来实现早期密度场的场级正向建模。动力学与粒子网格重力解算器集成，从而探测轻度非线性状态。该代码适用于 Cosmicflows-4 编译，奇特速度高达 z < 0.05 (160 Mpc/h)。使用高精度 N 体代码重新模拟受约束的 IC。   提出了一系列一百个仅暗物质的宇宙学约束模拟，在 500^3 [Mpc/h]3 盒子中分辨率为 512^3 粒子。特别关注十二个突出的附近星系团，它们的模拟对应物在质量和分离标准上相匹配。我们提供了受每个簇动态环境约束的质量估计。   初始条件的场级正向建模产生高度受限的宇宙学模拟。目前，该方法在质量上已经超过了特速社区中使用的管道，尽管系统偏差仍需要解决。此外，由于贝叶斯方法固有的灵活性，改进模型很容易。

- **2026-02-03** **ELIQ: A Label-Free Framework for Quality Assessment of Evolving AI-Generated Images** [2602.03558](http://arxiv.org/abs/2602.03558)
  > 生成文本到图像的模型正在以前所未有的速度发展，不断改变感知质量上限，并使以前收集的标签对新一代来说变得不可靠。为了解决这个问题，我们提出了 ELIQ，一种用于对不断变化的人工智能生成图像进行质量评估的无标签框架。具体来说，ELIQ 专注于视觉质量和提示图像对齐，自动构建正对和特定方面的负对，以涵盖传统的失真和 AIGC 特定的失真模式，从而无需人工注释即可实现可转移的监督。在这些对的基础上，ELIQ 通过指令调整将预先训练的多模态模型调整为质量感知批评者，并使用轻量级门控融合和质量查询转换器来预测二维质量。跨多个基准的实验表明，ELIQ 始终优于现有的无标签方法，无需修改即可从人工智能生成内容 (AIGC) 推广到用户生成内容 (UGC) 场景，并为不断发展的生成模型下的可扩展和无标签质量评估铺平了道路。该代码将在发布后发布。

- **2026-02-03** **Constrained Dynamic Gaussian Splatting** [2602.03538](http://arxiv.org/abs/2602.03538)
  > 虽然动态高斯分布可以实现高保真 4D 重建，但其部署受到一个根本困境的严重阻碍：无约束的致密化导致内存消耗过多，与边缘设备不兼容，而启发式剪枝无法在预设高斯预算下实现最佳渲染质量。在这项工作中，我们提出了约束动态高斯分布（CDGS），这是一种新颖的框架，它将动态场景重建制定为预算约束的优化问题，以在训练期间强制执行严格的、用户定义的高斯预算。我们的主要见解是引入可微分预算控制器作为核心优化驱动器。在多模式统一重要性评分的指导下，该控制器融合了几何、运动和感知线索，以实现精确的容量调节。为了最大化该固定预算的效用，我们进一步解耦静态和动态元素的优化，采用自适应分配机制，根据运动复杂性动态分配容量。此外，我们实施了三阶段培训策略来无缝整合这些约束，确保精确遵守目标计数。结合双模式混合压缩方案，CDGS 不仅严格遵守硬件限制（误差 < 2%}），而且还推动了率失真性能的 Pareto 前沿。大量实验表明，CDGS 在不同的容量限制下可提供最佳渲染质量，与最先进的方法相比，压缩率提高了 3 倍以上。

- **2026-02-03** **MatGPTQ: Accurate and Efficient Post-Training Matryoshka Quantization** [2602.03537](http://arxiv.org/abs/2602.03537)
  > Matryoshka 量化 (MatQuant) 是一种最新的量化方法，表明通过在推理时对最高有效位 (MSB) 进行切片，可以跨多个精度提供单个整数量化模型。这使得单个检查点能够覆盖广泛的内存和延迟预算，但使量化变得更具挑战性。特别是，最初的 MatQuant 依赖于昂贵的量化感知训练 (QAT) 变体，而不是快速一次性训练后量化 (PTQ)，并且缺乏开源和内核支持。我们通过引入训练后俄罗斯套娃量化 (MatGPTQ) 来解决所有这些限制，这是一种新的 PTQ 管道，可基于小型校准集生成针对多个目标精度一次性联合优化的单父模型。 MatGPTQ 将 Matryoshka 量化作为具有位切片和交叉位误差补偿的多精度目标，从而产生一种在单次传递中生成多位宽度、“可切片”模型的算法。我们还针对异构每层位结合了新的预算感知搜索，并提供了实现切片和混合精度执行的高效内核。在标准 LLM 和基准测试中，MatGPTQ 保留了高位精度，同时大幅提高了低位宽度设置下的性能。总体而言，我们为俄罗斯套娃式训练后量化建立了新的技术水平，并使单检查点、多精度部署开放且实用。代码可在 https://github.com/IST-DASLab/MatGPTQ 获取。

- **2026-02-02** **Frequency Stability of Graphene Nonlinear Parametric Oscillator** [2602.02476](http://arxiv.org/abs/2602.02476)
  > 高频稳定性对于传感和计时应用中石墨烯谐振器的性能至关重要。然而，石墨烯极具吸引力的极端小型化和高机械柔顺性也使其极易受到非线性影响，从而降低频率稳定性。在这里，我们证明石墨烯参量振荡器提供了一种替代的非线性工作机制，尽管具有很强的非线性，但短期频率稳定性仍然可以得到增强。通过在锁相环（PLL）中操作石墨烯谐振器，我们通过实验证明，与相同振幅下的杜芬振荡相比，分叉后状态下的参量振荡在快速积分时间内实现了更低的艾伦偏差。这种改进源于参量振荡器固有的强非线性阻尼，它可以抑制大振幅下的幅频噪声转换。最小的理论模型捕获了观察到的相位扩散，并将非线性阻尼确定为控制相位噪声降低的主要机制。这些结果凸显了非线性耗散在实现超出石墨烯振荡器传统限制的精密传感方面的作用。

- **2026-02-02** **Mapping-Guided Task Discovery and Allocation for Robotic Inspection of Underwater Structures** [2602.02389](http://arxiv.org/abs/2602.02389)
  > 通过检查同步定位和建图 (SLAM) 数据，可以在不事先了解现有几何形状的情况下实现和优化水下多机器人检查的任务生成。通过考虑硬件参数和环境条件，从 SLAM 网格生成一组任务，并通过预期关键点得分和基于距离的修剪进行优化。水下测试用于证明算法的有效性并确定适当的参数。将这些结果与模拟的 Voronoi 分区和 Boustropedon 模式进行比较，以检查测试环境模型的覆盖范围。所提出的任务发现方法的主要优点包括能够适应意外的几何形状和分布，从而保持覆盖范围，同时关注更有可能出现缺陷或损坏的区域。

- **2026-02-02** **Implicit neural representation of textures** [2602.02354](http://arxiv.org/abs/2602.02354)
  > 内隐神经表示（INR）已被证明在各个领域都是准确和高效的。在这项工作中，我们探索了如何将不同的神经网络设计为新的纹理 INR，它在输入 UV 坐标空间上以连续方式而不是离散方式运行。通过彻底的实验，我们证明这些 INR 在图像质量方面表现良好，具有相当大的内存使用量和渲染推理时间。我们分析这些目标之间的平衡。此外，我们还研究了实时渲染和下游任务中的各种相关应用，例如mipmap 拟合和 INR 空间生成。

- **2026-02-02** **TTT-Parkour: Rapid Test-Time Training for Perceptive Robot Parkour** [2602.02331](http://arxiv.org/abs/2602.02331)
  > 在看不见的复杂地形上实现高度动态的人形跑酷仍然是机器人技术的一个挑战。尽管一般的运动策略展示了跨广泛地形分布的能力，但它们经常与任意且极具挑战性的环境作斗争。为了克服这一限制，我们提出了一种从真实到模拟到真实的框架，该框架利用新地形上的快速测试时间训练（TTT），显着增强机器人穿越极其困难的几何形状的能力。我们采用两阶段端到端学习范式：首先在不同的程序生成的地形上对策略进行预训练，然后对从现实世界捕获重建的高保真网格进行快速微调。具体来说，我们使用 RGB-D 输入开发前馈、高效、高保真几何重建管道，确保测试时训练期间的速度和质量。我们证明 TTT-Parkour 使人形机器人能够克服复杂的障碍，包括楔子、木桩、盒子、梯形和窄梁。在大多数测试地形上，捕获、重建和测试训练的整个流程需要不到 10 分钟。大量实验表明，测试时训练后的策略表现出强大的零样本模拟到真实的传输能力。

- **2026-02-02** **Enhancing Indoor Occupancy Prediction via Sparse Query-Based Multi-Level Consistent Knowledge Distillation** [2602.02318](http://arxiv.org/abs/2602.02318)
  > 占用预测为机器人技术提供了关键的几何和语义理解，但面临着效率与准确性的权衡。当前的密集方法在空体素上遭受计算浪费，而基于稀疏查询的方法在多样化和复杂的室内场景中缺乏鲁棒性。在本文中，我们提出了 DiScene，一种新颖的基于稀疏查询的框架，它利用多级蒸馏来实现高效且稳健的占用预测。特别是，我们的方法包含两个关键创新：（1）多级一致知识蒸馏策略，通过四个级别的协调对齐，将分层表示从大型教师模型转移到轻量级学生，包括编码器级特征对齐、查询级特征匹配、先验级空间指导和锚定级高置信度知识转移；（2）教师引导初始化策略，采用优化的参数预热来加速模型收敛。经过 Occ-Scannet 基准测试的验证，DiScene 在没有深度先验的情况下实现了 23.2 FPS，同时比我们的基线方法 OPUS 提高了 36.1%，甚至比深度增强版本 OPUS† 还要好。通过深度集成，DiScene† 实现了新的 SOTA 性能，比 EmbodiedOcc 提高了 3.7%，推理速度提高了 1.62 美元\倍$。此外，Occ3D-nuScenes 基准测试和野外场景的实验证明了我们的方法在各种环境中的多功能性。代码和模型可以在 https://github.com/getterupper/DiScene 访问。

- **2026-02-02** **Neural Geometry for PDEs: Regularity, Stability, and Convergence Guarantees** [2602.02271](http://arxiv.org/abs/2602.02271)
  > 隐式神经表示（INR）已成为几何表示的强大工具，但它们对基于物理的模拟的适用性仍未得到充分探索。虽然豪斯多夫距离等指标可以量化表面重建质量，但它们无法捕获可证明数值性能所需的几何规律。这项工作建立了一个统一的理论框架，将 INR 训练误差与偏微分方程 (PDE)（特别是线性椭圆方程）解精度联系起来。我们定义了 INR 支持适定边界值问题所需的最小几何正则性，并导出将神经网络的函数逼近误差与有限元离散化误差联系起来的 \emph{先验} 误差估计。我们的分析表明，为了匹配线性有限元的收敛速度，INR 训练损失必须相对于网格大小呈二次方缩放。

- **2026-02-02** **SSI-DM: Singularity Skipping Inversion of Diffusion Models** [2602.02193](http://arxiv.org/abs/2602.02193)
  > 将真实图像反转到噪声空间对于使用扩散模型的编辑任务至关重要，但由于早期噪声步骤的不准确性，现有方法会产生可编辑性较差的非高斯噪声。我们确定了根本原因：数学奇点导致反演从根本上不适定。我们提出了扩散模型的奇异性跳过反演（SSI-DM），它通过在标准反演之前添加小噪声来绕过该奇异区域。这种简单的方法产生具有自然高斯特性的反转噪声，同时保持重建保真度。作为一种与通用扩散模型兼容的即插即用技术，我们的方法在用于重建和插值任务的公共图像数据集上实现了卓越的性能，为扩散模型反演提供了原则性且有效的解决方案。

- **2026-02-02** **UrbanGS: A Scalable and Efficient Architecture for Geometrically Accurate Large-Scene Reconstruction** [2602.02089](http://arxiv.org/abs/2602.02089)
  > 虽然 3D 高斯溅射 (3DGS) 可以为有界场景实现高质量、实时渲染，但其扩展到大规模城市环境带来了几何一致性、内存效率和计算可扩展性方面的严峻挑战。为了解决这些问题，我们提出了 UrbanGS，这是一个可扩展的重建框架，可以有效解决城市规模应用的这些挑战。首先，我们提出了深度一致的 D-正则化模块。与仅依赖单目法线估计器的现有方法（可以有效地更新旋转参数但难以更新位置参数）不同，我们的方法将 D-法线约束与外部深度监督相结合。这允许全面更新所有几何参数。通过进一步结合基于梯度一致性和逆深度偏差的自适应置信权重机制，我们的方法显着增强了多视图深度对齐和几何一致性，有效解决了复杂大规模场景中的几何精度问题。为了提高可扩展性，我们引入了空间自适应高斯剪枝（SAGP）策略，该策略根据局部几何复杂性和可见性动态调整高斯密度以减少冗余。此外，还设计了统一的分区和视图分配方案来消除边界伪影并优化计算负载。在多个城市数据集上的大量实验表明，UrbanGS在渲染质量、几何精度和内存效率方面取得了优异的性能，为高保真大规模场景重建提供了系统的解决方案。

- **2026-02-02** **Rethinking Genomic Modeling Through Optical Character Recognition** [2602.02014](http://arxiv.org/abs/2602.02014)
  > 最近的基因组基础模型主要采用大型语言模型架构，将 DNA 视为一维标记序列。然而，详尽的顺序读取在结构上与稀疏和不连续的基因组语义不一致，导致低信息背景上的计算浪费，并阻碍了对长上下文的理解驱动的压缩。在这里，我们提出 OpticalDNA，这是一个基于视觉的框架，它将基因组建模重新构建为光学字符识别 (OCR) 式的文档理解。 OpticalDNA 将 DNA 渲染为结构化视觉布局，并使用 \emph{视觉 DNA 编码器}和 \emph{文档解码器} 训练支持 OCR 的视觉语言模型，其中编码器生成紧凑、可重构的视觉标记以进行高保真压缩。在此表示的基础上，OpticalDNA 在核心基因组基元读取、区域接地、子序列检索和掩蔽跨度完成上定义了即时条件目标，从而学习布局感知的 DNA 表示，在减少的有效令牌预算下保留细粒度的基因组信息。在不同的基因组基准中，OpticalDNA 始终优于最近的基准；在多达 450k 个碱基的序列上，它以减少近 20\times $的有效标记实现了最佳整体性能，并超越了激活参数高达 $985\times$ 的模型，同时仅调整 256k \emph{trainable} 参数。

- **2026-02-02** **On Quantum Learning Advantage Under Symmetries** [2602.02008](http://arxiv.org/abs/2602.02008)
  > 对称性是许多最有效的经典和量子学习算法的基础，但量子学习者能否在对称性强加的结构下获得根本优势仍然是一个悬而未决的问题。基于经典统计查询 ( $\SQ$) 框架在学习对称函数类中揭示指数查询复杂性的证据，我们问：量子学习算法能否更好地利用问题对称性？在这项工作中，我们研究了量子统计查询 ($\QSQ$) 模型中对称性的潜在好处，该模型是经典 $\SQ$ 的自然量子模拟。我们的结果揭示了三个不同的现象：（i）我们在排列不变函数类上获得了 $\QSQ$ 和 $\SQ$ 之间的指数分离； (ii) 我们为 $\QSQ$ 学习建立查询复杂度下界，在常数因子范围内与最常研究的对称性相应的经典 $\SQ$ 下界相匹配；然而，在高度倾斜的轨道分布下可能会出现潜在的优势； (iii) 我们进一步确定存在基于容差的分离，其中量子学习器在使经典 $\SQ$ 算法无效的噪声水平上取得成功。总之，这些发现让我们深入了解对称性何时可以在学习中发挥量子优势。

- **2026-02-02** **SurfSplat: Conquering Feedforward 2D Gaussian Splatting with Surface Continuity Priors** [2602.02000](http://arxiv.org/abs/2602.02000)
  > 从稀疏图像重建 3D 场景仍然是一项具有挑战性的任务，因为在不进行优化的情况下很难恢复准确的几何和纹理。最近的方法利用通用模型来使用 3D 高斯泼溅 (3DGS) 原语生成 3D 场景。然而，它们通常无法产生连续的表面，而是产生离散的、颜色偏向的点云，这些点云在正常分辨率下看似合理，但在特写视图下却显示出严重的伪影。为了解决这个问题，我们提出了 SurfSplat，一种基于 2D 高斯分布 (2DGS) 原语的前馈框架，它提供了更强的各向异性和更高的几何精度。通过结合表面连续性先验和强制 alpha 混合策略，SurfSplat 重建了连贯的几何形状和忠实的纹理。此外，我们引入了高分辨率渲染一致性（HRRC），这是一种旨在评估高分辨率重建质量的新评估指标。在 RealEstate10K、DL3DV 和 ScanNet 上进行的大量实验表明，SurfSplat 在标准指标和 HRRC 方面始终优于先前的方法，为稀疏输入的高保真 3D 重建建立了强大的解决方案。项目页面：https://hebing-sjtu.github.io/SurfSplat-website/

- **2026-02-02** **On the stability of Born-Infeld-regularised electroweak monopoles** [2602.01921](http://arxiv.org/abs/2602.01921)
  > Cho-Maison 单极子提供了电弱场方程的单极子解，但由于超荷电扇区的麦克斯韦形式而拥有无限的经典能量。受弦有效场论的启发，我们研究了当超电荷动力学项通过 Born-Infeld 扩展进行正则化时 Cho-Maison 单极子的微扰稳定性，这使得单极子能量有限。重点关注具有未修改的 $SU(2)_L$ 扇区和 Born-Infeld U(1)_Y 扇区的玻色子电弱理论，我们分析了关于正则化单极子背景的线性涨落。使用复四分体和自旋加权调和分解，我们将涨落方程简化为耦合径向薛定谔型特征值问题，并检查所得算子的谱。我们将 Gervalle 和 Volkov 开发的变量分离框架扩展到这种非线性规范场设置。我们表明，在适当的规范固定和约束消除之后，Born-Infeld 变形保留了麦克斯韦理论的角通道结构，并导致径向模式稳定性的自伴 Sturm-Liouville 型问题，修正的径向系数由背景 Born-Infeld 剖面确定。由此产生的算子代表了麦克斯韦情况的平滑变形并保留了正动重量。我们的结果为玻恩-因费尔德变形单极子的稳定性提供了合理的证据，最重要的是，为未来旨在确定光谱分析的数值或变分研究提供了系统框架。

- **2026-02-02** **Observation-dependent Bayesian active learning via input-warped Gaussian processes** [2602.01898](http://arxiv.org/abs/2602.01898)
  > 贝叶斯主动学习依赖于预测不确定性的精确量化来探索未知的函数景观。虽然高斯过程代理是此类任务的标准，但一个未被充分认识的事实是，它们的后验方差仅取决于通过超参数观察到的输出，从而使得探索很大程度上对实际测量不敏感。我们建议通过学习的单调重新参数化来扭曲输入空间来注入依赖于观察的反馈。这种机制允许设计策略根据观察到的变化来扩展或压缩输入空间的区域，从而塑造基于方差的采集函数的行为。我们证明，虽然这种扭曲可以通过边际似然进行训练，但新颖的自我监督目标可以产生更好的性能。我们的方法提高了一系列主动学习基准的样本效率，特别是在非平稳性挑战传统方法的情况下。

- **2026-02-02** **ProxyImg: Towards Highly-Controllable Image Representation via Hierarchical Disentangled Proxy Embedding** [2602.01881](http://arxiv.org/abs/2602.01881)
  > 流行的图像表示方法，包括诸如光栅图像和高斯基元之类的显式表示，以及诸如潜在图像之类的隐式表示，要么遭受表示冗余的困扰，导致繁重的手动编辑工作，要么缺乏从潜在变量到语义实例或部分的直接映射，从而使得细粒度操作变得困难。这些限制阻碍了高效且可控的图像和视频编辑。为了解决这些问题，我们提出了一种基于分层代理的参数图像表示，它将语义、几何和纹理属性分解为独立且可操作的参数空间。基于输入图像的语义感知分解，我们的表示通过自适应贝塞尔拟合和迭代内部区域细分和网格划分构建分层代理几何形状。多尺度隐式纹理参数嵌入到生成的几何感知分布式代理节点中，从而实现像素域中的连续高保真重建以及实例或部分独立的语义编辑。此外，我们引入了局部自适应特征索引机制来确保空间纹理的一致性，这进一步支持高质量的背景完成而不依赖于生成模型。关于图像重建和编辑基准（包括 ImageNet、OIR-Bench 和 HumanEdit）的大量实验表明，我们的方法以明显更少的参数实现了最先进的渲染保真度，同时实现了直观、交互式和物理上合理的操作。此外，通过将代理节点与基于位置的动力学集成，我们的框架支持使用轻量级隐式渲染的实时物理驱动动画，与生成方法相比，实现了卓越的时间一致性和视觉真实感。

- **2026-02-02** **CloDS: Visual-Only Unsupervised Cloth Dynamics Learning in Unknown Conditions** [2602.01844](http://arxiv.org/abs/2602.01844)
  > 深度学习在模拟复杂动态系统方面表现出了卓越的能力。然而，现有方法需要已知的物理属性作为监督或输入，限制了它们在未知条件下的适用性。为了探索这一挑战，我们引入了布料动力学基础（CDG），这是一种通过多视图视觉观察无监督学习布料动力学的新颖场景。我们进一步提出了 Cloth Dynamics Splatting (CloDS)，这是一种专为 CDG 设计的无监督动态学习框架。 CloDS 采用三级管道，首先执行视频到几何接地，然后在接地网格上训练动力学模型。为了应对接地过程中的大非线性变形和严重的自遮挡，我们引入了双位置不透明度调制，该调制在视频到几何接地阶段通过基于网格的高斯泼溅支持 2D 观测和 3D 几何之间的双向映射。它共同考虑高斯分量的绝对位置和相对位置。综合实验评估表明，CloDS 可以有效地从视觉数据中学习布料动力学，同时保持对不可见配置的强大泛化能力。我们的代码可在 https://github.com/whynot-zyl/CloDS 获取。可视化结果可在 https://github.com/whynot-zyl/CloDS_video}.%\footnote{如本例所示。

- **2026-02-02** **Hyperbolicity analysis of the linearised 3+1 formulation in the Teleparallel Equivalent of General Relativity** [2602.01830](http://arxiv.org/abs/2602.01830)
  > 我们研究了远平行等效广义相对论 (TEGR) 中 3+1 运动方程主符号的性质，并评估了双曲性的条件。我们使用基于哈密顿形式主义中规范变量的矢量、反对称、对称无迹和迹 (VAST) 分解的哈密顿公式，以及文献中先前提出的哈密顿方程。我们在线性水平上研究了微分方程组，并表明主符号有一个具有虚特征值的扇区，这使得该系统不是双曲线的。通过在一个或三个坐标方向上进行空间导数，这种情况仍然存在，并且它应该被解释为特定规范选择的问题，而不是 TEGR 的一般问题。汉密尔顿方程在这项工作中的首次实际应用可以扩展到证明球对称性的适定性，并在 TEGR 中建立数值相对论设置。

- **2026-02-02** **CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding** [2602.01785](http://arxiv.org/abs/2602.01785)
  > 大型语言模型（LLM）在源代码理解方面取得了显着的成功，但随着软件系统规模的增长，计算效率已成为关键瓶颈。目前，这些模型依赖于基于文本的范例，将源代码视为令牌的线性序列，这导致上下文长度和相关计算成本线性增加。多模态 LLM (MLLM) 的快速发展带来了通过将源代码表示为渲染图像来优化效率的机会。与难以在不丢失语义的情况下压缩的文本不同，图像模态本质上适合压缩。通过调整分辨率，图像可以缩放到原始代币成本的一小部分，同时保持视觉模型的可识别性。为了探索这种方法的可行性，我们对 MLLM 在代码理解方面的有效性进行了首次系统研究。我们的实验表明：（1）MLLM 可以有效地理解代码，并大幅减少标记，实现高达 8 倍的压缩； (2) MLLM 可以有效利用语法突出显示等视觉提示，提高 4 倍压缩下的代码完成性能； (3) 克隆检测等代码理解任务对视觉压缩表现出卓越的弹性，某些压缩率甚至略优于原始文本输入。我们的研究结果强调了 MLLM 在代码理解方面的潜在和当前局限性，这指出了向图像模态代码表示的转变作为更有效推理的途径。

- **2026-02-02** **Backdoor Sentinel: Detecting and Detoxifying Backdoors in Diffusion Models via Temporal Noise Consistency** [2602.01765](http://arxiv.org/abs/2602.01765)
  > 扩散模型已广泛应用于AIGC服务中；然而，它们对不透明训练数据和程序的依赖暴露了后门注入的广泛攻击面。在实际审计场景中，由于知识产权和商业机密的保护，审计人员通常无法访问模型参数，使得现有的白盒或查询密集型检测方法不切实际。更重要的是，即使在检测到后门之后，现有的解毒方法也常常陷入解毒效果和生成质量之间的困境。   在这项工作中，我们发现了一种先前未报告的现象，称为时间噪声不一致性，其中相邻扩散时间步之间的噪声预测在输入被触发时在特定时间段中被破坏，而在干净输入下保持稳定。利用这一发现，我们提出了时间噪声一致性防御（TNC-Defense），这是一个用于后门检测和解毒的统一框架。该框架首先利用相邻时间步噪声一致性来设计灰盒检测模块，用于识别和定位异常扩散时间步。此外，该框架使用识别出的异常时间步长来构建一个与触发无关、时间步长感知的解毒模块，该模块可以直接纠正后门生成路径。这有效地抑制了后门行为，同时显着降低了解毒成本。   我们在五种代表性后门攻击场景下评估所提出的方法，并将其与最先进的防御进行比较。结果表明，TNC-Defense 将平均检测精度提高了 $11\%$，而额外开销可以忽略不计，并且使平均 $98.5\%$ 的触发样本无效，而生成质量仅略有下降。

- **2026-01-30** **PaperBanana: Automating Academic Illustration for AI Scientists** [2601.23265](http://arxiv.org/abs/2601.23265)
  > 尽管在语言模型的支持下，自主人工智能科学家取得了快速进步，但生成可发表的插图仍然是研究工作流程中的劳动密集型瓶颈。为了减轻这一负担，我们引入了 PaperBanana，这是一个用于自动生成可供出版的学术插图的代理框架。在最先进的 VLM 和图像生成模型的支持下，PaperBanana 协调专门的代理来检索参考、规划内容和风格、渲染图像，并通过自我批评进行迭代完善。为了严格评估我们的框架，我们引入了 PaperBananaBench，其中包含来自 NeurIPS 2025 出版物的 292 个方法图测试用例，涵盖不同的研究领域和插图风格。综合实验表明，PaperBanana 在忠实性、简洁性、可读性和美观性方面始终优于领先的基线。我们进一步表明，我们的方法可以有效地扩展到生成高质量的统计图。总的来说，PaperBanana 为自动生成可供出版的插图铺平了道路。

- **2026-01-30** **High-Efficiency Hexagonal Nanowire MAPbI3 Perovskite Solar Cell with Broadband Light Trapping** [2601.23191](http://arxiv.org/abs/2601.23191)
  > 钙钛矿太阳能电池 (PSC) 因其卓越的光吸收特性、可调谐性和制造经济性而成为下一代光伏 (PV) 技术的有力竞争者。在这里，我们提出了一种巧妙的基于六角纳米线（HNW）的PSC，它可以实现宽带吸收，最大限度地减少反射率，并通过改善光与物质的相互作用和提高电荷收集效率来提供强大的偏振不敏感性。 HNW 配置的旋转对称性在可见光和近红外光谱的 TE 和 TM 照明下产生与偏振无关的吸光度。基于 CH3NH3PbI3 的 HNW 结构的几何参数（包括直径、周期和填充比）的优化提供了影响光学特性和器件性能的广泛变化。为了进一步强化光子限制，将介电 SiO2 球部分嵌入 ITO 层中，从而提高长波长吸光度并增加有源区附近的电子空穴对生成。我们分析了时域有限差分（FDTD）方法来检查我们提出的结构的光学特性。这项研究表明，我们提出的结构实现了更高的产生率、增强的吸光度和更高的光学短路电流密度（Jsc）（29.53 mA/cm2）。通过求解载流子传输动力学的耦合漂移扩散方程和泊松方程来评估电性能。优化后的 HNW 结构实现了 24.2% 的显着功率转换效率，凸显了光学限制和有效载流子传输之间的紧密联系。这些属性使拟议的高净值 PSC 成为高性能光伏系统和可扩展薄膜太阳能技术的可行选择。

- **2026-01-30** **ReGuLaR: Variational Latent Reasoning Guided by Rendered Chain-of-Thought** [2601.23184](http://arxiv.org/abs/2601.23184)
  > 虽然思想链 (CoT) 显着增强了大型语言模型 (LLM) 的性能，但显式推理链引入了大量的计算冗余。最近的潜在推理方法试图通过将推理过程压缩到潜在空间来缓解这一问题，但由于缺乏适当的压缩指导，常常会遭受严重的性能下降。在这项研究中，我们提出了渲染 CoT 引导的变分潜在推理（ReGuLaR），这是一种简单而新颖的潜在学习范式，可以解决这个问题。从根本上说，我们在变分自动编码（VAE）框架内制定潜在推理，从以先前分布为条件的后验分布中采样当前的潜在推理状态。具体来说，在学习这种变分潜在推理模型时，我们将显式推理链渲染为图像，从中提取密集的视觉语义表示来正则化后验分布，从而以最小的信息损失实现有效的压缩。大量实验表明，ReGuLaR 在计算效率和推理有效性方面都显着优于现有的潜在推理方法，甚至通过多模态推理超越 CoT，为潜在推理提供了一种新的、富有洞察力的解决方案。代码：https://github.com/FanmengWang/ReGuLaR。

- **2026-01-30** **MeshGraphNet-Transformer: Scalable Mesh-based Learned Simulation for Solid Mechanics** [2601.23177](http://arxiv.org/abs/2601.23177)
  > 我们提出了 MeshGraphNet-Transformer (MGN-T)，这是一种新颖的架构，它将 Transformer 的全局建模功能与 MeshGraphNet 的几何归纳偏差相结合，同时保留基于网格的图形表示。 MGN-T 克服了标准 MGN 的一个关键限制，即由于在大型高分辨率网格上传递迭代消息而导致的远程信息传播效率低下。物理注意力 Transformer 充当全局处理器，同时更新所有节点状态，同时显式保留节点和边缘属性。通过直接捕获远程物理交互，MGN-T 消除了对深度消息传递堆栈或分层、粗化网格的需求，从而能够在工业规模上对具有不同几何形状、拓扑和边界条件的高分辨率网格进行有效学习。   我们证明 MGN-T 成功处理工业规模的冲击动力学网格，在这种情况下，标准 MGN 由于消息传递范围不足而失败。该方法准确地模拟自接触、可塑性和多元输出，包括内部唯象塑性变量。此外，MGN-T 在经典基准上的表现优于最先进的方法，仅使用竞争基准所需参数的一小部分，即可在保持实际效率的同时实现更高的精度。

- **2026-01-30** **Distribution-informed Efficient Conformal Prediction for Full Ranking** [2601.23128](http://arxiv.org/abs/2601.23128)
  > 量化不确定性对于在现实应用中安全部署排名模型至关重要。最近的工作提供了在完整排名场景中使用保形预测的严格解决方案，其目的是根据校准项目的相对排名构建测试项目的绝对排名的预测集。然而，依赖不合格分数的上限使得该方法过于保守，导致预测集相当大。为了解决这个问题，我们提出了基于分布的共形排序（DCR），它通过导出不合格分数的精确分布来生成有效的预测集。特别是，我们发现校准项目的绝对排名遵循负超几何分布，以它们的相对排名为条件。因此，DCR 使用排名分布来导出不合格分数分布并确定保形阈值。我们提供了理论上的保证，即 DCR 可以实现比基线更高的效率，同时确保温和假设下的有效覆盖范围。大量实验证明了 DCR 的优越性，可将平均预测集大小减少高达 36%，同时保持有效覆盖范围。

- **2026-01-30** **Omni-fMRI: A Universal Atlas-Free fMRI Foundation Model** [2601.23090](http://arxiv.org/abs/2601.23090)
  > 自监督功能磁共振成像基础模型已经显示出有希望的传输性能，但大多数依赖于预定义的区域级分割，这些分割会丢弃细粒度的体素信息并引入依赖于图谱的偏差。我们提出了 Omni-fMRI，这是一种直接对体素级信号进行操作的无图谱基础模型。为了在跨 9 个数据集的 49,497 个 fMRI 会话上实现可扩展的预训练，Omni-fMRI 引入了动态修补机制，可大幅降低计算成本，同时保留信息丰富的空间结构。为了支持可重复性和公平比较，我们建立了一个全面的基准套件，涵盖 11 个数据集以及一组不同的静息状态和基于任务的 fMRI 任务。实验结果表明，Omni-fMRI 始终优于现有的基础模型，为无图谱的大脑表征学习提供了可扩展且可重复的框架。代码和日志可用。

- **2026-01-30** **EAG-PT: Emission-Aware Gaussians and Path Tracing for Indoor Scene Reconstruction and Editing** [2601.23065](http://arxiv.org/abs/2601.23065)
  > 最近基于辐射场的重建方法（例如 NeRF 和 3DGS）以高视觉保真度再现室内场景，但由于烘烤照明和缺乏明确的光传输而在场景编辑下崩溃。相比之下，基于物理的逆渲染依赖于网格表示和路径跟踪，这强制执行正确的光传输，但对几何保真度提出了强烈要求，成为真实室内场景的实际瓶颈。在这项工作中，我们提出了发射感知高斯和路径跟踪（EAG-PT），旨在实现具有统一的 2D 高斯表示的基于物理的光传输。我们的设计基于三个核心：(1) 使用 2D 高斯作为统一的场景表示和传输友好的几何代理，避免重建网格；(2) 在重建过程中显式分离发射和非发射组件以进行进一步的场景编辑；(3) 在场景编辑后使用高效的单反射优化和高质量的多反射路径跟踪，将重建与最终渲染解耦。对合成和真实室内场景的实验表明，与辐射场景重建相比，EAG-PT 在编辑后可产生更自然和物理一致的渲染，同时与基于网格的逆路径追踪相比，保留更精细的几何细节并避免网格引起的伪影。这些结果为室内设计、XR 内容创建和嵌入式人工智能的未来应用指明了有前景的方向。

- **2026-01-30** **Unlocking the Power of Orbital-Free Density Functional Theory to Explore the Electronic Structure Under Extreme Conditions** [2601.23002](http://arxiv.org/abs/2601.23002)
  > X射线自由电子激光诊断的最新进展使得能够在极端压力和温度下直接探测电子结构，例如在恒星内部和惯性约束聚变实验中遇到的情况，这对解释实验数据的理论模型提出了挑战。 Kohn-Sham 密度泛函理论 (KSDFT) 已成功应用于分析实验 X 射线散射测量，但其高计算成本使得常规应用不切实际。无轨道 DFT (OFDFT) 是一种效率更高的替代方案，其计算成本与系统尺寸呈线性关系，并且温度依赖性较弱，但它通常缺乏电子结构描述所需的精度。为了克服这一限制，我们提出了一种非经验 Kohn-Sham 辅助的无轨道密度泛函框架，用于极端条件下的计算，该框架能够在各种条件下对电子密度、电子离子结构因子和状态方程进行有效的 OFDFT 模拟，并具有 KSDFT 级的精度。与稠密氢的量子蒙特卡罗数据的基准比较以及针对热稠密铍的瑞利重量测量的验证证明了该框架的可靠性，并且与 KSDFT 相比，速度提高了高达数百倍。我们进一步表明，即使在 100 eV 的温度下，量子非定域性对于正确描述致密氢的电子结构仍然至关重要。

- **2026-01-30** **A Real-Time Privacy-Preserving Behavior Recognition System via Edge-Cloud Collaboration** [2601.22938](http://arxiv.org/abs/2601.22938)
  > 随着智能传感扩展到卫生间和更衣室等高隐私环境，该领域面临着严重的隐私安全悖论。传统的 RGB 监视引起了对视觉记录和存储的严重关注，而现有的隐私保护方法（从物理脱敏到传统的加密或混淆技术）通常会损害语义理解能力或无法保证针对重建攻击的数学不可逆性。为了应对这些挑战，本研究提出了一种基于AI Flow理论框架和边云协同架构的新型隐私保护感知技术。所提出的方法将源脱敏与不可逆特征映射相结合。利用信息瓶颈理论，边缘设备执行毫秒级处理，通过非线性映射和随机噪声注入将原始图像转换为抽象特征向量。这个过程构建了一个单向信息流，剥离了身份敏感属性，使得原始图像的重建变得不可能。随后，云平台利用多模态族模型仅对这些抽象向量进行联合推理，以检测异常行为。这种方式从架构层面从根本上切断了隐私泄露的路径，实现了从视频监控到去识别化行为感知的突破，为高敏感公共空间的风险管理提供了稳健的解决方案。

- **2026-01-30** **Eroding the Truth-Default: A Causal Analysis of Human Susceptibility to Foundation Model Hallucinations and Disinformation in the Wild** [2601.22871](http://arxiv.org/abs/2601.22871)
  > 随着基础模型 (FM) 接近人类水平的流畅性，区分合成内容和有机内容已成为可信网络智能的关键挑战。   本文提出了 JudgeGPT 和 RogueGPT，这是一个双轴框架，将“真实性”与“归因”解耦，以研究人类易感性的机制。通过分析 5 个 FM（包括 GPT-4 和 Llama-2）的 918 项评估，我们采用结构因果模型 (SCM) 作为制定有关检测准确性的可测试因果假设的主要框架。   与党派叙述相反，我们发现政治取向与检测性能的关联可以忽略不计（ $r=-0.10$）。相反，“假新闻熟悉度”作为候选调解者出现（$r=0.35$ ），这表明曝光可能起到人类歧视者的对抗性训练的作用。我们发现了一个“流畅性陷阱”，其中 GPT-4 输出（HumanMachineScore：0.20）绕过源监控机制，使其与人类文本无法区分。   这些发现表明，“预掩埋”干预措施应针对认知源监控而不是人口细分，以确保值得信赖的信息生态系统。

- **2026-01-29** **PI-Light: Physics-Inspired Diffusion for Full-Image Relighting** [2601.22135](http://arxiv.org/abs/2601.22135)
  > 由于收集大规模结构化配对数据的困难、维持物理合理性的困难以及数据驱动先验所带来的有限的通用性，全图像重新照明仍然是一个具有挑战性的问题。现有的弥合全场景重新照明合成与真实差距的尝试仍然不够理想。为了应对这些挑战，我们引入了全图像 reLight 的物理启发扩散（ $π$-Light，或 PI-Light），这是一个利用物理启发扩散模型的两阶段框架。我们的设计融合了（i）批量感知注意力，它提高了图像集合中内在预测的一致性，（ii）物理引导的神经渲染模块，强制执行物理上合理的光传输，（iii）物理启发的损失，将训练动态调整为具有物理意义的景观，从而增强对现实世界图像编辑的通用性，以及（iv）精心策划的在受控照明条件下捕获的不同对象和场景的数据集。这些组件共同实现了预训练扩散模型的高效微调，同时还为下游评估提供了坚实的基准。实验表明，$π$ -Light 可以合成各种材质的镜面高光和漫反射，与之前的方法相比，实现了对现实世界场景的卓越泛化。

- **2026-01-29** **VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning** [2601.22069](http://arxiv.org/abs/2601.22069)
  > 长上下文推理极大地增强了大型语言模型（LLM）处理复杂任务的能力，但由于计算复杂性，它引入了严重的效率瓶颈。现有的有效方法通常依赖于复杂的额外训练或外部模型进行压缩，这限制了可扩展性并丢弃了关键的细粒度信息。在本文中，我们提出了 VTC-R1，一种新的高效推理范式，它将视觉文本压缩集成到推理过程中。 VTC-R1 不是处理冗长的文本痕迹，而是将中间推理片段渲染成紧凑的图像，这些图像作为“光学记忆”迭代反馈到视觉语言模型中。我们基于 OpenR1-Math-220K 构建了一个训练数据集，实现了 3.4 倍的令牌压缩，并对代表性的 VLM-Glyph 和 Qwen3-VL 进行了微调。对 MATH500、AIME25、AMC23 和 GPQA-D 等基准测试的大量实验表明，VTC-R1 始终优于标准的长上下文推理。此外，我们的方法显着提高了推理效率，在端到端延迟方面实现了 2.7 倍的加速，凸显了其作为推理密集型应用程序的可扩展解决方案的潜力。我们的代码可在 https://github.com/w-yibo/VTC-R1 获取。

- **2026-01-29** **MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources** [2601.22054](http://arxiv.org/abs/2601.22054)
  > 缩放推动了视觉基础模型的最新进展，但由于异构传感器噪声、相机相关偏差以及嘈杂的跨源 3D 数据中的度量模糊性，将这种范式扩展到度量深度估计仍然具有挑战性。我们推出了 Metric Anything，这是一个简单且可扩展的预训练框架，可以从嘈杂、多样化的 3D 源中学习度量深度，而无需手动设计提示、特定于相机的建模或特定于任务的架构。我们方法的核心是稀疏度量提示，它是通过随机屏蔽深度图创建的，它作为一个通用接口，将空间推理与传感器和相机偏差分离。使用跨越 10000 个相机模型重建、捕获和渲染 3D 数据的约 2000 万个图像深度对，我们首次展示了公制深度轨道中清晰的缩放趋势。预训练模型擅长提示驱动任务，例如深度完成、超分辨率和雷达相机融合，而其精炼的无提示学生在单目深度估计、相机内在恢复、单/多视图度量 3D 重建和 VLA 规划方面取得了最先进的结果。我们还表明，使用 Metric Anything 的预训练 ViT 作为视觉编码器可以显着增强空间智能中的多模态大语言模型能力。这些结果表明，度量深度估计可以受益于驱动现代基础模型的相同缩放法则，从而建立一条通向可扩展且高效的现实世界度量感知的新路径。我们在 http://metric-anything.github.io/metric-anything-io/ 上开源了 MetricAnything 以支持社区研究。

- **2026-01-29** **PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction** [2601.22046](http://arxiv.org/abs/2601.22046)
  > 单目图像序列的流式重建仍然具有挑战性，因为现有方法通常倾向于高质量渲染或精确几何，但很少两者兼而有之。我们提出了 PLANING，这是一种基于混合表示的高效动态重建框架，它将显式几何基元与神经高斯松散耦合，从而能够以解耦的方式对几何和外观进行建模。这种解耦支持在线初始化和优化策略，将几何和外观更新分开，从而产生稳定的流式重建，并显着减少结构冗余。 PLANING 使密集网格 Chamfer-L2 比 PGSR 提高了 18.52%，PSNR 超过 ARTDECO 1.31 dB，并在 100 秒内重建 ScanNetV2 场景，比 2D Gaussian Splatting 快 5 倍以上，同时与离线每个场景优化的质量相匹配。除了重建质量之外，\modelname~的结构清晰度和计算效率使其非常适合广泛的下游应用，例如为具体人工智能实现大规模场景建模和模拟就绪环境。项目页面：https://city-super.github.io/PLANING/ 。

- **2026-01-29** **Urban Neural Surface Reconstruction from Constrained Sparse Aerial Imagery with 3D SAR Fusion** [2601.22045](http://arxiv.org/abs/2601.22045)
  > 神经表面重建 (NSR) 最近显示出利用多视图航空图像进行城市 3D 重建的强大潜力。然而，现有的 NSR 方法经常面临几何模糊性和不稳定性的问题，特别是在稀疏视图条件下。这个问题在大规模城市遥感中至关重要，因为航空图像采集受到飞行路径、地形和成本的限制。为了应对这一挑战，我们提出了第一个城市 NSR 框架，该框架将 3D 合成孔径雷达 (SAR) 点云与航空图像融合，以便在受限、稀疏视图设置下进行高保真重建。 3D SAR 甚至可以从单个侧视飞行路径中有效地捕获大规模几何形状，从而提供强大的先验来补充图像中的光度线索。我们的框架将雷达衍生的空间约束集成到基于 SDF 的 NSR 主干中，指导结构感知射线选择和自适应采样，以实现稳定高效的优化。我们还利用共同配准的 3D SAR 点云和航空图像构建了第一个基准数据集，促进了跨模态 3D 重建的系统评估。大量实验表明，与高度稀疏和斜视条件下的单模态基线相比，采用 3D SAR 显着提高了重建的准确性、完整性和鲁棒性，凸显了利用先进的机载和星载光学 SAR 传感实现可扩展的高保真城市重建的可行途径。

- **2026-01-29** **Isogonal conjugation in isosceles tetrahedron** [2601.22042](http://arxiv.org/abs/2601.22042)
  > 在本文中，我们研究等腰四面体中等角共轭的性质。特别是，我们揭示了三个双曲抛物面，每个双曲抛物面都是由在各自的双中线对称的等角共轭点对形成的，并且我们证明了等腰四面体的外接球在该四面体的等角共轭下是不变的。

- **2026-01-29** **Hybrid Foveated Path Tracing with Peripheral Gaussians for Immersive Anatomy** [2601.22026](http://arxiv.org/abs/2601.22026)
  > 体积医学成像为理解复杂的病理学提供了巨大的潜力。然而，传统的 2D 切片对于解释空间关系几乎没有提供支持，迫使用户在心理上将解剖结构重建为三个维度。直接体积路径追踪和 VR 渲染可以改善感知，但计算成本较高，而预先计算的表示（例如高斯泼溅）则需要提前规划。这两种方法都限制了交互使用。   我们提出了一种混合渲染方法，用于高质量、交互式和沉浸式解剖可视化。我们的方法将流式注视点路径追踪与外围的轻量级高斯泼溅近似相结合。外围模型生成利用体积数据进行优化，并使用中心凹渲染不断细化，从而实现交互式更新。深度引导重投影进一步提高了对延迟的稳健性，并允许用户在保真度与刷新率之间取得平衡。   我们将我们的方法与直接路径追踪和高斯分布进行比较。我们的结果强调了它们的组合如何能够保持视觉质量的优势，同时在一秒内重新生成外围模型，从而消除大量的预处理和近似。这为交互式医学可视化开辟了新的选择。

- **2026-01-29** **Photonic Links for Spin-Based Quantum Sensors** [2601.22011](http://arxiv.org/abs/2601.22011)
  > 近年来，越来越多的光学自旋量子位出现，成为量子传感器、量子位和量子存储器的关键组件。然而，传统的基于自旋的量子架构的可扩展性仍然受到直接微波传输的限制，这会引入热噪声、电磁串扰以及低温、高场和分布式系统的设计限制。在这项工作中，我们提出了一个统一的框架，通过 RFoF 光学检测金刚石中氮空位 (NV) 中心的磁共振 (ODMR) 光谱来控制光学可访问的自旋。 RFoF 平台依赖于通过光纤传输微波信号的电光调制电信频段激光器和恢复 RF 波形以驱动 NV 中心自旋跃迁的高速光电二极管。我们在 2.90~GHz 处获得了 1.81\% 的 RFoF 效率，对应于 $P_{\mathrm{RF,out}}=-0.7$ ~dBm。 RFoF 架构提供了一条通向低噪声、热隔离和低温兼容 ODMR 系统的途径，将传统的基于自旋的量子传感协议与新兴的分布式量子技术连接起来。

- **2026-01-29** **Stückelberg inspired approach for avoiding singular Hamiltonians in Lorentz violating models of antisymmetric tensor field** [2601.22007](http://arxiv.org/abs/2601.22007)
  > 已知反对称张量场的自发洛伦兹破坏模型在真空流形上具有奇异哈密顿量，导致无法解决的病理现象，使此类理论不适用于宇宙学研究。在这项工作中，我们表明，通过引入受 Stückelberg 机制启发的辅助矢量场来恢复拉格朗日的规范对称性，可以解决真空歧管上的此类病症。使用 Dirac-Bergmann 方法进行约束分析得到一个约束矩阵，该矩阵依赖于 Stückelberg 场的梯度和共轭动量，因此在真空流形上保持非奇异性。

- **2026-01-29** **Investigation of Wake Dynamics of a Slender Symmetric Trailing Edge Hydrofoil** [2601.21939](http://arxiv.org/abs/2601.21939)
  > 准确预测水翼后面的尾流动力学对于减轻涡流引起的振动和提高液压机械的性能至关重要。传统的湍流建模方法通常难以捕捉控制尾流行为的不稳定、相干结构，特别是对于在高雷诺数下运行的细长水翼。本研究通过将尺度解析数值模拟（包括高分辨率大涡模拟（LES））与粒子图像测速（PIV）测量相结合来解决这一局限性，以研究在零攻角下运行的对称钝后缘水翼的湍流尾流。在大约 7.5x10e5 的雷诺数下分析流动，即接近尾流-结构相互作用效应的开始。 LES 使用约 5 亿个节点的精细网格进行，以解析实验视野之外的近壁和尾流动力学，而 PIV 测量提供后缘下游的时间分辨速度场。将本征正交分解 (POD) 应用于 PIV 数据，以提取主要相干结构并量化它们对湍流动能的贡献。 POD 分析表明，能量分布在多种模式中，其中主导模式捕获主要尾流动力学，而更高模式形成与冯卡门涡旋脱落相关的耦合振荡对。 PIV-LES 协议表明，中心尾流测量与数值模拟相结合，可以实现完整的尾流重建，并验证与振动相关的水翼动力学建模。


## 具生智能&自动驾驶

- **2026-02-03** **BridgeV2W: Bridging Video Generation Models to Embodied World Models via Embodiment Masks** [2602.03793](http://arxiv.org/abs/2602.03793)
  > 具身世界模型已成为机器人技术中一个有前途的范例，其中大多数利用大规模互联网视频或预训练的视频生成模型来丰富视觉和运动先验。然而，它们仍然面临关键挑战：坐标空间动作和像素空间视频之间的不对准、对相机视点的敏感性以及跨实施例的非统一架构。为此，我们提出了 BridgeV2W，它将坐标空间动作转换为根据 URDF 和相机参数渲染的像素对齐的实施例掩模。然后，这些掩模通过 ControlNet 风格的路径注入到预训练的视频生成模型中，该路径将动作控制信号与预测视频对齐，添加特定于视图的调节以适应相机视点，并在各个实施例中生成统一的世界模型架构。为了减轻对静态背景的过度拟合，BridgeV2W 进一步引入了基于流的运动损失，专注于学习动态和任务相关区域。在单臂 (DROID) 和双臂 (AgiBot-G1) 数据集上进行的实验涵盖了具有未见过的视点和场景的多样化且具有挑战性的条件，结果表明，与之前最先进的方法相比，BridgeV2W 提高了视频生成质量。我们进一步展示了 BridgeV2W 在下游现实世界任务中的潜力，包括政策评估和目标条件规划。更多结果可以在我们的项目网站 https://BridgeV2W.github.io 上找到。

- **2026-02-03** **QVLA: Not All Channels Are Equal in Vision-Language-Action Model's Quantization** [2602.03782](http://arxiv.org/abs/2602.03782)
  > 视觉-语言-动作（VLA）模型的出现代表了体现智能的重大飞跃，但其巨大的计算需求严重阻碍了在资源有限的机器人平台上的部署。直观上，低位量化是大规模模型压缩的普遍且首选的技术。然而，我们发现从根本上缺乏对VLA模型量化的系统分析。我们认为，天真地将大型语言模型（LLM）的统一位量化应用于机器人技术是有缺陷的，因为这些方法优先考虑被动数据保真度，而忽略了微小的动作偏差如何导致灾难性的任务失败。为了弥补这一差距，我们引入了 QVLA，这是第一个专门为体现控制而设计的以动作为中心的量化框架。与基于 LLM 的方法的严格、统一位量化截然不同，QVLA 引入了高度粒度、通道方式的位分配策略。其核心机制是将每个单独通道量化为各种位宽时直接测量最终的动作空间灵敏度。此过程产生精确的每通道重要性指标，指导全局优化，从而将量化和修剪（0 位）优雅地统一到一个单一的、有凝聚力的框架中。对不同基线的广泛评估证明了我们方法的优越性。在 LIBERO 中，采用我们方法的 OpenVLA-OFT 量化版本仅需要原始模型 VRAM 的 29.2%，同时保持其原始性能的 98.9%，并实现 1.49 倍的加速。这意味着比 LLM 衍生方法 SmoothQuant 的性能提高了 22.6%。我们的工作为压缩机器人领域的 VLA 模型奠定了新的原则性基础，为在现实世界的硬件上部署强大的大规模模型铺平了道路。代码将被发布。

- **2026-02-03** **LIVE: Long-horizon Interactive Video World Modeling** [2602.03747](http://arxiv.org/abs/2602.03747)
  > 自回归视频世界模型预测以动作为条件的未来视觉观察。虽然这些模型在短期内有效，但在长期生成时往往会遇到困难，因为小的预测误差会随着时间的推移而积累。现有方法通过引入预训练的教师模型和序列级分布匹配来缓解这一问题，但这会产生额外的计算成本，并且无法防止错误传播超出训练范围。在这项工作中，我们提出了 LIVE，一种长视野交互式视频世界模型，它通过新颖的循环一致性目标强制限制误差累积，从而消除了基于教师的蒸馏的需要。具体来说，LIVE 首先从真实帧执行前向推出，然后应用反向生成过程来重建初始状态。随后在重建的最终状态上计算扩散损失，为长范围误差传播提供明确的约束。此外，我们提供包含不同方法的统一观点，并引入渐进式培训课程以稳定培训。实验表明，LIVE 在长期基准测试中实现了最先进的性能，生成了远远超出训练部署长度的稳定、高质量的视频。

- **2026-02-03** **Edge-Optimized Vision-Language Models for Underground Infrastructure Assessment** [2602.03742](http://arxiv.org/abs/2602.03742)
  > 下水道和涵洞系统等地下基础设施的自主检查对于公共安全和城市可持续发展至关重要。尽管配备视觉传感器的机器人平台可以有效地检测结构缺陷，但从这些检测中自动生成人类可读的摘要仍然是一个重大挑战，特别是在资源有限的边缘设备上。本文提出了一种新颖的两级管道，用于对地下缺陷进行端到端总结，将我们的轻量级 RAPID-SCAN 分割模型与部署在边缘计算平台上的微调视觉语言模型（VLM）相结合。第一阶段采用 RAPID-SCAN（使用紧凑自适应网络的资源感知管道检查和缺陷分割），仅用 0.64M 参数即可实现 0.834 F1 分数，实现高效缺陷分割。第二阶段利用经过微调的 Phi-3.5 VLM，从分割输出中以自然语言生成简洁的、特定领域的摘要。我们引入了一个精选的检查图像数据集，其中包含用于 VLM 微调和评估的手动验证的描述。为了实现实时性能，我们采用训练后量化和特定于硬件的优化，在不影响摘要质量的情况下显着减少模型大小和推理延迟。我们在移动机器人平台上部署和评估我们的完整管道，展示其在实际检查场景中的有效性。我们的结果表明，可边缘部署的集成人工智能系统有潜力弥合自动缺陷检测和基础设施维护的可操作见解之间的差距，为更具可扩展性和自主性的检测解决方案铺平道路。

- **2026-02-03** **MVP-LAM: Learning Action-Centric Latent Action via Cross-Viewpoint Reconstruction** [2602.03668](http://arxiv.org/abs/2602.03668)
  > 从不同的人类视频中学习\emph{潜在动作}可以将机器人学习扩展到特定于实施例的机器人数据集之外，并且这些潜在动作最近已被用作视觉语言动作（VLA）模型预训练的伪动作标签。为了使 VLA 预训练有效，潜在动作应该包含有关底层代理动作的信息，尽管没有真实标签。我们提出 \textbf{M}ulti-\textbf{V}iew\textbf{P}oint \textbf{L}atent \textbf{A}ction \textbf{M}odel (\textbf{MVP-LAM})，它学习离散的潜在动作，这些动作对时间同步的多视图视频中的真实动作提供了丰富的信息。 MVP-LAM 以 \emph{跨视点重建} 为目标来训练潜在动作，因此从一个视图推断出的潜在动作必须以另一种视图解释未来，从而减少对特定于视点的线索的依赖。在 Bridge V2 上，MVP-LAM 产生更多以动作为中心的潜在动作，通过真实动作实现更高的互信息并改进动作预测，包括在分布外评估下。最后，使用 MVP-LAM 潜在动作预训练 VLA 提高了 SIMPLER 和 LIBERO-Long 基准上的下游操作性能。

- **2026-02-03** **A Lightweight Library for Energy-Based Joint-Embedding Predictive Architectures** [2602.03604](http://arxiv.org/abs/2602.03604)
  > 我们推出了 EB-JEPA，这是一个使用联合嵌入预测架构 (JEPA) 学习表示和世界模型的开源库。 JEPA 学习在表示空间而不是像素空间中进行预测，避免生成建模的陷阱，同时捕获适合下游任务的语义上有意义的特征。我们的库提供了模块化、独立的实现，说明了为图像级自监督学习开发的表示学习技术如何转移到视频（其中时间动态增加了复杂性），并最终转移到动作条件的世界模型（其中模型必须另外学习预测控制输入的效果）。每个示例都专为在几个小时内进行单 GPU 训练而设计，使基于能量的自我监督学习可用于研究和教育。我们在 CIFAR-10 上提供 JEA 组件的消融。探测这些表示的准确率达到 91%，这表明该模型学习了有用的特征。扩展到视频，我们在 Moving MNIST 上提供了一个多步骤预测示例，演示了相同的原理如何扩展到时间建模。最后，我们展示了这些表示如何驱动动作条件世界模型，从而在两室导航任务中实现 97% 的规划成功率。全面的消融揭示了每个正则化组件对于防止表示崩溃的至关重要性。代码可在 https://github.com/facebookresearch/eb_jepa 获取。

- **2026-02-03** **Multi-Player, Multi-Strategy Quantum Game Model for Interaction-Aware Decision-Making in Autonomous Driving** [2602.03571](http://arxiv.org/abs/2602.03571)
  > 尽管自动驾驶的决策已经取得了重大进展，但在现实世界中的部署仍然面临挑战。一项挑战在于解决交互意识。大多数现有方法过度简化了自我车辆与周围代理之间的交互，并且经常忽略代理本身之间的交互。常见的解决方案是使用经典博弈论对这些交互进行建模。然而，它的表述假设参与者是理性的，而人类的行为往往是不确定或非理性的。为了应对这些挑战，我们提出了量子博弈决策（QGDM）模型，这是一种将经典博弈论与量子力学原理（例如叠加、纠缠和干扰）相结合的新颖框架，用于解决多人、多策略决策问题。据我们所知，这是最早将量子博弈论应用于自动驾驶决策的研究之一。 QGDM 在标准计算机上实时运行，无需量子硬件。我们在各种场景（包括环岛、合并和高速公路）的模拟中评估 QGDM，并将其性能与多种基线方法进行比较。结果表明，与经典方法相比，QGDM 显着提高了成功率并降低了冲突率，特别是在交互性较高的场景中。

- **2026-02-03** **EHRWorld: A Patient-Centric Medical World Model for Long-Horizon Clinical Trajectories** [2602.03569](http://arxiv.org/abs/2602.03569)
  > 世界模型为模拟干预下的未来状态提供了一个原则框架，但在医学等复杂、高风险的领域实现此类模型仍然具有挑战性。最近的大语言模型（LLM）在静态医学推理任务上取得了出色的表现，这引发了一个问题：它们是否可以作为能够模拟疾病进展和治疗结果随时间变化的动态医学世界模型。在这项工作中，我们表明，仅结合医学知识的法学硕士很难在连续干预下维持一致的患者状态，导致长期临床模拟中的错误累积。为了解决这一限制，我们引入了 EHRWorld（一种在因果顺序范式下训练的以患者为中心的医学世界模型）以及 EHRWorld-110K（源自真实世界电子健康记录的大规模纵向临床数据集）。广泛的评估表明，EHRWorld 显着优于基于 LLM 的原始基线，实现了更稳定的长期模拟，改进了临床敏感事件的建模，并提高了推理效率，强调了基于因果关系、随时间变化的临床数据进行训练的必要性，以实现可靠和稳健的医学世界建模。

- **2026-02-03** **A Minimal Task Reveals Emergent Path Integration and Object-Location Binding in a Predictive Sequence Model** [2602.03490](http://arxiv.org/abs/2602.03490)
  > 适应性认知需要表示对象及其关系的结构化内部模型。预测神经网络经常被提出来形成这样的“世界模型”，但其潜在机制仍不清楚。一种假设是，动作条件序列预测足以学习这样的世界模型。在这项工作中，我们在最小的计算机环境中研究了这种可能性。从 2D 连续令牌场景中顺序采样令牌，训练循环神经网络以根据当前输入和类似扫视的位移来预测即将到来的令牌。在新颖的场景中，整个序列的预测准确性得到提高，这表明上下文学习。解码分析揭示了路径整合以及令牌身份与位置的动态绑定。介入分析表明，可以在序列后期学习新的结合，并且可以学习分布外的结合。总之，这些结果证明了依赖于灵活绑定的结构化表示如何出现来支持预测，从而提供了与认知科学相关的顺序世界建模的机械解释。

- **2026-02-03** **HetroD: A High-Fidelity Drone Dataset and Benchmark for Autonomous Driving in Heterogeneous Traffic** [2602.03447](http://arxiv.org/abs/2602.03447)
  > 我们推出 HetroD，这是一个用于在异构环境中开发自动驾驶系统的数据集和基准。 HetroD 的目标是应对由弱势道路使用者 (VRU) 主导的现实世界异构交通的严峻挑战，其中包括与车辆互动的行人、骑自行车的人和骑摩托车的人。这些混合代理类型表现出复杂的行为，例如弯道、分道和非正式的路权协商。这些行为给自动驾驶汽车带来了重大挑战，但在专注于结构化、车道管制交通的现有数据集中仍然代表性不足。为了弥补这一差距，我们收集了基于无人机的大规模数据集，通过厘米级精确的注释、高清地图和交通信号状态来提供对交通场景的整体观察。我们进一步开发了一个模块化工具包，用于提取每个代理场景以支持下游任务开发。该数据集总共包含超过 65.4k 个高保真智能体轨迹，其中 70% 来自 VRU。 HetroD 支持对密集、异构流量中的 VRU 行为进行建模，并为预测、规划和模拟任务提供标准化基准。评估结果表明，最先进的预测和规划模型正在努力应对我们的数据集带来的挑战：它们无法预测横向 VRU 运动，无法处理非结构化操作，并且在密集和多智能体场景中表现出有限的性能，这凸显了对异构流量更强大的方法的需求。有关更多示例，请参阅我们的项目页面：https://hetroddata.github.io/HetroD/

- **2026-02-02** **TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments** [2602.02459](http://arxiv.org/abs/2602.02459)
  > 在动态、以人为中心的环境中的机器人必须遵循语言指令，同时保持实时反应控制。视觉-语言-动作（VLA）模型提供了一个有前途的框架，但它们假设推理和控制在时间上一致，尽管语义推理相对于实时动作本质上是延迟的。我们引入了 Think-in-Control (TIC)-VLA，这是一种延迟感知框架，可显式模拟动作生成过程中的延迟语义推理。 TIC-VLA 定义了一个延迟语义控制接口，除了当前观察之外，该接口还根据延迟视觉语言语义状态和显式延迟元数据来调节动作生成，从而使策略能够补偿异步推理。我们进一步提出了一种延迟一致的训练管道，在模仿学习和在线强化学习期间注入推理推理延迟，使训练与异步部署保持一致。为了支持真实的评估，我们推出了 DynaNav，这是一种物理精确、逼真的模拟套件，用于动态环境中的语言引导导航。模拟和真实机器人上的大量实验表明，TIC-VLA 始终优于先前的 VLA 模型，同时在多秒推理延迟下保持鲁棒的实时控制。项目网站：https://ucla-mobility.github.io/TIC-VLA/

- **2026-02-02** **World-Gymnast: Training Robots with Reinforcement Learning in a World Model** [2602.02454](http://arxiv.org/abs/2602.02454)
  > 机器人通过与物理世界交互进行学习从根本上受到物理交互成本的瓶颈。这两种替代方案，即来自专家演示的监督微调 (SFT) 和基于软件的模拟器中的强化学习 (RL)，都受到可用专家数据量以及操作的模拟与真实差距的限制。随着最近从现实世界视频动作数据中学习的世界模型的出现，我们提出一个问题：在世界模型中训练策略是否比监督学习或软件模拟更有效地实现更好的真实机器人性能。我们提出了 World-Gymnast，它通过在动作条件视频世界模型中推出策略并用视觉语言模型（VLM）奖励推出来对视觉语言动作（VLA）策略进行强化学习微调。在 Bridge 机器人设置中，World-Gymnast 的性能比 SFT 高出 18 倍，比软件模拟器高出 2 倍。更重要的是，World-Gymnast 通过世界模型展示了 RL 的有趣功能，包括对世界模型中的多种语言指令和新颖场景进行训练、新颖场景中的测试时训练以及在线迭代世界模型和策略改进。我们的结果表明，学习世界模型并在云中训练机器人策略可能是弥合演示机器人和可以在任何家庭中工作的机器人之间差距的关键。

- **2026-02-02** **Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory** [2602.02393](http://arxiv.org/abs/2602.02393)
  > 我们提出了 Infinite-World，这是一种强大的交互式世界模型，能够在复杂的现实环境中保持超过 1000 多个帧的连贯视觉记忆。虽然现有的世界模型可以在具有完美地面实况的合成数据上进行有效优化，但由于嘈杂的姿势估计和缺乏视点重访，它们缺乏针对真实世界视频的有效训练范例。为了弥补这一差距，我们首先引入了一种分层无姿势记忆压缩器（HPMC），它将历史潜伏递归地提取为固定预算表示。通过联合优化压缩器和生成主干，HPMC 使模型能够以有限的计算成本自主锚定遥远过去的世代，从而消除了对显式几何先验的需要。其次，我们提出了一个不确定性感知动作标签模块，将连续运动离散化为三态逻辑。该策略最大限度地利用原始视频数据，同时保护确定性动作空间免受噪声轨迹的破坏，确保稳健的动作响应学习。此外，在试点玩具研究的指导下，我们采用了 Revisit-Dense Finetuning 策略，使用紧凑的 30 分钟数据集来有效激活模型的远程闭环功能。包括客观指标和用户研究在内的大量实验表明，Infinite-World 在视觉质量、动作可控性和空间一致性方面实现了卓越的性能。

- **2026-02-02** **Self-Supervised Learning from Structural Invariance** [2602.02381](http://arxiv.org/abs/2602.02381)
  > 联合嵌入自监督学习（SSL）是从视觉数据进行无监督表示学习的关键范例，它从语义相关数据对之间的不变性中学习。我们研究 SSL 中的一对多映射问题，其中每个数据可能映射到多个有效目标。当数据对来自自然发生的生成过程（例如连续的视频帧）时，就会出现这种情况。我们表明现有的方法很难灵活地捕捉这种条件不确定性。作为补救措施，我们引入一个潜在变量来解释这种不确定性，并得出配对嵌入之间互信息的变分下界。我们的推导为标准 SSL 目标生成了一个简单的正则化项。由此产生的方法，我们称之为 AdaSSL，适用于基于对比和基于蒸馏的 SSL 目标，我们凭经验证明了它在因果表示学习、细粒度图像理解和视频世界建模方面的多功能性。

- **2026-02-02** **Choice-Model-Assisted Q-learning for Delayed-Feedback Revenue Management** [2602.02283](http://arxiv.org/abs/2602.02283)
  > 我们研究带有延迟反馈的收入管理的强化学习，其中很大一部分价值是由预订后几天观察到的客户取消和修改决定的。我们提出\emph{选择模型辅助强化学习}：使用校准的离散选择模型作为固定的部分世界模型来估算决策时学习目标的延迟部分。在固定模型部署方案中，我们证明具有模型估算目标的表格 Q 学习收敛于最优 Q 函数的 $O(\varepsilon/(1-γ))$ 邻域，其中 $\varepsilon$ 总结了部分模型误差，并附加了 $O(t^{-1/2})$ 采样项。根据 61{,}619 个酒店预订（1{,}088 次独立运行）校准的模拟器中的实验表明：(i) 与固定设置中的成熟度缓冲 DQN 基线没有统计上可检测到的差异； (ii) 家庭内参数变化带来的积极影响，经过 Holm-Bonferroni 校正后，10 个变化场景中的 5 个有显着增益（高达 12.4\%）； (iii) 在结构性错误指定下持续退化，违反了选择模型假设（收入降低 1.4--2.6\%）。这些结果表征了部分行为模型何时提高了转变下的鲁棒性以及何时引入了有害的偏见。

- **2026-02-02** **Online Fine-Tuning of Pretrained Controllers for Autonomous Driving via Real-Time Recurrent RL** [2602.02236](http://arxiv.org/abs/2602.02236)
  > 在现实应用中部署预训练策略提出了巨大的挑战，从根本上限制了基于学习的控制系统的实际适用性。当自主系统遇到系统动力学、传感器漂移或任务目标等环境变化时，固定策略的性能会迅速下降。我们证明，采用实时循环强化学习（RTRRL）（一种生物学上合理的在线适应算法）可以有效地微调预训练策略，以提高自主代理在驾驶任务上的表现。我们进一步证明 RTRRL 与最近受生物学启发的循环网络模型（液体电阻液体电容 RNN）具有协同作用。我们在模拟 CarRacing 环境和配备事件摄像机的 RoboRacer 赛车的现实循线任务中展示了这种闭环方法的有效性。

- **2026-02-02** **LiFlow: Flow Matching for 3D LiDAR Scene Completion** [2602.02232](http://arxiv.org/abs/2602.02232)
  > 在自动驾驶场景中，收集的激光雷达点云可能会受到遮挡和远距离稀疏的挑战，限制了自动驾驶系统的感知。场景补全方法可以推断不完整 3D LiDAR 场景中缺失的部分。最近的方法采用局部点级去噪扩散概率模型，需要预测高斯噪声，导致训练和推理初始分布之间不匹配。本文介绍了第一个用于 3D LiDAR 场景完成的流匹配框架，通过确保训练和推理之间一致的初始分布来改进基于扩散的方法。该模型采用最近邻流匹配损失和倒角距离损失来增强点云对齐中的局部结构和全局覆盖。 LiFlow 在多个指标上实现了最先进的性能。代码：https://github.com/matteandre/LiFlow。

- **2026-02-02** **MAIN-VLA: Modeling Abstraction of Intention and eNvironment for Vision-Language-Action Models** [2602.02212](http://arxiv.org/abs/2602.02212)
  > 尽管视觉语言动作 (VLA) 取得了重大进展，但在涉及实时不可预测交互的高度复杂和动态环境中（例如 3D 开放世界和大型 PvP 游戏），现有方法在从冗余传感器流中提取关键动作信号方面仍然效率低下。为了解决这个问题，我们引入了 MAIN-VLA，这是一个框架，它明确地对意图和环境的抽象进行建模，以深层语义对齐而不是表面模式匹配的方式进行决策。具体来说，我们的意图抽象（IA）将详细的语言指令及其相关推理提取为紧凑、明确的语义原语，而环境语义抽象（ESA）将压倒性的视觉流投射到结构化的拓扑可供性表示中。此外，对齐这两种抽象模式会产生一种新的注意力集中效应，从而实现一种无参数的标记修剪策略，可以过滤掉感知冗余而不降低性能。在开放世界 Minecraft 和大型 PvP 环境（《和平精英》和《Valorant》）中进行的大量实验表明，MAIN-VLA 树立了新的最先进水平，实现了卓越的决策质量、更强的泛化性和尖端的推理效率。

- **2026-02-02** **FD-VLA: Force-Distilled Vision-Language-Action Model for Contact-Rich Manipulation** [2602.02142](http://arxiv.org/abs/2602.02142)
  > 力传感是视觉-语言-动作（VLA）框架的重要模式，因为它可以在接触丰富的任务中实现细粒度的感知和灵巧的操作。我们提出了 Force-Distilled VLA (FD-VLA)，这是一种新颖的框架，它将力感知集成到富含接触的操作中，而不依赖于物理力传感器。我们方法的核心是力蒸馏模块（FDM），它通过将可学习的查询标记（以视觉观察和机器人状态为条件）映射为与实际力信号的潜在表示一致的预测力标记来提取力。在推理过程中，这种经过提炼的力令牌被注入到预训练的 VLM 中，从而实现力感知推理，同时保留其视觉语言语义的完整性。这种设计具有两个主要优点：首先，它允许在缺乏昂贵或脆弱的力扭矩传感器的各种机器人上进行实际部署，从而降低硬件成本和复杂性；其次，FDM 在 VLM 之前引入了额外的力-视觉-状态融合，从而改善了跨模式对齐并增强了接触丰富场景中的感知-动作鲁棒性。令人惊讶的是，我们的物理实验表明，蒸馏力令牌优于直接传感器力测量以及其他基线，这凸显了这种力蒸馏 VLA 方法的有效性。

- **2026-02-02** **An Empirical Study of World Model Quantization** [2602.02110](http://arxiv.org/abs/2602.02110)
  > 世界模型学习环境动态的内部表示，使代理能够在紧凑的潜在空间内模拟和推理未来状态，以完成规划、预测和推理等任务。然而，运行世界模型依赖于大量的计算成本和内存占用，这使得模型量化对于高效部署至关重要。迄今为止，训练后量化（PTQ）对世界模型的影响在​​很大程度上仍未得到检验。在这项工作中，我们以 DINO-WM 作为代表案例，对世界模型量化进行了系统的实证研究，评估了仅权重和联合权重激活设置下的各种 PTQ 方法。我们对不同的视觉规划任务进行了广泛的实验，涉及各种位宽、量化粒度和最多 50 次迭代的规划范围。我们的结果表明，世界模型中的量化效果超出了标准精度和位宽权衡：分组权重量化可以稳定低位推出，激活量化粒度产生不一致的好处，编码器和预测器模块之间的量化灵敏度高度不对称。此外，激进的低位量化会显着降低规划目标和任务成功之间的一致性，从而导致无法通过额外优化来补救的失败。这些发现揭示了基于世界模型的规划中不同的量化引起的故障模式，并为在严格的计算约束下部署量化世界模型提供了实用指导。代码可在 https://github.com/huawei-noah/noah-research/tree/master/QuantWM 获取。

- **2026-02-02** **See2Refine: Vision-Language Feedback Improves LLM-Based eHMI Action Designers** [2602.02063](http://arxiv.org/abs/2602.02063)
  > 自动驾驶车辆缺乏与其他道路使用者的自然沟通渠道，因此外部人机界面 (eHMI) 对于在共享环境中传达意图和维持信任至关重要。然而，大多数 eHMI 研究依赖于开发人员制作的消息-操作对，这很难适应多样化和动态的流量环境。一种有前途的替代方案是使用大型语言模型 (LLM) 作为生成上下文条件 eHMI 操作的操作设计器，但此类设计器缺乏感知验证，并且通常依赖于固定提示或昂贵的人工注释反馈来进行改进。我们提出了 See2Refine，这是一个无人参与的闭环框架，它使用视觉语言模型 (VLM) 感知评估作为自动视觉反馈来改进基于 LLM 的 eHMI 动作设计器。给定驾驶环境和候选 eHMI 操作，VLM 评估该操作的感知适当性，并且此反馈用于迭代修改设计人员的输出，从而无需人工监督即可进行系统改进。我们跨三种 eHMI 模式（灯条、眼睛和手臂）和多个 LLM 模型大小评估我们的框架。在各种设置中，我们的框架在基于 VLM 的指标和人类受试者评估中始终优于仅提示的 LLM 设计者和手动指定的基线。结果进一步表明，改进适用于各种模式，并且 VLM 评估与人类偏好非常一致，支持 See2Refine 在可扩展行动设计方面的稳健性和有效性。

- **2026-02-02** **UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving** [2602.02002](http://arxiv.org/abs/2602.02002)
  > 世界模型已经展示了自动驾驶数据合成的巨大前景。然而，现有方法主要集中于单模态生成，通常侧重于多摄像头视频或激光雷达序列合成。在本文中，我们提出了 UniDriveDreamer，这是一种用于自动驾驶的单阶段统一多模态世界模型，它直接生成多模态未来观测结果，而不依赖于中间表示或级联模块。我们的框架引入了 LiDAR 专用的变分自动编码器 (VAE)，旨在对输入 LiDAR 序列进行编码，以及用于多摄像头图像的视频 VAE。为了确保跨模态兼容性和训练稳定性，我们提出了统一潜在锚定（ULA），它明确地对齐了两种模态的潜在分布。对齐的特征由扩散变换器融合和处理，该扩散变换器联合模拟它们的几何对应和时间演化。此外，结构化场景布局信息按模态投影作为调节信号来指导合成。大量实验表明，UniDriveDreamer 在视频和 LiDAR 生成方面均优于以前最先进的方法，同时在下游方面也产生了可衡量的改进

- **2026-02-02** **Grounding Generated Videos in Feasible Plans via World Models** [2602.01960](http://arxiv.org/abs/2602.01960)
  > 大规模视频生成模型已经显示出作为零镜头视觉规划器的新兴功能，但视频生成的计划经常违反时间一致性和物理约束，导致映射到可执行动作时失败。为了解决这个问题，我们提出了基于世界模型的视频计划（GVP-WM），这是一种使用学习的动作条件世界模型将视频生成的计划转化为可行的动作序列的规划方法。在测试时，GVP-WM 首先根据初始观察和目标观察生成视频计划，然后通过视频引导的潜在搭配将视频引导投影到多种动态可行的潜在轨迹上。特别是，我们将基础制定为目标条件潜在空间轨迹优化问题，在世界模型动态下联合优化潜在状态和动作，同时保持与视频生成计划的语义对齐。根据经验，GVP-WM 从零镜头图像到视频生成的运动模糊视频中恢复了可行的长期计划，这些视频违反了导航和操作模拟任务的物理约束。

- **2026-02-02** **ForSim: Stepwise Forward Simulation for Traffic Policy Fine-Tuning** [2602.01916](http://arxiv.org/abs/2602.01916)
  > 作为自动驾驶闭环训练和评估的基础，交通仿真仍然面临两个基本挑战：开环模仿学习引入的协变量偏移以及反映现实交通中观察到的多模态行为的能力有限。尽管 RIFT 等最新框架通过组相关优化部分解决了这些问题，但它们的前向模拟程序在很大程度上仍然是非反应性的，导致虚拟域内的代理交互不切实际，并最终限制模拟保真度。为了解决这些问题，我们提出了 ForSim，一种逐步闭环正向仿真范例。在每个虚拟时间步长，交通代理通过物理基础的运动动力学传播与参考轨迹在时空上最佳匹配的虚拟候选轨迹，从而保留多模态行为多样性，同时确保模态内一致性。其他智能体通过逐步预测进行更新，从而产生连贯且具有交互感知的进化。当纳入 RIFT 流量模拟框架时，ForSim 与组相关优化结合运行，以微调流量策略。大量实验证实，这种集成能够持续提高安全性，同时保持效率、真实性和舒适性。这些结果强调了在正向仿真中对闭环多模态交互进行建模的重要性，并提高了自动驾驶交通仿真的保真度和可靠性。项目页面：https://currychen77.github.io/ForSim/

- **2026-02-02** **Quantum vortex channels as Josephson junctions** [2602.01889](http://arxiv.org/abs/2602.01889)
  > 在量子气体中，薄弱环节通常是通过外部施加的光势来实现的。我们表明，在旋转的二元凝聚态中，一个组分中的量子化涡流形成中空通道，充当另一组分的自诱导薄弱环节，从而使超流能够通过其他不可穿透的相分离域。这引入了一种新颖的势垒机制：量子压力在涡流通道内创建了一个有效的势垒，该势垒由控制超流的收缩宽度设定。调整种间相互作用强度可驱动从流体动力传输到约瑟夫森隧道机制的交叉。长程偶极相互作用进一步调整弱连接特性，使短连接和两个串联耦合结成为可能。电路模型定量地捕获两种配置的直流电流-相位关系。这些结果将涡旋确立为超流体中可重构、相互作用控制的约瑟夫森元件。

- **2026-02-02** **Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models** [2602.01834](http://arxiv.org/abs/2602.01834)
  > 视觉语言动作（VLA）模型通过将多模式指令转换为可执行行为来关闭感知动作循环，但这种能力放大了安全风险：仅仅在法学硕士中产生有毒文本的越狱可能会在具体系统中触发不安全的物理动作。现有的防御调整、过滤或即时强化干预得太晚或以错误的方式进行，导致融合表示可被利用。我们引入了一种基于概念的字典学习框架，用于推理时间安全控制。通过从隐藏的激活构建稀疏的、可解释的字典，我们的方法识别有害的概念方向，并应用基于阈值的干预措施来抑制或阻止不安全的激活。在 Libero-Harm、BadRobot、RoboPair 和 IS-Bench 上进行的实验表明，我们的方法实现了最先进的防御性能，在保持任务成功的同时将攻击成功率降低了 70% 以上。至关重要的是，该框架是插件且与模型无关，无需重新训练并与不同的 VLA 无缝集成。据我们所知，这是第一个用于实体系统的基于推理时间概念的安全方法，提高了 VLA 模型的可解释性和安全部署。

- **2026-02-02** **From Knowing to Doing Precisely: A General Self-Correction and Termination Framework for VLA models** [2602.01811](http://arxiv.org/abs/2602.01811)
  > 虽然实体主体的视觉-语言-动作（VLA）模型集成了感知、推理和控制，但它们仍然受到两个关键弱点的限制：首先，在抓取任务期间，语言模型生成的动作标记经常表现出与目标对象的微妙空间偏差，导致抓取失败；其次，它们缺乏可靠地识别任务完成情况的能力，从而导致冗余操作和频繁的超时错误。为了应对这些挑战并增强鲁棒性，我们提出了一个轻量级、免训练的框架，VLA-SCT。该框架作为一个自我纠正控制循环运行，将数据驱动的操作细化与终止条件逻辑相结合。因此，与基线方法相比，我们的方法在 LIBERO 基准测试中的所有数据集上实现了一致的改进，显着提高了精细操作任务的成功率并确保任务的准确完成，从而促进了在复杂、非结构化环境中部署更可靠的 VLA 代理。

- **2026-02-02** **Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention** [2602.01801](http://arxiv.org/abs/2602.01801)
  > 自回归视频扩散模型支持流式生成，为长格式合成、视频世界模型和交互式神经游戏引擎打开了大门。然而，它们的核心注意力层成为推理时的主要瓶颈：随着生成的进展，KV 缓存不断增长，导致延迟增加和 GPU 内存不断增加，这反过来又限制了可用的时间上下文并损害了远程一致性。在这项工作中，我们研究了自回归视频扩散中的冗余，并确定了三个持久源：跨帧的近乎重复的缓存键、缓慢演变的（主要是语义的）查询/键，这使得许多注意力计算变得冗余，以及长提示上的交叉注意力，其中每帧只有一小部分标记很重要。基于这些观察，我们提出了一个用于自回归扩散的统一的、免训练的注意力框架：TempCache 通过时间对应来压缩 KV 缓存以限制缓存增长； AnnCA 通过使用快速近似最近邻 (ANN) 匹配选择与帧相关的提示标记来加速交叉注意力； AnnSA 通过将每个查询限制为语义匹配的键（也使用轻量级 ANN）来稀疏自注意力。这些模块共同减少了注意力、计算和记忆，并且与现有的自回归扩散主干和世界模型兼容。实验证明，端到端加速高达 x5--x10，同时保持几乎相同的视觉质量，最重要的是，在长期部署过程中保持稳定的吞吐量和几乎恒定的峰值 GPU 内存使用量，而之前的方法会逐渐减慢速度并受到内存使用量增加的影响。

- **2026-02-02** **DDP-WM: Disentangled Dynamics Prediction for Efficient World Models** [2602.01780](http://arxiv.org/abs/2602.01780)
  > 世界模型对于自主机器人规划至关重要。然而，现有的基于 Transformer 的密集模型的大量计算开销极大地阻碍了实时部署。为了解决这个效率性能瓶颈，我们引入了 DDP-WM，这是一种以解缠动态预测 (DDP) 原理为中心的新颖世界模型。我们假设观察到的场景中的潜在状​​态演化是异构的，并且可以分解为由物理交互驱动的稀疏主要动力学和次要上下文驱动的背景更新。 DDP-WM 通过一种架构实现了这种分解，该架构将高效的历史处理与动态定位相结合以隔离主要动态。通过采用交叉注意力机制进行后台更新，该框架优化了资源分配，并为规划者提供了平滑的优化环境。大量实验表明，DDP-WM 在不同的任务中实现了显着的效率和性能，包括导航、精确的桌面操作以及复杂的可变形或多体交互。具体来说，在具有挑战性的 Push-T 任务上，与最先进的密集模型相比，DDP-WM 实现了约 9 倍的推理加速，并将 MPC 成功率从 90% 提高到 98%。研究结果为开发高效、高保真的世界模型开辟了一条有希望的道路。代码可在 https://github.com/HCPLabSYSU/DDP-WM 获取。

- **2026-02-02** **SafePred: A Predictive Guardrail for Computer-Using Agents via World Models** [2602.01725](http://arxiv.org/abs/2602.01725)
  > 随着计算机使用代理（CUA）在复杂的现实环境中的广泛部署，普遍存在的长期风险往往会导致严重且不可逆转的后果。大多数现有的 CUA 护栏都采用反应性方法，仅在当前观察空间内限制智能体的行为。虽然这些护栏可以防止立即的短期风险（例如，点击网络钓鱼链接），但它们无法主动避免长期风险：看似合理的行动可能会导致延迟出现的高风险后果（例如，清理日志导致未来的审计无法追踪），而反应性护栏无法在当前观察空间内识别这些后果。为了解决这些限制，我们提出了一种预测护栏方法，其核心思想是将预测的未来风险与当前决策相结合。基于这种方法，我们提出了 SafePred，这是一种针对 CUA 的预测护栏框架，它建立了风险到决策循环以确保安全代理行为。 SafePred支持两个关键能力：（1）短期和长期风险预测：以安全策略作为风险预测的基础，SafePred利用世界模型的预测能力生成短期和长期风险的语义表示，从而识别和修剪导致高风险状态的行为； （2）决策优化：通过步骤级干预和任务级重新规划，将预测风险转化为可操作的安全决策指导。大量实验表明，SafePred 显着减少了高风险行为，与反应基线相比，实现了 97.6% 以上的安全性能，并将任务效用提高了高达 21.4%。

- **2026-01-30** **IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models** [2601.23266](http://arxiv.org/abs/2601.23266)
  > 本文提出了一种新颖的逆强化学习框架，使用基于扩散的自适应前瞻规划器（IRL-DAL）用于自动驾驶车辆。训练从模仿专家有限状态机 (FSM) 控制器开始，以提供稳定的初始化。环境术语与 IRL 鉴别器信号相结合，以与专家目标保持一致。然后使用混合奖励来执行强化学习 (RL)，该混合奖励结合了分散的环境反馈和有针对性的 IRL 奖励。条件扩散模型充当安全监督员，规划安全路径。它保持在车道上，避开障碍物并平稳移动。然后，可学习的自适应掩模（LAM）可以改善感知。它根据车速和附近的危险来转移视觉注意力。基于 FSM 的模仿之后，使用近端策略优化（PPO）对策略进行微调。培训在 Webots 模拟器中进行，课程分为两个阶段。成功率达到 96%，碰撞次数减少至每 1000 步 0.05 次，树立了安全导航的新标杆。通过应用所提出的方法，代理不仅可以在车道上行驶，还可以以专家级别处理不安全的情况，从而提高鲁棒性。我们公开了我们的代码。

- **2026-01-30** **FlowCalib: LiDAR-to-Vehicle Miscalibration Detection using Scene Flows** [2601.23107](http://arxiv.org/abs/2601.23107)
  > 准确的传感器到车辆校准对于安全自动驾驶至关重要。激光雷达传感器的角度偏差可能会在自主操作期间导致安全关键问题。然而，当前的方法主要集中于纠正传感器到传感器的误差，而不考虑首先导致这些误差的各个传感器的校准错误。我们介绍 FlowCalib，这是第一个使用静态物体场景流中的运动线索来检测 LiDAR 与车辆的校准误差的框架。我们的方法利用了由连续 3D 点云生成的流场中的旋转失准引起的系统偏差，从而无需额外的传感器。该架构集成了用于流量估计的神经场景流先验，并结合了双分支检测网络，该网络将学习的全局流量特征与手工制作的几何描述符融合在一起。这些组合表示允许系统执行两个互补的二元分类任务：指示是否存在未对准的全局二元决策和指示每个旋转轴是否未对准的单独的、特定于轴的二元决策。 nuScenes 数据集上的实验证明了 FlowCalib 能够稳健地检测误校准，从而为传感器到车辆的误校准检测建立基准。

- **2026-01-30** **Spatial self-organization driven by temporal noise** [2601.23098](http://arxiv.org/abs/2601.23098)
  > 从噪声中反直觉地出现秩序是科学中的一个核心现象，从模式形成和同步到受挫系统中的无序有序。虽然局部空间噪声引起的大规模空间自组织已得到充分研究，但时间噪声是否也能驱动这种组织仍然是一个悬而未决的问题。在这里，通过研究相互作用的粒子系统，我们表明时间相关的噪声可以导致自组织状态，并抑制长程密度波动或超均匀性。此外，我们发展了一种脉动流体动力学理论，定量地解释了这种现象的起源。最后，通过将动力学转化为随机优化问题，我们表明时间相关性会带来更好的解决方案，类似于神经网络中的扰动梯度下降——在训练期间注入噪声以逃避较差的最小值。这揭示了粒子系统能量景观上的扰动梯度下降动力学与神经网络损失景观之间的惊人对应关系。我们的研究将时间相关性建立为噪声驱动自组织的一种新机制，对自组装材料、生物系统和利用时间噪声进行差分私人学习等应用的优化算法具有广泛的影响。

- **2026-01-30** **Alignment among Language, Vision and Action Representations** [2601.22948](http://arxiv.org/abs/2601.22948)
  > 认知科学和人工智能的一个基本问题涉及不同的学习方式：语言、视觉和行动是否会产生不同或共享的内部表征。传统观点认为，在不同数据类型上训练的模型会开发专门的、不可转移的表示。然而，最近的证据表明出乎意料的融合：针对不同任务优化的模型可能会开发出类似的表征几何形状。我们通过训练基于变压器的代理来响应自然语言指令来执行目标导向的行为，从而研究这种融合是否扩展到具体的动作学习。使用 BabyAI 平台上的行为克隆，我们生成了专门根据感觉运动控制要求形成的基于动作的语言嵌入。然后，我们将这些表示与从最先进的大型语言模型（LLaMA、Qwen、DeepSeek、BERT）和视觉语言模型（CLIP、BLIP）中提取的表示进行了比较。尽管训练数据、模式和目标存在巨大差异，但我们观察到了强大的跨模式对齐。动作表示与仅解码器的语言模型和 BLIP 高度一致（精度@15：0.70-0.73），接近语言模型本身之间观察到的对齐。与 CLIP 和 BERT 的对齐明显较弱。这些发现表明，语言、视觉和动作表示趋向于部分共享的语义结构，支持独立于模态的语义组织，并凸显了具体人工智能系统中跨域转移的潜力。

- **2026-01-30** **Linear perturbation theory and structure formation in a Brans-Dicke theory of gravity without dark matter** [2601.22937](http://arxiv.org/abs/2601.22937)
  > 我们研究了属于布兰斯-迪克理论类的重力标量张量理论中大尺度宇宙结构的形成。宇宙只包含重子物质，既不包含暗物质，也不包含暗能量。表征动力学项和自相互作用势的标量场的两个任意函数分别设置为 $W(\varphi)=-1$ 和 $V(\varphi) = -Ξ\varphi$，其中 $Ξ$ 为正常数。在弱场极限下，该理论简化为折射引力，这是一种非相对论理论，其修正的泊松方程包含标量场$\varphi$，它提供了描述没有暗物质的星系和星系团动力学所需的引力增强。在平坦、以物质为主、均匀且各向同性的宇宙中，相同的标量场 $\varphi$ 驱动着宇宙的加速膨胀，并描述了观测到的哈勃-勒梅特参数 $H(z)$ 的红移演化。然而，在线性微扰理论的增长因子方程中，$V(\varphi)$的形式使得引力场源的系数与$H^{-1}(z)$成正比；因此，引力场在早期受到强烈抑制，结构形成被延迟到红移$z<1$，这与在更大红移时观察到的形成星系不一致。此外，$W(\varphi)$ 的形式和线性 $V(\varphi)$ 意味着 $\varphi$ 对大质量粒子产生的引力增强是光子产生的引力增强的两倍，这对引力透镜现象可能产生可观察到的后果。 $W(\varphi)$ 和 $V(\varphi)$ 的不同选择是否仍然可以使理论简化为弱场极限下的折射重力，是否可以缓解这些问题还有待研究。

- **2026-01-30** **MTDrive: Multi-turn Interactive Reinforcement Learning for Autonomous Driving** [2601.22930](http://arxiv.org/abs/2601.22930)
  > 轨迹规划是自动驾驶的核心任务，需要在不同场景下预测安全舒适的路径。将多模态大型语言模型 (MLLM) 与强化学习 (RL) 集成，在解决“长尾”场景方面显示出了希望。然而，现有方法仅限于单轮推理，限制了它们处理需要迭代细化的复杂任务的能力。为了克服这一限制，我们提出了 MTDrive，这是一种多轮框架，使 MLLM 能够根据环境反馈迭代地细化轨迹。 MTDrive 引入了多轮组相对策略优化 (mtGRPO)，它通过计算轮次之间的相对优势来减轻奖励稀疏性。我们进一步从闭环模拟构建交互式轨迹理解数据集以支持多回合训练。 NAVSIM 基准测试证明了与现有方法相比具有优越的性能，验证了我们的多轮推理范式的有效性。此外，我们还实施了系统级优化，以减少由高分辨率图像和多轮序列引起的数据传输开销，实现 2.5 倍的训练吞吐量。我们的数据、模型和代码将很快提供。

- **2026-01-30** **Toward Fully Autonomous Driving: AI, Challenges, Opportunities, and Needs** [2601.22927](http://arxiv.org/abs/2601.22927)
  > 自动驾驶（AD）前景广阔，但向完全自动驾驶的过渡除其他外，还受到真实、不断变化的开放世界以及由此带来的挑战的影响。然而，AD 领域的研究表明，人工智能 (AI) 有能力超越经典方法、处理更高的复杂性并达到新的自主水平。与此同时，人工智能的使用引发了安全性和可转移性的进一步问题。为了确定人工智能在自动驾驶功能方面带来的挑战和机遇，我们分析了自动驾驶的现状，概述了局限性，并确定了可预见的技术可能性。因此，在未来发展的背景下审查了各种进一步的挑战。通过这种方式，本文重新思考了人工智能领域的自动驾驶进展，并提出了各自的需求和由此产生的研究问题。

- **2026-01-30** **A Serverless Edge-Native Data Processing Architecture for Autonomous Driving Training** [2601.22919](http://arxiv.org/abs/2601.22919)
  > 数据既是自动驾驶机器学习的关键推动因素，也是主要瓶颈。有效的模型训练不仅需要大量的传感器数据，还需要平衡的覆盖范围，其中包括罕见但安全关键的场景。捕捉此类事件需要大量的驾驶时间和高效的选择。本文介绍了 Lambda 框架，这是一个边缘原生平台，可通过用户定义的函数实现车载数据过滤和处理。该框架提供了一个受无服务器启发的抽象层，它将应用程序逻辑与低级执行问题（例如调度、部署和隔离）分开。通过将功能即服务 (FaaS) 原则应用于资源受限的汽车环境，它允许开发人员实现模块化、事件驱动的过滤算法，同时保持与 ROS 2 和现有数据记录管道的兼容性。我们在 NVIDIA Jetson Orin Nano 上评估该框架，并将其与本机 ROS 2 部署进行比较。结果显示了具有竞争力的性能，减少了延迟和抖动，并证实基于 lambda 的抽象可以支持嵌入式自动驾驶系统中的实时数据处理。源代码可在 https://github.com/LASFAS/jblambda 获取。

- **2026-01-30** **When Anomalies Depend on Context: Learning Conditional Compatibility for Anomaly Detection** [2601.22868](http://arxiv.org/abs/2601.22868)
  > 异常检测通常是在以下假设下制定的：异常是观察的固有属性，与上下文无关。这种假设在许多现实世界中都站不住脚，其中相同的物体或动作可能是正常的或异常的，具体取决于潜在的上下文因素（例如，在跑道上跑步还是在高速公路上跑步）。我们重新审视\emph{上下文异常检测}，经典地定义为上下文相关的异常，并将其在视觉领域中操作，其中异常标签取决于主题上下文兼容性而不是内在外观。为了能够系统地研究这种设置，我们引入了 CAAD-3K，这是一种通过在改变上下文时控制受试者身份来隔离上下文异常的基准。我们进一步提出了一种条件兼容性学习框架，该框架利用视觉-语言表示来在有限监督下对主题-上下文关系进行建模。我们的方法大大优于 CAAD-3K 上的现有方法，并在 MVTec-AD 和 VisA 上实现了最先进的性能，这表明上下文依赖建模可以补充传统的结构异常检测。我们的代码和数据集将公开发布。

- **2026-01-30** **AutoMerge: Search-Based Model Merging Framework for Effective Model Reuse** [2601.22748](http://arxiv.org/abs/2601.22748)
  > 软件重用长期以来一直被认为是软件工程中一个关键且广泛研究的主题，它在降低开发成本、提高软件质量和提高运营效率方面提供了巨大的好处。这种范式通过模型重用扩展到深度学习。最近，模型合并作为一种免训练方法出现在大型语言模型 (LLM) 领域，该方法采用与源模型具有相同架构的多个特定于任务的模型，并将它们合并而无需重新训练，从而增强了 LLM 内的模型重用。然而，之前的工作还没有系统地研究这种方法是否可以有效地应用于跨领域具有不同架构的其他深度学习模型。为了弥补这一差距，我们提出了第一个系统研究，评估了跨三个领域的三种不同模型架构的五种模型合并技术：法学硕士、图像分类和自动驾驶。我们的研究结果表明，直接应用现有的模型合并技术会导致高度不一致的结果，并且明显低于法学硕士的成功率。此外，单一模型合并技术通常无法处理模型内的异构结构属性，限制了其跨领域不同模型架构的适用性。此外，模型合并技术的有效性对超参数配置高度敏感，从而限制了其更广泛采用的潜力。受这些见解的启发，我们提出了 AutoMerge，一种新颖的基于搜索的模型合并框架，它首先将复杂模型分割成多个异构块，然后系统地探索合并空间以识别合并技术及其超参数配置。

- **2026-01-29** **DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation** [2601.22153](http://arxiv.org/abs/2601.22153)
  > 操纵动态对象仍然是视觉-语言-动作（VLA）模型的一个开放挑战，尽管静态操纵具有很强的泛化性，但在需要快速感知、时间预测和连续控制的动态场景中却表现不佳。我们提出了 DynamicVLA，一个动态对象操作框架，通过三个关键设计集成了时间推理和闭环自适应：1）紧凑的 0.4B VLA，使用卷积视觉编码器进行空间高效、结构忠实的编码，从而实现快速多模态推理； 2）连续推理，实现重叠推理和执行，以降低延迟并及时适应对象运动； 3）潜在感知动作流，通过强制时间对齐的动作执行来弥合感知与执行之间的差距。为了填补动态操作数据的缺失基础，我们引入了动态对象操作 (DOM) 基准，该基准从头开始构建，具有自动数据收集管道，可有效收集 2.8K 场景和 206 个对象的 200K 合成片段，并无需远程操作即可快速收集 2K 真实世界片段。广泛的评估证明了响应速度、感知和泛化方面的显着改进，将 DynamicVLA 定位为跨实施例的通用动态对象操作的统一框架。

- **2026-01-29** **DynaWeb: Model-Based Reinforcement Learning of Web Agents** [2601.22149](http://arxiv.org/abs/2601.22149)
  > 由大型语言模型 (LLM) 和强化学习 (RL) 提供支持的自主网络代理的开发代表了向通用人工智能助手迈出的重要一步。然而，与实时互联网交互的挑战严重阻碍了这些智能体的培训，这些挑战效率低下、成本高昂且充满风险。基于模型的强化学习（MBRL）通过学习环境的世界模型来实现模拟交互，提供了一种有前景的解决方案。本文介绍了 DynaWeb，这是一种新颖的 MBRL 框架，它通过与网络世界模型交互来训练网络代理，该模型经过训练可以预测给定代理动作的自然网页表示。该模型充当合成网络环境，代理策略可以通过生成大量的滚动动作轨迹来实现高效的在线强化学习。除了免费的策略推出之外，DynaWeb 还结合了来自训练数据的真实专家轨迹，这些轨迹在训练期间与策略推出随机交织，以提高稳定性和样本效率。在具有挑战性的 WebArena 和 WebVoyager 基准测试上进行的实验表明，DynaWeb 始终如一地显着提高了最先进的开源 Web 代理模型的性能。我们的研究结果证实了通过想象力训练网络代理的可行性，提供了一种可扩展且有效的方法来扩展在线代理强化学习。

- **2026-01-29** **World of Workflows: a Benchmark for Bringing World Models to Enterprise Systems** [2601.22130](http://arxiv.org/abs/2601.22130)
  > 前沿大语言模型（LLM）在许多领域都作为自主代理表现出色，但它们在复杂的企业系统中尚未经过测试，在复杂的企业系统中，隐藏的工作流程会在互连的数据库之间产生级联效应。现有的企业基准评估与一般消费者基准类似的表面级代理任务完成情况，忽略了企业中的真正挑战，例如有限的可观察性、大型数据库状态以及具有级联副作用的隐藏工作流程。我们引入了 World of Workflows (WoW)，这是一个基于 ServiceNow 的现实环境，包含系统中嵌入的 4,000 多个业务规则和 55 个活动工作流，以及 WoW-bench，这是一个包含 234 个任务的基准，用于评估受限代理任务完成和企业动态建模功能。我们揭示了两个主要结论：（1）前沿法学硕士遭受动态失明，始终无法预测其行为的不可见的级联副作用，从而导致无声约束违规，以及（2）不透明系统的可靠性需要扎根的世界建模，其中代理必须在心理上模拟隐藏状态转换，以在高保真反馈不可用时弥合可观察性差距。对于可靠且有用的企业代理，WoW 激发了一种新的范式来明确地学习系统动力学。我们发布了用于设置和评估 WoW 的 GitHub。

- **2026-01-29** **The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR** [2601.22128](http://arxiv.org/abs/2601.22128)
  > 通过下一个单词预测训练的大型语言模型 (LLM) 作为临床基础模型取得了成功。这些语言主干的表示在生物医学任务中产生了强大的线性探测性能，这表明患者语义是从大规模的下一个标记预测中产生的。然而，这种范式将患者视为要总结的文档，而不是要模拟的动力系统；患者的轨迹是在干预和时间的作用下从其状态演变而来的，需要模拟动态而不是预测标记的模型。为了解决这个问题，我们引入了 SMB-Structure，这是一种结构化 EHR 的世界模型，它以联合嵌入预测架构 (JEPA) 和下一个令牌预测 (SFT) 为基础。 SFT 使我们的模型能够在令牌空间中重建未来的患者状态，而 JEPA 仅根据初始患者表示来预测潜在空间中的未来，从而迫使在观察下一个状态之前对轨迹动态进行编码。我们在两个大型队列中进行了验证：Memorial Sloan Kettering（23,319 名肿瘤患者；超过 323,000 名患者年）和 INSPECT（19,402 名肺栓塞患者）。使用在疾病轨迹上的多个点进行评估的线性探针，我们证明了我们的训练范例学习了嵌入，这些嵌入捕获了自回归基线无法恢复的疾病动态，使 SMB-Structure 能够在以患者高度异质性为特征的复杂任务上实现有竞争力的表现。模型权重可在 https://huggingface.co/standardmodelbio/SMB-v1-1.7B-Structure 上获取。

- **2026-01-29** **Learning Transient Convective Heat Transfer with Geometry Aware World Models** [2601.22086](http://arxiv.org/abs/2601.22086)
  > 偏微分方程 (PDE) 模拟是工程和物理学的基础，但对于实时应用来说，计算量往往过高。虽然生成式人工智能为代理建模提供了一种有前景的途径，但标准视频生成架构缺乏物理模拟所需的特定控制和数据兼容性。本文介绍了一种几何感知世界模型架构，该架构源自视频生成架构（LongVideoGAN），旨在学习瞬态物理。我们引入了两个关键的架构元素：（1）结合全局物理参数和局部几何掩模的双重调节机制，以及（2）支持任意通道尺寸的架构适应，超越标准 RGB 约束。我们在二维瞬态计算流体动力学 (CFD) 问题上评估了这种方法，该问题涉及浮力驱动流与固体结构中热流耦合的对流换热。我们证明，条件模型成功地再现了训练数据的复杂时间动态和空间相关性。此外，我们评估了模型对未见过的几何配置的泛化能力，强调了其受控模拟合成的潜力以及当前分布外样本空间精度的限制。

- **2026-01-29** **MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources** [2601.22054](http://arxiv.org/abs/2601.22054)
  > 缩放推动了视觉基础模型的最新进展，但由于异构传感器噪声、相机相关偏差以及嘈杂的跨源 3D 数据中的度量模糊性，将这种范式扩展到度量深度估计仍然具有挑战性。我们推出了 Metric Anything，这是一个简单且可扩展的预训练框架，可以从嘈杂、多样化的 3D 源中学习度量深度，而无需手动设计提示、特定于相机的建模或特定于任务的架构。我们方法的核心是稀疏度量提示，它是通过随机屏蔽深度图创建的，它作为一个通用接口，将空间推理与传感器和相机偏差分离。使用跨越 10000 个相机模型重建、捕获和渲染 3D 数据的约 2000 万个图像深度对，我们首次展示了公制深度轨道中清晰的缩放趋势。预训练模型擅长提示驱动任务，例如深度完成、超分辨率和雷达相机融合，而其精炼的无提示学生在单目深度估计、相机内在恢复、单/多视图度量 3D 重建和 VLA 规划方面取得了最先进的结果。我们还表明，使用 Metric Anything 的预训练 ViT 作为视觉编码器可以显着增强空间智能中的多模态大语言模型能力。这些结果表明，度量深度估计可以受益于驱动现代基础模型的相同缩放法则，从而建立一条通向可扩展且高效的现实世界度量感知的新路径。我们在 http://metric-anything.github.io/metric-anything-io/ 上开源了 MetricAnything 以支持社区研究。

- **2026-01-29** **Emergent Spatial Textures from Interaction Quenches in the Hubbard Model** [2601.22053](http://arxiv.org/abs/2601.22053)
  > 强相关电子系统中的相互作用猝灭为探测非平衡多体动力学提供了强有力的途径。对于哈伯德模型，非平衡动态平均场理论揭示了相干的淬火后振荡、动态交叉和长寿命瞬态状态。然而，这些研究很大程度上局限于空间均匀动力学，因此忽略了超快演化过程中空间结构形成的作用。在这里，我们使用真实空间时间相关的 Gutzwiller 框架研究半填充 Hubbard 模型中的相互作用猝灭。我们证明，齐次非平衡动力学通常是不稳定的：即使是任意微弱的空间涨落也会动态增长，并驱动系统走向本质上不齐次的状态。根据相互作用的强度，淬火后的演化表现出空间分化、成核和类莫特域的缓慢粗化。我们的结果将空间自组织确立为远离平衡相关物质的一般特征，并揭示了空间均匀非平衡理论的基本局限性。

- **2026-01-29** **Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving** [2601.22032](http://arxiv.org/abs/2601.22032)
  > 端到端自动驾驶越来越多地利用自监督视频预训练来学习可转移的规划表示。然而，迄今为止，用于场景理解的预训练视频世界模型只带来了有限的改进。这种限制因驾驶固有的模糊性而变得更加复杂：每个场景通常只提供单个人类轨迹，使得学习多模式行为变得困难。在这项工作中，我们提出了 Drive-JEPA，这是一个将视频联合嵌入预测架构（V-JEPA）与多模态轨迹蒸馏相集成的框架，用于端到端驾驶。首先，我们将 V-JEPA 用于端到端驾驶，在大规模驾驶视频上预训练 ViT 编码器，以生成与轨迹规划一致的预测表示。其次，我们引入了一个以提案为中心的规划器，它可以提取模拟器生成的各种轨迹以及人类轨迹，并具有动量感知选择机制来促进稳定和安全的行为。在 NAVSIM 上进行评估时，V-JEPA 表示形式与简单的基于变压器的解码器相结合，在无感知设置中的性能比先前方法高出 3 PDMS。完整的 Drive-JEPA 框架在 v1 上实现了 93.3 PDMS，在 v2 上实现了 87.8 EPDMS，创下了新的最先进水平。

- **2026-01-29** **Causal World Modeling for Robot Control** [2601.21998](http://arxiv.org/abs/2601.21998)
  > 这项工作强调了视频世界建模以及视觉语言预训练为机器人学习奠定了全新且独立的基础。直观地说，视频世界模型提供了通过理解动作和视觉动态之间的因果关系来想象不久的将来的能力。受此启发，我们引入了 LingBot-VA，一种同时学习帧预测和策略执行的自回归扩散框架。我们的模型具有三种精心设计的设计：(1) 共享潜在空间，集成视觉和动作令牌，由混合变压器 (MoT) 架构驱动；(2) 闭环推出机制，允许通过地面实况观察持续获取环境反馈；(3) 异步推理管道，并行动作预测和电机执行以支持高效控制。我们在模拟基准和现实场景中评估我们的模型，它在长期操作、训练后的数据效率以及对新颖配置的强大通用性方面显示出巨大的前景。代码和模型是公开的，以方便社区。

- **2026-01-29** **MoE-ACT: Improving Surgical Imitation Learning Policies through Supervised Mixture-of-Experts** [2601.21971](http://arxiv.org/abs/2601.21971)
  > 模仿学习在机器人操作方面取得了显着的成功，但由于数据稀缺、工作空间有限以及对卓越安全性和可预测性的需求，其在手术机器人中的应用仍然具有挑战性。我们提出了一种有监督的专家混合（MoE）架构，专为阶段结构的手术操作任务而设计，可以添加到任何自主策略之上。与之前依赖于多摄像头设置或数千次演示的手术机器人学习方法不同，我们证明，当配备我们的架构时，像动作分块变压器（ACT）这样的轻量级动作解码器策略可以从不到 150 个仅使用立体内窥镜图像的演示中学习复杂的长视野操作。我们评估了我们在肠道抓取和回缩协作手术任务上的方法，其中机器人助手解释人类外科医生的视觉提示，对可变形组织进行有针对性的抓取，并执行持续回缩。我们将我们的方法与最先进的视觉-语言-行动 (VLA) 模型和标准 ACT 基线进行基准测试。我们的结果表明，即使在标准分布条件下，通才 VLA 也无法完全完成任务。此外，虽然标准 ACT 在分布中取得了一定的成功，但采用有监督的 MoE 架构显着提高了其性能，在分布中产生更高的成功率，并在分布外场景中表现出卓越的鲁棒性，包括新颖的抓取位置、减少的照明和部分遮挡。值得注意的是，它推广到了看不见的测试观点，并且无需额外训练即可将零样本转移到离体猪组织，为体内部署提供了一条有希望的途径。为了支持这一点，我们提出了猪体内手术期间政策推出的定性初步结果。


[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

