---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.05.01
> Usage instructions: [here](./docs/README.md#usage)

## Video Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-29**|**TesserAct: Learning 4D Embodied World Models**|本文提出了一种学习新的4D实体世界模型的有效方法，该模型预测了3D场景随时间的动态演变，以响应实体代理的动作，提供了空间和时间的一致性。我们建议通过RGB-DN（RGB、深度和法线）视频训练来学习4D世界模型。这不仅超越了传统的2D模型，将详细的形状、配置和时间变化纳入其预测中，而且使我们能够有效地学习具体代理的精确逆动态模型。具体来说，我们首先利用现成的模型，利用深度和正常信息扩展现有的机器人操纵视频数据集。接下来，我们在此带注释的数据集上微调视频生成模型，该模型联合预测每帧的RGB-DN（RGB、深度和法线）。然后，我们提出了一种算法，可以将生成的RGB、深度和法线视频直接转换为高质量的4D世界场景。我们的方法确保了来自具体场景的4D场景预测的时间和空间一致性，为具体环境实现了新颖的视图合成，并促进了策略学习，其性能明显优于先前基于视频的世界模型。 et.al.|[2504.20995](http://arxiv.org/abs/2504.20995)|null|
|**2025-04-29**|**DDPS: Discrete Diffusion Posterior Sampling for Paths in Layered Graphs**|扩散模型构成了当今生成模型的一个重要类别，在尖端人工智能研究中占据了很大一部分。虽然存在许多超出图像和视频生成的扩展，但很少有这样的方法解决所生成样本中的显式约束问题。在本文中，我们研究了使用离散扩散模型在分层图（有向无环图的变体）中生成路径的问题，同时保证我们生成的样本确实是路径。我们的方法利用了一种简单而有效的路径表示，我们称之为填充邻接表矩阵（PALM）。此外，我们展示了如何有效地执行分类器引导，这有助于将采样路径引导到特定的首选边，而无需对扩散模型进行任何重新训练。我们的初步结果表明，从经验上讲，我们的方法优于没有明确考虑路径约束的替代方案。 et.al.|[2504.20754](http://arxiv.org/abs/2504.20754)|null|
|**2025-04-29**|**Advance Fake Video Detection via Vision Transformers**|基于人工智能的多媒体生成的最新进展使人们能够创建超逼真的图像和视频，这引发了人们对它们在传播错误信息方面的潜在用途的担忧。生成技术的广泛可及性，允许从提示或现有媒体中制作虚假多媒体，以及对其的不断改进，突显了对高度准确和通用的人工智能生成媒体检测方法的迫切需求，欧洲数字人工智能法案等新法规也强调了这一点。本文从基于视觉变换器（ViT）的假图像检测中汲取灵感，并将这一思想扩展到视频中。我们提出了一个｛原创｝%的创新框架，随着时间的推移，该框架有效地集成了ViT嵌入，以提高检测性能。我们的方法在使用最先进的五种开源生成技术生成的新的、大型和多样化的视频数据集以及包含专有生成方法生成的视频的单独数据集上显示出有前景的准确性、通用性和少量镜头学习能力。 et.al.|[2504.20669](http://arxiv.org/abs/2504.20669)|null|
|**2025-04-28**|**DiVE: Efficient Multi-View Driving Scenes Generation Based on Video Diffusion Transformer**|收集多视图驾驶场景视频以提高3D视觉感知任务的性能带来了重大挑战，并带来了巨大的成本，使生成真实数据的模型成为一种有吸引力的替代方案。然而，最近作品生成的视频质量和时空一致性较差，削弱了它们在驾驶场景下推进感知任务的效用。为了解决这一差距，我们提出了DiVE，这是一种基于扩散变换器的生成框架，经过精心设计，可以生成高保真、时间连贯和跨视图一致的多视图视频，与鸟瞰布局和文本描述无缝对齐。DiVE利用统一的交叉注意力和SketchFormer对多模态数据进行精确控制，同时结合了一种不添加额外参数的视图膨胀注意力机制，从而保证了视图之间的一致性。尽管取得了这些进步，但在多模态约束下合成高分辨率视频带来了双重挑战：在复杂的多条件输入下研究最佳的无分类器制导配置，以及减轻高分辨率渲染中的过度计算延迟——这两者在先前的研究中都没有得到充分的探索。为了解决这些局限性，我们引入了两项创新：多控制辅助分支蒸馏，它简化了多条件CFG选择，同时避免了高计算开销，以及分辨率渐进采样，这是一种无需训练的加速策略，可以错开分辨率缩放，以减少高分辨率带来的高延迟。这些创新共同实现了2.62倍的加速，同时将质量下降降到最低。在nuScenes数据集上进行评估后，DiVE在多视图视频生成中实现了SOTA性能，产生了具有出色时间和跨视图连贯性的逼真输出。 et.al.|[2504.19614](http://arxiv.org/abs/2504.19614)|null|
|**2025-04-29**|**IM-Portrait: Learning 3D-aware Video Diffusion for Photorealistic Talking Heads from Monocular Videos**|我们提出了一种新的基于3D感知扩散的方法，用于直接从单个身份图像和显式控制信号（例如表情）生成逼真的说话头视频。我们的方法生成多平面图像（MPIs），确保几何一致性，使其成为沉浸式观看体验的理想选择，如VR耳机的双目视频。与通常需要单独阶段或联合优化来重建3D表示（如NeRF或3D高斯）的现有方法不同，我们的方法通过一个去噪过程直接生成最终输出，消除了对后处理步骤的需求，从而有效地渲染新视图。为了有效地从单眼视频中学习，我们引入了一种训练机制，在目标或参考相机空间中随机重建输出MPI。这种方法使模型能够同时学习清晰的图像细节和底层的3D信息。大量实验证明了我们的方法的有效性，即使没有明确的3D重建或高质量的多视图训练数据，该方法也能实现具有竞争力的化身质量和新颖的视图渲染能力。 et.al.|[2504.19165](http://arxiv.org/abs/2504.19165)|null|
|**2025-04-26**|**Audio-Driven Talking Face Video Generation with Joint Uncertainty Learning**|在数字人类技术领域，生成具有任意语音音频的人脸视频是一个重大挑战。之前的研究强调了音频嘴唇同步和视觉质量的重要性。目前，对视觉不确定性的学习关注有限，这在现有系统中造成了几个问题，包括不同输入条件下的视觉质量不一致和性能不可靠。为了解决这个问题，我们提出了一种用于高质量说话面部视频生成的联合不确定性学习网络（JULNet），该网络结合了与视觉误差直接相关的不确定性表示。具体来说，我们首先设计一个不确定性模块，在获得生成的图像后分别预测误差图和不确定性图。误差图表示生成的图像和地面真实图像之间的差异，而不确定性图用于预测不正确估计的概率。此外，为了通过KL散度项将不确定性分布与误差分布相匹配，我们引入了一种直方图技术来近似分布。通过联合优化误差和不确定性，可以提高我们模型的性能和鲁棒性。大量实验表明，与之前的方法相比，我们的方法在说话人脸视频生成中实现了更高的高保真度和音频唇形同步。 et.al.|[2504.18810](http://arxiv.org/abs/2504.18810)|null|
|**2025-04-26**|**Stealing Creator's Workflow: A Creator-Inspired Agentic Framework with Iterative Feedback Loop for Improved Scientific Short-form Generation**|由于内容的复杂性以及专家作者和读者之间的差距，从科学论文中生成引人入胜、准确的短视频具有挑战性。现有的端到端方法往往存在事实不准确和视觉伪影，限制了它们在科学传播中的实用性。为了解决这些问题，我们提出了SciTalk，这是一个新颖的多LLM代理框架，将视频基于各种来源，如文本、图形、视觉风格和化身。受内容创作者工作流程的启发，SciTalk使用专门的代理进行内容摘要、视觉场景规划以及文本和布局编辑，并结合了一种迭代反馈机制，在该机制中，视频代理模拟用户角色，对之前迭代生成的视频提供反馈，并完善生成提示。实验评估表明，在视频生成的精细循环中，SciTalk在生成科学准确和引人入胜的内容方面优于简单的提示方法。尽管初步结果尚未与人类创作者的质量相匹配，但我们的框架为反馈驱动的视频生成的挑战和益处提供了宝贵的见解。我们的代码、数据和生成的视频将公开。 et.al.|[2504.18805](http://arxiv.org/abs/2504.18805)|null|
|**2025-04-25**|**NoiseController: Towards Consistent Multi-view Video Generation via Noise Decomposition and Collaboration**|高质量的视频生成对许多领域至关重要，包括电影业和自动驾驶。然而，生成具有时空一致性的视频仍然具有挑战性。当前的方法通常利用注意力机制或修改噪声来实现一致的视频，忽略了有助于确保视频生成过程中空间和时间一致性的全局时空信息。本文提出了由多级噪声分解、多帧噪声协作和联合去噪组成的噪声控制器，以提高视频生成中的时空一致性。在多级噪声分解中，我们首先将初始噪声分解为场景级前景/背景噪声，捕捉不同的运动特性来模拟多视图前景/背景变化。此外，每个场景级噪声被进一步分解为单独的共享级和残差级分量。共享噪声保持一致性，而残差分量保持多样性。在多帧噪声协作中，我们引入了视点间时空协作矩阵和视点内影响协作矩阵，该矩阵捕获了相互的跨视点效果和历史跨帧影响，以提高视频质量。联合去噪包含两个并行的去噪U-Net，用于去除每个场景级的噪声，相互增强视频生成。我们在公共数据集上评估了NoiseController，重点关注视频生成和下游任务，展示了其最先进的性能。 et.al.|[2504.18448](http://arxiv.org/abs/2504.18448)|null|
|**2025-04-24**|**Dynamic Camera Poses and Where to Find Them**|在动态互联网视频上按比例注释相机姿势对于推进逼真视频生成和模拟等领域至关重要。然而，收集这样的数据集是困难的，因为大多数互联网视频都不适合姿势估计。此外，即使对于最先进的方法来说，注释动态互联网视频也带来了重大挑战。本文介绍了DynPose-100K，这是一个用相机姿态注释的动态互联网视频的大规模数据集。我们的收集管道使用一组精心组合的任务特定和通用模型来解决过滤问题。对于姿态估计，我们结合了点跟踪、动态掩蔽和运动结构的最新技术，以实现对最先进方法的改进。我们的分析和实验表明，DynPose-100K在几个关键属性上既大规模又多样化，为各种下游应用的进步开辟了道路。 et.al.|[2504.17788](http://arxiv.org/abs/2504.17788)|null|
|**2025-04-24**|**MV-Crafter: An Intelligent System for Music-guided Video Generation**|音乐视频作为一种流行的多媒体娱乐形式，为观众提供引人入胜的视听体验，在歌手和粉丝中广受欢迎。创作者可以通过视觉元素自然地表达他们对音乐的诠释。然而，音乐视频的创作过程需要熟练掌握脚本设计、视频拍摄和音乐视频同步，这对非专业人士来说是一个重大挑战。之前的工作设计了自动音乐视频生成框架。然而，它们的输入复杂，输出质量差。作为回应，我们推出了MV Crafter，这是一个能够制作具有同步音乐视频节奏和风格的高质量音乐视频的系统。我们的方法涉及三个模拟人类创作过程的技术模块：脚本生成模块、视频生成模块和音乐视频同步模块。MV Crafter利用大型语言模型生成考虑音乐语义的脚本。为了解决短视频片段与不同长度音乐同步的挑战，我们提出了一种动态节拍匹配算法和视觉包络诱导扭曲方法，以确保精确、单调的音乐视频同步。此外，我们设计了一个用户友好的界面，通过直观的编辑功能简化了创建过程。大量实验表明，MV Crafter为提高生成的音乐视频的质量提供了一种有效的解决方案。 et.al.|[2504.17267](http://arxiv.org/abs/2504.17267)|null|

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-29**|**TesserAct: Learning 4D Embodied World Models**|本文提出了一种学习新的4D实体世界模型的有效方法，该模型预测了3D场景随时间的动态演变，以响应实体代理的动作，提供了空间和时间的一致性。我们建议通过RGB-DN（RGB、深度和法线）视频训练来学习4D世界模型。这不仅超越了传统的2D模型，将详细的形状、配置和时间变化纳入其预测中，而且使我们能够有效地学习具体代理的精确逆动态模型。具体来说，我们首先利用现成的模型，利用深度和正常信息扩展现有的机器人操纵视频数据集。接下来，我们在此带注释的数据集上微调视频生成模型，该模型联合预测每帧的RGB-DN（RGB、深度和法线）。然后，我们提出了一种算法，可以将生成的RGB、深度和法线视频直接转换为高质量的4D世界场景。我们的方法确保了来自具体场景的4D场景预测的时间和空间一致性，为具体环境实现了新颖的视图合成，并促进了策略学习，其性能明显优于先前基于视频的世界模型。 et.al.|[2504.20995](http://arxiv.org/abs/2504.20995)|null|
|**2025-04-29**|**GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for Targeted Scene Confusion**|随着3D高斯散斑（3DGS）作为场景表示和新颖视图合成的突破，其在安全关键领域（如自主系统、AR/VR）的快速采用迫切需要对潜在的安全漏洞进行审查。本文首次对3DGS管道中的后门威胁进行了系统研究。我们发现，对手可能会植入后门视图，在推理过程中引发恶意场景混淆，这可能会导致自主导航中的环境误解或沉浸式环境中的空间失真。为了发现这种风险，我们提出了GuassTrap，这是一种针对3DGS模型的新型中毒攻击方法。GuassTrap在特定的攻击视点注入恶意视图，同时在非目标视图中保持高质量的渲染，确保最小的可检测性并最大限度地提高潜在危害。具体来说，所提出的方法包括一个三阶段管道（攻击、稳定和正常训练），在3DGS中植入隐形、视点一致的有毒渲染，共同优化攻击效果和感知真实性，以暴露3D渲染中的安全风险。在合成和现实世界数据集上的广泛实验表明，GuassTrap可以有效地嵌入不可察觉但有害的后门视图，同时在正常视图中保持高质量的渲染，验证了其鲁棒性、适应性和实际适用性。 et.al.|[2504.20829](http://arxiv.org/abs/2504.20829)|null|
|**2025-04-29**|**EfficientHuman: Efficient Training and Reconstruction of Moving Human using Articulated 2D Gaussian**|3D高斯散斑（3DGS）已被公认为场景重建和新颖视图合成的开创性技术。最近使用3DGS重建3D人体的工作试图利用人体姿势的先验信息来提高渲染质量并提高训练速度。然而，由于多视图不一致和冗余的高斯分布，它很难有效地拟合动态曲面平面。这种不一致性是因为高斯椭球体不能准确地表示动态物体的表面，这阻碍了动态人体的快速重建。同时，冗余高斯分布的普遍性意味着这些作品的训练时间对于快速适应动态人体来说仍然不理想。为了解决这些问题，我们提出了EfficientHuman，这是一种使用铰接2D高斯快速完成人体动态重建的模型，同时确保了高渲染质量。关键创新在于将高斯斑点编码为规范空间中的铰接二维高斯曲面，然后通过线性混合蒙皮（LBS）将其转换为姿态空间，以实现高效的姿态转换。与3D高斯曲面不同，铰接式2D高斯曲面可以快速适应动态人体，同时确保视图一致的几何形状。此外，我们引入了一个姿态校准模块和一个LBS优化模块，以实现动态人体姿态的精确拟合，提高模型的性能。在ZJU MoCap数据集上进行的广泛实验表明，EfficientHuman平均在不到一分钟的时间内实现了快速的3D动态人体重建，比目前最先进的方法快20秒，同时也减少了冗余高斯的数量。 et.al.|[2504.20607](http://arxiv.org/abs/2504.20607)|null|
|**2025-04-28**|**Joint Optimization of Neural Radiance Fields and Continuous Camera Motion from a Monocular Video**|神经辐射场（NeRF）已经证明了其表示3D几何的优越能力，但在训练过程中需要精确地预先计算相机姿态。为了降低这一要求，现有的方法通常依赖于良好的姿态初始化或深度先验来联合优化相机姿态和NeRF。然而，这些方法在具有挑战性的场景中很难实现，例如大旋转，因为它们将每个相机映射到世界坐标系。我们提出了一种新方法，通过将连续相机运动建模为随时间变化的角速度和速度来消除先验依赖性。相机之间的相对运动首先通过速度积分来学习，而相机姿态可以通过将这些相对运动聚合到视频中单个时间步长定义的世界坐标系来获得。具体来说，通过时间依赖的NeRF学习精确的连续相机运动，该NeRF通过在每个时间步长从相邻帧进行训练来捕获局部场景几何形状和运动。学习到的运动能够微调NeRF以表示整个场景几何体。在Co3D和Scannet上的实验表明，与最先进的方法相比，我们的方法实现了卓越的相机姿态和深度估计，以及相当新颖的视图合成性能。我们的代码可在https://github.com/HoangChuongNguyen/cope-nerf. et.al.|[2504.19819](http://arxiv.org/abs/2504.19819)|null|
|**2025-04-28**|**CE-NPBG: Connectivity Enhanced Neural Point-Based Graphics for Novel View Synthesis in Autonomous Driving Scenes**|当前的基于点的方法在使用大型3D点云地图时遇到了可扩展性和渲染质量方面的限制，因为直接将它们用于新颖的视图合成（NVS）会导致可视化效果下降。我们发现这些低质量渲染背后的主要问题是几何体和外观之间的可见性不匹配，这是由于同时使用这两种模式造成的。为了解决这个问题，我们提出了CE-NPBG，这是一种在大规模自动驾驶场景中进行新颖视图合成（NVS）的新方法。我们的方法是一种基于神经点的技术，它利用了两种模态：姿态图像（相机）和同步的原始3D点云（LiDAR）。我们首先使用外观和几何体之间的连接关系图，该图从当前相机视角观察到的大型3D点云图中检索点，并将其用于渲染。通过利用这种连接，我们的方法仅使用大型3D点云图中的一小部分点，显著提高了渲染质量，增强了运行时间和可扩展性。我们的方法将神经描述符与点相关联，并使用它们来合成视图。为了增强这些描述符的编码并提高渲染质量，我们提出了一种联合对抗和点光栅化训练。在训练过程中，我们将图像合成器网络与多分辨率鉴别器配对。在推理时，我们将它们解耦，并使用图像合成器生成新的视图。我们还将我们的提案整合到最近的3D高斯散斑工作中，以突出其在改进渲染和可扩展性方面的优势。 et.al.|[2504.19557](http://arxiv.org/abs/2504.19557)|null|
|**2025-04-27**|**Rendering Anywhere You See: Renderability Field-guided Gaussian Splatting**|场景视图合成从有限的视角生成新颖的视图，对于虚拟现实、增强现实和机器人等应用越来越重要。与基于对象的任务（如生成汽车的360度视图）不同，场景视图合成可以处理整个环境，在这些环境中，非均匀的观察对稳定的渲染质量提出了独特的挑战。为了解决这个问题，我们提出了一种新的方法：可渲染性场引导高斯溅射（RF-GS）。该方法通过可渲染性域量化输入的不均匀性，引导伪视图采样以增强视觉一致性。为了确保宽基线伪视图的质量，我们训练了一个图像恢复模型，将点投影映射到可见光样式。此外，我们验证的混合数据优化策略有效地融合了伪视角和源视图纹理的信息。对模拟和真实数据的比较实验表明，我们的方法在渲染稳定性方面优于现有方法。 et.al.|[2504.19261](http://arxiv.org/abs/2504.19261)|null|
|**2025-04-26**|**TransparentGS: Fast Inverse Rendering of Transparent Objects with Gaussians**|基于神经和高斯的辐射场方法的出现，在新颖的视图合成和3D对象重建方面取得了长足的进步。尽管如此，由于辐射场对高频光变化的不稳定性和不正确的过拟合，镜面反射和折射仍然构成重大挑战。目前，即使是3D高斯散斑（3D-GS）作为一种强大而高效的工具，由于存在明显的二次射线效应，在恢复具有附近内容的透明物体方面也存在不足。为了解决这个问题，我们提出了TransparentGS，这是一种基于3D-GS的透明对象快速逆渲染管道。主要贡献有三方面。首先，设计了一种透明对象的有效表示，即透明高斯基元，通过延迟折射策略实现镜面折射。其次，我们利用高斯光场探针（GaussProbe）在统一的框架中对环境光和附近的内容进行编码。第三，提出了一种基于深度的迭代探针查询（IterQuery）算法，以减少我们基于探针的框架中的视差误差。实验证明了我们的方法在从复杂环境中恢复透明物体方面的速度和准确性，以及在计算机图形学和视觉中的几个应用。 et.al.|[2504.18768](http://arxiv.org/abs/2504.18768)|null|
|**2025-04-24**|**iVR-GS: Inverse Volume Rendering for Explorable Visualization via Editable 3D Gaussian Splatting**|在体积可视化中，用户可以通过在传递函数（TF）中指定颜色和不透明度映射或调整照明参数来交互式地探索三维数据，从而有助于对底层结构进行有意义的解释。然而，渲染大规模卷需要强大的GPU和高速内存访问来实现实时性能。虽然现有的新颖视图合成（NVS）方法以较低的硬件要求提供了更快的渲染速度，但重建场景的可见部分是固定的，并受到预设TF设置的限制，这大大限制了用户的探索。本文介绍了一种创新的NVS方法——基于高斯飞溅的逆体绘制（iVR GS），该方法在降低绘制成本的同时，还支持交互式体探索的场景编辑。具体来说，我们组合了多个与基本TF相关的iVR GS模型，覆盖不相交的可见部分，使整个体积场景可见。每个基本模型都包含一组3D可编辑高斯分布，其中每个高斯分布都是一个支持实时场景渲染和编辑的3D空间点。我们在各种体积数据集上展示了iVR GS相对于其他NVS解决方案（Plenox、CCNeRF和base 3DGS）的卓越重建质量和可组合性。该代码可在以下网址获得https://github.com/TouKaienn/iVR-GS. et.al.|[2504.17954](http://arxiv.org/abs/2504.17954)|null|
|**2025-04-24**|**CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from Casually Captured Videos**|最近，神经辐射场（NeRF）和3D高斯散斑（3DGS）等多视图图像的照片级逼真新视图合成因其卓越的性能而受到广泛关注。然而，大多数作品依赖于低动态范围（LDR）图像，这限制了更丰富场景细节的捕捉。一些先前的工作侧重于高动态范围（HDR）场景重建，通常需要在曝光时间内在固定的相机位置捕获具有不同曝光时间的多视图清晰图像，这在实践中既耗时又具有挑战性。为了获得更灵活的数据采集，我们提出了一种单阶段方法：\textbf{CasualHDRSplat}，即使在存在严重运动模糊和未知曝光时间变化的情况下，也能从随机捕获的视频中轻松、稳健地重建3D HDR场景，并启用自动曝光。\textbf{CasualHDRSplat}包含一个统一的可微分物理成像模型，该模型首先对成像过程应用连续时间轨迹约束，以便我们可以共同优化曝光时间、相机响应函数（CRF）、相机姿态和清晰的3D HDR场景。大量实验表明，我们的方法在鲁棒性和渲染质量方面优于现有方法。我们的源代码将在https://github.com/WU-CVGL/CasualHDRSplat et.al.|[2504.17728](http://arxiv.org/abs/2504.17728)|null|
|**2025-04-24**|**Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation**|我们提出了一种通过心理意象模拟在视觉语言模型（VLMs）中进行透视感知推理的框架。视角获取，即从另一个角度感知环境或情况的能力，是人类视觉理解的关键基准，对于与自主代理的环境交互和协作至关重要。尽管VLM在空间推理方面取得了进步，但最近的研究表明，现代VLM严重缺乏透视感知推理能力，并表现出强烈的自我中心解释倾向。为了弥合VLM和人类感知之间的差距，我们关注心理意象的作用，即人类通过抽象的表征来感知世界，从而促进视角的转变。受此启发，我们提出了一个名为抽象透视变化（APC）的透视感知推理框架，该框架有效地利用视觉基础模型，如对象检测、分割和方向估计，来构建场景抽象并实现透视变换。与各种VLM相比，我们在合成和真实图像基准上的实验表明，我们的框架在透视感知推理方面有了显著改进，进一步优于微调的空间推理模型和新的基于视图合成的方法。 et.al.|[2504.17207](http://arxiv.org/abs/2504.17207)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-29**|**Large-scale visual SLAM for in-the-wild videos**|从随意、狂野的视频中准确、稳健地重建3D场景，可以大大简化机器人在新环境中的部署。然而，从这种无约束视频中可靠地估计相机姿态和重建场景仍然是一个悬而未决的挑战。现有的纯视觉SLAM方法在基准数据集上表现良好，但在处理真实世界的镜头时遇到了困难，这些镜头通常表现出不受控制的运动，包括快速旋转和纯向前运动、无纹理区域和动态对象。我们分析了当前方法的局限性，并介绍了一种鲁棒的管道，旨在改进休闲视频的3D重建。我们基于最近的深度视觉里程计方法，但在几个方面提高了鲁棒性。使用运动结构从前几帧中自动恢复相机内部特性。动态对象和约束较少的区域被预测模型所掩盖。此外，我们利用单目深度估计来规范光束调整，减轻低视差情况下的误差。最后，我们将位置识别和循环闭合相结合，以减少长期漂移，并通过全局束调整来细化内部函数和姿态估计。我们在各种环境中展示了来自多个在线视频的大规模连续3D模型。相比之下，基线方法通常在几个点上产生局部不一致的结果，产生单独的片段或扭曲的地图。代替地面真实姿态数据，我们评估了重新渲染的NeRF模型的地图一致性、执行时间和视觉精度。我们提出的系统为在线发现的随意不受控制的视频的视觉重建建立了一个新的基线，在更长的野外视频序列上展示了比以前更一致的重建。 et.al.|[2504.20496](http://arxiv.org/abs/2504.20496)|null|
|**2025-04-28**|**LIRM: Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields**|我们提出了大型逆渲染模型（LIRM），这是一种变换器架构，可以在不到一秒钟的时间内联合重建具有视景相关效果的高质量形状、材料和辐射场。我们的模型基于最近的大型重建模型（LRM），实现了最先进的稀疏视图重建质量。然而，现有的LRM难以准确重建看不见的部分，也无法恢复光滑的外观或生成可由标准图形引擎使用的可重新照亮的3D内容。为了解决这些局限性，我们做出了三项关键技术贡献，以构建一个更实用的多视图3D重建框架。首先，我们引入了一个更新模型，允许我们逐步添加更多的输入视图来改进我们的重建。其次，我们提出了一种六平面神经SDF表示，以更好地恢复详细的纹理、几何和材料参数。第三，我们开发了一种新的神经定向嵌入机制来处理视图依赖效应。我们的模型在大规模形状和材料数据集上进行了训练，并采用了量身定制的从粗到细的训练方案，取得了令人信服的结果。在几何和重新照明精度方面，它与基于优化的密集视图逆渲染方法相比具有优势，同时只需要一小部分推理时间。 et.al.|[2504.20026](http://arxiv.org/abs/2504.20026)|null|
|**2025-04-28**|**Mesh-Learner: Texturing Mesh with Spherical Harmonics**|在本文中，我们提出了一个名为Mesh Learner的3D重建和渲染框架，该框架与传统的光栅化管道原生兼容。它将网格和球面谐波（SH）纹理（即填充SH系数的纹理）集成到学习过程中，以端到端地学习每个网格的视图相关辐射。通过使用一种新的插值方法在每个像素的采样点处插值周围的SH-Texels来渲染图像。相反，每个像素的梯度被反向传播到SH纹理中的相关SH纹理。Mesh Learner利用光栅化管道的图形特性（纹理采样、延迟渲染）进行渲染，这使得Mesh Learner与基于光栅化管道（如Blender）的工具和任务（如3D重建、场景渲染、机器人强化学习）自然兼容。我们的系统可以训练大量、无限的场景，因为我们只将截头锥体内的SH纹理传输到GPU进行训练。在其他时候，SH纹理存储在CPU RAM中，这导致GPU内存使用率适中。与现有的最先进的方法（例如3D高斯散斑和M2映射）相比，Replica和FAST-LIVO2数据集中的插值和外推序列的渲染结果达到了最先进的性能。为了造福社会，该代码将在https://github.com/hku-mars/Mesh-Learner. et.al.|[2504.19938](http://arxiv.org/abs/2504.19938)|null|
|**2025-04-28**|**Modeling of Parallel Single-Pixel Imaging for 3D Reconstruction: New Insights and Opportunities**|智能制造和自动驾驶汽车的日益普及加剧了对复杂反射和传输条件下三维（3D）重建的需求。传统的结构光技术依赖于固有的点对点三角测量，这限制了在这些具有挑战性的场景中进行精确的3D测量。并行单像素成像（PSI）在极端条件下表现出前所未有的优越性，并已成为一种有前景的精确3D测量方法。然而，在现有的工作中，还没有一个完整的理论模型来很好地解释其潜在机制并定量表征其性能。在这项研究中，提出了PSI方法的综合理论模型，包括成像和噪声模型。所提出的成像模型描述了复杂光照下的光传输系数，阐明了使用PSI成功进行3D成像的内在机制。所开发的噪声模型定量分析了环境噪声对测量精度的影响，为指导PSI系统的误差分析提供了框架。数值模拟和实验结果验证了所提出的模型，揭示了PSI的通用性和鲁棒性。最后，强调了潜在的研究方向，以指导和激励未来的研究。建立的理论模型为PSI奠定了坚实的基础，并为未来在更苛刻的3D重建任务中的应用带来了新的见解和机遇。 et.al.|[2504.19923](http://arxiv.org/abs/2504.19923)|null|
|**2025-04-28**|**Boosting 3D Liver Shape Datasets with Diffusion Models and Implicit Neural Representations**|虽然开放式3D医学形状数据集的可用性正在增加，为研究界带来了实质性的好处，但我们发现，不幸的是，其中许多数据集都是混乱的，并且包含伪影。这些问题限制了鲁棒模型的开发和训练，特别是对于精确的3D重建任务。在这篇论文中，我们研究了现有3D肝脏形状数据集的现状，并提出了一种使用扩散模型结合隐式神经表示（INR）来增强和扩展现有数据集的解决方案。我们的方法利用扩散模型的生成能力来创建逼真、多样化的3D肝脏形状，捕捉广泛的解剖变化，并解决数据稀缺的问题。实验结果表明，我们的方法增强了数据集的多样性，提供了一种可扩展的解决方案，以提高医学应用中三维肝脏重建和生成的准确性和可靠性。最后，我们建议扩散模型也可以应用于3D医学成像中的其他下游任务。 et.al.|[2504.19402](http://arxiv.org/abs/2504.19402)|null|
|**2025-04-27**|**Beyond Physical Reach: Comparing Head- and Cane-Mounted Cameras for Last-Mile Navigation by Blind Users**|盲人在最后一英里导航中面临着持续的挑战，包括定位入口、识别障碍物以及在复杂或混乱的空间中导航。尽管可穿戴相机越来越多地用于辅助系统，但还没有系统的、以优势为中心的比较来指导它们的设计。本文通过两部分调查来解决这一差距。首先，我们调查了十位经验丰富的盲人拐杖用户，揭示了导航策略、痛点和技术偏好。与会者强调了多感官整合、以目的地为中心的旅行以及补充（而不是取代）手杖触觉效用的辅助工具的重要性。其次，我们对一名盲人参与者进行了受控数据收集，该参与者使用同步的头戴式和手杖式摄像头在五个现实世界环境中导航，将有利位置作为主要变量。为了评估每个有利位置如何支持空间感知，我们评估了SLAM性能（用于定位和映射）和基于NeRF的3D重建（用于下游场景理解）。头戴式传感器提供了卓越的定位精度，而手杖式视图提供了更广泛的地面覆盖和更丰富的环境重建。组合（头+手杖）配置始终优于两者。这些结果突出了不同传感器放置的互补优势，并为开发感知、鲁棒和用户一致的混合导航辅助工具提供了可操作的指导。 et.al.|[2504.19345](http://arxiv.org/abs/2504.19345)|null|
|**2025-04-29**|**IM-Portrait: Learning 3D-aware Video Diffusion for Photorealistic Talking Heads from Monocular Videos**|我们提出了一种新的基于3D感知扩散的方法，用于直接从单个身份图像和显式控制信号（例如表情）生成逼真的说话头视频。我们的方法生成多平面图像（MPIs），确保几何一致性，使其成为沉浸式观看体验的理想选择，如VR耳机的双目视频。与通常需要单独阶段或联合优化来重建3D表示（如NeRF或3D高斯）的现有方法不同，我们的方法通过一个去噪过程直接生成最终输出，消除了对后处理步骤的需求，从而有效地渲染新视图。为了有效地从单眼视频中学习，我们引入了一种训练机制，在目标或参考相机空间中随机重建输出MPI。这种方法使模型能够同时学习清晰的图像细节和底层的3D信息。大量实验证明了我们的方法的有效性，即使没有明确的3D重建或高质量的多视图训练数据，该方法也能实现具有竞争力的化身质量和新颖的视图渲染能力。 et.al.|[2504.19165](http://arxiv.org/abs/2504.19165)|null|
|**2025-04-26**|**Video CLIP Model for Multi-View Echocardiography Interpretation**|超声心动图包括使用超声波记录心脏的视频，使临床医生能够评估其状况。大规模视觉语言模型（VLMs）的最新进展引起了人们对超声心动图视频自动解释的关注。然而，迄今为止，大多数用于医学解释的现有VLM都依赖于单帧（即图像）输入。因此，这些基于图像的模型通常对通过心脏运动可识别的疾病表现出较低的诊断准确性。此外，超声心动图视频是从各种视图记录的，这些视图取决于超声发射的方向，某些视图比其他视图更适合解释特定的情况。合并多个视图可能会进一步提高准确性。在这项研究中，我们开发了一个视频语言模型，该模型以五个不同的视图和完整的视频序列为输入，在60747例病例的成对超声心动图视频和临床报告上对其进行训练。我们的实验表明，这种扩展的方法比仅用单视图视频或静止图像训练的模型具有更高的解释精度。 et.al.|[2504.18800](http://arxiv.org/abs/2504.18800)|null|
|**2025-04-25**|**PerfCam: Digital Twinning for Production Lines Using 3D Gaussian Splatting and Vision Models**|我们介绍了PerfCam，这是一个开源的概念验证（PoC）数字孪生框架，它将相机和感官数据与3D高斯散斑和计算机视觉模型相结合，用于工业生产线中的数字孪生、对象跟踪和关键性能指标（KPI）提取。通过利用3D重建和卷积神经网络（CNN），PerfCam提供了一种半自动的对象跟踪和空间映射方法，使数字孪生能够捕获实时KPI，如可用性、性能、整体设备效率（OEE）和生产线中传送带的速度。我们通过在制药行业现实测试生产线上的实际部署验证了PerfCam的有效性，并提供了一个公开发布的数据集，以支持该领域的进一步研究和开发。结果表明，PerfCam能够通过其精确的数字孪生功能提供可操作的见解，突显了其作为在智能制造环境中开发可用数字孪生和提取运营分析的有效工具的价值。 et.al.|[2504.18165](http://arxiv.org/abs/2504.18165)|null|
|**2025-04-24**|**Range Image-Based Implicit Neural Compression for LiDAR Point Clouds**|本文提出了一种高效压缩光探测和测距（LiDAR）点云的新方案，实现了高精度的3D场景档案，这些档案为详细了解相应的3D场景铺平了道路。我们专注于2D距离图像~（RI）作为一种轻量级的格式，用于表示3D LiDAR观测结果。尽管传统的图像压缩技术可以提高RI的压缩效率，但由于比特精度的差异以及自然图像和RI之间不同的像素值分布特征，它们的实际性能预计会受到限制。我们提出了一种新的基于隐式神经表示的RI压缩方法，可以有效地处理浮点值像素。所提出的方法将RI分为深度和掩模图像，并分别使用具有模型修剪和量化的逐块和逐像素INR架构对其进行压缩。在KITTI数据集上的实验表明，在低比特率和解码延迟下，所提出的方法在3D重建和检测质量方面优于现有的基于图像、点云、RI和INR的压缩方法。 et.al.|[2504.17229](http://arxiv.org/abs/2504.17229)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-29**|**Conformal-DP: Differential Privacy on Riemannian Manifolds via Conformal Transformation**|差异隐私（DP）已被确立为通过增加信息发布的干扰来保护私人数据共享。先前对DP的研究已经扩展到平坦欧几里德空间中的数据之外，并通过沿测地线距离添加扰动来解决弯曲流形上的数据，例如扩散张量MRI、社交网络或器官形状分析。然而，现有的流形感知DP方法依赖于样本在流形上均匀分布的假设。事实上，数据密度各不相同，导致多个区域的噪声失衡，削弱了隐私效用的权衡。为了解决这一差距，我们提出了一种新的机制：共形DP，利用黎曼流形上的共形变换来均衡局部样本密度，并相应地重新定义测地线距离，同时保持流形的内在几何形状。我们的理论分析得出了两个主要结果。首先，我们证明了根据局部核密度估计计算的共形因子是显式数据密度感知的；其次，在共形度量下，该机制在任何完全黎曼流形上满足 $\varepsilon$-微分隐私，并在预期测地线误差上承认一个闭式上界，该上界仅取决于最大密度比，而不取决于流形的全局曲率。我们的实验结果验证了该机制在为同构和特别是异构流形数据提供$\varepsilon$ -DP保证的同时实现了高实用性。 et.al.|[2504.20941](http://arxiv.org/abs/2504.20941)|null|
|**2025-04-29**|**AI-GenBench: A New Ongoing Benchmark for AI-Generated Image Detection**|生成式人工智能的快速发展彻底改变了图像创建，使文本提示能够进行高质量的合成，同时对媒体真实性提出了关键挑战。我们介绍了Ai GenBench，这是一个新的基准测试，旨在解决在现实世界场景中对人工智能生成图像进行鲁棒检测的迫切需求。与在静态数据集上评估模型的现有解决方案不同，Ai-GenBench引入了一种时间评估框架，在该框架中，检测方法在合成图像上进行增量训练，历史上按其生成模型排序，以测试其泛化到新生成模型的能力，例如从GAN到扩散模型的过渡。我们的基准侧重于高质量、多样化的视觉内容，并克服了当前方法的关键局限性，包括任意数据集分割、不公平比较和过度的计算需求。Ai GenBench为研究人员和非专家（如记者、事实核查员）提供了一个全面的数据集、一个标准化的评估方案和可访问的工具，确保了可重复性，同时保持了实际的培训要求。通过建立明确的评估规则和受控的增强策略，Ai-GenBench能够对检测方法和可扩展的解决方案进行有意义的比较。代码和数据是公开的，以确保可重复性，并支持开发强大的法医探测器，以跟上新合成发生器的兴起。 et.al.|[2504.20865](http://arxiv.org/abs/2504.20865)|null|
|**2025-04-29**|**SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings**|本文介绍了SoccerDiffusion，这是一种基于变压器的扩散模型，旨在直接从现实世界的游戏记录中学习人形机器人足球的端到端控制策略。该模型使用从RoboCup比赛中收集的数据，根据多模态传感器输入（包括视觉、本体感觉和游戏状态）预测关节指令轨迹。我们采用蒸馏技术在嵌入式平台上实现实时推理，将多步扩散过程简化为一步。我们的结果表明，该模型能够在模拟和物理机器人上复制复杂的运动行为，如行走、踢腿和跌倒恢复。尽管高级战术行为仍然有限，但这项工作为后续的强化学习或偏好优化方法提供了坚实的基础。我们在以下位置发布数据集、预训练模型和代码：https://bit-bots.github.io/SoccerDiffusion et.al.|[2504.20808](http://arxiv.org/abs/2504.20808)|null|
|**2025-04-29**|**Q-Fusion: Diffusing Quantum Circuits**|量子计算在解决社会相关和计算复杂的问题方面具有巨大的潜力。此外，量子机器学习（QML）有望快速提高我们目前的机器学习能力。然而，目前有噪声的中间尺度量子（NISQ）器件受到量子比特数量和门计数的限制，这阻碍了它们的全部功能。此外，量子算法的设计仍然是一项艰巨的任务，需要大量的领域专业知识和时间。量子架构搜索（QAS）旨在通过自动生成新型量子电路来简化这一过程，减少人工干预的需要。在这篇论文中，我们提出了一种基于扩散的算法，利用LayerDAG框架来生成新的量子电路。这种方法与利用大型语言模型（LLM）、强化学习（RL）、变分自编码器（VAE）和类似技术的其他方法形成对比。我们的结果表明，所提出的模型始终产生100%有效的量子电路输出。 et.al.|[2504.20794](http://arxiv.org/abs/2504.20794)|null|
|**2025-04-29**|**Critical clusters in liquid crystals: Fractal geometry and conformal invariance**|我们研究了扭曲向列相液晶在相序动力学过程中的二维畴形态[R.A.L.Almeida，Phys.Rev.Lett.131（2023）268101]，这是自生成渗流普适类临界团簇的物理候选者。在这里，我们提供了实验证据，证明大团簇及其外壳确实都是分形，其尺寸与临界渗流模型中的相应图形相同。从原点附近的区域到圆盘边界的交叉概率的渐近衰减由劳勒-施拉姆-沃纳定理描述，前提是原始公式中的微观长度被液晶的粗化长度所取代。此外，在某些尺度上，大环的缠绕角行为与扩散率 $\kappa=6$ 的Schramm-Loewner演化曲线的行为是相容的。这些结果表明了临界团簇在相序中的实验实现。 et.al.|[2504.20788](http://arxiv.org/abs/2504.20788)|null|
|**2025-04-29**|**JTreeformer: Graph-Transformer via Latent-Diffusion Model for Molecular Generation**|基于原始化学分子分布发现新分子在医学上具有重要意义。与传统的图网络相比，图变换器具有高性能和可扩展性的优点，在最近的图结构应用研究中得到了广泛的探索。然而，基于电流互感器的图解码器难以有效地利用图信息，这限制了它们仅利用节点序列而不是分子图复杂拓扑结构的能力。本文重点构建一个基于图变换器的分子生成框架，我们称之为\textbf{JTreeformer}，因为它将图生成转换为连接树生成。它结合了GCN并行和多头注意力作为编码器。它将一个有向无环GCN集成到一个基于图的Transformer中，作为一个解码器，可以在每一步利用部分构建的分子结构的信息迭代合成整个分子。此外，在编码器生成的潜在空间中插入扩散模型，以进一步提高采样的效率和有效性。实证结果表明，我们的新框架优于现有的分子生成方法，从而为推进药物发现提供了一种有前景的工具(https://anonymous.4open.science/r/JTreeformer-C74C). et.al.|[2504.20770](http://arxiv.org/abs/2504.20770)|null|
|**2025-04-29**|**Influence network reconstruction from discrete time-series of count data modelled by multidimensional Hawkes processes**|在从犯罪分析到社交媒体的各种应用中，在没有已知先验网络结构的情况下从时间序列数据中识别关键影响者是一个具有挑战性的问题。虽然许多工作都集中在基于事件的时间序列（时间戳）数据上，但处理计数数据的方法较少，其中事件计数以固定间隔记录。我们为批量和顺序计数数据开发了网络推理方法。这里，强网络连接表示节点之间的关键影响。我们引入了一种基于集成的算法，该算法植根于期望最大化（EM）框架，并通过离散时间Cox或Hawkes过程证明了它在识别节点动态和连接方面的实用性。对于线性多维霍克斯模型，我们采用最小化-多数化（MM）方法，允许网络的并行推理。对于顺序推理，我们使用贝叶斯推理问题的二阶近似。在某些假设下，协方差矩阵的秩1更新可以降低计算成本。我们在合成数据和真实世界的数据集上验证我们的方法，包括欧洲学术界的电子邮件通信。我们的方法有效地重建了底层网络，同时考虑了激发和扩散的影响。这项工作推进了从真实场景中的计数数据进行网络重建。 et.al.|[2504.20758](http://arxiv.org/abs/2504.20758)|null|
|**2025-04-29**|**DDPS: Discrete Diffusion Posterior Sampling for Paths in Layered Graphs**|扩散模型构成了当今生成模型的一个重要类别，在尖端人工智能研究中占据了很大一部分。虽然存在许多超出图像和视频生成的扩展，但很少有这样的方法解决所生成样本中的显式约束问题。在本文中，我们研究了使用离散扩散模型在分层图（有向无环图的变体）中生成路径的问题，同时保证我们生成的样本确实是路径。我们的方法利用了一种简单而有效的路径表示，我们称之为填充邻接表矩阵（PALM）。此外，我们展示了如何有效地执行分类器引导，这有助于将采样路径引导到特定的首选边，而无需对扩散模型进行任何重新训练。我们的初步结果表明，从经验上讲，我们的方法优于没有明确考虑路径约束的替代方案。 et.al.|[2504.20754](http://arxiv.org/abs/2504.20754)|null|
|**2025-04-29**|**On optimal error rates for strong approximation of SDEs with a Hölder continuous drift coefficient**|在本文中，我们研究了在时间点 $1$具有有界和$\alpha$-H“旧连续漂移系数和恒定扩散系数的标量随机微分方程（SDEs）解的强近似。最近，在[arXiv:1909.07961v4（2021）]中表明，对于此类SDEs，等距Euler方案在所有$p\geq 1$和所有$\alpha \In（0,1]$的驱动布朗运动$W$的评估次数方面，实现了至少$（1+\alpha）/2$的$L^p$-误差率，直到任意小的$\varepsilon$。在这篇文章中，我们证明了$\alpha \In（0,1）$的匹配下限。更确切地说，我们证明，对于每一个$\alpha \ In（0,1）$，[arXiv:1909.07961v4（2021）]中Euler方案的$L^p$-错误率$（1+\alpha）/2$通常不能通过基于固定时间点$W$有限次评估的数值方法来改善。到目前为止，这一结果在文献中只为$\alpha=1$所知。此外，我们扩展了[arXiv:2402.13732v2（2024）]的一个结果，该结果关于具有分数Sobolev正则性$\alpha\in（0,1）$的有界漂移系数和时间点处的恒定扩散系数$1$的SDE的强近似的尖锐下限误差。我们证明，对于（0,1）$中的每一个$\alpha，在[arXiv:21011.1285v2（2022）]中显示的等距Euler方案的$L^p$-错误率$（1+\alpha）/2$，在对数项之前，通常不能通过基于固定时间点W的有限次计算的数值方法来改善。这一结果从[arXiv:2402.13732v2（2024）]中得知，仅适用于$\alpha\in（1/2.1）$和$p=2$ 。为了证明这些下限，我们使用Weierstrass函数的变体作为漂移系数，并采用最近在[arXiv:2010.00915v1（2020）]中引入的噪声耦合技术。 et.al.|[2504.20728](http://arxiv.org/abs/2504.20728)|null|
|**2025-04-29**|**Neural semi-Lagrangian method for high-dimensional advection-diffusion problems**|这项工作致力于高维平流扩散方程的数值近似。众所周知，经典方法，如有限体积法，存在维数灾难，并且它们的时间步长受到稳定性条件的约束。众所周知，半拉格朗日方法可以克服稳定性问题，而最近的基于时间离散神经网络的方法克服了维数灾难。在这项工作中，我们提出了一种新的神经半拉格朗日方法，结合了后两种方法。它依赖于将初始条件投影到有限维神经空间上，然后在每个时间步长求解涉及向后特征方程的优化问题。它特别适合在GPU上实现，因为它是完全可并行的，不需要网格。我们提供了粗略的误差估计，并展示了几个高维数值实验来评估我们方法的性能，并将其与其他神经方法进行了比较。 et.al.|[2504.20715](http://arxiv.org/abs/2504.20715)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-27**|**HumMorph: Generalized Dynamic Human Neural Fields from Few Views**|我们介绍了HumMorph，这是一种新的广义方法，用于在显式姿态控制下对动态人体进行自由视点渲染。HumMorph以任意姿势渲染给定几个观察到的视图（从一个开始）的任何指定姿势的人类演员。我们的方法能够实现快速推理，因为它只依赖于通过模型的前馈传递。我们首先在规范T姿势中构建演员的粗略表示，该表示结合了来自个体部分观察的视觉特征，并使用学习到的先验知识填充缺失的信息。粗表示由直接从观察到的视图中提取的细粒度像素对齐特征补充，这些特征提供了高分辨率的外观信息。我们证明，当只有一个输入视图可用时，HumMorph与最先进的技术具有竞争力，但是，在仅进行2次单目观察的情况下，我们可以获得明显更好的视觉质量。此外，之前的广义方法假设可以使用同步的多相机设置获得精确的身体形状和姿势参数。相比之下，我们考虑了一种更实际的场景，其中这些身体参数直接从观察到的视图中进行噪声估计。我们的实验结果表明，我们的架构对噪声参数中的误差更具鲁棒性，在这种情况下明显优于最新技术。 et.al.|[2504.19390](http://arxiv.org/abs/2504.19390)|null|
|**2025-04-24**|**Geometry aware inference of steady state PDEs using Equivariant Neural Fields representations**|神经场的最新进展使学习神经算子的强大离散不变方法成为可能，这些算子在一般几何上近似偏微分方程（PDE）的解。基于这些发展，我们引入了enf2enf，这是一种基于最近提出的等变神经场架构的编码器-解码器方法，用于预测具有非参数化几何变异性的稳态偏微分方程。在enf2enf中，输入几何被编码为潜在的点云嵌入，这些嵌入固有地保留了几何基础并捕获了局部现象。然后将得到的表示与全局参数相结合，并直接解码为连续的输出场，从而有效地对几何和物理之间的耦合进行建模。通过利用局部性和平移不变性的归纳偏差，我们的方法能够捕捉精细尺度的物理特征以及复杂的形状变化，从而增强泛化能力和物理顺应性。对高保真空气动力学数据集、超弹性材料基准和多元素翼型几何形状的广泛实验表明，与最先进的基于图、操作员学习和神经场的方法相比，所提出的模型具有更优越或更具竞争力的性能。值得注意的是，我们的方法支持实时推理和零样本超分辨率，能够在低分辨率网格上进行高效训练，同时保持全尺寸离散化的高精度。 et.al.|[2504.18591](http://arxiv.org/abs/2504.18591)|null|
|**2025-04-28**|**Physics-Driven Neural Compensation For Electrical Impedance Tomography**|电阻抗断层成像（EIT）提供了一种非侵入性的便携式成像方式，在医疗和工业应用中具有巨大的潜力。尽管EIT具有优势，但它遇到了两个主要挑战：其逆问题的不适定性质和空间可变、位置相关的灵敏度分布。传统的基于模型的方法通过正则化来减轻病态性，但忽略了灵敏度的可变性，而监督深度学习方法需要大量的训练数据，缺乏泛化能力。神经领域的最新发展引入了用于图像重建的隐式正则化技术，但这些方法通常忽略了EIT背后的物理原理，从而限制了它们的有效性。在这项研究中，我们提出了PhyNC（物理驱动神经补偿），这是一个无监督的深度学习框架，结合了EIT的物理原理。PhyNC通过动态地将神经表征能力分配给灵敏度较低的区域，确保准确和平衡的电导率重建，解决了不适定逆问题和灵敏度分布问题。对模拟和实验数据的广泛评估表明，PhyNC在细节保存和抗伪影方面优于现有方法，特别是在低灵敏度区域。我们的方法增强了EIT重建的鲁棒性，并提供了一个灵活的框架，可以适应具有类似挑战的其他成像方式。 et.al.|[2504.18067](http://arxiv.org/abs/2504.18067)|null|
|**2025-04-23**|**Spot solutions to a neural field equation on oblate spheroids**|理解神经场中激发模式的动力学是神经科学的一个重要课题。神经场方程是描述相互作用神经元的激发动力学以进行理论分析的数学模型。尽管许多神经场方程的分析都集中在神经元相互作用对平面的影响上，但在对大脑等器官进行建模时，动力学的几何约束也是一个有吸引力的话题。本文报道了在球体作为模型曲面上定义的神经场方程中的模式动力学。我们将点解视为局部模式，并讨论曲面的几何特性如何改变它们的特性。为了分析具有小展平的球体上的斑点模式，我们首先在球面上构造精确的静止斑点解，并揭示它们的稳定性。然后，我们扩展了分析，以证明球状情况下驻点解的存在性和稳定性。我们的一个理论结果是推导了扁球体极点处定域的驻点解的稳定性判据。该标准决定了点解是保持在极点还是移动。最后，我们进行了数值模拟，根据我们的理论预测讨论了点解的动力学。我们的结果表明，点解的动力学取决于曲面和神经相互作用的协调。 et.al.|[2504.16342](http://arxiv.org/abs/2504.16342)|null|
|**2025-04-22**|**Low-Rank Adaptation of Neural Fields**|处理视觉数据通常涉及微小的调整或变化序列，例如图像滤波、表面平滑和视频存储。虽然现有的图形技术，如法线映射和视频压缩，利用冗余来有效地对这种小变化进行编码，但对神经场（NF）的小变化（视觉或物理功能的神经网络参数化）进行编码的问题却很少受到关注。我们提出了一种使用低秩自适应（LoRA）更新神经场的参数高效策略。LoRA是一种来自参数高效微调LLM社区的方法，它以最小的计算开销对预训练模型进行小更新编码。我们使LoRA适应特定于实例的神经场，避免了对大型预训练模型的需求，从而产生了适用于低计算硬件的流水线。我们通过图像滤波、视频压缩和几何编辑的实验验证了我们的方法，证明了它在表示神经场更新方面的有效性和通用性。 et.al.|[2504.15933](http://arxiv.org/abs/2504.15933)|null|
|**2025-04-21**|**Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields**|弱引力透镜是星系形状的轻微扭曲，主要是由宇宙中暗物质的引力效应引起的。在我们的工作中，我们试图从2D望远镜图像中反转弱透镜信号，以重建宇宙暗物质场的3D图。虽然反演通常会产生暗物质场的二维投影，但暗物质分布的精确三维图对于定位感兴趣的结构和测试我们宇宙的理论至关重要。然而，3D反演带来了重大挑战。首先，与依赖于多个视点的标准3D重建不同，在这种情况下，图像仅从单个视点观察。通过观察整个体积中的星系发射器是如何被透镜化的，可以部分解决这一挑战。然而，这导致了第二个挑战：无透镜星系的形状和确切位置是未知的，只能在非常大的不确定性下进行估计。这引入了大量的噪声，几乎完全淹没了透镜信号。以前的方法通过对卷中的结构施加强有力的假设来解决这个问题。相反，我们提出了一种使用引力约束神经场来灵活模拟连续物质分布的方法。我们采用综合分析方法，通过完全可微的物理正向模型优化神经网络的权重，以再现图像测量中存在的透镜信号。我们展示了我们的模拟方法，包括模拟即将到来的望远镜调查数据的暗物质分布的真实模拟测量。我们的结果表明，我们的方法不仅可以超越以前的方法，而且重要的是还能够恢复潜在的令人惊讶的暗物质结构。 et.al.|[2504.15262](http://arxiv.org/abs/2504.15262)|null|
|**2025-04-20**|**Efficient Implicit Neural Compression of Point Clouds via Learnable Activation in Latent Space**|隐式神经表示（INR），也称为神经场，已成为深度学习中的一种强大范式，使用基于坐标的神经网络对连续空间场进行参数化。在本文中，我们提出了\textbf{PICO}，这是一个基于INR的静态点云压缩框架。与主流的编码器-解码器范式不同，我们将点云压缩任务分解为两个单独的阶段：几何压缩和属性压缩，每个阶段都有不同的INR优化目标。受Kolmogorov-Arnold网络（KANs）的启发，我们引入了一种新的网络架构\textbf{LeAFNet}，它利用潜在空间中的可学习激活函数来更好地近似目标信号的隐函数。通过将点云压缩重新表述为神经参数压缩，我们通过量化和熵编码进一步提高了压缩效率。实验结果表明，\textbf{LeAFNet}在基于INR的点云压缩中优于传统的MLP。此外，与当前的MPEG点云压缩标准相比，\textbf{PICO}实现了卓越的几何压缩性能，D1 PSNR平均提高了4.92 $dB。在联合几何和属性压缩方面，我们的方法表现出了极具竞争力的结果，平均PCQM增益为2.7美元乘以10^{-3}$ 。 et.al.|[2504.14471](http://arxiv.org/abs/2504.14471)|null|
|**2025-04-17**|**Radial Basis Function Techniques for Neural Field Models on Surfaces**|我们提出了一种使用径向基函数（RBF）插值和求积求解曲面上神经场方程的数值框架。神经场模型描述了宏观大脑活动的演变，但建模研究往往忽视了弯曲皮质区域的复杂几何形状。传统的数值方法，如有限元或谱方法，在计算上可能很昂贵，并且在不规则域上实现具有挑战性。相比之下，基于RBF的方法提供了一种灵活的替代方案，通过提供插值和正交方案，以高阶精度有效地处理任意几何形状。我们首先为一般曲面上的神经场模型开发了一个基于RBF的插值投影框架。详细推导了平面和曲面域的求积法，确保了高阶精度和稳定性，因为它们取决于RBF超参数（基函数、增广多项式和模板大小）。通过数值实验，我们证明了我们的方法的收敛性，突出了它在灵活性和准确性方面优于传统方法。最后，我们阐述了复杂表面上时空活动的数值模拟，说明了该方法捕捉复杂波传播模式的能力。 et.al.|[2504.13379](http://arxiv.org/abs/2504.13379)|null|
|**2025-04-16**|**SCENT: Robust Spatiotemporal Learning for Continuous Scientific Data via Scalable Conditioned Neural Fields**|由于空间和时间依赖性之间的复杂相互作用、数据的高维度和可扩展性约束，时空学习具有挑战性。这些挑战在科学领域进一步加剧，在这些领域，数据通常是不规则分布的（例如，传感器故障的缺失值）和高容量的（例如高保真模拟），带来了额外的计算和建模困难。在本文中，我们提出了SCENT，这是一种用于可扩展和连续性知情的时空表示学习的新框架。SCENT在单一架构中统一了插值、重建和预测。SCENT建立在基于变换器的编码器-处理器-解码器骨干上，引入了可学习的查询来增强泛化能力，并引入了查询式交叉关注机制来有效捕获多尺度依赖关系。为了确保数据大小和模型复杂性的可扩展性，我们引入了稀疏注意力机制，实现了灵活的输出表示和任意分辨率的高效评估。我们通过广泛的模拟和真实世界的实验来验证SCENT，在实现卓越可扩展性的同时，在多个具有挑战性的任务中展示了最先进的性能。 et.al.|[2504.12262](http://arxiv.org/abs/2504.12262)|null|
|**2025-04-14**|**DNF-Avatar: Distilling Neural Fields for Real-time Animatable Avatar Relighting**|从单眼视频中创建可重现和可动画化的人类化身是一个新兴的研究课题，具有广泛的应用，例如虚拟现实、体育和视频游戏。之前的研究利用神经场和基于物理的渲染（PBR）来估计人类化身的几何形状并解开其外观属性。然而，这些方法的一个缺点是由于昂贵的蒙特卡洛射线追踪导致渲染速度较慢。为了解决这个问题，我们提出将隐式神经场（教师）的知识提取为显式的2D高斯飞溅（学生）表示，以利用高斯飞溅的快速光栅化特性。为了避免光线追踪，我们对PBR外观采用了分裂和近似。我们还提出了用于阴影计算的新型部分式环境遮挡探头。阴影预测是通过每像素只查询一次这些探测器来实现的，这为化身的实时重新照明铺平了道路。这些技术相结合，可以提供高质量的重新照明效果和逼真的阴影效果。我们的实验表明，所提出的学生模型与我们的教师模型实现了相当甚至更好的重新照明结果，同时在推理时快了370倍，达到了67 FPS的渲染速度。 et.al.|[2504.10486](http://arxiv.org/abs/2504.10486)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

