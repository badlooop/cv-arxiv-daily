---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.10.07
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-03**|**Flash-Splat: 3D Reflection Removal with Flash Cues and Gaussian Splats**|我们介绍了一种简单而有效的分离透射光和反射光的方法。我们的关键见解是，现代逆渲染方法（例如，~3D高斯散点）提供的强大的新颖视图合成功能允许人们使用不成对的测量值进行闪光/无闪光反射分离——这种松弛大大简化了传统成对闪光/无闪光反射分离方法的图像采集。通过广泛的现实世界实验，我们展示了我们的方法Flash Splat，可以准确地重建3D中的透射和反射场景。我们的方法在很大程度上优于不利用照明控制的现有3D反射分离方法。我们的项目网页位于https://flash-splat.github.io/. et.al.|[2410.02764](http://arxiv.org/abs/2410.02764)|null|
|**2024-10-03**|**GI-GS: Global Illumination Decomposition on Gaussian Splatting for Inverse Rendering**|我们提出了GI-GS，这是一种新颖的逆渲染框架，它利用3D高斯散斑（3DGS）和延迟着色来实现照片级逼真的新颖视图合成和重新照明。在逆渲染中，精确建模对象的着色过程对于实现高保真结果至关重要。因此，至关重要的是结合全局照明来考虑在场景中多次反弹后到达对象的间接照明。以前基于3DGS的方法试图通过将间接照明表征为可学习的照明体积或每个高斯的附加属性来模拟间接照明，同时使用烘焙遮挡来表示阴影效果。然而，这些方法无法准确模拟光和物体之间复杂的物理相互作用，使得在重新照明过程中无法构建逼真的间接照明。为了解决这一局限性，我们建议使用具有延迟着色的有效路径跟踪来计算间接照明。在我们的框架中，我们首先渲染一个G缓冲区，以捕获场景的详细几何体和材质属性。然后，我们仅对直接照明执行基于物理的渲染（PBR）。使用G缓冲区和之前的渲染结果，可以通过轻量级路径跟踪计算间接照明。我们的方法有效地模拟了任何给定照明条件下的间接照明，从而实现了更好的新颖视图合成和重新照明。定量和定性结果表明，我们的GI-GS在渲染质量和效率方面都优于现有的基线。 et.al.|[2410.02619](http://arxiv.org/abs/2410.02619)|null|
|**2024-10-03**|**SuperGS: Super-Resolution 3D Gaussian Splatting via Latent Feature Field and Gradient-guided Splitting**|最近，3D高斯散斑（3DGS）以其实时渲染能力和卓越的质量在新颖的视图合成中脱颖而出。然而，由于从低分辨率输入视图导出的基元的粗糙性质，它面临着高分辨率新视图合成（HRNVS）的挑战。为了解决这个问题，我们提出了超分辨率3DGS（SuperGS），它是3DGS的扩展，采用两阶段粗到细的训练框架设计，利用预训练的低分辨率场景表示作为超分辨率优化的初始化。此外，我们引入了多分辨率特征高斯散斑（MFGS），以结合潜在特征场进行灵活的特征采样，并引入梯度引导的选择性分裂（GSS）进行有效的高斯上采样。通过将这些策略整合到从粗到细的框架中，可以确保高保真度和内存效率。大量实验表明，SuperGS在仅使用低分辨率输入挑战现实世界数据集方面超越了最先进的HRNVS方法。 et.al.|[2410.02571](http://arxiv.org/abs/2410.02571)|null|
|**2024-10-02**|**MVGS: Multi-view-regulated Gaussian Splatting for Novel View Synthesis**|最近在体绘制方面的工作，例如NeRF和3D高斯散点（3DGS），在学习到的隐式神经辐射场或3D高斯分布的帮助下，显著提高了渲染质量和效率。在显式表示的基础上进行渲染，vanilla 3DGS及其变体通过在训练过程中每次迭代都进行单视图监督来优化参数模型，从而提供实时效率。因此，某些视图被过度拟合，导致新颖的视图合成和不精确的3D几何中的外观不令人满意。为了解决上述问题，我们提出了一种新的3DGS优化方法，该方法体现了四个关键的新贡献：1）我们将传统的单视图训练范式转变为多视图训练策略。通过我们提出的多视图调节，3D高斯属性得到了进一步优化，而不会过拟合某些训练视图。作为通用解决方案，我们提高了各种场景和不同高斯变体的整体精度。2） 受其他观点带来的好处的启发，我们进一步提出了一种跨内在指导方案，从而针对不同分辨率进行了从粗到细的训练过程。3） 基于我们的多视图调节训练，我们进一步提出了一种交叉射线致密化策略，从一系列视图中在射线交叉区域致密化更多的高斯核。4） 通过进一步研究致密化策略，我们发现当某些观点明显不同时，致密化的效果应该得到增强。作为一种解决方案，我们提出了一种新的多视图增强致密化策略，其中鼓励3D高斯模型相应地被致密化到足够的数量，从而提高了重建精度。 et.al.|[2410.02103](http://arxiv.org/abs/2410.02103)|null|
|**2024-10-03**|**EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis**|我们提出了精确体积椭球体渲染（EVER），这是一种用于实时可微发射的纯体积渲染的方法。与最近3D高斯散斑（3DGS）的基于光栅化的方法不同，我们的基于基元的表示允许精确的体积渲染，而不是阿尔法合成3D高斯广告牌。因此，与3DGS不同，我们的公式不会受到爆裂伪影和视图依赖密度的影响，但仍然实现了$\sim\！在NVIDIA RTX4090上，720p分辨率下的帧率为30美元。由于我们的方法是建立在光线追踪的基础上的，因此它能够实现散焦模糊和相机失真（例如鱼眼相机）等效果，而这些效果很难通过光栅化来实现。我们证明，我们的方法比3DGS更准确，混合问题更少，并且在视图一致性渲染方面进行了后续工作，特别是在Zip-NeRF数据集中具有挑战性的大规模场景上，它在实时技术中取得了最清晰的结果。 et.al.|[2410.01804](http://arxiv.org/abs/2410.01804)|null|
|**2024-10-02**|**3DGS-DET: Empower 3D Gaussian Splatting with Boundary Guidance and Box-Focused Sampling for 3D Object Detection**|神经辐射场（NeRF）被广泛用于新颖的视图合成，并已被应用于3D对象检测（3DOD），通过视图合成表示为3DOD提供了一种有前景的方法。然而，NeRF面临着固有的局限性：（i）由于其隐式特性，3DOD的表示能力有限，以及（ii）渲染速度较慢。最近，3D高斯散斑（3DGS）已经成为解决这些局限性的显式3D表示。受这些优点的启发，本文首次将3DGS引入3DOD，确定了两个主要挑战：（i）高斯斑点的模糊空间分布：3DGS主要依赖于2D像素级监督，导致高斯斑点的3D空间分布不清楚，对象和背景之间的区分差，阻碍了3DOD；（ii）背景斑点过多：2D图像通常包含大量背景像素，导致重建的3DGS密度很高，其中许多噪声高斯斑点代表背景，对检测产生负面影响。为了应对挑战（i），我们利用3DGS重建来自2D图像的事实，并通过结合2D边界引导来显著增强高斯斑点的空间分布，从而更清晰地区分物体及其背景，提出了一种优雅高效的解决方案。为了应对挑战（ii），我们提出了一种使用2D框在3D空间中生成对象概率分布的框聚焦采样策略，允许在3D中进行有效的概率采样，以保留更多的对象斑点并减少噪声背景斑点。得益于我们的设计，我们的3DGS-DET明显优于基于SOTA NeRF的方法NeRF-DET，在mAP@0.25+8.1开始mAP@0.5ScanNet数据集，令人印象深刻的+31.5mAP@0.25ARKITCenes数据集。 et.al.|[2410.01647](http://arxiv.org/abs/2410.01647)|**[link](https://github.com/yangcaoai/3dgs-det)**|
|**2024-10-02**|**Gaussian Splatting in Mirrors: Reflection-Aware Rendering via Virtual Camera Optimization**|3D高斯散斑（3D-GS）的最新进展彻底改变了新的视图合成，促进了实时、高质量的图像渲染。然而，在涉及反射表面（特别是镜子）的场景中，3D-GS经常将反射误解为虚拟空间，导致镜子内的多视图渲染模糊和不一致。我们提出了一种新方法，旨在通过将反射建模为基于物理的虚拟相机来获得高质量的多视图一致反射渲染。我们使用3D-GS的深度和法线估计来估计镜面，并定义围绕镜面对称放置的虚拟相机。然后，这些虚拟相机用于解释场景中的镜面反射。为了解决镜面估计中的缺陷，我们提出了一种简单而有效的虚拟相机优化方法来提高反射质量。我们收集了一个新的镜像数据集，其中包括三个真实世界的场景，以进行更多样化的评估。Mirror-Nerf和我们的真实世界数据集上的实验验证证明了我们方法的有效性。与之前的最先进技术相比，我们在显著减少训练时间的同时，取得了相当或更优的结果。 et.al.|[2410.01614](http://arxiv.org/abs/2410.01614)|null|
|**2024-10-02**|**EVA-Gaussian: 3D Gaussian-based Real-time Human Novel View Synthesis under Diverse Camera Settings**|基于前馈的3D高斯散点方法在实时人类新颖视图合成方面表现出了卓越的能力。然而，现有的方法仅限于密集的视点设置，这限制了它们在各种相机视角差异的自由视点渲染中的灵活性。为了解决这一局限性，我们提出了一种名为EVA-Gassian的实时流水线，用于跨不同相机设置的3D人体新颖视图合成。具体来说，我们首先引入了一个高效的交叉视图注意力（EVA）模块，以准确估计源图像中每个3D高斯的位置。然后，我们将源图像与估计的高斯位置图进行整合，以预测3D高斯图像的属性和特征嵌入。此外，我们采用循环特征细化器来校正位置估计中由几何误差引起的伪影，并提高视觉保真度。为了进一步提高合成质量，我们为3D高斯属性和人脸地标引入了强大的锚丢失函数。THuman2.0和THumansit数据集的实验结果展示了我们的EVA高斯方法在不同相机设置下的渲染质量方面的优越性。项目页面：https://zhenliuzju.github.io/huyingdong/EVA-Gaussian. et.al.|[2410.01425](http://arxiv.org/abs/2410.01425)|null|
|**2024-10-02**|**AniSDF: Fused-Granularity Neural Surfaces with Anisotropic Encoding for High-Fidelity 3D Reconstruction**|神经辐射场最近彻底改变了新颖的视图合成，并实现了高保真渲染。然而，这些方法为了渲染质量而牺牲了几何体，限制了它们的进一步应用，包括重新照明和变形。如何在重建精确几何的同时合成照片级真实感渲染仍然是一个未解决的问题。在这项工作中，我们提出了AniSDF，这是一种新的方法，通过基于物理的编码来学习融合粒度的神经表面，以实现高保真度的3D重建。与之前的神经曲面不同，我们的融合粒度几何结构平衡了整体结构和精细的几何细节，产生了精确的几何重建。为了将几何体与反射外观区分开来，我们引入了混合辐射场，按照各向异性球面高斯编码（一种基于物理的渲染管道）对漫反射和镜面反射进行建模。通过这些设计，AniSDF可以重建具有复杂结构的对象，并生成高质量的渲染图。此外，我们的方法是一个统一的模型，不需要对特定对象进行复杂的超参数调整。大量实验表明，我们的方法在几何重建和新颖的视图合成方面都大大提高了基于SDF的方法的质量。 et.al.|[2410.01202](http://arxiv.org/abs/2410.01202)|null|
|**2024-10-01**|**GMT: Enhancing Generalizable Neural Rendering via Geometry-Driven Multi-Reference Texture Transfer**|新视图合成（NVS）旨在使用多视图图像在任意视点生成图像，神经辐射场（NeRF）的最新见解为显著改进做出了贡献。最近，对可推广NeRF（G-NeRF）的研究解决了NeRF中每场景优化的挑战。G-NeRF中动态构建辐射场简化了NVS过程，使其非常适合实际应用。同时，由于缺乏每个场景的优化，即使使用纹理丰富的多视图源输入，G-NeRF仍然难以表示特定场景的精细细节。作为补救措施，我们提出了一种几何驱动的多参考纹理传输网络（GMT），作为专为G-NeRF设计的即插即用模块。具体来说，我们提出了光线施加的可变形卷积（RayDCN），它对齐反映场景几何的输入和参考特征。此外，所提出的纹理保持变换器（TP Former）在保留纹理信息的同时聚合了多视图源特征。因此，我们的模块能够在图像增强过程中实现相邻像素之间的直接交互，这在每个像素具有独立渲染过程的G-NeRF模型中是不足的。这解决了阻碍捕获高频细节的限制。实验表明，我们的即插即用模块在各种基准数据集上持续改进了G-NeRF模型。 et.al.|[2410.00672](http://arxiv.org/abs/2410.00672)|**[link](https://github.com/yh-yoon/gmt)**|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-02**|**Learning from the Giants: A Practical Approach to Underwater Depth and Surface Normals Estimation**|单目深度和表面法线估计（MDSNE）对于3D重建、自主导航和水下勘探等任务至关重要。当前的方法要么依赖于与透明或反射表面斗争的判别模型，要么依赖于生成模型，尽管生成模型准确，但计算成本很高。本文提出了一种新的MDSNE深度学习模型，该模型专门针对水下环境量身定制，使用了一种混合架构，将卷积神经网络（CNN）与Transformers集成在一起，利用了这两种方法的优势。训练有效的MDSNE模型往往受到现实世界数据集噪声和合成数据集泛化能力有限的阻碍。为了解决这个问题，我们使用多个预训练的MDSNE模型生成伪标记的真实数据。为了确保这些数据的质量，我们提出了深度法线评估和选择算法（DNESA），该算法使用领域特定的度量来评估和选择最可靠的伪标记样本。然后，在这个精心策划的数据集上训练一个轻量级的学生模型。我们的模型将参数减少了90%，训练成本减少了80%，允许在资源受限的设备上进行实时3D感知。主要贡献包括：一种新颖高效的MDSNE模型、DNESA算法、特定领域的数据管道，以及对实时性能和可扩展性的关注。我们的模型专为现实世界的水下应用而设计，便于在水下机器人和自动驾驶车辆中进行低成本部署，弥合了研究与实际实施之间的差距。 et.al.|[2410.02072](http://arxiv.org/abs/2410.02072)|null|
|**2024-10-02**|**Enhancing Screen Time Identification in Children with a Multi-View Vision Language Model and Screen Time Tracker**|能够准确监测幼儿的屏幕暴露对于研究与屏幕使用相关的现象（如儿童肥胖、体育活动和社会互动）非常重要。大多数现有的研究都依赖于笨重的可穿戴传感器的自我报告或手动测量，因此在捕获定量屏幕曝光数据方面缺乏效率和准确性。在这项工作中，我们开发了一种新的传感器信息学框架，该框架利用了来自可穿戴传感器（称为屏幕时间跟踪器（STT））的以自我为中心的图像和视觉语言模型（VLM）。特别是，我们设计了一种多视图VLM，它从以自我为中心的图像序列中获取多个视图，并动态解释屏幕曝光。我们通过使用儿童自由生活活动的数据集验证了我们的方法，证明了其在普通视觉语言模型和对象检测模型方面比现有方法的显著改进。结果支持了这种监测方法的前景，它可以优化儿童自然环境中屏幕暴露的行为研究。 et.al.|[2410.01966](http://arxiv.org/abs/2410.01966)|null|
|**2024-10-02**|**GaussianBlock: Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians**|近年来，随着神经辐射场和高斯散斑技术的发展，三维重建技术已经达到了非常高的保真度。然而，通过这些方法学习的潜在表征是高度纠缠的，缺乏可解释性。在这篇论文中，我们提出了一种新的部分感知组合重建方法，称为GaussianBlock，它能够实现语义连贯和解纠缠的表示，允许类似于构建块的精确和物理编辑，同时保持高保真度。我们的GaussianBlock引入了一种混合表示法，该表示法利用了以灵活的可操作性和可编辑性而闻名的基元和在重建质量方面表现出色的3D Gaussian的优点。具体来说，我们通过一种新的注意力引导的中心丢失来实现语义连贯的原语，该丢失来自2D语义先验，并辅以动态分割和融合策略。此外，我们利用与基元杂交的3D高斯分布来细化结构细节并提高保真度。此外，采用绑定继承策略来加强和维护两者之间的连接。事实证明，我们重建的场景在不同的基准测试中表现出了解纠缠、构图和紧凑的特点，实现了无缝、直接和精确的编辑，同时保持了高质量。 et.al.|[2410.01535](http://arxiv.org/abs/2410.01535)|null|
|**2024-10-03**|**SurgPointTransformer: Vertebrae Shape Completion with RGB-D Data**|最先进的计算机和机器人辅助手术系统在很大程度上依赖于CT和荧光透视等术中成像技术来生成患者解剖结构的详细3D可视化。虽然成像技术非常准确，但它们基于电离辐射，使患者和临床医生暴露在外。本研究介绍了一种使用RGB-D数据重建3D脊柱解剖结构的无辐射替代方法。从外科医生在手术过程中形成的3D“心理图”中汲取灵感，我们介绍了SurgPointTransformer，这是一种用于手术应用的形状完成方法，可以从暴露表面的稀疏观察中准确重建未暴露的脊柱区域。我们的方法包括两个主要步骤：分割和形状完成。分割步骤包括脊柱定位和分割，然后是脊椎分割。然后，对分割的脊椎点云进行SurgPointTransformer处理，该处理利用注意力机制来学习可见表面特征和底层解剖结构之间的模式。为了进行评估，我们使用了九个样本的离体数据集。他们的CT数据用于建立地面实况数据，这些数据用于与我们的方法的输出进行比较。我们的方法明显优于最先进的基线，平均倒角距离为5.39，F分数为0.85，地球移动器距离为0.011，信噪比为22.90 dB。这项研究展示了我们的重建方法在3D椎体形状完成方面的潜力。它能够在没有电离辐射或侵入性成像的情况下对整个腰椎进行3D重建和手术指导。我们的工作有助于计算机辅助和机器人辅助手术，提高这些系统的感知和智能。 et.al.|[2410.01443](http://arxiv.org/abs/2410.01443)|null|
|**2024-10-02**|**AniSDF: Fused-Granularity Neural Surfaces with Anisotropic Encoding for High-Fidelity 3D Reconstruction**|神经辐射场最近彻底改变了新颖的视图合成，并实现了高保真渲染。然而，这些方法为了渲染质量而牺牲了几何体，限制了它们的进一步应用，包括重新照明和变形。如何在重建精确几何的同时合成照片级真实感渲染仍然是一个未解决的问题。在这项工作中，我们提出了AniSDF，这是一种新的方法，通过基于物理的编码来学习融合粒度的神经表面，以实现高保真度的3D重建。与之前的神经曲面不同，我们的融合粒度几何结构平衡了整体结构和精细的几何细节，产生了精确的几何重建。为了将几何体与反射外观区分开来，我们引入了混合辐射场，按照各向异性球面高斯编码（一种基于物理的渲染管道）对漫反射和镜面反射进行建模。通过这些设计，AniSDF可以重建具有复杂结构的对象，并生成高质量的渲染图。此外，我们的方法是一个统一的模型，不需要对特定对象进行复杂的超参数调整。大量实验表明，我们的方法在几何重建和新颖的视图合成方面都大大提高了基于SDF的方法的质量。 et.al.|[2410.01202](http://arxiv.org/abs/2410.01202)|null|
|**2024-10-02**|**Flex3D: Feed-Forward 3D Generation With Flexible Reconstruction Model And Input View Curation**|从文本、单幅图像或稀疏视图图像生成高质量的3D内容仍然是一项具有广泛应用的具有挑战性的任务。现有的方法通常采用多视图扩散模型来合成多视图图像，然后进行前馈过程进行3D重建。然而，这些方法往往受到少量固定数量的输入视图的限制，限制了它们捕获不同观点的能力，更糟糕的是，如果合成视图的质量较差，则会导致次优的生成结果。为了解决这些局限性，我们提出了Flex3D，这是一种新颖的两阶段框架，能够利用任意数量的高质量输入视图。第一阶段包括候选视图生成和管理管道。我们采用微调的多视图图像扩散模型和视频扩散模型来生成候选视图池，从而能够丰富地表示目标3D对象。随后，视图选择管道根据质量和一致性过滤这些视图，确保只有高质量和可靠的视图用于重建。在第二阶段，将策划的视图输入到灵活重建模型（FlexRM）中，该模型基于可以有效处理任意数量输入的变压器架构。FlemRM利用三平面表示直接输出3D高斯点，实现高效和详细的3D生成。通过对设计和培训策略的广泛探索，我们优化了FlexRM，以在重建和生成任务中实现卓越的性能。我们的结果表明，Flex3D实现了最先进的性能，与几种最新的前馈3D生成模型相比，在3D生成任务中的用户研究获胜率超过92%。 et.al.|[2410.00890](http://arxiv.org/abs/2410.00890)|null|
|**2024-10-01**|**A Low-Cost, High-Speed, and Robust Bin Picking System for Factory Automation Enabled by a Non-Stop, Multi-View, and Active Vision Scheme**|工厂自动化中的拣选系统通常面临由金属物体的稀疏和嘈杂的3D数据引起的鲁棒性问题。利用多个视图，特别是使用单次3D传感器和“手头传感器”配置，由于其有效性、灵活性和低成本而越来越受欢迎。在移动3D传感器以获取多个视图进行3D融合、关节优化或主动视觉时，会遇到低速问题。这是因为传感被视为一个与运动任务解耦的模块，而不是专门为垃圾箱拣选系统设计的。为了解决这些问题，我们设计了一个垃圾箱拣选系统，该系统将多视图、主动视觉方案与“手头传感器”配置中的运动任务紧密结合。它不仅通过将高速传感方案与机器人的位置动作并行化来加速系统，而且还决定了下一个传感路径，以保持整个拾取过程的连续性。与其他只关注传感评估的人不同，我们还通过在5种不同类型的物体上进行实验来评估我们的设计，而不需要人为干预。我们的实验表明，整个传感方案在CPU上可以在1.682秒内（最大）完成，平均拾取完成率超过97.75%。由于与机器人运动的并行化，传感方案的平均节拍时间仅为0.635秒。 et.al.|[2410.00706](http://arxiv.org/abs/2410.00706)|null|
|**2024-10-01**|**An Illumination-Robust Feature Extractor Augmented by Relightable 3D Reconstruction**|视觉特征的描述通常依赖于局部强度和梯度方向，近年来在机器人导航和定位中得到了广泛的应用。然而，视觉特征的提取通常会受到光照条件变化的干扰，这使得它在现实世界的应用中具有挑战性。以前的工作已经通过建立具有光照条件变化的数据集来解决这个问题，但可能成本高昂且耗时。本文提出了一种光照鲁棒特征提取器的设计过程，其中采用了最近开发的可重新照亮的3D重建技术，在不同的光照条件下快速直接地生成数据。提出了一种自监督框架，用于提取特征，该框架在关键点的可重复性和描述符在良好和不良光照条件下的相似性方面具有优势。实验证明了所提出的鲁棒特征提取方法的有效性。消融研究也表明了自我监督框架设计的有效性。 et.al.|[2410.00629](http://arxiv.org/abs/2410.00629)|null|
|**2024-10-01**|**3DGR-CAR: Coronary artery reconstruction from ultra-sparse 2D X-ray views with a 3D Gaussians representation**|重建三维冠状动脉对于冠状动脉疾病的诊断、治疗计划和手术导航非常重要。传统的重建技术通常需要多次投影，而从稀疏视图X射线投影进行重建是减少辐射剂量的一种潜在方法。然而，冠状动脉在3D体积中的极端稀疏性和超有限数量的投影对高效准确的3D重建构成了重大挑战。为此，我们提出了3DGR-CAR，这是一种用于从超稀疏X射线投影重建冠状动脉的3D高斯表示。我们利用3D高斯表示来避免冠状动脉数据极度稀疏造成的效率低下，并提出了一种高斯中心预测器来克服超稀疏视图投影中的噪声高斯初始化。所提出的方案仅需2个视图即可实现快速准确的3D冠状动脉重建。在两个数据集上的实验结果表明，所提出的方法在体素精度和冠状动脉视觉质量方面明显优于其他方法。该代码将在https://github.com/windrise/3DGR-CAR. et.al.|[2410.00404](http://arxiv.org/abs/2410.00404)|**[link](https://github.com/windrise/3dgr-car)**|
|**2024-10-01**|**Seamless Augmented Reality Integration in Arthroscopy: A Pipeline for Articular Reconstruction and Guidance**|关节镜是一种用于诊断和治疗关节问题的微创手术。关节镜的临床工作流程通常涉及通过小切口将关节镜插入关节，在此过程中，外科医生主要依靠关节镜的视觉评估进行导航和操作。然而，关节镜有限的视野和缺乏深度感知给在手术过程中导航复杂的关节结构和实现手术精度带来了挑战。为了提高术中意识，我们提出了一种强大的管道，该管道结合了同时定位和映射、深度估计和3D高斯飞溅，仅基于单眼关节镜视频即可真实地重建关节内结构。将3D重建扩展到增强现实（AR）应用，我们的解决方案以人体在环方式为关节切迹测量和注释锚定提供AR辅助。与传统的基于运动和神经辐射场的结构方法相比，我们的流水线平均在7分钟内实现了密集的3D重建和具有竞争力的渲染保真度，并具有显式的3D表示。当在四个体模数据集上进行评估时，我们的方法平均实现了RMSE=2.21mm的重建误差、PSNR=32.86和SSIM=0.89。由于我们的管道能够直接从单眼关节镜进行AR重建和引导，而无需任何额外的数据和/或硬件，因此我们的解决方案可能有助于提高关节镜手术中的意识和手术精度。我们的AR测量工具的精度在1.59+/-1.81mm以内，AR注释工具的mIoU为0.721。 et.al.|[2410.00386](http://arxiv.org/abs/2410.00386)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-10-03**|**Revisit Large-Scale Image-Caption Data in Pre-training Multimodal Foundation Models**|多模态模型的最新进展突显了重写标题对提高性能的价值，但关键挑战仍然存在。例如，虽然合成字幕通常提供卓越的质量和图像文本对齐，但尚不清楚它们是否可以完全取代AltTexts：合成字幕的作用及其在预训练中与原始网络抓取的AltTexts的交互仍然没有得到很好的理解。此外，不同的多模式基础模型可能对特定的字幕格式有独特的偏好，但为每个模型确定最佳字幕的努力仍然有限。在这项工作中，我们提出了一种新颖的、可控的、可扩展的字幕管道，旨在生成针对各种多模式模型量身定制的各种字幕格式。通过将短合成字幕（SSC）与密集合成字幕（DSC+）作为案例研究，我们系统地探索了它们在CLIP、多峰LLM和扩散模型等模型中的影响以及与AltTexts的相互作用。我们的研究结果表明，保留合成字幕和AltTexts的混合方法可以优于单独使用合成字幕，提高对齐和性能，每个模型都展示了对特定字幕格式的偏好。这种全面的分析为优化字幕策略提供了宝贵的见解，从而推进了多模态基础模型的预训练。 et.al.|[2410.02740](http://arxiv.org/abs/2410.02740)|null|
|**2024-10-03**|**Discovery of three magnetic He-sdOs with SALT**|最近，在一组四颗极其相似的富氦热亚矮星（He-sdO）中发现了强度在300至500kG之间的磁场。除了强磁场外，这些He sdO恒星还具有共同的大气参数，聚集在 $46500K左右，$\log g$ 接近6，氦丰度中等。在这里，我们发现了另外三颗磁热亚矮星，J123359.44-674929.11、J125611.42-575333.45和J144405.79-674400.93。这些恒星在大气参数方面几乎完全相同，但在约200kG的B美元下，它们的磁场比以前已知的磁场弱一些。所有已知He sdo的密切相似性暗示了一个精心调整的起源。我们提出了He白矮星与H+He白矮星的合并。合并界面处的微分旋转可能会引发一个环形磁场，该磁场由磁发电机演变为极向场。该场要么在地表直接可见，要么如果最初被掩埋，可能会向地表扩散。我们进一步讨论了一条以4630\r{a}为中心的宽吸收线，这是所有磁性He-sDO所共有的。这一特征可能与磁场无关，而是与这些He-sdO恒星中的中等氦丰度有关，这使得强He II 4686\r{A}线受到与氢原子碰撞的扰动。 et.al.|[2410.02737](http://arxiv.org/abs/2410.02737)|null|
|**2024-10-03**|**NETS: A Non-Equilibrium Transport Sampler**|我们提出了一种称为非平衡传输采样器（NETS）的算法，用于从非正态化概率分布中采样。NETS可以被视为基于Jarzynski等式的退火重要性抽样（AIS）的变体，其中用于执行非平衡抽样的随机微分方程被一个额外的学习漂移项增强，从而降低了AIS中使用的无偏权重的影响。我们证明，这种漂移是各种目标函数的最小值，这些目标函数都可以以无偏的方式进行估计，而无需通过控制采样的随机微分方程的解进行反向传播。我们还证明了这些目标控制了估计分布与其目标的Kullback-Leibler散度。NETS被证明是无偏的，此外，它还有一个可调的扩散系数，可以在训练后进行调整，以最大限度地提高有效样本量。我们证明了该方法在标准基准、高维高斯混合分布和统计格场理论模型上的有效性，它超越了相关工作和现有基线的性能。 et.al.|[2410.02711](http://arxiv.org/abs/2410.02711)|null|
|**2024-10-03**|**SteerDiff: Steering towards Safe Text-to-Image Diffusion Models**|文本到图像（T2I）扩散模型因其能够生成具有精确文本对齐的高质量图像而受到关注。然而，这些模型也可能被误用以产生不恰当的内容。现有的安全措施通常依赖于文本分类器或类似ControlNet的方法，但往往是不够的。传统的文本分类器依赖于大规模的标记数据集，很容易通过改写来绕过。随着扩散模型的不断扩展，微调这些保障措施变得越来越具有挑战性，缺乏灵活性。最近的红队攻击研究进一步强调了需要一种新的范式来防止不恰当内容的产生。在本文中，我们介绍了SteerDiff，这是一个轻量级的适配器模块，旨在充当用户输入和扩散模型之间的中介，确保生成的图像符合道德和安全标准，对可用性几乎没有影响。SteerDiff识别并操纵文本嵌入空间中的不恰当概念，以引导模型远离有害输出。我们在各种概念忘却任务中进行了广泛的实验，以评估我们方法的有效性。此外，我们将SteerDiff与多种红队策略进行基准测试，以评估其稳健性。最后，我们探索了SteerDiff在概念遗忘任务中的潜力，展示了它在文本条件图像生成中的多功能性。 et.al.|[2410.02710](http://arxiv.org/abs/2410.02710)|null|
|**2024-10-03**|**ControlAR: Controllable Image Generation with Autoregressive Models**|自回归（AR）模型将图像生成重新定义为下一个令牌预测，显示出巨大的潜力，并成为扩散模型的强大竞争对手。然而，在AR模型中，类似于ControlNet的图像生成控制在很大程度上仍未得到探索。尽管受大型语言模型进步的启发，一种自然的方法是将控制图像标记为标记，并在解码图像标记之前将其预填充到自回归模型中，但与ControlNet相比，它的生成质量仍然不足，效率低下。为此，我们引入了ControlAR，这是一种将空间控制集成到自回归图像生成模型中的高效框架。首先，我们探索了AR模型的控制编码，并提出了一种轻量级的控制编码器，将空间输入（例如canny边缘或深度图）转换为控制令牌。然后，ControlAR利用条件解码方法生成下一个图像令牌，该令牌以控制和图像令牌之间的每个令牌融合为条件，类似于位置编码。与预填充令牌相比，使用条件解码显著增强了AR模型的控制能力，但也保持了模型的效率。此外，所提出的ControlAR令人惊讶地通过条件解码和特定控制使AR模型能够生成任意分辨率的图像。广泛的实验可以证明所提出的ControlAR对于跨不同输入（包括边缘、深度和分割掩模）的图像生成的自回归控制的可控性。此外，定量和定性结果都表明，ControlAR超越了以前最先进的可控扩散模型，例如ControlNet++。代码、模型和演示将很快在https://github.com/hustvl/ControlAR. et.al.|[2410.02705](http://arxiv.org/abs/2410.02705)|**[link](https://github.com/hustvl/controlar)**|
|**2024-10-03**|**GUD: Generation with Unified Diffusion**|扩散生成模型通过反转一个逐渐向数据样本添加噪声的过程，将噪声转化为数据。受物理学中分析不同尺度系统的重整化群概念的启发，我们通过探索三个关键的设计方面来重新审视扩散模型：1）扩散过程运行的表示方式的选择（例如像素基、PCA基、傅里叶基或小波基），2）数据在扩散过程中转换为的先验分布（例如协方差高斯 $\Sigma$ ），3）分别应用于数据不同部分的噪声水平调度，由按组件的噪声调度捕获。结合这些选择的灵活性，我们为扩散生成模型开发了一个统一的框架，大大提高了设计自由度。特别是，我们引入了软条件模型，该模型在标准扩散模型和自回归模型（在任何基础上）之间平滑插值，在概念上弥合了这两种方法。我们的框架开辟了一个广阔的设计空间，这可能会导致更有效的训练和数据生成，并为集成不同生成方法和生成任务的新型架构铺平了道路。 et.al.|[2410.02667](http://arxiv.org/abs/2410.02667)|null|
|**2024-10-03**|**AGN STROM 2: X. The origin of the interband continuum delays in Mrk 817**|作为大型国际活动AGN STORM 2的一部分，使用星载和地面仪器对本地（z=0.0315）AGN Mrk 817进行了500多天的监测。在这里，我们使用宽线区域（BLR）的详细建模、按光学深度分类的几种盘风以及新的数值模拟，对宽带连续体变化进行了全面分析。我们发现，漫射连续谱（DC）发射，加上强而宽的发射线的额外贡献，可以解释该源在高光度和低光度阶段观察到的连续谱滞后。可变X射线日冕的圆盘照射仅占观测到的连续滞后的一小部分。我们的BLR模型假设辐射压力限制云分布在2-122光年的距离内。我们给出了许多发射线和直流发射的计算平均发射率半径，并提出了一种简单的传递函数相关方法，将它们与互相关滞后确定联系起来。我们没有发现大光学深度风的明确迹象，但确定了较低柱密度风的特征。特别是，我们将观测到的最短连续滞后与tau（1 Ryd）约2风和部分屏蔽的BLR的组合联系起来。甚至更小的光学深度风也可能与X射线吸收特征以及HeII和CIV等几条高电离线的宽度和滞后的显著变化有关。最后，我们证明了环面粉尘排放对i和z波段观测到的滞后的影响。 et.al.|[2410.02652](http://arxiv.org/abs/2410.02652)|null|
|**2024-10-03**|**Undesirable Memorization in Large Language Models: A Survey**|虽然最近的研究越来越多地展示了大型语言模型（LLM）的卓越能力，但面对它们隐藏的陷阱至关重要。在这些挑战中，记忆问题尤为突出，带来了重大的道德和法律风险。本文提出了一种关于LLMs记忆主题的知识系统化（SoK）。记忆是模型倾向于存储和再现训练数据中的短语或段落的效果，已被证明是针对LLM的各种隐私和安全攻击的根本问题。我们首先概述了关于记忆的文献，从五个关键维度对其进行了探索：意向性、程度、可检索性、抽象性和透明度。接下来，我们讨论了用于衡量记忆的指标和方法，然后分析了导致记忆现象的因素。然后，我们研究记忆如何在特定的模型架构中表现出来，并探索减轻这些影响的策略。我们通过确定近期潜在的研究课题来总结我们的概述：开发平衡LLM性能和隐私的方法，以及在特定情境下对记忆的分析，包括会话代理、检索增强生成、多语言语言模型和扩散语言模型。 et.al.|[2410.02650](http://arxiv.org/abs/2410.02650)|null|
|**2024-10-03**|**Efficient calibration of the shifted square-root diffusion model to credit default swap spreads using asymptotic approximations**|我们使用渐近系数展开技术近似非线性偏微分方程的解，推导了二维移位平方根扩散（SSRD）模型中信用违约掉期（CDS）利差的闭合形式近似。具体来说，我们确定了与CDS价差公式中缺乏解析解的两个项相关的柯西问题，并推导出了这些项的渐近近似值。我们的近似值不需要假设不相关的利率和违约强度过程，这是SSRD模型中校准的典型要求。通过使用CDS价差的市场数据进行的几项校准研究，我们证明了我们提出的公式的准确性和效率。 et.al.|[2410.02645](http://arxiv.org/abs/2410.02645)|null|
|**2024-10-03**|**Diffusion-based Extreme Image Compression with Compressed Feature Initialization**|基于扩散的极端图像压缩方法在极低比特率下取得了令人印象深刻的性能。然而，由于受到从纯噪声开始的迭代去噪过程的限制，这些方法在保真度和效率方面都受到限制。为了解决这两个问题，我们提出了中继残差扩散极端图像压缩（RDEIC），它利用了压缩特征初始化和残差扩散。具体来说，我们首先使用添加了噪声的图像的压缩潜在特征，而不是纯噪声，作为消除去噪过程中不必要的初始阶段的起点。其次，我们设计了一种新的中继残差扩散方法，通过迭代去除添加的噪声和压缩特征与目标潜在特征之间的残差来重建原始图像。值得注意的是，我们的中继残差扩散网络无缝集成了预训练的稳定扩散，以利用其强大的生成能力进行高质量的重建。第三，我们提出了一种固定步长的微调策略，以消除训练和推理阶段之间的差异，进一步提高重建质量。大量实验表明，所提出的RDEIC实现了最先进的视觉质量，在保真度和效率方面都优于现有的基于扩散的极端图像压缩方法。源代码将在https://github.com/huai-chang/RDEIC. et.al.|[2410.02640](http://arxiv.org/abs/2410.02640)|**[link](https://github.com/huai-chang/rdeic)**|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-09-30**|**DressRecon: Freeform 4D Human Reconstruction from Monocular Video**|我们提出了一种从单目视频中重建时间一致的人体模型的方法，重点是极其宽松的衣服或手持物体的交互。之前在人体重建方面的工作要么局限于没有物体交互的紧身衣服，要么需要校准的多视图捕捉或个性化的模板扫描，而大规模收集这些数据成本很高。我们对高质量但灵活的重建的关键见解是，将关于关节体形状的通用人类先验（从大规模训练数据中学习）与视频特定的关节“骨骼袋”变形（通过测试时间优化适合单个视频）仔细结合。我们通过学习一个神经隐式模型来实现这一点，该模型将身体和衣服的变形作为单独的运动模型层来解开。为了捕捉服装的微妙几何形状，我们在优化过程中利用了基于图像的先验，如人体姿势、表面法线和光流。由此产生的神经场可以提取到时间一致的网格中，或进一步优化为显式3D高斯分布，以实现高保真交互式渲染。在具有高度挑战性的服装变形和物体交互的数据集上，DressReston可以产生比现有技术更高保真的3D重建。项目页面：https://jefftan969.github.io/dressrecon/ et.al.|[2409.20563](http://arxiv.org/abs/2409.20563)|null|
|**2024-09-25**|**TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans**|我们介绍了一种新的框架，该框架从单眼视频中学习全身说话的人的动态神经辐射场（NeRF）。之前的工作只代表身体姿势或面部。然而，人类通过全身进行交流，结合身体姿势、手势和面部表情。在这项工作中，我们提出了TalkinNeRF，这是一个基于NeRF的统一网络，代表了整体4D人体运动。给定一个受试者的单眼视频，我们学习身体、面部和手的相应模块，这些模块结合在一起生成最终结果。为了捕捉复杂的手指关节，我们学习了手的额外变形场。我们的多身份表示能够同时训练多个科目，以及在完全看不见的姿势下进行强大的动画。只要输入一段短视频，它也可以推广到新的身份。我们展示了最先进的性能，用于为全身说话的人类制作动画，具有精细的手部发音和面部表情。 et.al.|[2409.16666](http://arxiv.org/abs/2409.16666)|null|
|**2024-09-24**|**Generative 3D Cardiac Shape Modelling for In-Silico Trials**|我们提出了一种深度学习方法，基于将形状表示为神经有符号距离场的零级集，对合成主动脉形状进行建模和生成，该方法受一系列可训练的嵌入向量的约束，并对每个形状的几何特征进行编码。通过使神经场在采样表面点上消失并强制其空间梯度具有单位范数，在从CT图像重建的主动脉根部网格数据集上训练网络。实证结果表明，我们的模型可以高保真地表示主动脉形状。此外，通过从学习到的嵌入向量中采样，我们可以生成类似于真实患者解剖结构的新形状，可用于计算机模拟试验。 et.al.|[2409.16058](http://arxiv.org/abs/2409.16058)|null|
|**2024-09-21**|**MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors**|由于缺乏几何指导和不完美的视图相关2D先验，从单眼图像中精确重建密集和语义注释的3D网格仍然是一项具有挑战性的任务。尽管我们已经见证了隐式神经场景表示的最新进展，能够简单地从多视图图像中进行精确的2D渲染，但很少有研究仅使用单眼先验来解决3D场景理解问题。在本文中，我们提出了MOSE，这是一种神经场语义重建方法，可以将推断的图像级噪声先验提升到3D，在3D和2D空间中产生精确的语义和几何。我们方法的关键动机是利用通用类不可知的分段掩码作为指导，在训练过程中促进渲染语义的局部一致性。在语义的帮助下，我们进一步将平滑正则化应用于无纹理区域，以获得更好的几何质量，从而实现几何和语义的互惠互利。在ScanNet数据集上的实验表明，我们的MOSE在3D语义分割、2D语义分割和3D表面重建任务的所有指标上都优于相关基线。 et.al.|[2409.14019](http://arxiv.org/abs/2409.14019)|null|
|**2024-09-17**|**SplatFields: Neural Gaussian Splats for Sparse 3D and 4D Reconstruction**|从多视图图像中数字化3D静态场景和4D动态事件长期以来一直是计算机视觉和图形学领域的一个挑战。最近，3D高斯散斑（3DGS）已经成为一种实用且可扩展的重建方法，由于其令人印象深刻的重建质量、实时渲染能力以及与广泛使用的可视化工具的兼容性而越来越受欢迎。然而，该方法需要大量的输入视图来实现高质量的场景重建，这引入了一个重大的实际瓶颈。在捕捉动态场景时，这一挑战尤为严峻，因为部署广泛的相机阵列的成本可能高得令人望而却步。在这项工作中，我们发现斑点特征缺乏空间自相关性是导致3DGS技术在稀疏重建环境中性能不佳的因素之一。为了解决这个问题，我们提出了一种优化策略，通过将splat特征建模为相应隐式神经场的输出，有效地正则化splat特征。这导致在各种场景中重建质量的一致提高。我们的方法有效地处理了静态和动态情况，这在不同设置和场景复杂性的广泛测试中得到了证明。 et.al.|[2409.11211](http://arxiv.org/abs/2409.11211)|null|
|**2024-10-02**|**Neural Fields for Adaptive Photoacoustic Computed Tomography**|光声计算机断层扫描（PACT）是一种具有广泛医学应用的非侵入性成像技术。传统的PACT图像重建算法受到组织中声速不均匀（SOS）引起的波前失真的影响，导致图像质量下降。考虑到这些影响可以提高图像质量，但测量SOS分布的实验成本很高。另一种方法是仅使用PA信号对初始压力图像和SOS进行联合重建。现有的关节重建方法存在局限性：计算成本高，无法直接恢复SOS，以及依赖于不准确的简化假设。隐式神经表示或神经场是计算机视觉中的一种新兴技术，用于通过基于坐标的神经网络学习物理场的有效和连续表示。在这项工作中，我们介绍了NF-APACT，这是一种高效的自监督框架，利用神经场来估计SOS，以实现准确和鲁棒的多通道解卷积。我们的方法比现有方法更快、更准确地消除了SOS像差。我们在一个新的数值体模以及实验收集的体模和体内数据上证明了我们的方法的成功。我们的代码和数字幻影可在https://github.com/Lukeli0425/NF-APACT. et.al.|[2409.10876](http://arxiv.org/abs/2409.10876)|null|
|**2024-09-09**|**Lagrangian Hashing for Compressed Neural Field Representations**|我们提出了拉格朗日散列，这是一种神经场的表示，结合了依赖于欧拉网格（即~InstantNGP）的快速训练NeRF方法的特征，以及使用配备有特征的点作为表示信息的方法（例如3D高斯散点或PointNeRF）。我们通过将基于点的表示合并到InstantNGP表示的分层哈希表的高分辨率层中来实现这一点。由于我们的点具有影响域，因此我们的表示可以被解释为哈希表中存储的高斯混合。我们提出的损失鼓励我们的高斯人向需要更多代表预算才能充分代表的地区移动。我们的主要发现是，我们的表示允许使用更紧凑的表示来重建信号，而不会影响质量。 et.al.|[2409.05334](http://arxiv.org/abs/2409.05334)|null|
|**2024-09-08**|**Exploring spectropolarimetric inversions using neural fields. Solar chromospheric magnetic field under the weak-field approximation**|全斯托克斯偏振数据集来源于狭缝光谱仪或窄带滤光片图，如今已被常规采集。随着二维光谱偏振仪和允许长时间高质量观测序列的观测技术的出现，数据速率正在增加。在光谱偏振反演中，显然需要通过利用推断物理量的时空相干性来超越传统的逐像素策略。我们探索了神经网络作为时间和空间（也称为神经场）上物理量的连续表示的潜力，用于光谱极化反演。我们已经实现并测试了一个神经场，以在弱场近似（WFA）下执行磁场矢量的推理（也称为物理知情神经网络的方法）。通过使用神经场来描述磁场矢量，我们可以通过假设物理量是坐标的连续函数来在空间和时间域中正则化解。我们研究了Ca II 8542 A谱线的合成和真实观测结果。我们还探讨了其他显式正则化的影响，例如使用外推磁场的信息或色球原纤维的取向。与传统的逐像素反演相比，神经场方法提高了磁场矢量重建的保真度，特别是横向分量。这种隐式正则化是一种提高观测值有效信噪比的方法。虽然它比逐像素WFA估计慢，但这种方法通过减少自由参数的数量并在解决方案中引入时空约束，显示出深度分层反演的巨大潜力。 et.al.|[2409.05156](http://arxiv.org/abs/2409.05156)|**[link](https://github.com/cdiazbas/neural_wfa)**|
|**2024-09-04**|**MDNF: Multi-Diffusion-Nets for Neural Fields on Meshes**|我们提出了一种在三角形网格上表示神经场的新框架，该框架在空间和频率域上都是多分辨率的。受神经傅里叶滤波器组（NFFB）的启发，我们的架构通过将更精细的空间分辨率级别与更高的频带相关联来分解空间和频率域，而将更粗糙的分辨率映射到较低的频率。为了实现几何感知的空间分解，我们利用了多个扩散网络组件，每个组件都与不同的空间分辨率级别相关联。随后，我们应用傅里叶特征映射来鼓励更精细的分辨率水平与更高的频率相关联。最终信号是使用正弦激活的MLP以小波激励的方式组成的，将高频信号聚集在低频信号之上。我们的架构在学习复杂神经场方面具有很高的精度，并且对目标场的不连续性、指数尺度变化和网格修改具有鲁棒性。我们通过将我们的方法应用于不同的神经领域，如合成RGB函数、UV纹理坐标和顶点法线，展示了其有效性，并说明了不同的挑战。为了验证我们的方法，我们将其性能与两种替代方案进行了比较，展示了我们的多分辨率架构的优势。 et.al.|[2409.03034](http://arxiv.org/abs/2409.03034)|null|
|**2024-09-03**|**GraspSplats: Efficient Manipulation with 3D Feature Splatting**|机器人对物体部件进行高效和零样本抓取的能力对于实际应用至关重要，并且随着视觉语言模型（VLM）的最新进展而变得普遍。为了弥合二维到三维表示的差距以支持这种能力，现有的方法依赖于神经场（NeRF），通过可微渲染或基于点的投影方法。然而，我们证明了NeRF由于其隐含性而不适合场景变化，并且基于点的方法对于没有基于渲染的优化的零件定位是不准确的。为了修正这些问题，我们提出了“把握辉煌”。使用深度监督和一种新的参考特征计算方法，GraspSplats在60秒内生成高质量的场景表示。我们进一步验证了基于高斯表示法的优势，表明GraspSplats中的显式和优化几何足以原生支持（1）实时抓取采样和（2）使用点跟踪器进行动态和铰接对象操作。通过在Franka机器人上进行的广泛实验，我们证明了在不同的任务设置下，GraspSplats的表现明显优于现有的方法。特别是，GraspSplats的性能优于基于NeRF的方法，如F3RM和LERF-TOGO，以及2D检测方法。 et.al.|[2409.02084](http://arxiv.org/abs/2409.02084)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

