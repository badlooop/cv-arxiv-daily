---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.02.26
> Usage instructions: [here](./docs/README.md#usage)

## Video Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-02-25**|**SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference**|由于其二次时间复杂性，高效的注意力实现对于大型模型至关重要。幸运的是，注意力通常表现出稀疏性，即注意力图中的许多值都接近零，从而可以省略相应的计算。许多研究利用稀疏模式来加速注意力。然而，大多数现有的工作都集中在通过利用注意力图的某些稀疏模式来优化特定模型中的注意力。保证不同模型的加速和端到端性能的普遍稀疏关注仍然难以捉摸。在本文中，我们提出了稀疏Attn，这是一种适用于任何模型的通用稀疏和量化注意。我们的方法使用两阶段在线过滤器：在第一阶段，我们快速准确地预测注意力图，从而跳过注意力中的一些矩阵乘法。在第二阶段，我们设计了一个在线软最大感知滤波器，该滤波器不会产生额外的开销，并且进一步跳过了一些矩阵乘法。实验表明，我们的方法在不牺牲端到端指标的情况下，显著加速了包括语言、图像和视频生成在内的各种模型。这些代码可在以下网址获得https://github.com/thu-ml/SpargeAttn. et.al.|[2502.18137](http://arxiv.org/abs/2502.18137)|null|
|**2025-02-25**|**ASurvey: Spatiotemporal Consistency in Video Generation**|通过利用动态视觉生成方法，视频生成突破了人工智能生成内容（AIGC）的界限。视频生成带来了静态图像生成之外的独特挑战，需要高质量的单个帧和时间连贯性来保持时空序列的一致性。最近的工作旨在解决视频生成中的时空一致性问题，但很少有文献从这个角度进行综述。这种差距阻碍了对高质量视频生成的潜在机制的深入理解。在这项调查中，我们系统地回顾了视频生成的最新进展，涵盖了五个关键方面：基础模型、信息表示、生成方案、后处理技术和评估指标。我们特别关注它们对保持时空一致性的贡献。最后，我们讨论了该领域的未来方向和挑战，希望能激发进一步的努力，推动视频生成的发展。 et.al.|[2502.17863](http://arxiv.org/abs/2502.17863)|null|
|**2025-02-24**|**X-Dancer: Expressive Music to Human Dance Video Generation**|我们展示了X-Dancer，这是一个新颖的零样本音乐驱动的图像动画管道，它从一个静态图像中创建了多样的、长距离的、逼真的人类舞蹈视频。作为其核心，我们引入了一个统一的变换器扩散框架，该框架具有一个自回归变换器模型，该模型综合了2D身体、头部和手部姿势的扩展和音乐同步令牌序列，然后引导扩散模型生成连贯逼真的舞蹈视频帧。与主要在3D中生成人体运动的传统方法不同，X-Dancer通过对各种2D舞蹈运动进行建模来解决数据限制并增强可扩展性，通过现成的单眼视频捕捉它们与音乐节拍的细微对齐。为了实现这一点，我们首先从与关键点置信度相关的2D人体姿势标签构建一个空间组合令牌表示，对大关节身体运动（如上半身和下半身）和细粒度运动（如头部和手部）进行编码。然后，我们设计了一个音乐到动作转换器模型，该模型自回归地生成与音乐对齐的舞蹈姿势令牌序列，将对音乐风格和先前动作背景的全局关注结合起来。最后，我们利用扩散骨干通过AdaIN用这些合成的姿势标记对参考图像进行动画处理，形成一个完全可微分的端到端框架。实验结果表明，X-Dancer能够制作出多样化和有特色的舞蹈视频，在多样性、表现力和真实感方面大大优于最先进的方法。代码和模型将用于研究目的。 et.al.|[2502.17414](http://arxiv.org/abs/2502.17414)|null|
|**2025-02-24**|**VideoGrain: Modulating Space-Time Attention for Multi-grained Video Editing**|扩散模型的最新进展显著提高了视频生成和编辑能力。然而，包括类级、实例级和部分级修改的多粒度视频编辑仍然是一个艰巨的挑战。多粒度编辑的主要困难包括文本与区域控制的语义不一致以及扩散模型内的特征耦合。为了解决这些困难，我们提出了VideoGrain，这是一种零样本方法，它调节时空（交叉和自）注意力机制，以实现对视频内容的细粒度控制。我们通过将每个局部提示的注意力放大到其相应的空间解纠缠区域，同时最小化交叉注意力中与无关区域的交互，来增强文本到区域的控制。此外，我们通过提高区域内意识和减少自我关注中的区域间干扰来改善特征分离。大量实验表明，我们的方法在现实世界场景中实现了最先进的性能。我们的代码、数据和演示可在https://knightyxp.github.io/VideoGrain_project_page/ et.al.|[2502.17258](http://arxiv.org/abs/2502.17258)|null|
|**2025-02-24**|**Diffusion Models for Tabular Data: Challenges, Current Progress, and Future Directions**|近年来，生成模型在各种应用中取得了显著的性能，包括图像生成、文本合成、音频创建、视频生成和数据增强。扩散模型已经成为生成对抗网络（GAN）和变分自编码器（VAE）的优越替代品，解决了它们的局限性，如训练不稳定、模式崩溃和多峰分布的表示不佳。这一成功激发了广泛的研究兴趣。在表格数据领域，扩散模型已经开始展现出与GAN和VAE类似的优势，实现了重大的性能突破，并展示了它们在解决表格数据建模中的独特挑战方面的潜力。然而，尽管图像和时间序列等领域有许多调查总结了扩散模型的进展，但表格数据的文献中仍存在显著差距。尽管人们对表格数据的扩散模型越来越感兴趣，但很少有人系统地回顾和总结这些发展。缺乏专门的调查限制了对这一关键领域的挑战、进展和未来方向的清晰理解。这项调查通过对表格数据的扩散模型进行全面审查来解决这一差距。涵盖了从2015年6月扩散模型出现到2024年12月的工作，我们分析了几乎所有相关研究，并在a\href中维护了更新{https://github.com/Diffusion-Model-Leiden/awesome-diffusion-models-for-tabular-data}｛GitHub存储库｝。假设读者具备统计学和扩散模型的基础知识，我们将采用数学公式进行严格而详细的综述，旨在促进这一新兴和令人兴奋的领域的发展。 et.al.|[2502.17119](http://arxiv.org/abs/2502.17119)|**[link](https://github.com/diffusion-model-leiden/awesome-diffusion-models-for-tabular-data)**|
|**2025-02-21**|**RIFLEx: A Free Lunch for Length Extrapolation in Video Diffusion Transformers**|视频生成的最新进展使模型能够合成高质量的分钟长视频。然而，生成具有时间连贯性的更长视频仍然是一个主要挑战，现有的长度外推方法会导致时间重复或运动减速。在这项工作中，我们系统地分析了频率分量在位置嵌入中的作用，并确定了主要控制外推行为的固有频率。基于这一认识，我们提出了RIFLEx，这是一种最小但有效的方法，可以降低固有频率以抑制重复，同时保持运动一致性，而不需要任何额外的修改。RIFLEx提供真正的免费午餐——以完全免培训的方式，在最先进的视频扩散变压器上实现高质量的2倍外推。此外，它提高了质量，并通过最小的微调实现了3倍的外推，而无需长视频。项目页面和代码：\href{https://riflex-video.github.io/}{https://riflex-video.github.io/.} et.al.|[2502.15894](http://arxiv.org/abs/2502.15894)|null|
|**2025-02-21**|**VaViM and VaVAM: Autonomous Driving through Video Generative Modeling**|我们探索了用于自动驾驶的大规模生成视频模型的潜力，引入了一个开源的自回归视频模型（VaViM）及其配套的视频动作模型（VaVAM），以研究视频预训练如何转移到现实世界的驾驶中。VaViM是一种简单的自回归视频模型，它使用时空标记序列预测帧。我们证明它捕捉到了驾驶场景的语义和动态。VaVAM是一种视频动作模型，它利用VaViM的学习表示通过模仿学习生成驾驶轨迹。这些模型共同构成了一个完整的感知到行动的管道。我们在开放和闭环驾驶场景中评估了我们的模型，揭示了基于视频的预训练对自动驾驶的前景。关键见解包括学习表示的语义丰富性、视频合成缩放的好处，以及闭环评估中模型大小、数据和安全指标之间的复杂关系。我们在以下时间发布代码和模型权重https://github.com/valeoai/VideoActionModel et.al.|[2502.15672](http://arxiv.org/abs/2502.15672)|**[link](https://github.com/valeoai/VideoActionModel)**|
|**2025-02-20**|**Hardware-Friendly Static Quantization Method for Video Diffusion Transformers**|自SORA令人印象深刻的性能以来，用于视频生成的扩散变换器引起了人们的极大研究兴趣。动态量化已经证明了在GPU上高效部署这种生成性AI模型。然而，资源受限的设备无法支持动态量化，需要对模型进行静态量化，以便在AI处理器上高效部署。在这篇论文中，我们提出了一种新的方法，用于视频扩散变换器OpenSora\cite{OpenSora}的训练后量化，而不依赖于动态量化技术。我们的方法采用静态量化，实现了与FP16和动态量化ViDiT-Q方法相当的视频质量，如CLIP和VQA度量所测量的。特别是，我们利用每一步的校准数据为每个时间步充分提供训练后的静态量化模型，对权重进行通道量化，对激活进行张量量化。通过进一步应用平滑量化技术，我们可以使用静态量化模型获得高质量的视频输出。大量的实验结果表明，静态量化可以作为视频扩散变换器动态量化的可行替代方案，在不牺牲性能的情况下提供了一种更有效的方法。 et.al.|[2502.15077](http://arxiv.org/abs/2502.15077)|null|
|**2025-02-20**|**LAVID: An Agentic LVLM Framework for Diffusion-Generated Video Detection**|生成模型在创建高质量视频方面取得的令人印象深刻的成就引发了人们对数字完整性和隐私漏洞的担忧。最近人工智能生成的内容检测工作在图像领域（如deepfake）得到了广泛的研究，但视频领域尚未得到探索。大型视觉语言模型（LVLM）因其强大的推理和多模态能力，已成为人工智能生成内容检测的新兴工具。它打破了传统基于深度学习的方法面临的缺乏透明度和无法识别新工件的局限性。受此启发，我们提出了LAVID，这是一种基于LVLM的新型人工智能生成视频检测方法，具有显式知识增强功能。我们的见解如下：（1）领先的LVLM可以调用外部工具提取有用信息，以促进其自身的视频检测任务；（2） 构建提示会影响LVLM解释视频内容中信息的推理能力。我们提出的流水线会自动选择一组显式知识工具进行检测，然后通过自重写自适应地调整结构提示。与之前训练额外检测器的SOTA不同，我们的方法完全不需要训练，只需要对LVLM进行推理即可进行检测。为了促进我们的研究，我们还创建了一个新的基准视频，其中包含从多个视频生成工具来源生成的高质量视频。评估结果显示，在我们的数据集上，LAVID在四个SOTA LVLM中使F1得分比最高基线提高了6.2%至30.2%。 et.al.|[2502.14994](http://arxiv.org/abs/2502.14994)|null|
|**2025-02-20**|**Improving the Diffusability of Autoencoders**|潜在扩散模型已成为生成高质量图像和视频的主要方法，利用压缩的潜在表示来减轻扩散过程的计算负担。虽然最近的进展主要集中在缩放扩散主干和提高自动编码器重建质量上，但这些组件之间的相互作用受到的关注相对较少。在这项工作中，我们对现代自编码器进行了频谱分析，并识别了其潜在空间中的异常高频分量，这在瓶颈信道尺寸较大的自编码器中尤为明显。我们假设这种高频分量干扰了扩散合成过程的粗到细的性质，并阻碍了生成质量。为了缓解这个问题，我们提出了尺度等变：一种简单的正则化策略，通过在解码器中强制尺度等变来跨频率对齐潜在空间和RGB空间。它只需要最少的代码更改，最多只需要20K的自动编码器微调步骤，但显著提高了生成质量，在ImageNet-1K 256x256上生成图像时，FID降低了19%，在Kinetics-700 17x256x256上的视频生成时，FVD降低了至少44%。 et.al.|[2502.14831](http://arxiv.org/abs/2502.14831)|null|

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-02-25**|**Synthesizing Consistent Novel Views via 3D Epipolar Attention without Re-Training**|大型扩散模型在单个图像的新颖视图合成中表现出显著的零样本能力。然而，这些模型在保持新颖和参考视图之间的一致性方面经常面临挑战。导致这一问题的一个关键因素是参考视图中上下文信息的利用有限。具体来说，当两个视图之间的视锥中存在重叠时，必须确保相应的区域在几何形状和外观上保持一致性。这一观察结果导致了一种简单而有效的方法，我们建议使用极线几何来定位和检索输入视图中的重叠信息。然后，这些信息被纳入目标视图的生成中，从而消除了训练或微调的需要，因为该过程不需要可学习的参数。此外，为了增强生成视图的整体一致性，我们将极线注意力的利用扩展到多视图设置，允许从输入视图和其他目标视图中检索重叠信息。定性和定量实验结果表明，我们的方法在不需要任何微调的情况下显著提高了合成视图的一致性。此外，这种增强还提高了3D重建等下游应用的性能。该代码可在以下网址获得https://github.com/botaoye/ConsisSyn. et.al.|[2502.18219](http://arxiv.org/abs/2502.18219)|null|
|**2025-02-23**|**Efficient 4D Gaussian Stream with Low Rank Adaptation**|最近的方法在合成具有长视频序列的新视图方面取得了重大进展。本文提出了一种高度可扩展的连续学习动态新视图合成方法。我们利用3D高斯分布来表示场景，并利用基于低阶自适应的变形模型来捕捉动态场景变化。我们的方法使用视频帧块连续重建动态，将流带宽减少了90%，同时保持了与离线SOTA方法相当的高渲染质量。 et.al.|[2502.16575](http://arxiv.org/abs/2502.16575)|null|
|**2025-02-24**|**Para-Lane: Multi-Lane Dataset Registering Parallel Scans for Benchmarking Novel View Synthesis**|为了评估端到端的自动驾驶系统，基于新型视图合成（NVS）技术的仿真环境至关重要，该环境在新的车辆姿态下，特别是在交叉车道场景下，从之前记录的序列中合成逼真的图像和点云。因此，开发多通道数据集和基准是必要的。虽然最近基于合成场景的NVS数据集已经为跨车道基准测试做好了准备，但它们仍然缺乏捕获图像和点云的真实感。为了进一步评估基于NeRF和3DGS的现有方法的性能，我们提出了第一个多车道数据集，该数据集专门用于记录从真实世界扫描中导出的新型驾驶视图合成数据集的并行扫描，包括25组相关序列，包括16000个正视图图像、64000个环绕视图图像和16000个激光雷达帧。所有帧都进行了标记，以区分移动对象和静态元素。使用此数据集，我们评估了现有方法在不同车道和距离的各种测试场景中的性能。此外，我们的方法为解决和评估多传感器姿态的质量提供了解决方案，用于多模态数据对齐，以便在现实世界中管理这样的数据集。我们计划不断添加新的序列，以测试现有方法在不同场景中的泛化能力。数据集在项目页面上公开发布：https://nizqleo.github.io/paralane-dataset/. et.al.|[2502.15635](http://arxiv.org/abs/2502.15635)|null|
|**2025-02-21**|**RGB-Only Gaussian Splatting SLAM for Unbounded Outdoor Scenes**|3D高斯散斑（3DGS）已成为SLAM中一种流行的解决方案，因为它可以产生高保真的新颖视图。然而，之前基于GS的方法主要针对室内场景，依赖于RGB-D传感器或预训练的深度估计模型，因此在室外场景中表现不佳。为了解决这个问题，我们提出了一种用于无界户外场景的仅RGB高斯飞溅SLAM方法——OpenGS SLAM。从技术上讲，我们首先使用点图回归网络在帧之间生成一致的点图，用于姿态估计。与常用的深度图相比，点图包括跨多个视图的空间关系和场景几何形状，从而实现了稳健的相机姿态估计。然后，我们提出将估计的相机姿态与3DGS渲染集成为端到端的可微分流水线。我们的方法实现了相机姿态和3DGS场景参数的同时优化，显著提高了系统跟踪精度。具体来说，我们还为点图回归网络设计了一个自适应比例映射器，它为3DGS图表示提供了更精确的点图映射。我们在Waymo数据集上的实验表明，OpenGS SLAM将跟踪误差降低到之前3DGS方法的9.8%，并在新的视图合成中取得了最先进的结果。项目页面：https://3dagentworld.github.io/opengs-slam/ et.al.|[2502.15633](http://arxiv.org/abs/2502.15633)|null|
|**2025-02-20**|**RendBEV: Semantic Novel View Synthesis for Self-Supervised Bird's Eye View Segmentation**|鸟瞰图（BEV）语义图作为解决辅助和自动驾驶任务的有用环境表示，最近引起了人们的广泛关注。然而，现有的大部分工作都集中在完全监督的环境中，在大型带注释的数据集上训练网络。在这项工作中，我们提出了RendBEV，这是一种用于BEV语义分割网络自监督训练的新方法，利用可微分体绘制来接收由2D语义分割模型计算的语义透视图的监督。我们的方法能够实现零样本BEV语义分割，并且已经在这种具有挑战性的环境中提供了具有竞争力的结果。当用作预训练，然后对标记的BEV地面真实值进行微调时，我们的方法显著提高了低注释状态下的性能，并在对所有可用标签进行微调时达到了新的水平。 et.al.|[2502.14792](http://arxiv.org/abs/2502.14792)|null|
|**2025-02-20**|**CDGS: Confidence-Aware Depth Regularization for 3D Gaussian Splatting**|3D高斯散斑（3DGS）在新颖的视图合成（NVS）中显示出显著的优势，特别是在实现高渲染速度和高质量结果方面。然而，由于在优化过程中缺乏明确的几何约束，其在3D重建中的几何精度仍然有限。本文介绍了CDGS，这是一种为增强3DGS而开发的具有置信度的深度正则化方法。我们利用单目深度估计的多线索置信图和运动深度稀疏结构，在优化过程中自适应地调整深度监控。我们的方法在早期训练阶段证明了改进的几何细节保存，并在NVS质量和几何精度方面取得了具有竞争力的性能。在公开的Tanks和Temples基准数据集上的实验表明，我们的方法实现了更稳定的收敛行为和更准确的几何重建结果，NVS的PSNR提高了2.31 dB，M3C2距离度量的几何误差也持续降低。值得注意的是，我们的方法仅用50%的训练迭代就达到了与原始3DGS相当的F分数。我们预计这项工作将有助于为数字孪生创建、遗产保护或林业应用等现实世界应用开发高效准确的3D重建系统。 et.al.|[2502.14684](http://arxiv.org/abs/2502.14684)|**[link](https://github.com/zqlin0521/cdgs-release)**|
|**2025-02-20**|**Exploiting Deblurring Networks for Radiance Fields**|在本文中，我们提出了DeepDeblurRF，这是一种新的辐射场去模糊方法，可以从模糊的训练视图中合成高质量的新视图，大大缩短训练时间。DeepDeblurRF利用基于深度神经网络（DNN）的去模糊模块来享受其去模糊性能和计算效率。为了有效地结合基于DNN的去模糊和辐射场构造，我们提出了一种新的辐射场（RF）引导的去模糊方法和一种迭代框架，该框架以交替的方式执行RF引导的去雾和辐射场构建。此外，DeepDeblurRF与各种场景表示兼容，如体素网格和3D高斯分布，从而扩展了其适用性。我们还介绍了BlurRF Synth，这是第一个用于训练辐射场去模糊框架的大规模合成数据集。我们对相机运动模糊和散焦模糊进行了广泛的实验，证明DeepDeblurRF在显著减少训练时间的情况下实现了最先进的新颖视图合成质量。 et.al.|[2502.14454](http://arxiv.org/abs/2502.14454)|null|
|**2025-02-19**|**Inter3D: A Benchmark and Strong Baseline for Human-Interactive 3D Object Reconstruction**|隐式3D重建方法的最新进展，例如神经渲染场和高斯飞溅，主要集中在具有连续运动状态的静态或动态对象的新颖视图合成上。然而，这些方法很难有效地对具有n个可移动部分的人类交互对象进行建模，需要2^n个单独的模型来表示所有离散状态。为了克服这一局限性，我们提出了Inter3D，这是一种新的基准和方法，用于人类交互对象的新型状态合成。我们引入了一个自收集的数据集，其中包含常见的交互对象和一个新的评估管道，在训练过程中只观察到单个零件状态，而零件组合状态则保持不可见。我们还提出了一种强大的基线方法，该方法利用空间差异张量来有效地对对象的所有状态进行建模。为了减轻训练状态对相机轨迹的不切实际的限制，我们提出了一种相互状态正则化机制，以提高可移动部分的空间密度一致性。此外，我们探索了两种占用网格采样策略，以提高训练效率。我们对拟议的基准进行了广泛的实验，展示了任务的挑战和我们方法的优越性。 et.al.|[2502.14004](http://arxiv.org/abs/2502.14004)|**[link](https://github.com/Inter3D-ui/Inter3D)**|
|**2025-02-19**|**Betsu-Betsu: Multi-View Separable 3D Reconstruction of Two Interacting Objects**|从多视图RGB图像中分离出多个对象的3D重建仍然是一个研究较少的问题，这会导致两个对象具有两种不同的3D形状，并且它们之间有明显的分离。由于对象交互边界上存在严重的相互遮挡和模糊性，这是一项具有挑战性的任务。本文研究了这种设置，并介绍了一种新的神经隐式方法，该方法可以重建两个正在进行密切交互的物体的几何形状和外观，同时在3D中分离这两个物体，避免表面相互穿透，并实现观察场景的新视图合成。该框架是端到端可训练的，并使用一种新颖的阿尔法混合正则化进行监督，确保即使在极端遮挡下，两种几何形状也能很好地分离。我们的重建方法是无标记的，可以应用于刚性和铰接物体。我们引入了一个新的数据集，该数据集由人类和物体之间的密切互动组成，并对人类表演武术的两个场景进行了评估。实验证实了我们的框架的有效性，并且与我们环境中适用的几种现有方法相比，使用3D和新颖的视图合成度量进行了实质性的改进。 et.al.|[2502.13968](http://arxiv.org/abs/2502.13968)|null|
|**2025-02-18**|**GS-QA: Comprehensive Quality Assessment Benchmark for Gaussian Splatting View Synthesis**|高斯散斑（GS）为实时3D场景渲染提供了神经辐射场（NeRF）的有前景的替代方案。与NeRF中使用的神经网络方法相比，GS使用一组3D高斯来表示复杂的几何形状和外观，实现了更快的渲染时间和更低的内存消耗。然而，GS生成的静态内容的质量评估尚未得到深入探讨。本文描述了一项主观质量评估研究，旨在评估用几种静态GS最先进方法获得的合成视频。这些方法被应用于各种视觉场景，涵盖了360度和前向（FF）相机轨迹。此外，使用主观研究得出的分数分析了18个客观质量指标的表现，深入了解了它们的优势、局限性以及与人类感知的一致性。所有视频和分数都是可用的，提供了一个全面的数据库，可以用作GS视图合成和客观质量指标的基准。 et.al.|[2502.13196](http://arxiv.org/abs/2502.13196)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-02-25**|**Table-top three-dimensional photoemission orbital tomography with a femtosecond extreme ultraviolet light source**|在量子力学电子波函数水平上跟踪分子和材料中的电子过程，具有埃级的空间分辨率，并完全可以访问其飞秒时间动力学，这是超快凝聚态物理学的核心。一项允许实验获取电子波函数的突破性发明是2009年根据角分辨光电子能谱数据重建分子轨道，称为光电发射轨道断层扫描（POT）。本发明使超快三维（3D）POT触手可及，为超快光物质相互作用、飞秒化学和光诱导相变的研究带来了许多新的前景。在这里，我们开发了一种协同实验算法方法，使用短脉冲极紫外光源实现了第一个3D-POT实验。我们将光电子能谱的一种新变体，即超快动量显微镜，与台式光谱可调高次谐波产生光源和量身定制的算法相结合，用于从稀疏、欠采样的数据中高效地进行3D重建。这种组合大大加快了实验数据采集的速度，同时降低了实现完整3D信息的采样要求。我们通过对原始Ag（110）上吸收的原型有机半导体的前线轨道进行全3D成像，展示了这种方法的强大功能。 et.al.|[2502.18269](http://arxiv.org/abs/2502.18269)|null|
|**2025-02-25**|**Synthesizing Consistent Novel Views via 3D Epipolar Attention without Re-Training**|大型扩散模型在单个图像的新颖视图合成中表现出显著的零样本能力。然而，这些模型在保持新颖和参考视图之间的一致性方面经常面临挑战。导致这一问题的一个关键因素是参考视图中上下文信息的利用有限。具体来说，当两个视图之间的视锥中存在重叠时，必须确保相应的区域在几何形状和外观上保持一致性。这一观察结果导致了一种简单而有效的方法，我们建议使用极线几何来定位和检索输入视图中的重叠信息。然后，这些信息被纳入目标视图的生成中，从而消除了训练或微调的需要，因为该过程不需要可学习的参数。此外，为了增强生成视图的整体一致性，我们将极线注意力的利用扩展到多视图设置，允许从输入视图和其他目标视图中检索重叠信息。定性和定量实验结果表明，我们的方法在不需要任何微调的情况下显著提高了合成视图的一致性。此外，这种增强还提高了3D重建等下游应用的性能。该代码可在以下网址获得https://github.com/botaoye/ConsisSyn. et.al.|[2502.18219](http://arxiv.org/abs/2502.18219)|null|
|**2025-02-24**|**Laplace-Beltrami Operator for Gaussian Splatting**|随着3D高斯散点的日益普及以及从渲染到3D重建的应用范围的扩大，也需要直接在这种新表示上进行几何处理应用。虽然将高斯中心视为点云或对其进行网格划分是允许应用现有算法的一种选择，但这可能会忽略数据中存在的信息或不必要地昂贵。此外，高斯飞溅往往包含大量异常值，这些异常值不会影响渲染质量，但需要正确处理，以免在几何处理应用程序中产生噪声结果。在这项工作中，我们提出了一个公式来计算拉普拉斯-贝尔特拉米算子，这是几何处理中广泛使用的工具，直接使用马氏距离在高斯溅射上计算。虽然在概念上类似于点云拉普拉斯算子，但我们的实验表明，在高斯飞溅中心编码的点云上具有更高的精度，此外，该算子可用于评估优化过程中的输出质量。 et.al.|[2502.17531](http://arxiv.org/abs/2502.17531)|null|
|**2025-02-24**|**Graph-Guided Scene Reconstruction from Images with 3D Gaussian Splatting**|本文研究了从图像重建高质量、大型3D开放场景的开放性研究挑战。据观察，现有的方法有各种局限性，例如需要精确的相机姿态进行输入，需要密集的视点进行监督。为了进行有效和高效的3D场景重建，我们提出了一种新的图引导3D场景重建框架GraphGS。具体来说，给定场景上RGB相机捕获的一组图像，我们首先设计了一种基于空间先验的场景结构估计方法。然后，这将用于创建包含有关相机拓扑信息的相机图。此外，我们建议将图引导的多视图一致性约束和自适应采样策略应用于3D高斯散斑优化过程。这大大缓解了高斯点对特定稀疏视点过拟合的问题，并加快了3D重建过程。我们证明GraphGS能够从图像中实现高保真度的3D重建，通过对多个数据集进行定量和定性评估，展现出最先进的性能。项目页面：https://3dagentworld.github.io/graphgs. et.al.|[2502.17377](http://arxiv.org/abs/2502.17377)|null|
|**2025-02-25**|**MegaLoc: One Retrieval to Place Them All**|从给定查询的同一位置检索图像是多个计算机视觉任务的重要组成部分，如视觉位置识别、地标检索、视觉定位、3D重建和SLAM。然而，现有的解决方案是专门为其中一项任务而构建的，当需求略有变化或满足分布外数据时，已知会失败。在本文中，我们结合了各种现有的方法、训练技术和数据集来训练一个名为MegaLoc的检索模型，该模型可在多个任务上运行。我们发现，MegaLoc（1）在大量视觉位置识别数据集上达到了最先进的水平，（2）在常见的地标检索数据集上取得了令人印象深刻的结果，（3）在LaMAR数据集上为视觉定位设定了新的水平，我们只将检索方法更改为现有的定位管道。MegaLoc的代码可在以下网址获得https://github.com/gmberton/MegaLoc et.al.|[2502.17237](http://arxiv.org/abs/2502.17237)|**[link](https://github.com/gmberton/megaloc)**|
|**2025-02-25**|**PointSea: Point Cloud Completion via Self-structure Augmentation**|点云完成是三维视觉中一个基本但尚未得到很好解决的问题。当前的方法通常依赖于3D坐标信息和/或附加数据（例如图像和扫描视点）来填充缺失的部分。与这些方法不同，我们探索了自结构增强，并提出了PointSea用于全局到局部点云的完成。在全球阶段，考虑我们如何检查物理对象的缺陷区域，我们可以从不同的角度观察它，以便更好地理解。受此启发，PointSea通过利用来自多个视图的自投影深度图像来增强数据表示。为了从交叉模态输入中重建紧凑的全局形状，我们引入了一个特征融合模块，在视图内和视图间级别融合特征。在局部阶段，为了揭示高度详细的结构，我们引入了一种称为自结构对偶生成器的点生成器。该生成器集成了学习到的形状先验和几何自相似性，用于形状细化。与对所有点应用统一策略的现有努力不同，我们的双路径设计采用了基于每个点的结构类型的细化策略，解决了每个点的特定不完整性。在广泛使用的基准上进行的综合实验表明，PointSea能够有效地理解全局形状，并从不完整的输入中生成局部细节，与现有方法相比有了明显的改进。 et.al.|[2502.17053](http://arxiv.org/abs/2502.17053)|null|
|**2025-02-24**|**Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain Model**|由于多视图几何的复杂性，从多视角图像进行房间布局估计的研究很少，这需要多步解决方案，如相机内外估计、图像匹配和三角测量。然而，在3D重建中，最近的3D基础模型（如DUSt3R）的进步已经将传统的多步结构从运动过程转变为端到端的单步方法。为此，我们介绍了Plane-DUSt3R}，这是一种利用3D基础模型DUSt3R进行多视图房间布局估计的新方法。Plane-DUSt3R整合了DUSt3R框架，并对房间布局数据集（Structure3D）进行了微调，修改了目标以估计结构平面。通过生成均匀和简约的结果，Plane-DUSt3R仅需一个后处理步骤和2D检测结果即可实现房间布局估计。与之前依赖于单视角或全景图像的方法不同，Plane-DUSt3R扩展了设置以处理多视角图像。此外，它还提供了一个简化的端到端解决方案，简化了流程并减少了错误累积。实验结果表明，Plane-DUSt3R不仅在合成数据集上优于最先进的方法，而且在具有不同图像风格（如卡通）的野外数据上也证明了其鲁棒性和有效性。 et.al.|[2502.16779](http://arxiv.org/abs/2502.16779)|null|
|**2025-02-21**|**RGB-Only Gaussian Splatting SLAM for Unbounded Outdoor Scenes**|3D高斯散斑（3DGS）已成为SLAM中一种流行的解决方案，因为它可以产生高保真的新颖视图。然而，之前基于GS的方法主要针对室内场景，依赖于RGB-D传感器或预训练的深度估计模型，因此在室外场景中表现不佳。为了解决这个问题，我们提出了一种用于无界户外场景的仅RGB高斯飞溅SLAM方法——OpenGS SLAM。从技术上讲，我们首先使用点图回归网络在帧之间生成一致的点图，用于姿态估计。与常用的深度图相比，点图包括跨多个视图的空间关系和场景几何形状，从而实现了稳健的相机姿态估计。然后，我们提出将估计的相机姿态与3DGS渲染集成为端到端的可微分流水线。我们的方法实现了相机姿态和3DGS场景参数的同时优化，显著提高了系统跟踪精度。具体来说，我们还为点图回归网络设计了一个自适应比例映射器，它为3DGS图表示提供了更精确的点图映射。我们在Waymo数据集上的实验表明，OpenGS SLAM将跟踪误差降低到之前3DGS方法的9.8%，并在新的视图合成中取得了最先进的结果。项目页面：https://3dagentworld.github.io/opengs-slam/ et.al.|[2502.15633](http://arxiv.org/abs/2502.15633)|null|
|**2025-02-21**|**A deep learning-based noise correction method for light-field fluorescence microscopy**|光场显微镜（LFM）通过单帧采集和快速3D重建算法实现了快速体积成像。LFM的高速和低光毒性使其非常适合实时3D荧光成像，如神经活动监测和血流分析的研究。然而，在体内荧光成像场景中，需要尽可能降低光强度以实现长期观察。光强度降低导致的低信噪比（SNR）显著降低了LFM中3D重建的质量。现有的基于深度学习的方法难以结合LFM数据固有的结构化强度分布和噪声特性，这通常会导致伪影和不均匀的能量分布。为了应对这些挑战，我们提出了去噪加权视图通道深度（DNW-VCD）网络，将两步噪声模型和能量权重矩阵集成到LFM重建框架中。此外，我们还开发了一种用于双信噪比图像采集的衰减器诱导成像系统，以验证DNW VCD的性能。实验结果表明，我们的方法实现了伪影减少的实时3D成像，具有各向同性分辨率和较低的光毒性，通过荧光珠、藻类和斑马鱼心脏的成像得到了验证。 et.al.|[2502.15259](http://arxiv.org/abs/2502.15259)|null|
|**2025-02-20**|**Planning, scheduling, and execution on the Moon: the CADRE technology demonstration mission**|美国国家航空航天局的合作自主分布式机器人探索（CADRE）任务计划于2025/2026年飞往月球的雷纳伽马地区，旨在演示月球表面和次表面的多智能体自主探索。一个由三个机器人和一个基站组成的团队将自主探索着陆器附近的区域，在没有人为输入的情况下收集表面三维重建所需的数据；然后使用多基地探地雷达（GPR）自主执行分布式传感，在执行协调雷达探测的同时进行编队驾驶，以创建地下地图。CADRE软件架构的核心是一个新型的自主分布式规划、调度和执行（PS&E）系统。该系统协调机器人的活动，规划和执行需要多个机器人参与的任务，同时确保每个机器人的热量和电力资源保持在规定的范围内，并遵守地面规定的睡眠-觉醒周期。该系统使用集中式规划、分布式执行范式，领导者选举机制确保了对单个代理故障的鲁棒性。本文描述了CADRE PS&E系统的体系结构；讨论其设计原理；并报告该系统在CADRE硬件上的验证和确认（V&V）测试，为在月球上部署做准备。 et.al.|[2502.14803](http://arxiv.org/abs/2502.14803)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-02-25**|**K-LoRA: Unlocking Training-Free Fusion of Any Subject and Style LoRAs**|最近的研究探索了将不同的LoRA结合起来，共同生成学习风格和内容。然而，现有的方法要么无法同时有效地保留原始主题和风格，要么需要额外的训练。本文认为，LoRA的内在特性可以有效地指导扩散模型融合学习主题和风格。基于这一认识，我们提出了K-LoRA，这是一种简单而有效的无需训练的LoRA融合方法。在每个注意力层中，K-LoRA比较每个要融合的LoRA中的Top-K元素，确定选择哪个LoRA进行最佳融合。这种选择机制确保在融合过程中保留了主题和风格中最具代表性的特征，有效地平衡了它们的贡献。实验结果表明，所提出的方法有效地整合了原始LoRA学习到的主题和风格信息，在定性和定量结果方面都优于最先进的基于训练的方法。 et.al.|[2502.18461](http://arxiv.org/abs/2502.18461)|null|
|**2025-02-25**|**Broadband surface phonon spectroscopy by time-domain extreme ultraviolet diffuse scattering**|我们提出了实验证据，证明波长从几十到几百纳米的表面声波的动力学是在极紫外光的时间依赖扩散散射中编码的。通过测量超快光学激发后表面的扩散散射，我们确定了各种样品中表面声波包在宽范围波矢量上的色散关系。比较不同表面形态样品的信号振幅表明，潜在的激发机制与样品表面的自然粗糙度有关。这种简单且非接触式的方法是瞬态光栅或布里渊光谱的补充实验工具，为纳米级表面动力学提供了有价值的见解。 et.al.|[2502.18445](http://arxiv.org/abs/2502.18445)|null|
|**2025-02-25**|**ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies**|在本文中，我们提出了ToMCAT（团队中合作代理的心理理论），这是一个生成ToM条件轨迹的新框架。它结合了一种元学习机制，对队友的潜在目标和未来行为进行ToM推理，以及一种多智能体去噪扩散模型，该模型根据智能体的目标和队友的特征为智能体及其队友生成计划，通过ToM计算。我们实现了一个在线规划系统，该系统在检测到先前生成的计划与当前世界状态之间的差异时，从扩散模型中动态采样新的轨迹（重计划）。我们在模拟烹饪领域使用ToMCAT进行了几个实验。我们的研究结果强调了动态重新规划机制在减少资源使用而不牺牲团队绩效方面的重要性。我们还表明，代理人在事件过程中收集的关于世界和队友行为的最新观察结果，结合ToM推理，对于制定团队意识计划以动态适应队友至关重要，尤其是在没有提供关于他们的先验信息的情况下。 et.al.|[2502.18438](http://arxiv.org/abs/2502.18438)|null|
|**2025-02-25**|**Single file dynamics of tethered random walkers**|我们考虑在一维中以扩散率 $D$移动的$N$相同随机步行者的单文件动力学（步行者在试图超车时相互反弹）。此外，我们要求相邻步行者之间的间距不能超过阈值$\Delta$，因此称之为“系留步行者”（它们的行为就像被绳子束缚一样，当达到最大长度$\Delta$时，绳子会完全收紧）。对于有限的$\Delta$，我们研究了扩散弛豫到平衡态，并对后者进行了表征[长时间弛豫是指数的，特征时间为$（N\Delta）^2/D$]。特别是，我们对$N$-粒子概率分布的近似方法得出了中心和边缘粒子的单粒子分布函数[前两个位置矩以$\Delta/\sqrt{4Dt}$的幂展开形式给出]。对于$N=2$，我们找到了一个精确解（在连续体和晶格上），并用它来测试我们对单粒子分布、位置矩和相关性的近似值。对于有限的$\Delta$和任意的$N$，边缘粒子以有效的长时间扩散率$D/N$移动，这与$\Delta=\infty$时观察到的$1/\ln（N）$行为形成鲜明对比。最后，我们计算了平衡系统长度和相关熵的概率分布。我们发现，将该长度改变给定量所需的力在该量中是线性的，（熵）弹簧常数为$6k_BT/（N\Delta^2）$ 。在这方面，该系统表现得像一种理想的聚合物。我们的主要分析结果得到了蒙特卡洛模拟的证实。 et.al.|[2502.18402](http://arxiv.org/abs/2502.18402)|null|
|**2025-02-25**|**No-slip, slip and friction at fluid-solid interfaces: Concept of adsorption layer**|当流体接触固体表面时，它可以扩散或滑动，接触线的运动涉及流体动力学和热力学效应之间的复杂相互作用。流体力学理论，如Huh&Scriven和Cox&Voinov模型，假设滑动边界条件，忽略了流固界面处的宏观流体滑动。然而，他们无法解释液滴扩散过程中的接触线运动，而热力学理论将其归因于流体分子的微观表面扩散。为了弥合这些观点，我们通过采用能量最小化原理来建立流固接触区域固液摩擦、热力学力和粘性应力之间的力平衡，从而关注滑移现象的物理起源。我们的分析表明，滑移是一种内在性质，就像分子表面扩散一样，也受流固分子间相互作用的控制。基于我们的滑移模型，我们通过引入摩擦来扩展经典的Huh&Scriven和Cox&Voinov理论，从而能够更全面地理解液滴滑移和动力学诱导的接触角滞后（CAH）。我们的研究结果表明，固液摩擦在基材和液滴之间的动量传递中起着至关重要的作用，因此，在润湿过程中，液滴内部的流体流动会发生剧烈变化。在强摩擦下，经典的CAH润湿预测得以恢复，而弱摩擦抑制了内部流体运动，导致CAH消失。这些发现为润湿动力学提供了新的见解，突出了摩擦在滑动行为中的重要性。这项工作对液滴传输、表面工程以及微流体和涂层中的应用具有广泛的影响。 et.al.|[2502.18380](http://arxiv.org/abs/2502.18380)|null|
|**2025-02-25**|**Mechanistic PDE Networks for Discovery of Governing Equations**|我们提出了机械PDE网络——一种从数据中发现控制偏微分方程的模型。机械PDE网络将时空数据表示为神经网络隐藏表示中的时空相关线性偏微分方程。然后，针对特定任务求解和解码所表示的PDE。学习到的PDE表示自然地表达了神经网络隐藏空间中数据的时空动态，从而提高了动态建模的能力。然而，以计算和内存高效的方式解决PDE表示是一个重大挑战。我们开发了一个原生的、支持GPU的、并行的、稀疏的和可微的多重网格求解器，专门用于线性偏微分方程，它充当机械PDE网络中的一个模块。利用PDE求解器，我们提出了一种发现架构，可以在复杂环境中发现非线性PDE，同时对噪声具有鲁棒性。我们在许多PDE上验证了PDE的发现，包括反应扩散和Navier-Stokes方程。 et.al.|[2502.18377](http://arxiv.org/abs/2502.18377)|null|
|**2025-02-25**|**GCDance: Genre-Controlled 3D Full Body Dance Generation Driven By Music**|从音乐中生成高质量的全身舞蹈序列是一项具有挑战性的任务，因为它需要严格遵守特定流派的编舞。此外，生成的序列必须在物理上逼真，并与音乐的节拍和节奏精确同步。为了克服这些挑战，我们提出了GCDance，这是一个无分类器的传播框架，用于生成基于音乐和文本提示的特定流派舞蹈动作。具体来说，我们的方法通过将高级预训练的音乐基础模型特征与手工制作的特征相结合来提取音乐特征，以实现多粒度特征融合。为了实现流派可控性，我们利用CLIP在舞蹈生成管道的每个时间步高效地嵌入基于流派的文本提示表示。我们的GCDance框架可以从同一首音乐中生成不同的舞蹈风格，同时确保与音乐的节奏和旋律保持一致。在FineDance数据集上获得的广泛实验结果表明，GCDance明显优于现有的最先进方法，这些方法在AIST++数据集上也取得了有竞争力的结果。我们的消融和推理时间分析表明，GCDance为高质量的音乐驱动舞蹈生成提供了一种有效的解决方案。 et.al.|[2502.18309](http://arxiv.org/abs/2502.18309)|null|
|**2025-02-25**|**Water Nucleation via Transient Bonds to Oxygen Functionalized Graphite**|我们结合低温扫描隧道显微镜（LT-STM）和机器学习结构搜索，研究了原始和氧官能化高取向热解石墨（O-HOPG）上冰生长的初始阶段。LT-STM图像显示，氧原子充当冰生长的成核位点，纳米级冰团的大小、结构和孔隙率强烈依赖于生长温度。机器学习辅助的结构搜索和第一性原理能量计算证实，水分子簇很可能通过氢键与化学吸附的氧原子结合。在团簇生长的早期阶段，水分子团簇很可能通过氢键与多个化学吸附的氧原子结合而固定。然而，当分子结合到仅与单个氧原子结合的较小团簇中时，分子氢键形成的能量增益足以诱导团簇扩散，并有利于较大冰团的生长。我们的结果表明，在表面存在缺陷的情况下，水分子的流动性显著降低。本文所呈现的缺陷碳上观察到的较低迁移率，加深了对功能化HOPG在环境条件下观察到的宏观防冰性能的理解，并提供了对星际空间尘埃颗粒表面冰生长早期阶段的洞察。 et.al.|[2502.18306](http://arxiv.org/abs/2502.18306)|null|
|**2025-02-25**|**LDGen: Enhancing Text-to-Image Synthesis via Large Language Model-Driven Language Representation**|本文介绍了LDGen，这是一种将大型语言模型（LLM）集成到现有文本到图像扩散模型中的新方法，同时最大限度地减少了计算需求。传统的文本编码器，如CLIP和T5，在多语言处理方面表现出局限性，阻碍了跨不同语言的图像生成。我们通过利用LLM的先进功能来应对这些挑战。我们的方法采用了一种语言表示策略，该策略应用了分层字幕优化和人工指令技术来获取精确的语义信息，。随后，我们结合了一个轻量级适配器和一个跨模式细化器，以促进LLM和图像特征之间的有效特征对齐和交互。LDGen减少了训练时间，并支持零样本多语言图像生成。实验结果表明，我们的方法在即时依从性和图像美学质量方面都优于基线模型，同时无缝支持多种语言。项目页面：https://zrealli.github.io/LDGen. et.al.|[2502.18302](http://arxiv.org/abs/2502.18302)|null|
|**2025-02-25**|**Improved amplitude amplification strategies for the quantum simulation of classical transport problems**|经典流体的量子模拟通常涉及使用概率算法，以所选量子态的振幅形式对动力学结果进行编码。然而，在大多数情况下，振幅概率太低，无法有效使用这些算法，从而阻碍了量子模拟的实际可行性。遗忘振幅放大算法通常被提出作为解决这个问题的方法，但对于大多数经典问题都没有用，因为它的适用性仅限于酉动力学。在本文中，我们分析地表明，当应用于非幺正动力学时，不经意的振幅放大会导致量子态的失真，并在量子更新中产生相应的误差。我们提供了这种误差的分析上限，作为动力学非统一程度的函数，并用平流扩散反应方程的量子模拟对其进行了测试，这是一个在科学和工程中具有重要意义的输运问题。最后，我们还提出了一种放大策略，有助于减轻失真误差，同时仍然确保提高成功概率。 et.al.|[2502.18283](http://arxiv.org/abs/2502.18283)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-02-20**|**MedFuncta: Modality-Agnostic Representations Based on Efficient Neural Fields**|最近关于深度学习医学图像分析的研究几乎完全集中在基于网格或体素的数据表示上。我们通过引入MedFuncta来挑战这一常见选择，MedFuncta是一种基于神经场的模态无关连续数据表示。我们演示了如何通过利用医学信号中的冗余以及应用具有上下文缩减方案的高效元学习方法，将神经场从单个实例扩展到大型数据集。我们通过引入 $\omega_0$ -调度，提高重建质量和收敛速度，进一步解决了常用SIREN激活中的光谱偏差问题。我们在各种不同维度和模式的医学信号上验证了我们提出的方法（1D：心电图；2D：胸部X射线、视网膜OCT、眼底照相机、皮肤镜、结肠组织病理学、细胞显微镜；3D：脑MRI、肺CT），并成功证明我们可以解决这些表示的相关下游任务。我们还发布了一个超过550k个带注释神经场的大规模数据集，以促进这方面的研究。 et.al.|[2502.14401](http://arxiv.org/abs/2502.14401)|**[link](https://github.com/pfriedri/medfuncta)**|
|**2025-02-15**|**Implicit Neural Representations of Molecular Vector-Valued Functions**|分子有各种计算表示，包括数值描述符、字符串、图形、点云和曲面。每种表示方法都可以应用各种机器学习方法，从线性回归到与大型语言模型配对的图神经网络。为了补充现有的表示，我们通过向量值函数或n维向量场引入分子的表示，这些向量值函数由神经网络参数化，我们称之为分子神经场。与表面表征不同，分子神经场捕获蛋白质等大分子的外部特征和疏水核心。与离散图或点表示相比，分子神经场结构紧凑，分辨率无关，天生适合在空间和时间维度上进行插值。分子神经场继承的这些特性适用于包括基于所需形状、结构和组成生成分子，以及空间和时间中分子构象之间分辨率无关的插值在内的任务。在这里，我们为分子神经场提供了一个框架和概念证明，即使用自动解码器架构对蛋白质-配体复合物进行参数化和超分辨率重建，以及使用自动编码器架构将分子体积嵌入潜在空间。 et.al.|[2502.10848](http://arxiv.org/abs/2502.10848)|**[link](https://github.com/daenuprobst/minf)**|
|**2025-02-05**|**Poisson Hypothesis and large-population limit for networks of spiking neurons**|我们研究了具有随机尖峰时间的线性（泄漏）和二次积分和放电神经元的空间扩展网络的平均场描述。我们考虑了具有线性和二次内在动力学的连续时间Galves-L“ocherbach（GL）网络的大种群极限。我们证明了泊松假设适用于这些网络的复制平均场极限，即在适当定义的极限内，神经元是独立的，相互作用时间被强度取决于平均放电率的独立时间非均匀泊松过程所取代，将已知结果扩展到具有二次内在动态和重置的网络。证明泊松假设成立为研究这些网络中的大种群限值开辟了可能性。我们证明这个极限是一个适定的神经场模型，受随机重置的影响。 et.al.|[2502.03379](http://arxiv.org/abs/2502.03379)|null|
|**2025-02-04**|**Geometric Neural Process Fields**|本文解决了神经场（NeF）泛化的挑战，其中模型必须有效地适应仅给出少量观测值的新信号。为了解决这个问题，我们提出了几何神经过程场（G-NPF），这是一个明确捕捉不确定性的神经辐射场的概率框架。我们将NeF泛化表述为概率问题，从而能够从有限的上下文观测中直接推断出NeF函数分布。为了引入结构归纳偏差，我们引入了一组几何基来编码空间结构，并促进NeF函数分布的推断。在此基础上，我们设计了一个分层潜在变量模型，使G-NPF能够整合多个空间层次的结构信息，并有效地参数化INR函数。这种分层方法提高了对新场景和未知信号的泛化能力。针对3D场景的新颖视图合成以及2D图像和1D信号回归的实验证明了我们的方法在捕捉不确定性和利用结构信息提高泛化能力方面的有效性。 et.al.|[2502.02338](http://arxiv.org/abs/2502.02338)|null|
|**2025-02-05**|**A Poisson Process AutoDecoder for X-ray Sources**|钱德拉X射线天文台和eROSITA等X射线观测设施已经探测到数百万个与高能现象相关的天文源。光子的到达作为时间的函数遵循泊松过程，并且可以按数量级变化，这为源分类、物理性质推导和异常检测等常见任务带来了障碍。之前的工作要么未能直接捕捉数据的泊松性质，要么只关注泊松率函数重建。在这项工作中，我们提出了泊松过程自动解码器（PPAD）。PPAD是一种神经场解码器，通过无监督学习将固定长度的潜在特征映射到跨能带和时间的连续泊松率函数。PPAD重建速率函数并同时产生表示。我们使用钱德拉源目录通过重建、回归、分类和异常检测实验证明了PPAD的有效性。 et.al.|[2502.01627](http://arxiv.org/abs/2502.01627)|null|
|**2025-02-03**|**Regularized interpolation in 4D neural fields enables optimization of 3D printed geometries**|精确生产具有特定特性的几何形状的能力可能是制造过程中最重要的特征。3D打印具有非凡的设计自由度和复杂性，但也容易出现几何和其他缺陷，必须解决这些缺陷才能充分发挥其潜力。最终，这将需要精明的设计决策和及时的参数调整来保持稳定性，即使是专业的人类操作员也很难做到这一点。虽然机器学习在3D打印中得到了广泛的研究，但现有的方法通常会忽略不同打印的空间特征，因此很难产生所需的几何形状。在这里，我们将打印部件的体积表示编码到神经场中，并应用一种新的正则化策略，该策略基于最小化场输出相对于单个不可学习参数的偏导数。因此，通过鼓励小的输入变化只产生小的输出变化，我们鼓励在观测体积之间进行平滑插值，从而实现现实的几何预测。因此，该框架允许提取“想象的”3D形状，揭示了在以前看不见的参数下制造的零件的外观。由此产生的连续场用于数据驱动优化，以最大限度地提高预期和生产几何形状之间的几何保真度，减少后处理、材料浪费和生产成本。通过动态优化工艺参数，我们的方法实现了先进的规划策略，有可能使制造商更好地实现复杂和功能丰富的设计。 et.al.|[2502.01517](http://arxiv.org/abs/2502.01517)|**[link](https://github.com/cam-cambridge/4d-neural-fields-optimise-3d-printing)**|
|**2025-02-03**|**Modelling change in neural dynamics during phonetic accommodation**|短期语音调节是口音变化背后的基本驱动力，但来自另一个说话者声音的实时输入是如何塑造对话者的语音规划表示的？我们基于运动规划和记忆动力学的动态神经场方程，提出了一种语音调节过程中语音表征变化的计算模型。我们测试了该模型从实验研究中捕捉经验模式的能力，在实验研究中，说话者用与自己不同的口音跟踪模型说话者。实验数据显示了阴影期间元音特定的收敛程度，随后在阴影后恢复到基线（或轻微发散）。该模型可以通过调节抑制性记忆动力学的大小来再现这些现象，这可能反映了由于语音和/或社会语言压力导致的对调节的抵抗。我们讨论了这些结果对短期语音调节和长期声音变化模式之间关系的影响。 et.al.|[2502.01210](http://arxiv.org/abs/2502.01210)|null|
|**2025-02-02**|**Lifting the Winding Number: Precise Representation of Complex Cuts in Subspace Physics Simulations**|切割薄壁可变形结构在日常生活中很常见，但由于引入了空间不连续性，给模拟带来了重大挑战。传统方法依赖于基于网格的域表示，这需要频繁的重新网格划分和细化，以准确捕捉不断变化的不连续性。这些挑战在缩减空间模拟中进一步加剧，在这种模拟中，基函数固有地依赖于几何和网格，使得基难以甚至不可能表示切割引入的各种不连续性。用神经场表示基函数的最新进展提供了一种有前景的替代方案，利用其离散化不可知的性质来表示不同几何形状的变形。然而，神经场的固有连续性阻碍了泛化，特别是在神经网络权重中编码了不连续性的情况下。我们提出了Wind-Lifter，这是一种新的神经表示，旨在精确模拟薄壁可变形结构中的复杂切割。我们的方法构建神经场，在指定位置精确再现不连续性，而无需在切割线的位置烘烤。至关重要的是，我们的方法没有将不连续性嵌入神经网络的权重中，为切割位置的泛化开辟了道路。我们的方法实现了实时仿真速度，并支持在仿真过程中动态更新切割线几何形状。此外，不连续性的显式表示使我们的神经场易于控制和编辑，与传统的神经场相比具有显著的优势，在传统的神经场内，不连续被嵌入网络的权重中，并支持依赖于一般切割位置的新应用。 et.al.|[2502.00626](http://arxiv.org/abs/2502.00626)|null|
|**2025-01-31**|**Lifting by Gaussians: A Simple, Fast and Flexible Method for 3D Instance Segmentation**|我们介绍了一种新的三维高斯散斑辐射场（3DGS）开放世界实例分割方法——高斯提升（LBG）。最近，3DGS场已经成为基于神经场的高质量新视图合成方法的高效和明确的替代方案。我们的3D实例分割方法直接从SAM（或FastSAM等）中提取2D分割掩模，以及CLIP和DINOv2的特征，直接将它们融合到3DGS（或类似的高斯辐射场，如2DGS）上。与以前的方法不同，LBG不需要每个场景的训练，使其能够在任何现有的3DGS重建上无缝运行。我们的方法不仅比现有方法快一个数量级，而且更简单；它也是高度模块化的，能够对现有的3DGS字段进行3D语义分割，而不需要对3D高斯进行特定的参数化。此外，我们的技术在保持灵活性和效率的同时，为2D语义新颖视图合成和3D资产提取结果实现了卓越的语义分割。我们进一步介绍了一种从3D辐射场分割方法中评估单独分割的3D资产的新方法。 et.al.|[2502.00173](http://arxiv.org/abs/2502.00173)|null|
|**2025-01-30**|**Zero-Shot Novel View and Depth Synthesis with Multi-View Geometric Diffusion**|从稀疏姿态图像重建3D场景的当前方法采用中间3D表示，如神经场、体素网格或3D高斯，以实现多视图一致的场景外观和几何形状。本文介绍了MVGD，这是一种基于扩散的架构，能够在给定任意数量的输入视图的情况下，从新的视点直接生成像素级的图像和深度图。我们的方法使用光线图调节来增强来自不同视点的空间信息的视觉特征，并指导从新视图生成图像和深度图。我们方法的一个关键方面是图像和深度图的多任务生成，使用可学习的任务嵌入来指导向特定模态的扩散过程。我们从公开可用的数据集中收集了6000多万个多视图样本来训练这个模型，并提出了在这种不同条件下实现高效和一致学习的技术。我们还提出了一种新策略，通过逐步微调较小的模型，实现了对较大模型的有效训练，并具有很好的扩展行为。通过广泛的实验，我们报告了多个新颖的视图合成基准以及多视图立体和视频深度估计的最新结果。 et.al.|[2501.18804](http://arxiv.org/abs/2501.18804)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

