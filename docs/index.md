---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.11.19
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-11-16**|**Adaptive Shells for Efficient Neural Radiance Field Rendering**|神经辐射场在新视图合成中实现了前所未有的质量，但其体积公式仍然昂贵，需要大量样本才能渲染高分辨率图像。体积编码对于表示树叶和头发等模糊几何体至关重要，它们非常适合随机优化。然而，许多场景最终主要由固体表面组成，这些表面可以通过每个像素的单个采样精确渲染。基于这一见解，我们提出了一种神经辐射公式，可以在基于体积和表面的渲染之间平滑过渡，大大加快渲染速度，甚至提高视觉逼真度。我们的方法构造了一个显式网格包络，该包络在空间上限制了神经体积表示。在实体区域中，包络几乎收敛到曲面，并且通常可以使用单个采样进行渲染。为此，我们推广了NeuS公式，该公式具有学习的空间变化的核大小，该核大小对密度的扩展进行编码，将宽核与类体积区域拟合，将紧核与类表面区域拟合。然后，我们提取表面周围窄带的显式网格，其宽度由内核大小决定，并微调该窄带内的辐射场。在推断时，我们将光线投射到网格上，并仅在封闭区域内评估辐射场，从而大大减少了所需的样本数量。实验表明，我们的方法能够以非常高的保真度实现高效的渲染。我们还证明了提取的包络可以实现动画和模拟等下游应用。 et.al.|[2311.10091](http://arxiv.org/abs/2311.10091)|null|
|**2023-11-16**|**Reconstructing Continuous Light Field From Single Coded Image**|我们提出了一种从单个观测图像重建目标场景的连续光场的方法。我们的方法两全其美：用于压缩光场采集的联合孔径曝光编码和用于视图合成的神经辐射场（NeRF）。在相机中实现的联合孔径曝光编码能够将3D场景信息有效地嵌入到观察到的图像中，但在以前的工作中，它仅用于重建离散的光场视图。基于NeRF的神经渲染能够从连续视点对3D场景进行高质量的视图合成，但当只给出单个图像作为输入时，它很难实现令人满意的质量。我们的方法将这两种技术集成到一个高效且端到端可训练的管道中。经过对各种场景的训练，我们的方法可以准确高效地重建连续光场，而无需任何测试时间优化。据我们所知，这是第一项将两个世界连接起来的工作：有效获取三维信息的相机设计和神经渲染。 et.al.|[2311.09646](http://arxiv.org/abs/2311.09646)|null|
|**2023-11-11**|**Aria-NeRF: Multimodal Egocentric View Synthesis**|基于受神经辐射场（NeRFs）启发的可微分体积射线跟踪，我们寻求加快开发从以自我为中心的数据训练的丰富的多模式场景模型的研究。从以自我为中心的图像序列构建类似NeRF的模型在理解人类行为方面发挥着关键作用，并在VR/AR领域具有多种应用。这种以自我为中心的类NeRF模型可以用作现实模拟，对能够在现实世界中执行任务的智能代理的发展做出了重大贡献。以自我为中心的视图合成的未来可能会通过使用多模式传感器（如用于自我运动跟踪的IMU、用于捕捉表面纹理和人类语言上下文的音频传感器以及用于推断场景中人类注意力模式的眼睛凝视跟踪器）来增强视觉数据，从而产生超越当今NeRF的新环境表示。为了支持和促进以自我为中心的多模式场景建模的开发和评估，我们提出了一个全面的多模式自我中心视频数据集。该数据集提供了一个全面的感官数据集，包括RGB图像、眼动追踪相机镜头、麦克风录音、气压计的气压读数、GPS的位置坐标、Wi-Fi和蓝牙的连接细节，以及与磁力计配对的双频IMU数据集（1kHz和800Hz）的信息。数据集是使用Meta Aria Glasses可穿戴设备平台收集的。该数据集中捕获的各种数据模式和真实世界背景为我们进一步理解人类行为奠定了坚实的基础，并在VR、AR和机器人领域实现了更身临其境的智能体验。 et.al.|[2311.06455](http://arxiv.org/abs/2311.06455)|null|
|**2023-11-10**|**Improved Positional Encoding for Implicit Neural Representation based Compact Data Representation**|采用位置编码来捕获隐式神经表示（INR）中编码信号的高频信息。在本文中，我们提出了一种新的位置编码方法，该方法提高了INR的重建质量。所提出的嵌入方法对于紧凑的数据表示更有利，因为它比现有方法具有更多的频率基。我们的实验表明，该方法在压缩任务中没有引入任何额外的复杂性，并且在新的视图合成中具有更高的重建质量，从而在率失真性能上获得了显著的增益。 et.al.|[2311.06059](http://arxiv.org/abs/2311.06059)|null|
|**2023-11-09**|**Real-Time Neural Rasterization for Large Scenes**|提出了一种新的大场景真实感实时新视图合成方法。现有的神经渲染方法可以生成逼真的结果，但主要适用于小规模场景（<50平方米），在大规模场景（>10000平方米）中存在困难。传统的基于图形的光栅化渲染对于大型场景来说速度很快，但缺乏真实感，并且需要昂贵的手动创建资源。我们的方法结合了两全其美，将中等质量的脚手架网格作为输入，学习神经纹理场和着色器来建模与视图相关的效果，以增强真实感，同时仍然使用标准图形管道进行实时渲染。我们的方法优于现有的神经渲染方法，为大型自动驾驶和无人机场景提供了至少30倍的渲染速度和相当或更好的真实感。我们的工作是第一个实现大型真实世界场景的实时渲染。 et.al.|[2311.05607](http://arxiv.org/abs/2311.05607)|null|
|**2023-11-09**|**Reconstructing Objects in-the-wild for Realistic Sensor Simulation**|从真实世界的数据中重建物体并以新颖的视图渲染它们，对于为机器人训练和测试的模拟带来真实性、多样性和规模至关重要。在这项工作中，我们提出了NeuSim，这是一种新的方法，可以根据在距离和有限视点捕获的稀疏野外数据来估计精确的几何结构和逼真的外观。为了实现这一目标，我们将物体表面表示为神经符号距离函数，并利用激光雷达和相机传感器数据来重建平滑准确的几何体和法线。我们用一种稳健的、受物理启发的反射率表示法对物体外观进行建模，该表示法对野外数据有效。我们的实验表明，NeuSim在具有稀疏训练视图的具有挑战性的场景中具有强大的视图合成性能。此外，我们展示了将NeuSim资产组合到虚拟世界中，并生成用于评估自动驾驶感知模型的真实多传感器数据。 et.al.|[2311.05602](http://arxiv.org/abs/2311.05602)|null|
|**2023-11-09**|**BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis**|从视频中合成逼真的4D人头头像对于VR/AR、远程呈现和视频游戏应用至关重要。尽管现有的基于神经辐射场（NeRF）的方法实现了高保真度的结果，但计算费用限制了它们在实时应用中的使用。为了克服这一限制，我们引入了BakedAvatar，这是一种用于实时神经头部化身合成的新表示，可部署在标准多边形光栅化管道中。我们的方法从学习的头部等值面中提取可变形的多层网格，并计算与表情、姿势和视图相关的外观，这些外观可以烘焙到静态纹理中，以实现高效的光栅化。因此，我们提出了一种用于神经头化身合成的三阶段流水线，包括学习连续变形、流形和辐射场，提取分层网格和纹理，以及使用差分光栅化微调纹理细节。实验结果表明，我们的表示生成的合成结果质量与其他最先进的方法相当，同时显著减少了所需的推理时间。我们进一步展示了单眼视频中的各种头部化身合成结果，包括视图合成、面部再现、表情编辑和姿势编辑，所有这些都是以交互式帧率进行的。 et.al.|[2311.05521](http://arxiv.org/abs/2311.05521)|null|
|**2023-11-09**|**VoxNeRF: Bridging Voxel Representation and Neural Radiance Fields for Enhanced Indoor View Synthesis**|创建高质量的视图合成对于沉浸式应用程序至关重要，但仍然存在问题，尤其是在室内环境和实时部署中。当前的技术经常需要大量的计算时间来进行训练和渲染，并且由于不充分的几何结构，经常产生不太理想的3D表示。为了克服这一点，我们引入了VoxNeRF，这是一种利用体积表示来提高室内视图合成质量和效率的新方法。首先，VoxNeRF构建结构化的场景几何体，并将其转换为基于体素的表示。我们使用多分辨率哈希网格自适应地捕捉空间特征，有效地管理室内场景的遮挡和复杂几何结构。其次，我们提出了一种独特的体素引导的高效采样技术。这一创新有选择地将计算资源集中在射线段的最相关部分，大大减少了优化时间。我们针对三个公共室内数据集验证了我们的方法，并证明VoxNeRF优于最先进的方法。值得注意的是，它在减少训练和渲染时间的同时实现了这些收益，速度甚至超过了Instant NGP，使技术更接近实时。 et.al.|[2311.05289](http://arxiv.org/abs/2311.05289)|null|
|**2023-11-08**|**VET: Visual Error Tomography for Point Cloud Completion and High-Quality Neural Rendering**|在过去的几年里，深度神经网络为新视图合成的巨大进步打开了大门。这些方法中的许多都是基于通过结构从运动算法获得的（粗略）代理几何结构。这种代理中的小缺陷可以通过神经渲染来修复，但较大的孔洞或缺失部分，通常出现在薄结构或光滑区域，仍然会导致分散注意力的伪影和时间不稳定。在本文中，我们提出了一种新的基于神经渲染的方法来检测和修复这些缺陷。作为代理，我们使用点云，这使我们能够轻松删除异常几何体并填充缺失的几何体，而无需复杂的拓扑操作。我们方法的关键是（i）一个可微分的、基于混合点的渲染器，它可以混合掉多余的点，以及（ii）视觉误差层析成像（VET）的概念，它允许我们提升2D误差图，以识别缺乏几何结构的3D区域，并相应地生成新的点。此外，（iii）通过添加点作为嵌套的环境贴图，我们的方法使我们能够在同一管道中生成高质量的周围环境渲染图。在我们的结果中，我们表明我们的方法可以提高由结构从运动中获得的点云的质量，从而显著提高新视图合成的质量。与点生长技术相比，该方法还可以有效地修复大规模孔洞和缺失的薄结构。渲染质量优于最先进的方法，时间稳定性显著提高，同时可以以实时帧速率进行渲染。 et.al.|[2311.04634](http://arxiv.org/abs/2311.04634)|**[link](https://github.com/lfranke/vet)**|
|**2023-11-08**|**Learning Robust Multi-Scale Representation for Neural Radiance Fields from Unposed Images**|我们介绍了一种改进的计算机视觉中基于神经图像的绘制问题的解决方案。给定一组在火车时刻从自由移动的相机拍摄的图像，所提出的方法可以在测试时刻从一个新颖的视角合成真实的场景图像。本文提出的关键思想是：（i）在神经新视图合成问题中，通过稳健的管道从未处理的日常图像中恢复准确的相机参数同样至关重要；（ii）以不同的分辨率对对象的内容进行建模更为实用，因为在日常的未渲染图像中，相机的剧烈运动极有可能发生。为了结合这些关键思想，我们利用了场景刚性、多尺度神经场景表示和单图像深度预测的基本原理。具体地说，所提出的方法使相机参数在基于神经场的建模框架中是可学习的。通过假设每个视图的深度预测是按比例进行的，我们限制了连续帧之间的相对姿态。根据相对姿态，通过多尺度神经场网络内的基于图神经网络的多运动平均来建模绝对相机姿态估计，从而产生单个损失函数。优化引入的损失函数提供了相机内在的、外在的以及从未聚焦的图像渲染的图像。我们通过例子证明，对于从日常获取的未聚焦多视图图像中精确建模多尺度神经场景表示的统一框架，在场景表示框架内进行精确的相机姿态估计同样重要。如果不考虑相机姿态估计管道中的鲁棒性措施，对多尺度混叠伪影进行建模可能会适得其反。我们在几个基准数据集上进行了大量实验，以证明我们的方法的适用性。 et.al.|[2311.04521](http://arxiv.org/abs/2311.04521)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-11-16**|**On the Overconfidence Problem in Semantic 3D Mapping**|语义3D映射是一个最近感兴趣的话题，它融合了多个视图之间的深度和图像分割信息，以实时构建用对象类注释的3D地图。本文强调了融合过度自信问题，在该问题中，传统的映射方法即使在不正确的情况下也会为整个映射分配高置信度，从而导致输出校准错误。提出了几种改进聚变管道不同阶段不确定度校准的方法，并在ScanNet数据集上进行了比较。我们表明，使用最广泛的贝叶斯融合策略是校准最差的策略之一，并提出了一种结合融合和校准的学习管道GLFS，它在保持实时能力的同时实现了更高的精度和3D地图校准。我们进一步说明了地图校准对下游任务的重要性，表明在模块化ObjectNav代理上结合适当的语义融合可以提高其成功率。我们的代码将在Github上提供，以便在接受后进行再现。 et.al.|[2311.10018](http://arxiv.org/abs/2311.10018)|null|
|**2023-11-16**|**DSR-Diff: Depth Map Super-Resolution with Diffusion Model**|彩色引导深度图超分辨率（CDSR）通过相应的高质量彩色图提高了低质量深度图的空间分辨率，有利于3D重建、虚拟现实和增强现实等各种应用。虽然传统的CDSR方法通常依赖于卷积神经网络或变换器，但扩散模型（DM）在高级视觉任务中表现出了显著的有效性。在这项工作中，我们提出了一种新的CDSR范式，该范式利用潜在空间内的扩散模型来生成深度图超分辨率的指导。所提出的方法包括制导生成网络（GGN）、深度图超分辨率网络（DSRN）和制导恢复网络（GRN）。GGN专门设计用于生成指南，同时管理其紧凑性。此外，我们将一个简单但有效的特征融合模块和转换器式特征提取模块集成到DSRN中，使其能够在多模型图像的提取、融合和重建中利用引导先验。考虑到准确性和效率，与最先进的方法相比，我们提出的方法在大量实验中显示出优越的性能。我们的代码将在https://github.com/shiyuan7/DSR-Diff. et.al.|[2311.09919](http://arxiv.org/abs/2311.09919)|null|
|**2023-11-16**|**EvaSurf: Efficient View-Aware Implicit Textured Surface Reconstruction on Mobile Devices**|重建真实世界的3D对象在计算机视觉中有许多应用，如虚拟现实、视频游戏和动画。理想情况下，3D重建方法应实时生成具有3D一致性的高保真度结果。传统方法使用照片一致性约束或学习特征来匹配图像之间的像素，而神经辐射场（NeRF）等可微分渲染方法使用基于表面的表示或可微分体积渲染来生成高保真场景。然而，这些方法需要过多的渲染运行时间，这使得它们对于日常应用程序来说不切实际。为了解决这些挑战，我们提出了 $\textbf｛EvaSurf｝$，一种$\textbf｛E｝$efficient$\textbf｛V｝$iew-$\textbf｛A｝$ware在移动设备上的隐式纹理$\textbf｛Surf｝$ ace重建方法。在我们的方法中，我们首先使用了一个高效的基于曲面的模型，该模型带有多视图监督模块，以确保精确的网格创建。为了实现高保真度渲染，我们学习了嵌入一组高斯波瓣的隐式纹理，以捕获与视图相关的信息。此外，通过显式几何和隐式纹理，我们可以使用轻量级的神经着色器来降低计算成本，并进一步支持在常见移动设备上的实时渲染。大量实验表明，我们的方法可以在合成数据集和真实世界数据集上重建高质量的外观和精确的网格。此外，我们的方法可以使用单个GPU在1-2小时内进行训练，并在移动设备上以超过40FPS（每秒帧数）的速度运行，渲染所需的最终包仅占用40-50 MB。 et.al.|[2311.09806](http://arxiv.org/abs/2311.09806)|null|
|**2023-11-15**|**Single-Image 3D Human Digitization with Shape-Guided Diffusion**|我们提出了一种从单个输入图像生成具有一致、高分辨率外观的人的360度视图的方法。NeRF及其变体通常需要来自不同视点的视频或图像。大多数采用单目输入的现有方法要么依赖于地面实况3D扫描进行监督，要么缺乏3D一致性。虽然最近的3D生成模型显示了3D一致性人类数字化的前景，但这些方法并不能很好地推广到不同的服装外观，而且结果缺乏真实感。与现有工作不同，我们使用为一般图像合成任务预训练的高容量2D扩散模型作为穿着衣服的人类的外观先验。为了在保持输入身份的同时实现更好的3D一致性，我们通过以轮廓和表面法线为条件的形状引导扩散修复缺失区域，逐步合成输入图像中人类的多个视图。然后，我们通过反向渲染将这些合成的多视图图像融合在一起，以获得给定人物的全纹理高分辨率3D网格。实验表明，我们的方法优于现有方法，并从单个图像中实现了对具有复杂纹理的各种穿着衣服的人的360度真实感合成。 et.al.|[2311.09221](http://arxiv.org/abs/2311.09221)|null|
|**2023-11-14**|**LocaliseBot: Multi-view 3D object localisation with differentiable rendering for robot grasping**|机器人抓取通常分为五个阶段：物体检测、物体定位、物体姿态估计、抓取姿态估计和抓取规划。我们专注于物体姿态估计。我们的方法依赖于三条信息：对象的多个视图、这些视图处的相机外部参数以及对象的3D CAD模型。第一步涉及标准的深度学习主干（FCN-ResNet）来估计对象标签、语义分割和对象相对于相机姿态的粗略估计。我们的新颖之处在于使用了一个细化模块，该模块从粗略的姿态估计开始，并通过可微分渲染进行优化来对其进行细化。这是一种纯粹基于视觉的方法，避免了对点云或深度图像等其他信息的需要。我们在ShapeNet数据集上评估了我们的物体姿态估计方法，并展示了对现有技术的改进。我们还表明，在使用标准实践计算的物体杂波室内数据集（OCID）抓握数据集上，与地面实况抓握候选数据相比，估计的物体姿态的抓握准确率为99.65%。 et.al.|[2311.08438](http://arxiv.org/abs/2311.08438)|null|
|**2023-11-14**|**DynamicSurf: Dynamic Neural RGB-D Surface Reconstruction with an Optimizable Feature Grid**|我们提出了DynamicSurf，这是一种无模型的神经隐式表面重建方法，用于单目RGB-D视频中非刚性表面的高保真3D建模。为了解决变形曲面的单目序列中缺乏多视图提示的问题，DynamicSurf利用深度、曲面法线和RGB损失来提高重建保真度和优化时间，这是3D重建最具挑战性的设置之一。DynamicSurf学习将曲面几何体的规范表示映射到当前帧的神经变形场。我们通过将正则表示设计为学习特征网格来偏离当前的神经非刚性表面重建模型，这比使用单个MLP的竞争方法更快、更准确地进行表面重建。我们在公共数据集上演示了DynamicSurf，并表明与纯基于MLP的方法相比，它可以以 $6\times$ speed优化不同帧的序列，同时获得与最先进方法相当的结果。项目可在https://mirgahney.github.io//DynamicSurf.io/. et.al.|[2311.08159](http://arxiv.org/abs/2311.08159)|null|
|**2023-11-13**|**$L_0$-Sampler: An $L_{0}$ Model Guided Volume Sampling for NeRF**|自提出以来，神经辐射场（NeRF）在相关任务中取得了巨大成功，主要采用分层体采样（HVS）策略进行体绘制。然而，NeRF的HVS使用分段常数函数来近似分布，这提供了相对粗略的估计。基于观察到训练有素的权重函数$w（t）$和点与曲面之间的$L_0$距离具有很高的相似性，我们提出了$L_0$-Sampler，通过将$L_0美元模型合并到$w（t）$中来指导采样过程。具体来说，我们建议使用分段指数函数而不是分段常数函数进行插值，这不仅可以很好地近似沿射线的准$L_0$权重分布，而且可以用几行代码轻松实现，而不需要额外的计算负担。通过将$L_0$ -Sampler应用于NeRF及其相关任务（如3D重建），可以实现稳定的性能改进。代码可在https://ustc3dv.github.io/L0-Sampler/。 et.al.|[2311.07044](http://arxiv.org/abs/2311.07044)|null|
|**2023-11-14**|**Comparative Multi-View Language Grounding**|在这项工作中，我们考虑了在给出比较语言描述时解决对象指称的任务。我们提出了一种基于上下文的多视图方法（MAGiC），该方法利用转换器在给定多个图像视图和语言描述的情况下对两个对象进行务实的推理。与过去试图在没有充分考虑所产生的指称上下文的情况下将视觉和语言联系起来完成这项任务的努力相反，MAGiC通过对对象指称候选者和指称语言表达的多个观点进行联合推理来利用比较信息。我们的分析表明，比较推理有助于SOTA在SNARE对象引用任务中的性能。 et.al.|[2311.06694](http://arxiv.org/abs/2311.06694)|null|
|**2023-11-11**|**3DFusion, A real-time 3D object reconstruction pipeline based on streamed instance segmented data**|本文提出了一种实时分割和重建系统，该系统利用RGB-D图像来生成捕获场景中对象的精确和详细的单个3D模型。利用最先进的实例分割技术，该系统对RGB-D数据进行像素级分割，有效地将前景对象与背景分离。然后在高性能计算平台中将分割的对象重建为不同的3D模型。实时3D建模可以应用于各个领域，包括增强/虚拟现实、室内设计、城市规划、道路辅助、安全系统等。为了实现实时性，本文提出了一种在保证重建质量的同时，对连续帧进行有效采样以减少网络负载的方法。此外，采用多进程SLAM流水线进行并行三维重建，能够有效地将聚类对象切割成个体。该系统采用业界领先的YOLO框架进行细分。为了提高YOLO的性能和准确性，对其进行了修改，以解决类似物体的重复或错误检测，确保重建的模型与目标对准。总的来说，这项工作建立了一个强大的实时系统，大大增强了室内环境中的对象分割和重建。它有可能扩展到户外场景，为现实世界的应用开辟了许多机会。 et.al.|[2311.06659](http://arxiv.org/abs/2311.06659)|null|
|**2023-11-09**|**Liquid phase fast electron tomography unravels the true 3D structure of colloidal assemblies**|电子断层扫描已成为研究纳米材料三维（3D）结构的常用工具，包括胶体纳米颗粒组件。然而，电子显微镜技术的性质通常要求在高真空下进行这种表征。因此，通过（湿）胶体化学方法制备的组件需要预处理样品制备，包括溶剂蒸发和在固体基底上沉积（TEM网格）。因此，变化总是强加在实际的纳米颗粒组织上，这在很大程度上是纳米材料性质的原因。因此，我们在此提出在纳米颗粒组件的原始胶体环境中应用（快速）电子断层扫描。为了解决与液体电子断层扫描相关的挑战，我们设计了一种方法，将商业液体原位TEM池中的快速数据采集与专用重建工作流程相结合。我们介绍了这种方法在两个不同系统中的应用，这两个系统举例说明了干燥和真空的影响，这取决于保护配体的性质。包括包封在聚合物壳中的聚苯乙烯封端的Au纳米颗粒的组件的3D重建显示，与干燥的对应物相比，在液体介质中进行的实验的结构不那么紧凑，变形更大。另一方面，对水中自组装Au纳米棒的颗粒间距离的定量分析与之前报道的纳米棒周围配体层的尺寸一致，而纳米棒在类似的干燥组件中接触得更紧密。因此，这项研究强调了开发高分辨率表征工具的重要性，以保护胶体纳米结构的天然环境。 et.al.|[2311.05309](http://arxiv.org/abs/2311.05309)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-11-16**|**The Chosen One: Consistent Characters in Text-to-Image Diffusion Models**|文本到图像生成模型的最新进展释放了视觉创造力的巨大潜力。然而，这些模型难以生成一致的角色，这是许多现实世界应用程序的关键方面，如故事可视化、游戏开发资产设计、广告等。当前的方法通常依赖于目标角色的多个预先存在的图像，或者涉及劳动密集型的手动过程。在这项工作中，我们提出了一种用于一致字符生成的全自动解决方案，唯一的输入是文本提示。我们引入了一个迭代过程，在每个阶段，识别一组共享相似身份的连贯图像，并从该图像集中提取一个更一致的身份。我们的定量分析表明，与基线方法相比，我们的方法在即时比对和身份一致性之间取得了更好的平衡，用户研究强化了这些发现。最后，我们展示了我们的方法的几个实际应用。项目页面位于https://omriavrahami.com/the-chosen-one et.al.|[2311.10093](http://arxiv.org/abs/2311.10093)|null|
|**2023-11-16**|**Spontaneous Opinion Swings in the Voter Model with Latency**|意见形成的认知过程通常以代理人对意见变化的固执或抗拒为特征。为了捕捉这样的特征，我们在意见动态的标准选民模型中引入了一个恒定的延迟时间：在切换意见后，代理必须将其保留一段时间。这种看似简单的修改极大地改变了原始模型的随机扩散行为，导致了代理人平均认为的确定性动力学振荡。我们解释了振荡的起源，并发展了一个动力学的数学公式，该公式已被广泛的数值模拟所证实。我们进一步刻画了该模型的富相空间及其渐近行为。我们的工作为理解和建模不同社会背景下的意见波动提供了见解。 et.al.|[2311.10045](http://arxiv.org/abs/2311.10045)|null|
|**2023-11-16**|**TransFusion -- A Transparency-Based Diffusion Model for Anomaly Detection**|表面异常检测是制造检测的重要组成部分。重建异常检测方法恢复物体的正常外观，理想情况下只修改异常区域。由于常用重建架构的局限性，所产生的重建通常很差，并且在无异常区域中仍然包含异常或缺乏细节。最近的重建方法采用了扩散模型，但对于标准的扩散过程，这些问题没有得到充分解决。我们提出了一种新的基于透明度的扩散过程，其中异常区域的透明度逐渐增加，准确地恢复其正常外观，并在不损失细节的情况下保持无异常区域的外观。我们提出了TRANSparency DifFUSION（TransFusion），这是一种有判别力的异常检测方法，实现了所提出的扩散过程，实现了准确的下游异常检测。TransFusion在VisA和MVTec AD数据集上都实现了最先进的性能，图像级AUROC分别为98.5%和99.2%。 et.al.|[2311.09999](http://arxiv.org/abs/2311.09999)|null|
|**2023-11-16**|**Co-data Learning for Bayesian Additive Regression Trees**|医学预测应用程序通常需要处理与协变量数量相比较小的样本量。这些数据给预测和变量选择带来了问题，尤其是当协变量响应关系复杂时。为了应对这些挑战，我们建议将共同数据，即协变量的外部信息，纳入贝叶斯加性回归树（BART），这是一种树和预测模型，利用树参数上的先验来防止过拟合。为了合并协同数据，开发了一个经验贝叶斯（EB）框架，在协同数据模型的辅助下，估计BART模型中的先验协变量权重。所提出的方法可以同时处理多种类型的协同数据。此外，所提出的EB框架也能够估计BART的其他超参数，为交叉验证提供了一种有吸引力的替代方案。我们证明了该方法可以找到相关的协变量，并且与模拟中的默认BART相比，它改进了预测。如果协变响应关系是非线性的，则该方法受益于BART的灵活性，以优于基于回归的协数据学习器。最后，基于临床协变量、基因突变、DNA易位和DNA拷贝数数据，联合数据的使用增强了对弥漫性大B细胞淋巴瘤预后的预测。关键词：贝叶斯加性回归树；经验贝叶斯；Co数据；高维数据；奥密克戎；预言 et.al.|[2311.09997](http://arxiv.org/abs/2311.09997)|**[link](https://github.com/JeroenGoedhart/EB_coBART_paper)**|
|**2023-11-16**|**Existence and dimensions of global attractors for a delayed reaction-diffusion equation on an unbounded domain**|本文研究了无界域上时滞反应扩散方程全局吸引子的存在性、Hausdorff维数和分形维数。域的非紧性导致拉普拉斯算子具有连续谱，线性部分和Sobolev嵌入生成的半群不再是紧的，这使得该问题与有界域上的方程相比更加困难。我们首先通过对解的先验估计，得到由方程生成的无穷维动力系统的吸收集的存在性。然后，我们通过对解的远场值的一致先验估计，以及Arzel-a-Ascoli定理，证明了解半流的渐近紧性，这有助于我们证明全局吸引子的存在性。通过将解分解为三个部分，并建立每个部分的压缩性质，我们得到了全局吸引子的Hausdorff和分形维数的显式上估计，与现有文献相比，该估计仅取决于方程的内部特征，而与熵数无关。 et.al.|[2311.09980](http://arxiv.org/abs/2311.09980)|null|
|**2023-11-16**|**The divergence-free velocity formulation of the consistent Navier-Stokes Cahn-Hilliard model with non-matching densities, divergence-conforming discretization, and benchmarks**|描述多组分流动的典型扩散界面模型是Navier-Stokes-Cahn-Hilliard模型（NSCH）。在过去的几十年里，出现了许多NSCH模型，它们声称描述了相同的物理现象，但彼此不同。在最近的一篇文章[M.F.P.ten Eikelder，K.G.van der Zee，I.Akkerman和D.Schillinger，Math.Mod.Meth.Appl.S.33，第175-221页，2023]中，我们建立了几乎所有NSCH模型的统一框架。该框架表明，只有一个一致的NSCH模型自然源于潜在的混合理论。在本文中，我们通过数值模拟的方法提出、验证和验证了这种新的一致性NSCH模型。为此，我们使用散度一致的等几何空间离散NSCH模型的无散度速度公式。我们将一致性模型的计算结果与文献中现有模型的结果进行了比较。数值方法的预测能力是通过对上升气泡和液丝收缩的三维计算来证明的，这些计算与实验数据进行了很好的比较。 et.al.|[2311.09966](http://arxiv.org/abs/2311.09966)|null|
|**2023-11-16**|**Score-based generative models learn manifold-like structures with constrained mixing**|基于分数的生成模型（SBM）如何学习低维流形上支持的数据分布？我们通过线性近似和由局部特征向量跨越的子空间来研究训练的SBM的得分模型。在扩散过程中，随着噪声的减少，局部维数增加，并且在不同的样本序列之间变化更大。重要的是，我们发现学习的向量场通过流形内的非保守场混合样本，尽管它用法线投影去噪，就好像在非流形方向上有能量函数一样。在每个噪声级，局部特征所跨越的子空间与有效密度函数重叠。这些观察结果表明，SBM可以灵活地将样本与学习的分数字段混合，同时小心地保持数据分布的流形结构。 et.al.|[2311.09952](http://arxiv.org/abs/2311.09952)|null|
|**2023-11-16**|**DSR-Diff: Depth Map Super-Resolution with Diffusion Model**|彩色引导深度图超分辨率（CDSR）通过相应的高质量彩色图提高了低质量深度图的空间分辨率，有利于3D重建、虚拟现实和增强现实等各种应用。虽然传统的CDSR方法通常依赖于卷积神经网络或变换器，但扩散模型（DM）在高级视觉任务中表现出了显著的有效性。在这项工作中，我们提出了一种新的CDSR范式，该范式利用潜在空间内的扩散模型来生成深度图超分辨率的指导。所提出的方法包括制导生成网络（GGN）、深度图超分辨率网络（DSRN）和制导恢复网络（GRN）。GGN专门设计用于生成指南，同时管理其紧凑性。此外，我们将一个简单但有效的特征融合模块和转换器式特征提取模块集成到DSRN中，使其能够在多模型图像的提取、融合和重建中利用引导先验。考虑到准确性和效率，与最先进的方法相比，我们提出的方法在大量实验中显示出优越的性能。我们的代码将在https://github.com/shiyuan7/DSR-Diff. et.al.|[2311.09919](http://arxiv.org/abs/2311.09919)|null|
|**2023-11-16**|**Connecting microscopic and mesoscopic mechanics in model structural glasses**|我们提出了一种新的形式来表征非晶态固体中的弹性不均匀性。特别地，我们导出了无热准静态动力学下成对能量的高阶应变能展开式。然后，我们使用所提出的形式主义来研究二维和三维系统中各种形成历史的成对展开系数的统计性质及其与软的准局部化模式统计的联系。我们进一步利用所提出的框架，通过在嵌入冻结基质的空腔内进行非线性应力-应变膨胀来访问局部屈服应力图。我们表明，我们的“键微观力学”与最初的“冻结矩阵”方法相比很好，但需要注意的是高估了大的应力激活。我们还展示了如何将局部屈服规则用作标量弹塑性模型（EPM）的输入，以预测从韧性到脆性材料的应力响应。最后，我们强调了简单中尺度模型在捕捉后屈服系统老化动力学方面的一些局限性。有趣的是，我们分别在基于粒子的模拟和电子探针中观察到了亚扩散和扩散剪切带的生长。 et.al.|[2311.09917](http://arxiv.org/abs/2311.09917)|null|
|**2023-11-16**|**Unbiased and Multilevel Methods for a Class of Diffusions Partially Observed via Marked Point Processes**|在这篇文章中，我们考虑了与部分观测到的扩散相关的滤波问题，观测遵循标记点过程。在该模型中，数据形成了一个点过程，其观察时间的强度由扩散驱动，相关标记也取决于扩散过程。我们假设必须对扩散过程进行时间离散，并开发粒子和多级粒子滤波器来递归逼近滤波器。特别地，我们证明了我们的多级粒子滤波器可以实现 $\mathcal｛O｝（\epsilon^2）$（$\epsilon>0$和任意）的均方误差（MSE），成本为$ \mathcal{O｝。然后，我们展示了如何将该方法扩展到给出滤波器的无偏（即没有时间离散化误差）估计量，这些估计量被证明具有有限方差，并且很可能具有有限代价。最后，我们将我们的方法扩展到在线静态参数估计问题。 et.al.|[2311.09875](http://arxiv.org/abs/2311.09875)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-11-15**|**RENI++ A Rotation-Equivariant, Scale-Invariant, Natural Illumination Prior**|反向渲染是一个不适定的问题。以前的工作试图通过关注对象或场景形状或外观的先验来解决这个问题。在这项工作中，我们转而关注自然照明的先验。目前的方法依赖于球面谐波照明或其他通用表示，充其量，依赖于参数的简单化先验。这导致在照明条件的表现力方面对反向设置的限制，尤其是在考虑镜面反射时。我们提出了一种基于变分自动解码器和变换器解码器的条件神经场表示。我们扩展了矢量神经元，将等方差直接构建到我们的架构中，并通过尺度不变损失函数利用深度估计的见解，实现了高动态范围（HDR）图像的精确表示。其结果是一个紧凑的、旋转等变的HDR神经照明模型，能够捕捉自然环境地图中复杂的高频特征。在一个由1.6K HDR自然场景环境图组成的精心策划的数据集上训练我们的模型，我们将其与传统表示进行比较，证明其适用于反向渲染任务，并显示部分观测的环境图完成情况。我们在https://github.com/JADGardner/ns_reni et.al.|[2311.09361](http://arxiv.org/abs/2311.09361)|**[link](https://github.com/jadgardner/ns_reni)**|
|**2023-11-15**|**Data Augmentations in Deep Weight Spaces**|在权重空间中学习，神经网络处理其他深度神经网络的权重，已成为一个很有前途的研究方向，在各个领域都有应用，从分析和编辑神经领域和隐式神经表示，到网络修剪和量化。最近的工作设计了在该空间中进行有效学习的架构，考虑到了其独特的置换等变结构。不幸的是，到目前为止，这些架构存在严重的过拟合问题，并被证明受益于大型数据集。这带来了重大挑战，因为为这种学习设置生成数据既费力又耗时，因为每个数据样本都是必须训练的一整套网络权重。在本文中，我们通过研究权重空间的数据增强来解决这一困难，这是一组能够在不需要训练额外输入权重空间元素的情况下实时生成新数据示例的技术。我们首先回顾了最近提出的几个数据增强方案%，并将其分为几类。然后，我们介绍了一种新的基于Mixup方法的增强方案。我们评估了这些技术在现有基准以及我们生成的新基准上的性能，这对未来的研究很有价值。 et.al.|[2311.08851](http://arxiv.org/abs/2311.08851)|null|
|**2023-11-14**|**Instant3D: Instant Text-to-3D Generation**|文本到三维生成，旨在通过文本提示合成生动的三维对象，引起了计算机视觉界的广泛关注。虽然已有的几项工作在这项任务上取得了令人印象深刻的成果，但它们主要依赖于耗时的优化范式。具体来说，这些方法为每个文本提示从头开始优化神经场，生成一个对象大约需要一个小时或更长时间。这种繁重和重复的培训成本阻碍了他们的实际部署。在本文中，我们提出了一种新的快速文本到三维生成框架，称为Instant3D。一旦经过训练，Instant3D就能够通过一次前馈网络运行，在不到一秒钟的时间内为看不见的文本提示创建一个3D对象。我们通过设计一个新的网络来实现这一惊人的速度，该网络直接从文本提示构建3D三平面。我们的Instant3D的核心创新在于探索将文本条件有效地注入网络的策略。此外，我们提出了一种简单而有效的激活函数，即缩放的sigmoid函数，以取代原始的sigmoid函数，它将训练收敛速度提高了十倍以上。最后，为了解决3D生成中的Janus（多头）问题，我们提出了一种自适应Perp-Neg算法，该算法可以在训练过程中根据Janus问题的严重程度动态调整其概念否定量表，有效地降低了多头效应。在各种基准数据集上进行的大量实验表明，所提出的算法在质量和数量上都优于最先进的方法，同时实现了显著更好的效率。项目页面位于https://ming1993li.github.io/Instant3DProj. et.al.|[2311.08403](http://arxiv.org/abs/2311.08403)|null|
|**2023-11-13**|**On the mathematical replication of the MacKay effect from redundant stimulation**|在这项研究中，我们研究了视觉感知与初级视觉皮层（V1）神经活动的数学建模之间的复杂联系，重点是复制麦凯效应[MacKay，Nature 1957]。虽然分叉理论一直是解决神经科学问题的一种突出的数学方法，特别是在描述V1中由于参数变化而自发形成的模式时，它在具有局部感觉输入的场景中面临挑战。例如，这一点在麦凯的心理物理学实验中很明显，在该实验中，视觉刺激信息的冗余导致了不规则的形状，使分叉理论和多尺度分析的效果较差。为了解决这个问题，我们遵循了一个基于Amari型神经场模型的输入输出可控性的数学观点。该框架将感觉输入视为一种控制功能，通过视觉刺激的视网膜-皮层图进行皮层表征，捕捉刺激的不同特征，特别是麦凯漏斗模式“麦凯射线”中的中心冗余。从控制理论的角度，讨论了Amari型方程对于线性和非线性响应函数的精确可控性。然后，应用于麦凯效应复制，我们调整了表示神经元内连接的参数，以确保在没有感觉输入的情况下，皮层活动指数稳定到静止状态，我们进行了定量和定性研究，以表明它捕捉到了麦凯报告的诱导后图像的所有基本特征 et.al.|[2311.07338](http://arxiv.org/abs/2311.07338)|null|
|**2023-11-10**|**Improved Positional Encoding for Implicit Neural Representation based Compact Data Representation**|采用位置编码来捕获隐式神经表示（INR）中编码信号的高频信息。在本文中，我们提出了一种新的位置编码方法，该方法提高了INR的重建质量。所提出的嵌入方法对于紧凑的数据表示更有利，因为它比现有方法具有更多的频率基。我们的实验表明，该方法在压缩任务中没有引入任何额外的复杂性，并且在新的视图合成中具有更高的重建质量，从而在率失真性能上获得了显著的增益。 et.al.|[2311.06059](http://arxiv.org/abs/2311.06059)|null|
|**2023-11-09**|**BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis**|从视频中合成逼真的4D人头头像对于VR/AR、远程呈现和视频游戏应用至关重要。尽管现有的基于神经辐射场（NeRF）的方法实现了高保真度的结果，但计算费用限制了它们在实时应用中的使用。为了克服这一限制，我们引入了BakedAvatar，这是一种用于实时神经头部化身合成的新表示，可部署在标准多边形光栅化管道中。我们的方法从学习的头部等值面中提取可变形的多层网格，并计算与表情、姿势和视图相关的外观，这些外观可以烘焙到静态纹理中，以实现高效的光栅化。因此，我们提出了一种用于神经头化身合成的三阶段流水线，包括学习连续变形、流形和辐射场，提取分层网格和纹理，以及使用差分光栅化微调纹理细节。实验结果表明，我们的表示生成的合成结果质量与其他最先进的方法相当，同时显著减少了所需的推理时间。我们进一步展示了单眼视频中的各种头部化身合成结果，包括视图合成、面部再现、表情编辑和姿势编辑，所有这些都是以交互式帧率进行的。 et.al.|[2311.05521](http://arxiv.org/abs/2311.05521)|null|
|**2023-11-08**|**Learning Robust Multi-Scale Representation for Neural Radiance Fields from Unposed Images**|我们介绍了一种改进的计算机视觉中基于神经图像的绘制问题的解决方案。给定一组在火车时刻从自由移动的相机拍摄的图像，所提出的方法可以在测试时刻从一个新颖的视角合成真实的场景图像。本文提出的关键思想是：（i）在神经新视图合成问题中，通过稳健的管道从未处理的日常图像中恢复准确的相机参数同样至关重要；（ii）以不同的分辨率对对象的内容进行建模更为实用，因为在日常的未渲染图像中，相机的剧烈运动极有可能发生。为了结合这些关键思想，我们利用了场景刚性、多尺度神经场景表示和单图像深度预测的基本原理。具体地说，所提出的方法使相机参数在基于神经场的建模框架中是可学习的。通过假设每个视图的深度预测是按比例进行的，我们限制了连续帧之间的相对姿态。根据相对姿态，通过多尺度神经场网络内的基于图神经网络的多运动平均来建模绝对相机姿态估计，从而产生单个损失函数。优化引入的损失函数提供了相机内在的、外在的以及从未聚焦的图像渲染的图像。我们通过例子证明，对于从日常获取的未聚焦多视图图像中精确建模多尺度神经场景表示的统一框架，在场景表示框架内进行精确的相机姿态估计同样重要。如果不考虑相机姿态估计管道中的鲁棒性措施，对多尺度混叠伪影进行建模可能会适得其反。我们在几个基准数据集上进行了大量实验，以证明我们的方法的适用性。 et.al.|[2311.04521](http://arxiv.org/abs/2311.04521)|null|
|**2023-11-06**|**Dynamic Neural Fields for Learning Atlases of 4D Fetal MRI Time-series**|我们提出了一种使用神经场快速构建生物医学图像图谱的方法。图谱是生物医学图像分析任务的关键，但传统的深度网络估计方法仍然耗时。在这项初步工作中，我们将特定主题的图谱构建框定为学习可变形时空观测的神经场。我们将我们的方法应用于学习子宫内胎儿动态BOLD MRI时间序列的受试者特异性图谱和运动稳定性。我们的方法产生了胎儿BOLD时间序列的高质量图谱，与现有工作相比，收敛速度更快。虽然我们的方法在解剖重叠方面稍逊于调整良好的基线，但它估计模板的速度要快得多，从而能够快速处理和稳定4D动态MRI采集的大型数据库。代码可在https://github.com/Kidrauh/neural-atlasing et.al.|[2311.02874](http://arxiv.org/abs/2311.02874)|**[link](https://github.com/kidrauh/neural-atlasing)**|
|**2023-11-04**|**LISNeRF Mapping: LiDAR-based Implicit Mapping via Semantic Neural Fields for Large-Scale 3D Scenes**|大规模语义映射对于户外自主代理完成规划和导航等高级任务至关重要。本文提出了一种通过单独的激光雷达测量的隐式表示进行大规模三维语义重建的新方法。我们首先利用基于八叉树的分层结构来存储隐式特征，然后通过浅层多层感知器（MLP）将这些隐式特征解码为语义信息和有符号距离值。我们采用现成的算法来预测点云的语义标签和实例ID。然后，我们使用点云几何的自监督范式和语义和全景标签的伪监督范式来联合优化隐含特征和MLP参数。随后，利用Marching Cubes算法对推理阶段的场景进行细分和可视化。对于内存受限的场景，还开发了一种地图拼接策略，将子地图合并为一个完整的地图。据我们所知，我们的方法是第一个从仅激光雷达的输入中重建语义隐含场景的工作。在SemanticKITTI、SemanticPOSS和nuScenes三个真实世界数据集上的实验证明了与当前最先进的3D映射方法相比，我们的框架的有效性和效率。 et.al.|[2311.02313](http://arxiv.org/abs/2311.02313)|null|
|**2023-11-03**|**EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision**|我们提出了EmerNeRF，这是一种简单而强大的方法，用于学习动态驾驶场景的时空表示。EmerNeRF以神经领域为基础，通过自举同时捕捉场景几何、外观、运动和语义。EmerNeRF取决于两个核心组件：首先，它将场景分为静态场和动态场。这种分解纯粹来自于自我监督，使我们的模型能够从一般的野外数据源中学习。其次，EmerNeRF将动态场中的感应流场参数化，并使用该流场进一步聚合多帧特征，从而提高动态对象的渲染精度。耦合这三个字段（静态、动态和流）使EmerNeRF能够自我充分地表示高度动态的场景，而不依赖于用于动态对象分割或光流估计的地面实况对象注释或预先训练的模型。我们的方法在传感器模拟中实现了最先进的性能，在重建静态（+2.93 PSNR）和动态（+3.70 PSNR）场景时显著优于以前的方法。此外，为了支持EmerNeRF的语义泛化，我们将2D视觉基础模型特征提升到4D时空中，并解决现代变形金刚中的普遍位置偏差，显著提高了3D感知性能（例如，占用预测准确率平均相对提高37.50%）。最后，我们构建了一个多样化且具有挑战性的120序列数据集，以在极端和高度动态的环境下对神经场进行基准测试。 et.al.|[2311.02077](http://arxiv.org/abs/2311.02077)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

