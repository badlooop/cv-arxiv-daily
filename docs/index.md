---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.05.21
> Usage instructions: [here](./docs/README.md#usage)

## Video Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-19**|**FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance**|尽管在视频生成方面取得了重大进展，但合成物理上合理的人类行为仍然是一个持续的挑战，特别是在建模细粒度语义和复杂的时间动态方面。例如，生成“0.5转跳台”等体操套路对当前的方法构成了实质性的困难，往往会产生不令人满意的结果。为了弥合这一差距，我们提出了FinePhys，这是一个细粒度的人类动作生成框架，它结合了物理学来获得有效的骨架指导。具体来说，FinePhys首先以在线方式估计2D姿势，然后通过上下文学习执行2D到3D的维度提升。为了减轻纯数据驱动的3D姿态的不稳定性和有限的可解释性，我们进一步引入了一个由欧拉-拉格朗日方程控制的基于物理的运动重新估计模块，通过双向时间更新计算关节加速度。然后将物理预测的3D姿态与数据驱动的姿态融合，为扩散过程提供多尺度2D热图指导。根据FineGym的三个细粒度动作子集（FX-JUMP、FX-TURN和FX-SALTO）进行评估，FinePhys的表现明显优于竞争基线。全面的定性结果进一步证明了FinePhys能够生成更自然、更合理的精细人类行为。 et.al.|[2505.13437](http://arxiv.org/abs/2505.13437)|null|
|**2025-05-19**|**Faster Video Diffusion with Trainable Sparse Attention**|缩放视频扩散变换器（DiTs）受到其二次3D注意力的限制，尽管大部分注意力集中在一小部分位置上。我们将这一观察结果转化为VSA，这是一种可训练的、硬件高效的稀疏注意力，在训练和推理时取代了完全注意力。在VSA中，一个轻量级的粗略阶段将令牌汇集到图块中，并识别高权重的\emph{关键令牌}；精细阶段仅在经过块计算布局的图块内计算令牌级注意力，以确保硬效率。这导致了一个端到端训练的单一可微分内核，不需要事后分析，并支持85%的FlashAttention3 MFU。我们通过将DiTs从60M预训练到1.4B参数，进行了大量的消融研究和标度律实验。VSA达到帕累托点，将训练FLOPS减少2.53美元，而扩散损失没有下降。改装开源Wan-2.1型号可将注意力时间缩短6美元，并将端到端生成时间从31秒缩短到18秒，质量相当。这些结果确立了可训练的稀疏注意力作为完全注意力的实用替代方案，也是进一步扩展视频扩散模型的关键因素。 et.al.|[2505.13389](http://arxiv.org/abs/2505.13389)|null|
|**2025-05-19**|**MAGI-1: Autoregressive Video Generation at Scale**|我们提出了MAGI-1，这是一个世界模型，通过自回归预测一系列视频块来生成视频，视频块被定义为连续帧的固定长度段。MAGI-1经过训练，可以对随时间单调增加的每个块噪声进行去噪，从而实现因果时间建模，并自然支持流生成。它在基于文本指令的图像到视频（I2V）任务上实现了强大的性能，提供了高时间一致性和可扩展性，这得益于几项算法创新和专用的基础设施堆栈。MAGI-1通过块式提示促进可控生成，并通过保持恒定的峰值推理成本来支持实时、内存高效的部署，而不管视频长度如何。MAGI-1的最大变体包含240亿个参数，支持高达400万个令牌的上下文长度，展示了我们方法的可扩展性和鲁棒性。代码和模型可在以下网址获得https://github.com/SandAI-org/MAGI-1以及https://github.com/SandAI-org/MagiAttention.该产品可在以下网址访问https://sand.ai. et.al.|[2505.13211](http://arxiv.org/abs/2505.13211)|**[link](https://github.com/sandai-org/magiattention)**|
|**2025-05-19**|**DreamGen: Unlocking Generalization in Robot Learning through Neural Trajectories**|我们介绍DreamGen，这是一个简单但高效的4级管道，用于训练机器人策略，通过神经轨迹（从视频世界模型生成的合成机器人数据）在行为和环境中进行泛化。DreamGen利用最先进的图像到视频生成模型，使其适应目标机器人实施例，在不同环境中生成熟悉或新颖任务的逼真合成视频。由于这些模型只生成视频，我们使用潜在动作模型或逆动力学模型（IDM）来恢复伪动作序列。尽管DreamGen很简单，但它解锁了强大的行为和环境泛化能力：人形机器人可以在可见和不可见的环境中执行22种新行为，同时只需要在一个环境中执行单个拾取和放置任务的遥操作数据。为了系统地评估管道，我们引入了DreamGen Bench，这是一个视频生成基准，显示基准性能与下游策略成功之间存在很强的相关性。我们的工作为将机器人学习扩展到手动数据收集之外建立了一个有前景的新轴。 et.al.|[2505.12705](http://arxiv.org/abs/2505.12705)|null|
|**2025-05-19**|**Safe-Sora: Safe Text-to-Video Generation via Graphical Watermarking**|生成视频模型的爆炸性增长放大了对人工智能生成内容可靠版权保护的需求。尽管隐形生成水印在图像合成中很受欢迎，但在视频生成中，它仍然没有得到充分的探索。为了解决这一差距，我们提出了Safe-Sora，这是第一个将图形水印直接嵌入视频生成过程的框架。基于水印性能与水印和覆盖内容之间的视觉相似性密切相关的观察，我们引入了一种分层的从粗到细的自适应匹配机制。具体而言，水印图像被划分为块，每个块被分配给视觉上最相似的视频帧，并进一步定位到最佳空间区域以实现无缝嵌入。为了实现跨视频帧的水印补丁的时空融合，我们开发了一种具有新颖时空局部扫描策略的3D小波变换增强Mamba架构，有效地模拟了水印嵌入和检索过程中的长程依赖关系。据我们所知，这是首次尝试将状态空间模型应用于水印，为高效和鲁棒的水印保护开辟了新途径。大量实验表明，Safe-Sora在视频质量、水印保真度和鲁棒性方面达到了最先进的性能，这在很大程度上归功于我们的建议。我们将在发布后发布我们的代码。 et.al.|[2505.12667](http://arxiv.org/abs/2505.12667)|null|
|**2025-05-19**|**BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation**|人工智能生成模型的进步促进了超现实的视频合成，通过社交媒体放大了错误信息的风险，并削弱了人们对数字内容的信任。一些研究工作探索了人工智能生成图像的新的深度伪造检测方法，以减轻这些风险。然而，随着Sora和WanX等视频生成模型的快速发展，目前缺乏用于伪造检测的大规模、高质量的AI生成视频数据集。此外，现有的检测方法主要将任务视为二元分类，在模型决策中缺乏可解释性，无法为公众提供可操作的见解或指导。为了应对这些挑战，我们提出了\textbf{GenBuster-200K}，这是一个大规模的人工智能生成的视频数据集，包含20万个高分辨率视频片段、各种最新的生成技术和现实世界场景。我们进一步介绍\textbf{BusterX}，这是一种新的人工智能生成的视频检测和解释框架，利用多模态大语言模型（MLLM）和强化学习来确定真实性和可解释的基本原理。据我们所知，GenBuster-200K是大规模、高质量的人工智能生成视频数据集，它结合了现实世界场景的最新生成技术。BusterX是{\t\textbf{first}}框架，它将MLLM与强化学习相结合，用于可解释的AI生成视频检测。与最先进的方法和消融研究的广泛比较验证了BusterX的有效性和普遍性。代码、模型和数据集将被发布。 et.al.|[2505.12620](http://arxiv.org/abs/2505.12620)|null|
|**2025-05-18**|**Video-GPT via Next Clip Diffusion**|GPT在自然语言处理方面取得了显著的成功。然而，语言序列不足以描述视觉世界中的时空细节。或者，视频序列擅长捕捉这些细节。基于这一事实，本文将视频视为视觉世界建模的新语言，提出了一种简洁的视频GPT。通过类比GPT中的下一个令牌预测，我们引入了一种新的下一片段扩散范式来预训练视频GPT。与之前的工作不同，这种独特的范式允许Video GPT通过根据历史上的干净片段对噪声片段进行自回归去噪来处理短期生成和长期预测。广泛的实验表明，我们的视频GPT在视频预测方面达到了最先进的性能，这是世界建模的关键因素（物理智商基准：视频GPT 34.97 vs.Kling 23.64 vs.Wan 20.89）。此外，它在视频生成和理解方面可以很好地适应6个主流视频任务，在下游显示出巨大的泛化能力。项目页面位于https://Video-GPT.github.io. et.al.|[2505.12489](http://arxiv.org/abs/2505.12489)|null|
|**2025-05-17**|**LOVE: Benchmarking and Evaluating Text-to-Video Generation and Video-to-Text Interpretation**|大型多模态模型（LMM）的最新进展推动了文本到视频（T2V）生成和视频到文本（V2T）解释任务的实质性进展。然而，当前的人工智能生成视频（AIGV）在感知质量和文本视频对齐方面仍然存在局限性。因此，需要一个可靠且可扩展的AIGV评估自动模型，该模型严重依赖于人类注释的规模和质量。为此，我们提出了AIGVE-60K，这是一个用于人工智能生成视频评估的综合数据集和基准，其特征是（i）综合任务，包括20个细粒度任务维度的3050个广泛提示，（ii）最大的人工注释，包括在30个T2V模型生成的58500个视频上注释的120K个平均意见得分（MOS）和60K个问答（QA）对，以及（iii）T2V生成和V2T解释能力的双向基准测试和评估。基于AIGVE-60K，我们提出了LOVE，这是一种基于LMM的AIGV评估指标，从多个维度进行评估，包括感知偏好、文本视频对应以及实例级和模型级的任务特定准确性。综合实验表明，LOVE不仅在AIGVE-60K数据集上实现了最先进的性能，而且有效地推广到了广泛的其他AIGV评估基准。这些发现突出了AIGVE-60K数据集的重要性。数据库和代码可匿名访问https://github.com/IntMeGroup/LOVE. et.al.|[2505.12098](http://arxiv.org/abs/2505.12098)|**[link](https://github.com/intmegroup/love)**|
|**2025-05-17**|**VFRTok: Variable Frame Rates Video Tokenizer with Duration-Proportional Information Assumption**|由于帧比例信息假设，基于潜在扩散模型的现代视频生成框架在标记化方面效率低下。现有的标记器提供固定的时间压缩率，导致扩散模型的计算成本随帧率线性缩放。本文提出了持续时间比例信息假设：视频信息容量的上限与持续时间成正比，而不是与帧数成正比。基于这一认识，本文介绍了VFRTok，一种基于Transformer的视频标记器，它通过编码器和解码器之间的非对称帧率训练实现了可变帧率编码和解码。此外，本文提出了部分旋转位置嵌入（RoPE）来解耦位置和内容建模，将相关补丁分组为统一的令牌。部分RoPE有效地提高了内容感知，增强了视频生成能力。得益于紧凑和连续的时空表示，VFRTok实现了具有竞争力的重建质量和最先进的生成保真度，而与现有的标记器相比，只使用了1/8的标记。 et.al.|[2505.12053](http://arxiv.org/abs/2505.12053)|null|
|**2025-05-17**|**SpatialCrafter: Unleashing the Imagination of Video Diffusion Models for Scene Reconstruction from Limited Observations**|新颖的视图合成（NVS）增强了计算机视觉和图形的沉浸式体验。现有技术虽然有所进步，但依赖于密集的多视图观测，限制了它们的应用。这项工作面临着从稀疏或单视图输入重建逼真3D场景的挑战。我们介绍了SpatialCrafter，这是一个利用视频扩散模型中的丰富知识来生成合理的额外观测值的框架，从而减轻了重建的模糊性。通过可训练的相机编码器和用于显式几何约束的极线注意机制，我们实现了精确的相机控制和3D一致性，并通过统一的尺度估计策略进一步加强了这一点，以处理数据集之间的尺度差异。此外，通过将单眼深度先验与视频潜在空间中的语义特征相结合，我们的框架直接回归3D高斯基元，并使用混合网络结构有效地处理长序列特征。大量实验表明，我们的方法增强了稀疏视图重建，恢复了3D场景的逼真外观。 et.al.|[2505.11992](http://arxiv.org/abs/2505.11992)|null|

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-19**|**Recollection from Pensieve: Novel View Synthesis via Learning from Uncalibrated Videos**|目前，几乎所有最先进的新颖视图合成和重建模型都依赖于校准的相机或额外的几何先验进行训练。这些先决条件极大地限制了它们对大量未校准数据的适用性。为了减轻这一要求，并释放在大规模未校准视频上进行自我监督训练的潜力，我们提出了一种新的两阶段策略，仅从原始视频帧或多视图图像训练视图合成模型，而不提供相机参数或其他先验。在第一阶段，我们学习在潜在空间中隐式重建场景，而不依赖于任何显式的3D表示。具体来说，我们预测每帧潜在的相机和场景上下文特征，并采用视图合成模型作为显式渲染的代理。这个预训练阶段大大降低了优化的复杂性，并鼓励网络以自我监督的方式学习底层的3D一致性。与真实的3D世界相比，学习的潜在相机和隐式场景表示有很大的差距。为了缩小这一差距，我们通过显式预测3D高斯基元引入了第二阶段训练。我们还应用了显式高斯散斑渲染损失和深度投影损失，以将学习到的潜在表示与物理基础的3D几何体对齐。通过这种方式，第一阶段提供了一个强大的初始化，第二阶段加强了3D一致性——这两个阶段是互补的，互惠互利的。大量实验证明了我们的方法的有效性，与使用校准、姿态或深度信息进行监督的方法相比，我们实现了高质量的新颖视图合成和精确的相机姿态估计。该代码可在以下网址获得https://github.com/Dwawayu/Pensieve. et.al.|[2505.13440](http://arxiv.org/abs/2505.13440)|**[link](https://github.com/dwawayu/pensieve)**|
|**2025-05-19**|**Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation**|动态3D场景重建的最新进展显示出有希望的结果，能够实现具有改进时间一致性的高保真3D新颖视图合成。其中，4D高斯散斑（4DGS）因其能够模拟高保真的空间和时间变化而成为一种有吸引力的方法。然而，由于4D高斯分布到静态区域的冗余分配，现有方法存在大量的计算和内存开销，这也会降低图像质量。在这项工作中，我们引入了混合3D-4D高斯散斑（3D-4DGS），这是一种新的框架，它用3D高斯自适应地表示静态区域，同时为动态元素保留4D高斯。我们的方法从完全4D高斯表示开始，迭代地将时间不变的高斯转换为3D，显著减少了参数的数量并提高了计算效率。同时，动态高斯模型保留了其完整的4D表示，以高保真度捕捉复杂的运动。与基线4D高斯散斑方法相比，我们的方法实现了更快的训练时间，同时保持或提高了视觉质量。 et.al.|[2505.13215](http://arxiv.org/abs/2505.13215)|null|
|**2025-05-17**|**SpatialCrafter: Unleashing the Imagination of Video Diffusion Models for Scene Reconstruction from Limited Observations**|新颖的视图合成（NVS）增强了计算机视觉和图形的沉浸式体验。现有技术虽然有所进步，但依赖于密集的多视图观测，限制了它们的应用。这项工作面临着从稀疏或单视图输入重建逼真3D场景的挑战。我们介绍了SpatialCrafter，这是一个利用视频扩散模型中的丰富知识来生成合理的额外观测值的框架，从而减轻了重建的模糊性。通过可训练的相机编码器和用于显式几何约束的极线注意机制，我们实现了精确的相机控制和3D一致性，并通过统一的尺度估计策略进一步加强了这一点，以处理数据集之间的尺度差异。此外，通过将单眼深度先验与视频潜在空间中的语义特征相结合，我们的框架直接回归3D高斯基元，并使用混合网络结构有效地处理长序列特征。大量实验表明，我们的方法增强了稀疏视图重建，恢复了3D场景的逼真外观。 et.al.|[2505.11992](http://arxiv.org/abs/2505.11992)|null|
|**2025-05-16**|**Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views**|基于视觉的机器人操纵使用相机捕捉包含待操纵对象的场景的一个或多个图像。如果任何物体从一个视点被遮挡，但从另一个视点更可见，拍摄多张图像会有所帮助。然而，必须将相机移动到一系列合适的位置以捕获多个图像，这需要时间，并且由于可达性限制，可能并不总是可能的。因此，虽然由于可用的额外信息，额外的图像可以产生更准确的抓握姿势，但时间成本会随着采样的额外视图数量的增加而增加。高斯散点等场景表示能够从用户指定的新颖视点渲染出精确的逼真虚拟图像。在这项工作中，我们展示了初步结果，表明新颖的视图合成可以在生成抓握姿势时提供额外的背景。我们在Grassnet-1十亿数据集上的实验表明，除了从稀疏采样的真实视图中获得的力闭合抓取外，新视图还贡献了力闭合抓取，同时提高了抓取覆盖率。未来，我们希望这项工作可以扩展到使用例如扩散模型或可推广的辐射场来改进从由单个输入图像构建的辐射场中提取的抓取。 et.al.|[2505.11467](http://arxiv.org/abs/2505.11467)|null|
|**2025-05-16**|**MutualNeRF: Improve the Performance of NeRF under Limited Samples with Mutual Information Theory**|本文介绍了MutualNeRF，这是一种使用互信息理论在有限样本下增强神经辐射场（NeRF）性能的框架。虽然NeRF在3D场景合成方面表现出色，但数据有限，旨在引入先验知识的现有方法缺乏统一框架中的理论支持，这带来了挑战。我们引入了一个简单但理论上稳健的概念，互信息，作为统一衡量图像之间相关性的指标，同时考虑了宏观（语义）和微观（像素）层面。对于稀疏视图采样，我们通过最小化互信息来策略性地选择包含更多非重叠场景信息的额外视点，而无需事先知道地面真实图像。我们的框架采用贪婪算法，提供近乎最优的解决方案。对于少镜头视图合成，我们最大化推断图像和地面实况之间的互信息，期望推断图像从已知图像中获得更多相关信息。这是通过结合高效的即插即用正则化术语来实现的。在有限样本下的实验表明，在不同环境下，与最先进的基线相比，我们的框架的有效性得到了持续的改善。 et.al.|[2505.11386](http://arxiv.org/abs/2505.11386)|null|
|**2025-05-15**|**NVSPolicy: Adaptive Novel-View Synthesis for Generalizable Language-Conditioned Policy Learning**|深度生成模型的最新进展展示了前所未有的零样本泛化能力，为非结构化环境中的机器人操作提供了巨大的潜力。给定对场景的部分观察，深度生成模型可以生成看不见的区域，从而提供更多的上下文，这增强了机器人在看不见环境中进行泛化的能力。然而，由于生成图像中的视觉伪影和策略学习中多模态特征的低效集成，这一方向仍然是一个悬而未决的挑战。我们介绍了NVSPolicy，这是一种可推广的语言条件策略学习方法，它将自适应新视图合成模块与分层策略网络相结合。给定输入图像，NVSPolicy动态选择一个有信息的视点，并合成一个自适应新视图图像，以丰富视觉上下文。为了减轻合成图像不完美的影响，我们采用了一种循环一致的VAE机制，将视觉特征分解为语义特征和剩余特征。然后，这两个特征分别被馈送到分层策略网络中：语义特征通知高级元技能选择，其余特征指导低级动作估计。此外，我们提出了几种实用的机制来提高所提出方法的效率。CALVIN上的大量实验证明了我们方法的最先进性能。具体来说，它在所有任务中的平均成功率为90.4%，大大优于最近的方法。消融研究证实了我们自适应新视角合成范式的重要性。此外，我们在现实世界的机器人平台上评估了NVSPolicy，以证明其实际适用性。 et.al.|[2505.10359](http://arxiv.org/abs/2505.10359)|null|
|**2025-05-15**|**VRSplat: Fast and Robust Gaussian Splatting for Virtual Reality**|3D高斯散斑（3DGS）已迅速成为新型视图合成的领先技术，通过高效的基于软件的GPU光栅化提供卓越的性能。它的多功能性使实时应用成为可能，包括在移动设备和低功耗设备上。然而，3DGS在虚拟现实（VR）中面临着关键挑战：（1）时间伪影，如头部运动时爆裂；（2）基于投影的失真，导致令人不安和视图不一致的漂浮物；（3）渲染大量高斯分布时帧率降低，低于VR的临界阈值。与桌面环境相比，这些问题因大视场、持续的头部移动和头戴式显示器（HMD）的高分辨率而大大加剧。在这项工作中，我们介绍了VRSplat：我们结合并扩展了3DGS的几个最新进展，以全面应对VR的挑战。我们展示了如何通过修改单个技术和核心3DGS光栅化器，使Mini Splatting、StopThePop和Optimal Projection的想法相辅相成。此外，我们提出了一种高效的中心凹光栅化器，可以在单个GPU启动中处理焦点和外围区域，避免冗余计算并提高GPU利用率。我们的方法还包含了一个微调步骤，该步骤基于StopThePop深度评估和最优投影来优化高斯参数。我们通过一项有25名参与者参与的对照用户研究来验证我们的方法，结果显示VRSplat比其他配置的Mini Splatting更受欢迎。VRSplat是第一个经过系统评估的3DGS方法，能够支持现代VR应用程序，实现72+FPS，同时消除爆裂和立体声干扰浮动。 et.al.|[2505.10144](http://arxiv.org/abs/2505.10144)|**[link](https://github.com/cekavis/vrsplat)**|
|**2025-05-13**|**FOCI: Trajectory Optimization on Gaussian Splats**|3D高斯散斑（3DGS）最近作为3D重建和视图合成方法中神经辐射场（NeRF）的更快替代方案而受到欢迎。利用3DGS中编码的空间信息，这项工作提出了FOCI（场重叠碰撞积分），这是一种能够直接在高斯本身上优化轨迹的算法。FOCI利用高斯重叠积分的概念，为3DGS利用了一种新颖且可解释的碰撞公式。与其他方法相反，这些方法用保守的边界框表示机器人，低估了环境的可穿越性，我们建议将环境和机器人表示为高斯散点。这不仅具有理想的计算特性，而且允许进行方向感知规划，使机器人能够穿过非常狭窄的空间。我们在合成和真实高斯Splats中广泛测试了我们的算法，展示了ANYmal腿式机器人的无碰撞轨迹，即使有数十万高斯人组成环境，也可以在几秒钟内计算出来。项目页面和代码可在https://rffr.leggedrobotics.com/works/foci/ et.al.|[2505.08510](http://arxiv.org/abs/2505.08510)|null|
|**2025-05-13**|**ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image**|我们将自适应视图规划引入多视图合成，旨在提高单视图3D重建的遮挡显示和3D一致性。我们不是独立或同时生成一组无序的视图，而是生成一系列视图，利用时间一致性来增强3D一致性。最重要的是，我们的视图序列不是由预先确定的相机设置决定的。相反，我们计算自适应相机轨迹（ACT），具体来说，是相机视图的轨迹，它最大限度地提高了要重建的3D对象的遮挡区域的可见性。一旦找到最佳轨道，我们将其输入视频扩散模型，以生成轨道周围的新视图，然后将其传递给多视图3D重建模型，以获得最终重建。我们的多视图合成管道非常高效，因为它不涉及运行时训练/优化，只涉及通过应用预训练的模型进行遮挡分析和多视图合成的前向推理。我们的方法预测了相机轨迹，有效地揭示了遮挡并产生了一致的新视图，在看不见的GSO数据集上显著改善了SOTA的3D重建，无论是定量还是定性。 et.al.|[2505.08239](http://arxiv.org/abs/2505.08239)|null|
|**2025-05-13**|**TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin Benchmark Dataset**|城市数字双胞胎（UDTs）已成为管理城市和整合来自不同来源的复杂异构数据的关键。创建UDT涉及多个过程阶段的挑战，包括获取准确的3D源数据、重建高保真3D模型、维护模型的更新，以及确保与下游任务的无缝互操作性。当前的数据集通常仅限于处理链的一部分，阻碍了全面的UDT验证。为了应对这些挑战，我们推出了第一个全面的多模式城市数字孪生基准数据集：TUM2TWIN。该数据集包括地理参考、语义对齐的3D模型和网络，以及各种地面、移动、空中和卫星观测，拥有32个数据子集，数据量约为100000美元，目前为767 GB。通过确保地理参考的室内外采集、高精度和多模态数据集成，该基准支持传感器的稳健分析和先进重建方法的开发。此外，我们还探索了展示TUM2TWIN潜力的下游任务，包括NeRF和高斯散斑的新颖视图合成、太阳势分析、点云语义分割和LoD3建筑重建。我们相信，这一贡献为克服UDT创建中的当前局限性奠定了基础，为更智能、数据驱动的城市环境培养了新的研究方向和实用的解决方案。该项目可在以下网址获得：https://tum2t.win et.al.|[2505.07396](http://arxiv.org/abs/2505.07396)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-19**|**TS-VLM: Text-Guided SoftSort Pooling for Vision-Language Models in Multi-View Driving Reasoning**|视觉语言模型（VLMs）通过利用多模态融合来增强场景感知、推理和决策，在推进自动驾驶方面显示出巨大的潜力。尽管有潜力，但现有模型存在计算开销和多视图传感器数据集成效率低的问题，这使得它们在安全关键的自动驾驶应用中无法实时部署。为了解决这些缺点，本文致力于设计一种名为TS-VLM的轻量级VLM，该VLM包含一个新颖的文本引导软排序池（TGSSP）模块。通过利用输入查询的语义，TGSSP对来自多个视图的视觉特征进行排名和融合，实现了动态和查询感知的多视图聚合，而不依赖于昂贵的注意力机制。这种设计确保了语义相关视图的查询自适应优先级，从而提高了自动驾驶多视图推理的上下文准确性。对DriveLM基准的广泛评估表明，一方面，TS-VLM的表现优于最先进的模型，BLEU-4得分为56.82，METEOR为41.91，ROUGE-L为74.64，CIDEr为3.39。另一方面，TS-VLM将计算成本降低了90%，其中最小版本仅包含2010万个参数，使其更适合在自动驾驶汽车中实时部署。 et.al.|[2505.12670](http://arxiv.org/abs/2505.12670)|null|
|**2025-05-18**|**From Low Field to High Value: Robust Cortical Mapping from Low-Field MRI**|通过MRI对皮质表面进行三维重建以进行形态计量分析是理解大脑结构的基础。虽然高场MRI（HF-MRI）是研究和临床环境中的标准，但其有限的可用性阻碍了其广泛使用。低场MRI（LF-MRI），特别是便携式系统，提供了一种经济高效且易于使用的替代方案。然而，现有的皮质表面分析工具针对高分辨率HF-MRI进行了优化，并与LF-MRI较低的信噪比和分辨率作了斗争。在这项工作中，我们提出了一种机器学习方法，用于在一系列对比度和分辨率下对便携式LF-MRI进行3D重建和分析。我们的方法“开箱即用”，无需重新训练。它使用在合成LF-MRI上训练的3D U-Net来预测皮质表面的带符号距离函数，然后进行几何处理以确保拓扑精度。我们使用同一受试者的成对HF/LF-MRI扫描来评估我们的方法，表明LF-MRI表面重建精度取决于采集参数，包括对比度类型（T1 vs T2）、方向（轴向vs各向同性）和分辨率。在4分钟内获得的3mm各向同性T2加权扫描与HF衍生表面高度一致：表面积相关r=0.96，皮质分裂达到Dice=0.98，灰质体积达到r=0.93。皮质厚度仍然更具挑战性，相关性高达r=0.70，反映了3mm体素亚毫米精度的困难。我们进一步验证了我们的方法在挑战死后LF-MRI方面的有效性，证明了其鲁棒性。我们的方法代表了在便携式LF-MRI上实现皮质表面分析的一步。代码可在https://surfer.nmr.mgh.harvard.edu/fswiki/ReconAny et.al.|[2505.12228](http://arxiv.org/abs/2505.12228)|null|
|**2025-05-17**|**GTR: Gaussian Splatting Tracking and Reconstruction of Unknown Objects Based on Appearance and Geometric Complexity**|我们提出了一种从单目RGBD视频中进行6自由度目标跟踪和高质量3D重建的新方法。现有的方法虽然取得了令人印象深刻的结果，但往往难以处理复杂的物体，特别是那些表现出对称性、复杂几何形状或复杂外观的物体。为了弥合这些差距，我们引入了一种自适应方法，该方法结合了3D高斯散布、混合几何/外观跟踪和关键帧选择，以实现对各种对象的鲁棒跟踪和精确重建。此外，我们提出了一个涵盖这些具有挑战性的对象类的基准，为评估跟踪和重建性能提供了高质量的注释。我们的方法在恢复高保真对象网格方面表现出了强大的能力，为开放世界环境中的单传感器3D重建树立了新的标准。 et.al.|[2505.11905](http://arxiv.org/abs/2505.11905)|null|
|**2025-05-17**|**Diffmv: A Unified Diffusion Framework for Healthcare Predictions with Random Missing Views and View Laziness**|通过利用预测分析，先进的医疗预测可以显著改善患者的预后。现有的工作主要利用电子健康记录（EHR）数据的各种视图，如诊断、实验室测试或临床记录，进行模型训练。这些方法通常假设完整的EHR视图可用，并且设计的模型可以充分利用每个视图的潜力。然而，在实践中，随机缺失视图和视图懒惰带来了两个重大挑战，阻碍了多视图利用率的进一步提高。为了应对这些挑战，我们引入了Diffmv，这是一种创新的基于扩散的生成框架，旨在推进EHR数据多视图的开发。具体来说，为了解决随机缺失的视图，我们将EHR数据的各种视图整合到一个统一的扩散去噪框架中，并丰富了不同的上下文条件，以促进渐进对齐和视图转换。为了减轻视图惰性，我们提出了一种新的重新加权策略，该策略评估了每个视图的相对优势，促进了模型内各种数据视图的平衡利用。我们提出的策略在来自三个流行数据集的多个健康预测任务中实现了卓越的性能，包括多视图和多模态场景。 et.al.|[2505.11802](http://arxiv.org/abs/2505.11802)|null|
|**2025-05-16**|**Patient-Specific Dynamic Digital-Physical Twin for Coronary Intervention Training: An Integrated Mixed Reality Approach**|背景和目的：冠状动脉介入治疗的精确术前计划和有效的医生培训越来越重要。尽管医学成像技术取得了进步，但将静态或有限的动态成像数据转化为全面的动态心脏模型仍然具有挑战性。现有的训练系统缺乏对心脏生理动力学的精确模拟。本研究基于4D-CTA开发了一个全面的动态心脏模型研究框架，整合了数字孪生技术、计算机视觉和物理模型制造，为介入心脏病学提供了精确、个性化的工具。方法：利用一名60岁女性三支冠状动脉狭窄患者的4D-CTA数据，我们分割了心腔和冠状动脉，构建了动态模型，并实现了骨骼蒙皮重量计算，以模拟20个心脏阶段的血管变形。使用医用级硅胶制造透明血管物理模型。我们开发了心输出量分析和虚拟血管造影系统，使用双目立体视觉实现了导丝3D重建，并通过血管造影验证和冠状动脉旁路移植术训练应用程序对系统进行了评估。结果：虚拟和真实血管造影的形态学一致性达到80.9%。导丝运动的Dice相似系数范围为0.741-0.812，平均轨迹误差低于1.1 mm。透明模型在冠状动脉旁路移植术训练中具有优势，可以在模拟心脏跳动挑战的同时进行直接可视化。结论：我们的患者特异性数字物理双胞胎方法有效地再现了冠状动脉血管的解剖结构和动态特征，提供了一个具有视觉和触觉反馈的动态环境，对教育和临床规划具有重要价值。 et.al.|[2505.10902](http://arxiv.org/abs/2505.10902)|null|
|**2025-05-15**|**Mapping Semantic Segmentation to Point Clouds Using Structure from Motion for Forest Analysis**|尽管使用遥感技术监测森林环境越来越受到关注，但由于成本高、传感器要求高和采集时间密集，公开可用的点云数据集仍然稀缺。此外，据我们所知，没有通过应用于图像的运动结构（SfM）算法生成的公共注释数据集，这可能是由于缺乏能够将语义分割信息映射到准确点云中的SfM算法，特别是在森林等具有挑战性的环境中。在这项工作中，我们提出了一种新的管道，用于生成森林环境的语义分段点云。使用定制的森林模拟器，我们生成了各种森林场景的逼真RGB图像及其相应的语义分割蒙版。然后，使用修改后的开源SfM软件对这些标记图像进行处理，该软件能够在3D重建过程中保留语义信息。由此产生的点云提供了几何和语义细节，为训练和评估旨在分割通过SfM获得的真实森林点云的深度学习模型提供了宝贵的资源。 et.al.|[2505.10751](http://arxiv.org/abs/2505.10751)|null|
|**2025-05-14**|**Robust Photo-Realistic Hand Gesture Generation: from Single View to Multiple View**|高保真手势生成是以人为中心的生成任务中的一项重大挑战。现有方法通常在提高手势生成质量之前采用单视图3D MANO网格渲染图像。然而，手部动作的复杂性和单视图渲染的固有局限性使得捕捉完整的3D手部信息变得困难，特别是在手指被遮挡的情况下。基本矛盾在于通过2D投影失去了3D拓扑关系，以及单视图表示固有的不完整空间覆盖。与单视图先验方法不同，我们提出了一种多视图先验框架，称为基于多模态UNet的特征编码器（MUFEN），用于指导扩散模型学习全面的3D手部信息。具体来说，我们扩展了传统的前视图渲染，包括后、左、右、上和下视角，选择信息最丰富的视图组合作为训练先验，以解决遮挡完成问题。这种具有专用双流编码器的多视图先验显著提高了模型对完整手部特征的理解。此外，我们设计了一个边界框特征融合模块，该模块可以融合手势定位特征和手势多模态特征，以增强MUFEN特征对手势相关特征的位置感知。实验证明，我们的方法在定量指标和定性评估方面都达到了最先进的性能。 et.al.|[2505.10576](http://arxiv.org/abs/2505.10576)|null|
|**2025-05-15**|**VolE: A Point-cloud Framework for Food 3D Reconstruction and Volume Estimation**|准确的食物量估计对于医疗营养管理和健康监测应用至关重要，但目前的食物量估算方法往往受到单核数据的限制，利用3D扫描仪等单一用途硬件，收集深度信息等面向传感器的信息，或依赖于使用参考对象的相机校准。在这篇论文中，我们提出了VolE，这是一种利用移动设备驱动的3D重建来估计食物量的新框架。得益于支持AR的移动设备，VolE可以自由捕捉图像和相机位置，以生成精确的3D模型。为了实现真实世界的测量，VolE是一个无参考和深度的框架，它利用食物视频分割来生成食物口罩。我们还引入了一个新的食品数据集，涵盖了之前基准测试中没有的具有挑战性的场景。我们的实验表明，VolE在多个数据集上的表现优于现有的体积估计技术，实现了2.22%的MAPE，突显了其在食物体积估计方面的卓越性能。 et.al.|[2505.10205](http://arxiv.org/abs/2505.10205)|null|
|**2025-05-13**|**Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions**|高质量的肺节段三维重建在肺癌节段切除术和手术治疗计划中起着至关重要的作用。由于目标重建的分辨率要求，传统的基于深度学习的方法经常受到计算资源约束或粒度有限的影响。相反，隐式建模因其计算效率和在任何分辨率下的连续表示而受到青睐。我们提出了一种基于神经隐式函数的方法来学习3D表面，以实现解剖感知的精确肺段重建，通过变形可学习的模板将其表示为形状。此外，我们引入了两个临床相关的评估指标来全面评估重建。此外，由于缺乏公开可用的形状数据集来对重建算法进行基准测试，我们开发了一个名为Lung3D的形状数据集中，包括800个标记的肺段和相应的气道、动脉、静脉和段间静脉的3D模型。我们证明，所提出的方法优于现有的方法，为肺段重建提供了新的视角。代码和数据将在https://github.com/M3DV/ImPulSe. et.al.|[2505.08919](http://arxiv.org/abs/2505.08919)|**[link](https://github.com/m3dv/impulse)**|
|**2025-05-13**|**FOCI: Trajectory Optimization on Gaussian Splats**|3D高斯散斑（3DGS）最近作为3D重建和视图合成方法中神经辐射场（NeRF）的更快替代方案而受到欢迎。利用3DGS中编码的空间信息，这项工作提出了FOCI（场重叠碰撞积分），这是一种能够直接在高斯本身上优化轨迹的算法。FOCI利用高斯重叠积分的概念，为3DGS利用了一种新颖且可解释的碰撞公式。与其他方法相反，这些方法用保守的边界框表示机器人，低估了环境的可穿越性，我们建议将环境和机器人表示为高斯散点。这不仅具有理想的计算特性，而且允许进行方向感知规划，使机器人能够穿过非常狭窄的空间。我们在合成和真实高斯Splats中广泛测试了我们的算法，展示了ANYmal腿式机器人的无碰撞轨迹，即使有数十万高斯人组成环境，也可以在几秒钟内计算出来。项目页面和代码可在https://rffr.leggedrobotics.com/works/foci/ et.al.|[2505.08510](http://arxiv.org/abs/2505.08510)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-19**|**Mean Flows for One-step Generative Modeling**|我们提出了一个原则性和有效的一步生成建模框架。我们引入了平均速度的概念来表征流场，与流动匹配方法建模的瞬时速度形成对比。推导出了平均速度和瞬时速度之间的明确标识，并用于指导神经网络训练。我们的方法称为MeanFlow模型，它是自包含的，不需要预先培训、提炼或课程学习。MeanFlow显示出强大的经验性能：它在从头开始训练的ImageNet 256x256上通过单函数评估（1-NFE）实现了3.43的FID，显著优于之前最先进的一步扩散/流动模型。我们的研究大大缩小了一步扩散/流动模型与其多步前辈之间的差距，我们希望这将激励未来的研究重新审视这些强大模型的基础。 et.al.|[2505.13447](http://arxiv.org/abs/2505.13447)|null|
|**2025-05-19**|**FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance**|尽管在视频生成方面取得了重大进展，但合成物理上合理的人类行为仍然是一个持续的挑战，特别是在建模细粒度语义和复杂的时间动态方面。例如，生成“0.5转跳台”等体操套路对当前的方法构成了实质性的困难，往往会产生不令人满意的结果。为了弥合这一差距，我们提出了FinePhys，这是一个细粒度的人类动作生成框架，它结合了物理学来获得有效的骨架指导。具体来说，FinePhys首先以在线方式估计2D姿势，然后通过上下文学习执行2D到3D的维度提升。为了减轻纯数据驱动的3D姿态的不稳定性和有限的可解释性，我们进一步引入了一个由欧拉-拉格朗日方程控制的基于物理的运动重新估计模块，通过双向时间更新计算关节加速度。然后将物理预测的3D姿态与数据驱动的姿态融合，为扩散过程提供多尺度2D热图指导。根据FineGym的三个细粒度动作子集（FX-JUMP、FX-TURN和FX-SALTO）进行评估，FinePhys的表现明显优于竞争基线。全面的定性结果进一步证明了FinePhys能够生成更自然、更合理的精细人类行为。 et.al.|[2505.13437](http://arxiv.org/abs/2505.13437)|null|
|**2025-05-20**|**A Practical Guide for Incorporating Symmetry in Diffusion Policy**|最近，用于策略学习的等变神经网络在样本效率和泛化方面显示出有希望的改进，然而，由于实现的复杂性，它们的广泛采用面临着巨大的障碍。等变架构通常需要专门的数学公式和自定义网络设计，这在与基于扩散的模型等现代政策框架集成时带来了重大挑战。在本文中，我们探索了一些简单实用的方法，将对称性收益纳入扩散策略，而不需要完全等变设计的开销。具体而言，我们研究了（i）通过相对轨迹动作和手眼感知的不变表示，（ii）集成等变视觉编码器，以及（iii）使用帧平均的预训练编码器进行对称特征提取。我们首先证明，将手眼感知与相对或增量动作参数化相结合会产生固有的SE（3）不变性，从而提高策略泛化能力。然后，我们对这些在扩散策略中集成对称性的设计选择进行了系统的实验研究，并得出结论，具有等变特征提取的不变表示显著提高了策略性能。我们的方法在大大简化实现的同时，实现了与完全等效架构相当或超过完全等效架构的性能。 et.al.|[2505.13431](http://arxiv.org/abs/2505.13431)|null|
|**2025-05-19**|**Fine-tuning Quantized Neural Networks with Zeroth-order Optimization**|随着大型语言模型的规模呈指数级增长，GPU内存已成为使这些模型适应下游任务的瓶颈。在这篇论文中，我们的目标是通过在统一的框架内最小化模型权重、梯度和优化器状态的内存使用来突破内存高效训练的极限。我们的想法是使用零阶优化来消除梯度和优化器的状态，零阶优化通过在正向传递过程中扰动权重来识别梯度方向，从而近似梯度。为了最大限度地减少权重的内存使用，我们采用了模型量化，例如从bfloat16转换为int4。然而，由于离散权重和连续梯度之间的精度差距，直接将零阶优化应用于量化权重是不可行的，否则需要去量化和重新量化。为了克服这一挑战，我们提出了量化零阶优化（QZO），这是一种扰乱连续量化尺度进行梯度估计的新方法，并使用方向导数削波方法来稳定训练。QZO与基于标量和基于码本的训练后量化方法正交。与bfloat16中的全参数微调相比，QZO可以将4位LLM的总内存成本降低18美元以上，并在单个24GB GPU内实现Llama-213B和Stable Diffusion 3.5 Large的微调。 et.al.|[2505.13430](http://arxiv.org/abs/2505.13430)|null|
|**2025-05-19**|**Unraveling superradiance: entanglement and mutual information in collective decay**|我们研究了初始倒置的二能级发射器系综到压缩光子库中的集体衰变。通过使用量子态扩散方法来解开发射过程，我们研究了随着时间的推移，沿着单个量子轨迹的纠缠和经典相关性。这一数值分析表明，尽管纠缠的初始建立加速，稳态下存在大量的自旋压缩，但超辐射爆发的基本特征可以用完全可分解态的平均值很好地描述。我们用所有2-局部可观测值的几乎完全因式分解来解释这一观察结果，我们将其确定为超辐射衰变的一般性质。基于这一认识，我们为压缩超辐射中的爆发提供了一个纯粹的经典理论，该理论对于大量发射器来说既直观又精确。此外，我们表明我们的数值方法也适用于亚辐射态的研究，亚辐射态在很长一段时间内主导着非均匀系综的缓慢残余衰变。 et.al.|[2505.13401](http://arxiv.org/abs/2505.13401)|null|
|**2025-05-19**|**Faster Video Diffusion with Trainable Sparse Attention**|缩放视频扩散变换器（DiTs）受到其二次3D注意力的限制，尽管大部分注意力集中在一小部分位置上。我们将这一观察结果转化为VSA，这是一种可训练的、硬件高效的稀疏注意力，在训练和推理时取代了完全注意力。在VSA中，一个轻量级的粗略阶段将令牌汇集到图块中，并识别高权重的\emph{关键令牌}；精细阶段仅在经过块计算布局的图块内计算令牌级注意力，以确保硬效率。这导致了一个端到端训练的单一可微分内核，不需要事后分析，并支持85%的FlashAttention3 MFU。我们通过将DiTs从60M预训练到1.4B参数，进行了大量的消融研究和标度律实验。VSA达到帕累托点，将训练FLOPS减少2.53美元，而扩散损失没有下降。改装开源Wan-2.1型号可将注意力时间缩短6美元，并将端到端生成时间从31秒缩短到18秒，质量相当。这些结果确立了可训练的稀疏注意力作为完全注意力的实用替代方案，也是进一步扩展视频扩散模型的关键因素。 et.al.|[2505.13389](http://arxiv.org/abs/2505.13389)|null|
|**2025-05-19**|**The localization transition for the directed polymer in a random environment is smooth**|当 $d\ge 3$时，已知$\mathbb Z^d$上随机环境中的定向聚合物a显示出从扩散相（称为\textit{弱无序}）到局部相（称为主无序}）的相变。这种转变由模型的自由能行为编码，由$$\mathfrak f（\beta）定义：=\lim_{N\to\infty}（1/N）\log W^{\beta}_N$$，其中$W^{/beta}_N$是长度为$N$的有向聚合物的归一化配分函数。更精确地说，弱无序对应于$\mathfrak f（\beta）=0$，强无序对应于$\mathfrag f（\bbeta）<0$。$\mathfrak f$的单调性和连续性意味着存在$\beta_c\in[0，\infty]$，因此弱无序等价于$\beta\in[0,\beta_c]$。此外，当且仅当$d\ge 3$时，$\beta_c>0$。我们证明了这种转变是无限平滑的，因为$\mathfrak f$的增长速度比$\beta_c$附近的任何幂函数都慢，即$\lim_{\beta\downarrow\beta_c}\frac{\log|\mathfrak-f（\beta）|}{\log（\beta-\beta_c）}=\infty。$$ et.al.|[2505.13382](http://arxiv.org/abs/2505.13382)|null|
|**2025-05-19**|**Restoration Score Distillation: From Corrupted Diffusion Pretraining to One-Step High-Quality Generation**|从损坏的数据中学习生成模型是跨科学学科的一项基本但持续具有挑战性的任务，特别是在获取干净数据有限或昂贵的情况下。去噪分数蒸馏（DSD）最近引入了一种新颖且令人惊讶的有效策略，该策略利用分数蒸馏直接从噪声观测中训练高保真生成模型。在此基础上，我们提出了\textit{恢复分数蒸馏}（RSD），这是DSD的一种原则性概括，可容纳更广泛的损坏类型，如模糊、不完整或低分辨率图像。RSD的操作方法是首先仅在损坏的数据上预训练教师扩散模型，然后将其提取到一个单步生成器中，生成高质量的重建。根据经验，RSD在自然和科学数据集的各种恢复任务中始终超越了其教师模型。此外，除了标准扩散目标外，RSD框架还与几种感知腐败的训练技术兼容，如Ambient Tweedie、Ambient diffusion及其傅里叶空间变体，从而能够与扩散建模的最新进展灵活集成。理论上，我们证明了在线性状态下，RSD从线性测量中恢复干净数据协方差矩阵的特征空间，从而充当隐式正则化器。这种解释将分数蒸馏重新定义为一种采样加速技术，而且是一种在严重退化的数据体系中提高生成性能的原则性方法。 et.al.|[2505.13377](http://arxiv.org/abs/2505.13377)|null|
|**2025-05-20**|**Minimum-Excess-Work Guidance**|我们提出了一个受热力学工作启发的正则化框架，通过最小化多余功来指导预训练的概率流生成模型（例如连续归一化流或扩散模型），这是一个植根于统计力学的概念，与最优输运有很强的概念联系。我们的方法能够在科学应用中常见的稀疏数据状态下进行有效的指导，在这种情况下，只有有限的目标样本或部分密度约束可用。我们介绍了两种策略：通过将概率质量集中在用户定义的子集上对罕见过渡态进行采样的路径引导，以及在保持熵的同时将生成的分布与实验可观测值对齐的可观测引导。我们在粗粒蛋白质模型上展示了该框架的多功能性，引导它对折叠/展开状态之间的过渡配置进行采样，并使用实验数据纠正系统偏差。该方法将热力学原理与现代生成架构联系起来，为数据稀缺领域的标准微调提供了一种有原则、高效和受物理启发的替代方案。实证结果强调了样品效率的提高和偏差的减少，强调了其对分子模拟及其他领域的适用性。 et.al.|[2505.13375](http://arxiv.org/abs/2505.13375)|null|
|**2025-05-19**|**Structure-preserving schemes conserving entropy and kinetic energy**|本文提出了一种新的欧拉方程结构保持方案，重点研究了熵和动能的数值守恒。在有限体积框架内引入了显式通量函数来保持熵。此外，还引入了离散动能守恒。本文首先概述了数值熵守恒和熵守恒和动能守恒通量的公式，然后研究了它们的性质和功效。引入了一种新颖的方法，将数值熵守恒与能量守恒方程的离散化联系起来。此外，还介绍了一种熵稳定的冲击捕获扩散方法和一种利用熵距离有效管理平滑区域的混合方法。在适当的区域添加人工粘度可确保熵的产生足以防止数值不稳定。展示了各种测试案例，展示了所提出方法的有效性和稳定性。 et.al.|[2505.13374](http://arxiv.org/abs/2505.13374)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-19**|**Neural Functional: Learning Function to Scalar Maps for Neural PDE Surrogates**|近年来，已经提出了许多神经PDE替代物的架构，主要基于神经网络或算子学习。在这项工作中，我们推导并提出了一种新的架构，即神经泛函，它学习函数到标量的映射。它的实现利用了算子学习和神经场的见解，我们展示了神经泛函隐式学习函数导数的能力。这是第一次通过学习哈密顿泛函并优化其泛函导数，将哈密顿力学扩展到神经PDE替代物。我们证明了哈密顿神经泛函可以通过提高1D和2D PDE的稳定性和守恒类能量来成为一种有效的替代模型。除了偏微分方程，泛函在物理学中也很普遍；函数逼近及其梯度学习可能还有其他用途，例如在分子动力学或设计优化中。 et.al.|[2505.13275](http://arxiv.org/abs/2505.13275)|**[link](https://github.com/anthonyzhou-1/hamiltonian_pdes)**|
|**2025-05-15**|**Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field**|近年来，在神经辐射场和3D高斯溅射技术的突破推动下，动态场景表示和重建取得了革命性的进展。虽然最初是为静态环境开发的，但这些方法已经通过广泛的研究迅速发展，以解决4D动态场景中固有的复杂性。结合可微分体绘制的创新，这些方法显著提高了运动表示和动态场景重建的质量，从而引起了计算机视觉和图形界的广泛关注。这项调查对200多篇论文进行了系统分析，这些论文侧重于使用辐射场进行动态场景表示，涵盖了从隐式神经表示到显式高斯基元的光谱。我们通过多个关键镜头对这些作品进行分类和评估：运动表示范式、不同场景动态的重建技术、辅助信息集成策略以及确保时间一致性和物理合理性的正则化方法。我们在统一的代表性框架下组织了不同的方法论方法，最后对持续存在的挑战和有前景的研究方向进行了批判性考察。通过提供这一全面的概述，我们的目标是为进入这一快速发展领域的研究人员建立一个明确的参考，同时为经验丰富的从业者提供对动态场景重建的概念原理和实践前沿的系统理解。 et.al.|[2505.10049](http://arxiv.org/abs/2505.10049)|**[link](https://github.com/moonflo/dynamic-radiation-field-paper-list)**|
|**2025-04-30**|**Neural Co-Optimization of Structural Topology, Manufacturable Layers, and Path Orientations for Fiber-Reinforced Composites**|我们提出了一种基于神经网络的计算框架，用于同时优化结构拓扑、弯曲层和路径方向，以在确保可制造性的同时实现纤维增强热塑性复合材料的强各向异性强度。我们的框架采用三个隐式神经场来表示几何形状、层序列和纤维取向。这使得设计和可制造性目标（如各向异性强度、结构体积、机器运动控制、层曲率和层厚度）能够直接公式化为一个集成和可微分的优化过程。通过将这些目标作为损失函数，该框架确保了所得复合材料具有优化的机械强度，同时保持了其在不同硬件平台上基于长丝的多轴3D打印的可制造性。物理实验表明，与具有顺序优化结构和制造顺序的复合材料相比，我们的协同优化方法产生的复合材料的破坏载荷可以提高33.1%。 et.al.|[2505.03779](http://arxiv.org/abs/2505.03779)|null|
|**2025-05-05**|**A New Perspective To Understanding Multi-resolution Hash Encoding For Neural Fields**|Instant NGP是近年来最先进的神经场架构。其令人难以置信的信号拟合能力通常归因于其多分辨率哈希网格结构，并在许多后续工作中得到了使用和改进。然而，目前尚不清楚这种哈希网格结构如何以及为什么能够如此大幅度地提高神经网络的能力。对哈希网格缺乏原则性的理解也意味着，伴随Instant NGP的大量超参数只能通过经验进行调整，而没有太多的启发式方法。为了直观地解释哈希网格的工作原理，我们提出了一种新的视角，即域操作。这一视角提供了一种全新的解释，即特征网格如何学习目标信号，并通过人工创建多个预先存在的线性段来提高神经场的表现力。我们对精心构建的一维信号进行了大量实验，以实证支持我们的主张，并辅助我们的说明。虽然我们的分析主要集中在一维信号上，但我们表明这个想法可以推广到更高的维度。 et.al.|[2505.03042](http://arxiv.org/abs/2505.03042)|**[link](https://github.com/stevolopolis/cp)**|
|**2025-04-27**|**HumMorph: Generalized Dynamic Human Neural Fields from Few Views**|我们介绍了HumMorph，这是一种新的广义方法，用于在显式姿态控制下对动态人体进行自由视点渲染。HumMorph以任意姿势渲染给定几个观察到的视图（从一个开始）的任何指定姿势的人类演员。我们的方法能够实现快速推理，因为它只依赖于通过模型的前馈传递。我们首先在规范T姿势中构建演员的粗略表示，该表示结合了来自个体部分观察的视觉特征，并使用学习到的先验知识填充缺失的信息。粗表示由直接从观察到的视图中提取的细粒度像素对齐特征补充，这些特征提供了高分辨率的外观信息。我们证明，当只有一个输入视图可用时，HumMorph与最先进的技术具有竞争力，但是，在仅进行2次单目观察的情况下，我们可以获得明显更好的视觉质量。此外，之前的广义方法假设可以使用同步的多相机设置获得精确的身体形状和姿势参数。相比之下，我们考虑了一种更实际的场景，其中这些身体参数直接从观察到的视图中进行噪声估计。我们的实验结果表明，我们的架构对噪声参数中的误差更具鲁棒性，在这种情况下明显优于最新技术。 et.al.|[2504.19390](http://arxiv.org/abs/2504.19390)|null|
|**2025-04-24**|**Geometry aware inference of steady state PDEs using Equivariant Neural Fields representations**|神经场的最新进展使学习神经算子的强大离散不变方法成为可能，这些算子在一般几何上近似偏微分方程（PDE）的解。基于这些发展，我们引入了enf2enf，这是一种基于最近提出的等变神经场架构的编码器-解码器方法，用于预测具有非参数化几何变异性的稳态偏微分方程。在enf2enf中，输入几何被编码为潜在的点云嵌入，这些嵌入固有地保留了几何基础并捕获了局部现象。然后将得到的表示与全局参数相结合，并直接解码为连续的输出场，从而有效地对几何和物理之间的耦合进行建模。通过利用局部性和平移不变性的归纳偏差，我们的方法能够捕捉精细尺度的物理特征以及复杂的形状变化，从而增强泛化能力和物理顺应性。对高保真空气动力学数据集、超弹性材料基准和多元素翼型几何形状的广泛实验表明，与最先进的基于图、操作员学习和神经场的方法相比，所提出的模型具有更优越或更具竞争力的性能。值得注意的是，我们的方法支持实时推理和零样本超分辨率，能够在低分辨率网格上进行高效训练，同时保持全尺寸离散化的高精度。 et.al.|[2504.18591](http://arxiv.org/abs/2504.18591)|**[link](https://github.com/giovannicatalani/enf2enf)**|
|**2025-04-28**|**Physics-Driven Neural Compensation For Electrical Impedance Tomography**|电阻抗断层成像（EIT）提供了一种非侵入性的便携式成像方式，在医疗和工业应用中具有巨大的潜力。尽管EIT具有优势，但它遇到了两个主要挑战：其逆问题的不适定性质和空间可变、位置相关的灵敏度分布。传统的基于模型的方法通过正则化来减轻病态性，但忽略了灵敏度的可变性，而监督深度学习方法需要大量的训练数据，缺乏泛化能力。神经领域的最新发展引入了用于图像重建的隐式正则化技术，但这些方法通常忽略了EIT背后的物理原理，从而限制了它们的有效性。在这项研究中，我们提出了PhyNC（物理驱动神经补偿），这是一个无监督的深度学习框架，结合了EIT的物理原理。PhyNC通过动态地将神经表征能力分配给灵敏度较低的区域，确保准确和平衡的电导率重建，解决了不适定逆问题和灵敏度分布问题。对模拟和实验数据的广泛评估表明，PhyNC在细节保存和抗伪影方面优于现有方法，特别是在低灵敏度区域。我们的方法增强了EIT重建的鲁棒性，并提供了一个灵活的框架，可以适应具有类似挑战的其他成像方式。 et.al.|[2504.18067](http://arxiv.org/abs/2504.18067)|null|
|**2025-04-23**|**Spot solutions to a neural field equation on oblate spheroids**|理解神经场中激发模式的动力学是神经科学的一个重要课题。神经场方程是描述相互作用神经元的激发动力学以进行理论分析的数学模型。尽管许多神经场方程的分析都集中在神经元相互作用对平面的影响上，但在对大脑等器官进行建模时，动力学的几何约束也是一个有吸引力的话题。本文报道了在球体作为模型曲面上定义的神经场方程中的模式动力学。我们将点解视为局部模式，并讨论曲面的几何特性如何改变它们的特性。为了分析具有小展平的球体上的斑点模式，我们首先在球面上构造精确的静止斑点解，并揭示它们的稳定性。然后，我们扩展了分析，以证明球状情况下驻点解的存在性和稳定性。我们的一个理论结果是推导了扁球体极点处定域的驻点解的稳定性判据。该标准决定了点解是保持在极点还是移动。最后，我们进行了数值模拟，根据我们的理论预测讨论了点解的动力学。我们的结果表明，点解的动力学取决于曲面和神经相互作用的协调。 et.al.|[2504.16342](http://arxiv.org/abs/2504.16342)|null|
|**2025-04-22**|**Low-Rank Adaptation of Neural Fields**|处理视觉数据通常涉及微小的调整或变化序列，例如图像滤波、表面平滑和视频存储。虽然现有的图形技术，如法线映射和视频压缩，利用冗余来有效地对这种小变化进行编码，但对神经场（NF）的小变化（视觉或物理功能的神经网络参数化）进行编码的问题却很少受到关注。我们提出了一种使用低秩自适应（LoRA）更新神经场的参数高效策略。LoRA是一种来自参数高效微调LLM社区的方法，它以最小的计算开销对预训练模型进行小更新编码。我们使LoRA适应特定于实例的神经场，避免了对大型预训练模型的需求，从而产生了适用于低计算硬件的流水线。我们通过图像滤波、视频压缩和几何编辑的实验验证了我们的方法，证明了它在表示神经场更新方面的有效性和通用性。 et.al.|[2504.15933](http://arxiv.org/abs/2504.15933)|null|
|**2025-04-21**|**Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields**|弱引力透镜是星系形状的轻微扭曲，主要是由宇宙中暗物质的引力效应引起的。在我们的工作中，我们试图从2D望远镜图像中反转弱透镜信号，以重建宇宙暗物质场的3D图。虽然反演通常会产生暗物质场的二维投影，但暗物质分布的精确三维图对于定位感兴趣的结构和测试我们宇宙的理论至关重要。然而，3D反演带来了重大挑战。首先，与依赖于多个视点的标准3D重建不同，在这种情况下，图像仅从单个视点观察。通过观察整个体积中的星系发射器是如何被透镜化的，可以部分解决这一挑战。然而，这导致了第二个挑战：无透镜星系的形状和确切位置是未知的，只能在非常大的不确定性下进行估计。这引入了大量的噪声，几乎完全淹没了透镜信号。以前的方法通过对卷中的结构施加强有力的假设来解决这个问题。相反，我们提出了一种使用引力约束神经场来灵活模拟连续物质分布的方法。我们采用综合分析方法，通过完全可微的物理正向模型优化神经网络的权重，以再现图像测量中存在的透镜信号。我们展示了我们的模拟方法，包括模拟即将到来的望远镜调查数据的暗物质分布的真实模拟测量。我们的结果表明，我们的方法不仅可以超越以前的方法，而且重要的是还能够恢复潜在的令人惊讶的暗物质结构。 et.al.|[2504.15262](http://arxiv.org/abs/2504.15262)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

