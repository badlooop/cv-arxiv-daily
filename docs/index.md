---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.05.02
> Usage instructions: [here](./docs/README.md#usage)

## Video Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-01**|**Controllable Weather Synthesis and Removal with Video Diffusion Models**|在视频中生成逼真可控的天气效果对许多应用都很有价值。基于物理的天气模拟需要精确的重建，这在野生视频中很难实现，而目前的视频编辑往往缺乏真实感和控制力。在这项工作中，我们引入了WeatherWeaver，这是一种视频扩散模型，可以将各种天气效果（包括雨、雪、雾和云）直接合成到任何输入视频中，而不需要3D建模。我们的模型提供了对天气影响强度的精确控制，并支持混合各种天气类型，确保了真实性和适应性。为了克服配对训练数据的稀缺性，我们提出了一种结合合成视频、生成图像编辑和自动标记现实世界视频的新数据策略。广泛的评估表明，我们的方法在天气模拟和去除方面优于最先进的方法，在各种真实世界的视频中提供了高质量、物理上合理和场景身份保持的结果。 et.al.|[2505.00704](http://arxiv.org/abs/2505.00704)|null|
|**2025-05-01**|**T2VPhysBench: A First-Principles Benchmark for Physical Consistency in Text-to-Video Generation**|近年来，文本到视频生成模型取得了重大进展，制作出高质量的视频，这些视频在美学吸引力和准确的教学遵循方面都表现出色，已成为数字艺术创作和在线用户参与的核心。然而，尽管取得了这些进步，它们遵守基本物理定律的能力在很大程度上仍未经过测试：许多输出仍然违反了刚体碰撞、能量守恒和引力动力学等基本约束，导致内容不切实际甚至具有误导性。现有的物理评估基准通常依赖于应用于简单生活场景提示的自动像素级指标，因此忽视了人类判断和第一原理物理学。为了填补这一空白，我们引入了\textbf{T2VPhysBench}，这是一个第一原则基准，系统地评估最先进的开源和商业文本到视频系统是否遵守十二个核心物理定律，包括牛顿力学、守恒原理和唯象效应。我们的基准采用了严格的人体评估方案，包括三项有针对性的研究：（1）总体合规性评估显示，所有模型在每个法律类别中的平均得分均低于0.60；（2）提示消融表明，即使是详细的、特定于法律的提示也无法纠正物理违规行为；以及（3）反事实稳健性测试，证明模型在收到指示时经常生成明确违反物理规则的视频。研究结果揭示了当前架构的持续局限性，并为指导未来研究实现真正的物理感知视频生成提供了具体见解。 et.al.|[2505.00337](http://arxiv.org/abs/2505.00337)|null|
|**2025-04-30**|**Direct Motion Models for Assessing Generated Videos**|视频生成视频模型目前的一个局限性是，它们生成看似合理的帧，但运动不佳——FVD和其他评估生成视频的流行方法并没有很好地捕捉到这个问题。在这里，我们超越了FVD，开发了一种更好地衡量可信对象交互和运动的度量。我们的新方法基于自动编码点轨迹，并产生运动特征，这些特征不仅可用于比较视频的分布（少至一个生成的和一个地面实况，或多至两个数据集），还可用于评估单个视频的运动。我们表明，使用点轨迹而不是像素重建或动作识别特征会产生一种对合成数据中的时间失真明显更敏感的度量，并且可以比各种替代方案更好地预测人类对从开源模型获得的生成视频的时间一致性和真实性的评估。我们还表明，通过使用点迹表示，我们可以在时空上定位生成视频的不一致性，为生成的视频错误提供相对于先前工作的额外可解释性。结果概述和代码链接可以在项目页面上找到：http://trajan-paper.github.io. et.al.|[2505.00209](http://arxiv.org/abs/2505.00209)|null|
|**2025-04-30**|**Eye2Eye: A Simple Approach for Monocular-to-Stereo Video Synthesis**|沉浸式视觉体验的日益普及增加了人们对立体3D视频生成的兴趣。尽管视频合成取得了重大进展，但由于3D视频数据的相对稀缺，创建3D视频仍然具有挑战性。我们提出了一种简单的方法，将文本到视频生成器转换为视频到立体声生成器。给定一个输入视频，我们的框架会自动从移动的视点生成视频帧，从而实现引人注目的3D效果。此任务的先前和并发方法通常分为多个阶段，首先估计视频视差或深度，然后相应地扭曲视频以产生第二个视图，最后修复被遮挡的区域。当场景涉及镜面反射表面或透明对象时，这种方法固有地会失败。在这种情况下，单层视差估计是不够的，导致扭曲过程中出现伪影和不正确的像素偏移。我们的工作绕过了这些限制，直接综合了新的观点，避免了任何中间步骤。这是通过利用预先训练的视频模型在几何、对象材料、光学和语义方面的先验来实现的，而不依赖于外部几何模型或手动将几何从合成过程中分离出来。我们展示了我们的方法在复杂的现实世界场景中的优势，这些场景具有不同的物体材料和成分。观看视频https://video-eye2eye.github.io et.al.|[2505.00135](http://arxiv.org/abs/2505.00135)|null|
|**2025-04-30**|**ReVision: High-Quality, Low-Cost Video Generation with Explicit 3D Physics Modeling for Complex Motion and Interaction**|近年来，视频生成取得了重大进展。然而，在产生复杂的运动和相互作用方面仍然存在挑战。为了应对这些挑战，我们引入了ReVision，这是一个即插即用的框架，它将参数化的3D物理知识明确地集成到预训练的条件视频生成模型中，显著增强了其生成具有复杂运动和交互的高质量视频的能力。具体来说，ReVision包括三个阶段。首先，使用视频扩散模型来生成粗略的视频。接下来，我们从粗略的视频中提取一组2D和3D特征，以构建一个以3D对象为中心的表示，然后通过我们提出的参数化物理先验模型对其进行细化，以生成精确的3D运动序列。最后，这种改进的运动序列作为附加条件被反馈到相同的视频扩散模型中，即使在涉及复杂动作和交互的场景中，也能生成运动一致的视频。我们验证了我们的方法在稳定视频扩散方面的有效性，其中ReVision显著提高了运动保真度和连贯性。值得注意的是，仅使用1.5B参数，它在复杂视频生成方面甚至远远优于具有超过13B参数的最先进视频生成模型。我们的研究结果表明，通过结合3D物理知识，即使是相对较小的视频扩散模型也可以生成具有更大真实感和可控性的复杂运动和交互，为物理上合理的视频生成提供了一种有前景的解决方案。 et.al.|[2504.21855](http://arxiv.org/abs/2504.21855)|null|
|**2025-04-30**|**HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene Generation**|扩散模型的快速发展有望彻底改变VR和AR技术的应用，这些技术通常需要场景级4D资产来提供用户体验。尽管如此，现有的扩散模型主要集中在建模静态3D场景或对象级动态，限制了它们提供真正身临其境体验的能力。为了解决这个问题，我们提出了HoloTime，这是一个集成视频扩散模型的框架，可以从单个提示或参考图像生成全景视频，以及一种360度4D场景重建方法，可以将生成的全景视频无缝转换为4D资产，为用户提供完全沉浸式的4D体验。具体来说，为了驯服用于生成高保真全景视频的视频扩散模型，我们引入了360World数据集，这是第一个适用于下游4D场景重建任务的全景视频综合集合。有了这个精心策划的数据集，我们提出了Panoramic Animator，这是一个两阶段的图像到视频扩散模型，可以将全景图像转换为高质量的全景视频。在此之后，我们提出了全景时空重建，它利用时空深度估计方法将生成的全景视频转换为4D点云，从而优化整体4D高斯散点表示，以重建空间和时间一致的4D场景。为了验证我们的方法的有效性，我们与现有的方法进行了比较分析，揭示了它在全景视频生成和4D场景重建方面的优越性。这证明了我们的方法能够创建更具吸引力和逼真的沉浸式环境，从而增强VR和AR应用程序中的用户体验。 et.al.|[2504.21650](http://arxiv.org/abs/2504.21650)|null|
|**2025-04-30**|**Simple Visual Artifact Detection in Sora-Generated Videos**|2024年12月发布的OpenAI的Sora是一个由自然语言提示驱动的强大视频生成模型，突显了大型语言模型（LLM）和视频合成之间日益趋同的趋势。随着这些多模式系统演变为支持视频的LLM（VidLLM），能够解释、生成视觉内容并与之交互，了解其局限性并确保其安全部署变得至关重要。本研究调查了Sora生成的视频中经常发现和报告的视觉伪影，这些伪影可能会影响质量、误导观众或传播虚假信息。我们提出了一种针对四种常见伪影标签类型的多标签分类框架：标签1：边界/边缘缺陷，标签2：纹理/噪声问题，标签3：运动/关节异常，标签4：对象失配/消失。使用从15个Sora生成的视频中提取的300个手动注释帧的数据集，我们训练了多个2D CNN架构（ResNet-50、EfficientNet-B3/B4、ViT-Base）。由ResNet-50训练的最佳性能模型实现了94.14%的平均多标签分类准确率。这项工作支持VidLLM的更广泛发展，有助于（1）创建视频质量评估的数据集，（2）超越语言度量的可解释伪影分析，以及（3）识别与真实性和安全性相关的视觉风险。 et.al.|[2504.21334](http://arxiv.org/abs/2504.21334)|null|
|**2025-04-30**|**Capturing Conditional Dependence via Auto-regressive Diffusion Models**|扩散模型在图像和视频生成方面都表现出了吸引人的性能。然而，许多作品发现，它们很难捕捉到现实世界中存在的重要、高层次的关系。例如，他们无法从数据中学习物理定律，甚至无法理解世界上的物体以稳定的方式存在。这是由于香草扩散模型中没有充分捕捉到重要的条件依赖结构。在这项工作中，我们对加强扩散模型以捕获数据中的条件依赖结构进行了深入研究。特别是，我们检验了自回归（AR）扩散模型在这方面的有效性，并在（可能）最温和的数据假设下，对AR扩散模型的采样误差得出了第一个理论结果。我们的理论发现表明，与典型的扩散模型相比，AR变体在近似数据条件分布时产生的样本差距减小。另一方面，AR扩散模型的总体推理时间仅略大于vanilla扩散模型的推理时间，这使得它们仍然适用于大规模应用。我们还提供了实证结果，表明当数据中存在明确的条件依赖结构时，AR扩散模型能够捕捉到这种结构，而vanilla DDPM则无法捕捉到。另一方面，当数据块之间没有明显的条件依赖关系时，AR扩散并不优于DDPM。 et.al.|[2504.21314](http://arxiv.org/abs/2504.21314)|null|
|**2025-04-29**|**TesserAct: Learning 4D Embodied World Models**|本文提出了一种学习新的4D实体世界模型的有效方法，该模型预测了3D场景随时间的动态演变，以响应实体代理的动作，提供了空间和时间的一致性。我们建议通过RGB-DN（RGB、深度和法线）视频训练来学习4D世界模型。这不仅超越了传统的2D模型，将详细的形状、配置和时间变化纳入其预测中，而且使我们能够有效地学习具体代理的精确逆动态模型。具体来说，我们首先利用现成的模型，利用深度和正常信息扩展现有的机器人操纵视频数据集。接下来，我们在此带注释的数据集上微调视频生成模型，该模型联合预测每帧的RGB-DN（RGB、深度和法线）。然后，我们提出了一种算法，可以将生成的RGB、深度和法线视频直接转换为高质量的4D世界场景。我们的方法确保了来自具体场景的4D场景预测的时间和空间一致性，为具体环境实现了新颖的视图合成，并促进了策略学习，其性能明显优于先前基于视频的世界模型。 et.al.|[2504.20995](http://arxiv.org/abs/2504.20995)|null|
|**2025-04-29**|**DDPS: Discrete Diffusion Posterior Sampling for Paths in Layered Graphs**|扩散模型构成了当今生成模型的一个重要类别，在尖端人工智能研究中占据了很大一部分。虽然存在许多超出图像和视频生成的扩展，但很少有这样的方法解决所生成样本中的显式约束问题。在本文中，我们研究了使用离散扩散模型在分层图（有向无环图的变体）中生成路径的问题，同时保证我们生成的样本确实是路径。我们的方法利用了一种简单而有效的路径表示，我们称之为填充邻接表矩阵（PALM）。此外，我们展示了如何有效地执行分类器引导，这有助于将采样路径引导到特定的首选边，而无需对扩散模型进行任何重新训练。我们的初步结果表明，从经验上讲，我们的方法优于没有明确考虑路径约束的替代方案。 et.al.|[2504.20754](http://arxiv.org/abs/2504.20754)|null|

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-01**|**RayZer: A Self-supervised Large View Synthesis Model**|我们介绍了RayZer，这是一种自我监督的多视图3D视觉模型，在没有任何3D监督（即相机姿态和场景几何形状）的情况下进行训练，同时表现出新兴的3D意识。具体来说，RayZer将未经基础和校准的图像作为输入，恢复相机参数，重建场景表示，并合成新的视图。在训练过程中，RayZer仅依靠其自我预测的相机姿态来渲染目标视图，消除了对任何地面实况相机注释的需要，并允许RayZer通过2D图像监控进行训练。RayZer的新兴3D意识归因于两个关键因素。首先，我们设计了一个自监督框架，通过解纠缠相机和场景表示来实现输入图像的3D感知自动编码。其次，我们设计了一个基于变换器的模型，其中唯一的3D先验是光线结构，同时连接相机、像素和场景。RayZer展示了与在训练和测试中依赖姿势注释的“oracle”方法相当甚至更优的新颖视图合成性能。项目：https://hwjiang1510.github.io/RayZer/ et.al.|[2505.00702](http://arxiv.org/abs/2505.00702)|null|
|**2025-04-29**|**TesserAct: Learning 4D Embodied World Models**|本文提出了一种学习新的4D实体世界模型的有效方法，该模型预测了3D场景随时间的动态演变，以响应实体代理的动作，提供了空间和时间的一致性。我们建议通过RGB-DN（RGB、深度和法线）视频训练来学习4D世界模型。这不仅超越了传统的2D模型，将详细的形状、配置和时间变化纳入其预测中，而且使我们能够有效地学习具体代理的精确逆动态模型。具体来说，我们首先利用现成的模型，利用深度和正常信息扩展现有的机器人操纵视频数据集。接下来，我们在此带注释的数据集上微调视频生成模型，该模型联合预测每帧的RGB-DN（RGB、深度和法线）。然后，我们提出了一种算法，可以将生成的RGB、深度和法线视频直接转换为高质量的4D世界场景。我们的方法确保了来自具体场景的4D场景预测的时间和空间一致性，为具体环境实现了新颖的视图合成，并促进了策略学习，其性能明显优于先前基于视频的世界模型。 et.al.|[2504.20995](http://arxiv.org/abs/2504.20995)|null|
|**2025-04-29**|**GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for Targeted Scene Confusion**|随着3D高斯散斑（3DGS）作为场景表示和新颖视图合成的突破，其在安全关键领域（如自主系统、AR/VR）的快速采用迫切需要对潜在的安全漏洞进行审查。本文首次对3DGS管道中的后门威胁进行了系统研究。我们发现，对手可能会植入后门视图，在推理过程中引发恶意场景混淆，这可能会导致自主导航中的环境误解或沉浸式环境中的空间失真。为了发现这种风险，我们提出了GuassTrap，这是一种针对3DGS模型的新型中毒攻击方法。GuassTrap在特定的攻击视点注入恶意视图，同时在非目标视图中保持高质量的渲染，确保最小的可检测性并最大限度地提高潜在危害。具体来说，所提出的方法包括一个三阶段管道（攻击、稳定和正常训练），在3DGS中植入隐形、视点一致的有毒渲染，共同优化攻击效果和感知真实性，以暴露3D渲染中的安全风险。在合成和现实世界数据集上的广泛实验表明，GuassTrap可以有效地嵌入不可察觉但有害的后门视图，同时在正常视图中保持高质量的渲染，验证了其鲁棒性、适应性和实际适用性。 et.al.|[2504.20829](http://arxiv.org/abs/2504.20829)|null|
|**2025-04-29**|**EfficientHuman: Efficient Training and Reconstruction of Moving Human using Articulated 2D Gaussian**|3D高斯散斑（3DGS）已被公认为场景重建和新颖视图合成的开创性技术。最近使用3DGS重建3D人体的工作试图利用人体姿势的先验信息来提高渲染质量并提高训练速度。然而，由于多视图不一致和冗余的高斯分布，它很难有效地拟合动态曲面平面。这种不一致性是因为高斯椭球体不能准确地表示动态物体的表面，这阻碍了动态人体的快速重建。同时，冗余高斯分布的普遍性意味着这些作品的训练时间对于快速适应动态人体来说仍然不理想。为了解决这些问题，我们提出了EfficientHuman，这是一种使用铰接2D高斯快速完成人体动态重建的模型，同时确保了高渲染质量。关键创新在于将高斯斑点编码为规范空间中的铰接二维高斯曲面，然后通过线性混合蒙皮（LBS）将其转换为姿态空间，以实现高效的姿态转换。与3D高斯曲面不同，铰接式2D高斯曲面可以快速适应动态人体，同时确保视图一致的几何形状。此外，我们引入了一个姿态校准模块和一个LBS优化模块，以实现动态人体姿态的精确拟合，提高模型的性能。在ZJU MoCap数据集上进行的广泛实验表明，EfficientHuman平均在不到一分钟的时间内实现了快速的3D动态人体重建，比目前最先进的方法快20秒，同时也减少了冗余高斯的数量。 et.al.|[2504.20607](http://arxiv.org/abs/2504.20607)|null|
|**2025-04-28**|**Joint Optimization of Neural Radiance Fields and Continuous Camera Motion from a Monocular Video**|神经辐射场（NeRF）已经证明了其表示3D几何的优越能力，但在训练过程中需要精确地预先计算相机姿态。为了降低这一要求，现有的方法通常依赖于良好的姿态初始化或深度先验来联合优化相机姿态和NeRF。然而，这些方法在具有挑战性的场景中很难实现，例如大旋转，因为它们将每个相机映射到世界坐标系。我们提出了一种新方法，通过将连续相机运动建模为随时间变化的角速度和速度来消除先验依赖性。相机之间的相对运动首先通过速度积分来学习，而相机姿态可以通过将这些相对运动聚合到视频中单个时间步长定义的世界坐标系来获得。具体来说，通过时间依赖的NeRF学习精确的连续相机运动，该NeRF通过在每个时间步长从相邻帧进行训练来捕获局部场景几何形状和运动。学习到的运动能够微调NeRF以表示整个场景几何体。在Co3D和Scannet上的实验表明，与最先进的方法相比，我们的方法实现了卓越的相机姿态和深度估计，以及相当新颖的视图合成性能。我们的代码可在https://github.com/HoangChuongNguyen/cope-nerf. et.al.|[2504.19819](http://arxiv.org/abs/2504.19819)|null|
|**2025-04-28**|**CE-NPBG: Connectivity Enhanced Neural Point-Based Graphics for Novel View Synthesis in Autonomous Driving Scenes**|当前的基于点的方法在使用大型3D点云地图时遇到了可扩展性和渲染质量方面的限制，因为直接将它们用于新颖的视图合成（NVS）会导致可视化效果下降。我们发现这些低质量渲染背后的主要问题是几何体和外观之间的可见性不匹配，这是由于同时使用这两种模式造成的。为了解决这个问题，我们提出了CE-NPBG，这是一种在大规模自动驾驶场景中进行新颖视图合成（NVS）的新方法。我们的方法是一种基于神经点的技术，它利用了两种模态：姿态图像（相机）和同步的原始3D点云（LiDAR）。我们首先使用外观和几何体之间的连接关系图，该图从当前相机视角观察到的大型3D点云图中检索点，并将其用于渲染。通过利用这种连接，我们的方法仅使用大型3D点云图中的一小部分点，显著提高了渲染质量，增强了运行时间和可扩展性。我们的方法将神经描述符与点相关联，并使用它们来合成视图。为了增强这些描述符的编码并提高渲染质量，我们提出了一种联合对抗和点光栅化训练。在训练过程中，我们将图像合成器网络与多分辨率鉴别器配对。在推理时，我们将它们解耦，并使用图像合成器生成新的视图。我们还将我们的提案整合到最近的3D高斯散斑工作中，以突出其在改进渲染和可扩展性方面的优势。 et.al.|[2504.19557](http://arxiv.org/abs/2504.19557)|null|
|**2025-04-27**|**Rendering Anywhere You See: Renderability Field-guided Gaussian Splatting**|场景视图合成从有限的视角生成新颖的视图，对于虚拟现实、增强现实和机器人等应用越来越重要。与基于对象的任务（如生成汽车的360度视图）不同，场景视图合成可以处理整个环境，在这些环境中，非均匀的观察对稳定的渲染质量提出了独特的挑战。为了解决这个问题，我们提出了一种新的方法：可渲染性场引导高斯溅射（RF-GS）。该方法通过可渲染性域量化输入的不均匀性，引导伪视图采样以增强视觉一致性。为了确保宽基线伪视图的质量，我们训练了一个图像恢复模型，将点投影映射到可见光样式。此外，我们验证的混合数据优化策略有效地融合了伪视角和源视图纹理的信息。对模拟和真实数据的比较实验表明，我们的方法在渲染稳定性方面优于现有方法。 et.al.|[2504.19261](http://arxiv.org/abs/2504.19261)|null|
|**2025-05-01**|**TransparentGS: Fast Inverse Rendering of Transparent Objects with Gaussians**|基于神经和高斯的辐射场方法的出现，在新颖的视图合成和3D对象重建方面取得了长足的进步。尽管如此，由于辐射场对高频光变化的不稳定性和不正确的过拟合，镜面反射和折射仍然构成重大挑战。目前，即使是3D高斯散斑（3D-GS）作为一种强大而高效的工具，由于存在明显的二次射线效应，在恢复具有附近内容的透明物体方面也存在不足。为了解决这个问题，我们提出了TransparentGS，这是一种基于3D-GS的透明对象快速逆渲染管道。主要贡献有三方面。首先，设计了一种透明对象的有效表示，即透明高斯基元，通过延迟折射策略实现镜面折射。其次，我们利用高斯光场探针（GaussProbe）在统一的框架中对环境光和附近的内容进行编码。第三，提出了一种基于深度的迭代探针查询（IterQuery）算法，以减少我们基于探针的框架中的视差误差。实验证明了我们的方法在从复杂环境中恢复透明物体方面的速度和准确性，以及在计算机图形学和视觉中的几个应用。 et.al.|[2504.18768](http://arxiv.org/abs/2504.18768)|null|
|**2025-04-24**|**iVR-GS: Inverse Volume Rendering for Explorable Visualization via Editable 3D Gaussian Splatting**|在体积可视化中，用户可以通过在传递函数（TF）中指定颜色和不透明度映射或调整照明参数来交互式地探索三维数据，从而有助于对底层结构进行有意义的解释。然而，渲染大规模卷需要强大的GPU和高速内存访问来实现实时性能。虽然现有的新颖视图合成（NVS）方法以较低的硬件要求提供了更快的渲染速度，但重建场景的可见部分是固定的，并受到预设TF设置的限制，这大大限制了用户的探索。本文介绍了一种创新的NVS方法——基于高斯飞溅的逆体绘制（iVR GS），该方法在降低绘制成本的同时，还支持交互式体探索的场景编辑。具体来说，我们组合了多个与基本TF相关的iVR GS模型，覆盖不相交的可见部分，使整个体积场景可见。每个基本模型都包含一组3D可编辑高斯分布，其中每个高斯分布都是一个支持实时场景渲染和编辑的3D空间点。我们在各种体积数据集上展示了iVR GS相对于其他NVS解决方案（Plenox、CCNeRF和base 3DGS）的卓越重建质量和可组合性。该代码可在以下网址获得https://github.com/TouKaienn/iVR-GS. et.al.|[2504.17954](http://arxiv.org/abs/2504.17954)|null|
|**2025-04-24**|**CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from Casually Captured Videos**|最近，神经辐射场（NeRF）和3D高斯散斑（3DGS）等多视图图像的照片级逼真新视图合成因其卓越的性能而受到广泛关注。然而，大多数作品依赖于低动态范围（LDR）图像，这限制了更丰富场景细节的捕捉。一些先前的工作侧重于高动态范围（HDR）场景重建，通常需要在曝光时间内在固定的相机位置捕获具有不同曝光时间的多视图清晰图像，这在实践中既耗时又具有挑战性。为了获得更灵活的数据采集，我们提出了一种单阶段方法：\textbf{CasualHDRSplat}，即使在存在严重运动模糊和未知曝光时间变化的情况下，也能从随机捕获的视频中轻松、稳健地重建3D HDR场景，并启用自动曝光。\textbf{CasualHDRSplat}包含一个统一的可微分物理成像模型，该模型首先对成像过程应用连续时间轨迹约束，以便我们可以共同优化曝光时间、相机响应函数（CRF）、相机姿态和清晰的3D HDR场景。大量实验表明，我们的方法在鲁棒性和渲染质量方面优于现有方法。我们的源代码将在https://github.com/WU-CVGL/CasualHDRSplat et.al.|[2504.17728](http://arxiv.org/abs/2504.17728)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-01**|**Pixel3DMM: Versatile Screen-Space Priors for Single-Image 3D Face Reconstruction**|我们解决了从单个RGB图像中重建人脸的3D问题。为此，我们提出了Pixel3DMM，这是一组高度通用的视觉变换器，可以预测每像素的几何线索，以约束3D变形人脸模型（3DMM）的优化。我们利用了DINO基础模型的潜在特征，并引入了一个定制的表面法线和紫外坐标预测头。我们通过在FLAME网格拓扑中注册三个高质量的3D人脸数据集来训练我们的模型，这总共产生了1000多个身份和976K张图像。对于3D人脸重建，我们提出了一种FLAME拟合优化方法，该方法从紫外坐标和法线估计中求解3DMM参数。为了评估我们的方法，我们引入了一种新的单图像人脸重建基准，该基准具有高度多样性的面部表情、视角和种族特征。至关重要的是，我们的基准是第一个同时评估姿势和中性面部几何形状的基准。最终，我们的方法在姿势面部表情的几何精度方面比最具竞争力的基线高出15%以上。 et.al.|[2505.00615](http://arxiv.org/abs/2505.00615)|null|
|**2025-05-01**|**Dietary Intake Estimation via Continuous 3D Reconstruction of Food**|监测饮食习惯对于预防与暴饮暴食和饮食不足相关的健康风险至关重要，包括肥胖、糖尿病和心血管疾病。跟踪食物摄入量的传统方法依赖于进食前后的自我报告数据，这很容易不准确。本研究提出了一种通过利用由单眼2D视频构建的3D食物模型来准确监测摄取行为的方法。使用COLMAP和姿态估计算法，我们生成了食物的详细3D表示，使我们能够观察到食物在食用过程中体积的变化。玩具模型和真实食品的实验证明了这种方法的潜力。同时，我们提出了一种新的自动状态识别挑战方法，以准确检测状态变化并保持模型保真度。3D重建方法在捕捉全面的饮食行为见解方面显示出希望，最终有助于开发自动化和准确的饮食监测工具。 et.al.|[2505.00606](http://arxiv.org/abs/2505.00606)|null|
|**2025-04-30**|**Kolmogorov Cascade as the Governing Mechanism for Intervortex Spacing in Quantum Turbulence**|本文研究了1.6和2 K温度下惯性强迫等温量子湍流（正常和超流体成分的共流）。实验在大型光学低温恒温器中进行，其中使用双振荡网格产生准各向同性均匀湍流。通过改变网格行程和频率来调整湍流强度。通过准等密度微球轨迹的二维和三维重建来探测流动，从中我们提取了不同雷诺数下全湍流状态下流动的大尺度特性：湍流速度波动、能量传递率和积分长度尺度。此外，我们通过在整个测量体积内衰减第二声驻波来确定平均涡流线密度 $\mathcal{L}$。我们的结果以更高的精度证实了皮质间距$\ell=1/\sqrt{\mathcal{L}}$与雷诺数$\text成比例{Re}_\kappa$（基于流通量$\kappa$）为$\ell\propto\text{Re}_\kappa^{-3/4}$，具有明确的数值前置因子，没有观察到温度依赖性。这个标度让人想起经典Kolmogorov（K41）湍流中的耗散长度标度，它使之前的作者将$\ell$ 解释为有效的耗散长度尺度。然而，在我们的温度范围内，这种解释与预制件的明显温度无关性不一致。基于这些论点，我们提出了另一种解释，认为同向流湍流中的涡旋间距离是超流体组分能量级联的量子限制深度的结果。 et.al.|[2504.21416](http://arxiv.org/abs/2504.21416)|null|
|**2025-04-30**|**Learning Multi-view Multi-class Anomaly Detection**|异常检测的最新趋势是训练一个统一的模型，而不是为每个类别训练一个单独的模型。然而，现有的多类异常检测（MCAD）模型在多视图场景中表现不佳，因为它们往往无法有效地对不同视图之间的关系和互补信息进行建模。本文介绍了一种多视图多类异常检测模型（MVMCAD），该模型整合了来自多个视图的信息，以准确识别异常。具体来说，我们提出了一种半冻结编码器，其中在冻结编码器之前添加了预编码器先验增强机制，实现了稳定的交叉视图特征建模和有效的自适应，以改进异常检测。此外，我们提出了一种异常放大模块（AAM），该模块模拟全局令牌交互并抑制正常区域以增强异常信号，从而提高了多视图设置中的检测性能。最后，我们提出了一种交叉特征丢失方法，将浅层编码器特征与深层解码器特征对齐，反之亦然，增强了模型在多视图场景下对不同语义级别异常的敏感性。在Real IAD数据集上进行的广泛实验验证了我们方法的有效性，在图像级和像素级分别实现了91.0/88.6/82.1和99.1/43.9/48.2/95.2的最新性能。 et.al.|[2504.21294](http://arxiv.org/abs/2504.21294)|null|
|**2025-04-29**|**GauSS-MI: Gaussian Splatting Shannon Mutual Information for Active 3D Reconstruction**|本研究解决了主动3D重建中实时主动视图选择和视觉质量不确定性量化的挑战。视觉质量是3D重建的一个关键方面。最近的进步，如神经辐射场（NeRF）和3D高斯散斑（3DGS），显著提高了重建模型的图像渲染质量。尽管如此，高效和有效地获取输入图像以进行重建——特别是选择信息量最大的视点——仍然是一个悬而未决的挑战，这对主动重建至关重要。现有的研究主要集中在评估几何完整性和探索未观察到或未知的区域，而没有直接评估重建模型中的视觉不确定性。为了解决这一差距，本文引入了一个概率模型，对每个高斯模型的视觉不确定性进行量化。利用香农互信息，我们制定了一个标准，高斯散布香农互信息（GauSS-MI），用于从新的视角实时评估视觉互信息，以促进选择下一个最佳视图。GauSS MI在与视图和运动规划器集成的主动重建系统中实现。在各种模拟和现实场景中进行的广泛实验展示了所提出系统的卓越视觉质量和重建效率性能。 et.al.|[2504.21067](http://arxiv.org/abs/2504.21067)|null|
|**2025-04-29**|**Large-scale visual SLAM for in-the-wild videos**|从随意、狂野的视频中准确、稳健地重建3D场景，可以大大简化机器人在新环境中的部署。然而，从这种无约束视频中可靠地估计相机姿态和重建场景仍然是一个悬而未决的挑战。现有的纯视觉SLAM方法在基准数据集上表现良好，但在处理真实世界的镜头时遇到了困难，这些镜头通常表现出不受控制的运动，包括快速旋转和纯向前运动、无纹理区域和动态对象。我们分析了当前方法的局限性，并介绍了一种鲁棒的管道，旨在改进休闲视频的3D重建。我们基于最近的深度视觉里程计方法，但在几个方面提高了鲁棒性。使用运动结构从前几帧中自动恢复相机内部特性。动态对象和约束较少的区域被预测模型所掩盖。此外，我们利用单目深度估计来规范光束调整，减轻低视差情况下的误差。最后，我们将位置识别和循环闭合相结合，以减少长期漂移，并通过全局束调整来细化内部函数和姿态估计。我们在各种环境中展示了来自多个在线视频的大规模连续3D模型。相比之下，基线方法通常在几个点上产生局部不一致的结果，产生单独的片段或扭曲的地图。代替地面真实姿态数据，我们评估了重新渲染的NeRF模型的地图一致性、执行时间和视觉精度。我们提出的系统为在线发现的随意不受控制的视频的视觉重建建立了一个新的基线，在更长的野外视频序列上展示了比以前更一致的重建。 et.al.|[2504.20496](http://arxiv.org/abs/2504.20496)|null|
|**2025-04-28**|**LIRM: Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields**|我们提出了大型逆渲染模型（LIRM），这是一种变换器架构，可以在不到一秒钟的时间内联合重建具有视景相关效果的高质量形状、材料和辐射场。我们的模型基于最近的大型重建模型（LRM），实现了最先进的稀疏视图重建质量。然而，现有的LRM难以准确重建看不见的部分，也无法恢复光滑的外观或生成可由标准图形引擎使用的可重新照亮的3D内容。为了解决这些局限性，我们做出了三项关键技术贡献，以构建一个更实用的多视图3D重建框架。首先，我们引入了一个更新模型，允许我们逐步添加更多的输入视图来改进我们的重建。其次，我们提出了一种六平面神经SDF表示，以更好地恢复详细的纹理、几何和材料参数。第三，我们开发了一种新的神经定向嵌入机制来处理视图依赖效应。我们的模型在大规模形状和材料数据集上进行了训练，并采用了量身定制的从粗到细的训练方案，取得了令人信服的结果。在几何和重新照明精度方面，它与基于优化的密集视图逆渲染方法相比具有优势，同时只需要一小部分推理时间。 et.al.|[2504.20026](http://arxiv.org/abs/2504.20026)|null|
|**2025-04-28**|**Mesh-Learner: Texturing Mesh with Spherical Harmonics**|在本文中，我们提出了一个名为Mesh Learner的3D重建和渲染框架，该框架与传统的光栅化管道原生兼容。它将网格和球面谐波（SH）纹理（即填充SH系数的纹理）集成到学习过程中，以端到端地学习每个网格的视图相关辐射。通过使用一种新的插值方法在每个像素的采样点处插值周围的SH-Texels来渲染图像。相反，每个像素的梯度被反向传播到SH纹理中的相关SH纹理。Mesh Learner利用光栅化管道的图形特性（纹理采样、延迟渲染）进行渲染，这使得Mesh Learner与基于光栅化管道（如Blender）的工具和任务（如3D重建、场景渲染、机器人强化学习）自然兼容。我们的系统可以训练大量、无限的场景，因为我们只将截头锥体内的SH纹理传输到GPU进行训练。在其他时候，SH纹理存储在CPU RAM中，这导致GPU内存使用率适中。与现有的最先进的方法（例如3D高斯散斑和M2映射）相比，Replica和FAST-LIVO2数据集中的插值和外推序列的渲染结果达到了最先进的性能。为了造福社会，该代码将在https://github.com/hku-mars/Mesh-Learner. et.al.|[2504.19938](http://arxiv.org/abs/2504.19938)|null|
|**2025-04-28**|**Modeling of Parallel Single-Pixel Imaging for 3D Reconstruction: New Insights and Opportunities**|智能制造和自动驾驶汽车的日益普及加剧了对复杂反射和传输条件下三维（3D）重建的需求。传统的结构光技术依赖于固有的点对点三角测量，这限制了在这些具有挑战性的场景中进行精确的3D测量。并行单像素成像（PSI）在极端条件下表现出前所未有的优越性，并已成为一种有前景的精确3D测量方法。然而，在现有的工作中，还没有一个完整的理论模型来很好地解释其潜在机制并定量表征其性能。在这项研究中，提出了PSI方法的综合理论模型，包括成像和噪声模型。所提出的成像模型描述了复杂光照下的光传输系数，阐明了使用PSI成功进行3D成像的内在机制。所开发的噪声模型定量分析了环境噪声对测量精度的影响，为指导PSI系统的误差分析提供了框架。数值模拟和实验结果验证了所提出的模型，揭示了PSI的通用性和鲁棒性。最后，强调了潜在的研究方向，以指导和激励未来的研究。建立的理论模型为PSI奠定了坚实的基础，并为未来在更苛刻的3D重建任务中的应用带来了新的见解和机遇。 et.al.|[2504.19923](http://arxiv.org/abs/2504.19923)|null|
|**2025-04-28**|**Boosting 3D Liver Shape Datasets with Diffusion Models and Implicit Neural Representations**|虽然开放式3D医学形状数据集的可用性正在增加，为研究界带来了实质性的好处，但我们发现，不幸的是，其中许多数据集都是混乱的，并且包含伪影。这些问题限制了鲁棒模型的开发和训练，特别是对于精确的3D重建任务。在这篇论文中，我们研究了现有3D肝脏形状数据集的现状，并提出了一种使用扩散模型结合隐式神经表示（INR）来增强和扩展现有数据集的解决方案。我们的方法利用扩散模型的生成能力来创建逼真、多样化的3D肝脏形状，捕捉广泛的解剖变化，并解决数据稀缺的问题。实验结果表明，我们的方法增强了数据集的多样性，提供了一种可扩展的解决方案，以提高医学应用中三维肝脏重建和生成的准确性和可靠性。最后，我们建议扩散模型也可以应用于3D医学成像中的其他下游任务。 et.al.|[2504.19402](http://arxiv.org/abs/2504.19402)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-01**|**Controllable Weather Synthesis and Removal with Video Diffusion Models**|在视频中生成逼真可控的天气效果对许多应用都很有价值。基于物理的天气模拟需要精确的重建，这在野生视频中很难实现，而目前的视频编辑往往缺乏真实感和控制力。在这项工作中，我们引入了WeatherWeaver，这是一种视频扩散模型，可以将各种天气效果（包括雨、雪、雾和云）直接合成到任何输入视频中，而不需要3D建模。我们的模型提供了对天气影响强度的精确控制，并支持混合各种天气类型，确保了真实性和适应性。为了克服配对训练数据的稀缺性，我们提出了一种结合合成视频、生成图像编辑和自动标记现实世界视频的新数据策略。广泛的评估表明，我们的方法在天气模拟和去除方面优于最先进的方法，在各种真实世界的视频中提供了高质量、物理上合理和场景身份保持的结果。 et.al.|[2505.00704](http://arxiv.org/abs/2505.00704)|null|
|**2025-05-01**|**GuideSR: Rethinking Guidance for One-Step High-Fidelity Diffusion-Based Super-Resolution**|在本文中，我们提出了GuideSR，这是一种新的基于单步扩散的图像超分辨率（SR）模型，专门用于提高图像保真度。现有的基于扩散的SR方法通常通过在退化输入的VAE降采样表示上添加额外的条件来使预训练的生成模型适应图像恢复任务，这通常会损害结构保真度。GuideSR通过引入双分支架构来解决这一局限性，该架构包括：（1）一个从原始分辨率降低的输入中保留高保真结构的制导分支，以及（2）一个扩散分支，它是一个预先训练的潜在扩散模型，以提高感知质量。与传统的调节机制不同，我们的引导分支具有针对图像恢复任务的定制结构，将全分辨率块（FRB）与通道注意力相结合，将图像引导网络（IGN）与引导注意力相结合。通过将详细的结构信息直接嵌入到修复管道中，GuideSR可以产生更清晰、视觉上更一致的结果。对基准数据集的广泛实验表明，GuideSR在保持单步方法的低计算成本的同时实现了最先进的性能，在具有挑战性的现实世界数据集上获得了高达1.39dB的PSNR增益。我们的方法在各种基于参考的指标上始终优于现有方法，包括PSNR、SSIM、LPIPS、DISTS和FID，进一步代表了现实世界图像恢复的实际进步。 et.al.|[2505.00687](http://arxiv.org/abs/2505.00687)|null|
|**2025-05-01**|**The local coupling of noise technique and its application to lower error bounds for strong approximation of SDEs with irregular coefficients**|近年来，人们对非Lipschitz连续系数随机微分方程（SDEs）的近似方法越来越感兴趣。我们展示了在单个时间点或全局时间点近似的情况下，这些方法的 $L^p$-误差的下限。一方面，我们表明，对于一大类分段Lipschitz连续漂移和非加性扩散，通过基于驱动布朗运动有限多次评估的任何方法可以实现的最终时间近似的最佳可能$L^p$-误差率最多为$3/4$，这在以前只为加性扩散所知。此外，我们表明，当漂移局部有界且扩散局部Lipschitz连续时，基于驱动布朗运动有限次评估的任何方法可以实现的全局近似的最佳$L^p$-误差率最多为1/2$。为了推导下限，我们引入了一种新的证明方法：噪声局部耦合技术。当在最后一次近似SDE的解$X$时使用此技术，基于对点$t_1<\dots<t_n$处的驱动布朗运动的评估的任何近似方法的$L^p$误差的下限可以通过相同SDE在$[t_{i-1}，t_i]$上的解的$L^ p$距离来确定，初始值为$X_{t_{i-1-}$，驱动布朗运动在$t_{i-1]，t_i$处耦合，并且独立，条件是$t_{i-1}，t_i$ 处的布朗运动值。 et.al.|[2505.00656](http://arxiv.org/abs/2505.00656)|null|
|**2025-05-01**|**ParkDiffusion: Heterogeneous Multi-Agent Multi-Modal Trajectory Prediction for Automated Parking using Diffusion Models**|自动停车是高级驾驶辅助系统（ADAS）的一个关键功能，在ADAS中，准确的轨迹预测对于桥接感知和规划模块至关重要。尽管具有重要意义，但该领域的研究仍然相对有限，现有的大多数研究都集中在车辆的单模态轨迹预测上。在这项工作中，我们提出了ParkDiffusion，这是一种预测自动停车场景中车辆和行人轨迹的新方法。ParkDiffusion采用扩散模型来捕捉未来轨迹的固有不确定性和多模态，并结合了几项关键创新。首先，我们提出了一种双映射编码器，该编码器使用两步交叉注意机制来处理软语义线索和硬几何约束。其次，我们引入了一个自适应代理类型嵌入模块，该模块根据车辆和行人的不同特征动态地调节预测过程。第三，为了确保运动学可行性，我们的模型输出控制信号，这些信号随后在运动学框架内用于生成物理上可行的轨迹。我们在龙湖停车场（DLP）数据集和十字路口无人机（inD）数据集上评估了ParkDiffusion。我们的工作为停车场景中的异构轨迹预测建立了一个新的基线，远远优于现有的方法。 et.al.|[2505.00586](http://arxiv.org/abs/2505.00586)|null|
|**2025-05-01**|**Narrow Inhomogeneous Distribution and Charge State Stabilization of Lead-Vacancy Centers in Diamond**|具有大基态分裂的金刚石中的铅空位（PbV）中心有望成为量子网络节点的构建块。由于铅原子的重量，制造具有窄不均匀分布和稳定电荷态的高质量PbV中心具有挑战性。在这项研究中，为了形成PbV中心，在Pb离子注入后进行了高达2300℃的高温退火。在1800℃的较低温度下，PbV中心显示出较大的不均匀分布和光谱扩散，而2200-2300℃的较高温度导致窄的不均匀分配，标准偏差约为5 GHz。在2200℃下形成的PbV中心的电荷态转变是通过在532nm激光照射下捕获周围缺陷产生的光载流子而发生的。最后，获得了具有几乎相同光子频率的多个稳定PbV中心，这对量子信息处理的应用至关重要。 et.al.|[2505.00576](http://arxiv.org/abs/2505.00576)|null|
|**2025-05-01**|**Safety-Critical Traffic Simulation with Guided Latent Diffusion Model**|安全关键交通模拟在评估罕见和具有挑战性的场景下的自动驾驶系统方面发挥着至关重要的作用。然而，由于对物理合理性的考虑不足，现有的方法往往会产生不切实际的场景，并且发电效率低。为了解决这些局限性，我们提出了一种引导潜在扩散模型（LDM），能够生成物理上真实和对抗性的安全关键交通场景。具体来说，我们的模型采用基于图的变分自编码器（VAE）来学习一个紧凑的潜在空间，该空间在提高计算效率的同时捕捉复杂的多智能体交互。在这个潜在空间内，扩散模型执行去噪过程以产生逼真的轨迹。为了实现可控和对抗性场景生成，我们引入了新的指导目标，推动扩散过程产生对抗性和行为现实的驾驶行为。此外，我们开发了一个基于物理可行性检查的样本选择模块，以进一步增强所生成场景的物理合理性。对nuScenes数据集的广泛实验表明，与现有基线相比，我们的方法在保持高水平真实性的同时，实现了更优的对抗效果和生成效率。我们的工作为现实的安全关键场景模拟提供了一种有效的工具，为更稳健地评估自动驾驶系统铺平了道路。 et.al.|[2505.00515](http://arxiv.org/abs/2505.00515)|null|
|**2025-05-01**|**JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers**|我们介绍了JointDiT，一种模拟RGB和深度联合分布的扩散变换器。通过利用最先进的扩散变换器的架构优势和出色的图像先验，JointDiT不仅生成高保真图像，还生成几何上合理和准确的深度图。这种可靠的联合分布建模是通过我们提出的两种简单而有效的技术实现的，即取决于每种模态噪声水平的自适应调度权重和不平衡时间步长采样策略。通过这些技术，我们在每种模态的所有噪声水平上训练我们的模型，使JointDiT能够通过简单地控制每个分支的时间步长来自然地处理各种组合生成任务，包括联合生成、深度估计和深度条件图像生成。JointDiT展现出卓越的联合发电性能。此外，它在深度估计和深度条件图像生成方面取得了可比的结果，这表明联合分布建模可以作为条件生成的替代方案。项目页面可在https://byungki-k.github.io/JointDiT/. et.al.|[2505.00482](http://arxiv.org/abs/2505.00482)|null|
|**2025-05-01**|**Stability of the first-order unified gas-kinetic scheme based on a linear kinetic model**|统一气体动力学方案（UGKS）在所有流态的多尺度模拟中越来越受欢迎。本文首次对应用于线性动力学模型的UGKS的稳定性进行了分析研究，该模型能够通过Chapman-Enskog展开法再现一维线性标量平流扩散方程。本文采用周期边界条件，忽略数值积分的误差，严格证明了Courant-Friedrichs-Lewy（CFL）条件下一阶UGKS的加权L^2 $稳定性。结果表明，该方法的时间步长不受小于粒子碰撞时间的限制，也不受求解扩散方程时通常应用的抛物线型CFL条件的限制。该证明的新颖之处在于，基于时间步长与粒子碰撞时间的比率，分布函数的更新被视为与各种物理过程（如粒子自由输运和碰撞）相关的子方法的凸组合。通过将子方法视为相应线性双曲系统的离散化，并利用相关的黎曼不变量，得到了子方法的加权L^2$稳定性。最后，UGKS的强稳定性保持特性导致了所需的加权L^2$ -稳定性。 et.al.|[2505.00434](http://arxiv.org/abs/2505.00434)|null|
|**2025-05-01**|**Leveraging Pretrained Diffusion Models for Zero-Shot Part Assembly**|3D零件装配旨在了解零件关系并预测其6-DoF姿态，以构建逼真的3D形状，满足对自主装配日益增长的需求，这对机器人至关重要。现有的方法主要通过在监督下训练神经网络来估计每个部分的变换，这需要大量的手动标记数据。然而，数据收集的高成本以及现实世界形状和零件的巨大可变性使得传统方法对于大规模应用来说不切实际。在本文中，我们首先提出了一种零样本零件装配方法，该方法利用预先训练的点云扩散模型作为装配过程中的鉴别器，指导零件操作以形成逼真的形状。具体而言，我们从理论上证明，利用零样本零件装配的扩散模型可以转化为迭代最近点（ICP）过程。然后，我们提出了一种新的推开策略来解决重叠部分，从而进一步增强了该方法的鲁棒性。为了验证我们的工作，我们对几种强基线方法进行了广泛的实验和定量比较，证明了所提出方法的有效性，甚至超过了监督学习方法。该代码已于发布https://github.com/Ruiyuan-Zhang/Zero-Shot-Assembly. et.al.|[2505.00426](http://arxiv.org/abs/2505.00426)|null|
|**2025-05-01**|**Prospects for Ultralow-Mass Nuclear Magnetic Resonance using Spin Defects in Hexagonal Boron Nitride**|固体中的光学活性量子缺陷，如金刚石中的氮空位（NV）中心，是环境条件下微米级和纳米级（超低质量）核磁共振（NMR）光谱和成像的主要形式。然而，当距离金刚石表面小于约10nm时，NV中心的自旋和光学性质会降低，从而限制了NMR灵敏度以及光谱和空间分辨率。在这里，我们概述了使用六方氮化硼（hBN）中带负电荷的硼空位（ $V_B^-$）开发替代纳米级核磁共振传感器的努力。作为范德华材料，hBN的表面没有悬空键和其他降低近表面NVs性能的顺磁噪声源，允许材料表面存在稳定的$V_B^-$缺陷。我们讨论了硼空位在应用于窄带（AC）磁场传感时的性质，并概述了针对该系统优化的实验设计。我们提出了纳米和微米尺度上统计和均匀极化样品的$V_B^-$NMR测量协议，包括相关脉冲序列、灵敏度计算和样品限制策略；并将预期性能与NV-NMR进行比较。我们在纳米尺度上估计了$V_B^-$电子自旋和样品核自旋之间的反作用效应；并考虑了流动受限纳米尺度下的非常规扩散动力学，计算了其对预期的$V_B^-$NMR信号的影响。最后，我们确定了最适合纳米级和微米级$V_B^-$ NMR的潜在样品靶点和操作制度。 et.al.|[2505.00383](http://arxiv.org/abs/2505.00383)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-04-27**|**HumMorph: Generalized Dynamic Human Neural Fields from Few Views**|我们介绍了HumMorph，这是一种新的广义方法，用于在显式姿态控制下对动态人体进行自由视点渲染。HumMorph以任意姿势渲染给定几个观察到的视图（从一个开始）的任何指定姿势的人类演员。我们的方法能够实现快速推理，因为它只依赖于通过模型的前馈传递。我们首先在规范T姿势中构建演员的粗略表示，该表示结合了来自个体部分观察的视觉特征，并使用学习到的先验知识填充缺失的信息。粗表示由直接从观察到的视图中提取的细粒度像素对齐特征补充，这些特征提供了高分辨率的外观信息。我们证明，当只有一个输入视图可用时，HumMorph与最先进的技术具有竞争力，但是，在仅进行2次单目观察的情况下，我们可以获得明显更好的视觉质量。此外，之前的广义方法假设可以使用同步的多相机设置获得精确的身体形状和姿势参数。相比之下，我们考虑了一种更实际的场景，其中这些身体参数直接从观察到的视图中进行噪声估计。我们的实验结果表明，我们的架构对噪声参数中的误差更具鲁棒性，在这种情况下明显优于最新技术。 et.al.|[2504.19390](http://arxiv.org/abs/2504.19390)|null|
|**2025-04-24**|**Geometry aware inference of steady state PDEs using Equivariant Neural Fields representations**|神经场的最新进展使学习神经算子的强大离散不变方法成为可能，这些算子在一般几何上近似偏微分方程（PDE）的解。基于这些发展，我们引入了enf2enf，这是一种基于最近提出的等变神经场架构的编码器-解码器方法，用于预测具有非参数化几何变异性的稳态偏微分方程。在enf2enf中，输入几何被编码为潜在的点云嵌入，这些嵌入固有地保留了几何基础并捕获了局部现象。然后将得到的表示与全局参数相结合，并直接解码为连续的输出场，从而有效地对几何和物理之间的耦合进行建模。通过利用局部性和平移不变性的归纳偏差，我们的方法能够捕捉精细尺度的物理特征以及复杂的形状变化，从而增强泛化能力和物理顺应性。对高保真空气动力学数据集、超弹性材料基准和多元素翼型几何形状的广泛实验表明，与最先进的基于图、操作员学习和神经场的方法相比，所提出的模型具有更优越或更具竞争力的性能。值得注意的是，我们的方法支持实时推理和零样本超分辨率，能够在低分辨率网格上进行高效训练，同时保持全尺寸离散化的高精度。 et.al.|[2504.18591](http://arxiv.org/abs/2504.18591)|null|
|**2025-04-28**|**Physics-Driven Neural Compensation For Electrical Impedance Tomography**|电阻抗断层成像（EIT）提供了一种非侵入性的便携式成像方式，在医疗和工业应用中具有巨大的潜力。尽管EIT具有优势，但它遇到了两个主要挑战：其逆问题的不适定性质和空间可变、位置相关的灵敏度分布。传统的基于模型的方法通过正则化来减轻病态性，但忽略了灵敏度的可变性，而监督深度学习方法需要大量的训练数据，缺乏泛化能力。神经领域的最新发展引入了用于图像重建的隐式正则化技术，但这些方法通常忽略了EIT背后的物理原理，从而限制了它们的有效性。在这项研究中，我们提出了PhyNC（物理驱动神经补偿），这是一个无监督的深度学习框架，结合了EIT的物理原理。PhyNC通过动态地将神经表征能力分配给灵敏度较低的区域，确保准确和平衡的电导率重建，解决了不适定逆问题和灵敏度分布问题。对模拟和实验数据的广泛评估表明，PhyNC在细节保存和抗伪影方面优于现有方法，特别是在低灵敏度区域。我们的方法增强了EIT重建的鲁棒性，并提供了一个灵活的框架，可以适应具有类似挑战的其他成像方式。 et.al.|[2504.18067](http://arxiv.org/abs/2504.18067)|null|
|**2025-04-23**|**Spot solutions to a neural field equation on oblate spheroids**|理解神经场中激发模式的动力学是神经科学的一个重要课题。神经场方程是描述相互作用神经元的激发动力学以进行理论分析的数学模型。尽管许多神经场方程的分析都集中在神经元相互作用对平面的影响上，但在对大脑等器官进行建模时，动力学的几何约束也是一个有吸引力的话题。本文报道了在球体作为模型曲面上定义的神经场方程中的模式动力学。我们将点解视为局部模式，并讨论曲面的几何特性如何改变它们的特性。为了分析具有小展平的球体上的斑点模式，我们首先在球面上构造精确的静止斑点解，并揭示它们的稳定性。然后，我们扩展了分析，以证明球状情况下驻点解的存在性和稳定性。我们的一个理论结果是推导了扁球体极点处定域的驻点解的稳定性判据。该标准决定了点解是保持在极点还是移动。最后，我们进行了数值模拟，根据我们的理论预测讨论了点解的动力学。我们的结果表明，点解的动力学取决于曲面和神经相互作用的协调。 et.al.|[2504.16342](http://arxiv.org/abs/2504.16342)|null|
|**2025-04-22**|**Low-Rank Adaptation of Neural Fields**|处理视觉数据通常涉及微小的调整或变化序列，例如图像滤波、表面平滑和视频存储。虽然现有的图形技术，如法线映射和视频压缩，利用冗余来有效地对这种小变化进行编码，但对神经场（NF）的小变化（视觉或物理功能的神经网络参数化）进行编码的问题却很少受到关注。我们提出了一种使用低秩自适应（LoRA）更新神经场的参数高效策略。LoRA是一种来自参数高效微调LLM社区的方法，它以最小的计算开销对预训练模型进行小更新编码。我们使LoRA适应特定于实例的神经场，避免了对大型预训练模型的需求，从而产生了适用于低计算硬件的流水线。我们通过图像滤波、视频压缩和几何编辑的实验验证了我们的方法，证明了它在表示神经场更新方面的有效性和通用性。 et.al.|[2504.15933](http://arxiv.org/abs/2504.15933)|null|
|**2025-04-21**|**Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields**|弱引力透镜是星系形状的轻微扭曲，主要是由宇宙中暗物质的引力效应引起的。在我们的工作中，我们试图从2D望远镜图像中反转弱透镜信号，以重建宇宙暗物质场的3D图。虽然反演通常会产生暗物质场的二维投影，但暗物质分布的精确三维图对于定位感兴趣的结构和测试我们宇宙的理论至关重要。然而，3D反演带来了重大挑战。首先，与依赖于多个视点的标准3D重建不同，在这种情况下，图像仅从单个视点观察。通过观察整个体积中的星系发射器是如何被透镜化的，可以部分解决这一挑战。然而，这导致了第二个挑战：无透镜星系的形状和确切位置是未知的，只能在非常大的不确定性下进行估计。这引入了大量的噪声，几乎完全淹没了透镜信号。以前的方法通过对卷中的结构施加强有力的假设来解决这个问题。相反，我们提出了一种使用引力约束神经场来灵活模拟连续物质分布的方法。我们采用综合分析方法，通过完全可微的物理正向模型优化神经网络的权重，以再现图像测量中存在的透镜信号。我们展示了我们的模拟方法，包括模拟即将到来的望远镜调查数据的暗物质分布的真实模拟测量。我们的结果表明，我们的方法不仅可以超越以前的方法，而且重要的是还能够恢复潜在的令人惊讶的暗物质结构。 et.al.|[2504.15262](http://arxiv.org/abs/2504.15262)|null|
|**2025-04-20**|**Efficient Implicit Neural Compression of Point Clouds via Learnable Activation in Latent Space**|隐式神经表示（INR），也称为神经场，已成为深度学习中的一种强大范式，使用基于坐标的神经网络对连续空间场进行参数化。在本文中，我们提出了\textbf{PICO}，这是一个基于INR的静态点云压缩框架。与主流的编码器-解码器范式不同，我们将点云压缩任务分解为两个单独的阶段：几何压缩和属性压缩，每个阶段都有不同的INR优化目标。受Kolmogorov-Arnold网络（KANs）的启发，我们引入了一种新的网络架构\textbf{LeAFNet}，它利用潜在空间中的可学习激活函数来更好地近似目标信号的隐函数。通过将点云压缩重新表述为神经参数压缩，我们通过量化和熵编码进一步提高了压缩效率。实验结果表明，\textbf{LeAFNet}在基于INR的点云压缩中优于传统的MLP。此外，与当前的MPEG点云压缩标准相比，\textbf{PICO}实现了卓越的几何压缩性能，D1 PSNR平均提高了4.92 $dB。在联合几何和属性压缩方面，我们的方法表现出了极具竞争力的结果，平均PCQM增益为2.7美元乘以10^{-3}$ 。 et.al.|[2504.14471](http://arxiv.org/abs/2504.14471)|null|
|**2025-04-17**|**Radial Basis Function Techniques for Neural Field Models on Surfaces**|我们提出了一种使用径向基函数（RBF）插值和求积求解曲面上神经场方程的数值框架。神经场模型描述了宏观大脑活动的演变，但建模研究往往忽视了弯曲皮质区域的复杂几何形状。传统的数值方法，如有限元或谱方法，在计算上可能很昂贵，并且在不规则域上实现具有挑战性。相比之下，基于RBF的方法提供了一种灵活的替代方案，通过提供插值和正交方案，以高阶精度有效地处理任意几何形状。我们首先为一般曲面上的神经场模型开发了一个基于RBF的插值投影框架。详细推导了平面和曲面域的求积法，确保了高阶精度和稳定性，因为它们取决于RBF超参数（基函数、增广多项式和模板大小）。通过数值实验，我们证明了我们的方法的收敛性，突出了它在灵活性和准确性方面优于传统方法。最后，我们阐述了复杂表面上时空活动的数值模拟，说明了该方法捕捉复杂波传播模式的能力。 et.al.|[2504.13379](http://arxiv.org/abs/2504.13379)|null|
|**2025-04-16**|**SCENT: Robust Spatiotemporal Learning for Continuous Scientific Data via Scalable Conditioned Neural Fields**|由于空间和时间依赖性之间的复杂相互作用、数据的高维度和可扩展性约束，时空学习具有挑战性。这些挑战在科学领域进一步加剧，在这些领域，数据通常是不规则分布的（例如，传感器故障的缺失值）和高容量的（例如高保真模拟），带来了额外的计算和建模困难。在本文中，我们提出了SCENT，这是一种用于可扩展和连续性知情的时空表示学习的新框架。SCENT在单一架构中统一了插值、重建和预测。SCENT建立在基于变换器的编码器-处理器-解码器骨干上，引入了可学习的查询来增强泛化能力，并引入了查询式交叉关注机制来有效捕获多尺度依赖关系。为了确保数据大小和模型复杂性的可扩展性，我们引入了稀疏注意力机制，实现了灵活的输出表示和任意分辨率的高效评估。我们通过广泛的模拟和真实世界的实验来验证SCENT，在实现卓越可扩展性的同时，在多个具有挑战性的任务中展示了最先进的性能。 et.al.|[2504.12262](http://arxiv.org/abs/2504.12262)|null|
|**2025-04-14**|**DNF-Avatar: Distilling Neural Fields for Real-time Animatable Avatar Relighting**|从单眼视频中创建可重现和可动画化的人类化身是一个新兴的研究课题，具有广泛的应用，例如虚拟现实、体育和视频游戏。之前的研究利用神经场和基于物理的渲染（PBR）来估计人类化身的几何形状并解开其外观属性。然而，这些方法的一个缺点是由于昂贵的蒙特卡洛射线追踪导致渲染速度较慢。为了解决这个问题，我们提出将隐式神经场（教师）的知识提取为显式的2D高斯飞溅（学生）表示，以利用高斯飞溅的快速光栅化特性。为了避免光线追踪，我们对PBR外观采用了分裂和近似。我们还提出了用于阴影计算的新型部分式环境遮挡探头。阴影预测是通过每像素只查询一次这些探测器来实现的，这为化身的实时重新照明铺平了道路。这些技术相结合，可以提供高质量的重新照明效果和逼真的阴影效果。我们的实验表明，所提出的学生模型与我们的教师模型实现了相当甚至更好的重新照明结果，同时在推理时快了370倍，达到了67 FPS的渲染速度。 et.al.|[2504.10486](http://arxiv.org/abs/2504.10486)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

