---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.10.12
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-11**|**rpcPRF: Generalizable MPI Neural Radiance Field for Satellite Camera**|卫星图像的新视图合成具有广泛的实际应用。虽然神经辐射场的最新进展主要针对针孔相机，而卫星相机的模型通常需要足够的输入视图。本文提出了一种用于有理多项式相机（RPC）的基于多平面图像（MPI）的平面神经辐射场rpcPRF。与需要一个场景的足够视图的基于坐标的神经辐射场不同，我们的模型适用于单个或少量输入，并且在来自看不见的场景的图像上表现良好。为了实现跨场景的泛化，我们建议使用重投影监督来诱导预测的MPI来学习3D坐标和图像之间的正确几何结构。此外，我们通过引入辐射场的绘制技术，消除了基于深度多视点立体的方法对密集深度监督的严格要求。rpcPRF结合了隐式表示的优势和RPC模型的优势，在学习三维结构的同时捕捉连续的高度空间。给定RGB图像及其相应的RPC，端到端模型学习将新视图与新的RPC合成，并重建场景的海拔高度。当提供多个视图作为输入时，rpcPRF施加由额外视图提供的额外监督。在ZY-3的TLC数据集和WV-3的城市场景的SatMVS3D数据集上，对于单视图和多视图任务，rpcPRF在图像保真度、重建精度和效率方面显著优于最先进的基于nerf的方法。 et.al.|[2310.07179](http://arxiv.org/abs/2310.07179)|null|
|**2023-10-06**|**Improving Neural Radiance Field using Near-Surface Sampling with Point Cloud Generation**|神经辐射场（NeRF）是一种新兴的视图合成方法，它对三维空间中的点进行采样，并估计它们的存在和颜色概率。NeRF的缺点是它需要很长的训练时间，因为它对许多3D点进行采样。此外，如果从遮挡区域或在不太可能存在对象的空间中采样点，则NeRF的渲染质量可能会降低。这些问题可以通过估计3D场景的几何形状来解决。本文提出了一种近表面采样框架来提高NeRF的渲染质量。为此，所提出的方法使用训练集的深度图像来估计3D对象的表面，并且仅在那里执行采样。为了获得新视图的深度信息，本文提出了一种三维点云生成方法和一种简单的点云投影深度细化方法。实验结果表明，与原始的NeRF和最先进的基于深度的NeRF方法相比，所提出的近表面采样NeRF框架可以显著提高渲染质量。此外，使用所提出的近表面采样框架，可以显著加快NeRF模型的训练时间。 et.al.|[2310.04152](http://arxiv.org/abs/2310.04152)|null|
|**2023-10-06**|**ILSH: The Imperial Light-Stage Head Dataset for Human Head View Synthesis**|本文介绍了Imperial Light Stage Head（ILSH）数据集，这是一个新颖的Light Stage捕获的人头数据集，旨在支持人头的视图合成学术挑战。ILSH数据集旨在促进各种方法，如场景特定或通用神经渲染、多视图几何、3D视觉和计算机图形学，以进一步推动照片逼真的人类化身的开发。本文详细介绍了专门用于捕捉高分辨率（4K）人头图像的光台的设置，并描述了在收集高质量数据时应对挑战（预处理、道德问题）的过程。除了数据收集之外，我们还将数据集拆分为训练集、验证集和测试集。我们的目标是为这个新的数据集设计和支持一个公平视图综合挑战任务，以便在使用测试集时，如在使用验证集时，可以保持和预期类似的性能水平。ILSH数据集由52名受试者组成，这些受试者使用24台相机拍摄，所有82个光源都打开，共产生1248张特写头部图像、边界遮罩和相机姿势对。 et.al.|[2310.03952](http://arxiv.org/abs/2310.03952)|null|
|**2023-10-05**|**Drag View: Generalizable Novel View Synthesis with Unposed Imagery**|我们介绍了DragView，这是一个新颖的交互式框架，用于生成看不见的场景的新颖视图。DragView从单个源图像初始化新视图，渲染由一组稀疏的未聚焦多视图图像支持，所有这些图像都在一个前馈过程中无缝执行。我们的方法从用户通过本地相对坐标系拖动源视图开始。像素对齐特征是通过将采样的3D点沿着目标射线投影到源视图上而获得的。然后，我们结合了一个与视图相关的调制层，以在投影过程中有效地处理遮挡。此外，我们将核极注意力机制扩展到包括所有源像素，有助于聚合来自其他未聚焦视图的初始化坐标对齐点特征。最后，我们使用另一个变换器将射线特征解码为最终的像素强度。至关重要的是，我们的框架既不依赖于2D先验模型，也不依赖于对相机姿态的明确估计。在测试过程中，DragView展示了将其推广到训练中看不见的新场景的能力，还仅使用未渲染的支持图像，从而能够生成以灵活的相机轨迹为特征的照片逼真的新视图。在我们的实验中，我们将DragView的性能与最近在无姿态条件下运行的场景表示网络以及在噪声测试相机姿态下的可推广NeRF进行了全面比较。DragView在视图合成质量方面始终如一地展示了其卓越的性能，同时也更加用户友好。项目页面：https://zhiwenfan.github.io/DragView/. et.al.|[2310.03704](http://arxiv.org/abs/2310.03704)|null|
|**2023-10-05**|**Point-Based Radiance Fields for Controllable Human Motion Synthesis**|本文提出了一种新的基于静态点辐射场的精细变形可控人体运动合成方法。尽管以前的可编辑神经辐射场方法可以在新的视图合成上产生令人印象深刻的结果，并允许天真变形，但很少有算法可以实现复杂的三维人体编辑，如正向运动学。我们的方法利用显式点云来训练静态3D场景，并通过使用变形MLP对点云平移进行编码来应用变形。为了确保渲染结果与规范空间训练一致，我们使用SVD估计局部旋转，并将每点旋转插值到预训练辐射场的查询视图方向。大量实验表明，我们的方法在精细复杂变形方面可以显著优于最先进的方法，该方法可以推广到除人类之外的其他3D角色。 et.al.|[2310.03375](http://arxiv.org/abs/2310.03375)|**[link](https://github.com/dehezhang2/point_based_nerf_editing)**|
|**2023-10-04**|**Consistent-1-to-3: Consistent Image to 3D View Synthesis via Geometry-aware Diffusion Models**|从单个图像中进行零样本新视图合成（NVS）是三维对象理解中的一个基本问题。尽管最近利用预先训练的生成模型的方法可以从野外输入中合成高质量的新视图，但它们仍然难以在不同视图之间保持3D一致性。在本文中，我们提出了Consistent-1-to-3，这是一个显著缓解这一问题的生成框架。具体来说，我们将NVS任务分解为两个阶段：（i）将观察到的区域转换为新的视图，以及（ii）对看不见的区域产生幻觉。我们设计了一个场景表示转换器和视图条件扩散模型，分别用于执行这两个阶段。在模型内部，为了增强三维一致性，我们建议使用六面体引导注意力来结合几何约束，并使用多视图注意力来更好地聚合多视图信息。最后，我们设计了一个层次生成范式来生成长序列的一致视图，允许对所提供的对象图像进行全方位的360度观察。对多个数据集的定性和定量评估证明了所提出的机制相对于最先进方法的有效性。我们的项目页面位于https://jianglongye.com/consistent123/ et.al.|[2310.03020](http://arxiv.org/abs/2310.03020)|null|
|**2023-10-04**|**Efficient-3DiM: Learning a Generalizable Single-image Novel-view Synthesizer in One Day**|新颖视图合成的任务旨在从有限的一组输入图像中生成对象或场景的看不见的视角。然而，从单个图像合成新颖的视图仍然是计算机视觉领域的一个重大挑战。以前的方法通过采用网格预测、多平面图像构建或更先进的技术（如神经辐射场）来解决这个问题。最近，一种专门为2D图像合成设计的预训练扩散模型已经证明，如果在3D微调任务上进行充分优化，它就能够产生逼真的新视图。尽管保真度和可推广性大大提高，但训练这样一个强大的扩散模型需要大量的训练数据和模型参数，这导致了众所周知的长时间和高计算成本。为了解决这个问题，我们提出了Efficient-3DiM，这是一个简单但有效的框架来学习单个图像的新颖视图合成器。受我们对扩散模型推理过程的深入分析的启发，我们提出了几种实用的策略，将训练开销降低到可管理的规模，包括精心设计的时间步长采样策略、卓越的3D特征提取器和增强的训练方案。当组合在一起时，我们的框架能够将总训练时间从10天减少到不到1天，从而显著加快了在相同计算平台下的训练过程（一个例子中有8个Nvidia A100 GPU）。通过综合实验验证了该方法的有效性和可推广性。 et.al.|[2310.03015](http://arxiv.org/abs/2310.03015)|null|
|**2023-10-05**|**USB-NeRF: Unrolling Shutter Bundle Adjusted Neural Radiance Fields**|神经辐射场（NeRF）由于其令人印象深刻的三维场景表示和合成新视图图像的能力，近年来受到了广泛的关注。现有的作品通常假设输入图像是由全局快门相机拍摄的。因此，滚动快门（RS）图像不能简单地应用于用于新颖视图合成的现成NeRF算法。滚动快门效应也会影响相机姿态估计的准确性（例如，通过COLMAP），这进一步阻碍了NeRF算法在RS图像中的成功。在本文中，我们提出了Unrolling Shutter Bundle Adjusted Neural Radiance Fields（USB NeRF）。USB NeRF能够在NeRF的框架下，通过对RS相机的物理图像形成过程进行建模，同时校正滚动快门失真并恢复精确的相机运动轨迹。实验结果表明，USB NeRF在RS效应去除、新视角图像合成以及相机运动估计方面都比以往的工作取得了更好的性能。此外，我们的算法还可以用于从RS图像序列中恢复高保真高帧率全局快门视频。 et.al.|[2310.02687](http://arxiv.org/abs/2310.02687)|null|
|**2023-10-05**|**MagicDrive: Street View Generation with Diverse 3D Geometry Control**|扩散模型的最新进展显著增强了2D控制的数据合成。然而，街景生成中的精确3D控制，对于3D感知任务至关重要，仍然难以捉摸。具体而言，将鸟瞰图（BEV）作为主要条件通常会导致几何控制（如高度）方面的挑战，影响物体形状、遮挡模式和路面高程的表示，所有这些对于感知数据合成至关重要，尤其是对于3D物体检测任务。在本文中，我们介绍了MagicDrive，这是一种新颖的街景生成框架，提供各种3D几何控制，包括相机姿势、道路地图和3D边界框，以及文本描述，通过定制的编码策略实现。此外，我们的设计包含了一个跨视图注意力模块，确保了多个相机视图的一致性。通过MagicDrive，我们实现了高保真街景合成，可以捕捉细微的3D几何结构和各种场景描述，增强了BEV分割和3D对象检测等任务。 et.al.|[2310.02601](http://arxiv.org/abs/2310.02601)|null|
|**2023-10-03**|**MIMO-NeRF: Fast Neural Rendering with Multi-input Multi-output Neural Radiance Fields**|神经辐射场（NeRF）在新的视图合成中显示出令人印象深刻的结果。然而，它们依赖于重复使用单输入单输出多层感知器（SISO MLP），该感知器以逐样本的方式将3D坐标和视图方向映射到颜色和体积密度，这会减慢渲染速度。我们提出了一种多输入多输出NeRF（MIMO NeRF），通过用MIMO MLP替换SISO MLP并以分组方式进行映射来减少运行的MLP的数量。这种方法的一个显著挑战是，根据组中输入坐标的选择，每个点的颜色和体积密度可能不同，这可能导致一些显著的模糊性。我们还提出了一种自监督学习方法，该方法使用多个快速重新表述的MLP来正则化MIMO MLP，以在不使用预训练模型的情况下缓解这种模糊性。包括比较和消融研究在内的综合实验评估结果表明，在合理的训练时间内，MIMO NeRF在速度和质量之间取得了良好的平衡。然后，我们通过将MIMO NeRF应用于两个具有代表性的快速NeRF，即具有样本减少的NeRF（DONeRF）和具有替代表示的NeRF，来证明MIMO NeRF与NeRF的先前进步兼容并互补。 et.al.|[2310.01821](http://arxiv.org/abs/2310.01821)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-11**|**Orbital Polarimetric Tomography of a Flare Near the Sagittarius A* Supermassive Black Hole**|银河系中心的超大质量黑洞人马座A $^*$ 与其吸积盘之间的相互作用，偶尔会在X射线、红外和无线电中产生高能耀斑。观测到的耀斑的一种机制是在吸积盘中靠近事件视界形成致密明亮区域。了解这些耀斑可以为了解黑洞吸积过程提供一个窗口。尽管复杂的模拟预测了这些耀斑的形成，但它们的结构尚待观测恢复。在这里，我们展示了从2017年4月11日观测到的ALMA光曲线中恢复的轨道上发射耀斑的首次三维（3D）重建。我们的恢复结果显示，在大约6倍视界的距离处有致密的明亮区域。此外，我们的恢复表明，在低倾角轨道平面上顺时针旋转，这一结果与EHT和GRAVITY合作的先前研究一致。为了恢复这种发射结构，我们通过将神经3D表示（一种新兴的3D重建人工智能方法）与黑洞引力模型相结合，解决了一个高度不适定的层析成像问题。尽管恢复的3D结构受模型假设的影响，有时也很敏感，但在物理激励的选择下，我们发现我们的结果是稳定的，我们的方法在模拟数据上是成功的。我们预计，在未来，这种方法可以用于分析更丰富的时间序列数据，这些数据可以揭示黑洞和等离子体动力学的机制。 et.al.|[2310.07687](http://arxiv.org/abs/2310.07687)|null|
|**2023-10-11**|**rpcPRF: Generalizable MPI Neural Radiance Field for Satellite Camera**|卫星图像的新视图合成具有广泛的实际应用。虽然神经辐射场的最新进展主要针对针孔相机，而卫星相机的模型通常需要足够的输入视图。本文提出了一种用于有理多项式相机（RPC）的基于多平面图像（MPI）的平面神经辐射场rpcPRF。与需要一个场景的足够视图的基于坐标的神经辐射场不同，我们的模型适用于单个或少量输入，并且在来自看不见的场景的图像上表现良好。为了实现跨场景的泛化，我们建议使用重投影监督来诱导预测的MPI来学习3D坐标和图像之间的正确几何结构。此外，我们通过引入辐射场的绘制技术，消除了基于深度多视点立体的方法对密集深度监督的严格要求。rpcPRF结合了隐式表示的优势和RPC模型的优势，在学习三维结构的同时捕捉连续的高度空间。给定RGB图像及其相应的RPC，端到端模型学习将新视图与新的RPC合成，并重建场景的海拔高度。当提供多个视图作为输入时，rpcPRF施加由额外视图提供的额外监督。在ZY-3的TLC数据集和WV-3的城市场景的SatMVS3D数据集上，对于单视图和多视图任务，rpcPRF在图像保真度、重建精度和效率方面显著优于最先进的基于nerf的方法。 et.al.|[2310.07179](http://arxiv.org/abs/2310.07179)|null|
|**2023-10-10**|**SketchBodyNet: A Sketch-Driven Multi-faceted Decoder Network for 3D Human Reconstruction**|由于其对许多高级3D应用的基本支持，从2D图像重建3D人形最近受到了越来越多的关注。与自然图像相比，徒手草图更灵活地描绘各种形状，为三维人体重建提供了一种极具潜力和价值的方法。然而，这样的任务极具挑战性。草图的稀疏抽象特性给二维到三维重建已经很不适定的问题增加了严重的困难，如任意性、不准确和缺乏图像细节。尽管目前的方法在从单视图图像重建三维人体方面取得了巨大成功，但在徒手草图上效果不佳。在本文中，我们提出了一种新的草图驱动的多面解码器网络SketchBodyNet来解决这一任务。具体而言，该网络由一个主干和三个独立的注意力解码器分支组成，其中每个解码器中利用一个多头自注意力模块来获得增强的特征，然后是多层感知器。多面解码器的目的是分别预测相机、形状和姿态参数，然后将其与SMPL模型相关联，以重建相应的3D人体网格。在学习中，通过相机参数将现有的三维网格投影到具有关节的二维合成草图中，这些草图与徒手草图相结合以优化模型。为了验证我们的方法，我们收集了一个由大约26k个徒手草图及其相应的3D网格组成的大规模数据集，其中包含14个不同角度的人体各种姿势。大量的实验结果表明，我们的SketchBodyNet在从徒手草图重建三维人体网格方面取得了卓越的性能。 et.al.|[2310.06577](http://arxiv.org/abs/2310.06577)|null|
|**2023-10-08**|**Experiences with CAMRE: Single-Device Collaborative Adaptive Mixed Reality Environment**|在XR（扩展现实）中的协作过程中，用户通常在公共共享虚拟环境中共享虚拟对象并与之交互。具体来说，在混合现实（MR）中，用户之间的协作需要了解他们的位置、运动和对物理环境周围视觉场景的理解。否则，一个用户可以将一个重要的虚拟对象移动到被物理环境阻挡的位置。然而，即使对于单个物理环境，3D重建也需要很长时间，并且所产生的3D数据的大小通常非常大。此外，这些大量的3D数据需要很长时间才能流式传输到接收器，这使得对渲染场景的实时更新具有挑战性。此外，MR中的许多协作系统需要多个设备，这占用空间并使设置变得困难。为了应对这些挑战，在本文中，我们描述了一个名为协作自适应混合现实环境（CAMRE）的单设备系统。我们使用HoloLens 2设备的场景理解功能构建CAMRE，为每个连接的用户创建共享的MR虚拟环境，并使用Leader-Follower（s）范式进行演示：由于数据较小，重建和场景更新时间更快。因此，多个用户可以根据他们的物理位置和移动，从选定的Leader接收共享的、同步的、接近实时延迟的虚拟场景。我们还展示了CAMRE MR虚拟环境的其他扩展功能，如使用实时虚拟迷你地图的导航和用于处理自适应墙不透明度的X射线视觉。我们分享了几个实验结果，这些结果评估了CAMRE在共享虚拟对象和其他功能时的网络延迟方面的性能。 et.al.|[2310.04996](http://arxiv.org/abs/2310.04996)|null|
|**2023-10-06**|**Towards Non-contact 3D Ultrasound for Wrist Imaging**|目的：这项工作的目的是尝试在现有的护理点超声（POCUS）系统的基础上，以最小的复杂性实现非接触式徒手三维超声成像。方法：本研究提出了一种使用机械轨道进行非接触超声（US）扫描的新方法。因此，该方法将探针运动限制在线性平面上，以简化采集和3D重建过程。开发了一种利用美国研究平台和基于GPU的边缘设备进行美国3D体积重建的管道。结果：通过离体和体内实验证明了该方法的有效性。结论：所提出的方法具有可调节的视场能力、非接触式设计和低部署成本，而不会显著改变现有设置，这将为传统系统的升级打开大门，使其能够应用于广泛的3D US成像。意义：超声（US）成像是一种流行的临床成像方式，用于护理点床边成像，尤其是儿科人群的手腕/膝盖，因为其具有非侵入性和无辐射性。然而，在这种情况下，用2D US获得的组织结构的有限视图使诊断具有挑战性。为了克服这一点，开发了使用2D US图像及其方向/位置来重建3D体积的3D US成像。在三维重建中，以低成本精确估计美国探测器的位置一直是一项具有挑战性的任务。此外，US成像涉及接触，这会给儿科受试者在监测活骨折或开放性伤口时带来困难。为了克服这些挑战，本工作尝试了一种新颖的框架。 et.al.|[2310.04296](http://arxiv.org/abs/2310.04296)|null|
|**2023-10-06**|**ILSH: The Imperial Light-Stage Head Dataset for Human Head View Synthesis**|本文介绍了Imperial Light Stage Head（ILSH）数据集，这是一个新颖的Light Stage捕获的人头数据集，旨在支持人头的视图合成学术挑战。ILSH数据集旨在促进各种方法，如场景特定或通用神经渲染、多视图几何、3D视觉和计算机图形学，以进一步推动照片逼真的人类化身的开发。本文详细介绍了专门用于捕捉高分辨率（4K）人头图像的光台的设置，并描述了在收集高质量数据时应对挑战（预处理、道德问题）的过程。除了数据收集之外，我们还将数据集拆分为训练集、验证集和测试集。我们的目标是为这个新的数据集设计和支持一个公平视图综合挑战任务，以便在使用测试集时，如在使用验证集时，可以保持和预期类似的性能水平。ILSH数据集由52名受试者组成，这些受试者使用24台相机拍摄，所有82个光源都打开，共产生1248张特写头部图像、边界遮罩和相机姿势对。 et.al.|[2310.03952](http://arxiv.org/abs/2310.03952)|null|
|**2023-10-05**|**Hard View Selection for Contrastive Learning**|许多对比学习（CL）方法将其模型训练为对图像输入的不同“视图”保持不变，而良好的数据增强管道对图像输入至关重要。尽管在改进文本前任务、架构或鲁棒性（例如，连体网络或教师softmax居中）方面做出了相当大的努力，但这些方法中的大多数仍然强烈依赖于图像增强管道内操作的随机采样，例如随机调整大小的裁剪或颜色失真操作。在本文中，我们认为，到目前为止，视图生成的作用及其对性能的影响还没有得到足够的关注。为了解决这一问题，我们提出了一种简单、无需学习但功能强大的硬视图选择（HVS）策略，该策略旨在扩展随机视图生成，以在CL训练期间将预训练的模型暴露给更硬的样本。它包括以下迭代步骤：1）随机采样多个视图并创建两个视图对，2）在当前训练的模型上为每个视图对运行前向传递，3）对抗性地选择产生最差损失的对，以及4）使用所选对运行后向传递。在我们的实证分析中，我们发现在引擎盖下，HVS通过在预训练过程中控制视图并集上的交集来增加任务难度。HVS只需要300个历元的预训练，就可以与800个历元DINO基线相媲美，即使考虑到HVS额外前锋导致的速度放缓，这一基线仍然非常有利。此外，HVS在ImageNet上的线性评估精度持续提高0.55%至1.9%，在多种CL方法（如DINO、SimSiam和SimCLR）的传输任务上也实现了类似的改进。 et.al.|[2310.03940](http://arxiv.org/abs/2310.03940)|null|
|**2023-10-04**|**Condition numbers in multiview geometry, instability in relative pose estimation, and RANSAC**|在本文中，我们介绍了一个通用框架，用于分析多视图几何中最小问题的数值条件，使用计算代数和黎曼几何的工具。特别的动机来自这样一个事实，即基于标准的5点或7点随机样本一致性（RANSAC）算法的相对姿态估计，即使不存在异常值，并且有足够的数据支持假设，也可能失败。我们认为，这些情况是由于5点和7点极小问题的内在不稳定性引起的。我们应用我们的框架来表征不稳定性，既可以从导致无限条件数的世界场景的角度，也可以直接从病态图像数据的角度。该方法产生计算测试，用于在解决最小问题之前评估条件数。最后，合成和真实数据实验表明，正如我们的理论预测的那样，RANSAC不仅可以去除异常值，还可以选择条件良好的图像数据。 et.al.|[2310.02719](http://arxiv.org/abs/2310.02719)|null|
|**2023-10-02**|**PC-NeRF: Parent-Child Neural Radiance Fields under Partial Sensor Data Loss in Autonomous Driving Environments**|重建大规模3D场景对自动驾驶汽车至关重要，尤其是在部分传感器数据丢失的情况下。尽管最近开发的神经辐射场（NeRF）在隐式表示中显示出了令人信服的结果，但使用部分丢失的激光雷达点云数据进行大规模3D场景重建仍需探索。为了弥补这一差距，我们提出了一种新的3D场景重建框架，称为父子神经辐射场（PC NeRF）。该框架包括两个模块，父NeRF和子NeRF，以同时优化场景级、分段级和点级场景表示。通过利用子NeRF的分段级表示能力，可以更有效地利用传感器数据，并且即使在有限的观测下也可以快速获得场景的近似体积表示。经过大量的实验，我们提出的PC NeRF被证明可以在大规模场景中实现高精度的3D重建。此外，PC NeRF可以有效地处理部分传感器数据丢失的情况，并且在有限的训练时间内具有较高的部署效率。我们的方法实施和预先培训的模型将在https://github.com/biter0088/pc-nerf. et.al.|[2310.00874](http://arxiv.org/abs/2310.00874)|**[link](https://github.com/biter0088/pc-nerf)**|
|**2023-10-01**|**Enabling Neural Radiance Fields (NeRF) for Large-scale Aerial Images -- A Multi-tiling Approaching and the Geometry Assessment of NeRF**|神经辐射场（NeRF）提供了有益于3D重建任务的潜力，包括航空摄影测量。然而，对于大规模航空资产，推断几何结构的可扩展性和准确性并没有得到很好的证明，因为这样的数据集通常会导致非常高的内存消耗和缓慢的收敛。。在本文中，我们的目标是在大型scael航空数据集上缩放NeRF，并对NeRF进行全面的几何评估。具体而言，我们介绍了一种特定于位置的采样技术以及多摄像头拼接（MCT）策略，以减少RAM图像加载期间的内存消耗、GPU内存的表示训练，并提高拼接内的收敛率。MCT将大帧图像分解为具有不同相机模型的多个拼接图像，允许这些小帧图像根据特定位置的需要被输入到训练过程中，而不会损失准确性。我们在一种具有代表性的方法Mip-NeRF上实现了我们的方法，并在两个典型的航空数据集上与激光雷达参考数据比较了其几何性能与三光图MVS管道。定性和定量结果都表明，与传统方法相比，所提出的NeRF方法产生了更好的完整性和对象细节，尽管到目前为止，它在准确性方面仍然不足。 et.al.|[2310.00530](http://arxiv.org/abs/2310.00530)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-11**|**ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models**|在这项工作中，我们研究了以比训练图像大小高得多的分辨率从预先训练的扩散模型生成图像的能力。此外，生成的图像应当具有任意的图像纵横比。当使用分辨率为512 x 512的训练图像使用预训练的稳定扩散直接以1024 x 1024的更高分辨率生成图像时，我们观察到对象重复和不合理的对象结构的持续问题。现有的高分辨率生成工作，如基于注意力的方法和联合扩散方法，无法很好地解决这些问题。作为一个新的视角，我们研究了扩散模型中U-Net的结构成分，并将关键原因确定为卷积核的有限感知场。基于这一关键观察，我们提出了一种简单而有效的重新膨胀，可以在推理过程中动态调整卷积感知场。我们进一步提出了分散卷积和无噪声阻尼分类器引导，它可以实现超高分辨率图像生成（例如，4096 x 4096）。值得注意的是，我们的方法不需要任何培训或优化。大量实验表明，我们的方法可以很好地解决重复问题，并在更高分辨率的图像合成上实现最先进的性能，尤其是在纹理细节方面。我们的工作还表明，在低分辨率图像上训练的预训练扩散模型可以直接用于高分辨率视觉生成，而无需进一步调整，这可能为未来超高分辨率图像和视频合成的研究提供见解。 et.al.|[2310.07702](http://arxiv.org/abs/2310.07702)|**[link](https://github.com/yingqinghe/scalecrafter)**|
|**2023-10-11**|**ConditionVideo: Training-Free Condition-Guided Text-to-Video Generation**|最近的工作已经成功地将大规模的文本到图像模型扩展到视频领域，产生了有希望的结果，但计算成本很高，并且需要大量的视频数据。在这项工作中，我们介绍了ConditionVideo，这是一种基于所提供的条件、视频和输入文本的文本到视频生成的无训练方法，通过利用现成的文本到图像生成方法（例如，稳定扩散）的力量。ConditionVideo从随机噪声或给定场景视频中生成逼真的动态视频。我们的方法明确地将运动表示分解为条件引导和场景运动分量。为此，ConditionVideo模型设计了一个UNet分支和一个控制分支。为了提高时间连贯性，我们引入了稀疏双向时空注意（sBiST-Attn）。3D控制网络扩展了传统的2D控制网络模型，旨在通过额外利用时域中的双向帧来增强条件生成的准确性。我们的方法在帧一致性、剪辑分数和条件精度方面表现出优异的性能，优于其他比较方法。 et.al.|[2310.07697](http://arxiv.org/abs/2310.07697)|null|
|**2023-10-11**|**Thermal rectification in mass-asymmetric one-dimensional anharmonic oscillator lattices with and without a ballistic spacer**|在这项工作中，我们对影响热整流效果的各种结构参数进行了系统分析，即不对称热流和负微分热阻——随着施加的热偏压的增加，热通量的减少——以一维形式存在，分段质量分级系统由一个耦合的最近邻谐振子晶格（弹道垫片）和两个在两个边界连接到晶格的扩散引线（由衬底电势建模）组成。与之前的工作不同，我们认为垫片的尺寸小于引线的尺寸。还考虑了引线沿着振荡器晶格的整个长度连接的情况；即在不存在弹道垫片的情况下。根据系统参数的变化，确定了在没有弹道垫片的情况下，对于本文所考虑的小系统尺寸限制，通过光谱特性量化的装置的性能大大增强。 et.al.|[2310.07673](http://arxiv.org/abs/2310.07673)|null|
|**2023-10-11**|**Mini-DALLE3: Interactive Text to Image by Prompting Large Language Models**|随着文本到图像（T2I）扩散模型的蓬勃发展，人工智能内容生成的革命迅速加速。在短短两年的发展中，最先进的模型能够产生前所未有的高质量、多样性和创造力。然而，在使用自然语言描述与这些流行的T2I模型（如稳定扩散）进行有效沟通方面，仍然存在一个普遍的局限性。如果没有复杂单词组合、魔术标签和注释的即时工程专业知识，通常很难获得引人入胜的图像。受最近发布的DALLE3-一种直接内置ChatGPT的T2I模型的启发，我们重新审视了现有的T2I系统，该系统致力于协调人类意图，并引入了一种新的任务-交互式文本到图像（iT2I），人们可以与LLM进行交互，以使用自然语言生成/编辑/细化交错的高质量图像，并用更强的图像和文本对应关系回答问题。在解决iT2I问题时，我们提出了一种简单的方法，通过提示技术和现成的T2I模型来增强iT2I的LLM。我们在不同LLM下的各种常用场景中评估了我们的iT2I方法，例如，ChatGPT、LLAMA、百川和InternetLM。我们证明，我们的方法可以是一种方便且低成本的方式，在没有任何训练的情况下为任何现有LLM和任何文本到图像模型引入iT2I功能，同时几乎不会降低LLM在例如问答和代码生成方面的固有能力。我们希望这项工作能够引起更广泛的关注，并为提高人机交互的用户体验以及下一代T2I系统的图像质量提供灵感。 et.al.|[2310.07653](http://arxiv.org/abs/2310.07653)|null|
|**2023-10-11**|**Third order tensor-oriented directional splitting for exponential integrators**|通过流行的多维算子的张量积公式（例如扩散-平流）进行适当的离散化，可以得到具有 $d$维Kronecker和结构的矩阵。对于包含此类算子并在时间上与指数积分器积分的进化偏微分方程，有效近似这类矩阵的$\varphi$ -函数的作用至关重要。在这项工作中，我们展示了如何产生关于时间步长的三阶定向分裂近似。它们方便地使用张量矩阵乘积（以高性能级别3的BLAS实现），并允许在实践中有效使用高达三阶的指数积分器。该方法已经在两个著名的物理模型上成功地与最先进的技术进行了测试，即FitzHugh——Nagumo和Schnakenberg。 et.al.|[2310.07551](http://arxiv.org/abs/2310.07551)|null|
|**2023-10-11**|**Flux gradient relations and their dependence on turbulence anisotropy**|Monin-Obukhov相似性理论（MOST）几乎在每个地球系统模型（ESM）中都被用于参数化近地表湍流交换，但文献中关于要使用的适当参数化存在很大的不确定性。此外，MOST在非常稳定和不稳定的情况下，在异质地形和复杂地形上都有局限性，并且被发现不能正确地表示地表通量。最近开发了一种将湍流各向异性作为标度参数的新方法，可以克服这些限制，并将通量方差关系推广到复杂地形。在本文中，我们分析了五个已知数据集的通量梯度关系。标度关系显示出显著的分散性，并突出了参数化选择的不确定性，即使在规范条件下也是如此。我们表明，通过将湍流各向异性信息作为额外的标度参数，原始散射变得有界，并且可以开发新的公式，这大大提高了不稳定条件下风切变（ $\phi_M$）和不稳定和稳定状态下温度梯度（$\phi _H$）通量梯度关系的准确性。该分析表明，$\phi_M$和$\phi_H$都强烈依赖于湍流各向异性，并允许最终确定长期讨论的$\phi_M$的自由对流状态，当考虑各向异性时，该自由对流状态清楚地表现出$-{1/3}$ 幂律。此外，我们还证明了动量和热量的涡流扩散率以及湍流普朗特数强烈依赖于各向异性，并且后者在自由对流极限下为零。这些结果强调了在近地表大气湍流研究中包括各向异性的必要性，并为复杂地形上边界层的理论上更稳健的模拟开辟了道路。 et.al.|[2310.07503](http://arxiv.org/abs/2310.07503)|null|
|**2023-10-11**|**Boosting Black-box Attack to Deep Neural Networks with Conditional Diffusion Models**|现有的黑盒攻击在创建对抗性示例（AE）以欺骗深度学习模型方面显示出了很有希望的潜力。这些攻击中的大多数需要处理巨大的优化空间，并且需要大量的查询，因此在现实世界中表现出有限的实际影响。在本文中，我们提出了一种新的黑匣子攻击策略——条件扩散模型攻击（CDMA），以提高在查询受限情况下生成AE的查询效率。CDMA的关键见解是将AE合成任务表述为一个分布变换问题，即良性示例及其相应的AE可以被视为来自两个不同的分布，并且可以通过特定的转换器相互变换。与传统的\textit｛查询和优化｝方法不同，我们使用上述数据转换器通过直接条件转换生成符合条件的AE，这可以显著减少所需的查询数量。CDMA采用条件去噪扩散概率模型作为转换器，可以学习从干净样本到AE的转换，并确保扰动噪声对各种防御策略的平稳发展。我们通过在三个基准数据集上将CDMA与九种最先进的黑匣子攻击进行比较，证明了CDMA的有效性和效率。平均而言，CDMA可以将查询次数减少到几次；在大多数情况下，查询计数只有一个。我们还表明，对于所有数据集上的非目标攻击和CIFAR-10上的目标攻击，CDMA可以获得 $>99\%$的攻击成功率，噪声预算为$\epsilon=16$ 。 et.al.|[2310.07492](http://arxiv.org/abs/2310.07492)|null|
|**2023-10-11**|**Variational stabilization of degenerate p-elasticae**|在钉扎平面 $p$-弹性体的背景下，发现了一种由简并扩散引起的新的稳定现象。众所周知，在非退化状态$p\in（1,2]$中，包括欧拉弹性的经典情况下，除了唯一的全局极小值之外，没有其他局部极小值。在这里，我们证明了，与此形成鲜明对比的是，在退化状态$p \in（2，\infty）$ 中，出现了无数具有发散能量的局部极小值。 et.al.|[2310.07451](http://arxiv.org/abs/2310.07451)|null|
|**2023-10-11**|**Hadronic Re-Acceleration at the Crab Pulsar Wind Termination Shock as a Source of PeV Gamma-Rays**|LHAASO和西藏AS $\gamma$ 的最新结果表明，蟹状星云的伽马射线光谱延伸到PeV能量范围，但这种最高能量发射的产生机制尚不清楚。有人假设强子发射的二次分量可以解释最高能量的伽马射线通量点，但这种强子群体的起源和加速机制尚未解释。我们假设了一种情况，即强子随着时间的推移从周围的超新星喷出物扩散到蟹状脉冲星风星云，随后被脉冲星风终止冲击重新加速。我们给出了直接粒子输运模拟（包括径向演化）的结果，以确定这种情况在Crab系统的整个寿命内是否可行。 et.al.|[2310.07429](http://arxiv.org/abs/2310.07429)|null|
|**2023-10-11**|**Multi-Concept T2I-Zero: Tweaking Only The Text Embeddings and Nothing Else**|文本到图像扩散模型的最新进展已经实现了从文本提示生成图像的真实感。尽管取得了巨大的进步，但现有的模型仍然难以自然生成合成的多概念图像，这限制了它们可视化人类想象力的能力。虽然最近的几项工作试图解决这个问题，但它们要么引入额外的训练，要么在推理时采用指导。在这项工作中，我们考虑了一个更雄心勃勃的目标：使用预先训练的扩散模型生成自然的多概念，并且几乎没有额外的成本。为了实现这一目标，我们确定了用于预训练的文本到图像扩散模型的文本嵌入的局限性。具体而言，我们观察到概念主导和非局部贡献严重降低了多概念生成性能。我们进一步设计了一种最低成本的解决方案，通过调整（而不是重新训练）文本嵌入来克服上述问题，以实现更逼真的多概念文本到图像生成。我们的“相似性校正”方法通过从最相似的标记中收集语义特征来定位贡献，从而调整概念的嵌入。为了避免概念的混合特征，我们还应用了交叉令牌非最大抑制，它排除了不同概念贡献的重叠。实验表明，尽管在扩散步骤中没有引入额外的训练或推理成本，但我们的方法在文本到图像、图像操作和个性化任务方面优于以前的方法。 et.al.|[2310.07419](http://arxiv.org/abs/2310.07419)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-10-11**|**S4C: Self-Supervised Semantic Scene Completion with Neural Fields**|三维语义场景理解是计算机视觉中的一个基本挑战。它使移动代理能够自主规划和导航任意环境。SSC将这一挑战形式化为从场景的稀疏观测中联合估计密集的几何结构和语义信息。当前的SSC方法通常基于聚合的激光雷达扫描在3D地面实况上进行训练。这一过程依赖于特殊的传感器和手工注释，这些传感器和注释成本高昂且规模不大。为了克服这个问题，我们的工作提出了第一种称为S4C的SSC自监督方法，该方法不依赖于3D地面实况数据。我们提出的方法可以从单个图像重建场景，并且只依赖于训练期间从现成的图像分割网络生成的视频和伪分割地面实况。与使用离散体素网格的现有方法不同，我们将场景表示为隐式语义场。该公式允许查询相机截锥体内的任何点的占用率和语义类。我们的架构是通过基于渲染的自监督损失进行训练的。尽管如此，我们的方法实现了接近于完全监督的最先进方法的性能。此外，我们的方法表现出强大的泛化能力，可以为遥远的视点合成准确的分割图。 et.al.|[2310.07522](http://arxiv.org/abs/2310.07522)|null|
|**2023-10-07**|**HI-SLAM: Monocular Real-time Dense Mapping with Hybrid Implicit Fields**|在这封信中，我们提出了一个基于神经场的实时单目映射框架，用于精确和密集的同时定位和映射（SLAM）。最近的神经映射框架显示出有希望的结果，但依赖于RGB-D或姿势输入，或者无法实时运行。为了解决这些局限性，我们的方法将密集SLAM与神经隐式场相结合。具体来说，我们的密集SLAM方法运行并行跟踪和全局优化，而基于神经场的映射是基于最新的SLAM估计逐步构建的。为了有效地构造神经场，我们采用了多分辨率网格编码和符号距离函数（SDF）表示。这使我们能够始终保持地图的最新状态，并通过循环关闭立即适应全球更新。为了全局一致性，我们提出了一种有效的基于Sim（3）的姿态图束调整（PGBA）方法来运行在线闭环并减轻姿态和尺度漂移。为了进一步提高深度精度，我们结合了学习的单目深度先验。我们提出了一种新的深度和尺度联合调整（JDSA）模块来解决深度先验中固有的尺度模糊性。对合成和真实世界数据集的广泛评估验证了我们的方法在准确性和地图完整性方面优于现有方法，同时保持了实时性能。 et.al.|[2310.04787](http://arxiv.org/abs/2310.04787)|null|
|**2023-10-05**|**Variational Barycentric Coordinates**|我们提出了一种变分技术来优化广义重心坐标，与现有模型相比，该技术提供了额外的控制。先前的工作使用网格或闭式公式表示重心坐标，在实践中限制了目标函数的选择。相反，我们使用神经场直接参数化连续函数，该函数将多面体内部的任何坐标映射到其重心坐标。这个公式是通过我们对重心坐标的理论表征实现的，这使我们能够构建将有效坐标的整个函数类参数化的神经场。我们使用各种目标函数展示了我们模型的灵活性，包括多重光滑性和变形感知能量；作为补充，我们还提出了数学上合理的方法来测量和最小化目标，如不连续神经场的总变化。我们提供了一个实用的加速策略，对我们的算法进行了彻底的验证，并展示了几个应用。 et.al.|[2310.03861](http://arxiv.org/abs/2310.03861)|null|
|**2023-10-05**|**High-Degrees-of-Freedom Dynamic Neural Fields for Robot Self-Modeling and Motion Planning**|机器人自模型是机器人物理形态的任务不可知表示，在没有经典几何运动学模型的情况下，可用于运动规划任务。特别是，当后者难以设计或机器人的运动学发生意外变化时，人类自由的自我建模是真正自主智能体的必要特征。在这项工作中，我们利用神经场使机器人能够将其运动学自建模为仅从带有相机姿势和配置的2D图像中学习的神经隐式查询模型。这使得比依赖于深度图像或几何知识的现有方法具有更大的适用性。为此，除了课程数据采样策略外，我们还提出了一种新的基于编码器的神经密度场架构，用于高自由度（DOF）条件下的动态对象中心场景。在7自由度机器人测试装置中，学习的自模型实现了机器人工作空间尺寸2%的倒角-L2距离。作为一个示例性的下游应用程序，我们展示了该模型在运动规划任务中的能力。 et.al.|[2310.03624](http://arxiv.org/abs/2310.03624)|null|
|**2023-10-02**|**Neural Processing of Tri-Plane Hybrid Neural Fields**|在用于存储和通信3D数据的神经场的吸引人的特性的驱动下，直接处理它们以解决分类和零件分割等任务的问题已经出现，并在最近的工作中进行了研究。早期的方法使用由在整个数据集上训练的共享网络参数化的神经场，实现了良好的任务性能，但牺牲了重建质量。为了改进后者，后来的方法侧重于参数化为大型多层感知器（MLP）的单个神经场，然而，由于权重空间的高维性、固有的权重空间对称性和对随机初始化的敏感性，这些神经元场的处理具有挑战性。因此，结果明显不如通过处理显式表示（例如点云或网格）所获得的结果。与此同时，混合表示，特别是基于三平面的混合表示，已经成为实现神经场的一种更有效的替代方案，但其直接处理尚未得到研究。在本文中，我们证明了三平面离散数据结构编码了丰富的信息，标准的深度学习机器可以有效地处理这些信息。我们定义了一个广泛的基准，涵盖了一组不同的字段，如占用率、有符号/无符号距离，以及首次定义的辐射字段。在处理具有相同重建质量的字段时，我们实现的任务性能远远优于处理大型MLP的框架，并且首次几乎与处理显式表示的架构不相上下。 et.al.|[2310.01140](http://arxiv.org/abs/2310.01140)|null|
|**2023-09-27**|**Neural Acoustic Context Field: Rendering Realistic Room Impulse Response With Neural Fields**|房间脉冲响应（RIR）测量声音在环境中的传播，对于合成给定环境下的高保真音频至关重要。一些先前的工作已经提出将RIR表示为声音发射器和接收器位置的神经场函数。然而，这些方法没有充分考虑音频场景的声学特性，导致性能不令人满意。这封信提出了一种新的神经声学上下文场方法，称为NACF，通过利用多个声学上下文（如几何结构、材料特性和空间信息）来参数化音频场景。在RIR的独特性质，即时间不光滑性和单调能量衰减的驱动下，我们设计了一个时间相关模块和多尺度能量衰减准则。实验结果表明，NACF的性能显著优于现有的基于字段的方法。请访问我们的项目页面了解更多定性结果。 et.al.|[2309.15977](http://arxiv.org/abs/2309.15977)|null|
|**2023-09-27**|**SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations**|隐式神经表示（INR）或神经场已成为编码多媒体信号（如图像和辐射场）同时保持高质量的流行框架。最近，Instant NGP提出的可学习特征网格通过用特征向量的多分辨率查找表和更小的神经网络取代大型神经网络，在训练和INR采样方面实现了显著的加速。然而，这些功能网格是以大量内存消耗为代价的，这可能是存储和流应用程序的瓶颈。在这项工作中，我们提出了SHACIRA，这是一个简单而有效的任务无关框架，用于压缩这种特征网格，而不需要额外的事后修剪/量化阶段。我们用量化的潜在权重对特征网格进行重新参数化，并在潜在空间中应用熵正则化，以在各个领域实现高水平的压缩。在由图像、视频和辐射场组成的不同数据集上的定量和定性结果表明，我们的方法优于现有的INR方法，而不需要任何大型数据集或特定领域的启发式方法。我们的项目页面可在http://shacira.github.io。 et.al.|[2309.15848](http://arxiv.org/abs/2309.15848)|null|
|**2023-09-27**|**NeuRBF: A Neural Fields Representation with Adaptive Radial Basis Functions**|我们提出了一种新型的神经场，它使用一般的径向基来表示信号。现有技术的神经领域通常依赖于用于存储局部神经特征的基于网格的表示和用于在连续查询点处插值特征的N维线性核。它们的神经特征的空间位置固定在网格节点上，不能很好地适应目标信号。相反，我们的方法建立在具有灵活内核位置和形状的通用径向基上，这些径向基具有更高的空间自适应性，可以更紧密地拟合目标信号。为了进一步提高径向基函数的信道容量，我们建议将它们与多频率正弦函数组合。该技术将径向基扩展到不同频带的多个傅立叶径向基，而不需要额外的参数，便于细节的表示。此外，通过将自适应径向基与基于网格的径向基相结合，我们的混合组合继承了自适应性和插值平滑性。我们精心设计了加权方案，使径向基有效地适应不同类型的信号。我们在2D图像和3D符号距离场表示上的实验证明了我们的方法比现有技术更高的精度和紧凑性。当应用于神经辐射场重建时，我们的方法实现了最先进的渲染质量，模型大小小，训练速度相当。 et.al.|[2309.15426](http://arxiv.org/abs/2309.15426)|**[link](https://github.com/oppo-us-research/NeuRBF)**|
|**2023-09-29**|**3D Reconstruction with Generalizable Neural Fields using Scene Priors**|由于神经领域的最新进展，高保真3D场景重建得到了实质性的推进。然而，大多数现有的方法为每个单独的场景从头开始训练单独的网络。这是不可扩展的，效率低下，并且在视图有限的情况下无法产生良好的结果。虽然基于学习的多视图立体方法在一定程度上缓解了这一问题，但它们的多视图设置使其扩展和广泛应用的灵活性降低。相反，我们引入了结合场景先验（NFP）的训练可推广神经场。NFP网络将任何单视图RGB-D图像映射为带符号的距离和辐射值。在没有融合模块的情况下，可以通过合并体积空间中的各个帧来重建完整的场景，这提供了更好的灵活性。场景先验可以在大规模数据集上进行训练，从而能够快速适应具有较少视图的新场景的重建。NFP不仅展示了SOTA场景重建的性能和效率，而且还支持单图像新视图合成，这在神经领域还没有得到充分的探索。更多定性结果可在以下网站获得：https://oasisyang.github.io/neural-prior et.al.|[2309.15164](http://arxiv.org/abs/2309.15164)|null|
|**2023-09-22**|**NOC: High-Quality Neural Object Cloning with 3D Lifting of Segment Anything**|随着神经领域的发展，从多视图输入重建目标物体的3D模型最近越来越受到社会的关注。现有的方法通常学习整个场景的神经场，而如何在飞行中重建用户指示的特定对象仍在探索之中。考虑到分段任意模型（SAM）在分割任何2D图像方面都显示出了有效性，本文提出了一种新的高质量3D对象重建方法——神经对象克隆（NOC），它从两个方面利用了神经场和SAM的优点。首先，为了将目标对象从场景中分离出来，我们提出了一种新的策略，将SAM的多视图2D分割掩模提升到一个统一的3D变化场中。然后，3D变化场被投影到2D空间中，并生成SAM的新提示。这个过程是迭代的，直到收敛，以将目标对象从场景中分离出来。然后，除了2D掩模之外，我们进一步将SAM编码器的2D特征提升到3D SAM场中，以提高目标对象的重建质量。NOC将SAM的2D掩模和特征提升到3D神经场中，用于高质量的目标对象重建。我们在几个基准数据集上进行了详细的实验，以证明我们的方法的优势。代码将被发布。 et.al.|[2309.12790](http://arxiv.org/abs/2309.12790)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

