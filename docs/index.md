---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.11.17
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-11-11**|**Aria-NeRF: Multimodal Egocentric View Synthesis**|基于受神经辐射场（NeRFs）启发的可微分体积射线跟踪，我们寻求加快开发从以自我为中心的数据训练的丰富的多模式场景模型的研究。从以自我为中心的图像序列构建类似NeRF的模型在理解人类行为方面发挥着关键作用，并在VR/AR领域具有多种应用。这种以自我为中心的类NeRF模型可以用作现实模拟，对能够在现实世界中执行任务的智能代理的发展做出了重大贡献。以自我为中心的视图合成的未来可能会通过使用多模式传感器（如用于自我运动跟踪的IMU、用于捕捉表面纹理和人类语言上下文的音频传感器以及用于推断场景中人类注意力模式的眼睛凝视跟踪器）来增强视觉数据，从而产生超越当今NeRF的新环境表示。为了支持和促进以自我为中心的多模式场景建模的开发和评估，我们提出了一个全面的多模式自我中心视频数据集。该数据集提供了一个全面的感官数据集，包括RGB图像、眼动追踪相机镜头、麦克风录音、气压计的气压读数、GPS的位置坐标、Wi-Fi和蓝牙的连接细节，以及与磁力计配对的双频IMU数据集（1kHz和800Hz）的信息。数据集是使用Meta Aria Glasses可穿戴设备平台收集的。该数据集中捕获的各种数据模式和真实世界背景为我们进一步理解人类行为奠定了坚实的基础，并在VR、AR和机器人领域实现了更身临其境的智能体验。 et.al.|[2311.06455](http://arxiv.org/abs/2311.06455)|null|
|**2023-11-10**|**Improved Positional Encoding for Implicit Neural Representation based Compact Data Representation**|采用位置编码来捕获隐式神经表示（INR）中编码信号的高频信息。在本文中，我们提出了一种新的位置编码方法，该方法提高了INR的重建质量。所提出的嵌入方法对于紧凑的数据表示更有利，因为它比现有方法具有更多的频率基。我们的实验表明，该方法在压缩任务中没有引入任何额外的复杂性，并且在新的视图合成中具有更高的重建质量，从而在率失真性能上获得了显著的增益。 et.al.|[2311.06059](http://arxiv.org/abs/2311.06059)|null|
|**2023-11-09**|**Real-Time Neural Rasterization for Large Scenes**|提出了一种新的大场景真实感实时新视图合成方法。现有的神经渲染方法可以生成逼真的结果，但主要适用于小规模场景（<50平方米），在大规模场景（>10000平方米）中存在困难。传统的基于图形的光栅化渲染对于大型场景来说速度很快，但缺乏真实感，并且需要昂贵的手动创建资源。我们的方法结合了两全其美，将中等质量的脚手架网格作为输入，学习神经纹理场和着色器来建模与视图相关的效果，以增强真实感，同时仍然使用标准图形管道进行实时渲染。我们的方法优于现有的神经渲染方法，为大型自动驾驶和无人机场景提供了至少30倍的渲染速度和相当或更好的真实感。我们的工作是第一个实现大型真实世界场景的实时渲染。 et.al.|[2311.05607](http://arxiv.org/abs/2311.05607)|null|
|**2023-11-09**|**Reconstructing Objects in-the-wild for Realistic Sensor Simulation**|从真实世界的数据中重建物体并以新颖的视图渲染它们，对于为机器人训练和测试的模拟带来真实性、多样性和规模至关重要。在这项工作中，我们提出了NeuSim，这是一种新的方法，可以根据在距离和有限视点捕获的稀疏野外数据来估计精确的几何结构和逼真的外观。为了实现这一目标，我们将物体表面表示为神经符号距离函数，并利用激光雷达和相机传感器数据来重建平滑准确的几何体和法线。我们用一种稳健的、受物理启发的反射率表示法对物体外观进行建模，该表示法对野外数据有效。我们的实验表明，NeuSim在具有稀疏训练视图的具有挑战性的场景中具有强大的视图合成性能。此外，我们展示了将NeuSim资产组合到虚拟世界中，并生成用于评估自动驾驶感知模型的真实多传感器数据。 et.al.|[2311.05602](http://arxiv.org/abs/2311.05602)|null|
|**2023-11-09**|**BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis**|从视频中合成逼真的4D人头头像对于VR/AR、远程呈现和视频游戏应用至关重要。尽管现有的基于神经辐射场（NeRF）的方法实现了高保真度的结果，但计算费用限制了它们在实时应用中的使用。为了克服这一限制，我们引入了BakedAvatar，这是一种用于实时神经头部化身合成的新表示，可部署在标准多边形光栅化管道中。我们的方法从学习的头部等值面中提取可变形的多层网格，并计算与表情、姿势和视图相关的外观，这些外观可以烘焙到静态纹理中，以实现高效的光栅化。因此，我们提出了一种用于神经头化身合成的三阶段流水线，包括学习连续变形、流形和辐射场，提取分层网格和纹理，以及使用差分光栅化微调纹理细节。实验结果表明，我们的表示生成的合成结果质量与其他最先进的方法相当，同时显著减少了所需的推理时间。我们进一步展示了单眼视频中的各种头部化身合成结果，包括视图合成、面部再现、表情编辑和姿势编辑，所有这些都是以交互式帧率进行的。 et.al.|[2311.05521](http://arxiv.org/abs/2311.05521)|null|
|**2023-11-09**|**VoxNeRF: Bridging Voxel Representation and Neural Radiance Fields for Enhanced Indoor View Synthesis**|创建高质量的视图合成对于沉浸式应用程序至关重要，但仍然存在问题，尤其是在室内环境和实时部署中。当前的技术经常需要大量的计算时间来进行训练和渲染，并且由于不充分的几何结构，经常产生不太理想的3D表示。为了克服这一点，我们引入了VoxNeRF，这是一种利用体积表示来提高室内视图合成质量和效率的新方法。首先，VoxNeRF构建结构化的场景几何体，并将其转换为基于体素的表示。我们使用多分辨率哈希网格自适应地捕捉空间特征，有效地管理室内场景的遮挡和复杂几何结构。其次，我们提出了一种独特的体素引导的高效采样技术。这一创新有选择地将计算资源集中在射线段的最相关部分，大大减少了优化时间。我们针对三个公共室内数据集验证了我们的方法，并证明VoxNeRF优于最先进的方法。值得注意的是，它在减少训练和渲染时间的同时实现了这些收益，速度甚至超过了Instant NGP，使技术更接近实时。 et.al.|[2311.05289](http://arxiv.org/abs/2311.05289)|null|
|**2023-11-08**|**VET: Visual Error Tomography for Point Cloud Completion and High-Quality Neural Rendering**|在过去的几年里，深度神经网络为新视图合成的巨大进步打开了大门。这些方法中的许多都是基于通过结构从运动算法获得的（粗略）代理几何结构。这种代理中的小缺陷可以通过神经渲染来修复，但较大的孔洞或缺失部分，通常出现在薄结构或光滑区域，仍然会导致分散注意力的伪影和时间不稳定。在本文中，我们提出了一种新的基于神经渲染的方法来检测和修复这些缺陷。作为代理，我们使用点云，这使我们能够轻松删除异常几何体并填充缺失的几何体，而无需复杂的拓扑操作。我们方法的关键是（i）一个可微分的、基于混合点的渲染器，它可以混合掉多余的点，以及（ii）视觉误差层析成像（VET）的概念，它允许我们提升2D误差图，以识别缺乏几何结构的3D区域，并相应地生成新的点。此外，（iii）通过添加点作为嵌套的环境贴图，我们的方法使我们能够在同一管道中生成高质量的周围环境渲染图。在我们的结果中，我们表明我们的方法可以提高由结构从运动中获得的点云的质量，从而显著提高新视图合成的质量。与点生长技术相比，该方法还可以有效地修复大规模孔洞和缺失的薄结构。渲染质量优于最先进的方法，时间稳定性显著提高，同时可以以实时帧速率进行渲染。 et.al.|[2311.04634](http://arxiv.org/abs/2311.04634)|**[link](https://github.com/lfranke/vet)**|
|**2023-11-08**|**Learning Robust Multi-Scale Representation for Neural Radiance Fields from Unposed Images**|我们介绍了一种改进的计算机视觉中基于神经图像的绘制问题的解决方案。给定一组在火车时刻从自由移动的相机拍摄的图像，所提出的方法可以在测试时刻从一个新颖的视角合成真实的场景图像。本文提出的关键思想是：（i）在神经新视图合成问题中，通过稳健的管道从未处理的日常图像中恢复准确的相机参数同样至关重要；（ii）以不同的分辨率对对象的内容进行建模更为实用，因为在日常的未渲染图像中，相机的剧烈运动极有可能发生。为了结合这些关键思想，我们利用了场景刚性、多尺度神经场景表示和单图像深度预测的基本原理。具体地说，所提出的方法使相机参数在基于神经场的建模框架中是可学习的。通过假设每个视图的深度预测是按比例进行的，我们限制了连续帧之间的相对姿态。根据相对姿态，通过多尺度神经场网络内的基于图神经网络的多运动平均来建模绝对相机姿态估计，从而产生单个损失函数。优化引入的损失函数提供了相机内在的、外在的以及从未聚焦的图像渲染的图像。我们通过例子证明，对于从日常获取的未聚焦多视图图像中精确建模多尺度神经场景表示的统一框架，在场景表示框架内进行精确的相机姿态估计同样重要。如果不考虑相机姿态估计管道中的鲁棒性措施，对多尺度混叠伪影进行建模可能会适得其反。我们在几个基准数据集上进行了大量实验，以证明我们的方法的适用性。 et.al.|[2311.04521](http://arxiv.org/abs/2311.04521)|null|
|**2023-11-07**|**3DiffTection: 3D Object Detection with Geometry-Aware Diffusion Features**|我们提出了3DiffTection，这是一种利用3D感知扩散模型的特征从单个图像中检测3D对象的最先进方法。注释用于3D检测的大规模图像数据是资源密集型且耗时的。最近，预训练的大图像扩散模型已经成为2D感知任务的有效特征提取器。然而，这些特征最初是在成对的文本和图像数据上训练的，这些数据没有针对3D任务进行优化，并且在应用于目标数据时经常表现出域间隙。我们的方法通过两种专门的调整策略弥合了这些差距：几何和语义。对于几何调整，我们通过引入新的核极扭曲算子，对扩散模型进行微调，以在单个图像的条件下执行新的视图合成。这项任务符合两个基本标准：3D感知的必要性和仅依赖于姿势图像数据，这些数据很容易获得（例如，来自视频），不需要手动注释。对于语义细化，我们在具有检测监督的目标数据上进一步训练模型。两个调优阶段都使用ControlNet来保持原始功能的完整性。在最后一步中，我们利用这些增强的功能在多个虚拟视点上进行测试时间预测集成。通过我们的方法，我们获得了为3D检测量身定制的3D感知特征，并擅长识别跨视点对应关系。因此，我们的模型成为了一个强大的3D检测器，大大超过了以前的基准，例如Cube RCNN，这是Omni3D ARkitscene数据集上AP3D单视图3D检测的先例，提高了9.43\%。此外，3DiffTection展示了强大的数据效率和跨领域数据的泛化能力。 et.al.|[2311.04391](http://arxiv.org/abs/2311.04391)|null|
|**2023-11-08**|**UP-NeRF: Unconstrained Pose-Prior-Free Neural Radiance Fields**|神经辐射场（NeRF）实现了具有高保真度的给定图像和相机姿态的新颖视图合成。随后的工作甚至通过联合优化NeRF和相机姿态，成功地消除了姿态先验的必要性。然而，这些作品仅限于相对简单的设置，例如光度一致和无遮挡的图像集合或视频中的图像序列。因此，他们很难处理具有不同照明和瞬态遮挡的无约束图像。在本文中，我们提出了 $\textbf｛UP NeRF｝$（$\textbf｛U｝$不受约束的$\textbf｛P｝$ose先验自由$\textbf｛Ne｝$ural$\textbf｛R｝$adiance$\textFf｝$ields），以在没有相机姿态先验的情况下优化具有无约束图像集合的NeRF。我们通过优化颜色不敏感特征场的代理任务和用于瞬态遮挡器的单独模块来解决这些挑战，以阻止它们对姿态估计的影响。此外，我们引入了一个候选头部，以实现更稳健的姿态估计和瞬态感知深度监督，从而最大限度地减少不正确先验的影响。在具有挑战性的互联网照片集$\textit｛Phototourism｝$ 数据集中，与包括BARF及其变体在内的基线相比，我们的实验验证了我们的方法的优越性能。 et.al.|[2311.03784](http://arxiv.org/abs/2311.03784)|**[link](https://github.com/mlvlab/upnerf)**|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-11-15**|**Single-Image 3D Human Digitization with Shape-Guided Diffusion**|我们提出了一种从单个输入图像生成具有一致、高分辨率外观的人的360度视图的方法。NeRF及其变体通常需要来自不同视点的视频或图像。大多数采用单目输入的现有方法要么依赖于地面实况3D扫描进行监督，要么缺乏3D一致性。虽然最近的3D生成模型显示了3D一致性人类数字化的前景，但这些方法并不能很好地推广到不同的服装外观，而且结果缺乏真实感。与现有工作不同，我们使用为一般图像合成任务预训练的高容量2D扩散模型作为穿着衣服的人类的外观先验。为了在保持输入身份的同时实现更好的3D一致性，我们通过以轮廓和表面法线为条件的形状引导扩散修复缺失区域，逐步合成输入图像中人类的多个视图。然后，我们通过反向渲染将这些合成的多视图图像融合在一起，以获得给定人物的全纹理高分辨率3D网格。实验表明，我们的方法优于现有方法，并从单个图像中实现了对具有复杂纹理的各种穿着衣服的人的360度真实感合成。 et.al.|[2311.09221](http://arxiv.org/abs/2311.09221)|null|
|**2023-11-14**|**LocaliseBot: Multi-view 3D object localisation with differentiable rendering for robot grasping**|机器人抓取通常分为五个阶段：物体检测、物体定位、物体姿态估计、抓取姿态估计和抓取规划。我们专注于物体姿态估计。我们的方法依赖于三条信息：对象的多个视图、这些视图处的相机外部参数以及对象的3D CAD模型。第一步涉及标准的深度学习主干（FCN-ResNet）来估计对象标签、语义分割和对象相对于相机姿态的粗略估计。我们的新颖之处在于使用了一个细化模块，该模块从粗略的姿态估计开始，并通过可微分渲染进行优化来对其进行细化。这是一种纯粹基于视觉的方法，避免了对点云或深度图像等其他信息的需要。我们在ShapeNet数据集上评估了我们的物体姿态估计方法，并展示了对现有技术的改进。我们还表明，在使用标准实践计算的物体杂波室内数据集（OCID）抓握数据集上，与地面实况抓握候选数据相比，估计的物体姿态的抓握准确率为99.65%。 et.al.|[2311.08438](http://arxiv.org/abs/2311.08438)|null|
|**2023-11-14**|**DynamicSurf: Dynamic Neural RGB-D Surface Reconstruction with an Optimizable Feature Grid**|我们提出了DynamicSurf，这是一种无模型的神经隐式表面重建方法，用于单目RGB-D视频中非刚性表面的高保真3D建模。为了解决变形曲面的单目序列中缺乏多视图提示的问题，DynamicSurf利用深度、曲面法线和RGB损失来提高重建保真度和优化时间，这是3D重建最具挑战性的设置之一。DynamicSurf学习将曲面几何体的规范表示映射到当前帧的神经变形场。我们通过将正则表示设计为学习特征网格来偏离当前的神经非刚性表面重建模型，这比使用单个MLP的竞争方法更快、更准确地进行表面重建。我们在公共数据集上演示了DynamicSurf，并表明与纯基于MLP的方法相比，它可以以 $6\times$ speed优化不同帧的序列，同时获得与最先进方法相当的结果。项目可在https://mirgahney.github.io//DynamicSurf.io/. et.al.|[2311.08159](http://arxiv.org/abs/2311.08159)|null|
|**2023-11-13**|**$L_0$-Sampler: An $L_{0}$ Model Guided Volume Sampling for NeRF**|自提出以来，神经辐射场（NeRF）在相关任务中取得了巨大成功，主要采用分层体采样（HVS）策略进行体绘制。然而，NeRF的HVS使用分段常数函数来近似分布，这提供了相对粗略的估计。基于观察到训练有素的权重函数$w（t）$和点与曲面之间的$L_0$距离具有很高的相似性，我们提出了$L_0$-Sampler，通过将$L_0美元模型合并到$w（t）$中来指导采样过程。具体来说，我们建议使用分段指数函数而不是分段常数函数进行插值，这不仅可以很好地近似沿射线的准$L_0$权重分布，而且可以用几行代码轻松实现，而无需额外的计算负担。通过将$L_0$ -Sampler应用于NeRF及其相关任务（如3D重建），可以实现稳定的性能改进。代码可在https://ustc3dv.github.io/L0-Sampler/。 et.al.|[2311.07044](http://arxiv.org/abs/2311.07044)|null|
|**2023-11-14**|**Comparative Multi-View Language Grounding**|在这项工作中，我们考虑了在给出比较语言描述时解决对象指称的任务。我们提出了一种基于上下文的多视图方法（MAGiC），该方法利用转换器在给定多个图像视图和语言描述的情况下对两个对象进行务实的推理。与过去试图在没有充分考虑所产生的指称上下文的情况下将视觉和语言联系起来完成这项任务的努力相反，MAGiC通过对对象指称候选者和指称语言表达的多个观点进行联合推理来利用比较信息。我们的分析表明，比较推理有助于SOTA在SNARE对象引用任务中的性能。 et.al.|[2311.06694](http://arxiv.org/abs/2311.06694)|null|
|**2023-11-11**|**3DFusion, A real-time 3D object reconstruction pipeline based on streamed instance segmented data**|本文提出了一种实时分割和重建系统，该系统利用RGB-D图像来生成捕获场景中对象的精确和详细的单个3D模型。利用最先进的实例分割技术，该系统对RGB-D数据进行像素级分割，有效地将前景对象与背景分离。然后在高性能计算平台中将分割的对象重建为不同的3D模型。实时3D建模可以应用于各个领域，包括增强/虚拟现实、室内设计、城市规划、道路辅助、安全系统等。为了实现实时性，本文提出了一种在保证重建质量的同时，对连续帧进行有效采样以减少网络负载的方法。此外，采用多进程SLAM流水线进行并行三维重建，能够有效地将聚类对象切割成个体。该系统采用业界领先的YOLO框架进行细分。为了提高YOLO的性能和准确性，对其进行了修改，以解决类似物体的重复或错误检测，确保重建的模型与目标对准。总的来说，这项工作建立了一个强大的实时系统，大大增强了室内环境中的对象分割和重建。它有可能扩展到户外场景，为现实世界的应用开辟了许多机会。 et.al.|[2311.06659](http://arxiv.org/abs/2311.06659)|null|
|**2023-11-09**|**Liquid phase fast electron tomography unravels the true 3D structure of colloidal assemblies**|电子断层扫描已成为研究纳米材料三维（3D）结构的常用工具，包括胶体纳米颗粒组件。然而，电子显微镜技术的性质通常要求在高真空下进行这种表征。因此，通过（湿）胶体化学方法制备的组件需要预处理样品制备，包括溶剂蒸发和在固体基底上沉积（TEM网格）。因此，变化总是强加在实际的纳米颗粒组织上，这在很大程度上是纳米材料性质的原因。因此，我们在此提出在纳米颗粒组件的原始胶体环境中应用（快速）电子断层扫描。为了解决与液体电子断层扫描相关的挑战，我们设计了一种方法，将商业液体原位TEM池中的快速数据采集与专用重建工作流程相结合。我们介绍了这种方法在两个不同系统中的应用，这两个系统举例说明了干燥和真空的影响，这取决于保护配体的性质。包括包封在聚合物壳中的聚苯乙烯封端的Au纳米颗粒的组件的3D重建显示，与干燥的对应物相比，在液体介质中进行的实验的结构不那么紧凑，变形更大。另一方面，对水中自组装Au纳米棒的颗粒间距离的定量分析与之前报道的纳米棒周围配体层的尺寸一致，而纳米棒在类似的干燥组件中接触得更紧密。因此，这项研究强调了开发高分辨率表征工具的重要性，以保护胶体纳米结构的天然环境。 et.al.|[2311.05309](http://arxiv.org/abs/2311.05309)|null|
|**2023-11-09**|**ConRad: Image Constrained Radiance Fields for 3D Generation from a Single Image**|我们提出了一种从单个RGB图像重建3D对象的新方法。我们的方法利用最新的图像生成模型来推断隐藏的3D结构，同时保持对输入图像的忠实。虽然现有的方法在从文本提示生成3D模型方面获得了令人印象深刻的结果，但它们并不能提供一种简单的方法来调节输入RGB数据。这些方法的简单扩展通常会导致输入图像和3D重建之间的外观不正确。我们通过引入图像约束辐射场（ConRad）来解决这些挑战，神经辐射场的一种新变体。ConRad是一种高效的3D表示，它明确地捕捉一个视点中输入图像的外观。我们提出了一种训练算法，该算法利用单个RGB图像和预训练的扩散模型来优化ConRad表示的参数。大量实验表明，ConRad表示可以简化图像细节的保存，同时产生逼真的3D重建。与现有的最先进的基线相比，我们表明，我们的3D重建仍然更忠实于输入，并产生更一致的3D模型，同时在ShapeNet对象基准上展示了显著改进的定量性能。 et.al.|[2311.05230](http://arxiv.org/abs/2311.05230)|null|
|**2023-11-08**|**Implicit Neural Representations for Breathing-compensated Volume Reconstruction in Robotic Ultrasound Aorta Screening**|超声（US）成像由于缺乏非电离辐射和普遍可用性，被广泛用于腹部疾病的诊断和分期。然而，操作员之间的显著可变性和不一致的图像采集阻碍了广泛采用广泛的筛查程序。机器人超声系统已经成为一种很有前途的解决方案，它提供了标准化的采集协议和自动化采集的可能性。此外，这些系统能够通过机器人跟踪访问3D数据，增强体积重建，以改进超声解释和精确的疾病诊断。然而，腹部图像的3D US重建的可解释性可能会受到患者呼吸运动的影响。本研究介绍了一种通过利用隐式神经表示来补偿3D US复合中的呼吸运动的方法。我们的方法采用机器人超声波系统进行自动筛查。为了证明该方法的有效性，我们将我们提出的诊断和监测腹主动脉瘤的方法作为一个有代表性的使用案例进行了评估。我们的实验表明，我们提出的管道有助于强大的自动机器人采集，减轻呼吸运动产生的伪影，并产生更平滑的3D重建，以增强筛查和医学诊断。 et.al.|[2311.04999](http://arxiv.org/abs/2311.04999)|null|
|**2023-11-08**|**LRM: Large Reconstruction Model for Single Image to 3D**|我们提出了第一个大型重建模型（LRM），它可以在5秒内从单个输入图像中预测对象的3D模型。与以前在ShapeNet等小规模数据集上以特定类别的方式训练的许多方法不同，LRM采用了一种高度可扩展的基于变换器的架构，具有5亿个可学习参数，可以直接从输入图像中预测神经辐射场（NeRF）。我们在包含约100万个对象的海量多视图数据上以端到端的方式训练我们的模型，包括Ob厌恶对象的合成渲染和MVImgNet的真实捕捉。这种高容量模型和大规模训练数据的结合使我们的模型能够高度通用，并根据各种测试输入产生高质量的3D重建，包括真实世界的野外捕捉和生成模型的图像。视频演示和可交互的3D网格可以在这个网站上找到：https://yiconghong.me/LRM/. et.al.|[2311.04400](http://arxiv.org/abs/2311.04400)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-11-15**|**Single-Image 3D Human Digitization with Shape-Guided Diffusion**|我们提出了一种从单个输入图像生成具有一致、高分辨率外观的人的360度视图的方法。NeRF及其变体通常需要来自不同视点的视频或图像。大多数采用单目输入的现有方法要么依赖于地面实况3D扫描进行监督，要么缺乏3D一致性。虽然最近的3D生成模型显示了3D一致性人类数字化的前景，但这些方法并不能很好地推广到不同的服装外观，而且结果缺乏真实感。与现有工作不同，我们使用为一般图像合成任务预训练的高容量2D扩散模型作为穿着衣服的人类的外观先验。为了在保持输入身份的同时实现更好的3D一致性，我们通过以轮廓和表面法线为条件的形状引导扩散修复缺失区域，逐步合成输入图像中人类的多个视图。然后，我们通过反向渲染将这些合成的多视图图像融合在一起，以获得给定人物的全纹理高分辨率3D网格。实验表明，我们的方法优于现有方法，并从单个图像中实现了对具有复杂纹理的各种穿着衣服的人的360度真实感合成。 et.al.|[2311.09221](http://arxiv.org/abs/2311.09221)|null|
|**2023-11-15**|**DMV3D: Denoising Multi-View Diffusion using 3D Large Reconstruction Model**|我们提出了一种新的3D生成方法\textbf{DMV3D}，该方法使用基于变换器的3D大重建模型来对多视图扩散进行去噪。我们的重建模型结合了三平面NeRF表示，可以通过NeRF重建和渲染对有噪声的多视图图像进行去噪，在单个A100 GPU上以 $\sim$ 30s实现单级3D生成。我们在高度多样化对象的大规模多视图图像数据集上训练\textbf｛DMV3D｝，只使用图像重建损失，而不访问3D资产。我们展示了单图像重建问题的最新结果，其中需要对看不见的物体部分进行概率建模，以生成具有清晰纹理的各种重建。我们还展示了高质量的文本到3D生成结果，其性能优于以前的3D扩散模型。我们的项目网站位于：https://justimyhxu.github.io/projects/dmv3d/。 et.al.|[2311.09217](http://arxiv.org/abs/2311.09217)|null|
|**2023-11-15**|**Finding polarised communities and tracking information diffusion on Twitter: The Irish Abortion Referendum**|对社交网络的分析能够理解社会互动、思想两极分化和信息传播，因此在社会中发挥着重要作用。我们使用推特数据——因为它是表达意见和传播信息的热门场所——来识别辩论的对立双方，重要的是，观察在当前两极分化的气候下，信息是如何在这些群体之间传播的。为了实现这一点，我们从2018年爱尔兰堕胎公投中收集了超过688000条推文，以建立一个对话网络，从用户提到的基于情感的同性恋者中。从这个网络中，社区检测方法使我们能够以高准确率（90.9%）分离出赞成或反对的支持者。我们通过跟踪信息级联如何通过31000多条转发级联传播来补充这一点。我们发现，在两极分化的社区之间传播的信息很少。这为通过隔离意识形态两极分化的群体并探索这些群体内部和之间的信息传播，提取和研究大型网络上的信息传播提供了一种有价值的方法。 et.al.|[2311.09196](http://arxiv.org/abs/2311.09196)|null|
|**2023-11-15**|**Planetary nebulae as tracers of stellar population properties: unlocking their potential with integral-field spectroscopy**|行星状星云（PNe）是漫射晕和团内光运动学的重要示踪剂，由于其强烈的发射线，恒星光谱是不可行的。然而，这并不是他们所能揭示的关于潜在恒星种群的全部。近年来，人们还发现，与富含金属的星系中心的PNe相比，贫金属星系晕中的PNe具有不同的性质（特定频率、光度函数）。对年龄和金属丰度在这些关系中的作用有更定量的了解，将使PNe成为有价值的恒星群体示踪剂。为了做到这一点，有必要在恒星光也可以详细分析的区域对PNe进行全面表征。在这项工作中，我们利用了覆盖星系中心区域的积分场光谱数据，这使我们能够测量恒星年龄和金属性，并检测PNe。这一分析对于校准PNe作为恒星种群示踪剂以及推动我们理解前所未有的星系中心距离下的星系性质至关重要。 et.al.|[2311.09176](http://arxiv.org/abs/2311.09176)|null|
|**2023-11-15**|**KPZ equation limit of random walks in random environments**|我们证明了在一定的中偏差标度下，乘性噪声随机热方程（SHE）是由一维随机游动的猝灭密度的波动引起的，其跃迁概率为iid[0,1]值随机变量。与中间无序状态下的定向聚合物的情况相反，在时空的扩散重标度下，我们的权重的方差是固定的，而不是消失的。因此，对于该模型，采用混沌展开的天真极限是失败的，并且在该极限中观察到非平凡的噪声系数。我们的证明没有使用混沌技术，而是使用了这样一个事实，即在这种情况下，淬火密度解决了类似SHE的离散SPDE。作为我们技术的副产品，它表明独立噪声是在极限内产生的。 et.al.|[2311.09151](http://arxiv.org/abs/2311.09151)|null|
|**2023-11-15**|**Degenerate Mean Field Type Control with Linear and Unbounded Diffusion, and their Associated Equations**|当扩散系数取决于状态及其测度和控制时，我们研究了对应于退化平均场型控制问题的前向-后向随机微分方程组的适定性。退化平均场型控制问题在文献中很少研究。我们的方法基于提升方法，该方法将Wasserstein空间中的控制问题和相关的FBSDE嵌入到某些Hilbert空间中。我们用延拓方法建立了FBSDE的可解性和该FBSDE G ateaux导数的可解。然后，我们探索了值函数在时间和测度自变量中的正则性，我们还证明了它是相关Bellman方程的唯一经典解。我们还研究了值函数的线性泛函导数的高正则性，从而得到了平均场型主方程的经典解。 et.al.|[2311.09138](http://arxiv.org/abs/2311.09138)|null|
|**2023-11-15**|**Fast Detection of Phase Transitions with Multi-Task Learning-by-Confusion**|机器学习已经成功地用于研究阶段转换。在没有基础阶段先验知识的情况下，从数据中识别关键点的最流行方法之一是通过混淆学习方案。作为输入，它需要从参数网格中提取系统样本，该参数的变化与潜在的相变有关。到目前为止，该方案需要为网格的每一次可能的两侧划分训练一个不同的二进制分类器，从而导致计算成本随着网格点的数量线性增加。在这项工作中，我们提出并展示了一种只需要训练单个多类分类器的替代实现。理想情况下，这种多任务学习消除了相对于网格点数量的缩放。在Ising模型和用稳定扩散生成的图像数据集的应用中，我们发现显著的加速与理想情况非常吻合，只有很小的偏差。 et.al.|[2311.09128](http://arxiv.org/abs/2311.09128)|null|
|**2023-11-15**|**Contrastive Transformer Learning with Proximity Data Generation for Text-Based Person Search**|给定描述性文本查询，基于文本的人物搜索（TBPS）旨在从图像库中检索最匹配的目标人物。由于显著的模态差距、细粒度差异和注释数据的不足，这样的跨模态检索任务相当具有挑战性。为了更好地协调这两种模式，大多数现有工作都侧重于引入复杂且难以实施的复杂网络结构和辅助任务。在本文中，我们提出了一个简单而有效的双Transformer模型，用于基于文本的人物搜索。通过利用硬度感知的对比学习策略，我们的模型在没有任何局部特征对齐或边信息的特殊设计的情况下实现了最先进的性能。此外，我们提出了一个邻近数据生成（PDG）模块，以自动生成更多样化的数据，用于跨模态训练。PDG模块首先引入了一种基于文本到图像扩散模型的自动生成算法，该算法在原始样本的邻近空间中生成新的文本-图像对样本。然后在训练过程中结合近似文本生成和特征级混合，进一步增强数据的多样性。PDG模块可以在很大程度上保证直接用于训练的生成样本的合理性，而无需任何人为的噪声抑制检查。它显著提高了我们模型的性能，为这种细粒度的视觉语言任务所面临的数据不足问题提供了一个可行的解决方案。在TBPS任务的两个流行数据集（即CUHK-PEDES和ICFG-PEDES）上进行的大量实验表明，所提出的方法明显优于现有方法，例如，在CUHK-PED的Top1、Top5和Top10方面分别提高了3.88%、4.02%和2.92%。代码将在https://github.com/HCPLab-SYSU/PersonSearch-CTLG et.al.|[2311.09084](http://arxiv.org/abs/2311.09084)|**[link](https://github.com/hcplab-sysu/personsearch-ctlg)**|
|**2023-11-15**|**A Spectral Diffusion Prior for Hyperspectral Image Super-Resolution**|基于融合的高光谱图像（HSI）超分辨率旨在通过融合低空间分辨率的HSI和高空间分辨率的多光谱图像来产生高空间分辨率HSI。这样的HSI超分辨率过程可以被建模为反问题，其中先验知识对于获得期望的解是必不可少的。受扩散模型成功的启发，我们提出了一种新的基于融合的HSI超分辨率光谱扩散先验。具体来说，我们首先研究了光谱生成问题，并设计了一个光谱扩散模型来对光谱数据分布进行建模。然后，在最大后验的框架下，我们在反向生成过程中保留每两个相邻状态之间的转换信息，从而将训练的谱扩散模型的知识以正则化项的形式嵌入到融合问题中。最后，我们将最终优化问题的每一个生成步骤都视为其子问题，并使用Adam逆序求解这些子问题。在合成数据集和真实数据集上进行的实验结果证明了所提出方法的有效性。拟议方法的代码将在https://github.com/liuofficial/SDP. et.al.|[2311.08955](http://arxiv.org/abs/2311.08955)|null|
|**2023-11-15**|**Observing planetesimal formation under streaming instability in the rings of HD 163296**|我们介绍了一种新的技术来确定明亮圆盘环中的气体湍流和表面密度，假设尘埃的生长受到环中心湍流碎片的限制。我们在HD 163296中对这一处方进行了基准测试，表明我们的测量结果与可用的湍流上限一致，并与气体表面密度的独立估计值在2倍以内一致。我们将我们的结果与尘埃表面密度和粒度的文献测量相结合，以确定67 au和100 au环中的尘埃与气体的比率和斯托克斯数。我们的估计表明，粒子聚集是在100 au环中流动不稳定性（SI）的影响下发生的。尽管在存在外部各向同性湍流的情况下，这一过程可能会受到阻碍，但我们提供的证据表明，湍流在两个环中都是非各向同性的，并且可能源于在SI下可以缓解颗粒聚集的机制（如双极扩散）。最后，在圆盘处于稳定状态并且湍流调节角动量输运的假设下，我们确定了质量吸积率。我们的结果与光谱测量结果相矛盾，并表明其他机制可能是吸积的原因，这与该系统中磁离心风的检测在质量上一致。将我们的方法应用于更大的样本可以用于统计评估SI是否是形成亮环星子的可行机制。 et.al.|[2311.08950](http://arxiv.org/abs/2311.08950)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-11-15**|**Data Augmentations in Deep Weight Spaces**|在权重空间中学习，神经网络处理其他深度神经网络的权重，已成为一个很有前途的研究方向，在各个领域都有应用，从分析和编辑神经领域和隐式神经表示，到网络修剪和量化。最近的工作设计了在该空间中进行有效学习的架构，考虑到了其独特的置换等变结构。不幸的是，到目前为止，这些架构存在严重的过拟合问题，并被证明受益于大型数据集。这带来了重大挑战，因为为这种学习设置生成数据既费力又耗时，因为每个数据样本都是必须训练的一整套网络权重。在本文中，我们通过研究权重空间的数据增强来解决这一困难，这是一组能够在不需要训练额外输入权重空间元素的情况下实时生成新数据示例的技术。我们首先回顾了最近提出的几个数据增强方案%，并将其分为几类。然后，我们介绍了一种新的基于Mixup方法的增强方案。我们评估了这些技术在现有基准以及我们生成的新基准上的性能，这对未来的研究很有价值。 et.al.|[2311.08851](http://arxiv.org/abs/2311.08851)|null|
|**2023-11-14**|**Instant3D: Instant Text-to-3D Generation**|文本到三维生成，旨在通过文本提示合成生动的三维对象，引起了计算机视觉界的广泛关注。虽然已有的几项工作在这项任务上取得了令人印象深刻的成果，但它们主要依赖于耗时的优化范式。具体来说，这些方法为每个文本提示从头开始优化神经场，生成一个对象大约需要一个小时或更长时间。这种繁重和重复的培训成本阻碍了他们的实际部署。在本文中，我们提出了一种新的快速文本到三维生成框架，称为Instant3D。一旦经过训练，Instant3D就能够通过一次前馈网络运行，在不到一秒钟的时间内为看不见的文本提示创建一个3D对象。我们通过设计一个新的网络来实现这一惊人的速度，该网络直接从文本提示构建3D三平面。我们的Instant3D的核心创新在于探索将文本条件有效地注入网络的策略。此外，我们提出了一种简单而有效的激活函数，即缩放的sigmoid函数，以取代原始的sigmoid函数，它将训练收敛速度提高了十倍以上。最后，为了解决3D生成中的Janus（多头）问题，我们提出了一种自适应Perp-Neg算法，该算法可以在训练过程中根据Janus问题的严重程度动态调整其概念否定量表，有效地降低了多头效应。在各种基准数据集上进行的大量实验表明，所提出的算法在质量和数量上都优于最先进的方法，同时实现了显著更好的效率。项目页面位于https://ming1993li.github.io/Instant3DProj. et.al.|[2311.08403](http://arxiv.org/abs/2311.08403)|null|
|**2023-11-13**|**On the mathematical replication of the MacKay effect from redundant stimulation**|在这项研究中，我们研究了视觉感知与初级视觉皮层（V1）神经活动的数学建模之间的复杂联系，重点是复制麦凯效应[MacKay，Nature 1957]。虽然分叉理论一直是解决神经科学问题的一种突出的数学方法，特别是在描述V1中由于参数变化而自发形成的模式时，它在具有局部感觉输入的场景中面临挑战。例如，这一点在麦凯的心理物理学实验中很明显，在该实验中，视觉刺激信息的冗余导致了不规则的形状，使分叉理论和多尺度分析的效果较差。为了解决这个问题，我们遵循了一个基于Amari型神经场模型的输入输出可控性的数学观点。该框架将感觉输入视为一种控制功能，通过视觉刺激的视网膜-皮层图进行皮层表征，捕捉刺激的不同特征，特别是麦凯漏斗模式“麦凯射线”中的中心冗余。从控制理论的角度，讨论了Amari型方程对于线性和非线性响应函数的精确可控性。然后，应用于麦凯效应复制，我们调整了表示神经元内连接的参数，以确保在没有感觉输入的情况下，皮层活动指数稳定到静止状态，我们进行了定量和定性研究，以表明它捕捉到了麦凯报告的诱导后图像的所有基本特征 et.al.|[2311.07338](http://arxiv.org/abs/2311.07338)|null|
|**2023-11-10**|**Improved Positional Encoding for Implicit Neural Representation based Compact Data Representation**|采用位置编码来捕获隐式神经表示（INR）中编码信号的高频信息。在本文中，我们提出了一种新的位置编码方法，该方法提高了INR的重建质量。所提出的嵌入方法对于紧凑的数据表示更有利，因为它比现有方法具有更多的频率基。我们的实验表明，该方法在压缩任务中没有引入任何额外的复杂性，并且在新的视图合成中具有更高的重建质量，从而在率失真性能上获得了显著的增益。 et.al.|[2311.06059](http://arxiv.org/abs/2311.06059)|null|
|**2023-11-09**|**BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis**|从视频中合成逼真的4D人头头像对于VR/AR、远程呈现和视频游戏应用至关重要。尽管现有的基于神经辐射场（NeRF）的方法实现了高保真度的结果，但计算费用限制了它们在实时应用中的使用。为了克服这一限制，我们引入了BakedAvatar，这是一种用于实时神经头部化身合成的新表示，可部署在标准多边形光栅化管道中。我们的方法从学习的头部等值面中提取可变形的多层网格，并计算与表情、姿势和视图相关的外观，这些外观可以烘焙到静态纹理中，以实现高效的光栅化。因此，我们提出了一种用于神经头化身合成的三阶段流水线，包括学习连续变形、流形和辐射场，提取分层网格和纹理，以及使用差分光栅化微调纹理细节。实验结果表明，我们的表示生成的合成结果质量与其他最先进的方法相当，同时显著减少了所需的推理时间。我们进一步展示了单眼视频中的各种头部化身合成结果，包括视图合成、面部再现、表情编辑和姿势编辑，所有这些都是以交互式帧率进行的。 et.al.|[2311.05521](http://arxiv.org/abs/2311.05521)|null|
|**2023-11-08**|**Learning Robust Multi-Scale Representation for Neural Radiance Fields from Unposed Images**|我们介绍了一种改进的计算机视觉中基于神经图像的绘制问题的解决方案。给定一组在火车时刻从自由移动的相机拍摄的图像，所提出的方法可以在测试时刻从一个新颖的视角合成真实的场景图像。本文提出的关键思想是：（i）在神经新视图合成问题中，通过稳健的管道从未处理的日常图像中恢复准确的相机参数同样至关重要；（ii）以不同的分辨率对对象的内容进行建模更为实用，因为在日常的未渲染图像中，相机的剧烈运动极有可能发生。为了结合这些关键思想，我们利用了场景刚性、多尺度神经场景表示和单图像深度预测的基本原理。具体地说，所提出的方法使相机参数在基于神经场的建模框架中是可学习的。通过假设每个视图的深度预测是按比例进行的，我们限制了连续帧之间的相对姿态。根据相对姿态，通过多尺度神经场网络内的基于图神经网络的多运动平均来建模绝对相机姿态估计，从而产生单个损失函数。优化引入的损失函数提供了相机内在的、外在的以及从未聚焦的图像渲染的图像。我们通过例子证明，对于从日常获取的未聚焦多视图图像中精确建模多尺度神经场景表示的统一框架，在场景表示框架内进行精确的相机姿态估计同样重要。如果不考虑相机姿态估计管道中的鲁棒性措施，对多尺度混叠伪影进行建模可能会适得其反。我们在几个基准数据集上进行了大量实验，以证明我们的方法的适用性。 et.al.|[2311.04521](http://arxiv.org/abs/2311.04521)|null|
|**2023-11-06**|**Dynamic Neural Fields for Learning Atlases of 4D Fetal MRI Time-series**|我们提出了一种使用神经场快速构建生物医学图像图谱的方法。图谱是生物医学图像分析任务的关键，但传统的深度网络估计方法仍然耗时。在这项初步工作中，我们将特定主题的图谱构建框定为学习可变形时空观测的神经场。我们将我们的方法应用于学习子宫内胎儿动态BOLD MRI时间序列的受试者特异性图谱和运动稳定性。我们的方法产生了胎儿BOLD时间序列的高质量图谱，与现有工作相比，收敛速度更快。虽然我们的方法在解剖重叠方面稍逊于调整良好的基线，但它估计模板的速度要快得多，从而能够快速处理和稳定4D动态MRI采集的大型数据库。代码可在https://github.com/Kidrauh/neural-atlasing et.al.|[2311.02874](http://arxiv.org/abs/2311.02874)|**[link](https://github.com/kidrauh/neural-atlasing)**|
|**2023-11-04**|**LISNeRF Mapping: LiDAR-based Implicit Mapping via Semantic Neural Fields for Large-Scale 3D Scenes**|大规模语义映射对于户外自主代理完成规划和导航等高级任务至关重要。本文提出了一种通过单独的激光雷达测量的隐式表示进行大规模三维语义重建的新方法。我们首先利用基于八叉树的分层结构来存储隐式特征，然后通过浅层多层感知器（MLP）将这些隐式特征解码为语义信息和有符号距离值。我们采用现成的算法来预测点云的语义标签和实例ID。然后，我们使用点云几何的自监督范式和语义和全景标签的伪监督范式来联合优化隐含特征和MLP参数。随后，利用Marching Cubes算法对推理阶段的场景进行细分和可视化。对于内存受限的场景，还开发了一种地图拼接策略，将子地图合并为一个完整的地图。据我们所知，我们的方法是第一个从仅激光雷达的输入中重建语义隐含场景的工作。在SemanticKITTI、SemanticPOSS和nuScenes三个真实世界数据集上的实验证明了与当前最先进的3D映射方法相比，我们的框架的有效性和效率。 et.al.|[2311.02313](http://arxiv.org/abs/2311.02313)|null|
|**2023-11-03**|**EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision**|我们提出了EmerNeRF，这是一种简单而强大的方法，用于学习动态驾驶场景的时空表示。EmerNeRF以神经领域为基础，通过自举同时捕捉场景几何、外观、运动和语义。EmerNeRF取决于两个核心组件：首先，它将场景分为静态场和动态场。这种分解纯粹来自于自我监督，使我们的模型能够从一般的野外数据源中学习。其次，EmerNeRF将动态场中的感应流场参数化，并使用该流场进一步聚合多帧特征，从而提高动态对象的渲染精度。耦合这三个字段（静态、动态和流）使EmerNeRF能够自我充分地表示高度动态的场景，而不依赖于用于动态对象分割或光流估计的地面实况对象注释或预先训练的模型。我们的方法在传感器模拟中实现了最先进的性能，在重建静态（+2.93 PSNR）和动态（+3.70 PSNR）场景时显著优于以前的方法。此外，为了支持EmerNeRF的语义泛化，我们将2D视觉基础模型特征提升到4D时空中，并解决现代变形金刚中的普遍位置偏差，显著提高了3D感知性能（例如，占用预测准确率平均相对提高37.50%）。最后，我们构建了一个多样化且具有挑战性的120序列数据集，以在极端和高度动态的环境下对神经场进行基准测试。 et.al.|[2311.02077](http://arxiv.org/abs/2311.02077)|null|
|**2023-11-01**|**Neural Field Dynamics Model for Granular Object Piles Manipulation**|我们提出了一个基于学习的颗粒材料操纵动力学模型。受流体动力学中常用的欧拉方法的启发，我们的方法采用了一个全卷积神经网络，该网络对基于密度场的物体堆和推进器表示进行操作，使其能够通过卷积操作利用物体间相互作用的空间局部性以及平移等变性。此外，我们的可微动作渲染模块使模型完全可微，并可以直接与基于梯度的轨迹优化算法集成。我们在模拟和真实世界的实验中用大量的桩操作任务评估了我们的模型，并证明它在精度和计算效率方面显著超过了现有的潜在或基于粒子的方法，并在各种环境和任务中表现出零样本泛化能力。 et.al.|[2311.00802](http://arxiv.org/abs/2311.00802)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

