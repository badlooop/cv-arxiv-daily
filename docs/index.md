---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.11.28
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-11-27**|**AerialBooth: Mutual Information Guidance for Text Controlled Aerial View Synthesis from a Single Image**|我们提出了一种新的方法，AerialBooth，用于使用文本描述从单个输入图像合成鸟瞰图。我们利用预训练的文本到2D图像的稳定扩散模型作为3D世界的先验知识。该模型分两步进行微调，分别针对重建输入图像及其逆透视映射的文本嵌入和UNet进行优化。反向透视映射在扩散模型的文本图像空间内产生方差，同时为鸟瞰图合成提供弱指导。在推断时，我们使用新的相互信息引导将生成的图像的内容引向输入图像，该相互信息引导使两个图像的概率分布之间的信息内容最大化。我们在广泛的真实和合成数据上评估了我们的方法，包括自然场景、室内场景、人类行为等。通过广泛的实验和消融研究，我们证明了AerialBooth的有效性，以及它对其他文本控制视图的可推广性。我们还表明，AerialBooth通过对分析输入图像的视点和保真度的7个指标进行定量评估，实现了最佳的视点保真度权衡。代码和数据可在https://github.com/divyakraman/AerialBooth2023. et.al.|[2311.15478](http://arxiv.org/abs/2311.15478)|null|
|**2023-11-26**|**Obj-NeRF: Extract Object NeRFs from Multi-view Images**|神经辐射场（NeRF）在3D环境中的新型视图合成中表现出显著的有效性。然而，由于遮挡和背景复杂性，从多视图图像中提取一个特定对象的辐射场遇到了实质性的挑战，从而在NeRF编辑和3D网格提取等下游应用中存在困难。为了解决这个问题，在本文中，我们提出了Obj-NeRF，这是一个综合的管道，可以使用单个提示从多视图图像中恢复特定对象的3D几何结构。该方法将Segment Anything Model（SAM）的2D分割能力与NeRF的3D重建能力相结合。具体来说，我们首先使用带有单个提示的SAM获得指示对象的多视图分割。然后，我们使用分割图像来监督NeRF的构建，集成了几种有效的技术。此外，我们构建了一个包含不同对象的大型对象级NeRF数据集，这在各种下游任务中都很有用。为了证明我们方法的实用性，我们还将Obj-NeRF应用于各种应用，包括对象移除、旋转、替换和重新着色。 et.al.|[2311.15291](http://arxiv.org/abs/2311.15291)|null|
|**2023-11-26**|**NeuRAD: Neural Rendering for Autonomous Driving**|神经辐射场（NeRF）在自动驾驶（AD）社区中越来越受欢迎。最近的方法显示了NeRF在闭环模拟、AD系统测试以及作为一种高级训练数据增强技术方面的潜力。然而，现有的方法往往需要较长的训练时间、密集的语义监督，或者缺乏可推广性。这反过来又阻碍了NeRF在AD中的大规模应用。在本文中，我们提出了NeuRAD，这是一种针对动态AD数据的稳健的新视图合成方法。我们的方法具有简单的网络设计、相机和激光雷达的广泛传感器建模（包括滚动快门、光束发散和光线下降），并且适用于开箱即用的多个数据集。我们在五个流行的AD数据集上验证了它的性能，全面实现了最先进的性能。为了鼓励进一步的开发，我们公开发布了NeuRAD源代码。看见https://github.com/georghess/NeuRAD。 et.al.|[2311.15260](http://arxiv.org/abs/2311.15260)|null|
|**2023-11-26**|**HumanRecon: Neural Reconstruction of Dynamic Human Using Geometric Cues and Physical Priors**|最近的动态人体重建方法已经获得了有希望的重建结果。这些方法中的大多数仅依赖于RGB颜色监督，而不考虑明确的几何约束。这导致现有的人类重建技术更容易过拟合颜色，并导致几何上固有的模糊性，尤其是在稀疏多视图设置中。受单目几何预测领域最新进展的启发，我们在学习用于动态人体重建的神经隐式表示时考虑了估计深度和法线的几何约束。作为一种几何正则化，这提供了可靠但明确的监督信息，并提高了重建质量。我们还利用了一些有益的物理先验，例如在视线方向上添加噪声和最大化人体表面的密度。这些先验确保了沿射线渲染的颜色对视图方向是鲁棒的，并减少了沿射线估计的密度的固有模糊性。实验结果表明，由特定于人类的单目估计器预测的深度和正常线索可以提供有效的监督信号，并呈现更准确的图像。最后，我们还表明，所提出的物理先验显著减少了过拟合，并提高了新视图合成的整体质量。我们的代码位于：~\href{https://github.com/PRIS-CV/HumanRecon}{https://github.com/PRIS-CV/HumanRecon}。 et.al.|[2311.15171](http://arxiv.org/abs/2311.15171)|null|
|**2023-11-25**|**Coordinate-Aware Modulation for Neural Fields**|将低维输入坐标映射到相应信号的神经场在表示各种信号方面显示出了有希望的结果。已经提出了许多方法，并且使用MLP和网格表示的技术已经取得了实质性的成功。MLP允许紧凑和高表达性，但经常受到光谱偏差和缓慢收敛速度的影响。另一方面，使用网格的方法没有光谱偏差，并且以高空间复杂性为代价实现了快速的训练速度。在这项工作中，我们提出了一种在神经领域中利用MLP和网格表示的新方法。与顺序组合它们（首先从网格中提取特征并将其提供给MLP）的流行方法不同，我们将无光谱偏差的网格表示注入MLP中的中间特征。更具体地说，我们提出了一种坐标感知调制（CAM），它使用从网格表示中提取的比例和偏移参数来调制中间特征。这可以保持MLP的优势，同时减轻任何剩余的潜在偏见，促进高频成分的快速学习。此外，我们根据经验发现，在神经领域文献中尚未成功的特征归一化，在与所提出的CAM结合应用时被证明是有效的。实验结果表明，CAM增强了神经表示的性能，并提高了一系列信号的学习稳定性。特别是在新颖的视图合成任务中，我们在动态场景中以最少的参数和快速的训练速度获得了最先进的性能，在1MB内存下在静态场景中获得了最佳性能。CAM的性能也大大优于使用神经场的最佳视频压缩方法。 et.al.|[2311.14993](http://arxiv.org/abs/2311.14993)|null|
|**2023-11-22**|**WildFusion: Learning 3D-Aware Latent Diffusion Models in View Space**|现代基于学习的3D感知图像合成方法实现了生成图像的高真实感和3D一致的视点变化。现有方法表示共享规范空间中的实例。然而，对于野生数据集，共享规范系统可能很难定义，甚至可能不存在。在这项工作中，我们转而在视图空间中对实例进行建模，从而减少了对摆拍图像和学习相机分布的需求。我们发现，在这种情况下，现有的基于GAN的方法容易生成平面几何体，并且难以实现分布覆盖。因此，我们提出了WildFusion，这是一种基于潜在扩散模型（LDMs）的3D感知图像合成的新方法。我们首先训练一个自动编码器，该编码器推断出压缩的潜在表示，该编码器还捕获了图像的底层3D结构，不仅能够进行重建，还能够进行新颖的视图合成。为了学习忠实的3D表示，我们利用单目深度预测的线索。然后，我们在3D感知的潜在空间中训练扩散模型，从而能够合成高质量的3D一致图像样本，优于最近最先进的基于GAN的方法。重要的是，我们的3D感知LDM在没有来自多视点图像或3D几何结构的任何直接监督的情况下进行训练，并且不需要姿势图像或学习姿势或相机分布。它直接学习三维表示，而不依赖于规范的相机坐标。这为可扩展的3D感知图像合成和从野生图像数据创建3D内容开辟了有前景的研究途径。看见https://katjaschwarz.github.io/wildfusion我们的3D结果的视频。 et.al.|[2311.13570](http://arxiv.org/abs/2311.13570)|null|
|**2023-11-21**|**An Efficient 3D Gaussian Representation for Monocular/Multi-view Dynamic Scenes**|在从多个输入视图合成场景的新视图中，3D高斯散射是现有辐射场方法的可行替代方案，提供了良好的视觉质量和实时渲染。尽管在静态场景中取得了成功，但由于每个时间步长存储3D高斯参数的责任，3D高斯表示的当前进展在动态场景中在内存消耗和每个时间步长需要大量观测方面面临挑战。在这项研究中，我们提出了一种为动态场景量身定制的高效3D高斯表示，其中我们将位置和旋转定义为时间的函数，同时保持静态3D高斯的其他时不变特性不变。值得注意的是，我们的表示减少了内存使用，无论输入序列长度如何，内存使用都是一致的。此外，它通过考虑时间变化来降低过度拟合观测帧的风险。基于图像和流重建的高斯表示的优化为单目和多视图情况下的动态场景视图合成提供了强大的框架。我们在单个GPU的分辨率为 $1352\times 1014$的情况下获得了每秒$118$ 帧（FPS）的最高渲染速度，显示了我们提出的方法在动态场景渲染场景中的实用性和有效性。 et.al.|[2311.12897](http://arxiv.org/abs/2311.12897)|null|
|**2023-11-21**|**Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields**|神经辐射场（NeRF）的最新进展已经实现了用于新型视图合成的高保真场景重建。然而，NeRF需要每个像素数百次网络评估来近似体积渲染积分，这使得它的训练速度很慢。将NeRF缓存到显式数据结构中可以有效地提高渲染速度，但代价是更高的内存使用率。为了解决这些问题，我们提出了Hyb-NeRF，这是一种具有多分辨率混合编码的新型神经辐射场，可以实现高效的神经建模和快速渲染，还可以实现高质量的新视图合成。Hyb-NeRF的关键思想是使用从粗分辨率到精细分辨率的不同编码策略来表示场景。Hyb-NeRF利用了粗分辨率下的记忆效率可学习的位置特征，以及精细分辨率下基于哈希的特征网格的快速优化速度和局部细节。此外，为了进一步提高性能，我们在可学习的位置编码中嵌入了基于圆锥跟踪的特征，从而消除了编码的模糊性并减少了混叠伪影。在合成和真实世界数据集上进行的大量实验表明，与以前最先进的方法相比，Hyb-NeRF实现了更快的渲染速度、更好的渲染质量，甚至更低的内存占用。 et.al.|[2311.12490](http://arxiv.org/abs/2311.12490)|null|
|**2023-11-20**|**Holistic Inverse Rendering of Complex Facade via Aerial 3D Scanning**|在这项工作中，我们使用多视图航空图像，使用神经符号距离场（SDF）重建立面的几何结构、照明和材料。在不需要复杂设备的情况下，我们的方法只将无人机捕捉到的简单RGB图像作为输入，以实现基于物理和照片真实感的新颖视图渲染、重新照明和编辑。然而，现实世界中的立面通常具有复杂的外观，从具有细微细节的漫射岩石到具有镜面反射的大面积玻璃窗，这使得很难处理所有事情。因此，以前的方法可以保留几何细节，但无法重建光滑的玻璃窗或虎钳。为了应对这一挑战，我们引入了三种空间和语义自适应优化策略，包括基于零样本分割技术的语义正则化方法以提高材料一致性，频率软件几何正则化方法来平衡不同表面中的表面平滑度和细节，以及基于可见性探针的方案，以实现对大规模户外环境中的局部照明的有效建模。此外，我们还捕捉了真实世界的立面航空3D扫描图像集和相应的点云，用于训练和基准测试。实验证明，与最先进的基线相比，我们的方法在立面整体逆绘制、新颖的视图合成和场景编辑方面具有卓越的质量。 et.al.|[2311.11825](http://arxiv.org/abs/2311.11825)|null|
|**2023-11-18**|**Structure-Aware Sparse-View X-ray 3D Reconstruction**|X射线以其揭示物体内部结构的能力而闻名，有望为3D重建提供比可见光更丰富的信息。然而，现有的神经辐射场（NeRF）算法忽略了X射线的这一重要性质，导致它们在捕捉成像对象的结构内容方面存在局限性。在本文中，我们提出了一个用于稀疏视图X射线三维重建的框架，即结构感知X射线神经辐射密度场（SAX-NeRF）。首先，我们设计了一个基于线段的转换器（Lineformer）作为SAX NeRF的主干。Linefomer通过对X射线的每个线段内的相关性进行建模，捕捉三维空间中对象的内部结构。其次，我们提出了一种掩模局部全局（MLG）射线采样策略来提取二维投影中的上下文和几何信息。此外，我们还收集了一个更大规模的数据集X3D，涵盖了更广泛的X射线应用。在X3D上的实验表明，SAX-NeRF在新的视图合成和CT重建方面分别比以前的基于NeRF的方法高出12.56和2.49dB。代码、模型和数据将在https://github.com/caiyuanhao1998/SAX-NeRF et.al.|[2311.10959](http://arxiv.org/abs/2311.10959)|**[link](https://github.com/caiyuanhao1998/sax-nerf)**|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-11-27**|**Weakly-Supervised 3D Reconstruction of Clothed Humans via Normal Maps**|我们提出了一种新的基于深度学习的方法，通过2D法线图使用弱监督对穿着衣服的人进行3D重建。给定单个RGB图像或多视图图像，我们的网络推断出在静止姿势下身体周围的四面体网格上离散的有符号距离函数（SDF）。随后，使用推断的姿势和相机参数从SDF生成法线贴图。我们方法的一个关键方面是使用Marching四面体从四面体网格上的SDF（唯一）计算三角化表面，便于直接微分（从而反向传播）。因此，仅给定地面实况法线图（没有体积信息地面实况信息），我们可以训练网络从相应的RGB图像中产生SDF值。可选地，额外的多视角损失导致改善的结果。我们展示了我们的方法在网络推理和三维重建方面的有效性。 et.al.|[2311.16042](http://arxiv.org/abs/2311.16042)|null|
|**2023-11-27**|**SiTH: Single-view Textured Human Reconstruction with Image-Conditioned Diffusion**|3D人体重建的一个长期目标是从单个图像中创建逼真且完全详细的3D人体。主要挑战在于推断图像中不可见区域的未知人形、服装和纹理信息。为了解决这一问题，我们提出了SiTH，这是一种将图像条件扩散模型独特地集成到3D网格重建工作流程中的新型管道。我们方法的核心是将不适定的单视图重建问题分解为幻觉和重建子问题。对于前者，我们使用强大的生成扩散模型来从输入图像中产生幻觉。对于后者，我们利用蒙皮的身体网格作为指导，从输入和后视图图像中恢复全身纹理网格。我们的设计只需大约500次3D人体扫描就可以训练管道，同时保持其通用性和稳健性。对两个3D重建基准的广泛实验和用户研究证明了我们的方法在从各种看不见的图像中生成逼真、完全纹理的3D人类方面的有效性。 et.al.|[2311.15855](http://arxiv.org/abs/2311.15855)|null|
|**2023-11-27**|**Unexpected Field Evaporation Sequence in $γ$-TiAl**|在原子探针层析成像（APT）中，针状样品表面的原子在高电场下蒸发，并通过飞行时间质谱和位置灵敏检测进行分析。原子位置的3D重建遵循一个简单的投影定律，由于偏离假设的理想蒸发序列，有时会导致伪影。在这里，我们使用分子动力学赋予的全动力学模拟方法，重新审视了[001]取向的$\gamma$ -TiAl的蒸发行为。在不了解电荷状态或对蒸发场的假设的情况下，我们成功地再现了在实验数据的重建中观察到的缺乏明显的Al和Ti层的情况，这传统上归因于Al在蒸发表面上的保留。我们进一步表明，与Al的同时断键相反，Ti的逐步断键过程解释了强键Ti原子的看似违反直觉的优先蒸发。 et.al.|[2311.15472](http://arxiv.org/abs/2311.15472)|null|
|**2023-11-26**|**Obj-NeRF: Extract Object NeRFs from Multi-view Images**|神经辐射场（NeRF）在3D环境中的新型视图合成中表现出显著的有效性。然而，由于遮挡和背景复杂性，从多视图图像中提取一个特定对象的辐射场遇到了实质性的挑战，从而在NeRF编辑和3D网格提取等下游应用中存在困难。为了解决这个问题，在本文中，我们提出了Obj-NeRF，这是一个综合的管道，可以使用单个提示从多视图图像中恢复特定对象的3D几何结构。该方法将Segment Anything Model（SAM）的2D分割能力与NeRF的3D重建能力相结合。具体来说，我们首先使用带有单个提示的SAM获得指示对象的多视图分割。然后，我们使用分割图像来监督NeRF的构建，集成了几种有效的技术。此外，我们构建了一个包含不同对象的大型对象级NeRF数据集，这在各种下游任务中都很有用。为了证明我们方法的实用性，我们还将Obj-NeRF应用于各种应用，包括对象移除、旋转、替换和重新着色。 et.al.|[2311.15291](http://arxiv.org/abs/2311.15291)|null|
|**2023-11-25**|**Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets**|我们提出了稳定视频扩散-一种潜在的视频扩散模型，用于高分辨率、最先进的文本到视频和图像到视频生成。最近，通过在小的、高质量的视频数据集上插入时间层并对其进行微调，为2D图像合成训练的潜在扩散模型已经转变为生成视频模型。然而，文献中的训练方法差异很大，该领域尚未就管理视频数据的统一策略达成一致。在本文中，我们确定并评估了成功训练视频LDM的三个不同阶段：文本到图像预训练、视频预训练和高质量视频微调。此外，我们证明了精心策划的预训练数据集对于生成高质量视频的必要性，并提出了一个系统的策划过程来训练强大的基础模型，包括字幕和过滤策略。然后，我们探索微调我们的基础模型对高质量数据的影响，并训练一个与闭源视频生成有竞争力的文本到视频模型。我们还表明，我们的基本模型为下游任务提供了强大的运动表示，如图像到视频的生成和对相机运动特定LoRA模块的适应性。最后，我们证明了我们的模型提供了强大的多视图3D先验，并且可以作为微调多视图扩散模型的基础，该模型以前馈的方式联合生成对象的多个视图，以其计算预算的一小部分优于基于图像的方法。我们在发布代码和模型权重https://github.com/Stability-AI/generative-models。 et.al.|[2311.15127](http://arxiv.org/abs/2311.15127)|null|
|**2023-11-25**|**View it like a radiologist: Shifted windows for deep learning augmentation of CT images**|深度学习有可能通过自动化和执行重要任务来彻底改变医疗实践，如检测和描绘医学图像中癌症的大小和位置。然而，大多数深度学习模型依赖于将医学图像视为自然图像的增强技术。特别是对于对比增强计算机断层扫描（CT）图像，产生体素强度的信号具有物理意义，当将这些图像视为自然图像时，在预处理和增强过程中会丢失物理意义。为了解决这一问题，我们提出了一种新的预处理和强度增强方案，其灵感来自放射科医生在评估CT图像时如何利用多个观察窗口。我们提出的方法，窗口移动，在训练过程中随机将观察窗口放置在感兴趣的区域周围。这种方法提高了肝损伤分割性能，并提高了在使用不合时宜的造影剂的图像上的鲁棒性。我们的方法在多个数据集上优于经典的强度增强以及流行的nn UNet的强度增强流水线。 et.al.|[2311.14990](http://arxiv.org/abs/2311.14990)|null|
|**2023-11-25**|**Multi-task Planar Reconstruction with Feature Warping Guidance**|分段平面3D重建同时分割平面实例并从图像中恢复它们的3D平面参数，这对于室内或人造环境特别有用。结合语义预测的3D平面的有效重建为需要场景理解和并发空间映射的广泛应用提供了优势。然而，大多数现有的平面重建模型要么忽略了语义预测，要么运行效率不够高，无法用于实时应用。我们介绍了SoloPlanes，这是一种基于改进的实例分割架构的实时平面重建模型，它同时预测每个平面实例的语义，以及平面参数和逐块平面实例掩码。通过在特征空间中提供多视图指导，尽管由于多任务学习中特征共享的性质，我们只扭曲了平面特征，但我们在实例掩模分割中实现了改进。我们的模型在推理时使用单个图像同时预测语义，同时以43 FPS实现实时预测。该代码将在发布后发布。 et.al.|[2311.14981](http://arxiv.org/abs/2311.14981)|null|
|**2023-11-24**|**RSB-Pose: Robust Short-Baseline Binocular 3D Human Pose Estimation with Occlusion Handling**|在日常应用广泛的3D人体姿势估计领域，对方便的采集设备的需求不断增长。为了满足这一需求，我们将目光投向了短基线双目设置，该设置既提供了便携性，又具有从根本上缓解深度模糊的几何测量特性。然而，随着双目基线的缩短，出现了两个严重的挑战：首先，3D重建对2D误差的鲁棒性恶化；其次，由于两个视图之间有限的视觉差异，遮挡再次出现。为了解决第一个挑战，我们提出了立体协同关键点估计模块，以提高2D关键点的视图一致性并增强3D鲁棒性。在该模块中，视差被用来表示双眼2D点的对应关系，并且立体体积特征被引入以包含跨越不同视差的双眼特征。通过SVF的回归，以协作的方式同时估计两个视图2D关键点，这限制了它们的视图一致性。此外，为了处理遮挡，引入了一个预训练的姿势转换器模块。通过该模块，通过感知姿势连贯性（关节相关性的表示）来细化3D姿势。这种感知是由姿势变换器网络注入的，并通过恢复迭代掩蔽关节的预训练任务学习。在H36M和MHAD数据集上进行的综合实验，辅以可视化，验证了我们的方法在短基线双目3D人体姿势估计和遮挡处理中的有效性。 et.al.|[2311.14242](http://arxiv.org/abs/2311.14242)|null|
|**2023-11-23**|**GigaPose: Fast and Robust Novel Object Pose Estimation via One Correspondence**|我们提出了GigaPose，这是一种快速、稳健和准确的方法，用于基于CAD的RGB图像中的新对象姿态估计。GigaPose首先利用判别模板（CAD模型的渲染图像）来恢复平面外旋转，然后使用补丁对应关系来估计剩余的四个参数。我们的方法只在两个自由度空间中对模板进行采样，而不是通常的三个自由度，并在特征空间中使用快速近邻搜索将输入图像与模板匹配，与现有技术相比，速度提高了38x。此外，GigaPose对分割误差的鲁棒性明显更强。我们对BOP挑战的七个核心数据集的广泛评估表明，它达到了最先进的精度，并且可以与细化方法无缝集成。此外，我们还展示了GigaPose与3D模型的潜力，这些模型是最近从单个图像进行3D重建的工作所预测的，从而放松了对CAD模型的需求，并使6D姿态对象估计更加方便。我们的源代码和经过训练的模型可在https://github.com/nv-nguyen/gigaPose et.al.|[2311.14155](http://arxiv.org/abs/2311.14155)|**[link](https://github.com/nv-nguyen/gigapose)**|
|**2023-11-23**|**MonoNav: MAV Navigation via Monocular Depth Estimation and Reconstruction**|部署最小的微型飞行器（MAV）平台（<100 g）的一个主要挑战是它们无法携带提供高分辨率测量深度信息的传感器（例如，激光雷达或立体相机）。当前的系统依赖于端到端的学习或启发式方法，这些方法直接将图像映射到控制输入，并且难以在未知环境中快速飞行。在这项工作中，我们提出了以下问题：仅使用单眼相机、光学里程计和非车载计算，我们能否创建精确的地图，以利用更先进的大型机器人系统所采用的强大路径规划和导航方法，在未知环境中实现强大的自主性？我们介绍了MonoNav：一种用于MAV的快速3D重建和导航堆栈，它利用深度预测神经网络的最新进展，从一系列单眼图像和姿势中实现精确的3D场景重建。MonoNav使用现成的预训练单目深度估计和融合技术来构建地图，然后在运动基元上搜索，以规划到达目标的无碰撞轨迹。在广泛的硬件实验中，我们展示了MonoNav如何使Crazyflie（37 g MAV）在杂乱的室内环境中快速导航（0.5 m/s）。我们根据最先进的端到端方法对MonoNav进行了评估，发现导航中的碰撞率显著降低（降低了4倍）。这种安全性的提高是以保守主义为代价的，目标完成率降低了22%。 et.al.|[2311.14100](http://arxiv.org/abs/2311.14100)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-11-27**|**Test-time Adaptation of Discriminative Models via Diffusion Generative Feedback**|生成建模的进步，特别是扩散模型的出现，引发了一个根本问题：如何有效地将这些模型用于判别任务？在这项工作中，我们发现生成模型可以成为判别模型的很好的测试时间适配器。我们的方法Diffusion TTA使用来自扩散模型的生成反馈，将预先训练的判别模型（如图像分类器、分割器和深度预测器）适配到测试集中的每个未标记示例。我们通过使用判别模型的输出来调节扩散模型的条件来实现这一点。然后，我们通过将梯度反向传播到判别模型的参数来最大化图像似然目标。我们发现Diffusion TTA显著提高了各种大规模预训练判别模型的准确性，如ImageNet分类器、CLIP模型、图像像素标注器和图像深度预测器。扩散TTA优于现有的测试时间自适应方法，包括TTT-MAE和TENT，尤其在在线自适应设置中大放异彩，其中判别模型不断适应测试集中的每个例子。我们在我们的网站上提供对代码、结果和可视化的访问：https://diffusion-tta.github.io/. et.al.|[2311.16102](http://arxiv.org/abs/2311.16102)|null|
|**2023-11-27**|**CG-HOI: Contact-Guided 3D Human-Object Interaction Generation**|我们提出了CG-HOI，这是第一种从文本中生成动态三维人机交互（HOI）的方法。我们以一种相互依存的方式对人和物体的运动进行建模，因为语义丰富的人的运动很少在没有任何交互的情况下孤立发生。我们的关键见解是，在训练和推理过程中，明确建模人体表面和物体几何形状之间的接触可以用作强大的代理指导。使用该指南来桥接人和物体的运动，可以生成更真实、物理上更合理的交互序列，其中人体和相应的物体以连贯的方式移动。我们的方法首先学习在联合扩散过程中对人类运动、物体运动和接触进行建模，通过交叉注意力相互关联。然后，我们利用这种习得的接触，在推理合成现实、连贯的HOI时提供指导。广泛的评估表明，我们基于联合接触的人机交互方法产生了现实和物理上合理的序列，我们展示了两个应用程序，突出了我们方法的能力。在给定物体轨迹的条件下，我们可以在不进行重新训练的情况下生成相应的人体运动，展示了强大的人-物体相关性学习。我们的方法也很灵活，可以应用于静态的真实世界3D场景扫描。 et.al.|[2311.16097](http://arxiv.org/abs/2311.16097)|null|
|**2023-11-27**|**KPZ-type equation from growth driven by a non-Markovian diffusion**|我们研究了一个描述增长子流形 $\mathbb｛M｝（t）\substeq\mathbb{R｝^｛\mathrm｛d｝+1｝$的随机几何流。它是一个SPDE，来自于起源激发随机行走或一度增强随机行走的连续版本。它是通过在反射布朗运动的边界轨迹附近同时对$\\mathbb{M}（t）$的边界进行平滑和膨胀而给出的。我们证明了关联高度函数的大尺度波动是由$\mathbb｛R｝^｛\mathrm｛d｝+1｝$中流形上的正则化Kardar Parisi Zhang（KPZ）型方程给出的，该方程由Dirichlet到Neumann算子调制。这显示在任何维度$\mathrm｛d｝\geq1$中。我们还证明了在维数$\mathrm{d}+1=2$中，该KPZ型SPDE中的正则化可以在重整化后被去除。因此，在维数$\mathrm｛d｝+1=2$ 中，几何流的波动具有奇异KPZ型方程给出的双重标度极限。据我们所知，这是随机拉普拉斯增长模型中KPZ型行为的第一个例子，在Parisi Zhang’84和Ramirez Sidoravicius’04中被问及（对于一些不同的模型）。 et.al.|[2311.16095](http://arxiv.org/abs/2311.16095)|null|
|**2023-11-27**|**Street TryOn: Learning In-the-Wild Virtual Try-On from Unpaired Person Images**|虚拟试穿已经成为一个热门的研究课题，但大多数现有的方法都集中在背景干净的工作室图像上。他们可以通过学习从配对的训练数据中扭曲服装图像以适合一个人的身体，即服装图像与穿着同一件衣服的人的图像配对，从而在这个工作室的试穿场景中获得合理的结果。这些数据通常是从商业网站上收集的，在这些网站上，每件衣服都会自己和几个模型进行演示。相比之下，在野外场景中很难收集成对的数据，因此，在杂乱的背景下对人们的随意图像进行虚拟试穿的研究很少。在这项工作中，我们通过（1）引入Street TryOn基准来评估街头场景的性能，以及（2）提出一种新的方法，可以在没有配对数据的情况下直接从一组野外人物图像中学习，从而填补了当前虚拟试穿研究的空白。我们的方法可以使用一种新的DensePose翘曲校正方法，结合由姿势和语义分割控制的基于扩散的修复，在商店和街道领域实现稳健的性能。我们的实验证明了标准工作室试穿任务的竞争性能，以及街头试穿和跨域试穿任务的SOTA性能。 et.al.|[2311.16094](http://arxiv.org/abs/2311.16094)|null|
|**2023-11-27**|**Self-correcting LLM-controlled Diffusion Models**|随着扩散模型的出现，文本到图像的生成已经取得了重大进展。尽管能够生成逼真的图像，但当前的文本到图像扩散模型仍然难以准确解释和遵循复杂的输入文本提示。与现有的仅尽最大努力生成图像的模型不同，我们引入了自校正LLM控制扩散（SLD）。SLD是一个框架，它根据输入提示生成图像，评估其与提示的一致性，并对生成的图像中的不精确性进行自我校正。在LLM控制器的指导下，SLD将文本到图像的生成转化为迭代闭环过程，确保生成图像的正确性。SLD不仅无需训练，还可以与API访问背后的扩散模型无缝集成，如DALL-E3，以进一步提高最先进的扩散模型的性能。实验结果表明，我们的方法可以纠正大多数错误的生成，特别是在生成算术、属性绑定和空间关系方面。此外，通过简单地调整LLM的指令，SLD可以执行图像编辑任务，弥合文本到图像生成和图像编辑管道之间的差距。我们将为未来的研究和应用提供我们的代码。 et.al.|[2311.16090](http://arxiv.org/abs/2311.16090)|null|
|**2023-11-27**|**DiffSLVA: Harnessing Diffusion Models for Sign Language Video Anonymization**|由于美国手语（ASL）没有标准的书面形式，聋人签名者经常分享视频，以便用他们的母语进行交流。然而，由于手和脸都在手语中传达关键的语言信息，手语视频无法保护签名者的隐私。尽管签名者对手语视频匿名化的各种应用表示了兴趣，这种技术可以有效地保存语言内容，但考虑到手势和面部表情的复杂性，开发这种技术的尝试收效甚微。现有的方法主要依赖于视频片段中签名者的精确姿势估计，并且通常需要手语视频数据集进行训练。这些要求使他们无法“在野外”处理视频，部分原因是当前手语视频数据集的多样性有限。为了解决这些限制，我们的研究引入了DiffSLVA，这是一种利用预先训练的大规模扩散模型进行零样本文本引导手语视频匿名化的新方法。我们结合了ControlNet，它利用了低级别的图像特征，如HED（整体嵌套边缘检测）边缘，以避免姿态估计的需要。此外，我们还开发了一个专门用于捕捉面部表情的模块，这对于用手语传递重要的语言信息至关重要。然后，我们将上述方法相结合，以实现匿名化，从而更好地保留原始签名者的基本语言内容。这种创新的方法首次使手语视频匿名化成为可能，可用于现实世界的应用，这将为聋人和重听人社区带来重大好处。我们通过一系列签名者匿名化实验证明了我们方法的有效性。 et.al.|[2311.16060](http://arxiv.org/abs/2311.16060)|null|
|**2023-11-27**|**Exploring Attribute Variations in Style-based GANs using Diffusion Models**|现有的属性编辑方法将语义属性视为二进制属性，从而对每个属性进行单个编辑。然而，眼镜、微笑或发型等特征表现出广泛的多样性。在这项工作中，我们通过建模属性编辑的多维性质来制定\textit｛多样属性编辑｝的任务。这使得用户能够为每个属性生成多个看似合理的编辑。我们利用预训练的GANs的解纠缠潜在空间，并训练去噪扩散概率模型（DDPM）来学习不同编辑的潜在分布。具体来说，我们在通过嵌入具有单个属性变化的图像对而获得的编辑潜在方向的数据集上训练DDPM。这导致了潜在的子空间，可以进行不同的属性编辑。在高度压缩的潜在空间中应用扩散使我们能够在有限的计算资源内对编辑的丰富分布进行建模。通过在一系列数据集上进行的大量定性和定量实验，我们证明了我们的方法对不同属性编辑的有效性。我们还展示了我们的方法应用于各种面部属性的3D编辑的结果。 et.al.|[2311.16052](http://arxiv.org/abs/2311.16052)|null|
|**2023-11-27**|**GaussianEditor: Editing 3D Gaussians Delicately with Text Instructions**|最近，在使用基于2D扩散模型的文本指令的3D场景编辑中已经取得了令人印象深刻的结果。然而，当前的扩散模型主要通过预测潜在空间中的噪声来生成图像，并且编辑通常应用于整个图像，这使得对3D场景执行精细的、特别是局部的编辑具有挑战性。受最近3D高斯飞溅的启发，我们提出了一个名为GaussianEditor的系统框架，通过带有文本指令的3D Gaussians来精细地编辑3D场景。得益于三维高斯的显式特性，我们设计了一系列技术来实现精细的编辑。具体来说，我们首先提取与文本指令相对应的感兴趣区域（RoI），将其与3D高斯对齐。高斯RoI进一步用于控制编辑过程。与以前的方法相比，我们的框架可以实现更精细、更精确的3D场景编辑，同时享受更快的训练速度，即在单个V100 GPU上不到20分钟，是Instruction-NeRF2NeRF（45分钟-2小时）的两倍多。 et.al.|[2311.16037](http://arxiv.org/abs/2311.16037)|null|
|**2023-11-27**|**Closing the ODE-SDE gap in score-based diffusion models through the Fokker-Planck equation**|基于分数的扩散模型已成为深度生成建模最有前途的框架之一，因为它们在许多生成任务中的最先进性能，同时依赖于随机微分方程（SDE）和常微分方程（ODE）等数学基础。根据经验，已经报道了基于ODE的样本不如基于SDE的样本。在本文中，我们严格描述了在训练基于分数的扩散模型时出现的动力学和近似范围，包括真实的SDE动力学、神经近似、由此产生的各种近似粒子动力学，以及它们相关的福克-普朗克方程和这些福克-普朗克方程式的神经网络近似。我们系统地分析了基于分数的扩散模型的ODE和SDE动力学之间的差异，并将其与相关的福克-普朗克方程联系起来。我们根据Fokker-Planck残差导出了ODE-和SDE诱导分布之间的Wasserstein 2-距离的理论上界。我们还从数值上表明，传统的基于分数的扩散模型可以在ODE和SDE诱导的分布之间表现出显著的差异，我们使用显式比较来证明这一点。此外，我们在数值上表明，通过将福克-普朗克残差作为一个额外的正则化项来减少，可以缩小ODE和SDE诱导分布之间的差距。我们的实验表明，这种正则化可以改善ODE产生的分布，但这可能是以降低SDE样本质量为代价的。 et.al.|[2311.15996](http://arxiv.org/abs/2311.15996)|null|
|**2023-11-27**|**DiffAnt: Diffusion Models for Action Anticipation**|对未来行动的预期本质上是不确定的。给定一个观察到的包含正在进行的动作的视频片段，可能会出现多个后续动作。在预测遥远的未来时，这种不确定性会变得更大。然而，大多数现有的行动预期模型都坚持确定性方法，忽略了对未来不确定性的考虑。在这项工作中，我们从生成的角度重新思考行动预期，采用扩散模型来捕捉不同可能的未来行动。在这个框架中，未来的动作是从潜在空间中的标准高斯噪声迭代生成的，以观察到的视频为条件，然后转换到动作空间中。在早餐、50份沙拉、EpicKitchens和EGTEA Gaze+四个基准数据集上进行了广泛的实验，所提出的方法取得了优于或可比于最先进方法的结果，表明了生成方法对行动预期的有效性。我们的代码和经过训练的模型将在GitHub上发布。 et.al.|[2311.15991](http://arxiv.org/abs/2311.15991)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-11-27**|**MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers**|我们介绍了MeshGPT，这是一种生成三角形网格的新方法，它反映了艺术家创建的网格的典型紧凑性，而不是通过等曲面方法从神经场提取的密集三角形网格。受强大的大型语言模型最新进展的启发，我们采用了一种基于序列的方法来自回归生成三角形网格作为三角形序列。我们首先使用图卷积学习潜在量化嵌入的词汇表，该词汇表向这些嵌入提供局部网格几何和拓扑。解码器对这些嵌入进行排序并将其解码为三角形，确保它们能够有效地重建网格。然后在这个学习的词汇表上训练转换器，以在给定先前嵌入的情况下预测下一个嵌入的索引。一旦训练好，我们的模型就可以进行自回归采样以生成新的三角形网格，直接生成具有尖锐边缘的紧凑网格，更接近于模仿手工网格的高效三角测量模式。与最先进的网格生成方法相比，MeshGPT有了显著的改进，形状覆盖率提高了9%，各种类别的FID得分提高了30分。 et.al.|[2311.15475](http://arxiv.org/abs/2311.15475)|null|
|**2023-11-26**|**Distributed Delay and Desynchronization in a Brain Network Model**|我们考虑了一个神经场模型，该模型由任意数量的Wilson Cowan节点组成，具有抑制性耦合强度和时间延迟兴奋性耦合的稳态调节。我们扩展了以前对该模型的研究，将具有常用内核分布的分布式时延包括在内：delta函数、均匀分布和gamma分布。着眼于满足常行和条件的网络，我们展示了连通矩阵的每个特征值如何与Hopf分支相关，并且特征值决定了分支是导致同步还是去同步的振荡行为。我们考虑两个示例网络，一个具有所有实特征值（双向环），另一个具有一些复特征值（单向环）。在双向环中，Hopf曲线被组织起来，使得只有同步的Hopf才会导致渐近稳定的行为。因此，网络中的行为总是同步的。然而，在单向环网络中，异步和同步Hopf曲线的交点可能会出现双Hopf分岔点。因此，可以出现渐近稳定的同步和异步极限环，以及结合同步和异步行为的类环面解。增加网络的大小或平均时延会使这些交叉点以及相关的异步行为更有可能发生。数值方法用于证实这一发现，并使用Wolfram Mathematica绘制了Hopf分岔曲线。这些见解提供了对大型振荡器网络中去同步机制的更深入理解。 et.al.|[2311.15329](http://arxiv.org/abs/2311.15329)|null|
|**2023-11-25**|**Coordinate-Aware Modulation for Neural Fields**|将低维输入坐标映射到相应信号的神经场在表示各种信号方面显示出了有希望的结果。已经提出了许多方法，并且使用MLP和网格表示的技术已经取得了实质性的成功。MLP允许紧凑和高表达性，但经常受到光谱偏差和缓慢收敛速度的影响。另一方面，使用网格的方法没有光谱偏差，并且以高空间复杂性为代价实现了快速的训练速度。在这项工作中，我们提出了一种在神经领域中利用MLP和网格表示的新方法。与顺序组合它们（首先从网格中提取特征并将其提供给MLP）的流行方法不同，我们将无光谱偏差的网格表示注入MLP中的中间特征。更具体地说，我们提出了一种坐标感知调制（CAM），它使用从网格表示中提取的比例和偏移参数来调制中间特征。这可以保持MLP的优势，同时减轻任何剩余的潜在偏见，促进高频成分的快速学习。此外，我们根据经验发现，在神经领域文献中尚未成功的特征归一化，在与所提出的CAM结合应用时被证明是有效的。实验结果表明，CAM增强了神经表示的性能，并提高了一系列信号的学习稳定性。特别是在新颖的视图合成任务中，我们在动态场景中以最少的参数和快速的训练速度获得了最先进的性能，在1MB内存下在静态场景中获得了最佳性能。CAM的性能也大大优于使用神经场的最佳视频压缩方法。 et.al.|[2311.14993](http://arxiv.org/abs/2311.14993)|null|
|**2023-11-22**|**Compact 3D Gaussian Representation for Radiance Field**|神经辐射场（NeRF）在高保真度捕捉复杂三维场景方面显示出非凡的潜力。然而，阻碍NeRFs广泛采用的一个持续挑战是体积绘制造成的计算瓶颈。另一方面，3D高斯飞溅（3DGS）最近作为一种替代表示出现，它利用了基于3D高斯的表示，并采用光栅化流水线来渲染图像，而不是体积渲染，从而实现了非常快的渲染速度和良好的图像质量。然而，一个显著的缺点出现了，因为3DGS需要大量的3D高斯来保持渲染图像的高保真度，这需要大量的内存和存储。为了解决这一关键问题，我们特别强调两个关键目标：在不牺牲性能的情况下减少高斯点的数量，以及压缩高斯属性，如与视图相关的颜色和协方差。为此，我们提出了一种可学习的掩码策略，该策略在保持高性能的同时显著减少高斯数。此外，我们通过使用基于网格的神经场而不是依赖于球面谐波，提出了一种紧凑但有效的视图相关颜色表示。最后，我们学习了通过矢量量化来紧凑地表示高斯几何属性的码本。在我们广泛的实验中，我们一致表明，与3DGS相比，存储空间减少了10美元，渲染速度提高，同时保持了场景表示的质量。我们的工作为3D场景表示提供了一个全面的框架，实现了高性能、快速训练、紧凑性和实时渲染。我们的项目页面可在https://maincold2.github.io/c3dgs/. et.al.|[2311.13681](http://arxiv.org/abs/2311.13681)|null|
|**2023-11-21**|**3D Compression Using Neural Fields**|神经场（NFs）作为一种压缩各种数据模式的工具，如图像和视频，已经获得了发展势头。这项工作利用了以前的进展，并提出了一种新的基于NF的3D数据压缩算法。我们推导出了两个版本的方法——一个是基于有符号距离域（SDF）的水密形状，另一个是使用无符号距离场（UDF）的任意非水密形状。我们证明了我们的方法在三维点云和网格上的几何压缩方面表现出色。此外，我们表明，由于NF公式，可以直接扩展我们的压缩算法来压缩3D数据的几何结构和属性（例如颜色）。 et.al.|[2311.13009](http://arxiv.org/abs/2311.13009)|null|
|**2023-11-20**|**NePF: Neural Photon Field for Single-Stage Inverse Rendering**|我们提出了一种新的单级框架——神经光子场（NePF），以解决多视图图像的不适定逆绘制问题。与以前在多个阶段恢复几何、材料和照明并从不同神经场的各种多层感知器中提取特性的方法相反，我们质疑这种复杂性，并介绍了我们的方法-一个统一恢复所有特性的单阶段框架。NePF通过充分利用神经隐式曲面的权重函数背后的物理含义和与视图相关的辐射来实现这种统一。此外，我们还介绍了一种创新的基于坐标的照明模型，用于快速基于体积的物理渲染。为了正则化这种照明，我们实现了用于散射估计的次表面散射模型。我们在真实数据集和合成数据集上评估了我们的方法。结果证明了我们的方法在恢复高保真几何和视觉上合理的材料属性方面的优越性。 et.al.|[2311.11555](http://arxiv.org/abs/2311.11555)|null|
|**2023-11-15**|**RENI++ A Rotation-Equivariant, Scale-Invariant, Natural Illumination Prior**|反向渲染是一个不适定的问题。以前的工作试图通过关注对象或场景形状或外观的先验来解决这个问题。在这项工作中，我们转而关注自然照明的先验。目前的方法依赖于球面谐波照明或其他通用表示，充其量，依赖于参数的简单化先验。这导致在照明条件的表现力方面对反向设置的限制，尤其是在考虑镜面反射时。我们提出了一种基于变分自动解码器和变换器解码器的条件神经场表示。我们扩展了矢量神经元，将等方差直接构建到我们的架构中，并通过尺度不变损失函数利用深度估计的见解，实现了高动态范围（HDR）图像的精确表示。其结果是一个紧凑的、旋转等变的HDR神经照明模型，能够捕捉自然环境地图中复杂的高频特征。在一个由1.6K HDR自然场景环境图组成的精心策划的数据集上训练我们的模型，我们将其与传统表示进行比较，证明其适用于反向渲染任务，并显示部分观测的环境图完成情况。我们在https://github.com/JADGardner/ns_reni et.al.|[2311.09361](http://arxiv.org/abs/2311.09361)|**[link](https://github.com/jadgardner/ns_reni)**|
|**2023-11-15**|**Data Augmentations in Deep Weight Spaces**|在权重空间中学习，神经网络处理其他深度神经网络的权重，已成为一个很有前途的研究方向，在各个领域都有应用，从分析和编辑神经领域和隐式神经表示，到网络修剪和量化。最近的工作设计了在该空间中进行有效学习的架构，考虑到了其独特的置换等变结构。不幸的是，到目前为止，这些架构存在严重的过拟合问题，并被证明受益于大型数据集。这带来了重大挑战，因为为这种学习设置生成数据既费力又耗时，因为每个数据样本都是必须训练的一整套网络权重。在本文中，我们通过研究权重空间的数据增强来解决这一困难，这是一组能够在不需要训练额外输入权重空间元素的情况下实时生成新数据示例的技术。我们首先回顾了最近提出的几个数据增强方案%，并将其分为几类。然后，我们介绍了一种新的基于Mixup方法的增强方案。我们评估了这些技术在现有基准以及我们生成的新基准上的性能，这对未来的研究很有价值。 et.al.|[2311.08851](http://arxiv.org/abs/2311.08851)|null|
|**2023-11-14**|**Instant3D: Instant Text-to-3D Generation**|文本到三维生成，旨在通过文本提示合成生动的三维对象，引起了计算机视觉界的广泛关注。虽然已有的几项工作在这项任务上取得了令人印象深刻的成果，但它们主要依赖于耗时的优化范式。具体来说，这些方法为每个文本提示从头开始优化神经场，生成一个对象大约需要一个小时或更长时间。这种繁重和重复的培训成本阻碍了他们的实际部署。在本文中，我们提出了一种新的快速文本到三维生成框架，称为Instant3D。一旦经过训练，Instant3D就能够通过一次前馈网络运行，在不到一秒钟的时间内为看不见的文本提示创建一个3D对象。我们通过设计一个新的网络来实现这一惊人的速度，该网络直接从文本提示构建3D三平面。我们的Instant3D的核心创新在于探索将文本条件有效地注入网络的策略。此外，我们提出了一种简单而有效的激活函数，即缩放的sigmoid函数，以取代原始的sigmoid函数，它将训练收敛速度提高了十倍以上。最后，为了解决3D生成中的Janus（多头）问题，我们提出了一种自适应Perp-Neg算法，该算法可以在训练过程中根据Janus问题的严重程度动态调整其概念否定量表，有效地降低了多头效应。在各种基准数据集上进行的大量实验表明，所提出的算法在质量和数量上都优于最先进的方法，同时实现了显著更好的效率。项目页面位于https://ming1993li.github.io/Instant3DProj. et.al.|[2311.08403](http://arxiv.org/abs/2311.08403)|null|
|**2023-11-13**|**On the mathematical replication of the MacKay effect from redundant stimulation**|在这项研究中，我们研究了视觉感知与初级视觉皮层（V1）神经活动的数学建模之间的复杂联系，重点是复制麦凯效应[MacKay，Nature 1957]。虽然分叉理论一直是解决神经科学问题的一种突出的数学方法，特别是在描述V1中由于参数变化而自发形成的模式时，它在具有局部感觉输入的场景中面临挑战。例如，这一点在麦凯的心理物理学实验中很明显，在该实验中，视觉刺激信息的冗余导致了不规则的形状，使分叉理论和多尺度分析的效果较差。为了解决这个问题，我们遵循了一个基于Amari型神经场模型的输入输出可控性的数学观点。该框架将感觉输入视为一种控制功能，通过视觉刺激的视网膜-皮层图进行皮层表征，捕捉刺激的不同特征，特别是麦凯漏斗模式“麦凯射线”中的中心冗余。从控制理论的角度，讨论了Amari型方程对于线性和非线性响应函数的精确可控性。然后，应用于麦凯效应复制，我们调整了表示神经元内连接的参数，以确保在没有感觉输入的情况下，皮层活动指数稳定到静止状态，我们进行了定量和定性研究，以表明它捕捉到了麦凯报告的诱导后图像的所有基本特征 et.al.|[2311.07338](http://arxiv.org/abs/2311.07338)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

