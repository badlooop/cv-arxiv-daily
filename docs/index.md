---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.09.29
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-09-26**|**Neural Light Spheres for Implicit Image Stitching and View Synthesis**|全景拍摄具有挑战性，在手机屏幕上显示也具有挑战性。矛盾的是，全景仍然是现代移动相机应用程序的主要功能，但未得到充分利用。在这项工作中，我们用球形神经光场模型来解决这两个挑战，用于隐式全景图像拼接和重新渲染；能够适应深度视差、视图相关照明以及捕获过程中的局部场景运动和颜色变化。在测试期间，适应任意路径的全景视频捕获——垂直、水平、随机行走——这些神经光球共同估计相机路径和高分辨率场景重建，以产生环境的新型宽视场投影。我们的单层模型避免了昂贵的体积采样，并将场景分解为紧凑的视图相关光线偏移和颜色分量，每个场景的总模型大小为80 MB，并以1080p分辨率进行实时（50 FPS）渲染。我们展示了比传统图像拼接和辐射场方法更高的重建质量，对场景运动和非理想捕获设置的容忍度明显更高。 et.al.|[2409.17924](http://arxiv.org/abs/2409.17924)|null|
|**2024-09-24**|**GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization**|尽管存在各种视觉定位方法，如场景坐标和姿态回归，但这些方法往往难以满足高内存消耗或广泛的优化要求。为了应对这些挑战，我们利用新型视图合成的最新进展，特别是3D高斯散斑（3DGS），来增强定位。3DGS允许通过其空间特征对3D几何和场景外观进行紧凑编码。我们的方法利用了XFeat轻量级关键点检测和描述模型生成的密集描述图。我们建议将这些密集的关键点描述符提取到3DGS中，以提高模型的空间理解能力，从而通过2D-3D对应关系进行更准确的相机姿态预测。在估计初始姿态后，我们使用光度扭曲损失对其进行细化。对流行的室内和室外数据集进行基准测试表明，我们的方法超越了最先进的神经渲染姿势（NRP）方法，包括NeRFMatch和PNeRFLoc。 et.al.|[2409.16502](http://arxiv.org/abs/2409.16502)|**[link](https://github.com/haksorus/gsplatloc)**|
|**2024-09-24**|**Semantics-Controlled Gaussian Splatting for Outdoor Scene Reconstruction and Rendering in Virtual Reality**|高斯散点（GS）等3D渲染技术的进步允许在虚拟现实（VR）中进行新颖的视图合成和实时渲染。然而，GS创建的3D环境通常很难编辑。对于场景增强或合并3D资源，按类分割高斯分布是必不可少的。现有的分割方法通常仅限于某些类型的场景，例如“圆形”场景，以确定清晰的对象边界。然而，在非“循环”场景（如大型室外场景）中删除大型物体时，这种方法是无效的。我们提出了语义控制GS（SCGS），这是一种分段驱动的GS方法，能够在不受控制的自然环境中分离大型场景部分。SCGS允许对VR进行场景编辑和提取场景部分。此外，我们引入了一个具有挑战性的室外数据集，克服了“循环”设置。我们在数据集的视觉质量和3D-OVS数据集的分割质量方面都优于最先进的技术。我们进行了一项探索性用户研究，将360度视频、普通GS和VR中的SCGS与固定视点进行了比较。在我们随后的主要研究中，允许用户自由移动，评估普通GS和SCGS。我们的主要研究结果表明，参与者明显更喜欢SCGS而不是普通GS。我们总体上提出了一种创新的方法，在技术和用户体验方面都超越了最先进的水平。 et.al.|[2409.15959](http://arxiv.org/abs/2409.15959)|null|
|**2024-09-24**|**Disentangled Generation and Aggregation for Robust Radiance Fields**|近年来，基于三平面的辐射场的利用引起了人们的关注，因为它能够以高质量的表示和低计算成本有效地分离3D场景。该方法的一个关键要求是精确输入相机姿态。然而，由于三平面的局部更新特性，与之前的联合姿态NeRF优化类似的联合估计很容易导致局部最小值。为此，我们提出了解耦三平面生成模块，将全局特征上下文和平滑度引入三平面学习，从而减轻了局部更新引起的误差。然后，我们提出了解耦平面聚合来减轻相机姿态更新过程中常见的三平面特征聚合引起的纠缠。此外，我们引入了一种两阶段热启动训练策略，以减少由三平面生成器引起的隐式约束。定量和定性结果表明，我们提出的方法在具有噪声或未知相机姿态的新型视图合成中取得了最先进的性能，并实现了高效的优化收敛。项目页面：https://gaohchen.github.io/DiGARR/. et.al.|[2409.15715](http://arxiv.org/abs/2409.15715)|null|
|**2024-09-23**|**AgriNeRF: Neural Radiance Fields for Agriculture in Challenging Lighting Conditions**|神经辐射场（NeRF）在3D场景重建和新颖的视图合成方面显示出巨大的前景。在农业环境中，NeRF可以作为数字双胞胎，为农民提供有关水果检测的关键信息，用于产量估算和其他重要指标。然而，传统的NeRF对具有挑战性的照明条件（如低光、极亮的光和变化的照明）并不稳健。为了解决这些问题，这项工作利用了三种不同的传感器：RGB相机、事件相机和热像仪。我们的RGB场景重建显示，PSNR和SSIM分别提高了+2.06 dB和+8.3%。我们的交叉光谱场景重建使mAP50的下游水果检测提高了+43.0%，mAP50-95提高了+61.1%。额外传感器的集成带来了更强大和信息量更大的NeRF。我们证明，我们的多模态系统在各种树冠覆盖和一天中的不同时间产生了高质量的照片级逼真重建。这项工作的结果是开发了一种有弹性的NeRF，能够在明显退化的情况下表现良好，以及一种用于自动水果检测的学习交叉光谱表示。 et.al.|[2409.15487](http://arxiv.org/abs/2409.15487)|null|
|**2024-09-23**|**SpikeGS: Learning 3D Gaussian Fields from Continuous Spike Stream**|尖峰相机是一种专用的高速视觉传感器，与传统的帧相机相比，它具有高时间分辨率和高动态范围等优点。这些特征为相机在许多计算机视觉任务中提供了显著的优势。然而，基于尖峰相机的3D重建和新型视图合成的任务仍然不发达。尽管有从尖峰流中学习神经辐射场的现有方法，但它们要么在极其嘈杂、低质量的光照条件下缺乏鲁棒性，要么由于神经辐射场中使用的深度全连接神经网络和光线行进渲染策略，计算复杂度很高，难以恢复精细的纹理细节。相比之下，3DGS的最新进展通过将点云表示优化为高斯椭球体实现了高质量的实时渲染。在此基础上，我们介绍了SpikeGS，这是第一种仅从尖峰流中学习3D高斯场的方法。我们设计了一个基于3DGS的可微分尖峰流渲染框架，结合了噪声嵌入和尖峰神经元。通过利用3DGS的多视图一致性和基于图块的多线程并行渲染机制，我们实现了高质量的实时渲染结果。此外，我们引入了一个尖峰渲染损失函数，该函数在不同的光照条件下具有通用性。我们的方法可以从移动尖峰相机捕获的连续尖峰流中重建具有精细纹理细节的视图合成结果，同时在极其嘈杂的低光场景中表现出很高的鲁棒性。在真实和合成数据集上的实验结果表明，我们的方法在渲染质量和速度方面超越了现有的方法。我们的代码将在https://github.com/520jz/SpikeGS. et.al.|[2409.15176](http://arxiv.org/abs/2409.15176)|**[link](https://github.com/520jz/spikegs)**|
|**2024-09-23**|**FusionRF: High-Fidelity Satellite Neural Radiance Fields from Multispectral and Panchromatic Acquisitions**|我们介绍了FusionRF，这是一种基于光学未处理卫星图像的新型神经渲染地形重建方法。虽然以前的方法依赖于外部泛色法来融合低分辨率多光谱图像和高分辨率全色图像，但FusionRF直接在没有先验知识的情况下基于光学未处理的采集进行重建。这是通过添加一个锐化内核来实现的，该内核对多光谱图像中的分辨率损失进行建模。此外，新颖的模态嵌入允许模型执行图像融合，这是新颖视图合成的瓶颈。我们在不同位置对WorldView-3卫星的多光谱和全色卫星图像进行了评估，FusionRF在未处理图像的深度重建、渲染清晰的训练和新颖的视图以及保留多光谱信息方面优于之前的最先进方法。 et.al.|[2409.15132](http://arxiv.org/abs/2409.15132)|null|
|**2024-09-23**|**AIM 2024 Sparse Neural Rendering Challenge: Methods and Results**|本文回顾了稀疏神经渲染的挑战，这是与ECCV 2024联合举办的图像处理进展（AIM）研讨会的一部分。本文重点介绍了比赛设置、提出的方法及其各自的结果。该挑战旨在从稀疏图像观测中生成不同场景的新颖相机视图合成。它由两条轨道组成，具有不同程度的稀疏性；Track 1中有3个视图（非常稀疏），Track 2中有9个视图（稀疏）。参与者被要求优化通过峰值信噪比（PSNR）度量测量的地面实况图像的客观保真度。对于这两个轨道，我们使用新引入的稀疏渲染（SpaRe）数据集和流行的DTU MVS数据集。在本次挑战中，5支队伍向Track 1提交了最终成绩，4支队伍向Track2提交了最终结果。提交的模型多种多样，突破了稀疏神经渲染的最新技术。本文详细描述了在挑战中开发的所有模型。 et.al.|[2409.15045](http://arxiv.org/abs/2409.15045)|null|
|**2024-09-23**|**AIM 2024 Sparse Neural Rendering Challenge: Dataset and Benchmark**|可微分和神经渲染的最新发展在各种2D和3D任务中取得了令人印象深刻的突破，例如新颖的视图合成、3D重建。通常，可微分渲染依赖于场景的密集视点覆盖，这样几何体就可以单独从外观观察中消除歧义。当只有少数输入视图可用时，会出现一些挑战，通常称为稀疏或少镜头神经渲染。由于这是一个约束不足的问题，大多数现有方法都引入了正则化的使用，以及各种学习和手工制作的先验。稀疏渲染文献中反复出现的一个问题是缺乏同质、最新的数据集和评估协议。虽然高分辨率数据集是密集重建文献中的标准，但稀疏渲染方法通常使用低分辨率图像进行评估。此外，不同手稿之间的数据分割不一致，测试地面真实图像通常是公开的，这可能会导致过度拟合。在这项工作中，我们提出了稀疏渲染（SpaRe）数据集和基准测试。我们引入了一个遵循DTU MVS数据集设置的新数据集。该数据集由97个基于合成高质量资产的新场景组成。每个场景最多有64个相机视图和7个照明配置，以1600x1200分辨率渲染。我们发布了82个场景的训练分割，以培养可推广的方法，并为验证和测试集提供了一个在线评估平台，其真实图像保持隐藏。我们提出了两种不同的稀疏配置（分别为3幅和9幅输入图像）。这为可重复评估提供了一个强大而方便的工具，并使研究人员能够轻松访问具有最先进绩效评分的公共排行榜。可用网址：https://sparebenchmark.github.io/ et.al.|[2409.15041](http://arxiv.org/abs/2409.15041)|null|
|**2024-09-22**|**MVPGS: Excavating Multi-view Priors for Gaussian Splatting from Sparse Input Views**|最近，神经辐射场（NeRF）的进步促进了少镜头新视图合成（NVS），这是3D视觉应用中的一个重大挑战。尽管多次尝试降低NeRF中的密集输入要求，但它仍然受到耗时的训练和渲染过程的困扰。最近，3D高斯散斑（3DGS）通过显式的基于点的表示实现了实时高质量的渲染。然而，与NeRF类似，由于缺乏约束，它往往会过度拟合训练视图。在本文中，我们提出了\textbf{MVPGS}，这是一种基于3D高斯散斑挖掘多视图先验的少镜头NVS方法。我们利用最近基于学习的多视图立体（MVS）来提高3DGS的几何初始化质量。为了减轻过拟合，我们提出了一种基于计算几何的前向扭曲方法，用于符合场景的额外外观约束。此外，我们为高斯参数引入了视图一致的几何约束，以促进适当的优化收敛，并利用单目深度正则化作为补偿。实验表明，该方法在实时渲染速度方面达到了最先进的性能。项目页面：https://zezeaaa.github.io/projects/MVPGS/ et.al.|[2409.14316](http://arxiv.org/abs/2409.14316)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-09-26**|**TFS-NeRF: Template-Free NeRF for Semantic 3D Reconstruction of Dynamic Scene**|尽管神经隐式模型在3D表面重建方面取得了进展，但处理具有任意刚性、非刚性或可变形实体的动态环境仍然具有挑战性。许多基于模板的方法是特定于实体的，专注于人类，而适用于这种动态场景的通用重建方法通常需要额外的输入，如深度或光流，或者依赖于预训练的图像特征来获得合理的结果。这些方法通常使用潜码来捕获逐帧变形。相比之下，一些无模板方法绕过了这些要求，采用传统的LBS（线性混合蒙皮）权重来详细表示可变形对象的运动，尽管它们涉及复杂的优化，导致训练时间过长。为此，作为补救措施，本文引入了TFS NeRF，这是一种无模板的3D语义NeRF，用于从稀疏或单视图RGB视频中捕获的动态场景，具有各种实体之间的交互功能，比其他基于LBS的方法更省时。我们的框架使用可逆神经网络（INN）进行LBS预测，简化了训练过程。通过解开多个实体的运动并优化每个实体的蒙皮权重，我们的方法有效地生成了准确的、语义上可分离的几何体。大量实验表明，与现有方法相比，我们的方法在复杂的交互中产生了可变形和不可变形对象的高质量重建，提高了训练效率。 et.al.|[2409.17459](http://arxiv.org/abs/2409.17459)|null|
|**2024-09-25**|**Generative Object Insertion in Gaussian Splatting with a Multi-View Diffusion Model**|生成新对象并将其插入到3D内容中是实现多功能场景再现的一种引人注目的方法。现有的方法依赖于SDS优化或单视图修复，往往难以产生高质量的结果。为了解决这个问题，我们提出了一种在高斯散斑表示的3D内容中插入对象的新方法。我们的方法引入了一个名为MVInpainter的多视图扩散模型，该模型基于预训练的稳定视频扩散模型构建，以促进视图一致的对象修复。在MVInpainter中，我们整合了一个基于ControlNet的条件注入模块，以实现受控和更可预测的多视图生成。在生成多视图修复结果后，我们进一步提出了一种掩模感知的3D重建技术，从这些稀疏的修复视图中改进高斯散斑重建。通过利用这些制造技术，我们的方法产生了不同的结果，确保了视图一致和和谐的插入，并产生了更好的物体质量。大量实验表明，我们的方法优于现有方法。 et.al.|[2409.16938](http://arxiv.org/abs/2409.16938)|**[link](https://github.com/jiutongbro/multiview_inpaint)**|
|**2024-09-25**|**Discriminative Anchor Learning for Efficient Multi-view Clustering**|多视图聚类旨在研究视图之间的互补信息并发现底层结构。为了解决现有方法相对较高的计算成本，最近提出了基于锚点的工作。即使具有可接受的聚类性能，这些方法也倾向于将来自多个视图的原始表示映射到基于原始数据集的固定共享图中。然而，大多数研究忽略了学习锚的判别特性，这破坏了所构建模型的表示能力。此外，通过简单地学习共享锚点图而不考虑视图特定锚点的质量，可以忽略跨视图锚点之间的互补信息。本文提出了用于多视图聚类的判别锚学习（DALMC）来处理上述问题。我们根据原始数据集学习区分视图特定的特征表示，并基于这些表示从不同视图构建锚点，从而提高了共享锚点图的质量。将判别特征学习和共识锚图构建集成到一个统一的框架中，相互改进，实现细化。通过正交约束学习来自多个视图的最优锚点和共识锚点图。我们给出了一个迭代算法来处理公式化问题。在不同数据集上的大量实验表明，与其他方法相比，我们的方法具有有效性和效率。 et.al.|[2409.16904](http://arxiv.org/abs/2409.16904)|null|
|**2024-09-25**|**Towards Unified 3D Hair Reconstruction from Single-View Portraits**|由于不同发型之间存在广泛的形状变化，单视图3D头发重建具有挑战性。目前最先进的方法专门用于恢复未编织的3D头发，并且经常将编织风格作为失败案例，因为无论是基于规则还是基于数据，都很难定义复杂发型的先验。我们提出了一种新的策略，通过统一的管道实现各种头发类型的单视图3D重建。为了实现这一目标，我们首先收集了一个大规模的合成多视图头发数据集SynMvHair，其中包含编织和非编织风格的各种3D头发，并学习了两个专门针对头发的扩散先验。然后，我们使用两个专门设计的模块（即视图和像素高斯细化）从先验中优化基于3D高斯的头发。我们的实验表明，通过统一的方法从单视图图像重建编织和非编织的3D头发是可能的，我们的方法在恢复复杂发型方面达到了最先进的性能。值得一提的是，我们的方法对真实图像显示出良好的泛化能力，尽管它从合成数据中学习头发先验。 et.al.|[2409.16863](http://arxiv.org/abs/2409.16863)|null|
|**2024-09-25**|**3DDX: Bone Surface Reconstruction from a Single Standard-Geometry Radiograph via Dual-Face Depth Estimation**|射线照相因其经济实惠和低辐射暴露而广泛应用于骨科。从单个射线照片进行3D重建，即所谓的2D-3D重建，提供了各种临床应用的可能性，但实现临床可行的准确性和计算效率仍然是一个未解决的挑战。与计算机视觉的其他领域不同，X射线成像的独特特性，如射线穿透和固定几何形状，尚未得到充分利用。我们提出了一种新方法，可以同时学习从X射线图像中导出的多个深度图（多个骨骼的前表面和后表面），以进行计算机断层扫描配准。该方法不仅利用了X射线成像的固定几何特性，而且提高了整个表面重建的精度。我们的研究涉及600张CT和2651张X射线图像（每位患者4至5张摆位X射线图像），证明了我们的方法优于传统方法，表面重建误差从4.78毫米减少到1.96毫米。这一显著的精度提高和计算效率的提高表明了我们的方法在临床应用中的潜力。 et.al.|[2409.16702](http://arxiv.org/abs/2409.16702)|null|
|**2024-09-24**|**Frequency-based View Selection in Gaussian Splatting Reconstruction**|三维重建是机器人感知中的一个基本问题。我们研究了主动视图选择的问题，以尽可能少的输入图像进行3D高斯散斑重建。尽管3D高斯散斑在图像渲染和3D重建方面取得了重大进展，但重建的质量受到2D图像选择和通过运动结构（SfM）算法估计相机姿态的强烈影响。目前选择直接依赖于遮挡、深度模糊或神经网络预测的不确定性的视图的方法不足以处理这个问题，并且很难推广到新的场景。通过在频域中对潜在视图进行排序，我们能够在没有地面实况数据的情况下有效地估计新视图的潜在信息增益。通过克服当前对模型架构和效率的限制，我们的方法在视图选择方面取得了最先进的结果，展示了其高效基于图像的3D重建的潜力。 et.al.|[2409.16470](http://arxiv.org/abs/2409.16470)|null|
|**2024-09-24**|**Underground Mapping and Localization Based on Ground-Penetrating Radar**|近年来，基于深度神经网络的三维物体重建越来越受到人们的关注。然而，对地下物体进行3D重建以生成点云图仍然是一个挑战。探地雷达（GPR）是探测和定位植物根系和管道等地下物体最强大、使用最广泛的工具之一，具有成本效益和不断发展的技术。本文介绍了一种基于深度卷积神经网络的抛物线信号检测网络，该网络利用探地雷达传感器的B扫描图像。检测到的关键点可以帮助精确拟合抛物线，用于将原始GPR B扫描图像解释为对象模型的横截面。此外，设计了一个多任务点云网络，可以同时执行点云分割和完成，填充稀疏点云地图。对于未知位置，GPR A扫描数据可用于匹配所构建地图中的相应A扫描数据，精确定位位置以验证模型构建地图的准确性。实验结果证明了我们方法的有效性。 et.al.|[2409.16446](http://arxiv.org/abs/2409.16446)|null|
|**2024-09-24**|**Age of Gossip in Networks with Multiple Views of a Source**|我们考虑网络中的信息版本年龄（AoI），其中节点子集充当感测节点，对通常可以遵循连续分布的源进行采样。源的任何样本都构成了信息的新版本，信息的版本年龄是根据整个网络可用信息的最新版本定义的。我们推导出了节点不同子集之间的平均版本AoI的递归表达式，可用于评估包括任何单个节点在内的任何节点子集的平均版本AoI。我们推导了各种拓扑结构（包括线、环和全连接网络）在网络任何单个节点上的平均AoI的渐近行为。Yates关于网络版本年龄的现有技术结果[ISIT'21]在我们的推导中可以被解释为具有单一源视图的网络，例如通过速率为 $\lambda_{00}$的泊松过程。我们的结果表明，通过分割相同的速率$\lambda_{00}$，将源的单个视图替换为跨多个节点的分布式感知，平均版本AoI性能没有损失。特别地，我们证明，对于全连接和环形网络，平均AoI分别渐近地缩放为$O（\log（n））$和$O（\sqrt{n}）$。更有趣的是，我们表明，对于环形网络，如果感测节点的数量仅随$O（\sqrt{n}）$而不是需要$O（n）$的先前已知结果缩放，则分布式感测在平均AoI上仍然可以实现相同的$O（$sqrt{n}）$渐近性能。我们的结果表明，只要连续非感测节点的最大数量也缩放为$O（\sqrt{n}）$ ，就可以任意选择感测节点。 et.al.|[2409.16285](http://arxiv.org/abs/2409.16285)|null|
|**2024-09-24**|**AIR-Embodied: An Efficient Active 3DGS-based Interaction and Reconstruction Framework with Embodied Large Language Model**|3D重建和神经渲染的最新进展增强了高质量数字资产的创建，但现有的方法很难在不同的对象形状、纹理和遮挡之间进行推广。虽然次优视图（NBV）规划和基于学习的方法提供了解决方案，但它们往往受到预定义标准的限制，无法用人类的常识来管理遮挡。为了解决这些问题，我们提出了AIR Embodied，这是一种新的框架，将嵌入的AI代理与大规模预训练的多模态语言模型集成在一起，以改进主动3DGS重建。AIR Embodied采用了一个三阶段过程：通过多模态提示了解当前的重建状态，通过视点选择和交互动作规划任务，并采用闭环推理来确保准确执行。代理根据计划结果和实际结果之间的差异动态改进其操作。在虚拟和现实世界环境中的实验评估表明，AIR Embodied显著提高了重建效率和质量，为主动3D重建中的挑战提供了一个稳健的解决方案。 et.al.|[2409.16019](http://arxiv.org/abs/2409.16019)|null|
|**2024-09-23**|**Matérn Kernels for Tunable Implicit Surface Reconstruction**|我们建议使用Mat'ern核家族进行可调隐式曲面重建，以最近成功的定向点云三维重建核方法为基础。正如我们所展示的，从理论和实践的角度来看，Mat'ern核都有一些吸引人的特性，使其特别适合曲面重建——优于基于弧余弦核的最先进方法，同时更容易实现、计算更快、可扩展。由于是平稳的，我们证明了Mat'ern核'光谱可以以与傅里叶特征映射相同的方式进行调整，以帮助基于坐标的MLP克服光谱偏差。此外，我们从理论上分析了Mat'ern核与SIREN网络的连接，以及它与以前使用的弧余弦核的关系。最后，基于最近引入的神经核域，我们提出了数据依赖的Mat'ern核，并得出结论，特别是拉普拉斯核（作为Mat'ern家族的一部分）具有极强的竞争力，在无噪声的情况下，其性能几乎与最先进的方法相当，同时训练时间缩短了五倍以上。 et.al.|[2409.15466](http://arxiv.org/abs/2409.15466)|**[link](https://github.com/mweiherer/matern-surface-reconstruction)**|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-09-26**|**FlowTurbo: Towards Real-time Flow-Based Image Generation with Velocity Refiner**|基于扩散模型在视觉生成中的成功，基于流的模型作为另一个突出的生成模型家族重新出现，在视觉质量和推理速度方面都取得了有竞争力或更好的性能。通过流匹配学习速度场，基于流的模型倾向于产生更直的采样轨迹，这在采样过程中是有利的。然而，与快速采样器发达的扩散模型不同，基于流的生成模型的有效采样很少被探索。在本文中，我们提出了一个名为FlowTurbo的框架，以加速基于流的模型的采样，同时提高采样质量。我们的主要观察结果是，基于流量的模型中的速度预测器的输出在采样过程中会变得稳定，从而能够通过轻量级的速度细化器来估计速度。此外，我们引入了几种技术，包括伪校正器和样本感知编译，以进一步减少推理时间。由于FlowTurbo不改变多步采样范式，因此它可以有效地应用于各种任务，如图像编辑、修复等。通过将FlowTurbo集成到不同的基于流的模型中，我们在类条件生成上获得了53.1% $\sim$58.3%的加速比，在文本到图像生成上得到了29.8%$\sim$ 38.5%的加速比。值得注意的是，FlowTurbo在ImageNet上的FID为2.12，为100（ms/img），FID为3.93，为38（ms/img），实现了实时图像生成，并建立了新的最先进技术。代码可在https://github.com/shiml20/FlowTurbo. et.al.|[2409.18128](http://arxiv.org/abs/2409.18128)|**[link](https://github.com/shiml20/flowturbo)**|
|**2024-09-26**|**Lotus: Diffusion-based Visual Foundation Model for High-quality Dense Prediction**|利用预先训练的文本到图像扩散模型的视觉先验，为在密集预测任务中增强零样本泛化提供了一种很有前途的解决方案。然而，现有的方法经常不加批判地使用原始的扩散公式，由于密集预测和图像生成之间的根本差异，这可能不是最优的。本文对密集预测的扩散公式进行了系统分析，重点关注质量和效率。我们发现，用于图像生成的原始参数化类型（学习预测噪声）对密集预测有害；多步噪声/去噪扩散过程也是不必要的，并且具有优化的挑战性。基于这些见解，我们介绍了Lotus，这是一种基于扩散的视觉基础模型，具有简单而有效的适应协议，用于密集预测。具体来说，Lotus经过训练，可以直接预测注释而不是噪声，从而避免有害的方差。我们还将扩散过程重新表述为单步过程，简化了优化并显著提高了推理速度。此外，我们引入了一种名为细节保持器的新型调优策略，该策略实现了更准确、更细粒度的预测。在不扩大训练数据或模型容量的情况下，Lotus在各种数据集的零样本深度和正常估计方面实现了SoTA性能。它还显著提高了效率，比大多数现有的基于扩散的方法快数百倍。 et.al.|[2409.18124](http://arxiv.org/abs/2409.18124)|null|
|**2024-09-26**|**EdgeRunner: Auto-regressive Auto-encoder for Artistic Mesh Generation**|当前的自回归网格生成方法存在不完整、细节不足和泛化能力差等问题。在本文中，我们提出了一种自回归自编码器（ArAE）模型，该模型能够以512^3$的空间分辨率生成多达4000个人脸的高质量3D网格。我们介绍了一种新的网格标记化算法，该算法有效地将三角形网格压缩为1D标记序列，显著提高了训练效率。此外，我们的模型将变长三角形网格压缩到固定长度的潜在空间中，从而能够训练潜在扩散模型以获得更好的泛化能力。大量实验证明，我们的模型在点云和图像条件网格生成任务中都具有卓越的质量、多样性和泛化能力。 et.al.|[2409.18114](http://arxiv.org/abs/2409.18114)|null|
|**2024-09-26**|**StackGen: Generating Stable Structures from Silhouettes via Diffusion**|人类通过观察和与世界互动，自然地获得了关于刚性物体之间相互作用和稳定性的直觉。正是这种直觉支配着我们在环境中定期配置对象的方式，使我们能够从简单的日常对象构建复杂的结构。另一方面，机器人代理传统上需要一个明确的世界模型，其中包括每个对象的详细几何形状和环境动力学的分析模型，这些模型难以扩展并排除泛化。相反，机器人将受益于对直观物理学的认识，这使它们能够对环境中物体的稳定相互作用进行类似的推理。为了实现这一目标，我们提出了StackGen，这是一种扩散模型，可以生成与目标轮廓匹配的构建块的各种稳定配置。为了证明该方法的能力，我们在模拟环境中对其进行评估，并使用机器人手臂将其部署在真实环境中，以组装模型生成的结构。 et.al.|[2409.18098](http://arxiv.org/abs/2409.18098)|null|
|**2024-09-26**|**DiffSSC: Semantic LiDAR Scan Completion using Denoising Diffusion Probabilistic Models**|感知系统在自动驾驶中起着至关重要的作用，它结合了多个传感器和相应的计算机视觉算法。3D激光雷达传感器被广泛用于捕捉车辆周围稀疏的点云。然而，由于这些点云的稀疏性和缺乏语义，这些系统很难感知场景中的遮挡区域和间隙。为了应对这些挑战，语义场景完成（SSC）在给定原始LiDAR测量值的情况下，联合预测场景中未观察到的几何和语义，旨在实现更完整的场景表示。基于图像生成和超分辨率任务中扩散模型的有前景的结果，我们通过在点和语义空间中分别实现噪声和去噪扩散过程，将其扩展到SSC。为了控制生成，我们使用语义LiDAR点云作为条件输入，并设计局部和全局正则化损失来稳定去噪过程。我们在自动驾驶数据集上评估了我们的方法，我们的方法优于SSC的最新技术。 et.al.|[2409.18092](http://arxiv.org/abs/2409.18092)|null|
|**2024-09-26**|**Stable Video Portraits**|生成式人工智能领域的快速发展，特别是文本到图像的方法，改变了我们今天与计算机生成的图像互动和感知的方式。与此同时，使用3D可变形模型（3DMM）进行3D人脸重建取得了很大进展。在本文中，我们提出了一种新的混合2D/3D生成方法SVP，该方法利用大型预训练的文本到图像先验（2D），通过3DMM（3D）控制，输出说话人脸的逼真视频。具体来说，我们通过提供时间3DMM序列作为条件并引入时间去噪过程，对一般的2D稳定扩散模型进行了针对个人的微调，并将其提升到视频模型中。作为输出，该模型使用基于3DMM的控件生成人的时间平滑图像，即特定于人的化身。这个特定于人的化身的面部外观可以编辑并变形为文本定义的名人，而无需在测试时进行任何微调。对该方法进行了定量和定性分析，我们表明我们的方法优于最先进的单眼头部化身方法。 et.al.|[2409.18083](http://arxiv.org/abs/2409.18083)|null|
|**2024-09-26**|**The radio halo in PLCKESZ G171.94 $-$ 40.65: Beacon of merging activity**|我们使用升级的巨型米波射电望远镜（uGMRT；400 MHz）和卡尔·G·扬斯基甚大阵列（JVLA；1-2 GHz）观测，对星系团PLCKESZ G171.94美元-40.65美元中的候选超陡谱射电晕进行了首次多频分析。我们的无线电数据得到了存档的钱德拉X射线观测的补充，为大规模发生的复杂团内介质（ICM）物理学提供了至关重要的见解。我们在400 MHz的频率下检测到1.5 Mpc的射电晕发射，比之前报道的要大得多，中心区域还有五尾星系。我们还报告了在星团外围发现了一个未知的扩散源“U”，其范围为300kpc。利用现有的观测结果，我们发现晕的无线电频谱很好地符合单一幂律，频谱指数为-1.36\pm 0.05$，表明它不是超陡峭的频谱无线电晕。我们的低分辨率（25$''$）分辨率光谱图显示了一个整体均匀的光谱指数，其中有一些波动。X射线和射电表面亮度在形态上是共空间的，沿西北-东南方向略有延伸，在两幅地图上都可以看到。射电和X射线表面亮度显示出强烈的正相关关系，具有亚线性相关斜率（$\sim$ 0.71）。多尾星系和射电晕表明星团中心区域存在高动态活动。 et.al.|[2409.18075](http://arxiv.org/abs/2409.18075)|null|
|**2024-09-26**|**Low Photon Number Non-Invasive Imaging Through Time-Varying Diffusers**|散射在光学成像中是一个重大挑战。在显微镜中，它会导致图像质量的逐渐下降，从而阻止在越来越深的深度进行样品检查。随着样品厚度的增加，可以成功穿过它的光子数量减少，导致信号减少，使我们无法获得清晰的图像。对于随时间变化的生物组织等动态散射体，成像变得更加困难。我们展示了隐藏在动态漫射器后面的荧光物体的非侵入性成像。我们的重建使用了为不同漫射器实现记录的一堆图像，即使在单个相机帧包含小光子数的情况下也能正常工作。 et.al.|[2409.18072](http://arxiv.org/abs/2409.18072)|null|
|**2024-09-26**|**Radio-FIR correlation- A probe into cosmic ray propagation in the nearby galaxy IC 342**|对不同频率星系的无线电和远红外（FIR）发射之间相关性的深入研究可以揭示恒星形成与相对论星际介质（ISM）之间的相互作用。得益于LOFAR LoTSS观测结果与VLA、赫歇尔和WISE数据的结合，我们研究了宇宙射线和磁场在附近星系IC342中~＞200pc尺度的无线电FIR相关性中的作用。在恒星形成区，22微米发射所追踪的热发射分别占0.14、1.4、4.8 GHz观测到的无线电发射的6%、13%和30%，在其他地区则较少。非热光谱指数在低于1.4 GHz的频率（a=-0.51+-0.09，S（nu）~nu^（a））比平均1.4至4.8 GHz（a=-1.06+-0.19）更平坦，这种平坦化不仅发生在恒星形成区，也发生在弥漫的ISM中。无线电FIR相关性在所有无线电频率上都成立；然而，在较高的无线电频率下，它更紧密。多尺度分析表明，由于宇宙射线电子（CRE）的扩散，这种相关性在小尺度上无法保持。与1.4 GHz（200个百分点）相比，0.14 GHz的相关性在更大范围内（320个百分点）中断，表明在较低频率下追踪的CRE在ISM中扩散了更长的路径。我们发现，CRE的能量指数在恒星形成区变得更平坦，这与之前的研究一致。只有在补偿了恒星形成活动的影响后，磁场对CRE的冷却才在全球范围内明显，恒星形成活动既加速了CRE，又放大了磁场。与附近的其他星系相比，研究表明，无线电FIR相关性的最小尺度与有序磁场对其有重要影响的CRE传播长度成正比。 et.al.|[2409.17999](http://arxiv.org/abs/2409.17999)|null|
|**2024-09-26**|**Distributed Invariant Unscented Kalman Filter based on Inverse Covariance Intersection with Intermittent Measurements**|本文研究了矩阵李群上传感器网络的分布式状态估计（DSE）问题，这对于系统状态在李群而不是向量空间上演化的应用至关重要。我们提出了一种基于扩散的分布式不变无迹卡尔曼滤波器，该滤波器使用逆协方差交集（DIUKF-ICI）方法来解决3D环境中的目标跟踪问题。与局限于向量空间的现有分布式UKF不同，我们的方法将分布式UKF框架扩展到李群，使局部估计能够与李群上相邻主体的中间信息融合。为了处理局部估计之间的未知相关性，我们首次将ICI融合策略扩展到矩阵李群，并将其整合到扩散算法中。我们证明了所提出方法的估计误差是有界的。此外，该算法是完全分布式的，对间歇测量具有鲁棒性，并适用于时变通信拓扑。通过大量的蒙特卡洛模拟验证了所提出方法的有效性。 et.al.|[2409.17997](http://arxiv.org/abs/2409.17997)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-09-25**|**TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans**|我们介绍了一种新的框架，该框架从单眼视频中学习全身说话的人的动态神经辐射场（NeRF）。之前的工作只代表身体姿势或面部。然而，人类通过全身进行交流，结合身体姿势、手势和面部表情。在这项工作中，我们提出了TalkinNeRF，这是一个基于NeRF的统一网络，代表了整体4D人体运动。给定一个受试者的单眼视频，我们学习身体、面部和手的相应模块，这些模块结合在一起生成最终结果。为了捕捉复杂的手指关节，我们学习了手的额外变形场。我们的多身份表示能够同时训练多个科目，以及在完全看不见的姿势下进行强大的动画。只要输入一段短视频，它也可以推广到新的身份。我们展示了最先进的性能，用于为全身说话的人类制作动画，具有精细的手部发音和面部表情。 et.al.|[2409.16666](http://arxiv.org/abs/2409.16666)|null|
|**2024-09-24**|**Generative 3D Cardiac Shape Modelling for In-Silico Trials**|我们提出了一种深度学习方法，基于将形状表示为神经有符号距离场的零级集，对合成主动脉形状进行建模和生成，该方法受一系列可训练的嵌入向量的约束，并对每个形状的几何特征进行编码。通过使神经场在采样表面点上消失并强制其空间梯度具有单位范数，在从CT图像重建的主动脉根部网格数据集上训练网络。实证结果表明，我们的模型可以高保真地表示主动脉形状。此外，通过从学习到的嵌入向量中采样，我们可以生成类似于真实患者解剖结构的新形状，可用于计算机模拟试验。 et.al.|[2409.16058](http://arxiv.org/abs/2409.16058)|null|
|**2024-09-21**|**MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors**|由于缺乏几何指导和不完美的视图相关2D先验，从单眼图像中精确重建密集和语义注释的3D网格仍然是一项具有挑战性的任务。尽管我们已经见证了隐式神经场景表示的最新进展，能够简单地从多视图图像中进行精确的2D渲染，但很少有研究仅使用单眼先验来解决3D场景理解问题。在本文中，我们提出了MOSE，这是一种神经场语义重建方法，可以将推断的图像级噪声先验提升到3D，在3D和2D空间中产生精确的语义和几何。我们方法的关键动机是利用通用类不可知的分段掩码作为指导，在训练过程中促进渲染语义的局部一致性。在语义的帮助下，我们进一步将平滑正则化应用于无纹理区域，以获得更好的几何质量，从而实现几何和语义的互惠互利。在ScanNet数据集上的实验表明，我们的MOSE在3D语义分割、2D语义分割和3D表面重建任务的所有指标上都优于相关基线。 et.al.|[2409.14019](http://arxiv.org/abs/2409.14019)|null|
|**2024-09-17**|**SplatFields: Neural Gaussian Splats for Sparse 3D and 4D Reconstruction**|从多视图图像中数字化3D静态场景和4D动态事件长期以来一直是计算机视觉和图形学领域的一个挑战。最近，3D高斯散斑（3DGS）已经成为一种实用且可扩展的重建方法，由于其令人印象深刻的重建质量、实时渲染能力以及与广泛使用的可视化工具的兼容性而越来越受欢迎。然而，该方法需要大量的输入视图来实现高质量的场景重建，这引入了一个重大的实际瓶颈。在捕捉动态场景时，这一挑战尤为严峻，因为部署广泛的相机阵列的成本可能高得令人望而却步。在这项工作中，我们发现斑点特征缺乏空间自相关性是导致3DGS技术在稀疏重建环境中性能不佳的因素之一。为了解决这个问题，我们提出了一种优化策略，通过将splat特征建模为相应隐式神经场的输出，有效地正则化splat特征。这导致在各种场景中重建质量的一致提高。我们的方法有效地处理了静态和动态情况，这在不同设置和场景复杂性的广泛测试中得到了证明。 et.al.|[2409.11211](http://arxiv.org/abs/2409.11211)|null|
|**2024-09-17**|**Neural Fields for Adaptive Photoacoustic Computed Tomography**|光声计算机断层扫描（PACT）是一种具有广泛医学应用的非侵入性成像技术。传统的PACT图像重建算法受到组织中声速不均匀（SOS）引起的波前失真的影响，导致图像质量下降。考虑到这些影响可以提高图像质量，但测量SOS分布的实验成本很高。另一种方法是仅使用PA信号对初始压力图像和SOS进行联合重建。现有的关节重建方法存在局限性：计算成本高，无法直接恢复SOS，以及依赖于不准确的简化假设。隐式神经表示或神经场是计算机视觉中的一种新兴技术，用于通过基于坐标的神经网络学习物理场的有效和连续表示。在这项工作中，我们介绍了NF-APACT，这是一种高效的自监督框架，利用神经场来估计SOS，以实现准确和鲁棒的多通道解卷积。我们的方法比现有方法更快、更准确地消除了SOS像差。我们在一个新的数值体模以及实验收集的体模和体内数据上证明了我们的方法的成功。我们的代码和数字幻影可在https://github.com/Lukeli0425/NF-APACT. et.al.|[2409.10876](http://arxiv.org/abs/2409.10876)|null|
|**2024-09-09**|**Lagrangian Hashing for Compressed Neural Field Representations**|我们提出了拉格朗日散列，这是一种神经场的表示，结合了依赖于欧拉网格（即~InstantNGP）的快速训练NeRF方法的特征，以及使用配备有特征的点作为表示信息的方法（例如3D高斯散点或PointNeRF）。我们通过将基于点的表示合并到InstantNGP表示的分层哈希表的高分辨率层中来实现这一点。由于我们的点具有影响域，我们的表示可以被解释为哈希表中存储的高斯混合。我们提出的损失鼓励我们的高斯人向需要更多代表预算才能充分代表的地区移动。我们的主要发现是，我们的表示允许使用更紧凑的表示来重建信号，而不会影响质量。 et.al.|[2409.05334](http://arxiv.org/abs/2409.05334)|null|
|**2024-09-08**|**Exploring spectropolarimetric inversions using neural fields. Solar chromospheric magnetic field under the weak-field approximation**|全斯托克斯偏振数据集来源于狭缝光谱仪或窄带滤光片图，如今已被常规采集。随着二维光谱偏振仪和允许长时间高质量观测序列的观测技术的出现，数据速率正在增加。在光谱偏振反演中，显然需要通过利用推断物理量的时空相干性来超越传统的逐像素策略。我们探索了神经网络作为时间和空间（也称为神经场）上物理量的连续表示的潜力，用于光谱极化反演。我们已经实现并测试了一个神经场，以在弱场近似（WFA）下执行磁场矢量的推理（也称为物理知情神经网络的方法）。通过使用神经场来描述磁场矢量，我们可以通过假设物理量是坐标的连续函数来在空间和时间域中正则化解。我们研究了Ca II 8542 A谱线的合成和真实观测结果。我们还探讨了其他显式正则化的影响，例如使用外推磁场的信息或色球原纤维的取向。与传统的逐像素反演相比，神经场方法提高了磁场矢量重建的保真度，特别是横向分量。这种隐式正则化是一种提高观测值有效信噪比的方法。虽然它比逐像素WFA估计慢，但这种方法通过减少自由参数的数量并在解决方案中引入时空约束，显示出深度分层反演的巨大潜力。 et.al.|[2409.05156](http://arxiv.org/abs/2409.05156)|**[link](https://github.com/cdiazbas/neural_wfa)**|
|**2024-09-04**|**MDNF: Multi-Diffusion-Nets for Neural Fields on Meshes**|我们提出了一种在三角形网格上表示神经场的新框架，该框架在空间和频率域上都是多分辨率的。受神经傅里叶滤波器组（NFFB）的启发，我们的架构通过将更精细的空间分辨率级别与更高的频带相关联来分解空间和频率域，而将更粗糙的分辨率映射到较低的频率。为了实现几何感知的空间分解，我们利用了多个扩散网络组件，每个组件都与不同的空间分辨率级别相关联。随后，我们应用傅里叶特征映射来鼓励更精细的分辨率水平与更高的频率相关联。最终信号是使用正弦激活的MLP以小波激励的方式组成的，将高频信号聚集在低频信号之上。我们的架构在学习复杂神经场方面具有很高的精度，并且对目标场的不连续性、指数尺度变化和网格修改具有鲁棒性。我们通过将我们的方法应用于不同的神经领域，如合成RGB函数、UV纹理坐标和顶点法线，展示了其有效性，并说明了不同的挑战。为了验证我们的方法，我们将其性能与两种替代方案进行了比较，展示了我们的多分辨率架构的优势。 et.al.|[2409.03034](http://arxiv.org/abs/2409.03034)|null|
|**2024-09-03**|**GraspSplats: Efficient Manipulation with 3D Feature Splatting**|机器人对物体部件进行高效和零样本抓取的能力对于实际应用至关重要，并且随着视觉语言模型（VLM）的最新进展而变得普遍。为了弥合二维到三维表示的差距以支持这种能力，现有的方法依赖于神经场（NeRF），通过可微渲染或基于点的投影方法。然而，我们证明了NeRF由于其隐含性而不适合场景变化，并且基于点的方法对于没有基于渲染的优化的零件定位是不准确的。为了修正这些问题，我们提出了“把握辉煌”。使用深度监督和一种新的参考特征计算方法，GraspSplats在60秒内生成高质量的场景表示。我们进一步验证了基于高斯表示法的优势，表明GraspSplats中的显式和优化几何足以原生支持（1）实时抓取采样和（2）使用点跟踪器进行动态和铰接对象操作。通过在Franka机器人上进行的广泛实验，我们证明了在不同的任务设置下，GraspSplats的表现明显优于现有的方法。特别是，GraspSplats的性能优于基于NeRF的方法，如F3RM和LERF-TOGO，以及2D检测方法。 et.al.|[2409.02084](http://arxiv.org/abs/2409.02084)|null|
|**2024-08-23**|**S4D: Streaming 4D Real-World Reconstruction with Gaussians and 3D Control Points**|最近，使用高斯分布的动态场景重建引起了越来越多的兴趣。主流方法通常采用全局变形场来扭曲规范空间中的3D场景。然而，隐式神经场固有的低频特性往往导致复杂运动的无效表示。此外，它们的结构刚性会阻碍对不同分辨率和持续时间的场景的适应。为了克服这些挑战，我们引入了一种利用离散3D控制点的新方法。该方法对局部射线进行物理建模，并建立一个运动解耦坐标系，该坐标系有效地将传统图形与可学习的流水线相结合，以实现鲁棒且高效的局部6自由度（6-DoF）运动表示。此外，我们还开发了一个广义框架，将我们的控制点与高斯算子结合起来。从初始3D重建开始，我们的工作流程将流式4D真实世界重建分解为四个独立的子模块：3D分割、3D控制点生成、对象运动操纵和残差补偿。我们的实验表明，该方法在Neu3DV和CMU全景数据集上的表现优于现有的最先进的4D高斯散斑技术。我们的方法还显著加速了训练，在单个NVIDIA 4070 GPU上，每帧只需2秒即可优化我们的3D控制点。 et.al.|[2408.13036](http://arxiv.org/abs/2408.13036)|**[link](https://github.com/hebing-sjtu/S4D)**|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

