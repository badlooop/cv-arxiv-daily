---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.08.04
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-08-01**|**EmoTalk3D: High-Fidelity Free-View Synthesis of Emotional 3D Talking Head**|我们提出了一种合成具有可控情绪的3D对话头的新方法，该方法具有增强的嘴唇同步和渲染质量。尽管在该领域取得了重大进展，但现有方法仍然存在多视图一致性和缺乏情感表达的问题。为了解决这些问题，我们收集了带有校准的多视图视频、情感注释和每帧3D几何的EmoTalk3D数据集。通过在EmoTalk3D数据集上进行训练，我们提出了一个\textit{“语音到几何到外观”}映射框架，该框架首先从音频特征预测忠实的3D几何序列，然后从预测的几何中合成由4D高斯表示的3D说话头的外观。该外观进一步被分解为规范高斯和动态高斯，从多视图视频中学习，并融合以渲染自由视图说话的头部动画。此外，我们的模型能够在生成的说话头中实现可控的情绪，并且可以在宽范围的视图中呈现。我们的方法在嘴唇运动生成中表现出改进的渲染质量和稳定性，同时捕获了动态面部细节，如皱纹和微妙的表情。实验证明了我们的方法在生成高保真度和情绪可控的3D对话头方面的有效性。代码和EmoTalk3D数据集发布于https://nju-3dv.github.io/projects/EmoTalk3D. et.al.|[2408.00297](http://arxiv.org/abs/2408.00297)|null|
|**2024-08-01**|**Head360: Learning a Parametric 3D Full-Head for Free-View Synthesis in 360°**|创建人类头部的360度参数模型是一项非常具有挑战性的任务。虽然最近的进展已经证明了利用合成数据构建此类参数化头部模型的有效性，但它们在表情驱动动画、发型编辑和基于文本的修改等关键领域的性能仍然不足。在本文中，我们构建了一个艺术家设计的高保真人头数据集，并提出从中创建一个新的参数化360度可渲染参数化人头模型。我们的方案将面部运动/形状和面部外观解耦，分别由经典的参数化3D网格模型和附加的神经纹理表示。我们进一步提出了一种分解发型和面部外观的训练方法，允许自由交换发型。提出了一种基于单图像输入的具有高泛化和保真度的反演拟合方法。据我们所知，我们的模型是第一个在单个模型中实现360度自由视图合成、基于图像的拟合、外观编辑和动画的参数化3D全头模型。实验表明，面部运动和外观在参数空间中很好地解耦，从而在渲染和动画质量方面提高了SOTA的性能。代码和SynHead100数据集发布于https://nju-3dv.github.io/projects/Head360. et.al.|[2408.00296](http://arxiv.org/abs/2408.00296)|null|
|**2024-08-01**|**LoopSparseGS: Loop Based Sparse-View Friendly Gaussian Splatting**|尽管原始的3D高斯散点（3DGS）实现了逼真的新视图合成（NVS）性能，但其渲染质量在稀疏输入视图下会显著降低。这种性能下降主要是由于稀疏输入生成的初始点数量有限、训练过程中的监督不足以及超大高斯椭球体的正则化不足造成的。为了解决这些问题，我们提出了LoopSparseGS，这是一个基于循环的3DGS框架，用于稀疏新颖视图合成任务。具体来说，我们提出了一种基于循环的渐进高斯初始化（PGI）策略，该策略可以在训练过程中使用渲染的伪图像迭代加密初始化的点云。然后，利用运动结构的稀疏可靠深度和基于窗口的密集单眼深度，通过提出的深度对齐正则化（DAR）提供精确的几何监督。此外，我们引入了一种新的稀疏友好采样（SFS）策略来处理导致大像素误差的超大高斯椭球。在四个数据集上的综合实验表明，在各种图像分辨率的室内、室外和对象级场景中，LoopSparseGS在稀疏输入新视图合成方面优于现有的最先进方法。 et.al.|[2408.00254](http://arxiv.org/abs/2408.00254)|null|
|**2024-07-31**|**Forecasting Future Videos from Novel Views via Disentangled 3D Scene Representation**|空间和时间视频外推（VEST）使观众能够预测未来的3D场景，并从新颖的视角观看。最近的方法提出学习纠缠表示，旨在将分层场景几何、运动预测和新颖的视图合成建模在一起，同时假设每个场景层都有简化的仿射运动和基于单应性的扭曲，导致视频外推不准确。我们的方法不是纠缠的场景表示和渲染，而是选择通过将2D场景提升到3D点云来将场景几何体与场景运动分离，从而能够从新颖的视角对未来的视频进行高质量的渲染。为了模拟未来的3D场景运动，我们提出了一种解纠缠的两阶段方法，该方法首先预测自我运动，然后预测动态对象（如汽车、人）的残余运动。这种方法通过减少自我运动与动态物体运动纠缠的不准确性来确保更精确的运动预测，更好的自我运动预测可以显著提高视觉效果。对两个城市场景数据集的广泛实验分析表明，与强基线相比，我们提出的方法具有更优的性能。 et.al.|[2407.21450](http://arxiv.org/abs/2407.21450)|null|
|**2024-07-30**|**Dynamic Scene Understanding through Object-Centric Voxelization and Neural Rendering**|从无监督视频中学习以对象为中心的表示是具有挑战性的。与之前大多数专注于分解2D图像的方法不同，我们提出了一个名为DynaVol-S的3D生成模型，用于动态场景，该模型在可微体绘制框架内实现了以对象为中心的学习。其关键思想是执行以对象为中心的体素化，以捕捉场景的3D特性，从而推断单个空间位置的每个对象占用概率。这些体素特征通过规范空间变形函数演变，并在具有组合NeRF的逆渲染管道中进行优化。此外，我们的方法整合了2D语义特征来创建3D语义网格，通过多个解纠缠的体素网格来表示场景。DynaVol-S在动态场景的新颖视图合成和无监督分解任务中都明显优于现有模型。通过联合考虑几何结构和语义特征，它有效地解决了涉及复杂对象交互的具有挑战性的现实世界场景。此外，一旦经过训练，显式有意义的体素特征能够实现2D场景分解方法无法实现的额外功能，例如通过编辑几何形状或操纵对象的运动轨迹来生成新的场景。 et.al.|[2407.20908](http://arxiv.org/abs/2407.20908)|**[link](https://github.com/zyp123494/dynavol)**|
|**2024-07-29**|**Radiance Fields for Robotic Teleoperation**|神经辐射场（NeRFs）或3D高斯散斑（3DGS）等辐射场方法彻底改变了图形和新颖的视图合成。它们能够合成具有照片级真实感的新视点，以及捕捉复杂的体积和镜面场景，使其成为机器人遥操作设置的理想可视化工具。直接摄像机遥操作以牺牲机动性为代价提供高保真度操作，而基于重建的方法提供了保真度较低的可控场景。考虑到这一点，我们建议用在线辐射场取代机器人遥操作管道的传统重建可视化组件，提供具有照片级真实感的高度可操作场景。因此，对现有技术有三个主要贡献：（1）使用来自多个相机的实时数据对辐射场进行在线训练，（2）支持包括NeRF和3DGS在内的各种辐射方法，（3）这些方法的可视化套件，包括虚拟现实场景。为了实现与现有设置的无缝集成，这些组件在多种配置下用多个机器人进行了测试，并使用传统工具和VR耳机进行了显示。将不同方法和机器人的结果与网格重建的基线进行了定量比较，并进行了一项用户研究来比较不同的可视化方法。有关视频和代码，请查看https://leggedrobotics.github.io/rffr.github.io/. et.al.|[2407.20194](http://arxiv.org/abs/2407.20194)|**[link](https://github.com/leggedrobotics/rf_ros)**|
|**2024-07-25**|**Towards the Spectral bias Alleviation by Normalizations in Coordinate Networks**|最近，使用坐标网络表示信号主导了逆问题领域，并广泛应用于各种科学计算任务中。尽管如此，坐标网络中仍存在光谱偏差的问题，限制了学习高频分量的能力。这个问题是由坐标网络的神经切线核（NTK）特征值的病理分布引起的。我们发现，使用经典归一化技术（批归一化和层归一化）可以改善这种病理分布，这些技术通常用于卷积神经网络，但很少用于坐标网络。我们证明，归一化技术大大降低了NTK特征值的最大值和方差，同时略微修改了均值，考虑到最大特征值远大于最大值，这种方差变化导致特征值分布从较低的分布向较高的分布偏移，因此可以减轻谱偏差。此外，我们通过以不同的方式组合这两种技术，提出了两种新的归一化技术。通过将基于归一化的坐标网络应用于各种任务，包括图像压缩、计算机断层扫描重建、形状表示、磁共振成像、新视图合成和多视图立体重建，这些归一化技术的有效性得到了显著改进和最新技术水平的证实。 et.al.|[2407.17834](http://arxiv.org/abs/2407.17834)|**[link](https://github.com/aiolus-x/norm-inr)**|
|**2024-07-24**|**SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency**|我们提出了稳定视频4D（SV4D），这是一种用于多帧和多视图一致动态3D内容生成的潜在视频扩散模型。与之前依赖于单独训练的生成模型进行视频生成和新颖视图合成的方法不同，我们设计了一个统一的扩散模型来生成动态3D对象的新颖视图视频。具体来说，给定单眼参考视频，SV4D为每个视频帧生成时间上一致的新视图。然后，我们使用生成的新颖视图视频来有效地优化隐式4D表示（动态NeRF），而不需要大多数先前工作中使用的繁琐的基于SDS的优化。为了训练我们的统一新颖视图视频生成模型，我们从现有的Objaverse数据集中策划了一个动态3D对象数据集。多个数据集和用户研究的广泛实验结果表明，与先前的工作相比，SV4D在新视图视频合成和4D生成方面具有最先进的性能。 et.al.|[2407.17470](http://arxiv.org/abs/2407.17470)|null|
|**2024-07-24**|**Pose Estimation from Camera Images for Underwater Inspection**|高精度定位是水下复验任务的关键。惯性导航系统、多普勒速度记录仪和声学定位等传统定位方法面临着重大挑战，对于某些应用来说成本效益不高。在这种情况下，视觉定位是一种经济高效的替代方案，利用检查车辆上已经配备的摄像头从周围场景的图像中估计姿态。其中，基于机器学习的图像姿态估计在水下环境中显示出前景，使用基于先前映射场景训练的模型进行高效的重新定位。我们探索了基于学习的姿态估计器在清水和浑浊水检查任务中的有效性，评估了图像格式、模型架构和训练数据多样性的影响。我们通过采用新颖的视图合成模型来生成增强训练数据，从而显著增强了未探索区域的姿态估计。此外，我们通过扩展卡尔曼滤波器将姿态估计器输出与传感器数据相结合，提高了定位精度，证明了轨迹平滑度和精度的提高。 et.al.|[2407.16961](http://arxiv.org/abs/2407.16961)|null|
|**2024-07-29**|**DHGS: Decoupled Hybrid Gaussian Splatting for Driving Scene**|现有的高斯飞溅方法在驾驶场景中往往无法实现令人满意的新颖视图合成，这主要是由于所涉及的元素缺乏巧妙的设计和几何约束。本文介绍了一种新的神经渲染方法，称为解耦混合高斯散点（DHGS），旨在提高静态驾驶场景新型视图合成的渲染质量。这项工作的新颖之处在于，它为道路和非道路层提供了解耦和混合像素级混合器，而不需要为整个场景提供传统的统一可微渲染逻辑，同时通过提出的深度有序混合渲染策略仍然保持一致和连续的叠加。此外，对由符号距离场（SDF）组成的隐式道路表示进行训练，以监控具有微妙几何属性的路面。伴随着辅助透射率损失和一致性损失的使用，最终获得了具有不可察觉边界和高保真度的新图像。在Waymo数据集上进行的大量实验证明，DHGS的性能优于最先进的方法。提供更多视频证据的项目页面是：https://ironbrotherstyle.github.io/dhgs_web. et.al.|[2407.16600](http://arxiv.org/abs/2407.16600)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-07-30**|**NIS-SLAM: Neural Implicit Semantic RGB-D SLAM for 3D Consistent Scene Understanding**|近年来，神经内隐表示范式在同步定位和映射（SLAM）领域引起了广泛关注。然而，在场景理解方面，现有的方法存在明显的差距。本文介绍了NIS-SLAM，这是一种高效的神经隐式语义RGB-D SLAM系统，它利用预训练的2D分割网络来学习一致的语义表示。具体来说，为了实现高保真表面重建和空间一致的场景理解，我们将基于高频多分辨率四面体的特征和低频位置编码结合起来作为隐式场景表示。此外，为了解决多视图二维分割结果的不一致性，我们提出了一种融合策略，将先前非关键帧的语义概率整合到关键帧中，以实现一致的语义学习。此外，我们实现了一种基于置信度的像素采样和渐进优化权重函数，用于鲁棒的相机跟踪。在各种数据集上的广泛实验结果表明，与其他现有的神经密集隐式RGB-D SLAM方法相比，我们的系统具有更好或更具竞争力的性能。最后，我们还表明我们的方法可以用于增强现实应用。项目页面：\href{https://zju3dv.github.io/nis_slam}{https://zju3dv.github.io/nis\_砰。 et.al.|[2407.20853](http://arxiv.org/abs/2407.20853)|null|
|**2024-07-29**|**X-ray nano-holotomography reconstruction with simultaneous probe retrieval**|在传统的断层重建中，预处理步骤包括平场校正，其中探测器上的每个样本投影都除以没有样本的参考图像。当使用相干X射线作为探针时，这种方法忽略了照明场（探针）的相位分量，导致相位检索投影图像中的伪影，然后将伪影传播到重建的3D样本表示中。在使用聚焦光学元件的纳米全息断层扫描中，由于各种缺陷，探头功能中会产生高频分量，这一问题更加严重。在这里，我们提出了一种新的全断层摄影迭代重建方案，同时检索复值探测函数。该算法在GPU上实现，可实现3D重建，分辨率为使用纳米全息断层扫描测量的3D ALD标准样品中的两倍薄层。 et.al.|[2407.20304](http://arxiv.org/abs/2407.20304)|null|
|**2024-07-29**|**TeleOR: Real-time Telemedicine System for Full-Scene Operating Room**|远程医疗的出现代表了利用技术将专业医疗专业知识扩展到远程手术的变革性发展，在这个领域，专家指导的即时性至关重要。然而，手术室（OR）场景的复杂动态给远程医疗带来了独特的挑战，特别是在障碍物和带宽限制下实现高保真、实时的场景重建和传输。本文介绍了TeleOR，这是一个开创性的系统，旨在通过远程干预的实时OR场景重建来应对这些挑战。TeleOR以三种创新方法脱颖而出：动态自校准，利用固有的场景特征进行校准，无需预设标记，允许避障和实时调整相机；选择性OR重建，侧重于动态变化的场景片段，以降低重建复杂度；基于实时客户端反馈优化数据传输以在带宽限制内有效地提供高质量的3D重建。4D-OR手术场景数据集的综合实验证明了TeleOR的优越性和适用性，阐明了通过克服远程手术指导固有的空间和技术障碍来彻底改变远程干预的潜力。 et.al.|[2407.19763](http://arxiv.org/abs/2407.19763)|null|
|**2024-07-29**|**SALVE: A 3D Reconstruction Benchmark of Wounds from Consumer-grade Videos**|管理慢性伤口是一项全球性挑战，可以通过采用消费级视频的临床伤口评估自动系统来缓解。虽然2D图像分析方法不足以处理伤口的3D特征，但利用3D重建方法的现有方法尚未得到彻底评估。为了解决这一差距，本文对消费级视频的3D伤口重建进行了全面的研究。具体来说，我们介绍了SALVE数据集，其中包括用不同相机拍摄的逼真伤口幻影的视频记录。使用此数据集，我们评估了最先进的3D重建方法的准确性和精度，从传统的摄影测量管道到先进的神经渲染方法。在我们的实验中，我们观察到摄影测量方法不能提供适合精确临床测量伤口的光滑表面。神经渲染方法在解决这一问题方面显示出希望，推动了这项技术在伤口护理实践中的应用。 et.al.|[2407.19652](http://arxiv.org/abs/2407.19652)|null|
|**2024-07-28**|**Cycle3D: High-quality and Consistent Image-to-3D Generation via Generation-Reconstruction Cycle**|最近的3D大型重建模型通常采用两阶段过程，包括首先通过多视图扩散模型生成多视图图像，然后利用前馈模型将图像重建为3D内容。然而，多视图扩散模型通常会产生低质量和不一致的图像，对最终3D重建的质量产生不利影响。为了解决这个问题，我们提出了一种名为Cycle3D的统一3D生成框架，该框架在多步扩散过程中循环利用基于2D扩散的生成模块和前馈3D重建模块。具体而言，2D扩散模型用于生成高质量的纹理，重建模型保证了多视图的一致性。此外，2D扩散模型可以进一步控制生成的内容，并为看不见的视图注入参考视图信息，从而增强去噪过程中3D生成的多样性和纹理一致性。大量实验证明，与最先进的基线相比，我们的方法具有创建高质量和一致性的3D内容的卓越能力。 et.al.|[2407.19548](http://arxiv.org/abs/2407.19548)|null|
|**2024-07-27**|**A Bayesian Approach Toward Robust Multidimensional Ellipsoid-Specific Fitting**|这项工作提出了一种新颖有效的方法，用于在噪声和异常值污染的情况下将多维椭球体拟合到散射数据中。我们将该问题视为贝叶斯参数估计过程，并在给定数据的情况下最大化某个椭球解的后验概率。我们基于贝叶斯框架内的预测分布在这些点之间建立了更稳健的相关性。我们采用均匀的先验分布来约束在椭球域内搜索原始参数，确保无论输入如何，都能得到椭球特定的结果。然后，我们通过贝叶斯规则建立测量点和模型数据之间的连接，以增强该方法对噪声的鲁棒性。由于与空间维度无关，所提出的方法不仅为具有挑战性的细长椭球体提供了高质量的拟合，而且很好地推广到多维空间。为了解决以往方法经常忽视的异常值干扰，我们在预测分布的基础上进一步引入了均匀分布，以显著增强算法对异常值的鲁棒性。我们引入了一种加速技术，大大加快了EM的收敛速度。据我们所知，这是第一种能够在各种干扰下在贝叶斯优化范式内进行多维椭球体特定拟合的综合方法。我们在存在强噪声、异常值和轴比大幅变化的情况下，在低维和高维空间中对其进行评估。此外，我们将其应用于广泛的实际应用，如显微镜细胞计数、3D重建、几何形状近似和磁力计校准任务。 et.al.|[2407.19269](http://arxiv.org/abs/2407.19269)|**[link](https://github.com/zikai1/bayfit)**|
|**2024-07-26**|**Floating No More: Object-Ground Reconstruction from a Single Image**|从单个图像重建3D对象的最新进展主要集中在提高对象形状的准确性上。然而，这些技术往往无法准确捕捉物体、地面和相机之间的相互关系。因此，当放置在平面上时，重建的对象通常会出现浮动或倾斜。这一限制严重影响了3D感知图像编辑应用程序，如阴影渲染和对象姿态操纵。为了解决这个问题，我们引入了ORG（地面对象重建），这是一项旨在结合地面重建3D对象几何的新任务。我们的方法使用两个紧凑的像素级表示来描述相机、物体和地面之间的关系。实验表明，与传统的单图像3D重建技术相比，所提出的ORG模型可以在看不见的数据上有效地重建目标地面几何，显著提高了阴影生成和姿态操纵的质量。 et.al.|[2407.18914](http://arxiv.org/abs/2407.18914)|null|
|**2024-07-26**|**IOVS4NeRF:Incremental Optimal View Selection for Large-Scale NeRFs**|现代应用的城市级三维重建需要高渲染保真度，同时最大限度地降低计算成本。神经辐射场（NeRF）的出现增强了3D重建，但它在多个视点下表现出伪影。本文提出了一种新的NeRF框架方法来解决这些问题。我们的方法使用图像内容和姿势数据来迭代地规划下一个最佳视图。该方法的一个关键方面涉及不确定性估计，指导从候选集中选择具有最大信息增益的视图。随着时间的推移，这种迭代过程提高了渲染质量。同时，我们引入了Vonoroi图和阈值采样以及飞行分类器，以提高效率，同时保持原始NeRF网络的完整性。它可以作为一个插件工具来帮助更好的渲染，优于基线和类似的先前工作。 et.al.|[2407.18611](http://arxiv.org/abs/2407.18611)|null|
|**2024-07-25**|**UMono: Physical Model Informed Hybrid CNN-Transformer Framework for Underwater Monocular Depth Estimation**|水下单目深度估计是水下场景三维重建等任务的基础。然而，由于光和介质的影响，水下环境经历了独特的成像过程，这给从单幅图像中准确估计深度带来了挑战。现有的方法未能考虑水下环境的独特特征，导致估计结果不足，泛化性能有限。此外，水下深度估计需要提取和融合局部和全局特征，这在现有方法中没有得到充分探索。本文提出了一种用于水下单目深度估计的端到端学习框架UMono，该框架将水下图像形成模型特征融入网络架构，有效地利用了水下图像的局部和全局特征。实验结果表明，该方法对水下单目深度估计是有效的，在定量和定性分析方面都优于现有方法。 et.al.|[2407.17838](http://arxiv.org/abs/2407.17838)|null|
|**2024-07-24**|**SMA-Hyper: Spatiotemporal Multi-View Fusion Hypergraph Learning for Traffic Accident Prediction**|预测交通事故是可持续城市管理的关键，这需要有效解决城市的动态和复杂的时空特征。当前的数据驱动模型经常与数据稀疏性作斗争，通常忽视了不同城市数据源的集成及其内部的高阶依赖关系。此外，它们经常依赖于预定义的拓扑或权重，限制了它们在时空预测中的适应性。为了解决这些问题，我们引入了时空多视图自适应超图学习（SMA Hyper）模型，这是一种为交通事故预测设计的动态深度学习框架。基于先前的研究，这一创新模型结合了双重自适应时空图学习机制，通过超图和动态适应不断变化的城市数据，实现了高阶跨区域学习。它还利用对比学习来增强稀疏数据集中的全局和局部数据表示，并采用预先注意机制来融合事故数据和城市功能特征的多种视图，从而丰富了对风险因素的上下文理解。对伦敦交通事故数据集的广泛测试表明，SMA Hyper模型在各种时间范围和多步输出方面明显优于基线模型，证实了其多视图融合和自适应学习策略的有效性。结果的可解释性进一步强调了其通过利用复杂的时空城市数据来改善城市交通管理和安全的潜力，提供了一个适应不同城市环境的可扩展框架。 et.al.|[2407.17642](http://arxiv.org/abs/2407.17642)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-08-01**|**Optimizing Diffusion Models for Joint Trajectory Prediction and Controllable Generation**|扩散模型在自动驾驶中的联合轨迹预测和可控生成方面很有前景，但它们面临着推理步骤效率低和计算要求高等挑战。为了应对这些挑战，我们引入了最优高斯扩散（OGD）和估计清洁歧管（ECM）制导。OGD优化了小扩散时间 $T$ 的先验分布，并从中开始反向扩散过程。ECM直接将制导梯度注入估计的干净流形，消除了整个网络中广泛的梯度反向传播。我们的方法简化了生成过程，使实际应用能够减少计算开销。在大规模Argoverse 2数据集上的实验验证证明了我们的方法的卓越性能，为计算高效、高质量的关节轨迹预测和自动驾驶可控生成提供了可行的解决方案。我们的项目网页位于https://yixiaowang7.github.io/OptTrajDiff_Page/. et.al.|[2408.00766](http://arxiv.org/abs/2408.00766)|null|
|**2024-08-01**|**Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention**|条件扩散模型在视觉内容生成方面取得了显著成功，在各个领域产生了高质量的样本，这在很大程度上归功于无分类器引导（CFG）。最近将指导扩展到无条件模型的尝试依赖于启发式技术，导致生成质量欠佳和意外影响。在这项工作中，我们提出了平滑能量引导（SEG），这是一种新的无训练和无条件的方法，利用基于能量的自我注意机制来增强图像生成。通过定义自我注意的能量，我们引入了一种减少注意能量景观曲率的方法，并将输出作为无条件预测。在实际应用中，我们通过调整高斯核参数来控制能量景观的曲率，同时保持制导尺度参数不变。此外，我们提出了一种查询模糊方法，该方法相当于模糊整个注意力权重，而不会导致令牌数量的二次复杂度。在我们的实验中，SEG在质量和副作用减少方面都实现了帕累托改进。代码位于\url{https://github.com/SusungHong/SEG-SDXL}. et.al.|[2408.00760](http://arxiv.org/abs/2408.00760)|null|
|**2024-08-01**|**TurboEdit: Text-Based Image Editing Using Few-Step Diffusion Models**|扩散模型为各种基于文本的图像编辑框架开辟了道路。然而，这些通常建立在反向扩散过程的多步骤性质之上，并且将其适应蒸馏的快速采样方法已被证明具有令人惊讶的挑战性。在这里，我们重点介绍一种流行的基于文本的编辑框架——“编辑友好”的DDPM噪声反转方法。我们分析了它在快速采样方法中的应用，并将其失败分为两类：视觉伪影的出现和编辑强度不足。我们将伪影追溯到反转噪声和预期噪声调度之间的不匹配噪声统计，并建议采用偏移噪声调度来校正这种偏移。为了提高编辑强度，我们提出了一种伪制导方法，该方法在不引入新伪影的情况下有效地增加了编辑的幅度。总而言之，我们的方法只需三个扩散步骤即可实现基于文本的图像编辑，同时为流行的基于文本的编辑方法背后的机制提供了新的见解。 et.al.|[2408.00735](http://arxiv.org/abs/2408.00735)|null|
|**2024-08-01**|**ISDE with logarithmic interaction and characteristic polynomials**|我们考虑某些随机矩阵特征值动力学，类似于Rider和Valko引入的戴森布朗运动。我们证明，从每个初始条件，包括涉及重合坐标的初始条件，经过更多信息的增强，动力学在路径空间上收敛到无限维的Feller连续扩散过程。我们证明了极限扩散求解具有对数相互作用的无限维随机微分方程组（ISDE）。此外，我们证明了从任何初始条件到平衡测度的无限维动力学的长期极限的收敛性，该平衡测度由贝塞尔行列式点过程的逆点给出。据我们所知，这是：（a）从每个初始条件到无限维Feller扩散的随机矩阵动力学的第一个路径空间收敛结果，（b）从每个可以在时间 $0$ 定义奇异漂移项的初始条件到具有对数相互作用的ISDE解的第一个构造，（c）对于这种ISDE，从每个初始状态到平衡的第一个收敛结果。争论分为两部分。第一部分以鲍罗丁和奥尔尚斯基引入和发展的交织器方法为基础。主要的新成分是在某种意义上，由无限维空间索引的随机矩阵族的谱的统一近似定理，以及处理收敛到平衡的交织器方法的扩展。第二部分介绍了一种新的方法，用于收敛动力学中的奇异漂移项，并通过与该过程相关的某些“特征多项式”显示极限路径的非交集。我们相信，它的变体将适用于来自随机矩阵的其他无限维动力学。 et.al.|[2408.00717](http://arxiv.org/abs/2408.00717)|null|
|**2024-08-01**|**MotionFix: Text-Driven 3D Human Motion Editing**|本文的重点是三维运动编辑。给定3D人体运动和所需修改的文本描述，我们的目标是生成文本描述的编辑运动。挑战包括缺乏训练数据和设计一个忠实编辑源运动的模型。在本文中，我们将解决这两个挑战。我们构建了一种方法，以（i）源运动、（ii）目标运动和（iii）编辑文本的形式半自动收集三元组数据集，并创建新的MotionFix数据集。访问这些数据使我们能够训练一个条件扩散模型TMED，该模型将源运动和编辑文本都作为输入。我们进一步构建了仅在文本运动对数据集上训练的各种基线，并展示了我们在三元组上训练的模型的卓越性能。我们引入了新的基于检索的运动编辑度量，并在MotionFix的评估集上建立了一个新的基准。我们的研究结果令人鼓舞，为进一步研究细粒度运动生成铺平了道路。代码和模型将公开。 et.al.|[2408.00712](http://arxiv.org/abs/2408.00712)|null|
|**2024-08-01**|**Alpha-VI DeepONet: A prior-robust variational Bayesian approach for enhancing DeepONets with uncertainty quantification**|我们介绍了一种新的深度算子网络（DeepONet）框架，该框架结合了广义变分推理（GVI），使用R’enyi的 $\alpha$-散度来学习复杂算子，同时量化不确定性。通过将贝叶斯神经网络作为分支和主干网络的构建块，我们的框架赋予了DeepONet不确定性量化。使用R'enyi的$\alpha$-散度，而不是标准变分推理中常用的Kullback-Leibler散度（KLD），可以缓解与变分贝叶斯DeepONets中普遍存在的先前错误指定相关的问题。这种方法提供了增强的灵活性和鲁棒性。我们证明，修改变分目标函数在最小化均方误差和提高测试集上的负对数似然性方面会产生更好的结果。我们的框架的有效性在各种机械系统中得到了验证，在预测准确性和不确定性量化方面，它优于基于确定性和标准KLD的VI DeepONets。可以调整控制鲁棒性程度的超参数$\alpha$，以优化特定问题的性能。我们将这种方法应用于一系列力学问题，包括重力摆、平流扩散和扩散反应系统。我们的研究结果强调了$\alpha$ -VI DeepONet在推进数据驱动的算子学习领域及其在工程和科学领域的应用方面的潜力。 et.al.|[2408.00681](http://arxiv.org/abs/2408.00681)|null|
|**2024-08-01**|**Evaluation Metrics and Methods for Generative Models in the Wireless PHY Layer**|生成模型通常通过直接检查其生成的样本来评估，例如，在图像的情况下通过目视检查。进一步的评估指标，如Fr’echet起始距离或最大平均差异，解释起来很复杂，缺乏物理动机。这些观察结果使得评估无线PHY层中的生成模型变得非常重要。这项工作建立了一个由应用于无线PHY层的生成模型的评估指标和方法组成的框架。所提出的度量和方法是由无线应用驱动的，有助于无线社区的解释和理解。特别是，我们提出了一种用于验证生成的信道规范的频谱效率分析和一种用于确认生成的信道方向的码本指纹识别方法。此外，我们提出了一种应用交叉检查来评估生成模型的样本，以便在相关的下游任务中训练基于机器学习的模型。我们的分析基于真实世界的测量数据，包括高斯混合模型、变分自编码器、扩散模型和生成对抗网络作为生成模型。我们在模型架构方面进行公平比较的结果表明，仅依赖最大平均差异等指标会产生不充分的评估结果。相比之下，所提出的度量和方法表现出一致和可解释的行为。 et.al.|[2408.00634](http://arxiv.org/abs/2408.00634)|null|
|**2024-08-01**|**Generalised BBGKY hierarchy for near-integrable dynamics**|我们考虑量子或经典多体哈密顿系统，其动力学由可积的接触相互作用加上另一个可能长程的通用二体势给出。我们展示了如何根据Bogoliubov-Born-Green-Kirkwood-Yvon层次的广义版本给出局部可观测的动力学，我们将其表示为gBBGKY，它是为基础可积模型的准粒子的密度及其相关性而建立的。与自由气体微扰理论的常见情况不同，可积模型中局部相互作用的存在“解除”了所谓的动力学阻塞，层次结构的第二层在所有时间尺度上再现了动力学。后者包括快速预平衡到非热稳态，以及随后热化到吉布斯系综。我们展示了最终的弛豫是如何被编码为涉及三个或更高体散射的玻尔兹曼散射积分的，值得注意的是，这完全取决于底层可积模型的扩散常数。我们用精确的分子动力学模拟来检验我们的结果，发现完全一致。我们的结果表明，gBBGKY如何在量子系统中成功用于计算散射积分和费米黄金法则跃迁率。 et.al.|[2408.00593](http://arxiv.org/abs/2408.00593)|null|
|**2024-08-01**|**Conditional Independence in Stationary Diffusions**|多元扩散过程的平稳分布最近被提出作为统计学和机器学习中因果系统的概率模型。受这些发展的启发，我们研究了具有稀疏结构漂移的平稳多元扩散过程。我们的主要结果给出了保持平稳分布的条件独立关系的特征。结果基于漂移结构的图形表示，并与条件独立关系有关，这些关系通常是漂移稀疏模式的结果。 et.al.|[2408.00583](http://arxiv.org/abs/2408.00583)|null|
|**2024-08-01**|**Dimension reduction for large-scale stochastic systems with non-zero initial states and controlled diffusion**|本文建立了新的策略来降低具有非零初始状态的大规模受控随机微分方程的维数。第一种方法将原始设置转换为初始状态为零的随机系统。这种转换自然会导致具有受控扩散的方程。在这个受控扩散框架中，我们详细分析了约化误差的主要子空间和界。随后，我们为原始框架引入了一个约化系统，并证明了第一个假设的先验误差界。这个界限涉及所谓的汉克尔奇异值，这些奇异值与一对新的格拉姆函数有关。提出了第二种策略，该策略基于分别减少控制和初始状态动力学的思想。在这里，使用不同的Gramian来推导一个简化模型，并指出了它们与优势子空间的关系。我们还展示了涉及两种Hankel奇异值的第二种方法的后验误差界。 et.al.|[2408.00581](http://arxiv.org/abs/2408.00581)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-08-01**|**Neural Octahedral Field: Octahedral prior for simultaneous smoothing and sharp edge regularization**|神经隐式表示，将距离函数参数化为坐标神经场，已成为解决无方向点云表面重建的有前景的前沿。为了确保方向一致，现有的方法侧重于正则化距离函数的梯度，例如将其约束为单位范数，最小化其散度，或将其与对应于零特征值的Hessian特征向量对齐。然而，在存在大扫描噪声的情况下，它们往往要么过拟合噪声输入，要么产生过于平滑的重建。在这项工作中，我们建议利用六面体网格中产生的八面体框架的球谐表示，在一种新的神经场变体——八面体场下指导曲面重建。当约束为平滑时，该字段会自动捕捉到几何特征，并在折痕上插值时自然保留锐角。通过同时拟合和平滑隐式几何旁边的八面体场，它的行为类似于双边滤波，从而在保持锐边的同时实现平滑重建。尽管是纯逐点操作，但我们的方法在广泛的实验中表现优于各种传统和神经方法，并且与需要正常和数据先验的方法非常有竞争力。我们的全面实施可在以下网址获得：https://github.com/Ankbzpx/frame-field. et.al.|[2408.00303](http://arxiv.org/abs/2408.00303)|null|
|**2024-07-30**|**Neural Fields for Continuous Periodic Motion Estimation in 4D Cardiovascular Imaging**|时间分辨三维血流MRI（4D血流MRI）提供了一种独特的非侵入性解决方案，用于可视化和量化主动脉弓等血管中的血流动力学。然而，由于难以获得完整的周期分割，目前大多数动脉4D血流MRI分析方法使用静态动脉壁。为了克服这一局限性，我们提出了一种基于神经场的方法，可以直接估计整个心动周期中连续的周期性壁变形。对于3D+时间成像数据集，我们优化了表示时间依赖速度矢量场（VVF）的隐式神经表示（INR）。ODE求解器用于将VVF集成到变形矢量场（DVF）中，该矢量场可以随着时间的推移使图像、分割掩模或网格变形，从而可视化和量化局部壁运动模式。为了正确反映3D+时间心血管数据的周期性，我们以两种方式施加周期性。首先，通过定期对输入到INR的时间进行编码，从而对VVF进行编码。其次，通过规范DVF。我们证明了这种方法在不同周期模式的合成数据、心电图门控CT和4D血流MRI数据上的有效性。所获得的方法可用于改进4D血流MRI分析。 et.al.|[2407.20728](http://arxiv.org/abs/2407.20728)|null|
|**2024-07-29**|**Aero-Nef: Neural Fields for Rapid Aircraft Aerodynamics Simulations**|本文提出了一种基于隐式神经表示（INR）在网格域上学习稳态流体动力学模拟替代模型的方法。所提出的模型可以直接应用于不同流动条件下的非结构化域，处理非参数3D几何变化，并推广到测试时看不见的形状。基于坐标的公式自然会导致离散化的鲁棒性，从而在计算成本（内存占用和训练时间）和精度之间实现了极好的权衡。该方法在两个工业相关应用中得到了验证：跨音速翼型上二维可压缩流的RANS数据集和三维机翼上表面压力分布的数据集，包括形状、流入条件和控制表面偏转变化。在所考虑的测试用例中，与最先进的图神经网络架构相比，我们的方法实现了三倍多的测试误差，并显著改善了看不见的几何形状的泛化误差。值得注意的是，该方法在RANS跨音速翼型数据集上的推理速度比高保真求解器快五个数量级。代码可在以下网址获得https://gitlab.isae-supaero.fr/gi.catalani/aero-nepf et.al.|[2407.19916](http://arxiv.org/abs/2407.19916)|null|
|**2024-07-26**|**ObjectCarver: Semi-automatic segmentation, reconstruction and separation of 3D objects**|隐式神经场在从多幅图像重建3D表面方面取得了显著进展；然而，在分离场景中的单个对象时，他们遇到了挑战。之前的工作试图通过引入一个框架来解决这个问题，该框架为N个对象中的每一个同时训练单独的带符号距离场（SDF），并使用正则化项来防止对象重叠。然而，所有这些方法都需要提供分割掩模，这并不总是容易获得的。我们介绍了我们的方法ObjectCarver，来解决在单个视图中从点击输入中分离对象的问题。给定摆出的多视图图像和一组用户输入点击来提示分割单个对象，我们的方法将场景分解为单独的对象，并为每个对象重建高质量的3D表面。我们引入了一个损失函数，可以防止漂浮物，避免因遮挡而造成不适当的雕刻。此外，我们引入了一种新的场景初始化方法，与之前的方法相比，该方法在保留几何细节的同时显著加快了过程。尽管不需要地面真实掩模或单眼线索，但我们的方法在定性和定量上都优于基线。此外，我们引入了一个新的基准数据集进行评估。 et.al.|[2407.19108](http://arxiv.org/abs/2407.19108)|null|
|**2024-07-24**|**Neural field equations with time-periodic external inputs and some applications to visual processing**|这项工作的目的是为研究视觉处理任务中的闪烁输入提供一个数学框架。当与几何图案结合时，这些输入会影响并诱发有趣的心理物理现象，如麦凯效应和比洛克-邹效应，在这些效应中，受试者感知到通常由闪烁频率调制的特定余像。由于输入的对称破缺结构，经典分叉理论和多尺度分析技术在我们的背景下不是很有效。因此，我们采用了一种基于Amari型神经场控制理论的输入-输出框架的方法。这使我们能够证明，当受到周期性输入的驱动时，动态会收敛到周期性状态。此外，我们研究了在哪些假设下，这些非线性动力学可以有效地线性化，在这种情况下，我们提出了短程兴奋性和远程抑制性神经元相互作用的积分核的精确近似值。最后，对于集中在具有闪烁背景的视野中心的输入，我们直接将余像中出现的虚幻轮廓的宽度与闪烁频率和抑制强度联系起来。 et.al.|[2407.17294](http://arxiv.org/abs/2407.17294)|null|
|**2024-07-23**|**Fluorescence Diffraction Tomography using Explicit Neural Fields**|从荧光图像中求解3D折射率（RI）可以提供有关生物样本的荧光和相位信息。然而，在大体积、高分辨率和反射模式下准确检索部分相干光的相位以重建无标签相位物体的未知RI仍然具有挑战性。为了应对这一挑战，我们开发了具有显式神经场的荧光衍射断层扫描（FDT），可以从散焦荧光散斑图像重建3D RI。使用FDT成功重建3D RI依赖于四个关键组件：粗到细建模、自校准、差分多层渲染模型和部分相干掩模。具体而言，显式表示与粗到细建模有效地集成在一起，以实现高速、高分辨率的重建。此外，我们将多层方程推进到微分多层渲染模型，这使得系统的外部和内部参数能够进行自校准。自校准有助于高精度的正向图像预测和RI重建。部分相干掩模是数字掩模，用于准确有效地解决相干光模型和部分相干光数据之间的差异。FDT成功地从荧光图像中重建了24个z $层上1024$×1024像素的530$×530$×300$μm^3$ 体积的3D培养无标记3D MuSCs管的RI，证明了在体外对体积庞大和异质的生物样本进行高保真3D RI重建。 et.al.|[2407.16657](http://arxiv.org/abs/2407.16657)|null|
|**2024-07-22**|**Iterative approach to reconstructing neural disparity fields from light-field data**|本研究提出了一种神经视差场（NDF），该场基于神经场建立了场景视差的隐式连续表示，并采用迭代方法解决了从光场数据重建NDF的逆问题。NDF能够无缝和精确地表征三维场景中的视差变化，并可以以任何任意分辨率对视差进行离散化，克服了传统视差图容易出现采样误差和插值不准确的局限性。所提出的NDF网络架构利用哈希编码结合多层感知器来捕获纹理级别的详细差异，从而增强其表示复杂场景几何信息的能力。通过利用光场数据中固有的空间角度一致性，开发了一种可微分正向模型，用于从光场数据生成中心视图图像。基于正向模型，建立了一种使用可微传播算子的NDF重建逆问题的优化方案。此外，在优化方案中，采用迭代求解方法重建NDF，该方法不需要训练数据集，适用于各种采集方法捕获的光场数据。实验结果表明，使用所提出的方法可以从光场数据中重建高质量的NDF。NDF可以有效地恢复高分辨率视差，证明了其隐式、连续表示场景视差的能力。 et.al.|[2407.15380](http://arxiv.org/abs/2407.15380)|null|
|**2024-07-19**|**Contextual modulation of language comprehension in a dynamic neural model of lexical meaning**|我们提出并计算实现了一个词汇意义的动态神经模型，并对其行为预测进行了实验测试。我们使用英语词汇“have”作为测试用例来演示模型的架构和行为，重点关注其多义词的使用。在该模型中，“have”映射到由两个连续的概念维度（连通性和控制不对称性）定义的语义空间，这两个维度之前被提出用于参数化语言的概念系统。映射被建模为表示词条的神经节点和表示概念维度的神经场之间的耦合。虽然词汇知识被建模为稳定的耦合模式，但实时词汇意义检索被建模为神经激活模式在对应于语义解释或阅读的亚稳态之间的运动。模型模拟捕捉到了两个先前报道的实证观察结果：（1）词汇语义解释的语境调制，以及（2）这种调制幅度的个体差异。模拟还产生了一种新的预测，即句子阅读时间和可接受性之间的试验关系应该根据上下文进行调节。结合自定进度阅读和可接受性判断的实验复制了之前的结果，并证实了新的模型预测。总之，研究结果支持了一种关于词汇多义的新观点：一个词的许多相关含义是亚稳态的神经激活状态，这是由控制连续语义维度解释的神经群体的非线性动力学引起的。 et.al.|[2407.14701](http://arxiv.org/abs/2407.14701)|null|
|**2024-07-18**|**MeshFeat: Multi-Resolution Features for Neural Fields on Meshes**|参数特征网格编码作为神经场的编码方法受到了广泛关注，因为它们允许更小的MLP，这大大缩短了模型的推理时间。在这项工作中，我们提出了MeshFeat，这是一种针对网格量身定制的参数特征编码，为此我们采用了欧几里德空间的多分辨率特征网格的思想。我们从给定顶点拓扑提供的结构开始，使用网格简化算法直接在网格上构建多分辨率特征表示。该方法允许在网格上的神经场中使用小MLP，与之前的表示相比，我们显示出显著的加速，同时保持了纹理重建和BRDF表示的可比重建质量。鉴于其与顶点的内在耦合，该方法特别适用于变形网格上的表示，使其非常适合对象动画。 et.al.|[2407.13592](http://arxiv.org/abs/2407.13592)|null|
|**2024-07-16**|**Adaptive Environment-Aware Robotic Arm Reaching Based on a Bio-Inspired Neurodynamical Computational Framework**|仿生机器人系统具有自适应学习、可扩展控制和高效信息处理的能力。为这些系统提供实时决策对于应对环境的动态变化至关重要。我们专注于在开放区域使用带有鸟瞰摄像头的机器人六自由度操纵器进行动态目标跟踪，并部署神经动力学计算框架（NeuCF）进行视觉反馈。NeuCF是最近开发的一种基于动态神经场（DNF）和随机最优控制（SOC）理论的仿生目标跟踪模型。它已经过训练，可以在平面上对局部视觉信标进行到达动作，并且可以根据环境的变化（例如，出现了新的目标，或者删除了现有的目标）实时重新定位或生成停止信号。我们在各种目标达成场景下评估了我们的系统。在所有实验中，与基线三次多项式轨迹生成器相比，NeuCF具有较高的末端执行器位置精度，生成了平滑的轨迹，并提供了更短的路径长度。总之，开发的系统提供了一种强大的、动态感知的机器人操纵方法，可以提供实时决策。 et.al.|[2407.11377](http://arxiv.org/abs/2407.11377)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

