---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.06.30
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-27**|**360 in the Wild: Dataset for Depth Prediction and View Synthesis**|大量的透视相机数据集促进了用于各种任务的新的基于学习的策略的出现，如相机定位、单图像深度估计或视图合成。然而，全景或全向图像数据集，包括姿势和深度等基本信息，大多是用合成场景制作的。在这项工作中，我们介绍了一个大规模的野外360 $^｛\circ｝$ 视频数据集。这个数据集是从互联网上仔细收集的，并从世界各地捕获。因此，该数据集展示了非常多样化的环境（例如，室内和室外）和上下文（例如，有和没有移动物体）。构成我们数据集的25K幅图像中的每一幅都提供了其各自相机的姿势和深度图。我们说明了我们的数据集与两个主要任务的相关性，即单图像深度估计和视图合成。 et.al.|[2406.18898](http://arxiv.org/abs/2406.18898)|null|
|**2024-06-26**|**Dynamic Gaussian Marbles for Novel View Synthesis of Casual Monocular Videos**|高斯散射已经成为新视图合成的一种流行表现，在效率、光度质量和成分可食性方面表现出明显的优势。在其成功之后，许多工作已经将高斯扩展到4D，表明动态高斯保持了这些优势，同时也比替代表示更好地跟踪场景几何。然而，这些方法假设密集的多视图视频作为监督，限制了它们在受控捕捉设置中的使用。在这项工作中，我们将高斯场景表示的能力扩展到随意捕捉的单目视频。我们表明，现有的4D高斯方法在这种设置中显著失败，因为单目设置约束不足。基于这一发现，我们提出了动态高斯大理石（DGMarbles），由三个核心修改组成，针对单目设置的困难。首先，DGMarbles使用各向同性的高斯“弹珠”，减少每个高斯的自由度，并将优化约束为关注局部形状的运动和外观。其次，DGMarbles采用分层分治学习策略来引导优化朝着具有连贯运动的解决方案前进。最后，DGMarbles将图像级和几何级先验添加到优化中，包括利用点跟踪的最新进展的跟踪损失。通过以这些方式约束优化，DGMarbles学习高斯轨迹，从而实现新颖的视图渲染并准确捕捉场景元素的3D运动。我们在（单眼）Nvidia Dynamic Scenes数据集和Dycheck iPhone数据集上进行了评估，结果表明DGMarbles在质量上显著优于其他高斯基线，与非高斯表示不相上下，同时保持了高斯的效率、合成性、可编辑性和跟踪优势。 et.al.|[2406.18717](http://arxiv.org/abs/2406.18717)|null|
|**2024-06-26**|**MultiDiff: Consistent Novel View Synthesis from a Single Image**|我们介绍了MultiDiff，这是一种从单个RGB图像中对场景进行一致新颖视图合成的新方法。从单个参考图像合成新视图的任务是自然造成的，因为对未观察到的区域存在多种看似合理的解释。为了解决这个问题，我们以单目深度预测器和视频扩散模型的形式结合了强先验。单目深度使我们能够根据目标视图的扭曲参考图像来调整模型，从而提高几何稳定性。视频扩散先验为3D场景提供了强大的代理，允许模型学习生成图像之间的连续和像素精确的对应关系。与依赖于易于漂移和误差累积的自回归图像生成的方法不同，MultiDiff联合合成一系列帧，从而产生高质量和多视图一致的结果——即使是对于具有大相机移动的长期场景生成，同时将推理时间减少一个数量级。为了进一步提高一致性和图像质量，我们引入了一种新颖的结构化噪声分布。我们的实验结果表明，MultiDiff在具有挑战性的真实世界数据集RealEstate10K和ScanNet上优于最先进的方法。最后，我们的模型自然支持多视图一致性编辑，而无需进一步调整。 et.al.|[2406.18524](http://arxiv.org/abs/2406.18524)|null|
|**2024-06-27**|**XLD: A Cross-Lane Dataset for Benchmarking Novel Driving View Synthesis**|彻底测试自动驾驶系统对于追求安全的自动驾驶汽车至关重要。这就需要创建超出现实世界数据安全收集范围的安全关键场景，因为其中许多场景在公共道路上很少发生。然而，大多数现有NVS方法的评估依赖于对来自训练数据的图像帧的零星采样，使用度量将渲染图像与真实图像进行比较。遗憾的是，该评估协议不能满足闭环仿真的实际要求。具体而言，真正的应用程序需要渲染超出原始轨迹的新颖视图（如跨车道视图）的能力，而这些视图在现实世界中很难捕捉。为了解决这一问题，本文提出了一种专门为自动驾驶模拟设计的新型驾驶视图合成数据集和基准。该数据集是独特的，因为它包括通过偏离训练轨迹1-4米而捕获的测试图像。它包括六个序列，包括不同的时间和天气条件。每个序列包含450个训练图像、150个测试图像以及它们对应的相机姿态和固有参数。利用这一新颖的数据集，我们建立了第一个现实的基准，用于在仅前置和多摄像头设置下评估现有的NVS方法。实验结果强调了当前方法中存在的显著差距，揭示了它们不足以满足跨车道或闭环模拟的苛刻先决条件。我们的数据集在项目页面上公开发布：https://3d-aigc.github.io/XLD/. et.al.|[2406.18360](http://arxiv.org/abs/2406.18360)|null|
|**2024-06-26**|**VDG: Vision-Only Dynamic Gaussian for Driving Simulation**|动态高斯飞溅已经在新颖的视图中带来了令人印象深刻的场景重建和图像合成进展。然而，现有的方法在很大程度上依赖于预先计算的姿态和通过运动结构（SfM）算法或昂贵的传感器进行的高斯初始化。本文首次通过将自监督VO集成到我们的无姿态动态高斯方法（VDG）中来解决这个问题，以促进姿态和深度初始化以及静态动态分解。此外，与无姿态动态视图合成方法相比，VDG可以仅使用RGB图像输入，以更快的速度和更大的场景构建动态场景。我们通过大量的定量和定性实验证明了我们的方法的稳健性。与最先进的动态视图合成方法相比，我们的结果显示出良好的性能。其他视频和源代码将发布在我们的项目页面上https://3d-aigc.github.io/VDG. et.al.|[2406.18198](http://arxiv.org/abs/2406.18198)|null|
|**2024-06-26**|**View-Invariant Pixelwise Anomaly Detection in Multi-object Scenes with Adaptive View Synthesis**|基础设施资产的检查和监控通常需要识别随着时间的推移定期拍摄的场景中的视觉异常。手动或使用机器人（如无人机）在不同时间点从同一场景收集的图像通常不会完全对齐。有监督的分割方法可以用于识别已知问题，但当出现未知异常时，需要无监督的异常检测方法。当前的无监督像素级异常检测方法主要是针对相机位置已知且恒定的工业环境开发的。然而，我们发现这些方法不能推广到图像没有完全对齐的情况。我们将两组不完全对齐的图像之间的无监督异常检测问题称为场景异常检测（Scene AD）。我们提出了一种称为OmniAD的新型网络来解决场景AD问题。具体来说，我们改进了异常检测方法反向蒸馏，以实现像素级异常检测性能提高40%。提出了两种新的数据增强策略，利用新颖的视图合成和相机定位来提高泛化能力，进一步证明了网络的性能得到了改善。我们在新的数据集ToyCity上验证了我们的方法，ToyCity是第一个具有多个对象的场景广告数据集，以及在已建立的以单个对象为中心的数据集MAD上验证了定性和定量结果。https://drags99.github.io/OmniAD/ et.al.|[2406.18012](http://arxiv.org/abs/2406.18012)|null|
|**2024-06-25**|**NerfBaselines: Consistent and Reproducible Evaluation of Novel View Synthesis Methods**|新颖的视图合成是许多应用中的一个重要问题，包括AR/VR、游戏和机器人模拟。随着神经辐射场（NeRF）和3D高斯散射（3DGS）方法的快速发展，由于使用不同评估协议的方法、难以安装和使用的代码库以及不能很好地推广到新的3D场景的方法，跟踪当前技术状态（SoTA）变得越来越困难。我们的实验支持了这一说法，表明各种方法的评估协议之间的微小差异可能导致报告的指标不一致。为了解决这些问题，我们提出了一个名为NerfBaselines的框架，它简化了各种方法的安装，提供了一致的基准测试工具，并确保了可重复性。我们通过复制原始论文中报告的数字来实验验证我们的实现。为了进一步提高可访问性，我们发布了一个网络平台，在标准基准上对常用方法进行比较。网状物https://jkulhanek.com/nerfbaselines et.al.|[2406.17345](http://arxiv.org/abs/2406.17345)|null|
|**2024-06-24**|**Reducing the Memory Footprint of 3D Gaussian Splatting**|3D高斯飞溅为新颖的视图合成提供了卓越的视觉质量，具有快速训练和实时渲染；不幸的是，这种方法对存储和传输的内存要求非常高。我们首先分析了原因，确定了可以减少存储的三个主要区域：用于表示场景的3D高斯基元的数量、用于表示方向辐射的球面谐波的系数数量以及存储高斯基元属性所需的精度。我们提出了每一个问题的解决方案。首先，我们提出了一种高效的、具有分辨率意识的原始修剪方法，将原始计数减少一半。其次，我们引入了一种自适应调整方法来选择用于表示每个高斯基元的方向辐射的系数数量，最后引入了一个基于码本的量化方法，以及用于进一步减少内存的半浮点表示。总之，这三个组件使我们测试的标准数据集的磁盘总大小减少了27，同时渲染速度加快了1.7。我们在标准数据集上演示了我们的方法，并展示了在移动设备上使用该方法时，我们的解决方案如何显著缩短下载时间。 et.al.|[2406.17074](http://arxiv.org/abs/2406.17074)|null|
|**2024-06-24**|**Articulate your NeRF: Unsupervised articulated object modeling via conditional view synthesis**|我们提出了一种新的无监督方法来学习具有刚性零件的关节对象的姿态和零件分割。给定一个物体在不同关节状态下的两个观察结果，我们的方法通过使用第一个观察结果的隐式模型来学习物体零件的几何形状和外观，从第二个观察结果中提取零件分割和关节，同时呈现后一个观察结果。此外，为了解决零件分割和连接联合优化的复杂性，我们提出了一种基于体素网格的初始化策略和解耦优化程序。与先前的无监督工作相比，我们的模型获得了显著更好的性能，并推广到具有多个部分的对象，同时它可以有效地从少数视图进行后期观察。 et.al.|[2406.16623](http://arxiv.org/abs/2406.16623)|null|
|**2024-06-24**|**Crowd-Sourced NeRF: Collecting Data from Production Vehicles for 3D Street View Reconstruction**|最近，神经辐射场（NeRF）在新的视图合成中取得了令人印象深刻的结果。Block NeRF展示了利用NeRF构建大城市规模模型的能力。对于大规模建模，需要大量的图像数据。从专门设计的数据采集车上采集图像无法支持大规模应用。如何获取大量高质量的数据仍然是一个悬而未决的问题。注意到汽车行业拥有大量的图像数据，众包是大规模数据收集的便捷方式。在本文中，我们提出了一个众包框架，该框架利用生产车辆捕获的大量数据来使用NeRF模型重建场景。这种方法解决了大规模重建的关键问题，即数据来自哪里以及如何使用它们。首先，对众包海量数据进行过滤，以消除冗余，并在时间和空间上保持平衡分布。然后执行来自运动模块的结构来细化相机姿态。最后，使用图像以及姿势来训练某个块中的NeRF模型。我们强调，我们提出了一个综合框架，集成了多个模块，包括数据选择、稀疏3D重建、序列外观嵌入、地表深度监测和遮挡完成。完整的系统能够从众包数据中有效地处理和重建高质量的3D场景。进行了大量的定量和定性实验来验证我们的系统的性能。此外，我们提出了一个名为“第一视角导航”的应用程序，该应用程序利用NeRF模型生成3D街景，并用合成视频引导驾驶员。 et.al.|[2406.16289](http://arxiv.org/abs/2406.16289)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-27**|**LiverUSRecon: Automatic 3D Reconstruction and Volumetry of the Liver with a Few Partial Ultrasound Scans**|肝脏体积测量的三维重建对于定性分析和疾病诊断非常重要。使用超声（US）扫描的肝脏容量测定虽然由于采集时间和安全性较短而具有优势，但由于超声扫描固有的噪声、边界模糊和部分肝脏可见性，因此具有挑战性。我们通过使用肝脏的一些不完全矢状面US扫描的分割掩模，以及使用一组肝脏CT扫描建立的统计形状模型（SSM）来解决这些挑战。我们通过参数回归网络计算扭曲该标准SSM以拟合US扫描所需的形状参数。由此产生的3D肝脏重建是准确的，并导致自动肝脏体积计算。我们使用RMSE评估估计的肝脏体积相对于CT分割体积的准确性。我们的体积计算在统计学上更接近于使用CT扫描估计的体积，而不是放射科医生使用Childs方法计算的体积：p值0.094（>0.05）表明，与Childs方法相比，CT分割体积与我们的体积之间没有显著差异。我们通过对US图像分辨率、用于SSM的CT扫描次数、主成分数量和输入US扫描次数的调查（消融研究）验证了我们的方法。据我们所知，这是第一个使用一些不完整的US扫描的自动肝脏容量测定系统，给出了一组SSM的肝脏CT扫描。 et.al.|[2406.19336](http://arxiv.org/abs/2406.19336)|null|
|**2024-06-26**|**On Scaling Up 3D Gaussian Splatting Training**|三维高斯散射（3DGS）以其优越的视觉质量和渲染速度在三维重建中越来越受欢迎。然而，3DGS训练目前发生在单个GPU上，由于内存限制，限制了其处理高分辨率和大规模3D重建任务的能力。我们介绍了Grendel，这是一个分布式系统，旨在划分3DGS参数并在多个GPU之间并行计算。由于每个高斯影响渲染像素的一个小的动态子集，Grendel采用稀疏的全对全通信将必要的高斯传输到像素分区，并执行动态负载平衡。与一次使用一个相机视图图像进行训练的现有3DGS系统不同，Grendel支持使用多个视图进行批量训练。我们探索了各种优化超参数缩放策略，发现一个简单的sqrt（批量大小）缩放规则是非常有效的。使用大规模、高分辨率场景的评估表明，Grendel通过在多个GPU上放大3DGS参数来提高渲染质量。在Rubble数据集上，我们通过在16个GPU上分布4040万高斯实现了27.28的测试PSNR，而在单个GPU上使用1120万高斯实现的PSNR为26.28。Grendel是一个开源项目，位于：https://github.com/nyu-systems/Grendel-GS et.al.|[2406.18533](http://arxiv.org/abs/2406.18533)|**[link](https://github.com/nyu-systems/grendel-gs)**|
|**2024-06-26**|**Repeat and Concatenate: 2D to 3D Image Translation with 3D to 3D Generative Modeling**|本文研究了一种具有直接技术的2D到3D图像转换方法，使相关的2D X射线到3D CT类重建成为可能。我们观察到，现有的方法在潜在空间中集成多个2D视图的信息，在潜在编码过程中会丢失有价值的信号信息。相反，我们只是简单地重复2D视图并将其连接到更高的通道3D体积中，并将3D重建挑战作为一个简单的3D到3D生成建模问题来解决，从而避开了几个复杂的建模问题。这种方法使重建的3D体积能够保留来自2D输入的有价值的信息，这些信息在Swin UNETR主干中的信道状态之间传递。我们的方法应用了神经最优传输，它快速稳定地进行训练，有效地集成了多个视图中的信号信息，而不需要精确对齐；它产生了即使在有限的训练之后也高度忠实于2D视图的非塌陷重建。我们在单个数据集上训练了我们的模型，并评估了其在六个数据集（包括分布外样本）上的泛化能力，从而展示了定性和定量的相关结果。 et.al.|[2406.18422](http://arxiv.org/abs/2406.18422)|**[link](https://github.com/abrilcf/3d-3d_repeat-concatenate)**|
|**2024-06-26**|**GS-Octree: Octree-based 3D Gaussian Splatting for Robust Object-level 3D Reconstruction Under Strong Lighting**|3D高斯散射技术显著推进了多视图图像辐射场的构建，实现了实时渲染。虽然基于点的光栅化有效地减少了渲染的计算需求，但它往往难以准确重建目标对象的几何结构，尤其是在强光下。为了应对这一挑战，我们引入了一种新的方法，将基于八叉树的隐式曲面表示与高斯飞溅相结合。我们的方法包括四个阶段。最初，它通过体积渲染重建有符号距离场（SDF）和辐射场，并将它们编码在低分辨率八叉树中。初始SDF表示目标对象的粗略几何图形。随后，它引入了3D高斯作为附加自由度，这些自由度由SDF引导。在第三阶段，优化的高斯进一步提高了SDF的精度，与第一阶段获得的初始SDF相比，可以恢复更精细的几何细节。最后，它采用了精细的SDF，通过飞溅进一步优化3D高斯，消除了对视觉外观贡献不大的高斯。实验结果表明，我们的方法利用了具有SDF的3D高斯分布，重建了更精确的几何体，特别是在具有由强光引起的镜面高光的图像中。 et.al.|[2406.18199](http://arxiv.org/abs/2406.18199)|null|
|**2024-06-25**|**Unified Auto-Encoding with Masked Diffusion**|在成功的生成和自我监督表示学习模型的核心，都有一个包含某种形式的图像腐败的重建目标。扩散模型通过预定的高斯破坏过程来实现这种方法，而掩蔽的自动编码器模型则通过掩蔽图像的块来实现。尽管它们的方法不同，但它们方法的潜在相似性为能够同时执行去噪任务的自动编码器提供了一条很有前途的途径。我们提出了一个统一的自监督目标，称为统一掩蔽扩散（UMD），它将基于补丁和基于噪声的破坏技术结合在一个单独的自动编码框架内。具体而言，UMD通过在扩散噪声调度中引入额外的无噪声、高掩蔽表示步骤来修改扩散变换器（DiT）训练过程，并将掩蔽和噪声的混合图像用于后续的时间步长。通过集成对扩散建模和预测屏蔽补丁令牌有用的特征，UMD在下游生成和表示学习任务中实现了强大的性能，包括线性探测和类条件生成。这是在不需要大量数据扩充、多视图或额外编码器的情况下实现的。此外，UMD在总训练时间上提高了先前基于扩散的方法的计算效率。我们在发布代码https://github.com/philippe-eecs/small-vision. et.al.|[2406.17688](http://arxiv.org/abs/2406.17688)|**[link](https://github.com/philippe-eecs/small-vision)**|
|**2024-06-25**|**Test-Time Generative Augmentation for Medical Image Segmentation**|在本文中，我们提出了一种在测试期间增强医学图像分割的新方法。我们主张使用高级域微调生成模型（GM），例如稳定扩散（SD）来增加测试时间，而不是在输入测试图像上使用手工制作的变换或函数来创建多个视图以增加测试时间。考虑到GM已经被训练来理解和封装全面的领域数据知识，它在表示数据特征和分布方面优于分割模型。因此，通过将GM集成到测试时间扩充中，我们可以有效地生成给定测试样本的多个视图，与样本的内容和外观特征以及相关的局部数据分布保持一致。与传统的手工转换相比，这种方法使增强过程更具适应性和弹性。在三个医学图像分割任务（九个数据集）上进行的综合实验证明了所提出的TTGA在增强分割结果方面的有效性和多功能性。此外，TTGA显著提高了像素误差估计，从而有助于部署更可靠的分割系统。代码将在以下位置发布：https://github.com/maxiao0234/TTGA. et.al.|[2406.17608](http://arxiv.org/abs/2406.17608)|**[link](https://github.com/maxiao0234/ttga)**|
|**2024-06-25**|**SyncNoise: Geometrically Consistent Noise Prediction for Text-based 3D Scene Editing**|基于文本的二维扩散模型在图像生成和编辑方面表现出了令人印象深刻的能力。同时，2D扩散模型也表现出用于3D编辑任务的巨大潜力。然而，如何在多个视点之间实现一致的编辑仍然是一个挑战。虽然迭代数据集更新方法能够实现全局一致性，但它存在收敛缓慢和纹理过度平滑的问题。我们提出了SyncNoise，这是一种新颖的几何引导的多视图一致性噪声编辑方法，用于高保真3D场景编辑。SyncNoise使用2D扩散模型同步编辑多个视图，同时强制多视图噪声预测保持几何一致，从而确保语义结构和低频外观的全局一致性。为了进一步增强高频细节的局部一致性，我们设置了一组锚视图，并通过跨视图重投影将它们传播到相邻的帧。为了提高多视图对应的可靠性，我们在训练过程中引入了深度监督，以增强精确几何形状的重建。我们的方法通过增强噪声和像素级别的几何一致性，在尊重文本指令的情况下，特别是在具有复杂纹理的场景中，实现了高质量的3D编辑结果。 et.al.|[2406.17396](http://arxiv.org/abs/2406.17396)|null|
|**2024-06-24**|**Crowd-Sourced NeRF: Collecting Data from Production Vehicles for 3D Street View Reconstruction**|最近，神经辐射场（NeRF）在新的视图合成中取得了令人印象深刻的结果。Block NeRF展示了利用NeRF构建大城市规模模型的能力。对于大规模建模，需要大量的图像数据。从专门设计的数据采集车上采集图像无法支持大规模应用。如何获取大量高质量的数据仍然是一个悬而未决的问题。注意到汽车行业拥有大量的图像数据，众包是大规模数据收集的便捷方式。在本文中，我们提出了一个众包框架，该框架利用生产车辆捕获的大量数据来使用NeRF模型重建场景。这种方法解决了大规模重建的关键问题，即数据来自哪里以及如何使用它们。首先，对众包海量数据进行过滤，以消除冗余，并在时间和空间上保持平衡分布。然后执行来自运动模块的结构来细化相机姿态。最后，使用图像以及姿势来训练某个块中的NeRF模型。我们强调，我们提出了一个综合框架，集成了多个模块，包括数据选择、稀疏3D重建、序列外观嵌入、地表深度监测和遮挡完成。完整的系统能够从众包数据中有效地处理和重建高质量的3D场景。进行了大量的定量和定性实验来验证我们的系统的性能。此外，我们提出了一个名为“第一视角导航”的应用程序，该应用程序利用NeRF模型生成3D街景，并用合成视频引导驾驶员。 et.al.|[2406.16289](http://arxiv.org/abs/2406.16289)|null|
|**2024-06-23**|**MLPHand: Real Time Multi-View 3D Hand Mesh Reconstruction via MLP Modeling**|多视图手部网格重建是虚拟现实和人机交互应用中的一项关键任务，但它仍然是一项艰巨的挑战。尽管现有的多视角手部重建方法实现了显著的准确性，但它们通常会带来巨大的计算负担，阻碍实时推理。为此，我们提出了MLPHand，这是一种用于实时多视图单手重建的新方法。MLP-Hand由两个主要模块组成：（1）一个基于MLP的轻量级Skeleton2Mesh模型，可有效地从手部骨骼中恢复手部网格；（2）一个多视图几何特征融合预测模块，可利用来自多个视图的详细几何信息增强Skeleton4Mesh模型。在三个广泛使用的数据集上的实验表明，MLPHand可以将计算复杂度降低90%，同时实现与现有最先进基线相当的重建精度。 et.al.|[2406.16137](http://arxiv.org/abs/2406.16137)|null|
|**2024-06-23**|**Learning with Noisy Ground Truth: From 2D Classification to 3D Reconstruction**|深度神经网络在数据密集型计算机视觉应用中取得了巨大成功，而这种成功在很大程度上依赖于大量干净的数据。在现实世界中，有时很难获得干净的数据。例如，在图像分类和分割任务中，数百万个样本的精确注释通常非常昂贵和耗时。在3D静态场景重建任务中，大多数与NeRF相关的方法都需要对静态场景进行基本假设（例如，一致的照明条件和持久的物体位置），这在现实世界的场景中经常被违反。为了解决这些问题，带噪声地面实况学习（LNGT）已成为一种有效的学习方法，并显示出巨大的潜力。在这项简短的调查中，我们提出了一个正式的定义，将LNGT-LNGT的分析统一到不同机器学习任务（分类和回归）的背景下。基于这一定义，我们提出了一种新的分类法，根据机器学习的基本定义，根据误差分解对现有工作进行分类。此外，我们对记忆效应进行了深入分析，并对未来从2D分类到3D重建的潜在研究机会进行了深入讨论，希望为后续研究提供指导。 et.al.|[2406.15982](http://arxiv.org/abs/2406.15982)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-27**|**Asymptotic Properties of Generalized Elephant Random Walks**|大象随机行走是一种特殊类型的随机行走，它结合了过去的记忆来决定未来的步伐。这种步行在某个时间点迈出特定一步（+1或-1）的概率，以整个历史为条件，取决于该步到该时间点的比例的线性函数。在这项工作中，我们研究了如果我们用满足某些分析条件的一般映射来代替这个线性函数，随机行走的动力学将如何变化。我们还提出了一个新的模型，称为多维广义大象随机行走，该模型在一个或更高的维度上结合了大象随机行走的几种变体及其推广。使用随机近似理论中的工具，我们导出了我们模型的渐近行为，从而在扩散和超扩散区域之间的相变边界上得到了新的结果。在这方面，我们还提到了一些悬而未决的问题。 et.al.|[2406.19383](http://arxiv.org/abs/2406.19383)|null|
|**2024-06-27**|**Spontaneous symmetry breaking in open quantum systems: strong, weak, and strong-to-weak**|根据与环境的耦合，开放量子系统的对称性表现为两种不同的形式，即强和弱。我们研究了具有不同对称性的相之间的自发对称性破缺。构造了具有强对称性和弱对称性的具体刘维模型，并从互补的方法研究了对称性破缺跃迁的不同场景。证明了强对称性总是自发地分解成相应的弱对称性。对于强 $U（1）$对称性，我们证明了强到弱对称性破坏导致无间隙的Goldstone模决定了对称电荷在平移不变系统中的扩散。我们推测，对于连续对称性，强到弱对称性破缺、无间隙模和对称电荷扩散之间的这种关系是普遍的。它可以被解释为开放量子系统的“增强的Lieb-Schultz-Mattis（LSM）定理”，根据该定理，无隙谱不需要非整数填充。我们还研究了强对称性完全断裂的情况。在对称破缺相中，我们确定了具有两个Goldstone模式的有效Keldysh作用，分别描述了对称电荷的阶参数波动和扩散流体动力学。对于这里研究的一个特定模型，我们揭示了从具有“玻色表面”的对称相到具有长程有序的对称破缺相的转变，这是通过调整填充引起的。还表明，在弱对称和强对称的情况下，$U（1）$对称性破缺的长程阶在空间维度$d\geq3$ 中是可能的。我们的工作概述了开放量子系统中自发对称性破坏的典型场景，并强调了其物理后果。 et.al.|[2406.19381](http://arxiv.org/abs/2406.19381)|null|
|**2024-06-27**|**Accelerating Multiphase Flow Simulations with Denoising Diffusion Model Driven Initializations**|这项研究引入了一种混合流体模拟方法，将生成扩散模型与基于物理的模拟相结合，旨在降低流动模拟的计算成本，同时兼顾所有感兴趣的物理特性。这些模拟增强了我们对应用的理解，例如评估地下储层中的氢气和CO $_2$ 储存效率。然而，它们在计算上是昂贵的，并且非唯一解决方案的存在可能需要在单个几何体内进行多次模拟。为了克服计算成本的障碍，我们提出了一种将生成扩散模型和基于物理的建模相结合的混合方法。我们引入了一个系统来调节具有感兴趣的几何形状的扩散模型，允许在相同的几何形状中产生可变的流体饱和度。在训练模型的同时，我们同时生成初始条件，并使用这些条件进行基于物理的模拟。这种集成方法使我们能够在配备CPU和GPU的单个计算节点上接收实时反馈。通过在一个计算节点内有效地管理这些过程，我们可以连续评估性能，并在满足所需标准时停止训练。为了测试我们的模型，我们在真实的Berea砂岩裂缝中生成了实现，这表明我们的技术比常用的流动模拟初始化快4.4倍。 et.al.|[2406.19333](http://arxiv.org/abs/2406.19333)|null|
|**2024-06-27**|**Subtractive Training for Music Stem Insertion using Latent Diffusion Models**|我们提出了减法训练，这是一种简单新颖的方法，用于在给定其他乐器作为背景的情况下合成单个乐器词干。该方法将完整音乐混音的数据集与1）缺乏特定词干的数据集变体和2）LLM生成的描述如何重新引入缺失词干的指令配对。然后，我们在现有词干和文本指令的指导下，对预训练的文本到音频的扩散模型进行微调，以生成缺失的乐器词干。我们的研究结果证明了减法训练在创造与现有曲目无缝融合的真实鼓杆方面的功效。我们还展示了我们可以使用文本指令从节奏、动态和流派方面控制插入词干的生成，使我们能够在保持其余乐器不变的同时修改整首歌中单个乐器的风格。最后，我们将这种技术扩展到MIDI格式，成功地为不完整的编排生成了兼容的低音、鼓和吉他部分。 et.al.|[2406.19328](http://arxiv.org/abs/2406.19328)|null|
|**2024-06-27**|**Vector Resonant Relaxation and Statistical Closure Theory. I. Direct Interaction Approximation**|围绕星系中心超大质量黑洞运行的恒星在其轨道方向上经历了非常有效的扩散。这就是“矢量共振弛豫”，一个在单位球面上正式发生的扩散过程。这种动力学本质上是非线性、随机和相关的，因此与流体力学或等离子体物理中的湍流有着深刻的相似之处。在这种情况下，我们展示了源自统计闭包理论的通用方法，即著名的“Martin Siggia-Rose形式主义”，可以用来表征描述轨道方向重新分布的相关性。特别是，将我们自己限制在这种闭合方案中的前导阶截断，即所谓的“直接相互作用近似”，并将我们自己置于各向同性取向分布的极限中，我们明确地将两点相关函数的相关预测与数值模拟的测量值进行比较。我们讨论了这种方法的成功和局限性，并介绍了未来可能的场所。 et.al.|[2406.19306](http://arxiv.org/abs/2406.19306)|null|
|**2024-06-27**|**Compositional Image Decomposition with Diffusion Models**|给定一个自然场景的图像，我们能够将其快速分解为一组组件，如对象、照明、阴影和前景。然后，我们可以想象一个场景，将某些组件与其他图像中的组件相结合，例如，在森林的照明条件下，我们卧室中的一组物体和动物园中的动物，即使我们以前从未遇到过这样的场景。在本文中，我们提出了一种将图像分解为这些组成成分的方法。我们的方法，分解扩散，是一种无监督的方法，当给定单个图像时，它推断图像中的一组不同分量，每个分量由扩散模型表示。我们演示了组件如何捕捉场景的不同因素，从阴影或面部表情等全局场景描述符到组成对象等局部场景描述符。我们进一步说明了推断的因素是如何灵活组合的，即使使用从其他模型推断的因素，也可以生成与训练时间中看到的场景截然不同的各种场景。网站和代码位于https://energy-based-model.github.io/decomp-diffusion. et.al.|[2406.19298](http://arxiv.org/abs/2406.19298)|null|
|**2024-06-27**|**Advection Augmented Convolutional Neural Networks**|物理科学中的许多问题都以时空序列的预测为特征。这些问题的范围从天气预测到疾病传播分析和视频预测。解决这些问题的现代技术通常将卷积神经网络（CNN）架构与时间预测机制相结合。然而，这种方法往往在信息的长期传播中表现不佳，缺乏可解释性。在这项工作中，我们介绍了一个物理启发的体系结构来解决这些问题。也就是说，我们建议通过设计一个新的半拉格朗日推算子来用平流来增强CNN。我们证明，与标准卷积核相比，所提出的算子允许信息的非局部变换。然后，我们用反应和扩散神经组件对其进行补充，形成一个高维模拟反应-平流-扩散方程的网络。我们在许多时空数据集上展示了我们网络的有效性，这些数据集显示了它们的优点。 et.al.|[2406.19253](http://arxiv.org/abs/2406.19253)|null|
|**2024-06-27**|**Diffuse interstellar bands in the near-infrared: Expanding the reddening range**|我们利用三个天文台的光谱，在比以前研究的更大的视线样本和更大的灭绝范围内，研究了三个强近红外漫射星际带（DIB）在13177、14680和15272的行为。我们应用了两种大地电磁校正技术来减少大气污染，并使用高斯拟合来表征DIB剖面和测量等效宽度。我们证实了13177、14680和15272 DIB与红化的强且近似线性的相关性，将它们扩展到更高的红化值，并加强了它们与星际物质的联系。｛\lang1033\lang103314680｛\llang1033DIB剖面的建模揭示了与它们的形成过程有关的内在变化，包括线加宽。这种影响在银河中心（GC）环境中尤为明显，在那里，沿着视线的多个扩散分子云导致了视线的加宽。｛\lang1033\lang1033我们在具有高红化的视线上检测到一个新的｛\llang1033\llang1033 DIB候选物｛\l\lang1033114795。｝。 et.al.|[2406.19229](http://arxiv.org/abs/2406.19229)|null|
|**2024-06-27**|**Numerical Analysis of the Complete Active-Space Extended Koopmans's Theorem**|我们研究了扩展库普曼斯定理（EKT）在再现原子和分子系统的全组态相互作用（FCI）和全活性空间组态相互作用的电离能（IE）（计算为N和（N-1）电子态能量之差）方面的数值精度。特别地，我们研究了随着基集和活动空间大小的变化，EKT IE收敛到其精确值的问题。我们发现，随着基集大小的增加，第一个FCI EKT IE接近它们的确切对应物。然而，增加基集或活动空间大小并不总是导致更准确的CAS-CI EKT IE。我们的研究支持了Davidson等人的观察[E.R.Davison等人，J.Chem.Phys.155051102（2021）]，即通过用适当对称的扩散函数补充基集，可以系统地以任意的数值精度改进FCI EKT IE，该扩散函数允许分离的电子远离参考系。通过改变扩散函数的指数和中心，我们的结果描绘了LiH的CAS-CI EKT IE的复杂模式，这对于小分子的光谱研究可能很重要。 et.al.|[2406.19211](http://arxiv.org/abs/2406.19211)|null|
|**2024-06-27**|**The case for Centaurus A as the main source of ultrahigh-energy cosmic rays**|我们讨论了脚踝上方宇宙射线的主要部分是由附近的单一来源引起的可能性，特别是考虑到半人马座a射电星系。在较低能量下非常温和的衰减效应意味着来自该源的次级核只提供了很小的贡献。考虑到观测到的中等各向异性，银河系外和银河系磁场的偏转应该在决定宇宙射线到达方向分布方面发挥关键作用。河外场的扩散以及有限的源寿命也会显著影响观测光谱的形状。数十EeV的宇宙射线通量由CNO分量主导，我们表明，它实际上更好地由C核和O核的混合物再现，而不是由有效描述该质量组的N分量的通常假设再现。在存在强光谱抑制的能量范围内，Si和Fe族成分在70EeV以上变得占主导地位。如果半人马座A方向周围出现在40EeV以上的局部通量过剩归因于CNO成分，则来自能量范围为10-20EeV的源的He核可能导致类似的各向异性，除非其贡献被抑制。在几个EeV的宇宙射线通量应该主要是由与河外源群体相关的更各向同性的光分量引起的。包含来自银河系成分的重核的亚优势贡献有助于再现1 EeV附近的观测结果。 et.al.|[2406.19199](http://arxiv.org/abs/2406.19199)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-26**|**3D Feature Distillation with Object-Centric Priors**|将自然语言与物理世界联系起来是一个普遍存在的话题，在计算机视觉和机器人领域有着广泛的应用。最近，像CLIP这样的2D视觉语言模型已经被广泛普及，因为它们在2D图像中具有令人印象深刻的开放词汇基础能力。最近的工作旨在通过特征提取将2D CLIP特征提升到3D，但要么学习特定于场景的神经场，因此缺乏泛化能力，要么专注于需要访问多个相机视图的室内房间扫描数据，这在机器人操作场景中是不现实的。此外，相关方法通常在像素级融合特征，并假设所有相机视图的信息量相等。在这项工作中，我们证明了这种方法在基础精度和分割清晰度方面都会导致次优的3D特征。为了缓解这种情况，我们提出了一种多视图特征融合策略，该策略采用以对象为中心的先验来消除基于语义信息的无信息视图，并通过实例分割掩码在对象级别融合特征。为了提取我们以对象为中心的3D特征，我们生成了一个杂乱桌面场景的大规模合成多视图数据集，从3300多个独特的对象实例中生成了15k个场景，并将其公开。我们表明，我们的方法在从单视图RGB-D重建3D CLIP特征的同时，具有改进的接地能力和空间一致性，从而偏离了测试时多个相机视图的假设。最后，我们证明了我们的方法可以推广到新的桌面领域，并在不进行微调的情况下重新用于3D实例分割，并证明了它在语言引导的机器人抓取中的实用性 et.al.|[2406.18742](http://arxiv.org/abs/2406.18742)|null|
|**2024-06-25**|**Masked Generative Extractor for Synergistic Representation and 3D Generation of Point Clouds**|在2D图像生成建模和表示学习领域，掩模生成编码器（MAGE）已经证明了生成建模与表示学习之间的协同潜力。受此启发，我们提出了Point MAGE，将这一概念扩展到点云数据。具体而言，该框架首先利用矢量量化变分自动编码器（VQVAE）来重建3D形状的神经场表示，从而学习点块的离散语义特征。随后，通过将掩蔽模型与可变掩蔽比相结合，我们实现了生成和表示学习的同步训练。此外，我们的框架与现有的点云自监督学习（SSL）模型无缝集成，从而提高了它们的性能。我们广泛评估了Point MAGE的表示学习和生成能力。在形状分类任务中，Point MAGE在ModelNet40数据集上的准确率为94.2%，在ScanObjectNN数据集上达到92.9%（+1.3%）。此外，它在少量镜头学习和零件分割任务中实现了最先进的性能。实验结果还证实，点MAGE可以在无条件和有条件的设置中生成详细和高质量的3D形状。 et.al.|[2406.17342](http://arxiv.org/abs/2406.17342)|null|
|**2024-06-17**|**DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features**|我们提出了DistilleNeRF，这是一种自监督学习框架，解决了在自动驾驶中从有限的2D观测中理解3D环境的挑战。我们的方法是一个可推广的前馈模型，它从稀疏的单帧多视图相机输入中预测丰富的神经场景表示，并通过可微分渲染进行自监督训练，以重建RGB、深度或特征图像。我们的第一个见解是通过生成密集的深度和虚拟相机目标进行训练，利用每场景优化的神经辐射场（NeRF），从而帮助我们的模型从稀疏的非重叠图像输入中学习3D几何。其次，为了学习语义丰富的3D表示，我们建议从预先训练的2D基础模型（如CLIP或DINOv2）中提取特征，从而实现各种下游任务，而不需要昂贵的3D人工注释。为了利用这两个见解，我们引入了一种新的模型架构，该架构具有两级提升-飞溅-拍摄编码器和参数化稀疏分层体素表示。在NuScenes数据集上的实验结果表明，DistilleNeRF在场景重建、新视图合成和深度估计方面显著优于现有的可比自监督方法；并且它允许竞争性的零样本3D语义占用预测，以及通过提取的基础模型特征来理解开放世界场景。演示和代码将在https://distillnerf.github.io/. et.al.|[2406.12095](http://arxiv.org/abs/2406.12095)|null|
|**2024-06-18**|**Effective Rank Analysis and Regularization for Enhanced 3D Gaussian Splatting**|从多视图图像中进行三维重建是计算机视觉和图形学的基本挑战之一。近年来，三维高斯散射（3DGS）已经成为一种很有前途的技术，能够实时渲染和高质量的三维重建。该方法利用了三维高斯表示和基于瓦片的飞溅技术，绕过了昂贵的神经场查询。尽管3DGS具有潜力，但由于高斯收敛为具有一个主导方差的各向异性高斯，3DGS仍面临挑战，包括针状伪影、次优几何结构和不准确法线。我们建议使用有效秩分析来检查3D高斯基元的形状统计，并识别高斯确实收敛为有效秩为1的针状形状。为了解决这个问题，我们引入了有效秩作为正则化，它约束高斯的结构。我们的新正则化方法增强了法线和几何重建，同时减少了针状伪影。该方法可以作为附加模块集成到其他3DGS变体中，在不影响视觉逼真度的情况下提高其质量。 et.al.|[2406.11672](http://arxiv.org/abs/2406.11672)|null|
|**2024-06-13**|**Well-posedness and regularity of solutions to neural field problems with dendritic processing**|我们研究了最近提出的神经场模型的解决方案，在该模型中，树突被建模为源自体细胞层的垂直纤维的连续体。由于电压通过具有非局部源的电缆方程沿树枝状方向传播，因此该模型具有各向异性扩散算子以及突触耦合的积分项。因此，相应的柯西问题与经典的神经场方程明显不同。我们证明了问题的弱公式允许一个唯一的解，嵌入估计类似于非线性局部反应扩散方程的嵌入估计。我们的分析依赖于无扩散问题的扰动弱解，即标准神经场，迄今为止尚未对其弱问题进行研究。我们找到了有扩散和无扩散问题的严格渐近估计，并证明了这两个模型的解在有限时间间隔上在适当的范数下保持接近。我们提供了微扰结果的数值证据。 et.al.|[2406.09222](http://arxiv.org/abs/2406.09222)|null|
|**2024-06-13**|**Preserving Identity with Variational Score for General-purpose 3D Editing**|我们提出了Piva（用变分分数蒸馏保持同一性），这是一种新的基于优化的方法，用于编辑基于扩散模型的图像和3D模型。具体来说，我们的方法受到了最近提出的2D图像编辑方法——德尔塔去噪分数（DDS）的启发。我们指出了DDS在二维和三维编辑中的局限性，这会导致细节丢失和过饱和。为了解决这一问题，我们提出了一个额外的分数提取术语，以强制执行身份保护。这导致了更稳定的编辑过程，逐步优化NeRF模型以匹配目标提示，同时保留关键的输入特征。我们证明了我们的方法在零样本图像和神经场编辑中的有效性。我们的方法成功地改变了视觉属性，添加了微妙和实质性的结构元素，转换了形状，并在标准的2D和3D编辑基准上取得了有竞争力的结果。此外，我们的方法没有施加任何约束，如掩蔽或预训练，使其与广泛的预训练扩散模型兼容。这允许进行多功能编辑，而不需要神经场到网格的转换，提供更用户友好的体验。 et.al.|[2406.08953](http://arxiv.org/abs/2406.08953)|null|
|**2024-06-12**|**Category-level Neural Field for Reconstruction of Partially Observed Objects in Indoor Environment**|通过各种成功案例，神经隐式表示在三维重建中引起了人们的关注。对于进一步的应用，如场景理解或编辑，一些作品已经显示出在对象组成重建方面的进展。尽管它们在观测区域具有优越的性能，但在重建部分观测到的对象时，它们的性能仍然有限。为了更好地处理这个问题，我们引入了类别级神经场，该神经场在场景中属于同一类别的对象之间学习有意义的公共3D信息。我们的主要想法是根据观察到的形状对对象进行子分类，以便更好地训练类别级模型。然后，我们利用神经场，通过选择基于射线的不确定性选择的代表性对象并与之对齐，来执行配准部分观测对象的挑战性任务。在模拟和真实世界数据集上的实验表明，我们的方法改进了几个类别的未观察零件的重建。 et.al.|[2406.08176](http://arxiv.org/abs/2406.08176)|**[link](https://github.com/Taekbum/category-nerf-reconstruction-official)**|
|**2024-06-12**|**OpenObj: Open-Vocabulary Object-Level Neural Radiance Fields with Fine-Grained Understanding**|近年来，人们对由视觉语言模型（VLM）促进的开放词汇三维场景重建产生了浓厚的兴趣，VLM在开放集检索中展示了非凡的能力。然而，现有的方法面临一些局限性：它们要么专注于学习逐点特征，导致语义理解模糊，要么只处理对象级重建，从而忽略对象内部的复杂细节。为了应对这些挑战，我们引入了OpenObj，这是一种创新的方法，用于构建具有细粒度理解的开放词汇表对象级神经辐射场（NeRF）。从本质上讲，OpenObj建立了一个健壮的框架，用于在对象级别进行高效和严密的场景建模和理解。此外，我们将零件级特征融入神经领域，从而实现物体内部的细致入微的表示。这种方法捕获对象级实例，同时保持细粒度的理解。在多个数据集上的结果表明，OpenObj在零样本语义分割和检索任务中取得了优异的性能。此外，OpenObj支持多尺度的真实世界机器人任务，包括全局移动和局部操纵。 et.al.|[2406.08009](http://arxiv.org/abs/2406.08009)|**[link](https://github.com/BIT-DYN/OpenObj)**|
|**2024-06-11**|**Image Neural Field Diffusion Models**|扩散模型在对复杂数据分布建模方面表现出了令人印象深刻的能力，与GANs相比具有几个关键优势，例如稳定的训练、更好地覆盖训练分布的模式，以及在没有额外训练的情况下解决反问题的能力。然而，大多数扩散模型学习固定分辨率图像的分布。我们建议通过在图像神经场上训练扩散模型来学习连续图像的分布，该模型可以以任何分辨率渲染，并显示出其相对于固定分辨率模型的优势。为了实现这一点，一个关键的挑战是获得一个代表真实感图像神经场的潜在空间。受最近几项技术的启发，我们提出了一种简单有效的方法，但有一些关键的变化，使图像神经场具有真实感。我们的方法可以用于将现有的潜在扩散自动编码器转换为图像神经场自动编码器。我们证明，图像神经场扩散模型可以使用混合分辨率图像数据集进行训练，优于固定分辨率扩散模型和超分辨率模型，并且可以有效地解决不同尺度条件下的逆问题。 et.al.|[2406.07480](http://arxiv.org/abs/2406.07480)|null|
|**2024-06-10**|**Space-Time Continuous PDE Forecasting using Equivariant Neural Fields**|最近，条件神经场（NeF）通过将解学习为条件NeF的潜在空间中的流，已成为偏微分方程的强大建模范式。尽管受益于NeFs的有利特性，如网格不可知性和时空连续动力学建模，但这种方法限制了将PDE的已知约束强加给解决方案的能力，例如对称性或边界条件，有利于建模的灵活性。相反，我们提出了一种基于时空连续NeF的求解框架，该框架通过在潜在空间中保留几何信息，尊重PDE的已知对称性。我们表明，将解建模为感兴趣组 $G$ 上的点云流，可以提高泛化和数据效率。我们验证了我们的框架很容易推广到看不见的空间和时间位置，以及初始条件的几何变换——在其他基于NeF的PDE预测方法失败的地方——并在一些具有挑战性的几何结构中超过基线进行改进。 et.al.|[2406.06660](http://arxiv.org/abs/2406.06660)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

