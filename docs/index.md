---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.09.20
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-16**|**ExBluRF: Efficient Radiance Fields for Extreme Motion Blurred Images**|我们提出了ExBluRF，这是一种基于有效辐射场优化的极端运动模糊图像的新视图合成方法。我们的方法由两个主要组成部分组成：基于6自由度相机轨迹的运动模糊公式和基于体素的辐射场。从极其模糊的图像中，我们通过联合估计生成模糊图像的相机轨迹来优化清晰的辐射场。在训练中，沿着相机轨迹的多条光线被累积以重建单个模糊的颜色，这相当于物理运动模糊操作。我们最小化了模糊图像空间上的照片一致性损失，并获得了具有相机轨迹的清晰辐射场，这些轨迹解释了所有图像的模糊。模糊图像空间上的联合优化需要与模糊大小成比例地痛苦地增加计算和资源。我们的方法通过将基于MLP的框架替换为低维6自由度相机姿态和基于体素的辐射场来解决这个问题。与现有作品相比，我们的方法从具有挑战性的运动模糊视图中恢复了更清晰的3D场景，训练时间和GPU内存消耗减少了10倍。 et.al.|[2309.08957](http://arxiv.org/abs/2309.08957)|null|
|**2023-09-16**|**DynaMoN: Motion-Aware Fast And Robust Camera Localization for Dynamic NeRF**|利用神经辐射场（NeRF）进行动态重建需要精确的相机姿态。这些通常很难用现有的运动结构（SfM）管道来检索，因为相机和场景内容都可能发生变化。我们提出了DynaMoN，它利用同步定位和映射（SLAM）与运动掩蔽相结合来处理动态场景内容。我们基于SLAM的稳健跟踪模块显著加快了动态NeRF的训练过程，同时提高了合成视图的质量。对TUM RGB-D、BONN RGB-D Dynamic和DyCheck的iPhone数据集这三个真实世界的数据集进行了广泛的实验验证，显示了DynaMoN在相机姿态估计和新颖视图合成方面的优势。 et.al.|[2309.08927](http://arxiv.org/abs/2309.08927)|null|
|**2023-09-14**|**Viewpoint Textual Inversion: Unleashing Novel View Synthesis with Pretrained 2D Diffusion Models**|文本到图像的扩散模型理解物体之间的空间关系，但它们是否仅从2D监督中代表了世界的真实3D结构？我们证明，是的，3D知识被编码在2D图像扩散模型中，如稳定扩散，我们证明这种结构可以用于3D视觉任务。我们的方法，视点神经纹理反演（ViewNeTI），控制从冻结扩散模型生成的图像中对象的3D视点。我们训练一个小型神经映射器来获取相机视点参数并预测文本编码器延迟；潜伏时间然后调节扩散生成过程以产生具有期望的相机视点的图像。ViewNeTI自然地解决了新颖视图合成（NVS）问题。通过利用冻结扩散模型作为先验，我们可以用很少的输入视图来解决NVS；我们甚至可以做单一视角的小说视角合成。与先前的方法相比，我们的单视图NVS预测具有良好的语义细节和真实感。我们的方法非常适合对稀疏三维视觉问题中固有的不确定性进行建模，因为它可以有效地生成不同的样本。我们的视图控制机制是通用的，甚至可以更改用户定义提示生成的图像中的相机视图。 et.al.|[2309.07986](http://arxiv.org/abs/2309.07986)|null|
|**2023-09-14**|**CoRF : Colorizing Radiance Fields using Knowledge Distillation**|基于神经辐射场（NeRF）的方法能够实现多视图图像的高质量新视图合成。本文提出了一种从输入的灰度多视图图像中合成彩色新视图的方法。当我们在生成的灰度级新视图上应用基于图像或视频的着色方法时，我们会观察到由于视图之间的不一致而产生的伪影。在彩色灰度图像序列上训练辐射场网络也不能解决3D一致性问题。我们提出了一种基于蒸馏的方法，将颜色知识从在自然图像上训练的着色网络转移到辐射场网络。具体来说，我们的方法使用辐射场网络作为3D表示，并从现有的2D着色方法中转移知识。实验结果表明，与基线相比，该方法在保持跨视图一致性的同时，为室内和室外场景生成了更好的彩色新视图。此外，我们展示了我们的方法在应用中的有效性，如从1.）红外（IR）多视图图像和2.）旧灰度多视图图像序列训练的辐射场网络的彩色化。 et.al.|[2309.07668](http://arxiv.org/abs/2309.07668)|null|
|**2023-09-13**|**Dynamic NeRFs for Soccer Scenes**|新颖视角合成这个长期存在的问题有很多应用，尤其是在体育广播中。特别是足球动作的逼真新颖视角合成，引起了广播业的极大兴趣。然而，只有少数几个工业解决方案被提出，甚至很少能达到合成回放的近广播质量。除了在操场周围设置多个静态摄像头外，最好的专有系统几乎没有透露任何关于其内部工作的信息。由于缺乏公共数据集，利用多个静态相机执行这样的任务确实是一个文献中很少解决的挑战：用小而快速的元素重建大规模的、主要是静态的环境。最近，神经辐射场的出现在许多新颖的视图合成应用中取得了惊人的进展，利用深度学习原理在最具挑战性的环境中产生逼真的结果。在这项工作中，我们研究了基于动态NeRF的任务解决方案的可行性，即旨在重建一般动态内容的神经模型。我们构建了合成足球环境，并使用它们进行了多项实验，确定了有助于用动态NeRF重建足球场景的关键组件。我们表明，尽管这种方法不能完全满足目标应用程序的质量要求，但它为实现成本效益高的自动解决方案提供了有希望的途径。我们还公开了我们的工作数据集和代码，目的是鼓励研究界进一步致力于动态足球场景的新颖视图合成任务。有关代码、数据和视频结果，请参阅https://soccernerfs.isach.be. et.al.|[2309.06802](http://arxiv.org/abs/2309.06802)|null|
|**2023-09-13**|**SAMPLING: Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image**|最近的新颖视图合成方法对于相对较小的场景（例如，室内环境和具有少数对象的场景）获得了有希望的结果，但对于具有单个图像作为输入的无边界室外场景往往失败。在本文中，我们介绍了SAMPLING，这是一种基于改进的多平面图像（MPI）的场景自适应分层多平面图像表示，用于从单个图像合成新视图。观察到无边界户外场景的深度分布变化很大，我们为MPI采用了自适应仓策略，根据每个场景图像排列平面。为了表示复杂的几何结构和多尺度细节，我们进一步引入了一个层次细化分支，它可以产生高质量的合成新视图。我们的方法在KITTI数据集上使用单个图像合成大规模无界户外场景时表现出了相当大的性能提升，并很好地推广到了看不见的Tanks和Temples数据集。代码和模型将很快提供。 et.al.|[2309.06323](http://arxiv.org/abs/2309.06323)|null|
|**2023-09-11**|**FlowIBR: Leveraging Pre-Training for Efficient Neural Image-Based Rendering of Dynamic Scenes**|我们介绍了一种用于动态场景的单目新颖视图合成的新方法。现有技术已经显示出令人印象深刻的渲染质量，但倾向于在不利用先验知识的情况下专注于单个场景内的优化。这种限制主要归因于缺乏可用于训练的动态场景数据集以及场景动力学的多样性。我们的方法FlowIBR通过集成基于神经图像的渲染方法来规避这些问题，该方法在广泛可用的静态场景的大型语料库上进行了预训练，并具有每个场景优化的场景流场。利用该流场，我们弯曲摄影机光线以抵消场景动力学，从而将动态场景呈现为渲染网络的静态场景。所提出的方法将每个场景的优化时间减少了一个数量级，实现了与现有方法相当的结果——所有这些都在单个消费级GPU上。 et.al.|[2309.05418](http://arxiv.org/abs/2309.05418)|null|
|**2023-09-11**|**Towards Viewpoint Robustness in Bird's Eye View Segmentation**|自动驾驶汽车（AV）要求用于感知的神经网络对不同的视点具有鲁棒性，如果它们要部署在许多类型的车辆上，而不需要为每种车辆重复数据收集和标记的成本。AV公司通常专注于从不同的场景和地点收集数据，但由于成本原因，不关注摄像机设备配置。因此，大多数震源组中只存在少量的钻机变体。在本文中，我们研究了AV感知模型如何受到摄像机视点变化的影响，并提出了一种在不重复数据收集和标记的情况下跨车辆类型缩放它们的方法。使用鸟瞰图（BEV）分割作为一项激励任务，我们通过大量实验发现，现有的感知模型对相机视点的变化非常敏感。当使用来自一个相机装备的数据进行训练时，在推断时相机的俯仰、偏航、深度或高度的微小变化会导致性能大幅下降。我们引入了一种新的视图合成技术，并使用它将收集的数据转换为目标钻机的视点，使我们能够为不同的目标钻机训练BEV分割模型，而无需任何额外的数据收集或标记成本。为了分析观点变化的影响，我们利用合成数据来缓解其他差距（内容、ISP等）。然后，我们的方法在真实数据上进行训练，并在合成数据上进行评估，从而能够对不同的目标钻机进行评估。我们发布所有数据以供未来工作使用。我们的方法能够回收部署到新钻机时损失的IoU的平均14.7%。 et.al.|[2309.05192](http://arxiv.org/abs/2309.05192)|null|
|**2023-09-10**|**SC-NeRF: Self-Correcting Neural Radiance Field with Sparse Views**|在最近的研究中，神经辐射场的泛化在新的视图合成任务中得到了广泛的探索。然而，现有的方法仅限于对象和室内场景。在这项工作中，我们将泛化任务扩展到户外场景，仅在对象级数据集上进行训练。这种方法提出了两个挑战。首先，训练和测试场景之间的显著分布变化导致渲染结果中出现黑色伪影。其次，室外场景中的视点变化会导致渲染图像中出现重影或区域丢失。为了应对这些挑战，我们提出了一个基于多头注意力机制的几何校正模块和外观校正模块。我们将渲染深度标准化，并将其与光方向组合，作为注意力机制中的查询。我们的网络有效地纠正了户外场景中不同的场景结构和几何特征，从物体层面很好地推广到看不见的户外场景。此外，我们使用外观校正模块来校正外观特征，防止由于视点更改而导致的渲染伪影，如空白边界和重影。通过结合这些模块，我们的方法成功地解决了户外场景泛化的挑战，产生了高质量的渲染结果。当在四个数据集（Blender、DTU、LLFF、Spaces）上进行评估时，我们的网络优于以前的方法。值得注意的是，与MVSNeRF相比，我们的网络将Spaces户外场景的平均PSNR从19.369提高到25.989，SSIM从0.838提高到0.889，并将LPIPS从0.265降低到0.224。 et.al.|[2309.05028](http://arxiv.org/abs/2309.05028)|null|
|**2023-09-14**|**SimpleNeRF: Regularizing Sparse Input Neural Radiance Fields with Simpler Solutions**|神经辐射场（NeRF）在场景的真实感自由视图渲染中表现出令人印象深刻的性能。然而，NeRF需要对给定场景中的图像进行密集采样，并且当只有稀疏的视图集可用时，其性能会显著下降。研究人员发现，监督NeRF估计的深度有助于用更少的视图有效地训练它。深度监督是使用经典方法或在大型数据集上预先训练的神经网络来获得的。前者可能只提供稀疏的监督，而后者可能存在泛化问题。与早期的方法不同，我们试图通过设计增强模型并将其与NeRF一起训练来学习深度监督。我们设计了增强模型，通过探索位置编码和视图相关辐射在训练少镜头NeRF中的作用，鼓励更简单的解决方案。由这些更简单的模型估计的深度用于监督NeRF深度估计。由于增强模型在某些区域可能不准确，我们设计了一种机制，只选择可靠的深度估计进行监督。最后，我们在NeRF的粗糙和精细多层感知器之间添加了一致性损失，以确保更好地利用分层采样。通过采用上述正则化，我们在两个流行的数据集上实现了最先进的视图合成性能。我们模型的源代码可以在我们的项目页面上找到：https://nagabhushansn95.github.io/publications/2023/SimpleNeRF.html et.al.|[2309.03955](http://arxiv.org/abs/2309.03955)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-18**|**Improving Neural Indoor Surface Reconstruction with Mask-Guided Adaptive Consistency Constraints**|从2D图像重建3D场景一直是一项长期任务。最近的研究利用神经隐式表面作为3D重建的统一表示，而不是估计每帧深度图并将其融合到3D中。这些方法配备了数据驱动的预训练几何线索，表现出了良好的性能。然而，不准确的先验估计（这通常是不可避免的）可能导致次优重建质量，特别是在一些几何复杂的区域。在本文中，我们提出了一个两阶段的训练过程，解耦视图相关和视图无关的颜色，并利用两个新的一致性约束来提高细节重建性能，而不需要额外的先验。此外，我们引入了一个基本的掩码方案来自适应地影响监督约束的选择，从而提高自监督范式中的性能。在合成数据集和真实世界数据集上的实验表明，该方法能够减少先验估计误差的干扰，并实现具有丰富几何细节的高质量场景重建。 et.al.|[2309.09739](http://arxiv.org/abs/2309.09739)|null|
|**2023-09-18**|**Robust Geometry-Preserving Depth Estimation Using Differentiable Rendering**|在这项研究中，我们解决了从单目深度估计中恢复3D场景结构的挑战。虽然传统的深度估计方法利用标记的数据集来直接预测绝对深度，但最近的进展提倡混合数据集训练，增强了在不同场景中的泛化能力。然而，这种混合数据集训练只能产生未知规模和偏移的深度预测，阻碍了精确的3D重建。现有的解决方案需要额外的3D数据集或几何体完整的深度注释，这些限制了它们的通用性。在本文中，我们提出了一种学习框架，该框架训练模型来预测几何保持深度，而不需要额外的数据或注释。为了产生逼真的3D结构，我们渲染重建场景的新颖视图，并设计损失函数，以提高不同视图之间的深度估计一致性。全面的实验强调了我们框架卓越的泛化能力，在几个基准数据集上超越了现有的最先进的方法，而不需要利用额外的训练信息。此外，我们创新的损失函数使模型能够仅使用未标记的图像自主恢复特定领域的尺度和偏移系数。 et.al.|[2309.09724](http://arxiv.org/abs/2309.09724)|null|
|**2023-09-18**|**Self-supervised Multi-view Clustering in Computer Vision: A Survey**|近年来，多视图聚类（MVC）在跨模态表示学习和数据驱动决策中具有重要意义。它通过利用多个视图之间的一致性和互补信息将样本聚类到不同的组中来实现这一点。然而，随着对比学习在计算机视觉领域的不断发展，自监督学习也取得了实质性的研究进展，并逐渐在MVC方法中占据主导地位。它通过设计代理任务来指导聚类过程，以挖掘图像和视频数据本身作为监督信息的表示。尽管自监督MVC发展迅速，但目前还没有一个全面的调查来分析和总结研究进展的现状。因此，本文探讨了自监督MVC出现的原因和优势，并讨论了常见数据集的内部联系和分类、数据问题、表示学习方法和自监督学习方法。本文不仅介绍了每一类方法的机制，还举例说明了如何使用这些技术。最后指出了一些有待进一步研究和发展的问题。 et.al.|[2309.09473](http://arxiv.org/abs/2309.09473)|null|
|**2023-09-17**|**Uncertainty-aware 3D Object-Level Mapping with Deep Shape Priors**|三维对象级映射是机器人技术中的一个基本问题，当推理过程中对象CAD模型不可用时，这一问题尤其具有挑战性。在这项工作中，我们提出了一个框架，可以为未知对象重建高质量的对象级映射。我们的方法以多个RGB-D图像作为输入，并为检测到的对象输出密集的3D形状和9-DoF姿势（包括3个比例参数）。我们方法的核心思想是利用形状类别的学习生成模型作为先验，并为3D重建制定概率、不确定性感知的优化框架。我们推导了一个概率公式，该公式通过两个新的损失函数传播形状并带来不确定性。与当前最先进的方法不同，我们在优化过程中明确地对对象形状和姿态的不确定性进行建模，从而产生高质量的对象级映射系统。此外，我们证明，由此产生的形状和姿态不确定性可以准确地反映我们物体地图的真实误差，也可以用于下游机器人任务，如主动视觉。我们对室内和室外真实世界的数据集进行了广泛的评估，实现了对最先进方法的实质性改进。我们的代码将在https://github.com/TRAILab/UncertainShapePose. et.al.|[2309.09118](http://arxiv.org/abs/2309.09118)|null|
|**2023-09-15**|**Uncertainty-Aware Multi-View Visual Semantic Embedding**|图像文本检索的关键挑战是有效地利用语义信息来测量视觉和语言数据之间的相似性。然而，使用实例级二进制标签，即每个图像与单个文本配对，无法捕捉不同语义单元之间的多个对应关系，导致多模态语义理解的不确定性。尽管最近的研究通过更复杂的模型结构或预训练技术捕获了细粒度的信息，但很少有研究直接建模对应关系的不确定性，以充分利用二进制标签。为了解决这个问题，我们提出了一个不确定性感知的多视图视觉语义嵌入（UAMVSE）}框架，该框架将整个图像-文本匹配分解为多视图-文本匹配。我们的框架引入了一个不确定性感知损失函数（UALoss），通过自适应地建模每个视图文本对应关系中的不确定性来计算每个视图文本损失的权重。不同的权重引导模型关注不同的语义信息，增强了模型理解图像和文本对应关系的能力。我们还通过对相似度矩阵进行归一化，设计了一种优化的图像-文本匹配策略，以提高模型性能。在Flicker30k和MS-COCO数据集上的实验结果表明，UAMVSE的性能优于最先进的模型。 et.al.|[2309.08154](http://arxiv.org/abs/2309.08154)|null|
|**2023-09-14**|**High-fidelity 3D Reconstruction of Solar Coronal Physics with the Updated CROBAR Method**|我们提出了一种将冠状重建到B对齐区域（CROBAR）方法扩展到线性无力场（LFFF）外推的方法，并将其应用于AIA、MDI和STEREO EUVI数据集的重建。结果表明，CROBAR不仅可以重建日冕发射结构，而且可以通过LFFF的螺旋度 $\alpha$ 参数帮助约束日冕场外推。他们还提供了一个真实世界的例子，说明CROBAR如何轻松地从多个角度整合信息，以改进其重建，我们还使用其他角度来帮助验证重建。我们还谈到了使用真实世界的发射通带，而不是使用DEM的理想化幂律型通带。最后，我们将CROBAR产生的发射与观测到的发射以及基于理想DEM的幂律产生的发射进行了比较。这些结果进一步说明了CROBAR在现实世界应用中的前景，我们提供了该软件的初步版本供下载。 et.al.|[2309.08053](http://arxiv.org/abs/2309.08053)|null|
|**2023-09-14**|**Combining Multiple View Components for Exploratory Visualization**|结构化复杂数据的分析，如基于聚类图的数据集，通常应用各种视觉表示技术和格式。目前大多数可用的探索性可视化工具和方法都建立在集成方案之上，用于同时显示研究对象和过程的多个方面。通常，这种方案将由多个视图组成的屏幕空间进行分区，并采用交互模式来关注数据驱动的项目。众所周知的概念，如概述加细节和重点加上下文，在用技术术语解释时是模棱两可的。因此，UI设计从业者需要对图形表示模块的视觉合成的基本方法进行审查和分类。我们建议对视图和焦点的基本组成部分进行描述，并概述它们的多种组合。 et.al.|[2309.07580](http://arxiv.org/abs/2309.07580)|null|
|**2023-09-13**|**Exploiting Multiple Priors for Neural 3D Indoor Reconstruction**|神经隐式建模允许在小物体上实现令人印象深刻的3D重建结果，而在大型室内场景中表现出显著的局限性。在这项工作中，我们提出了一种新的神经隐式建模方法，该方法利用多种正则化策略来实现大型室内环境的更好重建，同时仅依赖于图像。稀疏但准确的深度先验用于将场景锚定到初始模型。还引入了密集但不太准确的深度先验，它足够灵活，仍然可以让模型偏离它，以改进估计的几何结构。然后，提出了一种新的自监督策略来正则化估计的曲面法线。最后，可学习的曝光补偿方案允许应对具有挑战性的照明条件。实验结果表明，我们的方法在具有挑战性的室内场景中产生了最先进的3D重建。 et.al.|[2309.07021](http://arxiv.org/abs/2309.07021)|null|
|**2023-09-12**|**Semantic and Articulated Pedestrian Sensing Onboard a Moving Vehicle**|由于车辆的大的向前运动，很难从车载采集的视频执行3D重建。与标准基准相比，即使是物体检测和人体感应模型在板载视频上的表现也明显较差，因为与标准物体检测基准相比，物体经常出现在远离相机的地方，图像质量经常因运动模糊而降低，并且经常发生遮挡。这导致了交通数据特定基准的普及。最近，光探测和测距（LiDAR）传感器已经变得流行起来，可以直接估计深度，而无需执行3D重建。然而，与基于图像的方法相比，基于激光雷达的方法仍然缺乏远距离的关节式人体检测。我们假设，从激光雷达数据中针对关节式人体感知的基准可以增加对交通中人体感知和预测的研究，并可以改善行人的交通安全。 et.al.|[2309.06313](http://arxiv.org/abs/2309.06313)|null|
|**2023-09-12**|**SoccerNet 2023 Challenges Results**|SoccerNet 2023挑战赛是SoccerNet团队组织的第三届年度视频理解挑战赛。在第三版中，挑战由七项基于愿景的任务组成，分为三个主题。第一个主题，广播视频理解，由三个与描述视频广播中发生的事件相关的高级任务组成：（1）动作识别，专注于检索与足球全局动作相关的所有时间戳，专注于用自然语言和锚定时间戳描述广播。第二个主题，场理解，涉及（4）相机校准的单一任务，重点是从图像中检索内在和外在的相机参数。第三个也是最后一个主题，球员理解，由三个与提取球员信息相关的低级任务组成：（5）重新识别，重点是在多个视图中检索相同的球员，（6）多对象跟踪，重点是通过未经编辑的视频流跟踪球员和球，以及（7）球衣号码识别，专注于从tracklets中识别球员的球衣号码。与以前版本的SoccerNet挑战相比，任务（2-3-7）是新颖的，包括新的注释和数据，任务（4）用更多的数据和注释进行了增强，任务（6）现在专注于端到端方法。有关任务、挑战和排行榜的更多信息，请访问https://www.soccer-net.org.基线和开发工具包可在https://github.com/SoccerNet. et.al.|[2309.06006](http://arxiv.org/abs/2309.06006)|**[link](https://github.com/lRomul/ball-action-spotting)**|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-18**|**Generating and Imputing Tabular Data via Diffusion and Flow-based Gradient-Boosted Trees**|表格数据很难获取，并且可能会丢失值。本文提出了一种使用基于分数的扩散和条件流匹配生成和估算混合类型（连续和分类）表格数据的新方法。与之前依赖神经网络作为函数逼近器的工作相反，我们使用了XGBoost，一种流行的梯度增强树（GBT）方法。除了优雅之外，我们在各种数据集上实证表明，我们的方法i）在训练数据集干净或被缺失数据污染时生成高度真实的合成数据，以及ii）生成各种合理的数据输入。我们的方法通常优于深度学习生成方法，并且可以在不需要GPU的情况下使用CPU进行并行训练。为了使其易于访问，我们通过PyPI上的Python库和CRAN上的R包发布了代码。 et.al.|[2309.09968](http://arxiv.org/abs/2309.09968)|null|
|**2023-09-18**|**Extended defects-enhanced oxygen diffusion in ThO2**|氧自扩散是理解氧化物核燃料化学计量和缺陷结构的关键。在实验中，在候选核燃料ThO $_2$中发现了低活化势垒氧迁移，这可能是由于短路扩散机制。在这里，我们进行了广泛的分子动力学模拟，以表明各种类型的扩展缺陷可以增强氧的自扩散，ThO$_2$中的激活势垒大大降低。在这项工作中，我们考虑了扩展缺陷，包括1D（位错）、2D（晶界）和3D（空穴）缺陷。由于每种类型的扩展缺陷具有不同的特征，氧扩散的调制也各不相同。这些结果提供了氧传输的定量描述，氧传输在距离延伸缺陷近距离（纳米级）内显著增强。在所有这些缺陷中，晶界，特别是具有低形成能的$\Sigma 3$ 孪晶边界，对增加氧传输表现出最强的影响。 et.al.|[2309.09952](http://arxiv.org/abs/2309.09952)|null|
|**2023-09-18**|**What is a Fair Diffusion Model? Designing Generative Text-To-Image Models to Incorporate Various Worldviews**|生成文本到图像（GTI）模型从简短的文本描述中生成高质量的图像，并广泛应用于学术和创意领域。然而，GTI模型经常放大训练数据中的偏见，经常产生偏见或刻板印象。然而，目前的偏见缓解战略是有限的，主要侧重于加强各职业的性别平等。为了增强GTI偏见缓解，我们引入了DiffusionWorldViewer，这是一种分析和操纵GTI模型对影响其生成图像的世界的态度、价值观、故事和期望的工具。通过部署为基于web的GUI和Jupyter Notebook插件的交互式界面，DiffusionWorldViewer对GTI生成的图像的现有人口统计进行分类，并提供将图像人口统计与用户世界观相一致的交互式方法。在一项针对13名GTI用户的研究中，我们发现DiffusionWorldViewer允许用户表达他们对GTI输出公平的不同观点，并在这样做的过程中挑战了当前假设普遍世界观的公平观念。 et.al.|[2309.09944](http://arxiv.org/abs/2309.09944)|**[link](https://github.com/zoedesimone/diffusionworldviewer)**|
|**2023-09-18**|**Direct topological insulator transitions in three dimensions are destabilized by non-perturbative effects of disorder**|我们重新考虑三维 $\mathbb的相图{Z}_2$ 拓扑绝缘体在存在短程势无序的情况下，具有非微扰稀有态使分离不同拓扑相的非相互作用Dirac半金属临界点不稳定的见解。基于我们关于态密度、电导率和波函数的数值数据，我们认为，由于稀有区域的非微扰效应，假定的狄拉克半金属线不稳定为有限程度的扩散金属相。我们讨论了这些结果对掺杂拓扑绝缘体过去和现在的实验的影响。 et.al.|[2309.09857](http://arxiv.org/abs/2309.09857)|null|
|**2023-09-18**|**DriveDreamer: Towards Real-world-driven World Models for Autonomous Driving**|世界模型，尤其是自动驾驶模型，由于其理解驾驶环境的能力，正在成为趋势并引起广泛关注。已建立的世界模式在生成高质量驾驶视频和安全驾驶政策方面具有巨大潜力。然而，相关研究的一个关键局限性在于其主要关注游戏环境或模拟设置，从而缺乏真实世界驾驶场景的表现。因此，我们介绍DriveDreamer，这是一款完全源自现实世界驾驶场景的开创性世界车型。考虑到在复杂的驾驶场景中建模世界需要巨大的搜索空间，我们建议利用强大的扩散模型来构建复杂环境的综合表示。此外，我们引入了一个两阶段的培训管道。在最初阶段，DriveDreamer对结构化交通约束有了深刻的理解，而在随后的阶段，它具备了预测未来状态的能力。拟议中的DriveDreamer是第一个根据真实驾驶场景建立的世界模型。我们在具有挑战性的nuScenes基准上实例化了DriveDreamer，大量实验验证了DriveDreamer能够精确、可控地生成视频，忠实地捕捉现实世界交通场景的结构约束。此外，DriveDreamer能够制定现实合理的驾驶政策，为互动和实际应用开辟途径。 et.al.|[2309.09777](http://arxiv.org/abs/2309.09777)|null|
|**2023-09-18**|**Application-driven Validation of Posteriors in Inverse Problems**|当前用于图像分析任务的基于深度学习的解决方案通常无法处理存在多种不同合理解决方案的问题。作为回应，出现了基于后验的方法，如条件扩散模型和可逆神经网络；然而，由于缺乏对充分验证的研究，它们的翻译受到了阻碍。换句话说，衡量进度的方式往往不能反映驾驶实际应用的需求。为了填补文献中的这一空白，我们提出了第一个系统框架，用于反问题中基于后验方法的应用驱动验证。作为一种新颖的方法，它采用了物体检测验证领域的关键原理，该领域在解决如何定位和匹配图像中的多个物体实例的问题方面有着悠久的历史。将模式视为实例使我们能够从应用程序的角度使用可解释的度量来执行以模式为中心的验证。我们通过一个合成玩具示例和两个医学视觉用例的实例来证明我们的框架的价值：手术中的姿势估计和用于诊断的基于成像的功能组织参数量化。在所有三个例子中，我们的框架都提供了优于后验验证常用方法的关键优势，因此可以彻底改变反问题中的性能评估。 et.al.|[2309.09764](http://arxiv.org/abs/2309.09764)|null|
|**2023-09-18**|**TeV gamma-ray sensitivity to velocity-dependent dark matter models in the Galactic Center**|银河系中心是寻找暗物质（DM）湮灭信号的主要地点，因为它很近，预计DM浓度很高。由于重子收缩和反馈，DM粒子在银河系中心（GC）的分散速度放大，使得这一特定的天空区域成为探索速度相关DM模型的更有希望的目标。在这里，我们证明了目前使用H.E.S.S.望远镜进行的GC观测，即目前在该地区运行的最灵敏的TeV级伽马射线望远镜，对质量超过200 GeV的DM粒子的速度依赖性湮灭设置了最强的约束。对于p波湮灭，对于1TeV的DM质量，它们将电流约束提高了 $\sim$4。对于DM的空间分布，我们使用了银河系大小晕的最新FIRE-2变焦宇宙学模拟结果。此外，我们利用最新版本的GALPROP宇宙射线传播框架来模拟GC中的银河漫伽马射线发射。我们发现，质量约为1.7TeV并湮灭到$W^+$W^-$通道中的p波（d波）DM粒子在95%置信水平下表现出4.6$\乘以$10$^{-22}$cm$^3$s$^{-1}$（9.2$\乘以$10$^{-17}$cm$^3$s$^{-1}$）的速度加权湮灭截面上限。这大约是p波（d波）DM模型的热遗迹横截面的460倍（2$\times$10$^{6}$ ）。 et.al.|[2309.09691](http://arxiv.org/abs/2309.09691)|null|
|**2023-09-19**|**Non-Hermitian physics and topological phenomena in convective thermal metamaterials**|非埃尔米特物理和拓扑现象是凝聚态物理和人工超材料研究的两个热点。热超材料是一种可以自行控制热量的超材料。最近，人们发现非埃尔米特物理和拓扑现象可以在纯扩散系统中实现。然而，由于自由度的缺失，传导本身并不是万能的。伴随着传导的热对流能够实现大量的相。在这篇综述中，我们将介绍一些关于非埃尔米特和拓扑对流热超材料的重要工作。在非埃尔米特物理学中，我们将首先讨论异常点（EP）在热扩散中的实现，然后讨论高阶EP和EP的动态包围。然后，我们讨论了EP在扩散系统中的两个推广工作，即EP附近的手性热行为和Weyl例外环。对于拓扑相，我们将讨论两个例子：一维拓扑绝缘体和二维四极拓扑绝缘体。最后，我们将得出结论，并对这一领域提出有希望的展望。除了科学价值外，非埃尔米特和拓扑对流热超材料还有很大的工业应用潜力。 et.al.|[2309.09681](http://arxiv.org/abs/2309.09681)|null|
|**2023-09-18**|**Single and Few-step Diffusion for Generative Speech Enhancement**|扩散模型在语音增强中显示出了很好的结果，它使用了一个任务自适应的扩散过程来有条件地生成给定噪声混合物的干净语音。然而，在测试时，用于分数估计的神经网络被多次调用，以解决迭代反向过程。这导致推理过程缓慢，并导致在采样轨迹上积累的离散化误差。在本文中，我们通过两阶段的训练方法来解决这些局限性。在第一阶段，我们使用生成去噪分数匹配损失以通常的方式训练扩散模型。在第二阶段，我们通过求解反向过程来计算增强信号，并使用预测损失将所得估计与干净语音目标进行比较。我们表明，使用第二个训练阶段可以实现与基线模型相同的性能，只使用5个功能评估，而不是60个功能评估。虽然当降低函数评估（NFE）的数量以获得单步扩散时，通常的生成扩散算法的性能会显著下降，但我们表明，我们提出的方法保持了稳定的性能，因此在很大程度上优于该设置下的扩散基线，并且比其预测对应方法更好地推广。 et.al.|[2309.09677](http://arxiv.org/abs/2309.09677)|null|
|**2023-09-18**|**Anomalous Diffusion of Lithium-Anion Clusters in Ionic Liquids**|锂离子在离子液体（ILs）中的传输显著延迟。在这项工作中，我们使用[\emph进行了广泛的分子动力学（MD）模拟，以模拟离子液体中锂离子的动力学{N}-methyl-\emph{N}-propylpyrrolidium（pyr $_{13}$）][双（三氟甲磺酰基）酰亚胺（Ntf$_{2}$）]与添加的LiNtf$_{2}$盐。我们分析了它们的传输，开发了一个两状态模型，并将其与机器学习识别的状态进行了比较。锂离子的传输涉及介质中Ntf$_{2}$的局部壳层交换。我们计算了不同时间尺度上的列车大小分布。列车尺寸分布作为幂律衰减，代表非Poissonian爆壳交换。我们将锂离子传输的非泊松过程作为一个两态（软态和硬态）模型进行了分析。我们分析计算了两态模型的跃迁概率，它很好地拟合了LiNtf$_{2}$ 壳层的寿命自相关函数。为了识别两种状态，我们引入了包含局部分子结构的图中性网络。结果表明，壳的软态主要有助于锂离子的传输，在低温下它们的贡献更为重要。因此，提高壳层软态的比例是增强锂离子传输的关键。 et.al.|[2309.09674](http://arxiv.org/abs/2309.09674)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-09-15**|**Breathing New Life into 3D Assets with Generative Repainting**|基于扩散的文本到图像模型引发了视觉社区、艺术家和内容创作者的巨大关注。这些模型的广泛采用是由于世代质量的显著提高以及对各种模式的有效调节，而不仅仅是文本。然而，将这些2D模型的丰富生成先验提升到3D中是具有挑战性的。最近的工作提出了由扩散模型和神经场的纠缠提供动力的各种管道。我们探索了预训练的2D扩散模型和标准3D神经辐射场作为独立工具的威力，并展示了它们以非学习方式协同工作的能力。这种模块化具有易于部分升级的内在优势，这在这样一个快节奏的领域中成为了一个重要的特性。我们的管道接受任何遗留的可渲染几何体，如纹理或无纹理网格，协调2D生成细化和3D一致性强制工具之间的交互，并以多种格式输出绘制的输入几何体。我们对ShapeNetSem数据集中的广泛对象和类别进行了大规模研究，并从定性和定量两个方面展示了我们方法的优势。项目页面：https://www.obukhov.ai/repainting_3d_assets et.al.|[2309.08523](http://arxiv.org/abs/2309.08523)|**[link](https://github.com/toshas/remesh_isotropic_planar)**|
|**2023-09-14**|**Neural Field Representations of Articulated Objects for Robotic Manipulation Planning**|传统的操作规划方法依赖于环境的显式几何模型来将给定任务公式化为优化问题。然而，从原始传感器输入推断准确的模型本身就是一个难题，尤其是对于铰接物体（例如壁橱、抽屉）。在本文中，我们提出了一种关节对象的神经场表示（NFR），可以直接从图像中进行操作规划。具体来说，在拍摄了一个新的关节物体的几张照片后，我们可以向前模拟它可能的运动，因此，可以直接使用该神经模型进行轨迹优化规划。此外，这种表示可以用于形状重建、语义分割和图像渲染，这在训练和泛化过程中提供了强大的监督信号。我们表明，我们的模型仅在合成图像上训练，能够在模拟和真实图像中为同类看不见的物体提取有意义的表示。此外，我们证明了该表示能够直接从图像中对现实世界中的关节物体进行机器人操作。 et.al.|[2309.07620](http://arxiv.org/abs/2309.07620)|null|
|**2023-09-13**|**Generalizable Neural Fields as Partially Observed Neural Processes**|神经场将信号表示为由神经网络参数化的函数，是传统离散矢量或基于网格的表示的一种很有前途的替代方案。与离散表示相比，神经表示既能很好地扩展分辨率，又是连续的，并且可以是多次可微的。然而，给定我们想要表示的信号数据集，必须为每个信号优化单独的神经场是低效的，并且不能利用信号之间的共享信息或结构。现有的泛化方法将其视为元学习问题，并采用基于梯度的元学习来学习初始化，然后通过测试时间优化对初始化进行微调，或者学习超网络来产生神经场的权重。相反，我们提出了一种新的范式，将神经表征的大规模训练视为部分观察到的神经过程框架的一部分，并利用神经过程算法来解决这一任务。我们证明，这种方法优于最先进的基于梯度的元学习方法和超网络方法。 et.al.|[2309.06660](http://arxiv.org/abs/2309.06660)|null|
|**2023-09-08**|**Single View Refractive Index Tomography with Neural Fields**|折射率层析成像是一个反问题，我们试图从2D投影图像测量中重建场景的3D折射场。折射场本身是不可见的，而是影响光线在空间中传播时路径的连续弯曲。折射场出现在各种各样的科学应用中，从显微镜中的半透明细胞样本到弯曲来自遥远星系的光的暗物质场。这个问题带来了一个独特的挑战，因为折射场直接影响光的路径，使其恢复成为一个非线性问题。此外，与传统的层析成像相比，我们试图通过利用散射在整个介质中的光源的知识，仅从单个视点使用投影图像来恢复折射场。在这项工作中，我们介绍了一种使用基于坐标的神经网络对场景中潜在的连续折射场进行建模的方法。然后，我们使用射线三维空间曲率的显式建模来优化该网络的参数，通过综合分析方法重建折射场。通过在模拟中恢复折射场，并分析光源分布对恢复的影响，证明了我们方法的有效性。然后，我们在模拟暗物质映射问题上测试了我们的方法，在该问题中，我们恢复了真实模拟暗物质分布下的折射场。 et.al.|[2309.04437](http://arxiv.org/abs/2309.04437)|null|
|**2023-09-07**|**BluNF: Blueprint Neural Field**|神经辐射场（NeRF）彻底改变了场景新颖的视图合成，提供了视觉逼真、精确和稳健的隐式重建。虽然最近的方法允许NeRF编辑，例如对象删除、3D形状修改或材料特性操纵，但在这种编辑之前的手动注释使该过程变得乏味。此外，传统的2D交互工具缺乏对3D空间的准确感知，阻碍了对场景的精确操作和编辑。在本文中，我们介绍了一种新的方法，称为蓝图神经场（BluNF），以解决这些编辑问题。BluNF提供了一个强大且用户友好的2D蓝图，实现了直观的场景编辑。通过利用隐式神经表示，BluNF使用先前的语义和深度信息构建场景的蓝图。生成的蓝图可以轻松编辑和操作NeRF表示。我们通过直观的点击和更改机制展示了BluNF的可编辑性，实现了3D操作，如遮罩、外观修改和对象移除。我们的方法对视觉内容创作做出了重大贡献，为该领域的进一步研究铺平了道路。 et.al.|[2309.03933](http://arxiv.org/abs/2309.03933)|null|
|**2023-09-07**|**SimNP: Learning Self-Similarity Priors Between Neural Points**|用于3D对象重建的现有神经场表示要么（1）利用对象级表示，但由于对全局潜在代码的限制而遭受低质量细节，要么（2）能够完美地重建观测，但未能利用对象级先验知识来推断未观察到的区域。我们提出了一种学习类别级自相似性的方法SimNP，它通过将神经点辐射场与类别级自类似性表示相连接，结合了两个世界的优点。我们的贡献是双重的。（1） 我们利用相干点云的概念设计了第一个类别级别的神经点表示。由此产生的神经点辐射场为局部支持的对象区域存储了高级别的细节。（2） 我们了解了如何以无约束和无监督的方式在神经点之间共享信息，这允许在重建过程中根据给定的观测值导出对象的未观察区域。我们表明，SimNP在重建对称的看不见物体区域方面优于以前的方法，超过了建立在类别级或像素对齐辐射场上的方法，同时提供了实例之间的语义对应 et.al.|[2309.03809](http://arxiv.org/abs/2309.03809)|null|
|**2023-09-06**|**CoNeS: Conditional neural fields with shift modulation for multi-sequence MRI translation**|多序列磁共振成像（MRI）在现代临床研究和深度学习研究中都有广泛的应用。然而，在临床实践中，由于患者的不同图像采集协议或造影剂禁忌症，经常会出现一个或多个MRI序列缺失的情况，这限制了在多序列数据上训练的深度学习模型的使用。一种很有前途的方法是利用生成模型来合成缺失的序列，这可以作为替代获取。解决这一问题的最先进方法是基于卷积神经网络（CNN），该网络通常存在频谱偏差，导致高频精细细节的重建较差。在本文中，我们提出了具有移位调制的条件神经场（CoNeS），这是一种以体素坐标为输入并学习用于多序列MRI平移的目标图像的表示的模型。所提出的模型使用多层感知器（MLP）代替CNN作为像素到像素映射的解码器。因此，每个目标图像被表示为神经场，该神经场通过利用学习的潜码的移位调制而被调节在源图像上。在BraTS 2018和前庭神经鞘瘤患者的内部临床数据集上进行的实验表明，所提出的方法在视觉和定量上都优于最先进的多序列MRI翻译方法。此外，我们进行了光谱分析，表明CoNeS能够克服传统CNN模型中常见的光谱偏差问题。为了进一步评估合成图像在临床下游任务中的使用，我们在推理时使用合成图像测试了分割网络。 et.al.|[2309.03320](http://arxiv.org/abs/2309.03320)|**[link](https://github.com/cyjdswx/cones)**|
|**2023-09-06**|**ResFields: Residual Neural Fields for Spatiotemporal Signals**|神经场是一类被训练来表示高频信号的神经网络，近年来由于其在复杂三维数据建模方面的出色性能，特别是通过单个多层感知器（MLP）的大神经符号距离（SDFs）或辐射场（NeRFs），而受到了极大的关注。然而，尽管用MLP表示信号的能力和简单性很强，但由于MLP的容量有限，这些方法在建模大而复杂的时间信号时仍然面临挑战。在本文中，我们提出了一种有效的方法来解决这一限制，将时间残差层纳入神经场，称为ResFields，这是一类专门设计用于有效表示复杂时间信号的新型网络。我们对ResFields的性质进行了全面的分析，并提出了一种矩阵分解技术来减少可训练参数的数量并增强泛化能力。重要的是，我们的公式与现有技术无缝集成，并在各种具有挑战性的任务中持续改进结果：2D视频近似、通过时间SDF的动态形状建模和动态NeRF重建。最后，我们通过展示ResFields在从轻量级捕捉系统的稀疏感官输入捕捉动态3D场景方面的有效性，展示了它的实用性。 et.al.|[2309.03160](http://arxiv.org/abs/2309.03160)|**[link](https://github.com/markomih/ResFields)**|
|**2023-09-01**|**GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields**|开发能够在非结构化现实世界环境中通过视觉观察执行各种操作任务的代理是机器人技术中的一个长期问题。为了实现这一目标，机器人需要对场景的3D结构和语义有全面的了解。在这项工作中，我们提出了 $\textbf｛GNFactor｝$，一种用于多任务机器人操作的视觉行为克隆代理，具有$\textbf｛G｝$通用$\textbf｛N｝$eural功能$\textbf｛F｝$字段。GNFactor联合优化了作为重建模块的可推广神经场（GNF）和作为决策模块的感知转换器，利用了共享的深度3D体素表示。为了在3D中结合语义，重建模块利用视觉语言基础模型（$\textit｛例如｝$ ，Stable Diffusion）将丰富的语义信息提取到深度3D体素中。我们在3个真实机器人任务中评估了GNFactor，并在10个RLBench任务中进行了详细的消融，演示次数有限。我们观察到GNFactor在可见和不可见任务中比当前最先进的方法有了实质性的改进，证明了GNFactor强大的泛化能力。我们的项目网站是https://yanjieze.com/GNFactor/。 et.al.|[2308.16891](http://arxiv.org/abs/2308.16891)|**[link](https://github.com/YanjieZe/GNFactor)**|
|**2023-08-30**|**Active Neural Mapping**|我们用不断学习的神经场景表示来解决主动映射的问题，即主动神经映射。关键在于通过有效的代理移动积极找到要探索的目标空间，从而最大限度地减少在以前看不见的环境中飞行中的地图不确定性。在本文中，我们检验了连续学习神经场的权重空间，并从经验上表明，神经变异性，即对随机权重扰动的预测鲁棒性，可以直接用于测量神经映射的瞬时不确定性。结合神经映射中继承的连续几何信息，可以引导agent找到一条可遍历的路径，以逐渐获得环境知识。我们首次提出了一种用于在线场景重建的具有基于坐标的隐式神经表示的主动映射系统。在视觉逼真的Gibson和Matterport3D环境中的实验证明了所提出方法的有效性。 et.al.|[2308.16246](http://arxiv.org/abs/2308.16246)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

