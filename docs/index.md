---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.07.21
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-07-18**|**Shape of Motion: 4D Reconstruction from a Single Video**|由于单眼动态重建任务的高度不适定性，它是一个具有挑战性和长期存在的视觉问题。现有的方法存在局限性，因为它们要么依赖于模板，要么仅在准静态场景中有效，要么无法明确地对3D运动进行建模。在这项工作中，我们介绍了一种能够从随意捕获的单眼视频中重建具有显式、全序列长3D运动的通用动态场景的方法。我们通过两个关键的见解来解决这个问题的欠约束性质：首先，我们通过用一组紧凑的SE3运动基表示场景运动来利用3D运动的低维结构。每个点的运动都表示为这些基的线性组合，有助于将场景软分解为多个刚性移动的组。其次，我们利用了一套全面的数据驱动先验，包括单眼深度图和长距离2D轨迹，并设计了一种方法来有效地整合这些嘈杂的监控信号，从而得到动态场景的全局一致表示。实验表明，我们的方法在长距离3D/2D运动估计和动态场景上的新颖视图合成方面都取得了最先进的性能。项目页面：https://shape-of-motion.github.io/ et.al.|[2407.13764](http://arxiv.org/abs/2407.13764)|null|
|**2024-07-18**|**Streetscapes: Large-scale Consistent Street View Generation Using Autoregressive Video Diffusion**|我们提出了一种通过动态合成的城市尺度场景生成街景长序列视图的方法。我们这一代人受到语言输入（如城市名称、天气）以及承载所需轨迹的底层地图/布局的制约。与最近的视频生成或3D视图合成模型相比，我们的方法可以扩展到更远的摄像机轨迹，跨越几个街区，同时保持视觉质量和一致性。为了实现这一目标，我们基于最近在视频扩散方面的工作，在一个可以轻松扩展到长序列的自回归框架内使用。特别是，我们引入了一种新的时间插补方法，可以防止我们的自回归方法偏离现实城市图像的分布。我们使用来自谷歌街景的令人信服的数据源来训练我们的街景系统，这些数据源包括图像，以及上下文地图数据，这些数据允许用户根据任何所需的城市布局生成城市景观，并具有可控的摄像器姿态。请在我们的项目页面上查看更多结果https://boyangdeng.com/streetscapes. et.al.|[2407.13759](http://arxiv.org/abs/2407.13759)|null|
|**2024-07-18**|**KFD-NeRF: Rethinking Dynamic NeRF with Kalman Filter**|我们介绍了KFD NeRF，这是一种新型的动态神经辐射场，与基于卡尔曼滤波的高效高质量运动重建框架相结合。我们的关键思想是将动态辐射场建模为一个动态系统，其时变状态基于两个知识来源进行估计：观测和预测。我们介绍了一种新的插件卡尔曼滤波器引导的变形场，该变形场能够根据场景观测和预测进行精确的变形估计。我们使用浅层多层感知器（MLP）进行观测，并将运动建模为局部线性，以使用运动方程计算预测。为了进一步提高观测MLP的性能，我们在规范空间中引入正则化，以提高网络学习不同帧扭曲的能力。此外，我们采用了一种高效的三平面表示来编码规范空间，该表示已被实验证明可以快速、高质量地收敛。这使我们能够使用较浅的观测MLP，在我们的实现中仅由两层组成。我们对合成数据和真实数据进行了实验，并与过去的动态NeRF方法进行了比较。我们的KFD NeRF在相当的计算时间内表现出类似甚至更优的渲染性能，并通过彻底的训练实现了最先进的视图合成性能。 et.al.|[2407.13185](http://arxiv.org/abs/2407.13185)|null|
|**2024-07-17**|**Generalizable Human Gaussians for Sparse View Synthesis**|神经渲染的最新进展带来了开创性的方法，如NeRF和高斯散斑，这些方法彻底改变了AR/VR、游戏和内容创建等各个领域的视图渲染。虽然这些方法擅长在训练数据中插值，但从非常稀疏的视图推广到新场景和对象的挑战仍然存在。具体来说，由于人体几何形状的固有复杂性，从稀疏视图对3D人体进行建模存在巨大的障碍，导致几何和纹理的重建不准确。为了应对这一挑战，本文利用高斯散布的最新进展，介绍了一种学习可推广的人类高斯分布的新方法，该方法允许以前馈方式从有限的稀疏视图集中对新的人类对象进行逼真和精确的视图渲染。我们方法的一个关键创新是将3D高斯参数的学习重新表述为在人类模板的2D UV空间上定义的回归过程，这允许利用强几何先验和2D卷积的优点。此外，还提出了一种多脚手架来有效地表示偏移细节。我们的方法在数据集内泛化和跨数据集泛化设置上都优于最近的方法。 et.al.|[2407.12777](http://arxiv.org/abs/2407.12777)|null|
|**2024-07-17**|**Efficient Depth-Guided Urban View Synthesis**|隐式场景表示的最新进展实现了高保真街景新视图合成。然而，现有的方法严重依赖密集的训练图像和大量的计算资源，为每个场景优化神经辐射场。为了减轻这一缺点，我们引入了一种名为高效深度引导城市景观合成（EDUS）的新方法，用于快速前馈推理和高效的每场景微调。与基于特征匹配推断几何的先前可推广方法不同，EDUS利用噪声预测的几何先验作为指导，从稀疏输入图像中实现可推广的城市景观合成。几何先验允许我们直接在3D空间中应用我们的可推广模型，在各种稀疏级别上获得鲁棒性。通过在KITTI-360和Waymo数据集上的综合实验，我们展示了对新颖街道场景的有前景的泛化能力。此外，我们的结果表明，当与快速测试时间优化相结合时，EDUS在稀疏视图设置中实现了最先进的性能。 et.al.|[2407.12395](http://arxiv.org/abs/2407.12395)|null|
|**2024-07-17**|**Splatfacto-W: A Nerfstudio Implementation of Gaussian Splatting for Unconstrained Photo Collections**|由于光度变化和瞬态遮挡使精确的场景重建复杂化，从无约束的野生图像集合中进行新的视图合成仍然是一项重要但具有挑战性的任务。以前的方法通过在神经辐射场（NeRF）中集成每幅图像的外观特征嵌入来解决这些问题。尽管3D高斯散斑（3DGS）提供了更快的训练和实时渲染，但由于架构的显著不同，将其应用于无约束的图像集合并非易事。在本文中，我们介绍了Splatfacto-W，这是一种将每高斯神经颜色特征和每图像外观嵌入集成到光栅化过程中的方法，以及基于球面谐波的背景模型，用于表示不同的光度外观并更好地描绘背景。我们的主要贡献包括潜在外观建模、高效的瞬态对象处理和精确的背景建模。Splatfacto-W提供高质量、实时的新颖视图合成，在野外场景中提高了场景一致性。与3DGS相比，我们的方法将峰值信噪比（PSNR）平均提高了5.3 dB，与基于NeRF的方法相比，训练速度提高了150倍，并实现了与3DGS相似的渲染速度。集成到Nerfstudio中的其他视频结果和代码可在以下网址获得https://kevinxu02.github.io/splatfactow/. et.al.|[2407.12306](http://arxiv.org/abs/2407.12306)|null|
|**2024-07-16**|**NeuSurfEmb: A Complete Pipeline for Dense Correspondence-based 6D Object Pose Estimation without CAD Models**|6D物体姿态估计的最新方法假设CAD模型的可用性，并要求用户手动设置基于物理的渲染（PBR）管道以生成合成训练数据。这两个因素都限制了这些方法在现实世界场景中的应用。在这项工作中，我们提出了一种不需要CAD模型的管道，并允许训练最先进的姿态估计器，只需要一小部分真实图像作为输入。我们的方法基于NeuS2对象表示，我们通过基于运动结构（SfM）和对象无关分割的半自动过程来学习。我们利用NeuS2的新颖视图合成能力和简单的剪切粘贴增强来自动生成逼真的对象渲染，我们用它来训练基于对应的SurfEmb姿态估计器。我们在LINEMOD Occlusion数据集上评估了我们的方法，广泛研究了其各个组件的影响，并展示了基于CAD模型和PBR数据的方法的竞争性能。我们还展示了我们的管道在自我收集的真实世界对象上的易用性和有效性，表明我们的方法优于最先进的无CAD模型方法，对轻度遮挡具有更好的准确性和鲁棒性。为了让机器人社区从该系统中受益，我们将在https://www.github.com/ethz-asl/neusurfemb. et.al.|[2407.12207](http://arxiv.org/abs/2407.12207)|**[link](https://github.com/ethz-asl/neusurfemb)**|
|**2024-07-18**|**IPA-NeRF: Illusory Poisoning Attack Against Neural Radiance Fields**|神经辐射场（NeRF）代表了计算机视觉的一个重大进步，提供了隐式的基于神经网络的场景表示和新颖的视图合成功能。它的应用涵盖了不同的领域，包括机器人、城市地图、自主导航、虚拟现实/增强现实等，其中一些被认为是高风险的人工智能应用。然而，尽管NeRF被广泛采用，但其稳健性和安全性在很大程度上仍未得到探索。在这项研究中，我们通过引入针对神经辐射场的幻觉中毒攻击（IPA-NeRF）为这一领域做出了贡献。这种攻击涉及在NeRF中嵌入一个隐藏的后门视图，使其在提供指定的后门视图时能够产生预定的输出，即虚幻的输出，同时保持标准输入的正常性能。我们的攻击是专门为在特定位置欺骗用户或下游模型而设计的，同时确保从其他角度无法检测到NeRF中的任何异常。实验结果证明了我们的幻觉中毒攻击的有效性，在指定的视点上成功地呈现了所需的幻觉，而不会影响其他视图。值得注意的是，我们通过仅向训练集引入小扰动来实现这种攻击。代码可以在以下网址找到https://github.com/jiang-wenxiang/IPA-NeRF. et.al.|[2407.11921](http://arxiv.org/abs/2407.11921)|**[link](https://github.com/jiang-wenxiang/ipa-nerf)**|
|**2024-07-16**|**Ev-GS: Event-based Gaussian splatting for Efficient and Accurate Radiance Field Rendering**|与传统的基于帧的方法相比，使用事件相机的计算神经形态成像（CNI）具有运动模糊最小和动态范围增强等优点。现有的基于事件的辐射场渲染方法建立在神经辐射场的基础上，计算量大，重建速度慢。受这两个方面的启发，我们介绍了Ev-GS，这是第一个基于CNI的方案，用于从单目事件相机推断3D高斯飞溅，从而实现高效的新颖视图合成。利用3D高斯模型和纯粹的基于事件的监督，Ev-GS克服了检测快速移动物体和照明不足等挑战。实验结果表明，Ev-GS通过渲染具有减少模糊和提高视觉质量的真实视图，优于以基于帧的信号作为输入的方法。此外，与现有方法相比，它展示了具有竞争力的重建质量和减少的计算占用，为高效的CNI信号处理方法铺平了道路。 et.al.|[2407.11343](http://arxiv.org/abs/2407.11343)|null|
|**2024-07-15**|**AirNeRF: 3D Reconstruction of Human with Drone and NeRF for Future Communication Systems**|在快速发展的数字内容创作领域，对快速、方便和自主制作人类详细3D重建方法的需求显著增长。为了满足这一迫切需求，我们的AirNeRF系统为创建逼真的3D人体化身提供了一条创新途径。我们的方法利用神经辐射场（NeRF）和基于无人机的自动视频捕获方法。所获得的数据提供了一种快速准确的方法，可以在我们系统的几个阶段后创建高质量的人体重建。从我们的系统中得出的装配网格被证明是动态人类自由视图合成的良好基础，特别适合游戏和虚拟现实中的沉浸式体验。 et.al.|[2407.10865](http://arxiv.org/abs/2407.10865)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-07-18**|**MaRINeR: Enhancing Novel Views by Matching Rendered Images with Nearby References**|从3D重建中渲染逼真的图像是许多计算机视觉和机器人管道的重要任务，特别是对于混合现实应用以及在模拟环境中训练自主代理。然而，新颖视图的质量在很大程度上取决于源重建，由于噪声或缺少几何和外观，源重建往往是不完美的。受最近基于参考的超分辨率网络成功的启发，我们提出了MaRINeR，这是一种利用附近映射图像的信息来改善目标视点渲染的细化方法。我们首先基于深度特征在目标视点的场景几何的原始渲染图像和附近的参考之间建立匹配，然后进行分层细节传递。我们从显式和隐式场景表示的定量指标和定性示例中展示了改进的渲染。我们进一步将我们的方法应用于伪地面真实性验证、合成数据增强和细节恢复等下游任务，用于简化3D重建的渲染。 et.al.|[2407.13745](http://arxiv.org/abs/2407.13745)|null|
|**2024-07-18**|**EaDeblur-GS: Event assisted 3D Deblur Reconstruction with Gaussian Splatting**|随着神经辐射场（NeRF）和3D高斯散斑（3DGS）的发展，3D去模糊重建技术最近取得了重大进展。尽管这些技术可以从模糊的图像输入中恢复相对清晰的3D重建，但在处理严重模糊和复杂的相机运动方面仍然存在局限性。为了解决这些问题，我们提出了高斯散斑事件辅助3D去模糊重建（EaDeblur GS），它集成了事件相机数据，以增强3DGS对运动模糊的鲁棒性。通过采用自适应偏差估计器（ADE）网络来估计高斯中心偏差，并使用新的损失函数，EaDeblur GS实时实现了清晰的3D重建，其性能可与最先进的方法相媲美。 et.al.|[2407.13520](http://arxiv.org/abs/2407.13520)|null|
|**2024-07-17**|**Edge Projection-Based Adaptive View Selection for Cone-Beam CT**|附加制造部件的工业锥束X射线计算机断层扫描（CT）扫描从部件围绕单个轴的多个预定旋转角度采集的投影测量中产生3D重建。通常，需要大量的投影来实现高质量的重建，这一过程可能会持续几个小时或几天，具体取决于零件尺寸、材料成分和所需的分辨率。本文介绍了一种新颖的实时系统，旨在通过基于物体的几何形状和计算机辅助设计（CAD）模型智能选择最佳的下一个角度来优化扫描过程。这种选择过程在战略上平衡了与零件长边对齐的测量需求和保持一组不同的整体测量需求。通过模拟，我们证明，与传统方法相比，我们的算法显著减少了实现高质量重建所需的投影数量。 et.al.|[2407.12963](http://arxiv.org/abs/2407.12963)|null|
|**2024-07-17**|**HDLCopilot: Hardware Design Library Querying with Natural Language**|硬件设计工程师经常使用来自不同制造实验室的多个工艺设计套件（PDK），每个套件都包含几个标准单元库，针对速度、功率或密度等特定指标进行了优化。这些库包括多个视图，如用于计时信息的liberty文件、用于抽象布局细节的LEF文件和用于过程设计规则的技术LEF。在这个复杂的环境中导航以检索有关闸门或设计规则的特定信息通常既耗时又容易出错。为了解决这个问题，我们提出了HDLCopilot，这是一个基于LLM的PDK查询系统，允许工程师简化与自然语言格式的PDK的交互，使信息检索更加准确和高效。HDLCopilot在由各种复杂的自然语言查询组成的评估集上实现了94.23%的准确率。HDLCopilot将自己定位为硬件设计过程中的强大助手，提高了生产率并减少了潜在的人为错误。 et.al.|[2407.12749](http://arxiv.org/abs/2407.12749)|null|
|**2024-07-17**|**SG-NeRF: Neural Surface Reconstruction with Scene Graph Optimization**|从图像中重建3D表面对于许多应用至关重要。最近，神经辐射场（NeRFs）已经成为一种有前景的3D建模框架。然而，NeRF需要精确的相机姿态作为输入，现有的方法很难处理在现实世界场景中常见的噪声很大的姿态估计（即异常值）。为了应对这一挑战，我们提出了一种新方法，通过场景图优化辐射场，以减轻异常姿态的影响。我们的方法结合了一种基于场景图的自适应内层离群值置信度估计方案，强调图像与邻域的高度兼容性和渲染质量的一致性。我们还引入了一种有效的联合交叉（IoU）损失来优化相机姿态和表面几何形状，以及一种从粗到细的策略来促进训练。此外，我们提出了一个包含典型异常姿态的新数据集，用于详细评估。在各种数据集上的实验结果一致证明了我们的方法相对于现有方法的有效性和优越性，展示了它在处理异常值和生成高质量3D重建方面的鲁棒性。我们的代码和数据可在以下网址获得：\url{https://github.com/Iris-cyy/SG-NeRF}. et.al.|[2407.12667](http://arxiv.org/abs/2407.12667)|**[link](https://github.com/iris-cyy/sg-nerf)**|
|**2024-07-17**|**Serialized Point Mamba: A Serialized Point Cloud Mamba Segmentation Model**|点云分割对于机器人视觉感知和环境理解至关重要，可以实现机器人导航和3D重建等应用。然而，处理点云数据的稀疏和无序特性给高效和准确的分割带来了挑战。受Mamba模型在自然语言处理中的成功启发，我们提出了序列化点云Mamba分段模型（序列化点Mamba），该模型利用状态空间模型动态压缩序列，减少内存使用，提高计算效率。Serialized Point Mamba将局部全局建模功能与线性复杂性相结合，在室内和室外数据集上实现了最先进的性能。这种方法包括分阶段点云序列学习、网格池和条件位置编码等新技术，促进了不同点云任务的有效分割。我们的方法在Scannet上实现了76.8 mIoU，在S3DIS上实现了70.3 mIoU。在Scannetv2实例分段中，它记录了40.0 mAP。它还具有最低的延迟和合理的内存使用，使其成为基于曼巴的点语义分割模型中的SOTA。 et.al.|[2407.12319](http://arxiv.org/abs/2407.12319)|null|
|**2024-07-16**|**Learning Multi-view Anomaly Detection**|本研究探讨了最近提出的具有挑战性的多视图异常检测（AD）任务。单视图任务会遇到其他视角的盲点，导致样本级预测不准确。因此，我们引入\textbf{M}ulti-\textbf{V}iew\textbf{A}nomaly\textbf{D}etection（\textbf{MVAD}）框架，它从多个视图学习和集成功能。具体来说，我们提出了一个\textbf{M}ulti-\textbf{V}iew\textbf{A}daptive\textbf{S}election（\textbf{MVAS}）算法，用于跨多个视图的特征学习和融合。特征图被划分为邻域注意力窗口，以计算单个视图窗口和所有其他视图之间的语义相关性矩阵，这是针对每个单个视图窗口以及前K个相关性最高的多视图窗口的一种传导注意力机制。调整窗口大小和top-K可以将计算复杂度降至线性。在Real IAD数据集上进行的交叉设置（多类/单类）的广泛实验验证了我们方法的有效性，在样本\textbf{4.1\%} $\uparrow$/image\textbf{1.6\%}$\uparrow$/pixel\textbf{6.7\%}\\uparrow$ 级别中实现了最先进的性能，总共有十个指标，只有\textbf[18M}个参数，GPU内存和训练时间更少。 et.al.|[2407.11935](http://arxiv.org/abs/2407.11935)|null|
|**2024-07-16**|**MVG-Splatting: Multi-View Guided Gaussian Splatting with Adaptive Quantile-Based Geometric Consistency Densification**|在快速发展的3D重建领域，3D高斯散斑（3DGS）和2D高斯散斑技术（2DGS）代表了重大进步。尽管2DGS将3D高斯基元压缩为2D高斯表面以有效提高网格提取质量，但这种压缩可能会导致渲染质量的降低。此外，不可靠的致密化过程和通过不透明度累积计算深度可能会影响网格提取的细节。为了解决这个问题，我们介绍了MVG Splatting，这是一种基于多视图考虑的解决方案。具体来说，我们整合了一种计算法线的优化方法，该方法与图像梯度相结合，有助于纠正原始深度计算中的不一致。此外，利用类似于多视图立体（MVS）中的投影策略，我们提出了一种基于自适应分位数的方法，该方法动态确定由深度图引导的额外致密化水平，从粗到细。实验证据表明，我们的方法不仅解决了由深度差异引起的渲染质量下降的问题，而且还便于使用Marching Cubes算法从密集的高斯点云中直接提取网格。这种方法显著提高了3D重建过程的整体保真度和准确性，确保了几何细节和视觉质量。 et.al.|[2407.11840](http://arxiv.org/abs/2407.11840)|null|
|**2024-07-16**|**MRIo3DS-Net: A Mutually Reinforcing Images to 3D Surface RNN-like framework for model-adaptation indoor 3D reconstruction**|本文首次提出了一种端到端的图像相互增强的3D表面递归神经网络框架，用于模型自适应室内3D重建，其中多视图密集匹配和点云表面优化通过类似RNN的结构相互增强，而不是被视为一个单独的问题。其特点如下：在多视图密集匹配模块中，使用模型自适应策略对基于Transformer的多视图稠密匹配DNN进行微调和优化，使其具有更高的匹配图像特征和细节表达能力；在点云曲面优化模块中，采用模型自适应策略对基于三维隐式场的三维曲面重建网络进行优化，解决了在不知道三维曲面法向量的情况下点云曲面的优化问题。为了从点云改进和精细重建3D表面，提出了平滑损失并将其添加到该模块中；MRIo3DS-Net是一个类似RNN的框架，它利用PCSOM获得的精细优化的3D曲面来递归增强可微翘曲，以优化MVDMM。这种细化导致实现更好的密集匹配结果，更好的密集匹配对递归和相互实现更好的3D表面结果。因此，模型自适应策略可以更好地协调两个网络模块之间的差异，使它们相辅相成，达到更好的效果；为了加速从源域到目标域的迁移学习和训练收敛，使用基于贝叶斯不确定性的多任务损失函数自适应地调整MVDMM和PCSOM两个网络损失函数之间的权重；在这个多任务级联网络框架中，任何模块都可以被任何最先进的网络所取代，以获得更好的3D重建结果。 et.al.|[2407.11431](http://arxiv.org/abs/2407.11431)|null|
|**2024-07-15**|**Evaluating geometric accuracy of NeRF reconstructions compared to SLAM method**|随着神经辐射场（NeRF）实现变得更快、更高效、更准确，它们对现实世界映射任务的适用性变得更加容易。传统上，3D映射或场景重建依赖于昂贵的激光雷达传感。摄影测量可以执行基于图像的3D重建，但计算成本很高，需要极其密集的图像表示来恢复复杂的几何形状和照片真实感。NeRF通过在稀疏图像和姿态数据上训练神经网络来执行3D场景重建，在输入数据较少的情况下实现了优于摄影测量的结果。本文对两种用于估算垂直PVC圆柱体直径的NeRF场景重建进行了评估。其中一个是基于商品iPhone数据进行训练的，另一个是针对机器人来源的图像和姿势进行训练的。这种神经几何在场景噪声和度量精度方面与最先进的激光雷达惯性SLAM进行了比较。 et.al.|[2407.11238](http://arxiv.org/abs/2407.11238)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-07-18**|**Large deviations of Dyson Brownian motion on the circle and multiradial SLE0+**|本研究的主要动机是研究多径向Schramm-Loewner进化（SLE $_\kappa$）的渐近行为，即$\kappa\to0+$。我们证明了这种具有共同参数化的过程满足具有非负速率函数的Hausdorff度量中的有限时间大偏差原理（LDP），即多径向Loewner能量。我们还表征了具有有限能量和零能量的曲线的大时间行为（其驱动函数对应于三角Calogero-Moser系统）。本文的前半部分与SLE理论无关，具有独立的意义。它致力于证明当耦合参数$\beta=8/\kappa$趋于$\infty$时，固定数量$n$的粒子在圆上的戴森布朗运动的有限时间LDP。据我们所知，在文献中，戴森-布朗运动的大偏差只被认为是固定的$\beta$，而$n$趋向于$\infty$。虽然非Lipschitz漂移排除了Freidlin-Wentzell定理的应用，但我们证明，对于具有均匀Lipschitz漂的扩散，速率函数与Freidlin-Wentzell理论中的形式相同。在本文的下半部分，我们转向证明多辐射SLE的LDP$_ \kappa$。在这里，主要的技术难点是SLE$_ \kappa$ 曲线有一个共同的目标点，阻止了通常的配置或全局方法。相反，我们仔细地使用了LDP中戴森布朗运动的收缩原理（在本文的第一部分中得到了证明），并结合Loewner理论中的拓扑结果：我们证明了有限能量多径向Loewner壳总是简单曲线的不相交并集，除了可能在它们的共同端点处。一个关键是从径向Loewner映射的驱动函数能量的导数估计中获得。 et.al.|[2407.13762](http://arxiv.org/abs/2407.13762)|null|
|**2024-07-18**|**Streetscapes: Large-scale Consistent Street View Generation Using Autoregressive Video Diffusion**|我们提出了一种通过动态合成的城市尺度场景生成街景长序列视图的方法。我们这一代人受到语言输入（如城市名称、天气）以及承载所需轨迹的底层地图/布局的制约。与最近的视频生成或3D视图合成模型相比，我们的方法可以扩展到更远的摄像机轨迹，跨越几个街区，同时保持视觉质量和一致性。为了实现这一目标，我们基于最近在视频扩散方面的工作，在一个可以轻松扩展到长序列的自回归框架内使用。特别是，我们引入了一种新的时间插补方法，可以防止我们的自回归方法偏离现实城市图像的分布。我们使用来自谷歌街景的令人信服的数据源来训练我们的街景系统，这些数据源包括图像，以及上下文地图数据，这些数据允许用户根据任何所需的城市布局生成城市景观，并具有可控的摄像器姿态。请在我们的项目页面上查看更多结果https://boyangdeng.com/streetscapes. et.al.|[2407.13759](http://arxiv.org/abs/2407.13759)|null|
|**2024-07-18**|**LogoSticker: Inserting Logos into Diffusion Models for Customized Generation**|文本到图像模型定制的最新进展强调了将新概念与几个例子相结合的重要性。然而，这些进展在很大程度上局限于被广泛认可的学科，这些学科可以通过模型充分共享的先验知识相对容易地学习。相比之下，以独特模式和文本元素为特征的徽标很难在传播模型中建立共享知识，因此提出了独特的挑战。为了弥合这一差距，我们引入了徽标插入的任务。我们的目标是将徽标标识插入到传播模型中，并在不同的环境中实现无缝合成。我们提出了一种新颖的两阶段管道LogoSticker来解决这一任务。首先，我们提出了演员-评论家关系预训练算法，该算法解决了模型在理解徽标的潜在空间定位以及与其他对象的交互方面存在的重大差距。其次，我们提出了一种解耦的身份学习算法，该算法能够实现徽标的精确定位和身份提取。LogoSticker可以在不同的环境中准确和谐地生成徽标。我们全面验证了LogoSticker在定制方法和DALLE~3等大型模型上的有效性。\href{https://mingkangz.github.io/logosticker}｛项目页面｝。 et.al.|[2407.13752](http://arxiv.org/abs/2407.13752)|null|
|**2024-07-18**|**Understanding Reinforcement Learning-Based Fine-Tuning of Diffusion Models: A Tutorial and Review**|本教程对微调扩散模型以优化下游奖励函数的方法进行了全面的调查。虽然众所周知，扩散模型具有出色的生成建模能力，但在生物学等领域的实际应用中，需要生成最大化某些所需指标的样本（例如，RNA的翻译效率、分子的对接分数、蛋白质的稳定性）。在这些情况下，扩散模型不仅可以优化以生成逼真的样本，还可以显式地最大化感兴趣的度量。这些方法基于强化学习（RL）的概念。我们解释了各种RL算法的应用，包括PPO、可微优化、奖励加权MLE、值加权采样和路径一致性学习，这些算法是专门为微调扩散模型而定制的。我们的目标是探索基本方面，例如不同场景下基于强化学习的微调算法的优缺点，与非基于强化学习方法相比基于强化学习微调的优势，以及基于强化学习调优的形式目标（目标分布）。此外，我们的目标是研究它们与相关主题的联系，如分类器引导、Gflownets、基于流的扩散模型、路径积分控制理论以及从MCMC等非正态分布中采样。本教程的代码可在以下网址获得https://github.com/masa-ue/RLfinetuning_Diffusion_Bioseq et.al.|[2407.13734](http://arxiv.org/abs/2407.13734)|null|
|**2024-07-18**|**MeshSegmenter: Zero-Shot Mesh Semantic Segmentation via Texture Synthesis**|我们提出了MeshSegmenter，一个简单而有效的框架，设计用于零样本三维语义分割。该模型成功地将2D分割模型的强大功能扩展到3D网格，在不同的网格和分段描述中提供准确的3D分割。具体来说，我们的模型利用Segment Anything model（SAM）模型从3D形状渲染的图像中分割目标区域。鉴于纹理在分割中的重要性，我们还利用预训练的稳定扩散模型从3D形状生成具有纹理的图像，并利用SAM从具有纹理的图片中分割出目标区域。纹理补充了分割的形状，即使在几何上不突出的区域也有助于精确的3D分割，例如在汽车网格内分割汽车门。为了实现3D分割，我们渲染来自不同视图的2D图像，并对纹理和非纹理图像进行分割。最后，我们开发了一种多视图旋转方案，该方案将来自不同视图的2D分割结果和置信度得分集成到3D网格上，确保分割结果的3D一致性，并消除特定角度的不准确之处。通过这些创新，MeshSegmenter在定量和定性方面提供了稳定可靠的3D分割结果，突出了其作为3D零样本分割领域变革性工具的潜力。代码位于\url{https://github.com/zimingzhong/MeshSegmenter}. et.al.|[2407.13675](http://arxiv.org/abs/2407.13675)|null|
|**2024-07-18**|**Are the surface abundance structures stable in rapidly rotating Ap star 56 Ari?**|化学性质特殊的Ap/Bp恒星的表面磁性和丰度不均匀性是耦合的，是它们旋转调制变化的原因。在化石场假说的框架内，这些不均匀性被认为在主层序（MS）时间尺度上基本稳定。然而，一小群Ap/Bp恒星显示出自转周期的变化，目前尚不清楚。我们展示了快速旋转的Ap星56Ari的多普勒成像（DI）结果，之前已经检测到其周期变化。重建56Ari中硅的表面分布揭示了其复杂的斑点图案，这是旋转光变化的原因，并与磁场调制有关。对1986年至2014年前所未有的漫长研究间隔内获得的丰度图进行比较，证实了斑点模式的稳定性和刚性旋转。因此，56Ari中的周期变化不是由表面磁结构的重新排列和/或在短时间尺度上操作的原子扩散引起的。这也不太可能用恒星旋转轴自由体进动引起的斑点可见度变化来解释。在论文的最后，我们简要讨论了周期变异的可能替代解释。 et.al.|[2407.13645](http://arxiv.org/abs/2407.13645)|null|
|**2024-07-18**|**Open-Vocabulary 3D Semantic Segmentation with Text-to-Image Diffusion Models**|本文研究了在大规模图像字幕对上预先训练的扩散模型在开放词汇3D语义理解中的应用。我们提出了一种新方法，即Diff2Scene，它利用文本图像生成模型的冻结表示，以及显著感知和几何感知掩码，用于开放词汇3D语义分割和视觉基础任务。Diff2Scene消除了任何标记的3D数据，并有效地识别了3D场景中的对象、外观、材质、位置及其组成。我们证明，它优于竞争基线，并比最先进的方法有了显著改进。特别是，Diff2Scene将ScanNet200上最先进的方法提高了12%。 et.al.|[2407.13642](http://arxiv.org/abs/2407.13642)|null|
|**2024-07-18**|**Training-free Composite Scene Generation for Layout-to-Image Synthesis**|文本到图像扩散模型的最新突破极大地推动了从文本描述生成高保真、照片般逼真的图像。然而，这些模型往往难以从文本中解释空间排列，阻碍了它们生成具有精确空间配置的图像的能力。为了弥合这一差距，从布局到图像生成已成为一个有前景的方向。然而，基于训练的方法受到广泛注释数据集需求的限制，导致数据采集成本高，概念范围有限。相反，无训练方法在复杂组合中准确定位和生成语义相似的对象方面面临挑战。本文介绍了一种新的无训练方法，旨在克服扩散条件阶段的对抗性语义交叉。通过选择性抽样细化令牌内损失，并通过注意力再分配增强扩散过程，我们提出了两个创新约束：1）令牌间约束，解决了令牌冲突，以确保准确的概念合成；以及2）改善像素到像素关系的自我关注约束。我们的评估证实了利用布局信息指导传播过程的有效性，生成了保真度和复杂性增强的内容丰富的图像。代码可在以下网址获得https://github.com/Papple-F/csg.git. et.al.|[2407.13609](http://arxiv.org/abs/2407.13609)|null|
|**2024-07-18**|**Functional Renormalization Group analysis of the quark-condensation pattern on the Fermi surface: A simple effective-model approach**|基于量子色动力学（QCD）的高密度有效理论，构建了一个简单有效的中密度区域模型。在有效模型中，在朝向低动量缩放的重整化群（RG）下，原始QCD相互作用导致费米表面周围相关夸克和空穴模式的四夸克接触相互作用。标量通道中的接触相互作用可以追溯到瞬子背景中费米表面附近的零声型共线夸克散射。在给定费米速度的相反方向上的夸克和空穴态形成了集体标量玻色子模式 $\sigma$。通过从紫外（UV）到红外（IR）的有效平均作用的非微扰泛函重整化群（FRG）演化，研究了σ的大小。在$\sigma$的平均背景场近似中，在有效平均作用的IR极限中发现了非平凡最小值（$\bar{\sigma}\neq0$）。非变分$\bar{\sigma}$对应于在给定费米速度的相反方向上，在费米表面周围的动量空间中的薄壳状结构中，夸克态和空穴态的凝聚。这看起来类似于夸克子物质概念中假设的动量空间中的壳状重子分布。然而，当在RG流中包含动态玻色子$\sigma$ -模时，我们发现它的扩散性质破坏了夸克-空穴凝聚，即红外势在微不足道的值之外没有显示任何最小值。 et.al.|[2407.13589](http://arxiv.org/abs/2407.13589)|null|
|**2024-07-18**|**The long way of a viscous vortex dipole**|我们考虑了R^2 $中粘性涡偶极子的演化，该偶极子起源于一对具有相反环流的点涡。在高雷诺数$Re>>1$时，与涡流中心之间的距离相比，偶极子可以行进很长的距离，然后减速并最终被扩散破坏。在这种情况下，我们以双参数渐近展开的形式构建了解的精确近似，涉及偶极子的纵横比和逆雷诺数。然后，我们证明了Navier-Stokes方程的精确解在长度为$O（Re^\sigma）$的时间间隔上仍然接近近似值，其中$\sigma<1$是任意的。这改进了之前的结果，这些结果基本上仅限于$\sigma=0$ 。作为一个应用，我们对一个现有的公式进行了严格的论证，该公式对有限尺寸效应引起的偶极子平移速度进行了领先阶校正。 et.al.|[2407.13562](http://arxiv.org/abs/2407.13562)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-07-18**|**MeshFeat: Multi-Resolution Features for Neural Fields on Meshes**|参数特征网格编码作为神经场的编码方法受到了广泛关注，因为它们允许更小的MLP，这大大缩短了模型的推理时间。在这项工作中，我们提出了MeshFeat，这是一种针对网格量身定制的参数特征编码，为此我们采用了欧几里德空间的多分辨率特征网格的思想。我们从给定顶点拓扑提供的结构开始，使用网格简化算法直接在网格上构建多分辨率特征表示。该方法允许在网格上的神经场中使用小MLP，与之前的表示相比，我们显示出显著的加速，同时保持了纹理重建和BRDF表示的可比重建质量。鉴于其与顶点的内在耦合，该方法特别适用于变形网格上的表示，使其非常适合对象动画。 et.al.|[2407.13592](http://arxiv.org/abs/2407.13592)|null|
|**2024-07-16**|**Adaptive Environment-Aware Robotic Arm Reaching Based on a Bio-Inspired Neurodynamical Computational Framework**|仿生机器人系统具有自适应学习、可扩展控制和高效信息处理的能力。为这些系统提供实时决策对于应对环境的动态变化至关重要。我们专注于在开放区域使用带有鸟瞰摄像头的机器人六自由度操纵器进行动态目标跟踪，并部署神经动力学计算框架（NeuCF）进行视觉反馈。NeuCF是最近开发的一种基于动态神经场（DNF）和随机最优控制（SOC）理论的仿生目标跟踪模型。它已经过训练，可以在平面上对局部视觉信标进行到达动作，并且可以根据环境的变化（例如，出现了新的目标，或者删除了现有的目标）实时重新定位或生成停止信号。我们在各种目标达成场景下评估了我们的系统。在所有实验中，与基线三次多项式轨迹生成器相比，NeuCF具有较高的末端执行器位置精度，生成了平滑的轨迹，并提供了更短的路径长度。总之，开发的系统提供了一种强大的、动态感知的机器人操纵方法，可以提供实时决策。 et.al.|[2407.11377](http://arxiv.org/abs/2407.11377)|null|
|**2024-07-12**|**Physics-Informed Learning of Characteristic Trajectories for Smoke Reconstruction**|我们通过稀疏视图RGB视频深入研究了烟雾和障碍物的物理信息神经重建，解决了复杂动力学观测有限带来的挑战。现有的基于物理信息的神经网络通常强调短期物理约束，对长期守恒的适当保护探索较少。我们引入了神经特征轨迹场，这是一种利用欧拉神经场隐式建模拉格朗日流体轨迹的新表示方法。这种无拓扑、可自动微分的表示便于在任意帧之间进行高效的流图计算，以及通过自动微分进行高效的速度提取。因此，它实现了涵盖长期保护和短期物理先验的端到端监督。在此基础上，我们提出了基于物理的轨迹学习和集成到基于NeRF的场景重建中。我们通过自我监督的场景分解和无缝集成的边界约束来实现高级障碍物处理。我们的结果展示了克服遮挡不确定性、密度-颜色模糊性和静态-动态纠缠等挑战的能力。代码和示例测试位于\url{https://github.com/19reborn/PICT_smoke}. et.al.|[2407.09679](http://arxiv.org/abs/2407.09679)|null|
|**2024-07-10**|**Neural Localizer Fields for Continuous 3D Human Pose and Shape Estimation**|随着可用训练数据的爆炸性增长，单图像3D人体建模领先于向以数据为中心的范式过渡。成功利用数据规模的关键是设计灵活的模型，这些模型可以从不同研究人员或供应商生产的各种异构数据源进行监督。为此，我们提出了一种简单而强大的范式，用于无缝统一不同的人体姿势和形状相关的任务和数据集。我们的公式侧重于在训练和测试时查询人体体积的任意点并在3D中获得其估计位置的能力。我们通过学习身体点定位器函数的连续神经场来实现这一点，每个函数都是基于不同参数化的3D热图卷积点定位器（检测器）。为了生成参数输出，我们提出了一种高效的后处理步骤，用于将SMPL族身体模型拟合到非参数关节和顶点预测中。通过这种方法，我们可以自然地利用不同注释的数据源，包括网格、2D/3D骨架和密集姿势，而无需在它们之间进行转换，从而训练出大规模的3D人体网格和骨架估计模型，这些模型在3DPW、EMDB和SSP-3D等几个公共基准上的表现远远优于最先进的水平。 et.al.|[2407.07532](http://arxiv.org/abs/2407.07532)|null|
|**2024-07-03**|**Cerebral cortex inspired representation of neural field network**|进化及其智能元素在探索中带来了刺激和挑战。然而，物种如何拥有记忆、检索记忆并保持连续性是根本问题。大多数现象只能由研究人员假设，通过实验验证它们是一个很大的挑战。将大脑视为理想的智能机器并对其进行建模，为计算算法开辟了新的维度。本文提出了一个假设，即类似于大脑皮层的记忆创造。大脑皮层的区域隐含着特定功能的特异性，构成了一维的矢量形式的神经场。整个皮层的神经场相互连接形成了一个网络。这些网络与生存本能、情绪和奖励相关联，构成了对暴露环境的记忆，或者说学习。具有多维控制点的图形工具NURBS被隐式地用于将这些网络表示为一组三次方程。通过数据学习是智能系统的主要模块，本文试图将数据转换为低维模式，而不是实时智能系统的现有绝对形式。 et.al.|[2407.04741](http://arxiv.org/abs/2407.04741)|null|
|**2024-07-01**|**Fast and Efficient: Mask Neural Fields for 3D Scene Segmentation**|理解3D场景是计算机视觉研究中的一个关键挑战，其应用跨越多个领域。最近在将2D视觉语言基础模型提取到神经领域（如NeRF和3DGS）方面取得的进展，使3D场景能够从2D多视图图像中进行开放式词汇分割，而不需要精确的3D注释。然而，虽然有效，但高维CLIP特征的每像素蒸馏会引入模糊性，并需要复杂的正则化策略，从而在训练过程中增加效率。本文介绍了MaskField，它能够在弱监督下利用神经场实现快速高效的3D开放式分词。与以前的方法不同，MaskField提取掩模而不是密集的高维CLIP特征。MaskFields使用神经场作为二进制掩模生成器，并使用SAM生成的掩模对其进行监督，并通过粗略的CLIP特征进行分类。MaskField通过在训练过程中自然引入SAM分割的对象形状而无需额外的正则化来克服模糊的对象边界。通过在训练过程中避免直接处理高维CLIP特征，MaskField与3DGS等显式场景表示特别兼容。我们广泛的实验表明，MaskField不仅超越了现有的最先进的方法，而且实现了非常快的收敛速度，仅需5分钟的训练就超越了以前的方法。我们希望MaskField能够激发对如何训练神经场以从2D模型中理解3D场景的进一步探索。 et.al.|[2407.01220](http://arxiv.org/abs/2407.01220)|null|
|**2024-07-15**|**3D Feature Distillation with Object-Centric Priors**|将自然语言与物理世界联系起来是一个无处不在的话题，在计算机视觉和机器人技术中有着广泛的应用。最近，CLIP等二维视觉语言模型因其在二维图像中具有令人印象深刻的开放词汇基础能力而得到了广泛推广。最近的工作旨在通过特征提取将2D CLIP特征提升到3D，但要么学习特定于场景的神经场，因此缺乏泛化能力，要么专注于需要访问多个摄像头视图的室内房间扫描数据，这在机器人操作场景中是不可行的。此外，相关方法通常在像素级融合特征，并假设所有相机视图都具有相同的信息量。在这项工作中，我们表明这种方法在接地精度和分割清晰度方面都会导致次优的3D特征。为了缓解这一问题，我们提出了一种多视图特征融合策略，该策略采用以对象为中心的先验来消除基于语义信息的无信息视图，并通过实例分割掩码在对象级别融合特征。为了提取我们以对象为中心的3D特征，我们生成了一个大规模的合成多视图数据集，其中包含杂乱的桌面场景，从3300多个独特的对象实例中生成了15k个场景，我们将其公之于众。我们表明，我们的方法在从单视图RGB-D重建3D CLIP特征的同时，提高了接地容量和空间一致性，从而偏离了测试时多个相机视图的假设。最后，我们证明了我们的方法可以推广到新的桌面领域，并可以在不进行微调的情况下重新用于3D实例分割，并证明了它在混乱中的语言引导机器人抓取中的实用性 et.al.|[2406.18742](http://arxiv.org/abs/2406.18742)|null|
|**2024-06-25**|**Masked Generative Extractor for Synergistic Representation and 3D Generation of Point Clouds**|在二维图像生成建模和表示学习领域，掩模生成编码器（MAGE）已经证明了生成建模与表示学习之间的协同潜力。受此启发，我们提出Point MAGE将这一概念扩展到点云数据。具体来说，该框架首先利用矢量量化变分自编码器（VQVAE）重建3D形状的神经场表示，从而学习点补丁的离散语义特征。随后，通过将掩蔽模型与可变掩蔽比相结合，我们实现了生成和表示学习的同步训练。此外，我们的框架与现有的点云自监督学习（SSL）模型无缝集成，从而提高了它们的性能。我们广泛评估了Point MAGE的表示学习和生成能力。在形状分类任务中，Point MAGE在ModelNet40数据集上的准确率达到94.2%，在ScanObjectNN数据集上达到92.9%（+1.3%）。此外，它在少数镜头学习和零件分割任务中取得了最新的性能。实验结果还证实，Point MAGE可以在无条件和有条件的设置下生成详细和高质量的3D形状。 et.al.|[2406.17342](http://arxiv.org/abs/2406.17342)|null|
|**2024-06-17**|**DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features**|我们提出了DistillNeRF，这是一个自监督学习框架，解决了在自动驾驶中从有限的2D观察中理解3D环境的挑战。我们的方法是一种可推广的前馈模型，它从稀疏的单帧多视图相机输入中预测丰富的神经场景表示，并通过可微渲染进行自我监督训练，以重建RGB、深度或特征图像。我们的第一个见解是通过生成密集的深度和虚拟相机目标进行训练，利用每场景优化的神经辐射场（NeRF），从而帮助我们的模型从稀疏的非重叠图像输入中学习3D几何。其次，为了学习语义丰富的3D表示，我们建议从预先训练的2D基础模型（如CLIP或DINOv2）中提取特征，从而实现各种下游任务，而不需要昂贵的3D人工注释。为了利用这两个见解，我们引入了一种新的模型架构，该架构具有两级提升-飞溅-射击编码器和参数化的稀疏分层体素表示。NuScenes数据集的实验结果表明，DistillNeRF在场景重建、新颖视图合成和深度估计方面明显优于现有的可比自监督方法；并且它允许竞争性的零样本3D语义占用预测，以及通过提取的基础模型特征来理解开放世界场景。演示和代码将在https://distillnerf.github.io/. et.al.|[2406.12095](http://arxiv.org/abs/2406.12095)|null|
|**2024-06-18**|**Effective Rank Analysis and Regularization for Enhanced 3D Gaussian Splatting**|从多视图图像进行3D重建是计算机视觉和图形学中的基本挑战之一。最近，3D高斯散斑（3DGS）已经成为一种有前景的技术，能够实时渲染高质量的3D重建。该方法利用3D高斯表示和基于图块的飞溅技术，绕过了昂贵的神经场查询。尽管3DGS具有潜力，但由于高斯收敛为具有一个主要方差的各向异性高斯，它遇到了挑战，包括针状伪影、次优几何形状和不准确的法线。我们建议使用有效秩分析来检查3D高斯基元的形状统计，并识别高斯真的收敛到有效秩为1的针状形状。为了解决这个问题，我们引入了有效秩作为正则化，它约束了高斯的结构。我们的新正则化方法增强了法线和几何重建，同时减少了针状伪影。该方法可以作为附加模块集成到其他3DGS变体中，在不损害视觉保真度的情况下提高其质量。 et.al.|[2406.11672](http://arxiv.org/abs/2406.11672)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

