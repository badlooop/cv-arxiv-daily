---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.04.23
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-04-19**|**Contrastive Gaussian Clustering: Weakly Supervised 3D Scene Segmentation**|我们介绍了对比高斯聚类，这是一种新的方法，能够从任何角度提供分割掩模，并实现场景的3D分割。最近在新颖视图合成方面的工作已经展示了如何通过3D高斯云对场景的外观进行建模，以及如何在 $\alpha$混合颜色之前，通过在给定视点上投影高斯来生成准确的图像。在这个例子之后，我们训练一个模型，使其还包括每个高斯的分割特征向量。然后，这些可以用于3D场景分割，通过根据高斯特征向量对高斯进行聚类；以及通过将高斯投影在平面上并在其分割特征上进行$\alpha$混合来生成2D分割掩模。使用对比学习和空间正则化的组合，我们的方法可以在不一致的2D分割掩模上进行训练，并且仍然可以学习生成在所有视图中一致的分割掩模。此外，所得到的模型非常准确，将预测掩码的IoU精度比现有技术提高了$+8\%$ 。代码和训练模型将很快发布。 et.al.|[2404.12784](http://arxiv.org/abs/2404.12784)|null|
|**2024-04-22**|**Does Gaussian Splatting need SFM Initialization?**|3D高斯散射由于其高质量的结果和与硬件光栅化的兼容性，最近被视为一种用于场景重建和新颖视图合成的通用而有效的方法。尽管有其优点，但高斯飞溅对通过运动结构（SFM）算法进行高质量点云初始化的依赖是需要克服的一个重大限制。为此，我们研究了高斯散射的各种初始化策略，并深入研究了如何利用神经辐射场（NeRF）的体积重建来绕过对SFM数据的依赖。我们的研究结果表明，如果仔细设计，随机初始化可以执行得更好，并且通过采用改进的初始化策略和低成本NeRF模型的结构蒸馏相结合，可以实现与SFM初始化相同的结果，有时甚至更优。 et.al.|[2404.12547](http://arxiv.org/abs/2404.12547)|null|
|**2024-04-18**|**AG-NeRF: Attention-guided Neural Radiance Fields for Multi-height Large-scale Outdoor Scene Rendering**|现有的基于神经辐射场（NeRF）的大型户外场景新视图合成方法主要建立在单一海拔上。此外，它们通常需要先验的相机拍摄高度和场景范围，导致在相机高度变化时应用效率低下且不切实际。在这项工作中，我们提出了一个端到端的框架，称为AG-NeRF，并试图通过基于不同高度的场景合成自由视点图像来降低构建良好重建的训练成本。具体而言，为了解决从低空（无人机级）到高空（卫星级）的细节变化问题，开发了一种源图像选择方法和基于注意力的特征融合方法，从多高度图像中提取和融合目标视图的最相关特征，以实现高保真渲染。大量实验表明，AG NeRF在56个Leonard和Transamerica基准上实现了SOTA性能，与最新的BungieNeRF相比，只需要半小时的训练时间就可以达到有竞争力的PSNR。 et.al.|[2404.11897](http://arxiv.org/abs/2404.11897)|null|
|**2024-04-19**|**Factorized Motion Fields for Fast Sparse Input Dynamic View Synthesis**|设计用于快速优化和渲染的动态场景的3D表示是一项具有挑战性的任务。虽然最近的显式表示能够快速学习和渲染动态辐射场，但它们需要一组密集的输入视点。在这项工作中，我们专注于学习具有稀疏输入视点的动态辐射场的快速表示。然而，具有稀疏输入的优化是受约束不足的，并且需要使用运动先验来约束学习。现有的快速动态场景模型没有明确地对运动进行建模，这使得它们很难用运动先验进行约束。我们设计了一个显式运动模型作为因子分解的4D表示，它是快速的，可以利用运动场的时空相关性。然后，我们引入可靠的流先验，包括跨相机的稀疏流先验和相机内的密集流先验的组合，以正则化我们的运动模型。我们的模型快速、紧凑，在具有稀疏输入视点的流行多视图动态场景数据集上实现了非常好的性能。我们模型的源代码可以在我们的项目页面上找到：https://nagabhushansn95.github.io/publications/2024/RF-DeRF.html. et.al.|[2404.11669](http://arxiv.org/abs/2404.11669)|null|
|**2024-04-17**|**InFusion: Inpainting 3D Gaussians via Learning Depth Completion from Diffusion Prior**|3D高斯最近已经成为新颖视图合成的有效表示。这项工作研究了它的可编辑性，特别关注修复任务，该任务旨在用额外的点来补充一组不完整的3D高斯，以实现视觉和谐的渲染。与2D修复相比，修复3D高斯的关键是找出引入点的渲染相关属性，其优化很大程度上得益于它们的初始3D位置。为此，我们建议使用图像条件深度完成模型来指导点初始化，该模型学习基于观察到的图像直接恢复深度图。这样的设计允许我们的模型以与原始深度一致的比例填充深度值，并利用大规模扩散先验的强大可推广性。由于更准确的深度完成，我们的方法被称为InFusion，在各种复杂场景下以足够好的保真度和效率超越了现有的替代方案。我们进一步证明了InFusion在几个实际应用中的有效性，例如使用用户特定纹理或新的对象插入进行修复。 et.al.|[2404.11613](http://arxiv.org/abs/2404.11613)|null|
|**2024-04-18**|**DeblurGS: Gaussian Splatting for Camera Motion Blur**|尽管在从运动模糊图像重建清晰的3D场景方面取得了重大进展，但向现实世界应用的过渡仍然具有挑战性。主要障碍源于严重的模糊，这导致通过“运动结构”获取初始相机姿势的不准确，这是以前的方法经常忽略的一个关键方面。为了应对这一挑战，我们提出了DeblurGS，这是一种从运动模糊图像中优化清晰的3D高斯飞溅的方法，即使在有噪声的相机姿态初始化的情况下也是如此。我们通过利用3D高斯飞溅的卓越重建能力来恢复细粒度的清晰场景。我们的方法估计每个模糊观测的6自由度相机运动，并为优化过程合成相应的模糊渲染。此外，我们提出了高斯密集退火策略，以防止在相机运动仍然不精确的早期训练阶段，在错误的位置产生不精确的高斯。综合实验表明，我们的DeblurGS在真实世界和合成基准数据集以及现场捕捉的模糊智能手机视频的去模糊和新颖视图合成方面实现了最先进的性能。 et.al.|[2404.11358](http://arxiv.org/abs/2404.11358)|null|
|**2024-04-17**|**Novel View Synthesis for Cinematic Anatomy on Mobile and Immersive Displays**|3D解剖的交互式真实感可视化（即电影解剖）用于医学教育，以解释人体结构。目前，它仅限于正面教学场景，演示者需要强大的GPU和对数据集所在的大型存储设备的高速访问。我们展示了通过压缩的3D高斯飞溅使用新颖的视图合成来克服这一限制，并使学生能够在轻量级移动设备和虚拟现实环境中进行电影解剖。我们提出了一种自动方法来寻找一组图像，这些图像可以捕捉数据中所有潜在的可见结构。通过将特写视图与远处的图像混合，飞溅表示可以恢复高达体素分辨率的结构。Mip Splatting的使用可以在焦距增加时实现平滑过渡。即使是GB数据集，最终的可渲染表示通常也可以压缩到70 MB以下，从而可以使用光栅化在低端设备上进行交互式渲染。 et.al.|[2404.11285](http://arxiv.org/abs/2404.11285)|null|
|**2024-04-16**|**Gaussian Opacity Fields: Efficient and Compact Surface Reconstruction in Unbounded Scenes**|最近，3D高斯散射（3DGS）展示了令人印象深刻的新颖视图合成结果，同时允许实时渲染高分辨率图像。然而，由于3D高斯的显式和非连通性，利用3D高斯进行表面重建带来了重大挑战。在这项工作中，我们提出了高斯不透明度场（GOF），这是一种在无界场景中进行高效、高质量和紧凑表面重建的新方法。我们的GOF源于基于射线追踪的三维高斯体绘制，通过识别其水平集，可以直接从三维高斯中提取几何体，而无需像以前的工作中那样采用泊松重建或TSDF融合。我们将高斯的表面法线近似为射线-高斯相交平面的法线，从而可以应用正则化，显著增强几何体。此外，我们开发了一种利用行进四面体的有效几何提取方法，其中四面体网格是从3D高斯图中导出的，从而适应场景的复杂性。我们的评估表明，GOF在表面重建和新视图合成方面超过了现有的基于3DGS的方法。此外，它在质量和速度方面都优于甚至优于神经隐式方法。 et.al.|[2404.10772](http://arxiv.org/abs/2404.10772)|null|
|**2024-04-16**|**AbsGS: Recovering Fine Details for 3D Gaussian Splatting**|3D高斯散射（3D-GS）技术将3D高斯基元与可微分光栅化相耦合，以实现高质量的新颖视图合成结果，同时提供高级实时渲染性能。然而，由于其在3D-GS中的自适应密度控制策略的缺陷，它在包含高频细节的复杂场景中经常出现过度重建问题，导致渲染图像模糊。这个缺陷的根本原因仍然没有得到充分的探讨。在这项工作中，我们对上述伪影的原因进行了全面的分析，即梯度碰撞，它防止了过度重建区域中的大高斯分裂。为了解决这个问题，我们提出了一种新的单向视角空间位置梯度作为致密化的标准。我们的策略有效地识别了过度重建区域中的大高斯，并通过分割来恢复精细细节。我们在各种具有挑战性的数据集上评估了我们提出的方法。实验结果表明，我们的方法在减少或相似的内存消耗的情况下实现了最佳的渲染质量。我们的方法易于实现，并且可以结合到各种最新的基于高斯飞溅的方法中。我们将在正式发布后开放我们的代码源代码。我们的项目页面位于：https://ty424.github.io/AbsGS.github.io/ et.al.|[2404.10484](http://arxiv.org/abs/2404.10484)|null|
|**2024-04-16**|**1st Place Solution for ICCV 2023 OmniObject3D Challenge: Sparse-View Reconstruction**|在本报告中，我们提出了ICCV 2023 OmniObject3D挑战的第一名解决方案：稀疏视图重建。该挑战旨在评估仅使用每个对象的几个姿势图像进行新的视图合成和表面重建的方法。我们使用Pixel NeRF作为基本模型，并应用深度监督以及从粗到细的位置编码。实验证明了该方法在提高稀疏视图重建质量方面的有效性。我们在最终测试中以25.44614的PSNR排名第一。 et.al.|[2404.10441](http://arxiv.org/abs/2404.10441)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-04-19**|**Unified Scene Representation and Reconstruction for 3D Large Language Models**|使大型语言模型（LLM）能够与3D环境交互是一项挑战。现有的方法从地面实况（GT）几何或由辅助模型重建的3D场景中提取点云。然后，来自CLIP的与文本图像对齐的2D特征被提升到点云，点云用作LLM的输入。然而，该解决方案缺乏3D点对点连接的建立，导致空间结构信息的缺乏。同时，场景的几何和语义表示之间缺乏整合和统一，最终导致3D场景理解水平下降。在本文中，我们展示了具有统一的场景表示和重建框架的重要性，这对于3D场景中的LLM至关重要。具体来说，我们介绍了Uni3DR^2通过冻结的预训练的2D基础模型（例如，CLIP和SAM）和多尺度聚合3D解码器来提取3D几何和语义感知表示特征。我们学习的3D表示不仅有助于重建过程，而且为LLM提供了宝贵的知识。实验结果验证了我们的Uni3DR^2在3D重建数据集ScanNet上比基线产生了令人信服的增益（使F-Score增加+1.8\%）。当应用于LLM时，我们的Uni3DR^2-LLM在3D视觉语言理解数据集ScanQA上表现出优于基线的性能（在val集和测试集上，BLEU-1分别增加了+4.0\%和+4.2\%）。此外，它的性能优于在ScanQA和3DMV-VQA上使用额外GT点云的最先进方法。 et.al.|[2404.13044](http://arxiv.org/abs/2404.13044)|null|
|**2024-04-19**|**FlyNeRF: NeRF-Based Aerial Mapping for High-Quality 3D Scene Reconstruction**|当前的3D重建和环境测绘方法在实现高精度方面经常面临挑战，这突出了对实用有效解决方案的需求。针对这个问题，我们的研究介绍了FlyNeRF，这是一个将神经辐射场（NeRF）与基于无人机的数据采集相结合的系统，用于高质量的3D重建。利用无人机（UAV）捕捉图像和相应的空间坐标，随后将获得的数据用于基于NeRF的初始环境三维重建。重建渲染质量的进一步评估是通过在我们的系统范围内开发的图像评估神经网络来完成的。根据图像评估模块的结果，自主算法确定额外图像捕获的位置，从而提高重建质量。用于渲染质量评估的神经网络的准确率为97%。此外，我们的自适应方法提高了整体重建质量，导致10%分位数的峰值信噪比（PSNR）平均提高了2.5dB。FlyNeRF展示了有希望的结果，在环境监测、监控和数字双胞胎等领域取得了进步，其中高保真3D重建至关重要。 et.al.|[2404.12970](http://arxiv.org/abs/2404.12970)|null|
|**2024-04-18**|**Advancing Applications of Satellite Photogrammetry: Novel Approaches for Built-up Area Modeling and Natural Environment Monitoring using Stereo/Multi-view Satellite Image-derived 3D Data**|近几十年来，随着遥感技术的发展，具有亚米和米空间分辨率的星载传感器（Worldview和PlanetScope）已经实现了相当高的图像质量，可以通过立体匹配管道生成3D地理空间数据。这些成就显著提高了三维数据的可访问性，因此有必要调整这些三维地理空间数据来分析人类和自然环境。本文探讨了基于立体和多视图卫星图像衍生的三维地理空间数据的几种新方法，以解决建成区建模和自然环境监测的遥感应用问题，包括建筑模型三维重建、冰川动力学跟踪和湖泊藻类监测。第一项研究利用一种新的方法，利用模型驱动的工作流程，从卫星衍生的正射影像和DSM中推进了LoD-2建筑建模，该方法生成了建筑矩形三维几何模型。其次，我们进一步增强了针对密集城市区域和非矩形目的的建筑重建框架，实现了单元级分割的深度学习，并引入了基于梯度的圆形建筑圆形重建，以开发用于高级建筑LoD2重建的多边形合成技术。我们的第三项研究利用高时空分辨率PlanetScope卫星图像在中纬度地区进行三维冰川追踪。最后，我们提出了一个术语“藻类行为函数”，以完善水质监测中卫星图像中叶绿素a浓度的量化，解决藻类波动以及卫星观测和现场测量之间的时间差异，从而提高水下藻类体积估计的精度。总之，本文展示了卫星摄影测量应用在应对城市和环境挑战方面的广泛潜力。它进一步展示了创新的分析方法，增强了调整立体和多视图非常高分辨率卫星衍生的3D数据的适用性。（见文件中的完整摘要） et.al.|[2404.12487](http://arxiv.org/abs/2404.12487)|null|
|**2024-04-18**|**Spot-Compose: A Framework for Open-Vocabulary Object Retrieval and Drawer Manipulation in Point Clouds**|近年来，深度学习和大规模数据集的现代技术在3D实例分割、抓取姿态估计和机器人技术方面取得了令人印象深刻的进展。这允许在3D场景中直接进行精确检测，实现物体和环境感知的抓取预测，以及稳健和可重复的机器人操作。这项工作旨在将这些最新的方法集成到一个全面的框架中，用于在以人为中心的环境中进行机器人交互和操作。具体来说，我们利用商品3D扫描仪的3D重建进行开放式词汇实例分割，以及抓取姿势估计，以演示对象的动态拾取和抽屉的打开。我们在两组真实世界的实验中展示了我们模型的性能和稳健性，包括动态对象检索和抽屉打开，分别报告了51%和82%的成功率。我们的框架代码以及视频可在以下网站上获取：https://spot-compose.github.io/. et.al.|[2404.12440](http://arxiv.org/abs/2404.12440)|null|
|**2024-04-18**|**6Img-to-3D: Few-Image Large-Scale Outdoor Driving Scene Reconstruction**|当前的3D重建技术很难从少数图像中忠实地推断出无边界的场景。具体而言，现有方法具有高计算要求，需要详细的姿态信息，并且不能可靠地重建被遮挡区域。我们介绍了6Img-to-3D，这是一种用于单镜头图像到3D重建的高效、可扩展的基于转换器的编码器渲染器方法。我们的方法仅从六个面向外部的输入图像中输出3D一致的参数化三平面，用于大规模、无边界的户外驾驶场景。我们通过将收缩的自定义交叉和自关注机制结合起来，实现三平面参数化、可微分体积渲染、场景收缩和图像特征投影，朝着解决现有缺陷迈出了一步。我们展示了在没有全局姿态信息的情况下，来自单个时间戳的六幅环绕视图车辆图像足以在推理时间内重建360 $^｛\circ｝$ 场景，耗时395毫秒。例如，我们的方法允许渲染第三人称图像和鸟瞰图。我们的代码可在https://github.com/continental/6Img-to-3D，更多示例可以在我们的网站上找到https://6Img-to-3D.GitHub.io/. et.al.|[2404.12378](http://arxiv.org/abs/2404.12378)|**[link](https://github.com/continental/6img-to-3d)**|
|**2024-04-17**|**A Subspace-Constrained Tyler's Estimator and its Applications to Structure from Motion**|我们提出了子空间约束泰勒估计器（STE），该估计器设计用于恢复数据集中可能被异常值高度破坏的低维子空间。STE是泰勒M-估计量（TME）和快速中值子空间的一个变体的融合。我们的理论分析表明，在一个常见的内部异常值模型下，STE可以有效地恢复底层子空间，即使与稳健子空间恢复领域的其他方法相比，它包含的内部值较少。我们在运动结构（SfM）的背景下以两种方式应用STE：用于基本矩阵的鲁棒估计和用于去除外围摄像机，增强SfM管道的鲁棒性。数值实验证实了我们的方法在这些应用中的最先进性能。这项研究对鲁棒子空间恢复领域做出了重大贡献，特别是在计算机视觉和三维重建的背景下。 et.al.|[2404.11590](http://arxiv.org/abs/2404.11590)|null|
|**2024-04-17**|**Texture tomography, a versatile framework to study crystalline texture in 3D**|晶体结构是许多技术和生物材料的一个关键组织特征。在这些材料中，特别是分级结构的材料中，纳米成分的优先排列严重影响材料的宏观行为。为了研究具有高空间分辨率和高角度分辨率的局部晶体纹理，我们开发了纹理层析成像（TexTOM）。这种方法允许通过使用晶体系综的全倒数空间来对多晶材料的衍射数据进行建模，并通过取向分布函数来描述每个体素中的纹理。这意味着，它通过测量所有晶体取向的概率来提供局部纹理的3D重建。TexTOM方法解决了与现有模型相关的局限性：它将几个布拉格反射的强度关联起来，从而减少了对称性造成的模糊性。此外，它产生了局部真实空间晶体取向的定量概率分布，而无需对样品结构进行进一步假设。最后，它有效的数学公式使重建比实验的时间尺度更快。在本文中，我们介绍了数学模型、反演策略及其当前的实验实现。我们展示了模拟数据的特征以及从合成的无机模型样品——二氧化硅毒重石生物形态中获得的实验数据。总之，Tex-TOM为重建多晶样品的3D定量纹理信息提供了一个通用的框架。通过这种方式，它为深入了解天然和技术材料的纳米结构组成打开了大门。 et.al.|[2404.11195](http://arxiv.org/abs/2404.11195)|null|
|**2024-04-17**|**REACTO: Reconstructing Articulated Objects from a Single Video**|在本文中，我们解决了从单个视频重建一般关节式3D对象的挑战。采用动态神经辐射场的现有工作已经推进了视频中人类和动物等关节物体的建模，但由于其变形模型的局限性，分段刚性通用关节物体面临挑战。为了解决这一问题，我们提出了准刚性混合蒙皮，这是一种新的变形模型，可以增强每个零件的刚性，同时保持关节的柔性变形。我们的主要见解结合了三种不同的方法：1）用于改进组件建模的增强型骨骼装配系统，2）使用准稀疏蒙皮权重来提高零件刚度和重建保真度，以及3）应用测地线点分配来实现精确运动和无缝变形。正如在真实和合成数据集上所证明的那样，我们的方法在生成一般关节物体的高保真度3D重建方面优于以前的工作。项目页面：https://chaoyuesong.github.io/REACTO. et.al.|[2404.11151](http://arxiv.org/abs/2404.11151)|null|
|**2024-04-16**|**A Concise Tiling Strategy for Preserving Spatial Context in Earth Observation Imagery**|我们提出了一种新的平铺策略，即Flip-n-Slide，它是为在感兴趣对象（OoI）的位置未知且空间上下文可能是类消歧所必需的情况下特定用于大型地球观测卫星图像而开发的。翻转滑动是一种简洁而简约的方法，允许OoI在多个瓦片位置和方向上表示。该策略引入了空间上下文信息的多个视图，而不会在训练集中引入冗余。通过为每个瓦片重叠保持不同的变换排列，我们增强了训练集的可推广性，而不会歪曲真实的数据分布。我们的实验验证了Flip-n-Slide在语义分割任务中的有效性，语义分割是地球物理研究中必要的数据产品。我们发现，Flip-n-Slide在所有评估指标中都优于以前最先进的拼接数据增强例程。对于代表性不足的类，Flip-n-Slide可将精度提高15.8%。 et.al.|[2404.10927](http://arxiv.org/abs/2404.10927)|**[link](https://github.com/elliesch/flipnslide)**|
|**2024-04-16**|**RapidVol: Rapid Reconstruction of 3D Ultrasound Volumes from Sensorless 2D Scans**|二维（2D）徒手超声是最常用的医学成像方式之一，尤其是在妇产科。然而，它只捕获固有的3D解剖结构的2D横截面视图，丢失了有价值的上下文信息。作为需要昂贵且复杂的3D超声扫描仪的替代方案，可以使用机器学习从2D扫描构建3D体积。然而，这通常需要很长的计算时间。在这里，我们提出了RapidVol：一种神经表示框架，用于加快切片到体积的超声重建。我们使用张量秩分解，将典型的三维体积分解为三平面集，并将其存储起来，以及一个小型神经网络。形成完整的三维重建所需的全部内容是一组二维超声扫描，以及它们的真实（或估计）三维位置和方向（姿态）。重建是由真实的胎儿大脑扫描形成的，然后通过请求新的横截面视图进行评估。与之前基于全隐式表示的方法（如神经辐射场）相比，我们的方法速度快3倍以上，准确率高46%，如果给定不准确的姿态，则更稳健。通过从结构先验而不是从头开始重建，进一步加速也是可能的。 et.al.|[2404.10766](http://arxiv.org/abs/2404.10766)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-04-19**|**Analysis of Classifier-Free Guidance Weight Schedulers**|无分类器引导（CFG）增强了文本到图像扩散模型的质量和条件依从性。它通过使用固定权重将条件预测和无条件预测相结合来进行操作。然而，最近的工作在整个扩散过程中改变了权重，报告了优越的结果，但没有提供任何理由或分析。通过全面的实验，本文对CFG权重调度器进行了深入的研究。我们的研究结果表明，简单、单调增加的权重调度器只需要一行代码，就能持续提高性能。此外，可以对更复杂的参数化调度器进行优化以进行进一步改进，但不能在不同的模型和任务中进行推广。 et.al.|[2404.13040](http://arxiv.org/abs/2404.13040)|null|
|**2024-04-19**|**A multigrain-multilayer astrochemical model with variable desorption energy for surface species**|上下文星际表面化学是一个复杂的过程，发生在不同大小颗粒上积累的冰层中。表面过程的效率通常取决于吸附分子的直接环境。目的。我们研究了当表面分子脱附明确取决于分子结合能时，气体颗粒化学是如何变化的，而分子结合能是根据表面的性质而改变的。方法。分子结合能在三种不同的环境中逐渐变化——裸粒，其中极性的、以水为主的冰和非极性的，以一氧化碳为主的冰。除了扩散、蒸发和化学解吸之外，光吸收也与结合能有关，这与实验结果一致。这些现象发生在坍缩的星前核心模型中，该模型考虑了五种粒度的冰排列成四层。后果从裸露的谷物中有效的化学解吸显著延缓了冰的积累。分子在非极性冰上更容易的表面扩散促进了二氧化碳和其他物种的产生。结论。星际冰的组成由几种依赖结合能的解吸机制调节。它们的作用在时间和空间上重叠，这解释了主要冰成分（水和碳氧化物）的普遍比例，观察到它们在各个方向上都是相似的。 et.al.|[2404.13011](http://arxiv.org/abs/2404.13011)|null|
|**2024-04-19**|**RadRotator: 3D Rotation of Radiographs with Diffusion Models**|将二维（2D）图像转换为三维（3D）体积对于计算机视觉界来说是一个众所周知但具有挑战性的问题。在医学领域，以前的一些研究试图将两张或多张输入射线照片转换为计算机断层扫描（CT）体积。在他们的努力之后，我们引入了一种基于扩散模型的技术，该技术可以在3D空间中旋转任何输入射线照片的解剖内容，有可能实现从3D中的任何视点对射线照片的整个解剖内容的可视化。与之前的研究类似，我们使用CT体积创建数字重建射线照片（DRR）作为我们模型的训练数据。然而，我们解决了先前研究中遇到的两个重大局限性：1。我们使用了具有无分类器引导的条件扩散模型，而不是生成对抗性网络（GANs），以实现更高的模式覆盖率和改进的输出图像质量，唯一的折衷是较慢的推理时间，这在医学应用中往往不那么关键；和2。我们证明，风格转移深度学习（DL）模型（如Cycle GAN）将实际射线照片的风格转移到DRR的不可靠输出可以用简单而有效的训练变换来代替，该训练变换在训练期间随机改变输入和地面实况成像数据的像素强度直方图。这种变换使扩散模型不受输入数据像素强度的任何分布变化的影响，从而能够在输入DRR上可靠地训练DL模型，并在推理过程中将完全相同的模型应用于传统的射线照片（或DRR）。 et.al.|[2404.13000](http://arxiv.org/abs/2404.13000)|null|
|**2024-04-19**|**Cross-modal Diffusion Modelling for Super-resolved Spatial Transcriptomics**|空间转录组学（ST）的最新进展允许表征组织内的空间基因表达，以进行发现研究。然而，目前的ST平台分辨率较低，阻碍了对空间基因表达的深入理解。超分辨率方法有望通过将组织学图像与轮廓组织点的基因表达相结合来增强ST图。然而，目前的超分辨率方法受到恢复不确定性和模式崩溃的限制。尽管扩散模型在捕捉多模式条件之间的复杂相互作用方面显示出了前景，但整合组织学图像和基因表达以获得超分辨ST图仍然是一个挑战。本文提出了一种以组织学图像为指导的超分辨率ST图的跨模态条件扩散模型。具体来说，我们设计了一个具有跨模态自适应调制的多模态解纠缠网络，以利用组织学图像和空间基因表达的互补信息。此外，我们提出了一种动态交叉注意力建模策略，从组织学图像中提取分层的细胞到组织信息。最后，我们提出了一个基于共表达的基因相关图网络来建模多个基因的共表达关系。实验表明，在三个公共数据集上，我们的方法在ST超分辨率方面优于其他最先进的方法。 et.al.|[2404.12973](http://arxiv.org/abs/2404.12973)|null|
|**2024-04-19**|**On the McKean-Vlasov SDE with branching**|我们研究了McKean意义上的非线性分支扩散过程，即粒子受到平均场相互作用。我们首先考虑问题的一个强公式，并通过使用收缩自变量提供存在唯一性结果。然后我们考虑弱解的概念及其等价的鞅问题公式。在这种情况下，我们提供了一个普遍的弱存在性结果，以及混沌性质的传播，即当种群大小增长到无穷大时，McKean-Vlasov分支扩散是具有平均场相互作用的大种群分支过程的极限。 et.al.|[2404.12964](http://arxiv.org/abs/2404.12964)|null|
|**2024-04-19**|**Robust hybrid finite element methods for reaction-dominated diffusion problems**|对于反应主导的扩散问题，我们研究了一种原始和对偶混合有限元方法，其中弱连续性条件由拉格朗日乘子强制执行。离散方法的一致鲁棒性是通过用修改的面泡函数丰富局部离散化空间来实现的，面泡函数在单元内部呈指数衰减，这取决于奇异摄动参数和局部网格大小的比值。使用Fortin算子导出了后验误差估计量。它们相对于奇异摄动参数是鲁棒的。数值实验表明，如果存在振荡，则振荡明显小于普通有限元方法中观察到的振荡。 et.al.|[2404.12956](http://arxiv.org/abs/2404.12956)|null|
|**2024-04-19**|**Neural Flow Diffusion Models: Learnable Forward Process for Improved Diffusion Modelling**|传统的扩散模型通常依赖于固定的正向过程，该过程隐含地定义了潜在变量上的复杂边际分布。这通常会使逆向过程在学习生成轨迹时的任务复杂化，并导致扩散模型的推理成本高昂。为了解决这些局限性，我们引入了神经流扩散模型（NFDM），这是一种新的框架，通过支持固定线性高斯之外更广泛的正向过程来增强扩散模型。我们还提出了一种新的参数化技术来学习正向过程。我们的框架提供了一个端到端的、无模拟的优化目标，有效地最小化了负对数似然的变分上界。实验结果证明了NFDM的强大性能，最先进的似然估计证明了这一点。此外，我们还研究了NFDM学习具有特定特征的生成动力学的能力，例如确定性直线轨迹。这一探索强调了NFDM的多功能性及其在广泛应用中的潜力。 et.al.|[2404.12940](http://arxiv.org/abs/2404.12940)|null|
|**2024-04-19**|**Diffusive contact between randomly driven colloidal suspensions**|我们研究了两种驱动的胶体悬浮液扩散接触到稳态的弛豫过程，类似于热化。我们首先研究一种悬浮液，通过全息光学镊子将其置于随机驱动力下，将其搅拌到更高的有效温度。有趣的是，由爱因斯坦关系定义的悬架的有效温度表现出对驱动频率的非单调依赖性。接下来，我们跟踪两种扩散接触的悬浮液之间的粒子通量，从均匀密度开始，松弛到零净粒子通量的状态。对于具有不同频率但相同有效温度的系统，密度保持均匀。在高驱动频率下，我们表明稳态下的密度分布是通过将两个系统中的化学势与有效温度之比相等来确定的，这反映了热平衡行为。 et.al.|[2404.12929](http://arxiv.org/abs/2404.12929)|null|
|**2024-04-19**|**Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models**|在给定的医学扫描中定位精确的病理区域是一个重要的成像问题，需要准确地解决大量的边界盒基本事实注释。然而，也存在其他可能较弱的监督形式，如随附的自由文本报告，这些报告很容易获得。在文本引导下进行本地化的任务通常被称为短语基础。在这项工作中，我们使用了一个公开的基础模型，即潜在扩散模型，来解决这一具有挑战性的任务。这一选择得到了这样一个事实的支持，即尽管潜在扩散模型本质上是生成性的，但它包含隐含地将视觉和文本特征对齐的机制（交叉注意力），从而导致适合手头任务的中间表示。此外，我们的目标是以零样本的方式执行这项任务，即不需要对目标数据进行任何进一步的训练，这意味着模型的权重保持冻结。为此，我们设计了选择特征的策略，并在没有额外可学习参数的情况下通过后处理对其进行细化。我们将我们提出的方法与最先进的方法进行了比较，这些方法通过对比学习在联合嵌入空间中明确地强制图像-文本对齐。在一个流行的胸部X射线基准上的结果表明，我们的方法在不同类型的病理学上与SOTA相比具有竞争力，甚至在两个指标（平均IoU和AUC-ROC）方面平均优于它们。源代码将在验收后发布。 et.al.|[2404.12920](http://arxiv.org/abs/2404.12920)|null|
|**2024-04-19**|**Robust CLIP-Based Detector for Exposing Diffusion Model-Generated Images**|扩散模型（DM）已经彻底改变了图像生成，产生了高质量的图像，应用范围遍及各个领域。然而，他们创建超现实图像的能力在区分真实内容和合成内容方面带来了重大挑战，这引发了人们对数字真实性的担忧，并可能在创建deepfakes时被滥用。本文介绍了一种鲁棒检测框架，该框架将CLIP模型提取的图像和文本特征与多层感知器（MLP）分类器相结合。我们提出了一种新的损失，可以提高检测器的鲁棒性并处理不平衡的数据集。此外，我们在模型训练期间使损失景观变平，以提高检测器的泛化能力。通过广泛的实验证明了我们的方法的有效性，它优于传统的检测技术，强调了它在DM生成的图像检测中建立一种新的最先进方法的潜力。代码位于https://github.com/Purdue-M2/Robust_DM_Generated_Image_Detection. et.al.|[2404.12908](http://arxiv.org/abs/2404.12908)|**[link](https://github.com/purdue-m2/robust_dm_generated_image_detection)**|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-04-19**|**BANF: Band-limited Neural Fields for Levels of Detail Reconstruction**|主要由于其隐含性质，神经场缺乏直接的滤波机制，因为离散信号处理的傅立叶分析不直接适用于这些表示。神经场的有效滤波对于实现下游应用程序中的细节处理水平至关重要，并支持在规则网格上对场进行采样的操作（例如，行进立方体）。试图在频域中分解神经场的现有方法要么采用启发式方法，要么需要对神经场架构进行广泛修改。我们展示了通过一个简单的修改，可以获得低通滤波的神经场，进而展示了如何利用这一点来获得整个信号的频率分解。我们通过研究细节水平重建来证明我们的技术的有效性，并展示了如何有效地计算粗糙的表示。 et.al.|[2404.13024](http://arxiv.org/abs/2404.13024)|null|
|**2024-04-15**|**Efficient and accurate neural field reconstruction using resistive memory**|人类通过将稀疏的观测整合到大规模互连的突触和神经元中来构建空间感知，提供了卓越的并行性和效率。在人工智能中复制这一能力在医学成像、AR/VR和嵌入式人工智能中有着广泛的应用，在这些领域，输入数据往往是稀疏的，计算资源有限。然而，传统的数字计算机信号重构方法面临着软硬件两方面的挑战。在软件方面，传统显式信号表示中的存储效率低下会带来困难。硬件障碍包括冯·诺依曼瓶颈，它限制了CPU和存储器之间的数据传输，以及CMOS电路在支持并行处理方面的局限性。我们提出了一种软硬件协同优化的系统方法，用于从稀疏输入重建信号。在软件方面，我们使用神经场通过神经网络隐式地表示信号，并使用低秩分解和结构化修剪对其进行进一步压缩。在硬件方面，我们设计了一个基于电阻存储器的内存计算（CIM）平台，该平台具有高斯编码器（GE）和MLP处理引擎（PE）。GE利用电阻存储器的内在随机性进行有效的输入编码，而PE通过硬件感知量化（HAQ）电路实现精确的权重映射。我们在基于40nm 256Kb电阻存储器的内存内计算宏上展示了该系统的功效，在不影响3D CT稀疏重建、新视图合成和动态场景新视图合成等任务的重建质量的情况下，实现了巨大的能效和并行性改进。这项工作推进了人工智能驱动的信号恢复技术，为未来高效、稳健的医疗人工智能和3D视觉应用铺平了道路。 et.al.|[2404.09613](http://arxiv.org/abs/2404.09613)|null|
|**2024-04-10**|**Ray-driven Spectral CT Reconstruction Based on Neural Base-Material Fields**|在谱CT重建中，基底材料分解涉及求解大规模非线性积分方程组，这在数学上是高度不适定的。本文提出了一种模型，该模型使用神经场表示来参数化对象的衰减系数，从而避免了线积分离散化过程中像素驱动的投影系数矩阵的复杂计算。介绍了一种基于光线驱动神经场的线积分轻量级离散化方法，提高了离散化过程中积分逼近的精度。将基底材料表示为连续的向量值隐函数，以建立基底材料的神经场参数化模型。然后使用深度学习的自动微分框架来求解神经基底材料场的隐式连续函数。该方法不受重建图像空间分辨率的限制，并且网络具有紧凑和规则的特性。实验验证表明，我们的方法在处理光谱CT重建方面表现得非常好。此外，它还满足了生成高分辨率重建图像的要求。 et.al.|[2404.06991](http://arxiv.org/abs/2404.06991)|null|
|**2024-04-12**|**SpikeNVS: Enhancing Novel View Synthesis from Blurry Images via Spike Camera**|使用神经辐射场（NeRF）和三维高斯散射（3DGS）等神经场方法实现清晰的新视图合成（NVS）的最关键因素之一是训练图像的质量。然而，传统的RGB相机容易受到运动模糊的影响。相比之下，像事件和尖峰相机这样的神经形态相机固有地捕捉更全面的时间信息，这可以作为额外的训练数据提供场景的清晰表示。最近的方法已经探索了集成事件摄像机以提高NVS的质量。事件RGB方法有一些局限性，例如高昂的培训成本和无法在后台有效工作。相反，我们的研究引入了一种新的方法，使用尖峰相机来克服这些限制。通过将尖峰流的纹理重建视为基本事实，我们设计了尖峰纹理（TfS）损失。由于尖峰摄像机依赖于时间积分，而不是事件摄像机使用的时间微分，我们提出的TfS损失保持了可管理的训练成本。它同时处理前景对象和背景。我们还提供了用spike RGB相机系统拍摄的真实世界数据集，以促进未来的研究工作。我们使用合成和真实世界的数据集进行了广泛的实验，以证明我们的设计可以增强NeRF和3DGS的新视图合成。代码和数据集将提供给公众访问。 et.al.|[2404.06710](http://arxiv.org/abs/2404.06710)|null|
|**2024-04-03**|**A Coupled Neural Field Model for the Standard Consolidation Theory**|标准巩固理论指出，位于海马体的短期记忆能够巩固新皮层的长期记忆。换言之，新皮层在海马体的短暂支持下慢慢学习长期记忆，海马体会快速学习不稳定的记忆。然而，目前尚不清楚这些学习率和记忆时间尺度差异背后的神经生物学机制是什么。在这里，我们提出了一种新的标准巩固理论的建模方法，重点关注其潜在的神经生物学机制。除了突触可塑性和棘突频率适应外，我们的模型还结合了齿状回的成年神经发生以及新皮层和海马体之间的大小差异，我们将其与距离依赖性突触可塑性联系起来。我们还考虑了相关大脑区域的相互关联的空间结构，将上述神经生物学机制纳入耦合的神经场框架中，其中每个区域由具有区域内和区域间连接的单独神经场表示。据我们所知，这是将神经场应用于这一过程的首次尝试。使用数值模拟和数学分析，我们探索了在外部输入的海马重放和检索线索的相位交替时，模型的短期和长期动力学。该外部输入可被编码为单个神经场中的多凸点吸引器模式形式的记忆模式。在该模型中，由于海马记忆模式的突起之间的距离较小，海马记忆模式在新皮质记忆模式之前首先被编码。因此，在短时间尺度上检索新皮层中的输入模式需要由海马体的记忆模式提供额外的输入。新皮质记忆模式在较长的时间内逐渐巩固，直到它们的恢复不再需要海马体的支持。在较长的时间内，神经发生对海马神经场的扰动会抹去海马模式，导致记忆模式只在新皮层中唤起的最终状态。因此，我们模型的动力学成功地再现了标准固结理论的主要特征。这表明，海马体的神经发生和距离依赖性突触可塑性，再加上突触抑制和尖峰频率适应，确实是记忆巩固的关键神经生物学过程。 et.al.|[2404.02938](http://arxiv.org/abs/2404.02938)|null|
|**2024-04-03**|**LiDAR4D: Dynamic Neural Fields for Novel Space-time View LiDAR Synthesis**|尽管神经辐射场（NeRFs）在图像新视图合成（NVS）方面取得了成功，但激光雷达NVS在很大程度上仍未被探索。以前的激光雷达NVS方法采用了图像NVS方法的简单转变，同时忽略了激光雷达点云的动态特性和大规模重建问题。有鉴于此，我们提出了LiDAR4D，这是一种用于新的时空LiDAR视图合成的仅限LiDAR的可微分框架。考虑到稀疏性和大规模特征，我们设计了一种结合多平面和网格特征的4D混合表示，以实现从粗到细的有效重建。此外，我们引入了从点云导出的几何约束，以提高时间一致性。对于激光雷达点云的真实合成，我们结合了光线下降概率的全局优化，以保持跨区域模式。在KITTI-360和NuScenes数据集上进行的大量实验证明了我们的方法在实现几何感知和时间一致的动态重建方面的优越性。代码可在https://github.com/ispc-lab/LiDAR4D. et.al.|[2404.02742](http://arxiv.org/abs/2404.02742)|**[link](https://github.com/ispc-lab/lidar4d)**|
|**2024-04-04**|**Vestibular schwannoma growth prediction from longitudinal MRI by time conditioned neural fields**|前庭神经鞘瘤（VS）是一种良性肿瘤，通常通过MRI检查进行积极监测来治疗。为了进一步帮助临床决策并避免过度治疗，基于纵向成像的肿瘤生长的准确预测是非常可取的。在本文中，我们介绍了DeepGrowth，这是一种深度学习方法，它结合了神经场和递归神经网络，用于前瞻性肿瘤生长预测。在所提出的方法中，每个肿瘤都表示为以低维潜在码为条件的有符号距离函数（SDF）。与之前直接在图像空间中进行肿瘤形状预测的研究不同，我们预测潜在代码，然后从中重建未来的形状。为了处理不规则的时间间隔，我们引入了一个基于ConvLSTM的时间条件递归模块和一种新的时间编码策略，使所提出的模型能够输出随时间变化的肿瘤形状。在内部纵向VS数据集上的实验表明，所提出的模型显著提高了性能（ $\ge 1.6\%%$Dice评分和$\ge0.20$mm95\%Hausdorff距离），特别是对于生长或缩小最多的前20%肿瘤（$\ge4.6\%%$Dice评分和$\ge 0.73$ mm95\%Hausdoff距离）。我们的代码可在~\bull获得{https://github.com/cyjdswx/DeepGrowth} et.al.|[2404.02614](http://arxiv.org/abs/2404.02614)|**[link](https://github.com/cyjdswx/deepgrowth)**|
|**2024-04-02**|**NeRFCodec: Neural Feature Compression Meets Neural Radiance Fields for Memory-Efficient Scene Representation**|神经辐射场（NeRF）的出现极大地影响了三维场景建模和新颖的视图合成。作为一种用于三维场景表示的视觉媒体，具有高率失真性能的压缩是一个永恒的目标。受神经压缩和神经场表示进步的启发，我们提出了NeRFCodec，这是一种端到端的NeRF压缩框架，它集成了非线性变换、量化和熵编码，用于高效记忆的场景表示。由于直接在大规模的NeRF特征平面上训练非线性变换是不切实际的，我们发现，当添加内容特定参数时，可以使用预先训练的神经2D图像编解码器来压缩特征。具体来说，我们重用神经2D图像编解码器，但修改其编码器和解码器头，同时保持预训练解码器的其他部分冻结。这使我们能够通过监督渲染损失和熵损失来训练整个管道，通过更新特定于内容的参数来实现率失真平衡。在测试时，包含潜在代码、特征解码器头和其他辅助信息的比特流被发送用于通信。实验结果表明，我们的方法优于现有的NeRF压缩方法，能够在0.5MB的内存预算下实现高质量的新视图合成。 et.al.|[2404.02185](http://arxiv.org/abs/2404.02185)|null|
|**2024-04-18**|**NeRF-MAE: Masked AutoEncoders for Self-Supervised 3D Representation Learning for Neural Radiance Fields**|神经领域在计算机视觉和机器人领域表现出色，因为它们能够理解3D视觉世界，如推断语义、几何和动力学。考虑到神经场在从2D图像密集表示3D场景方面的能力，我们提出了一个问题：我们是否可以扩展它们的自监督预训练，特别是使用掩蔽的自动编码器，从姿态RGB图像中生成有效的3D表示。由于将转换器扩展到新型数据模式的惊人成功，我们采用了标准的3D视觉转换器来适应NeRF的独特配方。我们利用NeRF的体积网格作为变压器的密集输入，将其与其他3D表示（如点云）进行对比，在点云中，信息密度可能不均匀，并且表示不规则。由于将掩蔽的自动编码器应用于隐式表示（如NeRF）很困难，我们选择提取通过使用相机轨迹进行采样来规范化跨域场景的显式表示。我们的目标是通过从NeRF的辐射和密度网格中屏蔽随机补丁，并使用标准的3D Swin Transformer来重建屏蔽的补丁。通过这样做，模型可以学习完整场景的语义和空间结构。我们在我们提出的精心策划的姿势RGB数据上对这种表示进行了大规模的预训练，总共超过160万张图像。一旦经过预训练，编码器就用于有效的3D迁移学习。我们针对NeRF的新型自监督预训练NeRF-MAE可扩展性非常好，并提高了在各种具有挑战性的3D任务中的性能。在Front3D和ScanNet数据集上，利用未标记的姿态2D数据进行预训练，NeRF MAE显著优于自监督3D预训练和NeRF场景理解基线，在3D对象检测方面的绝对性能提高超过20%AP50和8%AP25。 et.al.|[2404.01300](http://arxiv.org/abs/2404.01300)|null|
|**2024-04-06**|**Grounding and Enhancing Grid-based Models for Neural Fields**|当代许多研究利用基于网格的模型来表示神经场，但仍然缺乏对基于网格模型的系统分析，阻碍了这些模型的改进。因此，本文介绍了一个基于网格的模型的理论框架。该框架指出，这些模型的逼近和泛化行为是由网格切线核（GTK）决定的，GTK是基于网格的模型的固有性质。所提出的框架有助于对各种基于网格的模型进行一致和系统的分析。此外，引入的框架推动了一种新的基于网格的模型的开发，该模型名为乘法傅立叶自适应网格（MulFAGrid）。数值分析表明，MulFAGrid表现出比其前身更低的泛化界，表明其具有鲁棒的泛化性能。实证研究表明，MulFAGrid在各种任务中都取得了最先进的性能，包括2D图像拟合、3D符号距离场（SDF）重建和新颖的视图合成，表现出了卓越的表示能力。项目网站位于https://sites.google.com/view/cvpr24-2034-submission/home. et.al.|[2403.20002](http://arxiv.org/abs/2403.20002)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

