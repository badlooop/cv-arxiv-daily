---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.07.03
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-07-01**|**DRAGON: Drone and Ground Gaussian Splatting for 3D Building Reconstruction**|从成像数据重建三维建筑是从城市规划到侦察等许多应用的重要任务。NeRF和Gaussian Splatting等现代新颖视图合成（NVS）方法为以无监督的方式从自然2D图像开发3D模型提供了强大的技术。这些算法通常需要感兴趣场景周围的输入训练视图，而在大型建筑的情况下，这通常不适用于所有的摄像机立面。特别是，在大多数建筑中，最容易获得的相机视角是在近地面（例如，使用手机）和空中（无人机）高度。然而，由于无人机和地面图像集在视点上的显著差异，相机配准——NVS算法的必要步骤——失败了。在这项工作中，我们提出了一种方法，即DRAGON，它可以将无人机和地面建筑图像作为输入，并生成3D NVS模型。DRAGON的关键见解是，中间高程图像可以通过NVS算法本身在具有感知正则化的迭代过程中外推，从而弥合两个高程之间的视觉特征差距并实现配准。我们使用Google Earth Studio汇编了一个包含9个大型建筑场景的半合成数据集，并从数量和质量上证明，与基线策略相比，DRAGON可以在该数据集上生成引人注目的渲染图。 et.al.|[2407.01761](http://arxiv.org/abs/2407.01761)|null|
|**2024-07-01**|**EndoSparse: Real-Time Sparse View Synthesis of Endoscopic Scenes using Gaussian Splatting**|从一组内窥镜图像中对生物组织进行3D重建是解锁具有3D能力的各种重要下游外科应用的关键。现有的方法使用各种先进的神经渲染技术进行真实感视图合成，但当只有稀疏的观测可用时，它们往往难以恢复准确的3D表示，这在现实世界的临床场景中通常是这样。为了应对这一{稀疏性}挑战，我们提出了一个在重建过程中利用多个基础模型的先验知识的框架，称为\textit{EndoSparse}。实验结果表明，在具有挑战性的稀疏视图条件下，包括仅使用三个视图，我们提出的策略显著提高了几何和外观质量。在针对最先进方法的严格基准测试实验中，\textit｛EndoSparse｝在精确的几何形状、逼真的外观和渲染效率方面取得了优异的结果，证实了内窥镜重建中对稀疏视图限制的稳健性。\textit｛EndoSparse｝标志着神经3D重建在现实世界临床场景中的实际部署迈出了稳步的一步。项目页面：https://endo-sparse.github.io/. et.al.|[2407.01029](http://arxiv.org/abs/2407.01029)|null|
|**2024-06-30**|**Ego-to-Exo: Interfacing Third Person Visuals from Egocentric Views in Real-time for Improved ROV Teleoperation**|水下遥控潜水器是一种无人潜水器，设计用于在海洋深处进行探索和操作。尽管使用了高端相机，但基于第一人称（以自我为中心）视角的典型遥操作引擎限制了水面操作员在复杂深水任务中操纵和导航ROV的能力。在本文中，我们提出了一种交互式遥操作界面，该界面（i）从过去的自我中心视图提供按需的“第三人”（外部中心）视觉效果，以及（ii）通过增强的ROV姿势实时增强外围信息。我们通过将基于3D几何的Ego-to-Exo视图合成算法集成到单目SLAM系统中以实现精确的轨迹估计来实现这一点。所提出的闭合形式解决方案仅使用ROV过去的以自我为中心的视图和SLAM主干进行姿态估计，这使其可移植到现有的ROV平台。与数据驱动的解决方案不同，它对应用程序和水体特定场景是不变的。我们通过在具有挑战性的弱光条件下进行2自由度室内导航和6自由度水下洞穴探索的大量实验，验证了所提出框架的几何精度。我们通过遵循水下洞穴内的洞穴线等导航指南，展示了动态Ego-to-Exo视图生成和实时姿态渲染在远程遥控潜水器遥操作中的优势。这种新的交互式遥控潜水器遥控操作方式为未来的水下遥控机器人研究开辟了广阔的前景。 et.al.|[2407.00848](http://arxiv.org/abs/2407.00848)|null|
|**2024-06-29**|**Intrinsic PAPR for Point-level 3D Scene Albedo and Shading Editing**|神经渲染的最新进展在从多视图RGB图像合成新视图方面表现出色。然而，它们通常缺乏在详细的点级别编辑场景的着色或颜色的能力，同时确保不同视点之间的一致性。在这项工作中，我们解决了点级3D场景反照率和多视图RGB图像的着色编辑的挑战，重点是点级而不是局部或全局级的详细编辑。虽然之前基于体积表示的工作（如NeRF）难以在点级别实现3D一致性编辑，但基于点的神经渲染的最新进展显示出克服这一挑战的前景。我们介绍了“内在PAPR”，这是一种基于最近的基于点的神经绘制技术——接近注意力点绘制（PAPR）的新方法。与其他对场景的内在分解建模的基于点的方法不同，我们的方法不依赖于复杂的着色模型或可能不普遍适用的简单先验。相反，我们直接将场景分解建模为反照率和阴影分量，从而获得更好的估计精度。与最新的基于点的反向渲染方法的比较评估表明，Intrinsic PAPR实现了更高质量的新颖视图渲染和卓越的点级反照率和着色编辑。 et.al.|[2407.00500](http://arxiv.org/abs/2407.00500)|null|
|**2024-06-28**|**ASSR-NeRF: Arbitrary-Scale Super-Resolution on Voxel Grid for High-Quality Radiance Fields Reconstruction**|基于NeRF的方法通过构建具有隐式或显式表示的辐射场来重建3D场景。虽然基于NeRF的方法可以在任意尺度上执行新视图合成（NVS），但在具有低分辨率（LR）优化的高分辨率新视图综合（HRNVS）中的性能往往导致过度平滑。另一方面，单图像超分辨率（SR）旨在将LR图像增强到HR图像，但缺乏多视点一致性。为了应对这些挑战，我们提出了任意尺度超分辨率NeRF（ASSR-NeRF），这是一种用于超分辨率新视图合成（SRNVS）的新框架。我们提出了一种基于注意力的VoxelGridSR模型来直接对优化的体积执行3D超分辨率（SR）。我们的模型在不同的场景中进行了训练，以确保可推广性。对于用LR视图训练的看不见的场景，我们可以直接应用我们的VoxelGridSR来进一步细化体积并实现多视图一致SR。我们从数量和质量上证明了所提出的方法在SRNVS中取得了显著的性能。 et.al.|[2406.20066](http://arxiv.org/abs/2406.20066)|null|
|**2024-06-27**|**360 in the Wild: Dataset for Depth Prediction and View Synthesis**|大量的透视相机数据集促进了用于各种任务的新的基于学习的策略的出现，如相机定位、单图像深度估计或视图合成。然而，全景或全向图像数据集，包括姿势和深度等基本信息，大多是用合成场景制作的。在这项工作中，我们介绍了一个大规模的野外360 $^｛\circ｝$ 视频数据集。这个数据集是从互联网上仔细收集的，并从世界各地捕获。因此，该数据集展示了非常多样化的环境（例如，室内和室外）和上下文（例如，有和没有移动物体）。构成我们数据集的25K幅图像中的每一幅都提供了其各自相机的姿势和深度图。我们说明了我们的数据集与两个主要任务的相关性，即单图像深度估计和视图合成。 et.al.|[2406.18898](http://arxiv.org/abs/2406.18898)|null|
|**2024-06-26**|**Dynamic Gaussian Marbles for Novel View Synthesis of Casual Monocular Videos**|高斯散射已经成为新视图合成的一种流行表现，在效率、光度质量和成分可食性方面表现出明显的优势。在其成功之后，许多工作已经将高斯扩展到4D，表明动态高斯保持了这些优势，同时也比替代表示更好地跟踪场景几何。然而，这些方法假设密集的多视图视频作为监督，限制了它们在受控捕捉设置中的使用。在这项工作中，我们将高斯场景表示的能力扩展到随意捕捉的单目视频。我们表明，现有的4D高斯方法在这种设置中显著失败，因为单目设置约束不足。基于这一发现，我们提出了动态高斯大理石（DGMarbles），由三个核心修改组成，针对单目设置的困难。首先，DGMarbles使用各向同性的高斯“弹珠”，减少每个高斯的自由度，并将优化约束为关注局部形状的运动和外观。其次，DGMarbles采用分层分治学习策略来引导优化朝着具有连贯运动的解决方案前进。最后，DGMarbles将图像级和几何级先验添加到优化中，包括利用点跟踪的最新进展的跟踪损失。通过以这些方式约束优化，DGMarbles学习高斯轨迹，从而实现新颖的视图渲染并准确捕捉场景元素的3D运动。我们在（单眼）Nvidia Dynamic Scenes数据集和Dycheck iPhone数据集上进行了评估，结果表明DGMarbles在质量上显著优于其他高斯基线，与非高斯表示不相上下，同时保持了高斯的效率、合成性、可编辑性和跟踪优势。 et.al.|[2406.18717](http://arxiv.org/abs/2406.18717)|null|
|**2024-06-26**|**MultiDiff: Consistent Novel View Synthesis from a Single Image**|我们介绍了MultiDiff，这是一种从单个RGB图像中对场景进行一致新颖视图合成的新方法。从单个参考图像合成新视图的任务是自然造成的，因为对未观察到的区域存在多种看似合理的解释。为了解决这个问题，我们以单目深度预测器和视频扩散模型的形式结合了强先验。单目深度使我们能够根据目标视图的扭曲参考图像来调整模型，从而提高几何稳定性。视频扩散先验为3D场景提供了强大的代理，允许模型学习生成图像之间的连续和像素精确的对应关系。与依赖于易于漂移和误差累积的自回归图像生成的方法不同，MultiDiff联合合成一系列帧，从而产生高质量和多视图一致的结果——即使是对于具有大相机移动的长期场景生成，同时将推理时间减少一个数量级。为了进一步提高一致性和图像质量，我们引入了一种新颖的结构化噪声分布。我们的实验结果表明，MultiDiff在具有挑战性的真实世界数据集RealEstate10K和ScanNet上优于最先进的方法。最后，我们的模型自然支持多视图一致性编辑，而无需进一步调整。 et.al.|[2406.18524](http://arxiv.org/abs/2406.18524)|null|
|**2024-06-27**|**XLD: A Cross-Lane Dataset for Benchmarking Novel Driving View Synthesis**|彻底测试自动驾驶系统对于追求安全的自动驾驶汽车至关重要。这就需要创建超出现实世界数据安全收集范围的安全关键场景，因为其中许多场景在公共道路上很少发生。然而，大多数现有NVS方法的评估依赖于对来自训练数据的图像帧的零星采样，使用度量将渲染图像与真实图像进行比较。遗憾的是，该评估协议不能满足闭环仿真的实际要求。具体而言，真正的应用程序需要渲染超出原始轨迹的新颖视图（如跨车道视图）的能力，而这些视图在现实世界中很难捕捉。为了解决这一问题，本文提出了一种专门为自动驾驶模拟设计的新型驾驶视图合成数据集和基准。该数据集是独特的，因为它包括通过偏离训练轨迹1-4米而捕获的测试图像。它包括六个序列，包括不同的时间和天气条件。每个序列包含450个训练图像、150个测试图像以及它们对应的相机姿态和固有参数。利用这一新颖的数据集，我们建立了第一个现实的基准，用于在仅前置和多摄像头设置下评估现有的NVS方法。实验结果强调了当前方法中存在的显著差距，揭示了它们不足以满足跨车道或闭环模拟的苛刻先决条件。我们的数据集在项目页面上公开发布：https://3d-aigc.github.io/XLD/. et.al.|[2406.18360](http://arxiv.org/abs/2406.18360)|null|
|**2024-06-26**|**VDG: Vision-Only Dynamic Gaussian for Driving Simulation**|动态高斯飞溅已经在新颖的视图中带来了令人印象深刻的场景重建和图像合成进展。然而，现有的方法在很大程度上依赖于预先计算的姿态和通过运动结构（SfM）算法或昂贵的传感器进行的高斯初始化。本文首次通过将自监督VO集成到我们的无姿态动态高斯方法（VDG）中来解决这个问题，以促进姿态和深度初始化以及静态动态分解。此外，与无姿态动态视图合成方法相比，VDG可以仅使用RGB图像输入，以更快的速度和更大的场景构建动态场景。我们通过大量的定量和定性实验证明了我们的方法的稳健性。与最先进的动态视图合成方法相比，我们的结果显示出良好的性能。其他视频和源代码将发布在我们的项目页面上https://3d-aigc.github.io/VDG. et.al.|[2406.18198](http://arxiv.org/abs/2406.18198)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-07-02**|**The influence of the 3D Galactic gas structure on cosmic-ray transport and gamma-ray emission**|宇宙射线（CR）在星际介质（ISM）的动力学中起着重要作用。它们的相互作用和传输电离、加热并推动ISM，从而耦合ISM的不同区域。CR的空间分布取决于其来源的分布以及它们相互作用的ISM成分，如气体、星光和磁场。特别是，气体与CR密切相互作用，影响CR通量和伽马射线发射。我们说明了三维气体结构对CR传输和伽马射线发射的影响。我们使用PICARD代码和最近HI和H $_2$ 银河系气体成分的多个3D重建样本来研究对CR传输和伽马射线发射的影响。我们找到了必要的输运参数来再现CR通量的局部测量，并发现它们取决于气体密度和结构的局部分布。CR通量的分布表现出与能量相关的结构，由于其相应的损失过程，所有CR物种都会发生变化。增强的次级（初级）物种的区域与气体密度在空间上相关（反相关）。我们观察到伽马射线发射对气体结构对比度的高灵敏度，因为这些结构决定了强子相互作用和韧致辐射的三维空间分布。我们发现在逆康普顿（IC）发射中也可以看到CR电子分布中相应的气体诱导结构。由于上述敏感性，对CR源和输送参数的CR数据的分析需要使用准确的3D气体图。 et.al.|[2407.02410](http://arxiv.org/abs/2407.02410)|null|
|**2024-07-02**|**Indoor 3D Reconstruction with an Unknown Camera-Projector Pair**|基于结构光的摄像机-投影对（CPP）方法在室内三维重建中起着至关重要的作用，尤其是对于纹理较弱的场景。以前的方法通常假设已知的本质，这些本质是从已知物体中预先校准的，或者是从多视图观测中自我校准的。在没有任何已知对象的情况下，仅从两个视图可靠地恢复CPP内部函数仍然具有挑战性。在本文中，我们提供了一个简单而可靠的解决方案。我们首次证明，可以从未知的长方体角（C2），例如房间的角，导出对CPP本质的足够约束，这是室内场景中的常见结构。此外，在只有已知相机主点的情况下，所有CPP本质的复杂多变量估计可以简化为一个简单的单变量优化问题，从而实现可靠的校准，从而在未知CPP的情况下直接进行3D重建。大量结果表明，与传统方法和基于学习的方法相比，所提出的方法具有优越性。此外，所提出的方法还展示了在没有主动照明的情况下解决类似任务的巨大潜力，例如来自运动的稀疏视图结构。 et.al.|[2407.01945](http://arxiv.org/abs/2407.01945)|null|
|**2024-07-02**|**PO-MSCKF: An Efficient Visual-Inertial Odometry by Reconstructing the Multi-State Constrained Kalman Filter with the Pose-only Theory**|有效的视觉惯性里程计（VIO）对于有效载荷受限的机器人至关重要。尽管现代基于优化的算法已经实现了优越的精度，但基于MSCKF的VIO算法仍然因其高效和一致的性能而被广泛要求。由于MSCKF建立在传统的多视图几何结构上，因此测量的残差不仅与状态误差有关，而且与特征位置误差有关。为了应用EKF融合，需要投影过程来消除观测模型中的特征位置误差，这可能导致模型和精度下降。为了获得有效的视觉惯性融合模型，同时保持模型的一致性，我们提出用新的仅姿态（PO）多视图几何描述来重建MSCKF-VIO。在新构建的滤波器中，我们对PO重投影残差进行了建模，这些残差仅与运动状态相关，从而克服了空间投影的要求。此外，新滤波器不需要任何特征位置信息，这消除了由3D重建过程带来的计算成本和线性化误差。我们在多个数据集上进行了全面的实验，其中所提出的方法在具有挑战性的序列中显示出准确性的提高和一致的性能。 et.al.|[2407.01888](http://arxiv.org/abs/2407.01888)|null|
|**2024-07-02**|**Multi-level Reliable Guidance for Unpaired Multi-view Clustering**|在本文中，我们解决了不成对多视图聚类（UMC）的挑战性问题，旨在使用多个视图中的不成对观测样本进行有效的联合聚类。通常，传统的不完全多视图聚类（IMC）方法通常依赖于成对的样本来捕获视图之间的互补信息。然而，由于缺乏配对样本，该策略在UMC中变得不切实际。尽管一些研究人员试图通过在视图之间保持一致的聚类结构来解决这个问题，但他们经常忽视这些聚类结构的可信度，尤其是对于初始训练期间的边界样本和不确定的聚类结构。因此，我们提出了一种称为UMC多级可靠指导（MRG-UMC）的方法，该方法利用多级聚类来帮助分别跨内部视图、跨视图和公共视图学习可信的聚类结构。具体来说，在每个视图中，多级集群在不同级别上培育了一个值得信赖的集群结构，并减少了集群错误。在跨视图学习中，可靠的视图引导增强了集群结构对其他视图的信心。同样，在多层次框架内，合并一个共同的视图有助于对齐不同的视图，从而减少聚类误差和聚类结构的不确定性。最后，正如大量实验所证明的那样，与20种最先进的方法相比，我们的UMC方法显示出显著的效率提高。 et.al.|[2407.01247](http://arxiv.org/abs/2407.01247)|null|
|**2024-07-01**|**EndoSparse: Real-Time Sparse View Synthesis of Endoscopic Scenes using Gaussian Splatting**|从一组内窥镜图像中对生物组织进行3D重建是解锁具有3D能力的各种重要下游外科应用的关键。现有的方法使用各种先进的神经渲染技术进行真实感视图合成，但当只有稀疏的观测可用时，它们往往难以恢复准确的3D表示，这在现实世界的临床场景中通常是这样。为了应对这一{稀疏性}挑战，我们提出了一个在重建过程中利用多个基础模型的先验知识的框架，称为\textit{EndoSparse}。实验结果表明，在具有挑战性的稀疏视图条件下，包括仅使用三个视图，我们提出的策略显著提高了几何和外观质量。在针对最先进方法的严格基准测试实验中，\textit｛EndoSparse｝在精确的几何形状、逼真的外观和渲染效率方面取得了优异的结果，证实了内窥镜重建中对稀疏视图限制的稳健性。\textit｛EndoSparse｝标志着神经3D重建在现实世界临床场景中的实际部署迈出了稳步的一步。项目页面：https://endo-sparse.github.io/. et.al.|[2407.01029](http://arxiv.org/abs/2407.01029)|null|
|**2024-06-28**|**Odd-One-Out: Anomaly Detection by Comparing with Neighbors**|本文介绍了一种新的异常检测（AD）问题，该问题的重点是识别相对于场景中其他实例的“奇怪的”对象。与传统的AD基准不同，在我们的设置中，这种情况下的异常是特定于场景的，由占大多数的常规实例定义。由于对象实例通常从单个视点部分可见，因此我们的设置提供每个场景的多个视图作为输入。为了为未来的研究提供一个试验台，我们介绍了两个基准，ToysAD-8K和PartsAD-15K。我们提出了一种新的方法，该方法为每个实例生成以对象为中心的3D表示，并通过实例之间的交叉检查来检测异常表示。我们在给出的基准中对我们的方法进行了严格的定量和定性分析。 et.al.|[2406.20099](http://arxiv.org/abs/2406.20099)|**[link](https://github.com/VICO-UoE/OddOneOutAD)**|
|**2024-06-28**|**SpotlessSplats: Ignoring Distractors in 3D Gaussian Splatting**|三维高斯散射（3DGS）是一种很有前途的三维重建技术，它提供了高效的训练和渲染速度，适用于实时应用。然而，当前的方法需要高度受控的环境（没有移动的人或风吹的元素，以及一致的照明）来满足3DGS的视图间一致性假设。这使得真实世界捕捉的重建成为问题。我们提出了SpotlessSplats，这是一种利用预先训练的通用功能与稳健优化相结合的方法，可以有效地忽略瞬态干扰因素。我们的方法在随意捕捉的情况下，在视觉和数量上都达到了最先进的重建质量。 et.al.|[2406.20055](http://arxiv.org/abs/2406.20055)|null|
|**2024-06-28**|**Deep Learning-based Depth Estimation Methods from Monocular Image and Videos: A Comprehensive Survey**|由于其在自动驾驶、3D重建、数字娱乐和机器人等许多领域的应用，从单个RGB图像和视频中估计深度引起了广泛的兴趣。在过去的10年里，已经发表了500多篇基于深度学习的论文，这表明人们对这项任务的兴趣越来越大。本文对现有的基于深度学习的方法、它们所面临的挑战以及它们在架构和监督方法方面的发展进行了全面的调查。它提供了一种分类法，用于根据输入和输出模式、网络架构和学习方法对当前工作进行分类。它还讨论了单目深度估计历史上的主要里程碑，以及现有方法中使用的不同管道、数据集和评估指标。 et.al.|[2406.19675](http://arxiv.org/abs/2406.19675)|null|
|**2024-06-28**|**LiverUSRecon: Automatic 3D Reconstruction and Volumetry of the Liver with a Few Partial Ultrasound Scans**|肝脏体积测量的三维重建对于定性分析和疾病诊断非常重要。使用超声（US）扫描的肝脏容量测定虽然由于采集时间和安全性较短而具有优势，但由于超声扫描固有的噪声、边界模糊和部分肝脏可见性，因此具有挑战性。我们通过使用肝脏的一些不完全矢状面US扫描的分割掩模，以及使用一组肝脏CT扫描建立的统计形状模型（SSM）来解决这些挑战。我们通过参数回归网络计算扭曲该标准SSM以拟合US扫描所需的形状参数。由此产生的3D肝脏重建是准确的，并导致自动肝脏体积计算。我们使用RMSE评估估计的肝脏体积相对于CT分割体积的准确性。我们的体积计算在统计学上更接近于使用CT扫描估计的体积，而不是放射科医生使用Childs方法计算的体积：p值0.094（>0.05）表明，与Childs方法相比，CT分割体积与我们的体积之间没有显著差异。我们通过对US图像分辨率、用于SSM的CT扫描次数、主成分数量和输入US扫描次数的调查（消融研究）验证了我们的方法。据我们所知，这是第一个使用一些不完整的US扫描的自动肝脏容量测定系统，给出了一组SSM的肝脏CT扫描。 et.al.|[2406.19336](http://arxiv.org/abs/2406.19336)|null|
|**2024-06-26**|**On Scaling Up 3D Gaussian Splatting Training**|三维高斯散射（3DGS）以其优越的视觉质量和渲染速度在三维重建中越来越受欢迎。然而，3DGS训练目前发生在单个GPU上，由于内存限制，限制了其处理高分辨率和大规模3D重建任务的能力。我们介绍了Grendel，这是一个分布式系统，旨在划分3DGS参数并在多个GPU之间并行计算。由于每个高斯影响渲染像素的一个小的动态子集，Grendel采用稀疏的全对全通信将必要的高斯传输到像素分区，并执行动态负载平衡。与一次使用一个相机视图图像进行训练的现有3DGS系统不同，Grendel支持使用多个视图进行批量训练。我们探索了各种优化超参数缩放策略，发现一个简单的sqrt（批量大小）缩放规则是非常有效的。使用大规模、高分辨率场景的评估表明，Grendel通过在多个GPU上放大3DGS参数来提高渲染质量。在Rubble数据集上，我们通过在16个GPU上分布4040万高斯实现了27.28的测试PSNR，而在单个GPU上使用1120万高斯实现的PSNR为26.28。Grendel是一个开源项目，位于：https://github.com/nyu-systems/Grendel-GS et.al.|[2406.18533](http://arxiv.org/abs/2406.18533)|**[link](https://github.com/nyu-systems/grendel-gs)**|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-07-02**|**Magic Insert: Style-Aware Drag-and-Drop**|我们提出了Magic Insert，这是一种在匹配目标图像的风格的同时，以物理上合理的方式将主题从用户提供的图像拖放到不同风格的目标图像中的方法。这项工作形式化了风格感知拖放的问题，并提出了一种通过解决两个子问题来解决它的方法：风格感知个性化和风格化图像中的真实对象插入。对于风格感知个性化，我们的方法首先使用主题图像上的LoRA和学习的文本标记来微调预训练的文本到图像的扩散模型，然后将目标风格的CLIP表示注入其中。对于对象插入，我们使用自举域自适应来将特定于域的照片真实感对象插入模型调整为不同艺术风格的域。总体而言，该方法显著优于传统方法，如修复。最后，我们提供了一个数据集SubjectPlop，以促进该领域的评估和未来进展。项目页面：https://magicinsert.github.io/ et.al.|[2407.02489](http://arxiv.org/abs/2407.02489)|null|
|**2024-07-02**|**Boosting Consistency in Story Visualization with Rich-Contextual Conditional Diffusion Models**|最近的研究展示了条件扩散模型在生成一致故事方面的巨大潜力。然而，目前的方法主要以自回归和过度依赖字幕的方式生成故事，在顺序生成过程中往往低估了框架的上下文一致性和相关性。为了解决这一问题，我们提出了一种新的富上下文条件扩散模型（RCDM），这是一种两阶段的方法，旨在增强故事生成的语义一致性和时间一致性。具体而言，在第一阶段，提出了帧先验变换器扩散模型，通过对齐已知片段的字幕和帧之间的语义相关性来预测未知片段的帧语义嵌入。第二阶段建立了一个具有丰富上下文条件的鲁棒模型，包括已知片段的参考图像、未知片段的预测帧语义嵌入以及所有字幕的文本嵌入。通过在图像和特征级别联合注入这些丰富的上下文条件，RCDM可以生成语义和时间一致性故事。此外，与自回归模型相比，RCDM可以通过单个正向推理生成一致的故事。我们的定性和定量结果表明，我们提出的RCDM在具有挑战性的场景中表现出色。代码和型号将在https://github.com/muzishen/RCDMs. et.al.|[2407.02482](http://arxiv.org/abs/2407.02482)|null|
|**2024-07-02**|**Mirages and Large TeV Halo-Pulsar Offsets from Cosmic Ray Propagation**|对扩展 $\gamma$ -射线源的研究通常假设宇宙射线的对称扩散。然而，最近对单个脉冲星附近多个源的观测以及TeV晕质心与其母脉冲星之间的显著偏移表明，这一假设过于简单。在这封信中，我们证明了宇宙射线在其加速器附近的不对称传播可能会产生多个TeV源，而不是单个对称源。这一机制也解释了TeV晕质心与其脉冲星之间的巨大偏移。我们证明，在不调用额外的不可见加速器的情况下，可以自然地解释几个令人困惑的检测源。 et.al.|[2407.02478](http://arxiv.org/abs/2407.02478)|null|
|**2024-07-02**|**Diffusion and pattern formation in spatial games**|扩散在从细菌群体感应到交通流动力学的各种现象中发挥着重要作用。虽然扩散通常倾向于消除梯度和不均匀性，但在某些类别的系统中，扩散仍被证明可以促进图案的形成。稳定结构的形成往往是促进合作行为在其他竞争环境中出现和持续的关键因素，但缺乏对扩散对此类系统影响的深入分析。因此，我们使用有噪声的空间迭代囚犯困境（IPD）的元胞自动机（CA）模型研究了扩散对合作行为的影响，物理扩展和随机性是几种自然现象不可避免的特征。我们进一步推导了一个平均场（MF）模型，该模型从CA模型中捕捉了3种物种的捕食动力学，并强调了模式形成是如何在这个新模型中产生的，然后描述了通过交换包括扩散是如何类似地使CA模型中出现大规模结构的。我们研究了这些新兴模式如何有利于参数空间区域的合作行为，其中IPD错误率通常禁止这种动态。因此，我们展示了扩散与非线性动力学的耦合如何反直觉地促进大规模结构的形成，并反过来为合作在随机空间系统中站稳脚跟奠定新的基础。 et.al.|[2407.02385](http://arxiv.org/abs/2407.02385)|null|
|**2024-07-02**|**OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation**|由于大型多模态模型Sora，文本到视频（T2V）生成最近获得了极大的关注。然而，T2V生成仍然面临两个重要挑战：1）缺乏精确的开源高质量数据集。以前流行的视频数据集，例如WebVid-10M和Panda-70M，对于大多数研究机构来说要么质量低，要么太大。因此，为T2V生成收集精确的高质量文本视频对是具有挑战性但至关重要的。2） 忽略以充分利用文本信息。最近的T2V方法专注于视觉转换器，使用简单的交叉注意力模块进行视频生成，无法从文本提示中彻底提取语义信息。为了解决这些问题，我们引入了OpenVid-1M，这是一个具有表达性字幕的精确高质量数据集。这个开放场景数据集包含超过100万个文本视频对，有助于T2V生成的研究。此外，我们策划了来自OpenVid-1M的433K 1080p视频，以创建OpenVidHD-0.4M，推进高清视频生成。此外，我们提出了一种新的多模式视频扩散转换器（MVDiT），能够从视觉标记中挖掘结构信息，并从文本标记中挖掘语义信息。广泛的实验和消融研究验证了OpenVid-1M相对于先前数据集的优势以及我们的MVDiT的有效性。 et.al.|[2407.02371](http://arxiv.org/abs/2407.02371)|null|
|**2024-07-02**|**Hypersonic Boundary Layer Transition and Heat Loading**|尽管文献中有一些参考文献，但使用高阶方法进行直接数值模拟（DNS）的高超音速边界层转换在很大程度上尚未被探索。高超音速状态下的实验数据很少，而几乎所有现有的高超音速代码都具有低阶精度，这可能导致长期积分和高雷诺数下的错误结果。在这里，我们关注从层流到湍流的过渡，其中努塞尔数可能是湍流状态下努塞尔数的五倍或更高。必须使用真实的化学方法对高超音速流场进行准确建模，以正确预测表面的热通量。在这项研究中，我们模拟了平板上的高超音速边界层过渡，以计算壁上的热应力和剪切应力。该域是用可压缩边界层方程的Blasius层流解初始化的。通过从壁上的薄条带抽吸和吹送来诱导向湍流的过渡。在流入和流出边界处定义海绵区域，以消除由于边界条件的反射而引起的溶液污染。在翼展方向上，施加周期性边界条件。这里应用的数值方法是域内部的六阶紧致有限差分，与使用交错变量的结构化笛卡尔网格的四阶龙格-库塔时间步进方案相耦合。基础有限差分程序可以模拟非平衡高超音速流动。利用近似反褶积模型和人工扩散系数对数值格式进行了稳定。我们研究了非平衡化学对高超音速边界层非线性不稳定性增长的影响。我们还量化了马赫数为10的边界层层流到湍流过渡期间的热载荷。 et.al.|[2407.02311](http://arxiv.org/abs/2407.02311)|null|
|**2024-07-02**|**Turbulent Diffuse Molecular Media with Non-ideal Magnetohydrodynamics and Consistent Thermochemistry: Numerical Simulations and Dynamic Characteristics**|湍流扩散分子云由于辐射、化学、流体和场之间的相互作用而呈现出复杂的形态。我们对湍流扩散分子星际介质进行了全三维模拟，其特征是与磁流体动力学（MHD）共同演化的时间相关非平衡热化学。模拟结果表明，关键化学物种（如C、CO、OH）的相对丰度在化学进化的“过早”时期（ $t\lesssim 2\times 10^5~｛\rm yr｝$）变化超过一个数量级。还进行了各种模拟，以研究物理参数的影响。非理想磁流体动力学效应对形成气体的行为至关重要，强磁场（$\sim 10~\mu｛\rm G｝$）往往会抑制剧烈的压缩，从而降低暖气体的比例（$T\gtrsim 10^2~｛\rmK｝$ ）。气体的热力学和化学条件对动力学条件的调制非常敏感，尤其是湍流的能量注入。化学特征，包括电离（宇宙射线和扩散星际辐射），不会直接影响湍流功率谱。尽管如此，它们的影响在温度和气体密度的分布图中是突出的。综合观测对于消除物理参数的退化和自信地约束扩散分子云的性质是必要和有用的。 et.al.|[2407.02306](http://arxiv.org/abs/2407.02306)|null|
|**2024-07-02**|**On the multicomponent reactive flows in moving domains**|本文研究了运动域内多组分反应流的全局时间弱解的存在性，该运动域的时间形状是规定的。流动由三维可压缩Navier-Stokes傅立叶系统与物质质量分数方程相耦合来控制。假设流体速度满足完全滑移边界条件，而热通量和物种扩散通量满足保守边界条件。通过适当的近似技术，得到了弱解的存在性。为此，我们需要严格分析弱公式中边界行为、粘度和压力的惩罚。 et.al.|[2407.02303](http://arxiv.org/abs/2407.02303)|null|
|**2024-07-02**|**Solution of parameter-dependent diffusion equation in layered media**|本文研究了由局部镜像对称层组成的二维域中的参数相关扩散方程。假设扩散系数在每一层中是一个常数。目标是找到具有少量项的近似参数到解决方案映射。结果表明，在两层的情况下，可以找到一个由三项组成的解公式，这三项与扩散系数有显式依赖关系。该公式基于将解分解为与层和层之间的界面相关的正交部分。然后将该公式扩展为多层情况下的近似公式。我们给出了正方形层的解析公式，并对更一般的层使用有限元公式。数值算例说明了这一结果，并通过分析Kolmogorov n宽度对简化基方法具有应用价值。 et.al.|[2407.02257](http://arxiv.org/abs/2407.02257)|null|
|**2024-07-02**|**GlyphDraw2: Automatic Generation of Complex Glyph Posters with Diffusion Models and Large Language Models**|海报在营销和广告中发挥着至关重要的作用，通过增强视觉传达和品牌知名度，对工业设计做出了重大贡献。随着可控文本到图像扩散模型的最新进展，更简洁的研究现在集中在合成图像中的文本渲染上。尽管文本渲染精度有所提高，但端到端海报生成领域的开发仍然不足。这项复杂的任务涉及在文本渲染精度和自动布局之间取得平衡，以生成具有可变纵横比的高分辨率图像。为了应对这一挑战，我们提出了一种端到端的文本渲染框架，该框架采用了植根于对齐学习的三重交叉注意力机制，旨在在详细的上下文背景中创建精确的海报文本。此外，我们还介绍了一个图像分辨率超过1024像素的高分辨率数据集。我们的方法利用了SDXL体系结构。大量实验验证了我们的方法生成具有复杂和丰富背景的海报图像的能力。代码将在https://github.com/OPPO-Mente-Lab/GlyphDraw2. et.al.|[2407.02252](http://arxiv.org/abs/2407.02252)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-07-01**|**Fast and Efficient: Mask Neural Fields for 3D Scene Segmentation**|理解3D场景是计算机视觉研究中的一个关键挑战，其应用涉及多个领域。在将2D视觉语言基础模型提取到神经领域（如NeRF和3DGS）方面的最新进展，使得能够从2D多视图图像中对3D场景进行开放式词汇分割，而无需精确的3D注释。然而，虽然有效，但高维CLIP特征的每像素提取引入了模糊性，并需要复杂的正则化策略，从而增加了训练过程中的低效率。本文提出了MaskField，它可以在弱监督下使用神经场实现快速高效的三维开放词汇分割。与以前的方法不同，MaskField提取的是遮罩，而不是密集的高维CLIP特征。MaskFields使用神经场作为二进制掩码生成器，并使用SAM生成的掩码对其进行监督，并根据粗略的CLIP特征进行分类。MaskField通过在训练过程中自然引入SAM分割的对象形状而无需额外的正则化，克服了模糊的对象边界。通过避免在训练过程中直接处理高维CLIP特征，MaskField与3DGS等显式场景表示特别兼容。我们的大量实验表明，MaskField不仅超越了现有的最先进的方法，而且实现了显著的快速收敛，仅需5分钟的训练就超过了以前的方法。我们希望MaskField将激励人们进一步探索如何训练神经场来从2D模型中理解3D场景。 et.al.|[2407.01220](http://arxiv.org/abs/2407.01220)|null|
|**2024-07-01**|**3D Feature Distillation with Object-Centric Priors**|将自然语言与物理世界联系起来是一个普遍存在的话题，在计算机视觉和机器人领域有着广泛的应用。最近，像CLIP这样的2D视觉语言模型已经被广泛普及，因为它们在2D图像中具有令人印象深刻的开放词汇基础能力。最近的工作旨在通过特征提取将2D CLIP特征提升到3D，但要么学习特定于场景的神经场，因此缺乏泛化能力，要么专注于需要访问多个相机视图的室内房间扫描数据，这在机器人操作场景中是不现实的。此外，相关方法通常在像素级融合特征，并假设所有相机视图的信息量相等。在这项工作中，我们证明了这种方法在基础精度和分割清晰度方面都会导致次优的3D特征。为了缓解这种情况，我们提出了一种多视图特征融合策略，该策略采用以对象为中心的先验来消除基于语义信息的无信息视图，并通过实例分割掩码在对象级别融合特征。为了提取我们以对象为中心的3D特征，我们生成了一个杂乱桌面场景的大规模合成多视图数据集，从3300多个独特的对象实例中生成了15k个场景，并将其公开。我们表明，我们的方法在从单视图RGB-D重建3D CLIP特征的同时，具有改进的接地能力和空间一致性，从而偏离了测试时多个相机视图的假设。最后，我们证明了我们的方法可以推广到新的桌面领域，并在不进行微调的情况下重新用于3D实例分割，并证明了它在语言引导的机器人抓取中的实用性 et.al.|[2406.18742](http://arxiv.org/abs/2406.18742)|null|
|**2024-06-25**|**Masked Generative Extractor for Synergistic Representation and 3D Generation of Point Clouds**|在2D图像生成建模和表示学习领域，掩模生成编码器（MAGE）已经证明了生成建模与表示学习之间的协同潜力。受此启发，我们提出了Point MAGE，将这一概念扩展到点云数据。具体而言，该框架首先利用矢量量化变分自动编码器（VQVAE）来重建3D形状的神经场表示，从而学习点块的离散语义特征。随后，通过将掩蔽模型与可变掩蔽比相结合，我们实现了生成和表示学习的同步训练。此外，我们的框架与现有的点云自监督学习（SSL）模型无缝集成，从而提高了它们的性能。我们广泛评估了Point MAGE的表示学习和生成能力。在形状分类任务中，Point MAGE在ModelNet40数据集上的准确率为94.2%，在ScanObjectNN数据集上达到92.9%（+1.3%）。此外，它在少量镜头学习和零件分割任务中实现了最先进的性能。实验结果还证实，点MAGE可以在无条件和有条件的设置中生成详细和高质量的3D形状。 et.al.|[2406.17342](http://arxiv.org/abs/2406.17342)|null|
|**2024-06-17**|**DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features**|我们提出了DistilleNeRF，这是一种自监督学习框架，解决了在自动驾驶中从有限的2D观测中理解3D环境的挑战。我们的方法是一个可推广的前馈模型，它从稀疏的单帧多视图相机输入中预测丰富的神经场景表示，并通过可微分渲染进行自监督训练，以重建RGB、深度或特征图像。我们的第一个见解是通过生成密集的深度和虚拟相机目标进行训练，利用每场景优化的神经辐射场（NeRF），从而帮助我们的模型从稀疏的非重叠图像输入中学习3D几何。其次，为了学习语义丰富的3D表示，我们建议从预先训练的2D基础模型（如CLIP或DINOv2）中提取特征，从而实现各种下游任务，而不需要昂贵的3D人工注释。为了利用这两个见解，我们引入了一种新的模型架构，该架构具有两级提升-飞溅-拍摄编码器和参数化稀疏分层体素表示。在NuScenes数据集上的实验结果表明，DistilleNeRF在场景重建、新视图合成和深度估计方面显著优于现有的可比自监督方法；并且它允许竞争性的零样本3D语义占用预测，以及通过提取的基础模型特征来理解开放世界场景。演示和代码将在https://distillnerf.github.io/. et.al.|[2406.12095](http://arxiv.org/abs/2406.12095)|null|
|**2024-06-18**|**Effective Rank Analysis and Regularization for Enhanced 3D Gaussian Splatting**|从多视图图像中进行三维重建是计算机视觉和图形学的基本挑战之一。近年来，三维高斯散射（3DGS）已经成为一种很有前途的技术，能够实时渲染和高质量的三维重建。该方法利用了三维高斯表示和基于瓦片的飞溅技术，绕过了昂贵的神经场查询。尽管3DGS具有潜力，但由于高斯收敛为具有一个主导方差的各向异性高斯，3DGS仍面临挑战，包括针状伪影、次优几何结构和不准确法线。我们建议使用有效秩分析来检查3D高斯基元的形状统计，并识别高斯确实收敛为有效秩为1的针状形状。为了解决这个问题，我们引入了有效秩作为正则化，它约束高斯的结构。我们的新正则化方法增强了法线和几何重建，同时减少了针状伪影。该方法可以作为附加模块集成到其他3DGS变体中，在不影响视觉逼真度的情况下提高其质量。 et.al.|[2406.11672](http://arxiv.org/abs/2406.11672)|null|
|**2024-06-13**|**Well-posedness and regularity of solutions to neural field problems with dendritic processing**|我们研究了最近提出的神经场模型的解决方案，在该模型中，树突被建模为源自体细胞层的垂直纤维的连续体。由于电压通过具有非局部源的电缆方程沿树枝状方向传播，因此该模型具有各向异性扩散算子以及突触耦合的积分项。因此，相应的柯西问题与经典的神经场方程明显不同。我们证明了问题的弱公式允许一个唯一的解，嵌入估计类似于非线性局部反应扩散方程的嵌入估计。我们的分析依赖于无扩散问题的扰动弱解，即标准神经场，迄今为止尚未对其弱问题进行研究。我们找到了有扩散和无扩散问题的严格渐近估计，并证明了这两个模型的解在有限时间间隔上在适当的范数下保持接近。我们提供了微扰结果的数值证据。 et.al.|[2406.09222](http://arxiv.org/abs/2406.09222)|null|
|**2024-06-13**|**Preserving Identity with Variational Score for General-purpose 3D Editing**|我们提出了Piva（用变分分数蒸馏保持同一性），这是一种新的基于优化的方法，用于编辑基于扩散模型的图像和3D模型。具体来说，我们的方法受到了最近提出的2D图像编辑方法——德尔塔去噪分数（DDS）的启发。我们指出了DDS在二维和三维编辑中的局限性，这会导致细节丢失和过饱和。为了解决这一问题，我们提出了一个额外的分数提取术语，以强制执行身份保护。这导致了更稳定的编辑过程，逐步优化NeRF模型以匹配目标提示，同时保留关键的输入特征。我们证明了我们的方法在零样本图像和神经场编辑中的有效性。我们的方法成功地改变了视觉属性，添加了微妙和实质性的结构元素，转换了形状，并在标准的2D和3D编辑基准上取得了有竞争力的结果。此外，我们的方法没有施加任何约束，如掩蔽或预训练，使其与广泛的预训练扩散模型兼容。这允许进行多功能编辑，而不需要神经场到网格的转换，提供更用户友好的体验。 et.al.|[2406.08953](http://arxiv.org/abs/2406.08953)|null|
|**2024-06-12**|**Category-level Neural Field for Reconstruction of Partially Observed Objects in Indoor Environment**|通过各种成功案例，神经隐式表示在三维重建中引起了人们的关注。对于进一步的应用，如场景理解或编辑，一些作品已经显示出在对象组成重建方面的进展。尽管它们在观测区域具有优越的性能，但在重建部分观测到的对象时，它们的性能仍然有限。为了更好地处理这个问题，我们引入了类别级神经场，该神经场在场景中属于同一类别的对象之间学习有意义的公共3D信息。我们的主要想法是根据观察到的形状对对象进行子分类，以便更好地训练类别级模型。然后，我们利用神经场，通过选择基于射线的不确定性选择的代表性对象并与之对齐，来执行配准部分观测对象的挑战性任务。在模拟和真实世界数据集上的实验表明，我们的方法改进了几个类别的未观察零件的重建。 et.al.|[2406.08176](http://arxiv.org/abs/2406.08176)|**[link](https://github.com/Taekbum/category-nerf-reconstruction-official)**|
|**2024-06-12**|**OpenObj: Open-Vocabulary Object-Level Neural Radiance Fields with Fine-Grained Understanding**|近年来，人们对由视觉语言模型（VLM）促进的开放词汇三维场景重建产生了浓厚的兴趣，VLM在开放集检索中展示了非凡的能力。然而，现有的方法面临一些局限性：它们要么专注于学习逐点特征，导致语义理解模糊，要么只处理对象级重建，从而忽略对象内部的复杂细节。为了应对这些挑战，我们引入了OpenObj，这是一种创新的方法，用于构建具有细粒度理解的开放词汇表对象级神经辐射场（NeRF）。从本质上讲，OpenObj建立了一个健壮的框架，用于在对象级别进行高效和严密的场景建模和理解。此外，我们将零件级特征融入神经领域，从而实现物体内部的细致入微的表示。这种方法捕获对象级实例，同时保持细粒度的理解。在多个数据集上的结果表明，OpenObj在零样本语义分割和检索任务中取得了优异的性能。此外，OpenObj支持多尺度的真实世界机器人任务，包括全局移动和局部操纵。 et.al.|[2406.08009](http://arxiv.org/abs/2406.08009)|**[link](https://github.com/BIT-DYN/OpenObj)**|
|**2024-06-11**|**Image Neural Field Diffusion Models**|扩散模型在对复杂数据分布建模方面表现出了令人印象深刻的能力，与GANs相比具有几个关键优势，例如稳定的训练、更好地覆盖训练分布的模式，以及在没有额外训练的情况下解决反问题的能力。然而，大多数扩散模型学习固定分辨率图像的分布。我们建议通过在图像神经场上训练扩散模型来学习连续图像的分布，该模型可以以任何分辨率渲染，并显示出其相对于固定分辨率模型的优势。为了实现这一点，一个关键的挑战是获得一个代表真实感图像神经场的潜在空间。受最近几项技术的启发，我们提出了一种简单有效的方法，但有一些关键的变化，使图像神经场具有真实感。我们的方法可以用于将现有的潜在扩散自动编码器转换为图像神经场自动编码器。我们证明，图像神经场扩散模型可以使用混合分辨率图像数据集进行训练，优于固定分辨率扩散模型和超分辨率模型，并且可以有效地解决不同尺度条件下的逆问题。 et.al.|[2406.07480](http://arxiv.org/abs/2406.07480)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

