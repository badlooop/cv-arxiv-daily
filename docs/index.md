---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.10.01
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-09-26**|**Neural Light Spheres for Implicit Image Stitching and View Synthesis**|全景拍摄具有挑战性，在手机屏幕上显示也具有挑战性。矛盾的是，全景仍然是现代移动相机应用程序的主要功能，但未得到充分利用。在这项工作中，我们用球形神经光场模型来解决这两个挑战，用于隐式全景图像拼接和重新渲染；能够适应深度视差、视图相关照明以及捕获过程中的局部场景运动和颜色变化。在测试期间，适应任意路径的全景视频捕获——垂直、水平、随机行走——这些神经光球共同估计相机路径和高分辨率场景重建，以产生环境的新型宽视场投影。我们的单层模型避免了昂贵的体积采样，并将场景分解为紧凑的视图相关光线偏移和颜色分量，每个场景的总模型大小为80 MB，并以1080p分辨率进行实时（50 FPS）渲染。我们展示了比传统图像拼接和辐射场方法更高的重建质量，对场景运动和非理想捕获设置的容忍度明显更高。 et.al.|[2409.17924](http://arxiv.org/abs/2409.17924)|null|
|**2024-09-24**|**GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization**|尽管存在各种视觉定位方法，如场景坐标和姿态回归，但这些方法往往难以满足高内存消耗或广泛的优化要求。为了应对这些挑战，我们利用新型视图合成的最新进展，特别是3D高斯散斑（3DGS），来增强定位。3DGS允许通过其空间特征对3D几何和场景外观进行紧凑编码。我们的方法利用了XFeat轻量级关键点检测和描述模型生成的密集描述图。我们建议将这些密集的关键点描述符提取到3DGS中，以提高模型的空间理解能力，从而通过2D-3D对应关系进行更准确的相机姿态预测。在估计初始姿态后，我们使用光度扭曲损失对其进行细化。对流行的室内和室外数据集进行基准测试表明，我们的方法超越了最先进的神经渲染姿势（NRP）方法，包括NeRFMatch和PNeRFLoc。 et.al.|[2409.16502](http://arxiv.org/abs/2409.16502)|**[link](https://github.com/haksorus/gsplatloc)**|
|**2024-09-24**|**Semantics-Controlled Gaussian Splatting for Outdoor Scene Reconstruction and Rendering in Virtual Reality**|高斯散点（GS）等3D渲染技术的进步允许在虚拟现实（VR）中进行新颖的视图合成和实时渲染。然而，GS创建的3D环境通常很难编辑。对于场景增强或合并3D资源，按类分割高斯分布是必不可少的。现有的分割方法通常仅限于某些类型的场景，例如“圆形”场景，以确定清晰的对象边界。然而，在非“循环”场景（如大型室外场景）中删除大型物体时，这种方法是无效的。我们提出了语义控制GS（SCGS），这是一种分段驱动的GS方法，能够在不受控制的自然环境中分离大型场景部分。SCGS允许对VR进行场景编辑和提取场景部分。此外，我们引入了一个具有挑战性的室外数据集，克服了“循环”设置。我们在数据集的视觉质量和3D-OVS数据集的分割质量方面都优于最先进的技术。我们进行了一项探索性用户研究，将360度视频、普通GS和VR中的SCGS与固定视点进行了比较。在我们随后的主要研究中，允许用户自由移动，评估普通GS和SCGS。我们的主要研究结果表明，参与者明显更喜欢SCGS而不是普通GS。我们总体上提出了一种创新的方法，在技术和用户体验方面都超越了最先进的水平。 et.al.|[2409.15959](http://arxiv.org/abs/2409.15959)|null|
|**2024-09-24**|**Disentangled Generation and Aggregation for Robust Radiance Fields**|近年来，基于三平面的辐射场的利用引起了人们的关注，因为它能够以高质量的表示和低计算成本有效地分离3D场景。该方法的一个关键要求是精确输入相机姿态。然而，由于三平面的局部更新特性，与之前的联合姿态NeRF优化类似的联合估计很容易导致局部最小值。为此，我们提出了解耦三平面生成模块，将全局特征上下文和平滑度引入三平面学习，从而减轻了局部更新引起的误差。然后，我们提出了解耦平面聚合来减轻相机姿态更新过程中常见的三平面特征聚合引起的纠缠。此外，我们引入了一种两阶段热启动训练策略，以减少由三平面生成器引起的隐式约束。定量和定性结果表明，我们提出的方法在具有噪声或未知相机姿态的新型视图合成中取得了最先进的性能，并实现了高效的优化收敛。项目页面：https://gaohchen.github.io/DiGARR/. et.al.|[2409.15715](http://arxiv.org/abs/2409.15715)|null|
|**2024-09-23**|**AgriNeRF: Neural Radiance Fields for Agriculture in Challenging Lighting Conditions**|神经辐射场（NeRF）在3D场景重建和新颖的视图合成方面显示出巨大的前景。在农业环境中，NeRF可以作为数字双胞胎，为农民提供有关水果检测的关键信息，用于产量估算和其他重要指标。然而，传统的NeRF对具有挑战性的照明条件（如低光、极亮的光和变化的照明）并不稳健。为了解决这些问题，这项工作利用了三种不同的传感器：RGB相机、事件相机和热像仪。我们的RGB场景重建显示，PSNR和SSIM分别提高了+2.06 dB和+8.3%。我们的交叉光谱场景重建使mAP50的下游水果检测提高了+43.0%，mAP50-95提高了+61.1%。额外传感器的集成带来了更强大和信息量更大的NeRF。我们证明，我们的多模态系统在各种树冠覆盖和一天中的不同时间产生了高质量的照片级逼真重建。这项工作的结果是开发了一种有弹性的NeRF，能够在明显退化的情况下表现良好，以及一种用于自动水果检测的学习交叉光谱表示。 et.al.|[2409.15487](http://arxiv.org/abs/2409.15487)|null|
|**2024-09-30**|**SpikeGS: Learning 3D Gaussian Fields from Continuous Spike Stream**|尖峰相机是一种专用的高速视觉传感器，与传统的帧相机相比，它具有高时间分辨率和高动态范围等优点。这些特征为相机在许多计算机视觉任务中提供了显著的优势。然而，基于尖峰相机的3D重建和新型视图合成的任务仍然不发达。尽管有从尖峰流中学习神经辐射场的现有方法，但它们要么在极其嘈杂、低质量的光照条件下缺乏鲁棒性，要么由于神经辐射场中使用的深度全连接神经网络和光线行进渲染策略，计算复杂度很高，难以恢复精细的纹理细节。相比之下，3DGS的最新进展通过将点云表示优化为高斯椭球体实现了高质量的实时渲染。在此基础上，我们介绍了SpikeGS，这是一种仅从尖峰流中学习3D高斯场的方法。我们设计了一个基于3DGS的可微分尖峰流渲染框架，结合了噪声嵌入和尖峰神经元。通过利用3DGS的多视图一致性和基于图块的多线程并行渲染机制，我们实现了高质量的实时渲染结果。此外，我们引入了一个尖峰渲染损失函数，该函数在不同的光照条件下具有通用性。我们的方法可以从移动尖峰相机捕获的连续尖峰流中重建具有精细纹理细节的视图合成结果，同时在极其嘈杂的低光场景中表现出很高的鲁棒性。在真实和合成数据集上的实验结果表明，我们的方法在渲染质量和速度方面超越了现有的方法。我们的代码将在https://github.com/520jz/SpikeGS. et.al.|[2409.15176](http://arxiv.org/abs/2409.15176)|**[link](https://github.com/520jz/spikegs)**|
|**2024-09-23**|**FusionRF: High-Fidelity Satellite Neural Radiance Fields from Multispectral and Panchromatic Acquisitions**|我们介绍了FusionRF，这是一种基于光学未处理卫星图像的新型神经渲染地形重建方法。虽然以前的方法依赖于外部泛色法来融合低分辨率多光谱图像和高分辨率全色图像，但FusionRF直接在没有先验知识的情况下基于光学未处理的采集进行重建。这是通过添加一个锐化内核来实现的，该内核对多光谱图像中的分辨率损失进行建模。此外，新颖的模态嵌入允许模型执行图像融合，这是新颖视图合成的瓶颈。我们在不同位置对WorldView-3卫星的多光谱和全色卫星图像进行了评估，FusionRF在未处理图像的深度重建、渲染清晰的训练和新颖的视图以及保留多光谱信息方面优于之前的最先进方法。 et.al.|[2409.15132](http://arxiv.org/abs/2409.15132)|null|
|**2024-09-23**|**AIM 2024 Sparse Neural Rendering Challenge: Methods and Results**|本文回顾了稀疏神经渲染的挑战，这是与ECCV 2024联合举办的图像处理进展（AIM）研讨会的一部分。本文重点介绍了比赛设置、提出的方法及其各自的结果。该挑战旨在从稀疏图像观测中生成不同场景的新颖相机视图合成。它由两条轨道组成，具有不同程度的稀疏性；Track 1中有3个视图（非常稀疏），Track 2中有9个视图（稀疏）。参与者被要求优化通过峰值信噪比（PSNR）度量测量的地面实况图像的客观保真度。对于这两个轨道，我们使用新引入的稀疏渲染（SpaRe）数据集和流行的DTU MVS数据集。在本次挑战中，5支队伍向Track 1提交了最终成绩，4支队伍向Track2提交了最终结果。提交的模型多种多样，突破了稀疏神经渲染的最新技术。本文详细描述了在挑战中开发的所有模型。 et.al.|[2409.15045](http://arxiv.org/abs/2409.15045)|null|
|**2024-09-23**|**AIM 2024 Sparse Neural Rendering Challenge: Dataset and Benchmark**|可微分和神经渲染的最新发展在各种2D和3D任务中取得了令人印象深刻的突破，例如新颖的视图合成、3D重建。通常，可微分渲染依赖于场景的密集视点覆盖，这样几何体就可以单独从外观观察中消除歧义。当只有少数输入视图可用时，会出现一些挑战，通常称为稀疏或少镜头神经渲染。由于这是一个约束不足的问题，大多数现有方法都引入了正则化的使用，以及各种学习和手工制作的先验。稀疏渲染文献中反复出现的一个问题是缺乏同质、最新的数据集和评估协议。虽然高分辨率数据集是密集重建文献中的标准，但稀疏渲染方法通常使用低分辨率图像进行评估。此外，不同手稿之间的数据分割不一致，测试地面真实图像通常是公开的，这可能会导致过度拟合。在这项工作中，我们提出了稀疏渲染（SpaRe）数据集和基准测试。我们引入了一个遵循DTU MVS数据集设置的新数据集。该数据集由97个基于合成高质量资产的新场景组成。每个场景最多有64个相机视图和7个照明配置，以1600x1200分辨率渲染。我们发布了82个场景的训练分割，以培养可推广的方法，并为验证和测试集提供了一个在线评估平台，其真实图像保持隐藏。我们提出了两种不同的稀疏配置（分别为3幅和9幅输入图像）。这为可重复评估提供了一个强大而方便的工具，并使研究人员能够轻松访问具有最先进绩效评分的公共排行榜。可用网址：https://sparebenchmark.github.io/ et.al.|[2409.15041](http://arxiv.org/abs/2409.15041)|null|
|**2024-09-22**|**MVPGS: Excavating Multi-view Priors for Gaussian Splatting from Sparse Input Views**|最近，神经辐射场（NeRF）的进步促进了少镜头新视图合成（NVS），这是3D视觉应用中的一个重大挑战。尽管多次尝试降低NeRF中的密集输入要求，但它仍然受到耗时的训练和渲染过程的困扰。最近，3D高斯散斑（3DGS）通过显式的基于点的表示实现了实时高质量的渲染。然而，与NeRF类似，由于缺乏约束，它往往会过度拟合训练视图。在本文中，我们提出了\textbf{MVPGS}，这是一种基于3D高斯散斑挖掘多视图先验的少镜头NVS方法。我们利用最近基于学习的多视图立体（MVS）来提高3DGS的几何初始化质量。为了减轻过拟合，我们提出了一种基于计算几何的前向扭曲方法，用于符合场景的额外外观约束。此外，我们为高斯参数引入了视图一致的几何约束，以促进适当的优化收敛，并利用单目深度正则化作为补偿。实验表明，该方法在实时渲染速度方面达到了最先进的性能。项目页面：https://zezeaaa.github.io/projects/MVPGS/ et.al.|[2409.14316](http://arxiv.org/abs/2409.14316)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-09-27**|**3DPX: Single Panoramic X-ray Analysis Guided by 3D Oral Structure Reconstruction**|全景X射线（PX）因其广泛的可用性和低成本而成为牙科实践中的一种流行方式。然而，作为3D结构的2D投影，PX会丢失解剖信息，与3D成像方式相比，PX诊断受到限制。已经探索了2D到3D重建方法，以合成2D PX中缺失的3D解剖信息，用于PX图像分析。然而，在利用这种3D合成重建方面存在挑战。首先，从2D图像推断3D深度仍然是一项具有挑战性的任务，精度有限。第二个挑战是2D PX与其3D合成对应物的联合分析，目的是最大限度地发挥2D-3D协同作用，同时最大限度地减少合成图像产生的误差。在这项研究中，我们提出了一种新的方法，称为3DPX-PX图像分析，以二维到三维重建为指导，以克服这些挑战。3DPX由两部分组成：（i）一个新颖的渐进重建网络，用于改进2D到3D重建；（ii）一个对比引导的双向多模态对齐模块，用于3D引导的2D PX分类和分割任务。重建网络逐步重建3D图像，在多个金字塔级别上对中间重建施加知识，并结合多层感知器来提高语义理解。下游网络通过特征对齐将重建图像作为PX分析的3D解剖指导，这增加了双向特征投影的2D-3D协同作用，并通过对比指导减少了潜在误差的影响。在涉及464项研究的两个口腔数据集上进行的广泛实验表明，3DPX在各种任务中表现优于最先进的方法，包括2D到3D重建、PX分类和病变分割。 et.al.|[2409.18701](http://arxiv.org/abs/2409.18701)|null|
|**2024-09-26**|**TFS-NeRF: Template-Free NeRF for Semantic 3D Reconstruction of Dynamic Scene**|尽管神经隐式模型在3D表面重建方面取得了进展，但处理具有任意刚性、非刚性或可变形实体的动态环境仍然具有挑战性。许多基于模板的方法是特定于实体的，专注于人类，而适用于这种动态场景的通用重建方法通常需要额外的输入，如深度或光流，或者依赖于预训练的图像特征来获得合理的结果。这些方法通常使用潜码来捕获逐帧变形。相比之下，一些无模板方法绕过了这些要求，采用传统的LBS（线性混合蒙皮）权重来详细表示可变形对象的运动，尽管它们涉及复杂的优化，导致训练时间过长。为此，作为补救措施，本文引入了TFS NeRF，这是一种无模板的3D语义NeRF，用于从稀疏或单视图RGB视频中捕获的动态场景，具有各种实体之间的交互功能，比其他基于LBS的方法更省时。我们的框架使用可逆神经网络（INN）进行LBS预测，简化了训练过程。通过解开多个实体的运动并优化每个实体的蒙皮权重，我们的方法有效地生成了准确的、语义上可分离的几何体。大量实验表明，与现有方法相比，我们的方法在复杂的交互中产生了可变形和不可变形对象的高质量重建，提高了训练效率。 et.al.|[2409.17459](http://arxiv.org/abs/2409.17459)|null|
|**2024-09-25**|**Generative Object Insertion in Gaussian Splatting with a Multi-View Diffusion Model**|生成新对象并将其插入到3D内容中是实现多功能场景再现的一种引人注目的方法。现有的方法依赖于SDS优化或单视图修复，往往难以产生高质量的结果。为了解决这个问题，我们提出了一种在高斯散斑表示的3D内容中插入对象的新方法。我们的方法引入了一个名为MVInpainter的多视图扩散模型，该模型基于预训练的稳定视频扩散模型构建，以促进视图一致的对象修复。在MVInpainter中，我们整合了一个基于ControlNet的条件注入模块，以实现受控和更可预测的多视图生成。在生成多视图修复结果后，我们进一步提出了一种掩模感知的3D重建技术，从这些稀疏的修复视图中改进高斯散斑重建。通过利用这些制造技术，我们的方法产生了不同的结果，确保了视图一致和和谐的插入，并产生了更好的物体质量。大量实验表明，我们的方法优于现有方法。 et.al.|[2409.16938](http://arxiv.org/abs/2409.16938)|**[link](https://github.com/jiutongbro/multiview_inpaint)**|
|**2024-09-25**|**Discriminative Anchor Learning for Efficient Multi-view Clustering**|多视图聚类旨在研究视图之间的互补信息并发现底层结构。为了解决现有方法相对较高的计算成本，最近提出了基于锚点的工作。即使具有可接受的聚类性能，这些方法也倾向于将来自多个视图的原始表示映射到基于原始数据集的固定共享图中。然而，大多数研究忽略了学习锚的判别特性，这破坏了所构建模型的表示能力。此外，通过简单地学习共享锚点图而不考虑视图特定锚点的质量，可以忽略跨视图锚点之间的互补信息。本文提出了用于多视图聚类的判别锚学习（DALMC）来处理上述问题。我们根据原始数据集学习区分视图特定的特征表示，并基于这些表示从不同视图构建锚点，从而提高了共享锚点图的质量。将判别特征学习和共识锚图构建集成到一个统一的框架中，相互改进，实现细化。通过正交约束学习来自多个视图的最优锚点和共识锚点图。我们给出了一个迭代算法来处理公式化问题。在不同数据集上的大量实验表明，与其他方法相比，我们的方法具有有效性和效率。 et.al.|[2409.16904](http://arxiv.org/abs/2409.16904)|null|
|**2024-09-25**|**Towards Unified 3D Hair Reconstruction from Single-View Portraits**|由于不同发型之间存在广泛的形状变化，单视图3D头发重建具有挑战性。目前最先进的方法专门用于恢复未编织的3D头发，并且经常将编织风格作为失败案例，因为无论是基于规则还是基于数据，都很难定义复杂发型的先验。我们提出了一种新的策略，通过统一的管道实现各种头发类型的单视图3D重建。为了实现这一目标，我们首先收集了一个大规模的合成多视图头发数据集SynMvHair，其中包含编织和非编织风格的各种3D头发，并学习了两个专门针对头发的扩散先验。然后，我们使用两个专门设计的模块（即视图和像素高斯细化）从先验中优化基于3D高斯的头发。我们的实验表明，通过统一的方法从单视图图像重建编织和非编织的3D头发是可能的，我们的方法在恢复复杂发型方面达到了最先进的性能。值得一提的是，我们的方法对真实图像显示出良好的泛化能力，尽管它从合成数据中学习头发先验。 et.al.|[2409.16863](http://arxiv.org/abs/2409.16863)|null|
|**2024-09-25**|**3DDX: Bone Surface Reconstruction from a Single Standard-Geometry Radiograph via Dual-Face Depth Estimation**|射线照相因其经济实惠和低辐射暴露而广泛应用于骨科。从单个射线照片进行3D重建，即所谓的2D-3D重建，提供了各种临床应用的可能性，但实现临床可行的准确性和计算效率仍然是一个未解决的挑战。与计算机视觉的其他领域不同，X射线成像的独特特性，如射线穿透和固定几何形状，尚未得到充分利用。我们提出了一种新方法，可以同时学习从X射线图像中导出的多个深度图（多个骨骼的前表面和后表面），以进行计算机断层扫描配准。该方法不仅利用了X射线成像的固定几何特性，而且提高了整个表面重建的精度。我们的研究涉及600张CT和2651张X射线图像（每位患者4至5张摆位X射线图像），证明了我们的方法优于传统方法，表面重建误差从4.78毫米减少到1.96毫米。这一显著的精度提高和计算效率的提高表明了我们的方法在临床应用中的潜力。 et.al.|[2409.16702](http://arxiv.org/abs/2409.16702)|null|
|**2024-09-24**|**Frequency-based View Selection in Gaussian Splatting Reconstruction**|三维重建是机器人感知中的一个基本问题。我们研究了主动视图选择的问题，以尽可能少的输入图像进行3D高斯散斑重建。尽管3D高斯散斑在图像渲染和3D重建方面取得了重大进展，但重建的质量受到2D图像选择和通过运动结构（SfM）算法估计相机姿态的强烈影响。目前选择直接依赖于遮挡、深度模糊或神经网络预测的不确定性的视图的方法不足以处理这个问题，并且很难推广到新的场景。通过在频域中对潜在视图进行排序，我们能够在没有地面实况数据的情况下有效地估计新视图的潜在信息增益。通过克服当前对模型架构和效率的限制，我们的方法在视图选择方面取得了最先进的结果，展示了其高效基于图像的3D重建的潜力。 et.al.|[2409.16470](http://arxiv.org/abs/2409.16470)|null|
|**2024-09-24**|**Underground Mapping and Localization Based on Ground-Penetrating Radar**|近年来，基于深度神经网络的三维物体重建越来越受到人们的关注。然而，对地下物体进行3D重建以生成点云图仍然是一个挑战。探地雷达（GPR）是探测和定位植物根系和管道等地下物体最强大、使用最广泛的工具之一，具有成本效益和不断发展的技术。本文介绍了一种基于深度卷积神经网络的抛物线信号检测网络，该网络利用探地雷达传感器的B扫描图像。检测到的关键点可以帮助精确拟合抛物线，用于将原始GPR B扫描图像解释为对象模型的横截面。此外，设计了一个多任务点云网络，可以同时执行点云分割和完成，填充稀疏点云地图。对于未知位置，GPR A扫描数据可用于匹配所构建地图中的相应A扫描数据，精确定位位置以验证模型构建地图的准确性。实验结果证明了我们方法的有效性。 et.al.|[2409.16446](http://arxiv.org/abs/2409.16446)|null|
|**2024-09-24**|**Age of Gossip in Networks with Multiple Views of a Source**|我们考虑网络中的信息版本年龄（AoI），其中节点子集充当感测节点，对通常可以遵循连续分布的源进行采样。源的任何样本都构成了信息的新版本，信息的版本年龄是根据整个网络可用信息的最新版本定义的。我们推导出了节点不同子集之间的平均版本AoI的递归表达式，可用于评估包括任何单个节点在内的任何节点子集的平均版本AoI。我们推导了各种拓扑结构（包括线、环和全连接网络）在网络任何单个节点上的平均AoI的渐近行为。Yates关于网络版本年龄的现有技术结果[ISIT'21]在我们的推导中可以被解释为具有单一源视图的网络，例如通过速率为 $\lambda_{00}$的泊松过程。我们的结果表明，通过分割相同的速率$\lambda_{00}$，将源的单个视图替换为跨多个节点的分布式感知，平均版本AoI性能没有损失。特别地，我们证明，对于全连接和环形网络，平均AoI分别渐近地缩放为$O（\log（n））$和$O（\sqrt{n}）$。更有趣的是，我们表明，对于环形网络，如果感测节点的数量仅随$O（\sqrt{n}）$而不是需要$O（n）$的先前已知结果缩放，则分布式感测在平均AoI上仍然可以实现相同的$O（$sqrt{n}）$渐近性能。我们的结果表明，只要连续非感测节点的最大数量也缩放为$O（\sqrt{n}）$ ，就可以任意选择感测节点。 et.al.|[2409.16285](http://arxiv.org/abs/2409.16285)|null|
|**2024-09-24**|**AIR-Embodied: An Efficient Active 3DGS-based Interaction and Reconstruction Framework with Embodied Large Language Model**|3D重建和神经渲染的最新进展增强了高质量数字资产的创建，但现有的方法很难在不同的对象形状、纹理和遮挡之间进行推广。虽然次优视图（NBV）规划和基于学习的方法提供了解决方案，但它们往往受到预定义标准的限制，无法用人类的常识来管理遮挡。为了解决这些问题，我们提出了AIR Embodied，这是一种新的框架，将嵌入的AI代理与大规模预训练的多模态语言模型集成在一起，以改进主动3DGS重建。AIR Embodied采用了一个三阶段过程：通过多模态提示了解当前的重建状态，通过视点选择和交互动作规划任务，并采用闭环推理来确保准确执行。代理根据计划结果和实际结果之间的差异动态改进其操作。在虚拟和现实世界环境中的实验评估表明，AIR Embodied显著提高了重建效率和质量，为主动3D重建中的挑战提供了一个稳健的解决方案。 et.al.|[2409.16019](http://arxiv.org/abs/2409.16019)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-09-27**|**PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation**|我们提出了PhysGen，这是一种新颖的图像到视频生成方法，它将单个图像和输入条件（例如，施加到图像中对象的力和扭矩）转换为生成逼真、物理上合理且时间上一致的视频。我们的关键见解是将基于模型的物理模拟与数据驱动的视频生成过程相结合，实现合理的图像空间动态。我们系统的核心是三个核心组件：（i）图像理解模块，可有效捕获图像的几何形状、材料和物理参数；（ii）图像空间动力学仿真模型，其利用刚体物理和推断参数来模拟真实行为；以及（iii）基于图像的渲染和细化模块，其利用生成视频扩散来生成以模拟运动为特征的逼真视频片段。生成的视频在物理和外观上都很逼真，甚至可以精确控制，通过定量比较和全面的用户研究，展示了优于现有数据驱动的图像到视频生成工作的卓越结果。PhysGen生成的视频可用于各种下游应用程序，例如将图像转换为逼真的动画，或允许用户与图像交互并创建各种动态。项目页面：https://stevenlsw.github.io/physgen/ et.al.|[2409.18964](http://arxiv.org/abs/2409.18964)|**[link](https://github.com/stevenlsw/physgen)**|
|**2024-09-27**|**$O(d/T)$ Convergence Theory for Diffusion Probabilistic Models under Minimal Assumptions**|基于分数的扩散模型通过学习反转将数据从目标分布扰动为噪声的扩散过程来生成新数据，在各种生成任务中取得了显著成功。尽管它们具有优越的经验性能，但现有的理论保证往往受到严格假设或次优收敛率的限制。本文在最小假设下，为流行的基于SDE的采样器建立了一个快速收敛理论。我们的分析表明，如果对分数函数进行$\ell_{2}$精确估计，目标分布和生成分布之间的总变化距离的上限为$O（d/T）$（忽略对数因子），其中$d$是数据维度，$T$ 是步数。这一结果适用于任何具有有限一阶矩的目标分布。据我们所知，这改进了基于SDE的采样器和另一种基于ODE的采样器的现有收敛理论，同时对目标数据分布和得分估计施加了最小的假设。这是通过一组新的分析工具实现的，这些工具提供了错误在反向过程的每个步骤中如何传播的细粒度特征。 et.al.|[2409.18959](http://arxiv.org/abs/2409.18959)|null|
|**2024-09-27**|**ReviveDiff: A Universal Diffusion Model for Restoring Images in Adverse Weather Conditions**|在具有挑战性的环境中拍摄的图像，如夜间、雾天、雨天和水下，往往会严重退化，导致视觉质量大幅下降。有效恢复这些退化的图像对于后续的视觉任务至关重要。虽然许多现有的方法已经成功地为单个任务引入了特定的先验，但这些量身定制的解决方案限制了它们对其他退化的适用性。在这项工作中，我们提出了一种通用的网络架构，称为“ReviveDiff”，它可以解决各种退化问题，并通过提高和恢复图像的质量来恢复图像的活力。我们的方法受到以下观察的启发，即与运动或电子问题引起的退化不同，不利条件下的质量退化主要源于自然介质（如雾、水和低亮度），这些介质通常会保留物体的原始结构。为了恢复此类图像的质量，我们利用扩散模型的最新进展，开发了ReviveDiff，从宏观和微观层面恢复图像质量，包括决定图像质量的一些关键因素，如锐度、失真、噪声水平、动态范围和色彩准确度。我们在七个基准数据集上对ReviveDiff进行了严格评估，涵盖了五种退化条件：雨天、水下、低光、烟雾和夜间雾霾。我们的实验结果表明，ReviveDiff在定量和视觉上都优于最先进的方法。 et.al.|[2409.18932](http://arxiv.org/abs/2409.18932)|null|
|**2024-09-27**|**AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**|模拟患者系统在现代医学教育和研究中发挥着至关重要的作用，提供安全、综合的学习环境，并实现临床决策模拟。大型语言模型（LLM）可以通过高保真和低成本复制医疗条件和医患互动来推进模拟患者系统。然而，确保这些系统的有效性和可信度仍然是一个挑战，因为它们需要一个庞大、多样化和精确的患者知识库，以及向用户传播强大而稳定的知识。在这里，我们开发了AIPatient，这是一个先进的模拟患者系统，以AIPatient知识图（AIPatient KG）为输入，推理检索增强生成（Reasoning RAG）代理工作流为生成骨干。AIPatient KG从重症监护医疗信息集市（MIMIC）-III数据库中的电子健康记录（EHR）中采样数据，产生了1495名具有高知识库有效性的临床多样性和相关队列（F1 0.89）。Reasoning RAG利用了六个LLM驱动的代理，涵盖了检索、KG查询生成、抽象、检查器、重写和摘要等任务。该代理框架在基于EHR的医疗问答（QA）中的总体准确率达到94.15%，优于不使用代理或仅使用部分代理集成的基准。我们的系统还具有高可读性（Flesch-Reading Ease中位数77.23；Flesch-Kincaid中位数5.6）、鲁棒性（方差分析F值0.6126，p<0.1）和稳定性（方差分析F值0.782，p<0.1）。AIPatient系统的良好性能突显了其支持广泛应用的潜力，包括医学教育、模型评估和系统集成。 et.al.|[2409.18924](http://arxiv.org/abs/2409.18924)|null|
|**2024-09-27**|**Unsupervised Low-light Image Enhancement with Lookup Tables and Diffusion Priors**|低光图像增强（LIE）旨在精确有效地恢复在恶劣光照环境中退化的图像。最近先进的LIE技术正在使用深度神经网络，这需要大量的低正常光图像对、网络参数和计算资源。因此，它们的实用性是有限的。在这项工作中，我们设计了一种基于扩散先验和查找表（DPLUT）的新型无监督LIE框架，以实现高效的低光图像恢复。所提出的方法包括两个关键组成部分：光调节查找表（LLUT）和噪声抑制查找表（NLUT）。LLUT使用一组无监督损失进行优化。它旨在预测特定图像动态范围调整的逐像素曲线参数。NLUT旨在消除光线变亮后放大的噪声。由于扩散模型对噪声敏感，因此引入了扩散先验来实现高性能的噪声抑制。大量实验表明，我们的方法在视觉质量和效率方面优于最先进的方法。 et.al.|[2409.18899](http://arxiv.org/abs/2409.18899)|null|
|**2024-09-27**|**Detecting Dataset Abuse in Fine-Tuning Stable Diffusion Models for Text-to-Image Synthesis**|文本到图像合成在生成逼真和风格化的图像方面已经变得非常流行，通常需要使用特定领域的数据集对生成模型进行微调，以完成专门的任务。然而，这些有价值的数据集面临着未经授权使用和未经批准共享的风险，损害了所有者的权利。在本文中，我们解决了在文本到图像合成的稳定扩散模型微调过程中数据集滥用的问题。我们提出了一种数据集水印框架，旨在检测未经授权的使用和跟踪数据泄漏。该框架在多个水印方案中采用了两种关键策略，对大规模数据集授权是有效的。大量的实验证明了该框架的有效性，对数据集的影响最小（只有2%的数据需要修改以获得高检测精度），并且能够跟踪数据泄漏。我们的研究结果还突出了该框架的鲁棒性和可转移性，证明了它在检测数据集滥用方面的实用性。 et.al.|[2409.18897](http://arxiv.org/abs/2409.18897)|null|
|**2024-09-27**|**Explainable Artifacts for Synthetic Western Blot Source Attribution**|人工智能的最新进展使生成模型能够生成与原始图像无法区分的合成科学图像，即使是习惯于处理此类内容的专家科学家也面临着挑战。当被称为造纸厂的组织利用时，这些技术会系统地生成欺诈性文章，从而大大助长关于无根据科学的错误信息的传播，可能会破坏对科学研究的信任。虽然之前的研究已经探索了黑盒解决方案，如卷积神经网络，用于识别合成内容，但只有一些研究解决了跨不同模型进行泛化的挑战，并提供了对合成图像中为检测过程提供信息的伪影的洞察。本研究旨在识别由最先进的生成模型（如生成对抗网络和扩散模型）生成的可解释伪影，并利用它们进行开放集识别和源归因（即指向创建图像的模型）。 et.al.|[2409.18881](http://arxiv.org/abs/2409.18881)|null|
|**2024-09-27**|**CemiFace: Center-based Semi-hard Synthetic Face Generation for Face Recognition**|隐私问题是开发人脸识别技术的主要关注点。尽管合成人脸图像可以部分减轻潜在的法律风险，同时保持有效的人脸识别（FR）性能，但由于这些合成样本的判别质量不足，由现有生成方法合成的人脸图像训练的FR模型经常出现性能下降的问题。在本文中，我们系统地研究了什么有助于实体人脸识别模型训练，并揭示了与身份中心具有一定程度相似性的人脸图像在训练的FR模型的性能方面表现出极大的有效性。受此启发，我们提出了一种新的基于扩散的方法（即基于中心的半硬合成人脸生成（CemiFace）），该方法生成与受试者中心具有不同相似度的人脸样本，从而可以生成包含有效判别样本的人脸数据集，用于训练人脸识别。实验结果表明，在适度相似的情况下，与前一代方法相比，在生成的数据集上进行训练可以产生具有竞争力的性能。 et.al.|[2409.18876](http://arxiv.org/abs/2409.18876)|null|
|**2024-09-27**|**Emu3: Next-Token Prediction is All You Need**|虽然nexttoken预测被认为是通往通用人工智能的一条很有前途的道路，但它一直难以在多模式任务中脱颖而出，这些任务仍然由扩散模型（例如，稳定扩散）和组合方法（例如，CLIP与LLM相结合）主导。在本文中，我们介绍了Emu3，这是一套新的最先进的多模态模型，仅使用下一个标记预测进行训练。通过将图像、文本和视频标记到一个离散的空间中，我们在多模态序列的混合上从头开始训练一个转换器。Emu3在生成和感知任务方面都优于几个成熟的任务特定模型，超越了SDXL和LLaVA-1.6等旗舰模型，同时消除了对扩散或组合架构的需求。Emu3还能够通过预测视频序列中的下一个令牌来生成高保真视频。我们通过聚焦于一个单一的焦点来简化复杂的多模态模型设计：标记，在训练和推理过程中释放出巨大的扩展潜力。我们的研究结果表明，下一个标记预测是构建超越语言的通用多模态智能的一条有前景的道路。我们开源关键技术和模型，以支持这一方向的进一步研究。 et.al.|[2409.18869](http://arxiv.org/abs/2409.18869)|null|
|**2024-09-27**|**MECG-E: Mamba-based ECG Enhancer for Baseline Wander Removal**|心电图（ECG）是诊断心血管疾病的重要非侵入性方法。然而，心电图信号容易受到噪声污染，如电干扰或信号漂移，这降低了诊断的准确性。已经提出了各种心电图去噪方法，但大多数现有方法在非常嘈杂的条件下会产生次优性能，或者在推理过程中需要几个步骤，导致在线处理过程中的延迟。在这篇论文中，我们提出了一种新的心电图去噪模型，即基于Mamba的心电图增强器（MECG-E），它利用了以快速推理和出色的非线性映射能力而闻名的Mamba架构。实验结果表明，在不同的噪声条件下，MECG-E在多个指标上超越了几个众所周知的现有模型。此外，MECG-E比最先进的基于扩散的心电图去噪器需要更少的推理时间，证明了该模型的功能和效率。 et.al.|[2409.18828](http://arxiv.org/abs/2409.18828)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-09-25**|**TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans**|我们介绍了一种新的框架，该框架从单眼视频中学习全身说话的人的动态神经辐射场（NeRF）。之前的工作只代表身体姿势或面部。然而，人类通过全身进行交流，结合身体姿势、手势和面部表情。在这项工作中，我们提出了TalkinNeRF，这是一个基于NeRF的统一网络，代表了整体4D人体运动。给定一个受试者的单眼视频，我们学习身体、面部和手的相应模块，这些模块结合在一起生成最终结果。为了捕捉复杂的手指关节，我们学习了手的额外变形场。我们的多身份表示能够同时训练多个科目，以及在完全看不见的姿势下进行强大的动画。只要输入一段短视频，它也可以推广到新的身份。我们展示了最先进的性能，用于为全身说话的人类制作动画，具有精细的手部发音和面部表情。 et.al.|[2409.16666](http://arxiv.org/abs/2409.16666)|null|
|**2024-09-24**|**Generative 3D Cardiac Shape Modelling for In-Silico Trials**|我们提出了一种深度学习方法，基于将形状表示为神经有符号距离场的零级集，对合成主动脉形状进行建模和生成，该方法受一系列可训练的嵌入向量的约束，并对每个形状的几何特征进行编码。通过使神经场在采样表面点上消失并强制其空间梯度具有单位范数，在从CT图像重建的主动脉根部网格数据集上训练网络。实证结果表明，我们的模型可以高保真地表示主动脉形状。此外，通过从学习到的嵌入向量中采样，我们可以生成类似于真实患者解剖结构的新形状，可用于计算机模拟试验。 et.al.|[2409.16058](http://arxiv.org/abs/2409.16058)|null|
|**2024-09-21**|**MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors**|由于缺乏几何指导和不完美的视图相关2D先验，从单眼图像中精确重建密集和语义注释的3D网格仍然是一项具有挑战性的任务。尽管我们已经见证了隐式神经场景表示的最新进展，能够简单地从多视图图像中进行精确的2D渲染，但很少有研究仅使用单眼先验来解决3D场景理解问题。在本文中，我们提出了MOSE，这是一种神经场语义重建方法，可以将推断的图像级噪声先验提升到3D，在3D和2D空间中产生精确的语义和几何。我们方法的关键动机是利用通用类不可知的分段掩码作为指导，在训练过程中促进渲染语义的局部一致性。在语义的帮助下，我们进一步将平滑正则化应用于无纹理区域，以获得更好的几何质量，从而实现几何和语义的互惠互利。在ScanNet数据集上的实验表明，我们的MOSE在3D语义分割、2D语义分割和3D表面重建任务的所有指标上都优于相关基线。 et.al.|[2409.14019](http://arxiv.org/abs/2409.14019)|null|
|**2024-09-17**|**SplatFields: Neural Gaussian Splats for Sparse 3D and 4D Reconstruction**|从多视图图像中数字化3D静态场景和4D动态事件长期以来一直是计算机视觉和图形学领域的一个挑战。最近，3D高斯散斑（3DGS）已经成为一种实用且可扩展的重建方法，由于其令人印象深刻的重建质量、实时渲染能力以及与广泛使用的可视化工具的兼容性而越来越受欢迎。然而，该方法需要大量的输入视图来实现高质量的场景重建，这引入了一个重大的实际瓶颈。在捕捉动态场景时，这一挑战尤为严峻，因为部署广泛的相机阵列的成本可能高得令人望而却步。在这项工作中，我们发现斑点特征缺乏空间自相关性是导致3DGS技术在稀疏重建环境中性能不佳的因素之一。为了解决这个问题，我们提出了一种优化策略，通过将splat特征建模为相应隐式神经场的输出，有效地正则化splat特征。这导致在各种场景中重建质量的一致提高。我们的方法有效地处理了静态和动态情况，这在不同设置和场景复杂性的广泛测试中得到了证明。 et.al.|[2409.11211](http://arxiv.org/abs/2409.11211)|null|
|**2024-09-17**|**Neural Fields for Adaptive Photoacoustic Computed Tomography**|光声计算机断层扫描（PACT）是一种具有广泛医学应用的非侵入性成像技术。传统的PACT图像重建算法受到组织中声速不均匀（SOS）引起的波前失真的影响，导致图像质量下降。考虑到这些影响可以提高图像质量，但测量SOS分布的实验成本很高。另一种方法是仅使用PA信号对初始压力图像和SOS进行联合重建。现有的关节重建方法存在局限性：计算成本高，无法直接恢复SOS，以及依赖于不准确的简化假设。隐式神经表示或神经场是计算机视觉中的一种新兴技术，用于通过基于坐标的神经网络学习物理场的有效和连续表示。在这项工作中，我们介绍了NF-APACT，这是一种高效的自监督框架，利用神经场来估计SOS，以实现准确和鲁棒的多通道解卷积。我们的方法比现有方法更快、更准确地消除了SOS像差。我们在一个新的数值体模以及实验收集的体模和体内数据上证明了我们的方法的成功。我们的代码和数字幻影可在https://github.com/Lukeli0425/NF-APACT. et.al.|[2409.10876](http://arxiv.org/abs/2409.10876)|null|
|**2024-09-09**|**Lagrangian Hashing for Compressed Neural Field Representations**|我们提出了拉格朗日散列，这是一种神经场的表示，结合了依赖于欧拉网格（即~InstantNGP）的快速训练NeRF方法的特征，以及使用配备有特征的点作为表示信息的方法（例如3D高斯散点或PointNeRF）。我们通过将基于点的表示合并到InstantNGP表示的分层哈希表的高分辨率层中来实现这一点。由于我们的点具有影响域，我们的表示可以被解释为哈希表中存储的高斯混合。我们提出的损失鼓励我们的高斯人向需要更多代表预算才能充分代表的地区移动。我们的主要发现是，我们的表示允许使用更紧凑的表示来重建信号，而不会影响质量。 et.al.|[2409.05334](http://arxiv.org/abs/2409.05334)|null|
|**2024-09-08**|**Exploring spectropolarimetric inversions using neural fields. Solar chromospheric magnetic field under the weak-field approximation**|全斯托克斯偏振数据集来源于狭缝光谱仪或窄带滤光片图，如今已被常规采集。随着二维光谱偏振仪和允许长时间高质量观测序列的观测技术的出现，数据速率正在增加。在光谱偏振反演中，显然需要通过利用推断物理量的时空相干性来超越传统的逐像素策略。我们探索了神经网络作为时间和空间（也称为神经场）上物理量的连续表示的潜力，用于光谱极化反演。我们已经实现并测试了一个神经场，以在弱场近似（WFA）下执行磁场矢量的推理（也称为物理知情神经网络的方法）。通过使用神经场来描述磁场矢量，我们可以通过假设物理量是坐标的连续函数来在空间和时间域中正则化解。我们研究了Ca II 8542 A谱线的合成和真实观测结果。我们还探讨了其他显式正则化的影响，例如使用外推磁场的信息或色球原纤维的取向。与传统的逐像素反演相比，神经场方法提高了磁场矢量重建的保真度，特别是横向分量。这种隐式正则化是一种提高观测值有效信噪比的方法。虽然它比逐像素WFA估计慢，但这种方法通过减少自由参数的数量并在解决方案中引入时空约束，显示出深度分层反演的巨大潜力。 et.al.|[2409.05156](http://arxiv.org/abs/2409.05156)|**[link](https://github.com/cdiazbas/neural_wfa)**|
|**2024-09-04**|**MDNF: Multi-Diffusion-Nets for Neural Fields on Meshes**|我们提出了一种在三角形网格上表示神经场的新框架，该框架在空间和频率域上都是多分辨率的。受神经傅里叶滤波器组（NFFB）的启发，我们的架构通过将更精细的空间分辨率级别与更高的频带相关联来分解空间和频率域，而将更粗糙的分辨率映射到较低的频率。为了实现几何感知的空间分解，我们利用了多个扩散网络组件，每个组件都与不同的空间分辨率级别相关联。随后，我们应用傅里叶特征映射来鼓励更精细的分辨率水平与更高的频率相关联。最终信号是使用正弦激活的MLP以小波激励的方式组成的，将高频信号聚集在低频信号之上。我们的架构在学习复杂神经场方面具有很高的精度，并且对目标场的不连续性、指数尺度变化和网格修改具有鲁棒性。我们通过将我们的方法应用于不同的神经领域，如合成RGB函数、UV纹理坐标和顶点法线，展示了其有效性，并说明了不同的挑战。为了验证我们的方法，我们将其性能与两种替代方案进行了比较，展示了我们的多分辨率架构的优势。 et.al.|[2409.03034](http://arxiv.org/abs/2409.03034)|null|
|**2024-09-03**|**GraspSplats: Efficient Manipulation with 3D Feature Splatting**|机器人对物体部件进行高效和零样本抓取的能力对于实际应用至关重要，并且随着视觉语言模型（VLM）的最新进展而变得普遍。为了弥合二维到三维表示的差距以支持这种能力，现有的方法依赖于神经场（NeRF），通过可微渲染或基于点的投影方法。然而，我们证明了NeRF由于其隐含性而不适合场景变化，并且基于点的方法对于没有基于渲染的优化的零件定位是不准确的。为了修正这些问题，我们提出了“把握辉煌”。使用深度监督和一种新的参考特征计算方法，GraspSplats在60秒内生成高质量的场景表示。我们进一步验证了基于高斯表示法的优势，表明GraspSplats中的显式和优化几何足以原生支持（1）实时抓取采样和（2）使用点跟踪器进行动态和铰接对象操作。通过在Franka机器人上进行的广泛实验，我们证明了在不同的任务设置下，GraspSplats的表现明显优于现有的方法。特别是，GraspSplats的性能优于基于NeRF的方法，如F3RM和LERF-TOGO，以及2D检测方法。 et.al.|[2409.02084](http://arxiv.org/abs/2409.02084)|null|
|**2024-08-23**|**S4D: Streaming 4D Real-World Reconstruction with Gaussians and 3D Control Points**|最近，使用高斯分布的动态场景重建引起了越来越多的兴趣。主流方法通常采用全局变形场来扭曲规范空间中的3D场景。然而，隐式神经场固有的低频特性往往导致复杂运动的无效表示。此外，它们的结构刚性会阻碍对不同分辨率和持续时间的场景的适应。为了克服这些挑战，我们引入了一种利用离散3D控制点的新方法。该方法对局部射线进行物理建模，并建立一个运动解耦坐标系，该坐标系有效地将传统图形与可学习的流水线相结合，以实现鲁棒且高效的局部6自由度（6-DoF）运动表示。此外，我们还开发了一个广义框架，将我们的控制点与高斯算子结合起来。从初始3D重建开始，我们的工作流程将流式4D真实世界重建分解为四个独立的子模块：3D分割、3D控制点生成、对象运动操纵和残差补偿。我们的实验表明，该方法在Neu3DV和CMU全景数据集上的表现优于现有的最先进的4D高斯散斑技术。我们的方法还显著加速了训练，在单个NVIDIA 4070 GPU上，每帧只需2秒即可优化我们的3D控制点。 et.al.|[2408.13036](http://arxiv.org/abs/2408.13036)|**[link](https://github.com/hebing-sjtu/S4D)**|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

