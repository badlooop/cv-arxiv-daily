---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.11.14
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-11-12**|**Novel View Synthesis with Pixel-Space Diffusion Models**|从单个输入图像合成新视图是一项具有挑战性的任务。传统上，这项任务是通过估计场景深度、扭曲和修复来完成的，机器学习模型支持部分管道。最近，生成模型越来越多地用于新颖视图合成（NVS），通常涵盖整个端到端系统。在这项工作中，我们采用了一种现代扩散模型架构，用于像素空间中的端到端NVS，其性能大大优于先前最先进的（SOTA）技术。我们探索了将几何信息编码到网络中的不同方法。我们的实验表明，虽然这些方法可以提高性能，但与使用改进的生成模型相比，它们的影响很小。此外，我们引入了一种新的NVS训练方案，该方案利用了单视图数据集，利用了它们与多视图数据集相比的相对丰富性。这提高了对具有域外内容的场景的泛化能力。 et.al.|[2411.07765](http://arxiv.org/abs/2411.07765)|null|
|**2024-11-13**|**Projecting Gaussian Ellipsoids While Avoiding Affine Projection Approximation**|最近，3D高斯散斑以其实时渲染速度和最先进的渲染质量主导了新颖的视图合成。然而，在渲染过程中，使用投影变换的仿射近似的雅可比矩阵会导致不可避免的误差，从而导致最终渲染图像中的模糊、伪影和缺乏场景一致性。为了解决这个问题，我们引入了一种基于椭球体的投影方法来计算高斯椭球体在图像平面上的投影，这是3D高斯散斑的原始方法。由于我们提出的基于椭球体的投影方法无法处理内部有相机原点或相机空间中位于 $z=0$ 平面以下的高斯椭球体，我们设计了一种预滤波策略。在多个广泛采用的基准数据集上的实验表明，使用我们的基于椭球体的投影方法可以提高3D高斯散斑及其扩展的渲染质量。 et.al.|[2411.07579](http://arxiv.org/abs/2411.07579)|null|
|**2024-11-11**|**A Hierarchical Compression Technique for 3D Gaussian Splatting Compression**|3D高斯散斑（GS）在新颖的视图合成中表现出优异的渲染质量和生成速度。然而，大量的数据量给存储和传输带来了挑战，使3D GS压缩成为一项必不可少的技术。当前的3D GS压缩研究主要集中在开发更紧凑的场景表示，例如将显式的3D GS数据转换为隐式形式。相比之下，GS数据本身的压缩几乎并没有得到探索。为了解决这一差距，我们提出了一种分层GS压缩（HGSC）技术。最初，我们根据从全局和局部重要性中得出的重要性得分来修剪不重要的高斯分布，有效地减少了冗余，同时保持了视觉质量。八叉树结构用于压缩3D位置。基于3D GS八叉树，我们采用KD树将3D GS划分为多个块，实现了一种分层属性压缩策略。我们应用最远点采样来选择每个块内的锚基元，并将其他锚基元作为具有不同细节级别（LoD）的非锚基元。锚基元用作跨不同LoD预测非锚基元的参考点，以减少空间冗余。对于锚基元，我们使用区域自适应分层变换来实现各种属性的近无损压缩。对于非锚基元，每个基元都是基于k个最近的锚基元进行预测的。为了进一步最小化预测误差，将重建的LoD和锚基元组合在一起，形成新的锚基元，以预测下一个LoD。与小型场景数据集上最先进的压缩方法相比，我们的方法显著实现了卓越的压缩质量，数据大小大幅减少了4.5倍以上。 et.al.|[2411.06976](http://arxiv.org/abs/2411.06976)|null|
|**2024-11-10**|**Adaptive and Temporally Consistent Gaussian Surfels for Multi-view Dynamic Reconstruction**|3D高斯散点最近在动态场景的新颖视图合成和静态场景的几何重建方面取得了显著成功。在这些进步的基础上，通过全局优化整个序列，开发了用于动态表面重建的早期方法。然而，重建具有显著拓扑变化、出现或消失的物体以及快速运动的动态场景仍然是一个巨大的挑战，特别是对于长序列。为了解决这些问题，我们提出了AT-GS，这是一种通过每帧增量优化从多视图视频中重建高质量动态曲面的新方法。为了避免跨帧的局部最小值，我们引入了一种统一的自适应梯度感知致密化策略，该策略整合了传统克隆和分裂技术的优势。此外，我们通过确保连续帧中曲率图的一致性来减少动态曲面中的时间抖动。我们的方法在动态表面重建中实现了卓越的精度和时间相干性，即使在复杂和具有挑战性的场景中也能提供高保真的时空新颖视图合成。对不同多视图视频数据集的广泛实验证明了我们的方法的有效性，显示出比基线方法明显的优势。项目页面：\url{https://fraunhoferhhi.github.io/AT-GS} et.al.|[2411.06602](http://arxiv.org/abs/2411.06602)|null|
|**2024-11-12**|**SplatFormer: Point Transformer for Robust 3D Gaussian Splatting**|3D高斯散斑（3DGS）最近改变了真实感重建，实现了高视觉保真度和实时性能。然而，当测试视图偏离训练期间使用的相机角度时，渲染质量会显著下降，这对沉浸式自由视点渲染和导航的应用程序构成了重大挑战。在这项工作中，我们对3DGS和相关的新型视图合成方法在非分布（OOD）测试相机场景下进行了全面评估。通过使用合成和真实世界的数据集创建不同的测试用例，我们证明了大多数现有的方法，包括那些结合了各种正则化技术和数据驱动先验的方法，都难以有效地推广到面向对象的视图。为了解决这一局限性，我们引入了SplatFormer，这是第一个专门设计用于操作高斯斑点的点变换器模型。SplatFormer将在有限训练视图下优化的初始3DGS集作为输入，并在一次前向传递中对其进行细化，有效地消除了OOD测试视图中的潜在伪影。据我们所知，这是点变换器直接在3DGS集上的首次成功应用，超越了以前多场景训练方法的局限性，这些方法在推理过程中只能处理有限数量的输入视图。我们的模型显著提高了极端新颖视图下的渲染质量，在这些具有挑战性的场景中实现了最先进的性能，并优于各种3DGS正则化技术、为稀疏视图合成量身定制的多场景模型和基于扩散的框架。 et.al.|[2411.06390](http://arxiv.org/abs/2411.06390)|**[link](https://github.com/ChenYutongTHU/SplatFormer)**|
|**2024-11-10**|**Through the Curved Cover: Synthesizing Cover Aberrated Scenes with Refractive Field**|最近的扩展现实耳机和现场机器人已经采用了覆盖物来保护前置摄像头免受环境危害和坠落。盖子上的表面不规则性会导致光学像差，如模糊和非参数失真。NeRF和3D高斯散斑等新型视图合成方法不适合从具有光学像差的序列进行合成。为了应对这一挑战，我们引入了SynthCover，通过保护罩为下游扩展现实应用实现新颖的视图合成。SynthCover采用折射场来估计覆盖物的几何形状，从而能够对折射光线进行精确的分析计算。在合成场景和真实场景上的实验表明，我们的方法能够准确地模拟通过保护罩看到的场景，与现有方法相比，渲染质量有了显著提高。我们还表明，该模型可以很好地适应各种覆盖几何形状，并使用不同表面曲率的覆盖物捕获合成序列。为了推动对这一问题的进一步研究，我们提供了包含用保护罩光学像差捕获的真实和合成可步行场景的基准数据集。 et.al.|[2411.06365](http://arxiv.org/abs/2411.06365)|null|
|**2024-11-09**|**GaussianSpa: An "Optimizing-Sparsifying" Simplification Framework for Compact and High-Quality 3D Gaussian Splatting**|3D高斯散斑（3DGS）已成为新型视图合成的主流，利用高斯函数的连续聚合来模拟场景几何。然而，3DGS需要大量的内存来存储大量的高斯人，这阻碍了它的实用性。为了应对这一挑战，我们引入了GaussiansSpa，这是一个基于优化的简化框架，用于紧凑和高质量的3DGS。具体来说，我们将简化问题表述为与3DGS训练相关的优化问题。相应地，我们提出了一种高效的“优化稀疏”解决方案，交替解决两个独立的子问题，在训练过程中逐渐将强稀疏性强加到高斯算子上。我们对各种数据集的综合评估表明，GaussianSpa优于现有的最先进方法。值得注意的是，GaussianSpa在真实世界的深度混合数据集上实现了0.9 dB的平均PSNR改善，与普通3DGS相比，Gaussian减少了10倍。我们的项目页面可在https://gaussianspa.github.io/. et.al.|[2411.06019](http://arxiv.org/abs/2411.06019)|null|
|**2024-11-07**|**MVSplat360: Feed-Forward 360 Scene Synthesis from Sparse Views**|我们介绍MVSplat360，这是一种前馈方法，用于仅使用稀疏观测对不同现实世界场景进行360度新颖视图合成（NVS）。由于输入视图之间的最小重叠和提供的视觉信息不足，这种设置本身就不合适，这使得传统方法难以实现高质量的结果。我们的MVSplat360通过有效地将几何感知3D重建与时间一致的视频生成相结合来解决这个问题。具体来说，它重构了一个前馈的3D高斯散斑（3DGS）模型，将特征直接渲染到预训练的稳定视频扩散（SVD）模型的潜在空间中，然后这些特征作为姿态和视觉线索来指导去噪过程，并产生逼真的3D一致视图。我们的模型是端到端可训练的，支持用少至5个稀疏输入视图渲染任意视图。为了评估MVSplat360的性能，我们使用具有挑战性的DL3DV-10K数据集引入了一个新的基准，与最先进的方法相比，MVSplat36在宽扫甚至360度NVS任务中实现了卓越的视觉质量。在现有基准RealEstate10K上的实验也证实了我们模型的有效性。视频结果可在我们的项目页面上查看：https://donydchen.github.io/mvsplat360. et.al.|[2411.04924](http://arxiv.org/abs/2411.04924)|**[link](https://github.com/donydchen/mvsplat360)**|
|**2024-11-07**|**GANESH: Generalizable NeRF for Lensless Imaging**|无透镜成像通过消除传统笨重的透镜系统，为开发超紧凑型相机提供了重要机会。然而，如果没有聚焦元件，传感器的输出不再是直接图像，而是复杂的多路复用场景表示。传统方法试图通过采用可学习的反演和精化模型来解决这一挑战，但这些方法主要是为2D重建而设计的，不能很好地推广到3D重建。我们介绍了GANESH，这是一种新颖的框架，旨在实现多视图无透镜图像的同时细化和新颖的视图合成。与需要特定场景训练的现有方法不同，我们的方法支持即时推理，而无需对每个场景进行再训练。此外，我们的框架允许我们根据特定场景调整模型，从而提高渲染和细化质量。为了促进这一领域的研究，我们还提出了第一个多视图无透镜数据集LenslessScenes。大量实验表明，我们的方法在重建精度和细化质量方面优于当前的方法。代码和视频结果可在https://rakesh-123-cryp.github.io/Rakesh.github.io/ et.al.|[2411.04810](http://arxiv.org/abs/2411.04810)|null|
|**2024-11-06**|**Structure Consistent Gaussian Splatting with Matching Prior for Few-shot Novel View Synthesis**|尽管新型视图合成取得了实质性进展，但现有的方法，无论是基于神经辐射场（NeRF）还是最近的3D高斯散斑（3DGS），在输入变得稀疏时都会出现严重退化。人们已经做出了许多努力来缓解这个问题，但他们仍然难以有效地综合出令人满意的结果，特别是在大型场景中。本文提出了SCGaussian，这是一种使用匹配先验来学习3D一致场景结构的结构一致高斯散点方法。考虑到高斯属性的高度相互依赖性，我们在两个方面优化了场景结构：渲染几何体，更重要的是高斯基元的位置，由于非结构特性，高斯基元在普通3DGS中很难直接受到约束。为了实现这一点，我们提出了一种混合高斯表示法。除了普通的非结构高斯基元外，我们的模型还包括基于光线的高斯基元，这些基元绑定到匹配的光线上，其位置的优化沿光线受到限制。因此，我们可以利用匹配对应关系直接强制这些高斯基元的位置收敛到光线相交的表面点。在面向前方、周围和复杂的大型场景上进行的广泛实验表明，我们的方法具有最先进的性能和高效率。代码可在以下网址获得https://github.com/prstrive/SCGaussian. et.al.|[2411.03637](http://arxiv.org/abs/2411.03637)|**[link](https://github.com/prstrive/scgaussian)**|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-11-12**|**SP-VIO: Robust and Efficient Filter-Based Visual Inertial Odometry with State Transformation Model and Pose-Only Visual Description**|基于滤波器的视觉惯性里程计（VIO）具有计算效率高、内存需求小的优点，在小型化和有效载荷受限的嵌入式系统中具有良好的应用前景。然而，基于滤波器的方法存在精度不足的问题。为此，我们通过重建状态和测量模型，并考虑进一步的视觉剥夺条件，提出了状态转换和仅姿态VIO（SP-VIO）。详细地说，我们首先提出了一种基于双状态变换扩展卡尔曼滤波器（DST-EKF）的系统模型，该模型已被证明比基于扩展卡尔曼滤波器和状态变换扩展Kalman滤波器的模型具有更好的可观测性和一致性。其次，为了减少由不准确的3D重建引起的线性化误差的影响，我们采用仅位姿（PO）理论将测量模型与3D特征解耦。此外，为了应对视觉剥夺的情况，我们提出了一种双态变换Rauch Tung-Striebel（DST-RTS）回溯方法来优化视觉中断期间的运动轨迹。在公共（EuRoC、Tum VI、KITTI）和个人数据集上的实验表明，SP-VIO比最先进的（SOTA）VIO算法具有更好的准确性和效率，并且在视觉剥夺条件下具有更好的鲁棒性。 et.al.|[2411.07551](http://arxiv.org/abs/2411.07551)|null|
|**2024-11-12**|**Extreme Rotation Estimation in the Wild**|我们提出了一种技术和基准数据集，用于估计在极端环境中捕获的一对互联网图像之间的相对3D方向，其中图像具有有限或不重叠的视场。之前针对极端旋转估计的工作假设了受约束的3D环境，并通过从全景图中裁剪区域来模拟透视图像。然而，在野外拍摄的真实图像非常多样化，在外观和相机内部都表现出变化。在这项工作中，我们提出了一种基于Transformer的方法来估计极端现实环境中的相对旋转，并贡献了由场景级互联网照片集组装而成的ExtremeLandmarkPairs数据集。我们的评估表明，我们的方法成功地估计了各种极端视图互联网图像对中的相对旋转，优于各种基线，包括专用旋转估计技术和当代3D重建方法。 et.al.|[2411.07096](http://arxiv.org/abs/2411.07096)|null|
|**2024-11-11**|**AV-PedAware: Self-Supervised Audio-Visual Fusion for Dynamic Pedestrian Awareness**|在这项研究中，我们介绍了AV PedAware，这是一种自我监督的视听融合系统，旨在提高机器人应用中的动态行人感知能力。行人意识是许多机器人应用中的关键要求。然而，依赖相机和LIDAR覆盖多个视图的传统方法可能很昂贵，并且容易受到光照、遮挡和天气条件变化等问题的影响。我们提出的解决方案使用低成本的音频和视觉融合来复制人类对3D行人检测的感知。这项研究首次尝试利用视听融合来监测脚步声，以预测附近行人的运动。该系统通过基于激光雷达生成标签的自我监督学习进行训练，使其成为基于激光雷达的行人感知的经济高效的替代方案。AV PedAware以极低的成本实现了与基于激光雷达的系统相当的结果。通过利用注意力机制，它可以处理动态照明和遮挡，克服了传统激光雷达和基于相机的系统的局限性。为了评估我们的方法的有效性，我们收集了一个新的多模式行人检测数据集，并进行了实验，证明该系统即使在极端的视觉条件下，也能仅使用音频和视觉数据提供可靠的3D检测结果。我们将把收集到的数据集和源代码在线提供给社区，以鼓励机器人感知系统领域的进一步发展。 et.al.|[2411.06789](http://arxiv.org/abs/2411.06789)|null|
|**2024-11-10**|**Real-time Deformation-aware Control for Autonomous Robotic Subretinal Injection under iOCT Guidance**|机器人平台提供可重复和精确的工具定位，显著增强视网膜显微手术。这种系统与术中光学相干断层扫描（iOCT）的集成实现了图像引导的机器人干预，允许自主执行高级治疗可能性，例如将治疗剂注射到视网膜下腔。然而，在自主iOCT引导的机器人视网膜下注射中，由于工具-组织相互作用导致的组织变形是一个主要挑战，会影响正确的针头定位，从而影响手术的结果。本文提出了一种在iOCT引导下自主视网膜下注射的新方法，该方法考虑了插入过程中的组织变形。这是通过从密集采样的iOCT B扫描（我们称之为B5扫描）中实时分割和3D重建手术场景来实现的，以监测仪器相对于ILM和RPE之间相对位置处定义的虚拟目标层的定位。我们在离体猪眼睛上的实验表明，与之前的自主插入方法相比，插入深度的动态调整和针头定位的整体精度得到了提高。与之前方法生成视网膜下泡的成功率为35%相比，我们提出的方法在所有实验中都可靠、稳健地创建了视网膜下泡。 et.al.|[2411.06557](http://arxiv.org/abs/2411.06557)|null|
|**2024-11-10**|**A novel algorithm for optimizing bundle adjustment in image sequence alignment**|捆绑调整（BA）模型通常使用非线性最小二乘法进行优化，Levenberg-Marquardt（L-M）算法是典型的选择。然而，尽管L-M算法很有效，但当应用于条件较差的数据集时，它对初始条件的敏感性往往会导致收敛速度较慢，从而激发了对替代优化策略的探索。本文介绍了一种在低温电子断层成像图像序列比对背景下优化BA模型的新算法，该算法利用最优控制理论直接优化一般非线性函数。所提出的最优控制算法（OCA）表现出优异的收敛速度，并有效地缓解了L-M算法中经常观察到的振荡行为。对合成数据集和真实世界数据集进行了广泛的实验，以评估算法的性能。结果表明，与L-M算法相比，OCA实现了更快的收敛。此外，基于二分法的更新过程显著提高了OCA的性能，特别是在初始化不佳的数据集中。这些发现表明，OCA可以大大提高低温电子断层扫描中3D重建的效率。 et.al.|[2411.06343](http://arxiv.org/abs/2411.06343)|null|
|**2024-11-08**|**Benchmarking 3D multi-coil NC-PDNet MRI reconstruction**|深度学习在从欠采样数据中重建MRI方面显示出巨大的前景，但目前还缺乏对其在非笛卡尔欠采样的3D并行成像采集中的性能进行验证的研究。此外，伪影和由此产生的图像质量取决于欠采样模式。为了解决这一未知领域的问题，我们将非笛卡尔原始双网络（NC PDNet）扩展到3D多线圈设置，这是一种最先进的展开神经网络。我们评估了通道特定训练配置与通道无关训练配置的影响，并检查了线圈压缩的效果。最后，我们使用公开的卡尔加里坎皮纳斯数据集，对四种不同的非笛卡尔欠采样模式进行基准测试，加速因子为6。我们的结果表明，在具有不同输入通道数的压缩数据上训练的NC PDNet在1mm各向同性32通道全脑3D重建中实现了42.98 dB的平均PSNR。推理时间为4.95秒，GPU内存使用率为5.49 GB，我们的方法在临床研究应用中具有巨大的潜力。 et.al.|[2411.05883](http://arxiv.org/abs/2411.05883)|null|
|**2024-11-07**|**MVSplat360: Feed-Forward 360 Scene Synthesis from Sparse Views**|我们介绍MVSplat360，这是一种前馈方法，用于仅使用稀疏观测对不同现实世界场景进行360度新颖视图合成（NVS）。由于输入视图之间的最小重叠和提供的视觉信息不足，这种设置本身就不合适，这使得传统方法难以实现高质量的结果。我们的MVSplat360通过有效地将几何感知3D重建与时间一致的视频生成相结合来解决这个问题。具体来说，它重构了一个前馈的3D高斯散斑（3DGS）模型，将特征直接渲染到预训练的稳定视频扩散（SVD）模型的潜在空间中，然后这些特征作为姿态和视觉线索来指导去噪过程，并产生逼真的3D一致视图。我们的模型是端到端可训练的，支持用少至5个稀疏输入视图渲染任意视图。为了评估MVSplat360的性能，我们使用具有挑战性的DL3DV-10K数据集引入了一个新的基准，与最先进的方法相比，MVSplat36在宽扫甚至360度NVS任务中实现了卓越的视觉质量。在现有基准RealEstate10K上的实验也证实了我们模型的有效性。视频结果可在我们的项目页面上查看：https://donydchen.github.io/mvsplat360. et.al.|[2411.04924](http://arxiv.org/abs/2411.04924)|**[link](https://github.com/donydchen/mvsplat360)**|
|**2024-11-07**|**Differentiable Gaussian Representation for Incomplete CT Reconstruction**|不完全计算机断层扫描（CT）通过减少辐射暴露使患者受益。然而，由于问题的不适定性质，从有限的视图或角度重建高保真图像仍然具有挑战性。深度学习重建（DLR）方法在提高图像质量方面显示出了希望，但训练数据多样性和高泛化能力之间的悖论仍未得到解决。在这篇论文中，我们提出了一种新的不完全CT重建的高斯表示法（GRCT），无需使用任何神经网络或全剂量CT数据。具体来说，我们将3D体积建模为一组可学习的高斯分布，这些高斯分布直接从不完整的正弦图中优化。我们的方法可以应用于多个视图和角度，而无需改变架构。此外，我们提出了一种可区分的快速CT重建方法，以实现高效的临床应用。在多个数据集和设置上进行的广泛实验表明，重建质量指标和效率有了显著提高。我们计划以开源的形式发布我们的代码。 et.al.|[2411.04844](http://arxiv.org/abs/2411.04844)|null|
|**2024-11-07**|**GANESH: Generalizable NeRF for Lensless Imaging**|无透镜成像通过消除传统笨重的透镜系统，为开发超紧凑型相机提供了重要机会。然而，如果没有聚焦元件，传感器的输出不再是直接图像，而是复杂的多路复用场景表示。传统方法试图通过采用可学习的反演和精化模型来解决这一挑战，但这些方法主要是为2D重建而设计的，不能很好地推广到3D重建。我们介绍了GANESH，这是一种新颖的框架，旨在实现多视图无透镜图像的同时细化和新颖的视图合成。与需要特定场景训练的现有方法不同，我们的方法支持即时推理，而无需对每个场景进行再训练。此外，我们的框架允许我们根据特定场景调整模型，从而提高渲染和细化质量。为了促进这一领域的研究，我们还提出了第一个多视图无透镜数据集LenslessScenes。大量实验表明，我们的方法在重建精度和细化质量方面优于当前的方法。代码和视频结果可在https://rakesh-123-cryp.github.io/Rakesh.github.io/ et.al.|[2411.04810](http://arxiv.org/abs/2411.04810)|null|
|**2024-11-07**|**Enhancing Bronchoscopy Depth Estimation through Synthetic-to-Real Domain Adaptation**|单眼深度估计在一般成像任务中显示出希望，有助于定位和3D重建。虽然在各个领域都很有效，但由于缺乏标记数据，它在支气管镜图像中的应用受到阻碍，这对监督学习方法的使用提出了挑战。在这项工作中，我们提出了一种迁移学习框架，该框架利用具有深度标签的合成数据进行训练，并调整领域知识以在真实支气管镜数据中进行准确的深度估计。与仅在合成数据上进行训练相比，我们的网络使用域自适应对真实镜头进行了改进的深度预测，验证了我们的方法。 et.al.|[2411.04404](http://arxiv.org/abs/2411.04404)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-11-13**|**Scaling Properties of Diffusion Models for Perceptual Tasks**|在本文中，我们认为，使用扩散模型的迭代计算不仅为生成任务，而且为视觉感知任务提供了一种强大的范式。我们在图像到图像转换的框架下统一了深度估计、光流和amodal分割等任务，并展示了扩散模型如何从这些感知任务的缩放训练和测试时间计算中受益。通过对这些缩放特性的仔细分析，我们制定了计算最优训练和推理配方，以缩放视觉感知任务的扩散模型。我们的模型使用更少的数据和计算，实现了与最先进方法相媲美的性能。要访问我们的代码和模型，请参阅https://scaling-diffusion-perception.github.io . et.al.|[2411.08034](http://arxiv.org/abs/2411.08034)|null|
|**2024-11-12**|**GaussianAnything: Interactive Point Cloud Latent Diffusion for 3D Generation**|虽然3D内容生成已经取得了显著进展，但现有方法在输入格式、潜在空间设计和输出表示方面仍然面临挑战。本文介绍了一种新的3D生成框架，可以解决这些挑战，提供可扩展的、高质量的3D生成，并具有交互式点云结构的潜在空间。我们的框架采用变分自编码器（VAE），以多视图姿态RGB-D（epth）-N（normal）渲染作为输入，使用独特的潜在空间设计来保留3D形状信息，并结合级联潜在扩散模型来改善形状-纹理解纠缠。所提出的方法GaussianAnything支持多模态条件3D生成，允许点云、字幕和单/多视图图像输入。值得注意的是，新提出的潜在空间自然地实现了几何纹理解纠缠，从而允许进行3D感知编辑。实验结果证明了我们的方法在多个数据集上的有效性，在文本和图像条件下的3D生成方面都优于现有方法。 et.al.|[2411.08033](http://arxiv.org/abs/2411.08033)|null|
|**2024-11-12**|**Commissioning of the 2.6 m tall two-phase xenon time projection chamber of Xenoscope**|Xenoscope是XLZD（xenon-LUX-ZEPLIN-DARWIN）合作提出的下一代基于氙的天体粒子物理天文台的演示器。它有一个2.6米高的两相氙时间投影室（TPC），在一个装有360公斤液态氙的低温恒温器中。该设施的主要目标是证明液态氙中的电子在这段距离内的漂移，测量电子云的横向和纵向扩散，以及介质的光学性质。在这项工作中，我们详细描述了TPC的建造和调试，并报告了用宇宙μ子观测光和电荷信号的情况。 et.al.|[2411.08022](http://arxiv.org/abs/2411.08022)|null|
|**2024-11-12**|**Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model with Compact Wavelet Encodings**|大规模3D生成模型需要大量的计算资源，但在高分辨率下捕捉精细细节和复杂几何形状方面往往不足。我们将这种局限性归因于当前表示的低效性，它缺乏有效建模生成模型所需的紧凑性。为了解决这个问题，我们引入了一种称为小波潜在扩散或WaLa的新方法，该方法将3D形状编码为基于小波的紧凑潜在编码。具体来说，我们将一个256^3 $的带符号距离字段压缩为12^3\times 4$的潜在网格，在细节损失最小的情况下实现了令人印象深刻的2427x压缩比。这种高水平的压缩使我们的方法能够在不增加推理时间的情况下有效地训练大规模生成网络。我们的模型，无论是有条件的还是无条件的，都包含大约10亿个参数，并成功地以256^3$ 的分辨率生成高质量的3D形状。此外，WaLa提供了快速推理，根据条件在两到四秒内生成形状，尽管模型的规模很大。我们在多个数据集上展示了最先进的性能，在生成质量、多样性和计算效率方面有了显著提高。我们开源了我们的代码，并且据我们所知，发布了不同模式下最大的预训练3D生成模型。 et.al.|[2411.08017](http://arxiv.org/abs/2411.08017)|null|
|**2024-11-12**|**Quantitative Phase-Field Modeling of Rapid Alloy Solidification**|我们进一步开发了最近引入的快速合金凝固相场模型[Ji等人，PRL 2023]。该模型利用空间扩散界面区域内增强的溶质扩散率，以更大的界面宽度定量捕获溶质捕获，从而使实验相关长度和时间尺度上的模拟在计算上可行。这里介绍的主要发展包括测试不同变分公式的稳健性，通过结合热力学数据库中的固体和液体自由能将模型扩展到浓缩合金，如使用CALPHAD的亚共晶Al-Ag合金所示，将收敛测试作为界面宽度的函数扩展到3D，并在2D和3D中进行模拟以检验现有的微观结构发展理论。我们的结果表明，在固体和液体形式之间插值体自由能密度的最简单变分公式是最稳健的。值得注意的是，对于亚共晶Al-Ag合金，这种公式产生了一个与界面宽度无关的高速非平衡相图，从而证明了增强溶质扩散框架可以非平凡地扩展到浓缩合金。其他变分公式具有可可靠建模的材料或加工参数的有限范围。我们使用二维模拟来构建稀Al-Cu合金的高速微观结构选择图。此外，3D模拟显示了良好的收敛性，类似于2D中观察到的界面宽度的函数。全3D模拟表明，尽管2D和3D中这种不稳定性的形态表现不同，但绝对稳定性的标准理论可以很好地预测上临界速度，超过该速度，稳态增长将变得不稳定。 et.al.|[2411.07953](http://arxiv.org/abs/2411.07953)|null|
|**2024-11-12**|**Microscopic fluctuations in the spreading fronts of circular wetting liquid droplets**|我们数值研究了非挥发性液滴在固体基底上扩散的前体前缘的动力学粗糙化特性，对于圆形液滴的情况，这在实验中更为常见。为此，我们对晶格气体模型进行了动力学蒙特卡罗（kMC）模拟，该模型的动力学粗糙化行为最近在能带几何中进行了评估[J.\M.M.Marcos等人，Phys.\Rev.\E{\bf105}，054801（2022）]。考虑到相关重要的Kardar-Parisi-Zhang（KPZ）普适性类的不同生长几何形状的不同普适性子类的出现，我们比较了这两种几何形状获得的扩展前沿的缩放行为。对于圆形液滴，我们发现平均前沿位置随着 $R\sim t^{\delta}$的扩散而增加（亚），其中$\delta\lesssim 1/2$对温度和基材润湿性的条件的依赖性比带内几何形状更强。尽管如此，圆形液滴的前沿波动在性质上与带几何形状的波动相似，动力学粗糙化指数值同样取决于温度$T$，但对于足够高的$T$则变得与$T$ 无关。圆形液滴还显示出内在的异常标度，在短尺度和大尺度上具有不同的粗糙度指数值，波动统计接近适用于相应KPZ普适性子类的Tracy Widom概率分布函数，现在是具有整体圆对称性的界面所期望的。 et.al.|[2411.07923](http://arxiv.org/abs/2411.07923)|null|
|**2024-11-12**|**When Randomness Beats Redundancy: Insights into the Diffusion of Complex Contagions**|社交网络结构如何放大或抑制行为扩散？现有理论表明，当社会强化使行为更有可能被采用时，它应该在具有冗余关系的集群网络上传播得更远更快。相反，如果收养没有从社会强化中受益，那么它应该在没有这种冗余的随机网络上传播得更多。我们开发了一种具有可调概率采用和社会强化参数的行为扩散新模型，以系统地评估与随机网络相比，集群网络更好地传播行为的条件。使用模拟和分析技术，我们在参数空间中找到了精确的边界，其中任何一种网络类型都优于另一种或表现相同。我们发现，在大多数情况下，尽管有很强的社会强化，但随机网络与集群网络相比，将行为传播得一样远或更远。虽然在某些地区，集群网络通过社会强化更好地传播传染病，但这仅在传播过程接近确定性阈值模型时成立，并不适用于所有更普遍的社会强化行为。充其量，在18%的参数空间中，当社会强化相对于基线采用概率较大时，集群网络的表现仅比随机网络好至少5%。 et.al.|[2411.07907](http://arxiv.org/abs/2411.07907)|null|
|**2024-11-12**|**Diverse capability and scaling of diffusion and auto-regressive models when learning abstract rules**|人类擅长从有限的样本中发现规则结构，并将推断出的规则应用于新的环境。我们研究了现代生成模型是否可以类似地从有限样本中学习底层规则，并通过条件采样进行推理。受Raven的渐进矩阵任务的启发，我们设计了GenRAVEN数据集，其中每个样本由三行组成，40条关系规则中的一条适用于所有行，这些规则控制着对象的位置、数量或属性。我们训练生成模型来学习数据分布，其中样本被编码为整数数组，以专注于规则学习。我们比较了两个生成模型家族：扩散模型（EDM、DiT、SiT）和自回归模型（GPT2、Mamba）。我们评估了他们生成结构一致的样本并通过无条件和有条件采样进行面板完成的能力。我们发现扩散模型在无条件生成方面表现出色，从头开始产生更多新颖和一致的样本，记忆更少，但在面板完成方面表现较差，即使使用先进的条件采样方法。相反，自回归模型擅长以规则一致的方式完成缺失的面板，但无条件地生成不太一致的样本。我们观察到不同的数据缩放行为：对于这两个模型家族，规则学习都以一定的数据集大小出现——每条规则大约有1000个示例。随着训练数据的增加，扩散模型提高了无条件和条件生成能力。然而，对于自回归模型，虽然面板完成率随着训练数据的增加而提高，但无条件生成一致性下降。我们的研究结果突出了扩散和自回归模型在规则学习和推理任务中的互补能力和局限性，为进一步研究它们的机制和类人推理的潜力提供了途径。 et.al.|[2411.07873](http://arxiv.org/abs/2411.07873)|null|
|**2024-11-12**|**API Phonons: Python Interfaces for Phonon Transport Modeling**|API Phonons是一个Python软件包，用于预测载热声子的传输动力学。使用Python的强大语法，该包提供了不同包之间的模块和函数接口，用于原子模拟、晶格动力学和声子-声子相互作用计算，包括LAMMPS、Quippy、Phonopy和ShengBTE。API声子实现了复杂的声子计算，包括（1）从任意原子间势中提取谐波和非谐波力常数，这些常数可以用作求解玻尔兹曼输运方程的输入；（2） 使用Kubo的线性响应理论预测热导率，该理论捕获了准粒子输运和带间相干输运；以及（3）使用基于模式分辨声子特性的格林函数方法对超快泵浦探针热响应进行建模，以研究弹道、流体动力学和扩散输运动力学。该软件包提供了一个灵活、易于使用和广泛的平台，用于通过Python编程对声子输运物理进行建模。 et.al.|[2411.07774](http://arxiv.org/abs/2411.07774)|null|
|**2024-11-12**|**Novel View Synthesis with Pixel-Space Diffusion Models**|从单个输入图像合成新视图是一项具有挑战性的任务。传统上，这项任务是通过估计场景深度、扭曲和修复来完成的，机器学习模型支持部分管道。最近，生成模型越来越多地用于新颖视图合成（NVS），通常涵盖整个端到端系统。在这项工作中，我们采用了一种现代扩散模型架构，用于像素空间中的端到端NVS，其性能大大优于先前最先进的（SOTA）技术。我们探索了将几何信息编码到网络中的不同方法。我们的实验表明，虽然这些方法可以提高性能，但与使用改进的生成模型相比，它们的影响很小。此外，我们引入了一种新的NVS训练方案，该方案利用了单视图数据集，利用了它们与多视图数据集相比的相对丰富性。这提高了对具有域外内容的场景的泛化能力。 et.al.|[2411.07765](http://arxiv.org/abs/2411.07765)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-11-09**|**Epi-NAF: Enhancing Neural Attenuation Fields for Limited-Angle CT with Epipolar Consistency Conditions**|神经场方法最初在逆渲染领域取得了成功，最近已扩展到CT重建，标志着传统技术的范式转变。虽然这些方法在稀疏视图CT重建中提供了最先进的结果，但它们在有限的角度设置中很难实现，在有限的视角范围内捕获输入投影。我们提出了一种基于X射线投影图像中相应极线之间一致性条件的新损失项，旨在规范神经衰减场优化。通过强制执行这些一致性条件，我们的方法Epi NAF将监督从有限角度范围内的输入视图传播到整个锥束CT范围内的预测投影。与基线方法相比，这种损失导致重建的定性和定量改进。 et.al.|[2411.06181](http://arxiv.org/abs/2411.06181)|null|
|**2024-11-07**|**LoFi: Scalable Local Image Reconstruction with Implicit Neural Representation**|神经场或隐式神经表示（INR）因其对图像和3D体积的有效连续表示而在机器学习和信号处理中引起了广泛关注。在这项工作中，我们以INR为基础，引入了一种基于坐标的局部处理框架来解决成像逆问题，称为LoFi（局部场）。与传统的图像重建方法不同，LoFi通过多层感知器（MLP）分别处理每个坐标处的局部信息，在该特定坐标处恢复对象。与INR类似，LoFi可以在任何连续坐标下恢复图像，从而实现多分辨率的图像重建。LoFi在图像重建方面的性能与标准CNN相当或更好，几乎与图像分辨率无关，对分布外数据和内存使用具有出色的泛化能力。值得注意的是，对1024美元×1024美元的图像进行训练只需要3GB的内存，比标准CNN通常需要的内存少20多倍。此外，LoFi的局部设计使其能够在小于10个样本的极小数据集上进行训练，而不会过拟合或需要正则化或提前停止。最后，我们使用LoFi作为即插即用框架中的去噪先验，用于解决一般的逆问题，以受益于其连续的图像表示和强大的泛化能力。尽管在低分辨率图像上进行了训练，但LoFi可以用作低维先验，以解决任何分辨率的逆问题。我们通过各种成像方式验证了我们的框架，从低剂量计算机断层扫描到无线电干涉成像。 et.al.|[2411.04995](http://arxiv.org/abs/2411.04995)|null|
|**2024-11-04**|**Physically Based Neural Bidirectional Reflectance Distribution Function**|我们介绍了基于物理的神经双向反射分布函数（PBNBRDF），这是一种基于神经场的材料外观的新颖连续表示。我们的模型准确地重建了真实世界的材料，同时独特地增强了现实BRDF的物理特性，特别是通过重新参数化的亥姆霍兹互易性和通过高效分析积分的能量无源性。我们进行了系统分析，证明了遵守这些物理定律对重建材料的视觉质量的好处。此外，我们通过引入色度强制监督RGB通道的规范来提高神经BRDF的颜色精度。通过在多个测量的真实BRDF数据库上进行定性和定量实验，我们表明，遵守这些物理约束可以使神经场更忠实、更稳定地表示原始数据，并实现更高的渲染质量。 et.al.|[2411.02347](http://arxiv.org/abs/2411.02347)|null|
|**2024-11-01**|**Intensity Field Decomposition for Tissue-Guided Neural Tomography**|锥束计算机断层扫描（CBCT）通常需要数百次X射线投影，这引起了人们对辐射暴露的担忧。虽然稀疏视图重建通过使用更少的投影来减少曝光，但它很难达到令人满意的图像质量。为了应对这一挑战，本文介绍了一种新的稀疏视图CBCT重建方法，该方法为神经场赋予了人体组织正则化的能力。我们的方法被称为组织引导神经断层扫描（TNT），其动机是CBCT中骨骼和软组织之间明显的强度差异。直观地说，分离这些成分可能有助于神经场的学习过程。更确切地说，TNT包括一个异构的四重网络和相应的训练策略。该网络将强度场表示为软组织和硬组织成分及其各自纹理的组合。我们在估计的组织投影的指导下训练网络，从而能够有效地学习网络头所需的模式。大量实验表明，所提出的方法显著改善了稀疏视图CBCT重建，投影数量从10到60不等。与最先进的基于神经渲染的方法相比，我们的方法以更少的投影和更快的收敛实现了相当的重建质量。 et.al.|[2411.00900](http://arxiv.org/abs/2411.00900)|null|
|**2024-10-26**|**Neural Fields in Robotics: A Survey**|神经场已经成为计算机视觉和机器人技术中3D场景表示的一种变革性方法，能够从姿势的2D数据中准确推断几何、3D语义和动力学。利用可微分渲染，神经场包括连续隐式和显式神经表示，实现了高保真3D重建、多模态传感器数据的集成和新视点的生成。这项调查探讨了它们在机器人技术中的应用，强调了它们在增强感知、规划和控制方面的潜力。它们的紧凑性、内存效率和可微性，以及与基础模型和生成模型的无缝集成，使其成为实时应用的理想选择，提高了机器人的适应性和决策能力。本文基于200多篇论文，对机器人中的神经场进行了全面的回顾，对各个领域的应用进行了分类，并评估了它们的优势和局限性。首先，我们介绍了四个关键的神经场框架：占用网络、有符号距离场、神经辐射场和高斯散斑。其次，我们详细介绍了神经场在五个主要机器人领域的应用：姿态估计、操纵、导航、物理和自动驾驶，重点介绍了关键工作，并讨论了要点和公开挑战。最后，我们概述了神经场在机器人技术中的局限性，并为未来的研究提出了有前景的方向。项目页面：https://robonerf.github.io et.al.|[2410.20220](http://arxiv.org/abs/2410.20220)|**[link](https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics)**|
|**2024-10-24**|**3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation**|多视图图像扩散模型显著推进了开放域3D对象生成。然而，大多数现有模型依赖于缺乏固有3D偏差的2D网络架构，导致几何一致性受损。为了应对这一挑战，我们引入了3D Adapter，这是一个插件模块，旨在将3D几何感知注入预训练的图像扩散模型中。我们方法的核心是3D反馈增强的思想：对于采样循环中的每个去噪步骤，3D Adapter将中间的多视图特征解码为连贯的3D表示，然后对渲染的RGBD视图进行重新编码，通过特征添加来增强预训练的基础模型。我们研究了3D Adapter的两种变体：一种是基于高斯飞溅的快速前馈版本，另一种是利用神经场和网格的通用无训练版本。我们广泛的实验表明，3D Adapter不仅大大提高了文本到多视图模型（如Instant3D和Zero123++）的几何质量，而且还使用纯文本到图像的稳定扩散实现了高质量的3D生成。此外，我们通过在文本到3D、图像到3D、文本到纹理和文本到化身任务中呈现高质量的结果，展示了3D适配器的广泛应用潜力。 et.al.|[2410.18974](http://arxiv.org/abs/2410.18974)|**[link](https://github.com/Lakonik/MVEdit)**|
|**2024-10-22**|**Cortical Dynamics of Neural-Connectivity Fields**|皮质组织的宏观研究揭示了振荡活动的普遍性，这反映了神经相互作用的微调。本研究通过将广义振荡动力学纳入先前关于保守或半保守神经场动力学的工作中，扩展了神经场理论。先前的研究在很大程度上假设了神经单元之间的各向同性连接；然而，这项研究表明，广泛的各向异性和波动连接仍然可以维持振荡。使用拉格朗日场方法，我们研究了不同类型的连接、它们的动力学以及与神经场的潜在相互作用。基于这一理论基础，我们推导出了一个框架，该框架通过连接场的概念将Hebbian和非Hebbian学习（即可塑性）纳入神经场的研究中。 et.al.|[2410.16852](http://arxiv.org/abs/2410.16852)|null|
|**2024-10-15**|**Deep vectorised operators for pulsatile hemodynamics estimation in coronary arteries from a steady-state prior**|心血管血流动力学场为冠状动脉疾病提供了有价值的医学决策标志。计算流体动力学（CFD）是体内准确、无创评估这些量的金标准。在这项工作中，我们提出了一种基于机器学习的时间高效替代模型，用于基于稳态先验估计脉动血流动力学。我们引入了深度矢量化算子，这是一种用于在无限维函数空间上进行离散化独立学习的建模框架。基础神经结构是一个以血流动力学边界条件为条件的神经场。重要的是，我们展示了如何将逐点动作的要求放宽到置换等变，从而产生一系列可以通过消息传递和自我关注层进行参数化的模型。我们在从冠状动脉计算机断层扫描血管造影（CCTA）中提取的74条狭窄冠状动脉的数据集上评估了我们的方法，并将患者特异性脉动CFD模拟作为基本事实。我们证明，我们的模型能够准确估计脉动速度和压力，同时不受源域重新采样的影响（离散化独立性）。这表明，深度矢量化算子是冠状动脉及其他动脉心血管血流动力学估计的强大建模工具。 et.al.|[2410.11920](http://arxiv.org/abs/2410.11920)|null|
|**2024-10-07**|**Fast Training of Sinusoidal Neural Fields via Scaling Initialization**|神经场是一种新兴的范式，它将数据表示为由神经网络参数化的连续函数。尽管有许多优点，但神经场通常具有较高的训练成本，这阻碍了更广泛的采用。在本文中，我们关注一个流行的神经场家族，称为正弦神经场（SNF），并研究如何初始化它以最大限度地提高训练速度。我们发现，基于信号传播原理设计的SNF标准初始化方案是次优的。特别是，我们证明，通过简单地将每个权重（最后一层除外）乘以一个常数，我们可以将SNF训练加速10 $\times$。这种方法被称为$\textit{weight scaling}$ ，在各种数据域上持续提供显著的加速，使SNF的训练速度比最近提出的架构更快。为了理解为什么权重缩放效果良好，我们进行了广泛的理论和实证分析，结果表明，权重缩放不仅有效地解决了频谱偏差，而且具有良好的优化轨迹。 et.al.|[2410.04779](http://arxiv.org/abs/2410.04779)|null|
|**2024-10-04**|**End-to-End Reaction Field Energy Modeling via Deep Learning based Voxel-to-voxel Transform**|在计算生物化学和生物物理学中，理解静电相互作用的作用对于阐明生物分子的结构、动力学和功能至关重要。泊松-玻尔兹曼（PB）方程是通过描述带电分子内部和周围的静电势来模拟这些相互作用的基础工具。然而，由于生物分子表面的复杂性和需要考虑可移动离子，求解PB方程带来了重大的计算挑战。虽然求解PB方程的传统数值方法是准确的，但它们的计算成本很高，并且随着系统规模的增加而扩展性较差。为了应对这些挑战，我们引入了PBNeF，这是一种新的机器学习方法，灵感来自基于神经网络的偏微分方程求解器的最新进展。我们的方法将PB方程的输入和边界静电条件转化为可学习的体素表示，使神经场变换器能够预测PB解，进而预测反应场势能。大量实验表明，与传统的PB求解器相比，PBNeF的速度提高了100倍以上，同时保持了与广义玻恩（GB）模型相当的精度。 et.al.|[2410.03927](http://arxiv.org/abs/2410.03927)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

