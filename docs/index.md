---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.12.30
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-12-27**|**Dust to Tower: Coarse-to-Fine Photo-Realistic Scene Reconstruction from Sparse Uncalibrated Images**|在实践中，从稀疏视图、未校准的图像重建逼真的场景是非常必要的。尽管已经取得了一些成功，但现有的方法要么是稀疏视图，但需要精确的相机参数（即内在和外在参数），要么是无SfM，但需要密集捕获的图像。为了结合这两种方法的优点，同时解决各自的弱点，我们提出了Dust To Tower（D2T），这是一种准确有效的粗到细框架，可以从稀疏和未校准的图像中同时优化3DGS和图像姿态。我们的关键思想是首先有效地构建一个粗略的模型，然后在新的视角下使用扭曲和修复的图像对其进行细化。为此，我们首先引入了一个粗略构造模块（CCM），该模块利用快速的多视图立体模型来初始化3D高斯散点（3DGS）并恢复初始相机姿态。为了在新的视角下优化3D模型，我们提出了一个置信度感知深度对齐（CADA）模块，通过将置信度部分与单深度模型的估计深度对齐来优化粗略的深度图。然后，提出了一种扭曲图像引导内涂（WIGI）模块，通过精细的深度图将训练图像扭曲到新的视点，并应用修复来填补由视图方向变化引起的扭曲图像中的“洞”，提供高质量的监督，以进一步优化3D模型和相机姿态。广泛的实验和消融研究证明了D2T及其设计选择的有效性，在保持高效率的同时，在新的视图合成和姿态估计任务中实现了最先进的性能。代码将公开可用。 et.al.|[2412.19518](http://arxiv.org/abs/2412.19518)|null|
|**2024-12-27**|**Learning Radiance Fields from a Single Snapshot Compressive Image**|本文探讨了快照压缩成像（SCI）技术从单个时间压缩图像中恢复底层3D场景结构的潜力。SCI是一种经济高效的方法，它能够使用低成本的2D成像传感器将高维数据（如高光谱或时间信息）记录到单个图像中。为了实现这一点，通常会采用一系列专门设计的2D掩模，降低存储和传输要求，并提供潜在的隐私保护。受此启发，我们进一步利用神经辐射场（NeRF）强大的3D场景表示能力来恢复编码的3D场景信息。具体来说，我们提出了SCINeRF，其中我们将SCI的物理成像过程作为NeRF训练的一部分，使我们能够利用其在捕捉复杂场景结构方面的出色性能。此外，我们进一步整合了流行的3D高斯散点（3DGS）框架，并提出了SCISplat，通过将点云明确优化为3D高斯表示来提高3D场景重建质量和训练/渲染速度。为了评估我们方法的有效性，我们使用SCI系统捕获的合成数据和真实数据进行了广泛的评估。实验结果表明，我们提出的方法在图像重建和新颖的视图合成方面超越了最先进的方法。此外，我们的方法还通过利用SCI和3DGS的渲染能力，实时渲染高帧率多视图一致图像。代码可在以下网址获得：https://github.com/WU-CVGL/SICSPLAT。 et.al.|[2412.19483](http://arxiv.org/abs/2412.19483)|null|
|**2024-12-27**|**DriveEditor: A Unified 3D Information-Guided Framework for Controllable Object Editing in Driving Scenes**|以视觉为中心的自动驾驶系统需要多样化的数据进行稳健的训练和评估，可以通过操纵现有场景捕获中的对象位置和外观来增强。虽然扩散模型的最新进展在视频编辑方面显示出了希望，但由于位置控制不精确和难以保持高保真对象外观，它们在驾驶场景中的对象操纵应用仍然具有挑战性。为了解决位置和外观控制方面的这些挑战，我们引入了DriveEditor，这是一个基于扩散的框架，用于驾驶视频中的对象编辑。DriveEditor为全面的对象编辑操作提供了一个统一的框架，包括重新定位、替换、删除和插入。这些不同的操作都是通过一组共享的不同输入来实现的，这些输入由相同的位置控制和外观维护模块处理。位置控制模块在保留深度信息的同时投影给定的3D边界框，并将其分层注入扩散过程中，从而能够精确控制对象的位置和方向。外观维护模块通过采用三层方法来保持与单个参考图像的一致属性：低级细节保留、高级语义维护和来自新颖视图合成模型的3D先验的集成。对nuScenes数据集的广泛定性和定量评估表明，DriveEditor在生成各种驾驶场景编辑方面具有出色的保真度和可控性，并且具有促进下游任务的显著能力。 et.al.|[2412.19458](http://arxiv.org/abs/2412.19458)|null|
|**2024-12-26**|**BeSplat -- Gaussian Splatting from a Single Blurry Image and Event Stream**|辐射场方法的发展极大地增强了新的视图合成。3D高斯散斑（3DGS）的引入有效地解决了关键挑战，如训练时间长和渲染速度慢，这通常与神经辐射场（NeRF）有关，同时保持了高质量的重建。在这项工作（BeSplat）中，我们演示了从单个运动模糊图像及其相应的事件流中恢复清晰的辐射场（高斯斑点）。我们的方法通过高斯散斑联合学习场景表示，并通过贝塞尔SE（3）公式有效地恢复相机运动，最大限度地减少模糊图像和相应事件流的合成测量值与真实世界测量值之间的差异。我们在合成和真实数据集上评估了我们的方法，展示了它从学习到的辐射场和估计的相机轨迹中渲染视图一致、清晰图像的能力。据我们所知，我们的工作是第一个在高斯散布框架中解决这一极具挑战性的病态问题的工作，该框架有效地结合了使用事件流捕获的时间信息。 et.al.|[2412.19370](http://arxiv.org/abs/2412.19370)|null|
|**2024-12-26**|**Reflective Gaussian Splatting**|由于基于NeRF和3DGS的方法越来越强大，新型视图合成技术取得了重大进展。然而，反射对象重建仍然具有挑战性，缺乏一种适当的解决方案来实现实时、高质量的渲染，同时适应相互反射。为了填补这一空白，我们引入了一个反射高斯飞溅（\textbf{Ref-Gausian}）框架，该框架由两个部分组成：（I）基于物理的延迟渲染}，通过公式化分裂和近似，为渲染方程赋予像素级材质属性；（II） {\em高斯接地互反射}首次在高斯溅射范式内实现了所需的互反射功能。为了增强几何建模，我们进一步引入了材料感知的法线传播和初始的每高斯着色阶段，以及2D高斯基元。在标准数据集上进行的大量实验表明，Ref-Gassian在定量指标、视觉质量和计算效率方面优于现有方法。此外，我们表明，我们的方法可以作为反射和非反射场景的统一解决方案，超越了之前只关注反射场景的替代方案。此外，我们还说明了Ref-Gassian支持更多的应用程序，如重新照明和编辑。 et.al.|[2412.19282](http://arxiv.org/abs/2412.19282)|null|
|**2024-12-25**|**GSAVS: Gaussian Splatting-based Autonomous Vehicle Simulator**|现代自动驾驶汽车模拟器具有不断增长的资产库，包括车辆、建筑物、道路、行人等。虽然这种程度的定制在创建虚拟城市环境时被证明是有益的，但当打算在数字孪生或真实场景的复制品中训练时，这个过程会变得很麻烦。高斯飞溅技术是一种强大的场景重建和新颖的视图合成技术，具有高保真度和渲染速度。本文介绍了GSAVS，一种支持自动驾驶汽车模型创建和开发的自动驾驶汽车模拟器。模拟器中的每个资产都是一个3D高斯平面图，包括车辆和环境。然而，模拟器在经典的3D引擎中运行，实时渲染3D高斯斑点。这使得模拟器能够利用3D高斯飞溅所拥有的真实感，同时提供经典3D引擎的定制和易用性。 et.al.|[2412.18816](http://arxiv.org/abs/2412.18816)|null|
|**2024-12-24**|**3DEnhancer: Consistent Multi-View Diffusion for 3D Enhancement**|尽管神经渲染取得了进展，但由于缺乏高质量的3D数据集和多视图扩散模型的固有局限性，视图合成和3D模型生成仅限于低分辨率和次优的多视图一致性。在这项研究中，我们提出了一种新的3D增强管道，称为3DEnhancer，它采用多视图潜在扩散模型来增强粗略的3D输入，同时保持多视图的一致性。我们的方法包括一个姿态感知编码器和一个基于扩散的去噪器，用于细化低质量的多视图图像，以及数据增强和一个具有极线聚合的多视图注意力模块，以保持视图之间一致的高质量3D输出。与现有的基于视频的方法不同，我们的模型支持无缝的多视图增强，提高了不同视角的连贯性。广泛的评估表明，3DEnhancer的性能明显优于现有的方法，可以增强多视图增强和每个实例的3D优化任务。 et.al.|[2412.18565](http://arxiv.org/abs/2412.18565)|null|
|**2024-12-24**|**RSGaussian:3D Gaussian Splatting with LiDAR for Aerial Remote Sensing Novel View Synthesis**|本研究提出了RSGaussian，这是一种用于航空遥感场景的创新型视图合成（NVS）方法，该方法将LiDAR点云作为约束纳入3D高斯散点法，确保高斯分布沿着几何基准生长和分裂，解决了过度生长和浮球问题。此外，该方法为相机模型引入了具有失真参数的坐标变换，以实现LiDAR点云和2D图像之间的像素级对齐，促进异构数据融合，实现航空遥感所需的高精度地理对齐。深度和平面一致性损失被纳入损失函数，以引导高斯向真实的深度和平面表示，显著提高了深度估计的准确性。实验结果表明，我们的方法实现了新的视图合成，在航空遥感数据集下平衡了照片级逼真的视觉质量和高精度的几何估计。最后，我们还建立并开源了一个密集的LiDAR点云数据集及其相应的航空多视图图像AIR-LONGYAN。 et.al.|[2412.18380](http://arxiv.org/abs/2412.18380)|null|
|**2024-12-23**|**FaceLift: Single Image to 3D Head with View Generation and GS-LRM**|我们介绍FaceLift，这是一种前馈方法，用于从单张图像中快速、高质量、360度重建头部。我们的管道首先采用多视图潜在扩散模型，该模型从单个面部输入生成一致的头部侧视图和后视图。这些生成的视图然后作为GS-LRM重建器的输入，该重建器使用高斯斑点生成全面的3D表示。为了训练我们的系统，我们使用合成的3D人头作为集合开发了一个多视图渲染数据集。基于扩散的多视图生成器仅在合成头部图像上进行训练，而GS-LRM重建器在Objaverse上进行初始训练，然后对合成头部数据进行微调。FaceLift擅长保护身份并保持视图之间的一致性。尽管FaceLift仅基于合成数据进行训练，但它对现实世界的图像表现出了出色的泛化能力。通过广泛的定性和定量评估，我们表明FaceLift在3D头部重建方面优于最先进的方法，突出了其在现实世界图像上的实用性和鲁棒性。除了单图像重建外，FaceLift还支持4D新颖视图合成的视频输入，并与2D复活技术无缝集成，以实现3D面部动画。项目页面：https://weijielyu.github.io/FaceLift. et.al.|[2412.17812](http://arxiv.org/abs/2412.17812)|null|
|**2024-12-23**|**Editing Implicit and Explicit Representations of Radiance Fields: A Survey**|近年来，神经辐射场（NeRF）通过提供一种新的体积表示法彻底改变了新颖的视图合成，这种表示法结构紧凑，可提供高质量的图像渲染。然而，编辑这些辐射场的方法比NeRF其他方面的许多改进发展得慢。随着受NeRF启发的基于辐射场的替代表示的最新发展，以及文本到图像模型在全球范围内的普及，出现了许多新的机会和策略来提供辐射场编辑。在本文中，我们对文献中NeRF和其他类似辐射场表示的不同编辑方法进行了全面的调查。我们提出了一种新的分类法，用于根据编辑方法对现有作品进行分类，回顾了开创性的模型，反思了辐射场编辑的当前和潜在的新应用，并在编辑选项和性能方面比较了最先进的方法。 et.al.|[2412.17628](http://arxiv.org/abs/2412.17628)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-12-25**|**WeatherGS: 3D Scene Reconstruction in Adverse Weather Conditions via Gaussian Splatting**|3D高斯散斑（3DGS）在3D场景重建方面受到了广泛关注，但仍然受到复杂室外环境的影响，尤其是在恶劣天气下。这是因为3DGS将恶劣天气造成的伪影视为场景的一部分，并将直接重建它们，大大降低了重建场景的清晰度。为了应对这一挑战，我们提出了WeatherGS，这是一种基于3DGS的框架，用于在不同天气条件下从多视图图像重建清晰的场景。具体来说，我们明确地将多天气伪影分为具有非常不同特征的密集颗粒和镜头遮挡，其中前者是由空气中的雪花和雨滴引起的，后者是由相机镜头上的降水引起的。鉴于此，我们提出了一种从密集到稀疏的预处理策略，该策略通过大气效应滤波器（AEF）顺序去除密集粒子，然后使用透镜效应检测器（LED）提取相对稀疏的遮挡掩模。最后，我们通过处理后的图像和生成的掩模来训练一组3D高斯分布，以排除遮挡区域，并通过高斯飞溅准确恢复底层清晰场景。我们进行了一个多样化且具有挑战性的基准测试，以促进在复杂天气场景下对3D重建的评估。对这一基准的广泛实验表明，我们的WeatherGS在各种天气场景中始终如一地生成高质量、干净的场景，优于现有的最先进的方法。请参阅项目页面：https://jumponthemoon.github.io/weather-gs. et.al.|[2412.18862](http://arxiv.org/abs/2412.18862)|null|
|**2024-12-24**|**PartGen: Part-level 3D Generation and Reconstruction with Multi-View Diffusion Models**|文本或图像到3D生成器和3D扫描仪现在可以生成具有高质量形状和纹理的3D资产。这些资产通常由一个单一的融合表示组成，如隐式神经场、高斯混合或网格，没有任何有用的结构。然而，大多数应用程序和创意工作流程都要求资产由几个可以独立操作的有意义的部分组成。为了解决这一差距，我们引入了PartGen，这是一种新颖的方法，可以从文本、图像或非结构化3D对象生成由有意义的部分组成的3D对象。首先，给定生成或渲染的3D对象的多个视图，多视图扩散模型提取一组合理且视图一致的零件分割，将对象划分为零件。然后，第二个多视图扩散模型分别获取每个部分，填充遮挡，并通过将这些完成的视图馈送到3D重建网络来使用它们进行3D重建。这个完成过程考虑了整个对象的上下文，以确保各部分紧密结合。生成完成模型可以弥补因遮挡而丢失的信息；在极端情况下，它可以根据输入的3D资源产生完全不可见的部分的幻觉。我们在生成的和真实的3D资产上评估了我们的方法，并表明它在很大程度上优于分割和零件提取基线。我们还展示了3D零件编辑等下游应用程序。 et.al.|[2412.18608](http://arxiv.org/abs/2412.18608)|null|
|**2024-12-24**|**Resolution-Robust 3D MRI Reconstruction with 2D Diffusion Priors: Diverse-Resolution Training Outperforms Interpolation**|由于3D训练数据的可用性有限，基于深度学习的3D成像，特别是磁共振成像（MRI）具有挑战性。因此，在2D切片上训练的2D扩散模型开始被用于3D MRI重建。然而，正如我们在本文中所展示的，现有的方法适用于固定的体素大小，当体素大小变化时，性能会下降，这在临床实践中经常发生。本文提出并研究了几种利用二维扩散先验进行分辨率鲁棒三维MRI重建的方法。作为这项研究的结果，我们获得了一种基于随机采样二维切片扩散引导正则化的简单分辨率鲁棒变分三维重建方法。与后验采样基线相比，该方法提供了有竞争力的重建质量。为了解决分辨率偏移的敏感性，我们研究了最先进的基于模型的方法，包括高斯飞溅、神经表示和无限维扩散模型，以及一种简单的以数据为中心的方法，在多种分辨率上训练扩散模型。我们的实验表明，基于模型的方法无法缩小3D MRI的性能差距。相比之下，以数据为中心的方法在各种分辨率上训练扩散模型，有效地提供了一种分辨率鲁棒的方法，而不会影响准确性。 et.al.|[2412.18584](http://arxiv.org/abs/2412.18584)|null|
|**2024-12-24**|**Sharper Error Bounds in Late Fusion Multi-view Clustering Using Eigenvalue Proportion**|多视图聚类（MVC）旨在整合来自多个视图的互补信息，以提高聚类性能。后期融合多视图聚类（LFMVC）通过将不同的聚类结果合成为统一的共识，展现出了巨大的潜力。然而，当前的LFMVC方法在噪声和冗余分区方面很困难，并且经常无法捕获视图之间的高阶相关性。为了解决这些局限性，我们提出了一种新的理论框架，利用局部Rademacher复杂性和主特征值比例来分析多核 $k$-means的泛化误差界。我们的分析建立了$\mathcal{O}（1/n）$的收敛率，在$\mathal{O}。基于这一认识，我们提出了一种在多重线性$k$ -means框架内的低通图滤波策略，以减轻噪声和冗余，进一步细化主特征值比例并提高聚类精度。在基准数据集上的实验结果证实，我们的方法在聚类性能和鲁棒性方面优于最先进的方法。相关代码可在以下网址获得https://github.com/csliangdu/GMLKM . et.al.|[2412.18207](http://arxiv.org/abs/2412.18207)|null|
|**2024-12-24**|**A Review of 3D Particle Tracking and Flow Diagnostics Using Digital Holography**|先进的三维（3D）跟踪方法对于研究各种复杂系统中的粒子动力学至关重要，包括多相流、环境和大气科学、胶体科学、生物和医学研究以及工业制造过程。本综述全面总结了使用数字全息术（DH）的3D粒子跟踪和流动诊断。我们首先介绍了DH的原理，并详细讨论了数值重建。然后，该综述探讨了DH中使用的各种硬件设置，包括内联、离轴和双视图或多视图配置，概述了它们的优点和局限性。我们还深入研究了不同的全息图处理方法，分为传统的多步、逆向和基于机器学习的方法，深入了解了它们在多个研究中用于3D粒子跟踪和流动诊断的应用。该综述最后讨论了未来前景，强调了机器学习在实现制造、环境监测和生物科学等不同领域的基于DH的精确粒子跟踪和流动诊断技术方面的重要作用。 et.al.|[2412.18094](http://arxiv.org/abs/2412.18094)|null|
|**2024-12-23**|**Cross-View Referring Multi-Object Tracking**|参考多目标跟踪（RMOT）是当前跟踪领域的一个重要课题。它的任务形式是引导跟踪器跟踪与语言描述匹配的对象。目前的研究主要集中在单视图下的多目标跟踪，指的是一个视图序列或多个不相关的视图序列。然而，在单一视图中，对象的某些外观很容易不可见，导致对象与语言描述的不正确匹配。在这项工作中，我们提出了一个新的任务，称为交叉视图参考多目标跟踪（CRMOT）。它引入了交叉视图来从多个视图中获取对象的外观，避免了RMOT任务中对象外观不可见的问题。CRMOT是一项更具挑战性的任务，即准确跟踪与语言描述匹配的对象，并保持每个交叉视图中对象的身份一致性。为了推进CRMOT任务，我们构建了一个基于CAMPUS和DIVOTrack数据集的交叉视图参考多目标跟踪基准，称为CRTrack。具体来说，它提供了13个不同的场景和221种语言描述。此外，我们提出了一种端到端的交叉视图参考多目标跟踪方法，称为CRTracker。在CRTrack基准上进行的大量实验验证了我们方法的有效性。数据集和代码可在https://github.com/chen-si-jia/CRMOT. et.al.|[2412.17807](http://arxiv.org/abs/2412.17807)|**[link](https://github.com/chen-si-jia/crmot)**|
|**2024-12-21**|**EasyVis2: A Real Time Multi-view 3D Visualization for Laparoscopic Surgery Training Enhanced by a Deep Neural Network YOLOv8-Pose**|EasyVis2是一个专为腹腔镜手术中的免提实时3D可视化而设计的系统。它包含一个配备有一组微型摄像头的手术套管针，这些摄像头插入体腔以提供扩大的视野和手术过程的3D透视图。YOLOv8-Pose是一种复杂的深度神经网络算法，专门用于估计每个单独相机视图中手术器械的位置和方向。随后，使用跨多个视图的相关2D关键点进行3D手术工具姿态估计。这使得能够渲染覆盖在观察到的背景场景上的手术工具的3D表面模型，以实现实时可视化。在这项研究中，我们解释了为新的手术工具开发训练数据集的过程，以定制YoLOv8姿势，同时最大限度地减少标记工作。进行了广泛的实验，将EasyVis2与原始EasyVis进行了比较，结果表明，在相同数量的相机下，新系统提高了3D重建精度并缩短了计算时间。此外，在真实动物组织上进行的3D渲染实验通过显示虚拟侧视图直观地展示了手术工具和组织之间的距离，表明了未来在真实手术中的潜在应用。 et.al.|[2412.16742](http://arxiv.org/abs/2412.16742)|null|
|**2024-12-21**|**LUCES-MV: A Multi-View Dataset for Near-Field Point Light Source Photometric Stereo**|最近，光度立体（PS）领域最大的改进来自于采用可微分体绘制技术，如NeRF或神经SDF，在DiLiGenT MV基准上实现了0.2mm的令人印象深刻的重建误差。然而，虽然有相当大的环境照明对象数据集，如数字孪生目录（DTS），但只有几个小的光度立体数据集，它们往往缺乏具有挑战性的对象（简单、平滑、无纹理）和实用的小形状因子（近场）光设置。为了解决这个问题，我们提出了LUCES-MV，这是第一个为近场点光源光度立体设计的真实世界多视图数据集。我们的数据集包括15个具有不同材料的物体，每个物体都是在不同的光照条件下从距离相机中心30到40厘米的15个LED阵列中成像的。为了促进透明的端到端评估，我们的数据集不仅提供地面真实法线和地面真实对象网格和姿态，还提供灯光和相机校准图像。我们评估了最先进的近场光度立体算法，强调了它们在不同材料和形状复杂性方面的优势和局限性。LUCES-MV数据集为开发更稳健、准确和可扩展的基于光度立体的真实世界3D重建方法提供了重要的基准。 et.al.|[2412.16737](http://arxiv.org/abs/2412.16737)|null|
|**2024-12-21**|**Context-Aware Outlier Rejection for Robust Multi-View 3D Tracking of Similar Small Birds in An Outdoor Aviary**|本文提出了一种使用多摄像机系统对室外鸟舍中的多只鸟类进行鲁棒3D跟踪的新方法。我们的方法通过利用环境地标进行增强的特征匹配和3D重建，解决了视觉上相似的鸟类及其快速运动的挑战。在我们的方法中，异常值根据其最近的地标被拒绝。这使得精确的3D建模和同时跟踪多只鸟成为可能。通过利用环境背景，我们的方法显著提高了视觉上相似的鸟类之间的区分，这是现有跟踪系统中的一个关键障碍。实验结果证明了我们的方法的有效性，在3D重建过程中消除了20%的异常值，匹配精度为97%。3D建模的这种非凡精度转化为对多只鸟类的稳健可靠跟踪，即使在具有挑战性的室外条件下也是如此。我们的工作不仅推进了计算机视觉领域的发展，而且为研究自然环境中的鸟类行为和运动模式提供了宝贵的工具。我们还提供了一个大型的带注释的数据集，包含80只栖息在四个围栏中的鸟类，持续20小时，为计算机视觉、鸟类学家和生态学家的研究人员提供了丰富的试验平台。代码和数据集链接可在https://github.com/airou-lab/3D_Multi_Bird_Tracking et.al.|[2412.16511](http://arxiv.org/abs/2412.16511)|**[link](https://github.com/airou-lab/3d_multi_bird_tracking)**|
|**2024-12-19**|**Generative Multiview Relighting for 3D Reconstruction under Extreme Illumination Variation**|从不同环境中拍摄的照片中重建物体的几何形状和外观是困难的，因为照明和物体外观在捕获的图像中会有所不同。对于外观强烈依赖于观察方向的镜面反射物体来说，这尤其具有挑战性。一些先前的方法使用每图像嵌入向量来模拟图像之间的外观变化，而另一些方法则使用基于物理的渲染来恢复材质和每图像照明。考虑到输入光照的显著变化，这种方法无法忠实地恢复与视图相关的外观，并且往往会产生大部分漫反射结果。我们提出了一种从不同照明下拍摄的图像重建对象的方法，该方法首先使用多视图重新照明扩散模型在单个参考照明下重新照明图像，然后使用对重新照明图像之间剩余的小不一致性具有鲁棒性的辐射场架构重建对象的几何形状和外观。我们在合成和真实数据集上验证了我们提出的方法，并证明它在从极端光照变化下拍摄的图像重建高保真外观方面大大优于现有技术。此外，我们的方法在恢复视图相关的“闪亮”外观方面特别有效，这些外观无法通过现有方法重建。 et.al.|[2412.15211](http://arxiv.org/abs/2412.15211)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-12-27**|**Periodically and aperiodically Thue-Morse driven long-range systems: from dynamical localization to slow dynamics**|我们研究了电场驱动的幂律随机带状矩阵（PLRBM）模型，其中幂律指数α的变化会产生离域到局域的相变。我们借助Floquet算子研究了周期驱动的PLRBM模型。Floquet哈密顿量的能级间距比和广义参与比揭示了在非驱动PLRBM模型的离域侧存在一个伴随着扩散输运的驱动诱导分形相。在局部化方面，时间周期模型保持局部化——平均间距比对应于泊松统计，在动力学中观察到对数输运。将我们的分析扩展到非周期性Thue-Morse（TM）驱动系统，我们发现非周期性驱动的清洁长程跳频模型（PLRBM模型的清洁对应物）在特定点调整驱动参数时表现出精确动态局部化（EDL）现象。无序时间非周期系统在离域侧表现出扩散输运，随后弛豫到无限温度状态，在局域侧表现出具有次扩散的预热平台。此外，我们将其与同样经历局域化-去局域化转变的准周期驱动的AAH模型进行了比较。与无序的长程模型不同，它具有一个延长的预热平台，然后再扩散到无限温度状态，即使在离域侧也是如此。 et.al.|[2412.19736](http://arxiv.org/abs/2412.19736)|null|
|**2024-12-27**|**A coupled mathematical and numerical model for protein spreading and tissue atrophy, applied to Alzheimer's disease**|本文的目的是在实践中介绍、分析和测试一种新的数学模型，该模型描述了病原体扩散驱动的生物组织萎缩之间的相互作用，并应用于神经退行性疾病。本研究介绍了一种新的数学和计算模型，该模型包括用于物种扩散的Fisher Kolmogorov方程和控制质量损失的弹性方程。这些方程通过指示介质质量减少的逻辑斯谛定律相互交织。该模型的一个潜在应用在于了解阿尔茨海默病的发病和发展。在这里，这些方程可以描述错误折叠的tau蛋白的传播以及随之而来的疾病脑萎缩特征。为了在数值上解决继承的复杂性，我们提出了一种在多边形/多面体网格上的多边形间断伽略金方法进行空间离散化，而时间积分则依赖于θ方法。我们提出了数学模型，深入研究了它的特点，并提出了离散化的应用。此外，本文还展示了收敛结果以验证该模型，并附有模拟，说明了阿尔茨海默病发作的应用场景。 et.al.|[2412.19661](http://arxiv.org/abs/2412.19661)|null|
|**2024-12-27**|**VideoMaker: Zero-shot Customized Video Generation with the Inherent Force of Video Diffusion Models**|零样本定制视频生成因其巨大的应用潜力而受到广泛关注。现有的方法依赖于附加的模型来提取和注入参考主题特征，假设单独的视频扩散模型（VDM）不足以生成零样本定制视频。然而，由于次优的特征提取和注入技术，这些方法往往难以保持一致的受试者外观。本文揭示了VDM固有地具有提取和注入主体特征的能力。与之前的启发式方法不同，我们引入了一种新颖的框架，该框架利用VDM的内在力量来实现高质量的零样本定制视频生成。具体来说，对于特征提取，我们直接将参考图像输入VDM并使用其固有的特征提取过程，这不仅提供了细粒度的特征，而且与VDM的预训练知识非常一致。对于特征注入，我们通过VDM中的空间自我关注，在主题特征和生成的内容之间设计了一种创新的双向交互，确保VDM在保持生成视频多样性的同时具有更好的主题保真度。在定制的人类和对象视频生成上的实验验证了我们框架的有效性。 et.al.|[2412.19645](http://arxiv.org/abs/2412.19645)|null|
|**2024-12-27**|**Stochastic resetting in a nonequilibrium environment**|本研究考察了随机重置下示踪粒子在非平衡介质中扩散的动力学。非平衡状态是由示踪剂和浴粒子之间的谐波耦合引起的，产生了随时间呈指数衰减的记忆效应。我们在泊松重置协议下探索示踪剂的行为，在该协议下，重置不会干扰浴环境，重点关注在有外力和没有外力的情况下，关键的动力学行为和第一通道特性。耦合强度和浴粒子扩散率之间的相互作用显著影响示踪剂的弛豫动力学和搜索时间，外力进一步调节这些影响。我们的分析根据其扩散率确定了不同的热浴和冷浴粒子，揭示了与热粒子的耦合有助于搜索过程，而与冷粒子的耦合则阻碍了搜索过程。通过结合数值模拟和分析方法，本研究为理解非马尔可夫系统中的重置机制提供了一个全面的框架，并可能应用于复杂的环境，如活性和粘弹性介质，其中记忆驱动的动力学和非平衡相互作用非常重要。 et.al.|[2412.19564](http://arxiv.org/abs/2412.19564)|null|
|**2024-12-27**|**Explicit propagation reversal bounds for bistable differential equations on trees**|本文给出了正则双无限树上双稳反应扩散方程的钉扎区和传播反转现象的显式描述。与光滑双稳态的一般存在性结果相反，通过选择分段线性McKean的漫画，可以实现闭式公式。我们构造了精确的钉扎波，并展示了它们的稳定性。结果与光滑双稳性的传播反转结果定性相似。主要的例外在于双稳态McKean漫画中钉扎区域的无限性。因此，对于任意大的扩散也会发生传播反转。 et.al.|[2412.19548](http://arxiv.org/abs/2412.19548)|null|
|**2024-12-27**|**StyleRWKV: High-Quality and High-Efficiency Style Transfer with RWKV-like Architecture**|风格转换旨在生成一个新的图像，保留内容，但具有风格来源的艺术表现力。现有的方法大多基于变换器或扩散模型，但存在二次计算复杂度高、推理时间长的问题。RWKV作为一种新兴的深度序列模型，在NLP任务中的长上下文序列建模方面显示出巨大的潜力。在这项工作中，我们提出了一种新的框架StyleRWKV，以有限的内存使用和线性时间复杂度实现高质量的风格转换。具体而言，我们提出了一种复发性WKV（Re-WKV）注意机制，该机制结合了双向注意，建立了一个全局感受野。此外，我们开发了一个可变形移位（Deform-Shifting）层，该层将可学习的偏移引入卷积核的采样网格，允许令牌从感兴趣的区域灵活自适应地移位，从而增强了模型捕获局部依赖关系的能力。最后，我们提出了一种跳过扫描（S扫描）方法，该方法有效地建立了全局上下文依赖关系。包括定性和定量评估在内的广泛分析实验表明，我们的方法在风格化质量、模型复杂性和推理效率方面优于最先进的方法。 et.al.|[2412.19535](http://arxiv.org/abs/2412.19535)|null|
|**2024-12-27**|**P3S-Diffusion:A Selective Subject-driven Generation Framework via Point Supervision**|最近关于主题驱动生成的研究越来越强调选择性主题特征的重要性。然而，准确选择给定参考图像中的内容仍然存在挑战，特别是在选择图像中相似的对象（例如，两只不同的狗）时。一些方法试图使用文本提示或像素掩码来隔离特定元素。然而，文本提示往往无法准确描述特定内容，像素掩码通常很昂贵。为了解决这个问题，我们引入了P3S扩散，这是一种新的架构，旨在通过点监督进行上下文选择的主题驱动生成。P3S Diffusion利用最小成本标签（例如点）生成受试者驱动的图像。在微调过程中，它可以从这些点生成扩展的基础掩模，从而不需要额外的分割模型。遮罩用于修复和对齐主题表示。P3S扩散通过多层条件注射保留了受试者的精细特征。通过改进训练的注意力一致性损失增强，广泛的实验证明了其出色的特征保存和图像生成能力。 et.al.|[2412.19533](http://arxiv.org/abs/2412.19533)|null|
|**2024-12-27**|**Lévy Score Function and Score-Based Particle Algorithm for Nonlinear Lévy--Fokker--Planck Equations**|扩散过程的分数函数，也称为对数密度梯度，是表征概率流的基本概念，在基于分数的扩散生成建模和随机微分方程的模拟中具有重要应用。然而，扩散跳跃过程的概率流和相应的得分函数都是未知的。本文提供了数学推导、数值算法和误差分析，重点研究了由非线性L'表示的具有跳跃和不连续性的非高斯系统中的相应得分函数{e}vy--Fokker--Planck方程。我们建议L{e}vy针对具有非局部双积分项的随机方程的得分函数，我们通过最小化样本中提出的损失函数来开发其训练算法。基于概率流与确定性动力学的等价性，我们开发了一种基于自洽分数的输运粒子算法来对交互式L’进行采样{e}vy离散时间网格点的随机过程。我们通过克服L中的非局部挑战，为数值概率密度函数和真概率密度函数之间的Kullback-Leibler散度提供了误差界{e}vy分数。进一步建立了蒙特卡洛误差和时间离散误差的全误差分析。为了证明我们的方法的有用性和效率，对生物学和金融应用中的数值例子进行了测试。 et.al.|[2412.19520](http://arxiv.org/abs/2412.19520)|null|
|**2024-12-27**|**Dynamical phase transitions in certain non-ergodic stochastic processes**|我们提出了一类随机过程，其中时间积分可观测值的大偏差函数表现出与轨迹动态相变相关的奇异性。这些说明性的例子包括具有死亡率或存在吸收壁的布朗运动，为此，我们考虑了一组经验可观测值，如净位移、局部时间、停留时间和轨迹下的面积。使用向后的福克-普朗克方法，我们推导出了这些可观测值的大偏差函数，并证明了奇点是如何从生存和扩散之间的竞争中产生的。此外，我们使用一种具有倾斜算子的替代方法来分析这种情况，表明在奇点处，有效动力学会发生突然转变。扩展这种方法，我们发现类似的转换可能会在具有瞬态的马尔可夫链中普遍出现。这种情况对于非马尔可夫动力学和多体系统来说是稳健和可推广的，可能会导致多个动力学相变。 et.al.|[2412.19516](http://arxiv.org/abs/2412.19516)|null|
|**2024-12-27**|**RobotDiffuse: Motion Planning for Redundant Manipulator based on Diffusion Model**|冗余机械手具有更高的自由度（DOF），可提供增强的运动学性能和多功能性，使其适用于制造、手术机器人和人机协作等应用。然而，由于自由度的增加和复杂的动态环境，这些机械手的运动规划具有挑战性。虽然传统的运动规划算法在高维空间中苦苦挣扎，但基于深度学习的方法在复杂任务中往往面临不稳定和效率低下的问题。本文介绍了RobotDiffuse，这是一种基于扩散模型的冗余度机械臂运动规划方法。通过将物理约束与点云编码器集成，并用仅编码器的转换器替换U-Net结构，RobotDiffuse提高了模型捕获时间依赖关系并生成更平滑、更连贯的运动计划的能力。我们使用复杂的模拟器验证了该方法，并发布了一个包含35M机器人姿态和0.14M避障场景的新数据集。实验结果证明了RobotDiffuse的有效性和扩散模型在运动规划任务中的应用前景。该代码可在以下网址访问https://github.com/ACRoboT-buaa/RobotDiffuse. et.al.|[2412.19500](http://arxiv.org/abs/2412.19500)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-12-26**|**Humans as a Calibration Pattern: Dynamic 3D Scene Reconstruction from Unsynchronized and Uncalibrated Videos**|最近关于动态神经场重建的工作假设输入来自具有已知姿势的同步多视图视频。这些输入约束在现实世界的设置中经常得不到满足，使得这种方法不切实际。我们证明，如果视频捕捉到人体运动，则姿态未知的非同步视频可以生成动态神经场。人类是最常见的动态主体之一，其姿势可以使用最先进的方法进行估计。在有噪声的情况下，估计的人体形状和姿态参数为训练一致的动态神经表示的高度非凸和欠约束问题提供了一个不错的初始化。给定人类的姿势和形状序列，我们估计视频之间的时间偏移，然后通过分析3D关节位置进行相机姿势估计。然后，我们使用多分辨率脊训练动态NeRF，同时细化时间偏移和相机姿态。该设置仍然涉及优化许多参数，因此，我们引入了一种鲁棒的渐进学习策略来稳定该过程。实验表明，我们的方法在具有挑战性的条件下实现了精确的时空校准和高质量的场景重建。 et.al.|[2412.19089](http://arxiv.org/abs/2412.19089)|null|
|**2024-12-24**|**PartGen: Part-level 3D Generation and Reconstruction with Multi-View Diffusion Models**|文本或图像到3D生成器和3D扫描仪现在可以生成具有高质量形状和纹理的3D资产。这些资产通常由一个单一的融合表示组成，如隐式神经场、高斯混合或网格，没有任何有用的结构。然而，大多数应用程序和创意工作流程都要求资产由几个可以独立操作的有意义的部分组成。为了解决这一差距，我们引入了PartGen，这是一种新颖的方法，可以从文本、图像或非结构化3D对象生成由有意义的部分组成的3D对象。首先，给定生成或渲染的3D对象的多个视图，多视图扩散模型提取一组合理且视图一致的零件分割，将对象划分为零件。然后，第二个多视图扩散模型分别获取每个部分，填充遮挡，并通过将这些完成的视图馈送到3D重建网络来使用它们进行3D重建。这个完成过程考虑了整个对象的上下文，以确保各部分紧密结合。生成完成模型可以弥补因遮挡而丢失的信息；在极端情况下，它可以根据输入的3D资源产生完全不可见的部分的幻觉。我们在生成的和真实的3D资产上评估了我们的方法，并表明它在很大程度上优于分割和零件提取基线。我们还展示了3D零件编辑等下游应用程序。 et.al.|[2412.18608](http://arxiv.org/abs/2412.18608)|null|
|**2024-12-23**|**S-INF: Towards Realistic Indoor Scene Synthesis via Scene Implicit Neural Field**|基于学习的方法在3D室内场景合成（ISS）中越来越受欢迎，显示出优于传统基于优化的方法的性能。这些基于学习的方法通常使用生成模型在简单但明确的场景表示上对分布进行建模。然而，由于过于简单的显式表示忽略了详细信息，并且缺乏场景内多模态关系的指导，大多数基于学习的方法都难以生成具有逼真对象排列和风格的室内场景。本文介绍了一种新的室内场景合成方法——场景隐式神经场（S-INF），旨在学习多模态关系的有意义表示，以提高室内场景合成的真实感。S-INF假设场景布局通常与对象详细信息有关。它将多模态关系分解为场景布局关系和详细对象关系，然后通过隐式神经场（INF）将它们融合在一起。通过学习专门的场景布局关系并将其投影到S-INF中，我们实现了场景布局的真实生成。此外，S-INF通过可微分渲染捕获密集而详细的对象关系，确保对象之间的风格一致性。通过在基准3D-FRONT数据集上的广泛实验，我们证明了我们的方法在不同类型的ISS下始终达到最先进的性能。 et.al.|[2412.17561](http://arxiv.org/abs/2412.17561)|**[link](https://github.com/zixiliang/s-inf)**|
|**2024-12-22**|**HyperNet Fields: Efficiently Training Hypernetworks without Ground Truth by Learning Weight Trajectories**|为了有效地适应大型模型或训练神经表示的生成模型，超网络引起了人们的兴趣。虽然超级网络工作良好，但训练它们很麻烦，而且通常需要为每个样本进行地面实况优化的权重。然而，获得这些权重中的每一个都是一个需要训练的训练问题，例如，适应权重，甚至是超网络回归的整个神经场。在这项工作中，我们提出了一种训练超网络的方法，而不需要任何每个样本的地面真实值。我们的关键思想是学习一个超网络“场”，并估计网络权重训练的整个轨迹，而不是简单地估计其收敛状态。换句话说，我们向超网络引入了一个额外的输入，即收敛状态，这使它成为一个神经场，对任务网络的整个收敛路径进行建模。这样做的一个关键好处是，在任何收敛状态下，估计权重的梯度都必须与原始任务的梯度相匹配——仅此约束就足以训练超网络场。我们通过个性化图像生成和从图像和点云进行3D形状重建的任务来证明我们的方法的有效性，在没有任何样本地面真实性的情况下展示了具有竞争力的结果。 et.al.|[2412.17040](http://arxiv.org/abs/2412.17040)|null|
|**2024-12-20**|**CCNDF: Curvature Constrained Neural Distance Fields from 3D LiDAR Sequences**|神经距离场（NDF）已成为解决3D计算机视觉和图形下游问题的有力工具。虽然在从各种传感器数据中学习NDF方面取得了重大进展，但需要注意的一个关键方面是在训练过程中对神经场的监督，因为地面真实NDF不适用于大规模户外场景。以往的工作利用各种形式的预期符号距离来指导模型学习。然而，这些方法通常需要更多地关注表面几何形状的关键考虑因素，并且仅限于小规模实施。为此，我们提出了一种利用带符号距离场的二阶导数来改进神经场学习的新方法。我们的方法通过准确估计符号距离来解决局限性，从而更全面地了解底层几何。为了评估我们的方法的有效性，我们对NDF的主要应用领域——测绘和定位任务的流行方法进行了比较评估。我们的结果证明了所提出方法的优越性，突出了其在计算机视觉和图形应用中提高神经距离场能力的潜力。 et.al.|[2412.15909](http://arxiv.org/abs/2412.15909)|null|
|**2024-12-19**|**SolidGS: Consolidating Gaussian Surfel Splatting for Sparse-View Surface Reconstruction**|高斯飞溅在新颖的视图合成和多视图图像的表面重建方面都取得了令人印象深刻的改进。然而，目前的方法仍然难以使用高斯飞溅从稀疏的视图输入图像中重建高质量的表面。在本文中，我们提出了一种名为SolidGS的新方法来解决这个问题。我们观察到，由于几何渲染中高斯函数的特性，重建的几何在多个视图之间可能会严重不一致。这促使我们通过采用更坚实的核函数来整合所有高斯函数，从而有效地提高了曲面重建质量。在几何正则化和单目法线估计的额外帮助下，我们的方法在稀疏视图曲面重建方面取得了比广泛使用的DTU、Tanks和Temples以及LLFF数据集上的所有高斯溅射方法和神经场方法更优越的性能。 et.al.|[2412.15400](http://arxiv.org/abs/2412.15400)|null|
|**2024-12-19**|**LiftRefine: Progressively Refined View Synthesis from 3D Lifting with Volume-Triplane Representations**|我们提出了一种新的视图合成方法，通过从单个或少数视图输入图像合成3D神经场。为了解决图像到3D生成问题的不适定性质，我们设计了一种两阶段方法，该方法涉及重建模型和用于视图合成的扩散模型。我们的重建模型首先将一个或多个输入图像从体积提升到3D空间，作为粗尺度3D表示，然后是三平面作为细尺度3D表示。为了减轻遮挡区域的模糊性，我们的扩散模型会在三个平面的渲染图像中产生缺失细节的幻觉。然后，我们引入了一种新的渐进式细化技术，该技术迭代地应用重建和扩散模型来逐步合成新的视图，提高了3D表示及其渲染的整体质量。实证评估表明，我们的方法在合成SRN-Car数据集、野外CO3D数据集和大规模Objaverse数据集上优于最先进的方法，同时实现了采样效率和多视图一致性。 et.al.|[2412.14464](http://arxiv.org/abs/2412.14464)|null|
|**2024-12-18**|**Level-Set Parameters: Novel Representation for 3D Shape Analysis**|3D形状分析主要集中在点云和网格的传统3D表示上，但这些数据的离散性使得分析容易受到输入分辨率变化的影响。神经场的最新发展从带符号距离函数中引入了水平集参数，作为3D形状的新颖、连续和数值表示，其中形状表面被定义为这些函数的零水平集。这促使我们将形状分析从传统的3D数据扩展到这些新的参数数据。由于水平集参数不是类似欧几里德的点云，我们通过将它们表示为伪正态分布来建立不同形状之间的相关性，并从相应的数据集中预先学习分布。为了进一步探索具有形状变换的水平集参数，我们建议将这些参数的子集设置在旋转和平移上，并使用超网络生成它们。与使用传统数据相比，这简化了与姿势相关的形状分析。我们通过在形状分类（任意姿态）、检索和6D对象姿态估计中的应用，展示了新表示法的前景。本研究中的代码和数据见https://github.com/EnyaHermite/LevelSetParamData. et.al.|[2412.13502](http://arxiv.org/abs/2412.13502)|null|
|**2024-12-13**|**Neural Vector Tomography for Reconstructing a Magnetization Vector Field**|矢量断层重建的离散化技术容易在重建中产生伪影。随着噪声量的增加，这些重建的质量可能会进一步恶化。在这项工作中，我们使用平滑神经场对底层向量场进行建模。由于神经网络中的激活函数可以被选择为平滑的，并且域不再像素化，因此即使在存在噪声的情况下，该模型也能得到高质量的重建。在我们具有潜在的全局连续对称性的情况下，我们发现神经网络比现有技术大大提高了重建的准确性。 et.al.|[2412.09927](http://arxiv.org/abs/2412.09927)|null|
|**2024-12-12**|**PBR-NeRF: Inverse Rendering with Physics-Based Neural Fields**|我们使用基于物理的渲染（PBR）理论的神经辐射场（NeRF）方法来解决3D重建中的不适定逆渲染问题，称为PBR-NeRF。我们的方法解决了大多数NeRF和3D高斯散斑方法的一个关键局限性：它们在不建模场景材质和照明的情况下估计与视图相关的外观。为了解决这一局限性，我们提出了一种能够联合估计场景几何形状、材质和照明的逆渲染（IR）模型。我们的模型建立在最近基于NeRF的IR方法的基础上，但关键是引入了两种新的基于物理的先验，更好地约束了IR估计。我们的先验被严格地表述为直观的损失项，在不影响新颖视图合成质量的情况下实现了最先进的材料估计。我们的方法很容易适应其他需要材料估计的逆渲染和3D重建框架。我们展示了将当前的神经渲染方法扩展到完全建模场景属性的重要性，而不仅仅是几何和视图相关的外观。代码可在以下网址公开获取https://github.com/s3anwu/pbrnerf et.al.|[2412.09680](http://arxiv.org/abs/2412.09680)|**[link](https://github.com/s3anwu/pbrnerf)**|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

