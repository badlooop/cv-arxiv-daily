---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.06.27
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-25**|**NerfBaselines: Consistent and Reproducible Evaluation of Novel View Synthesis Methods**|新颖的视图合成是许多应用中的一个重要问题，包括AR/VR、游戏和机器人模拟。随着神经辐射场（NeRF）和3D高斯散射（3DGS）方法的快速发展，由于使用不同评估协议的方法、难以安装和使用的代码库以及不能很好地推广到新的3D场景的方法，跟踪当前技术状态（SoTA）变得越来越困难。我们的实验支持了这一说法，表明各种方法的评估协议之间的微小差异可能导致报告的指标不一致。为了解决这些问题，我们提出了一个名为NerfBaselines的框架，它简化了各种方法的安装，提供了一致的基准测试工具，并确保了可重复性。我们通过复制原始论文中报告的数字来实验验证我们的实现。为了进一步提高可访问性，我们发布了一个网络平台，在标准基准上对常用方法进行比较。网状物https://jkulhanek.com/nerfbaselines et.al.|[2406.17345](http://arxiv.org/abs/2406.17345)|null|
|**2024-06-24**|**Reducing the Memory Footprint of 3D Gaussian Splatting**|3D高斯飞溅为新颖的视图合成提供了卓越的视觉质量，具有快速训练和实时渲染；不幸的是，这种方法对存储和传输的内存要求非常高。我们首先分析了原因，确定了可以减少存储的三个主要区域：用于表示场景的3D高斯基元的数量、用于表示方向辐射的球面谐波的系数数量以及存储高斯基元属性所需的精度。我们提出了每一个问题的解决方案。首先，我们提出了一种高效的、具有分辨率意识的原始修剪方法，将原始计数减少一半。其次，我们引入了一种自适应调整方法来选择用于表示每个高斯基元的方向辐射的系数数量，最后引入了一个基于码本的量化方法，以及用于进一步减少内存的半浮点表示。总之，这三个组件使我们测试的标准数据集的磁盘总大小减少了27，同时渲染速度加快了1.7。我们在标准数据集上演示了我们的方法，并展示了在移动设备上使用该方法时，我们的解决方案如何显著缩短下载时间。 et.al.|[2406.17074](http://arxiv.org/abs/2406.17074)|null|
|**2024-06-24**|**Articulate your NeRF: Unsupervised articulated object modeling via conditional view synthesis**|我们提出了一种新的无监督方法来学习具有刚性零件的关节对象的姿态和零件分割。给定一个物体在不同关节状态下的两个观察结果，我们的方法通过使用第一个观察结果的隐式模型来学习物体零件的几何形状和外观，从第二个观察结果中提取零件分割和关节，同时呈现后一个观察结果。此外，为了解决零件分割和连接联合优化的复杂性，我们提出了一种基于体素网格的初始化策略和解耦优化程序。与先前的无监督工作相比，我们的模型获得了显著更好的性能，并推广到具有多个部分的对象，同时它可以有效地从少数视图进行后期观察。 et.al.|[2406.16623](http://arxiv.org/abs/2406.16623)|null|
|**2024-06-24**|**Crowd-Sourced NeRF: Collecting Data from Production Vehicles for 3D Street View Reconstruction**|最近，神经辐射场（NeRF）在新的视图合成中取得了令人印象深刻的结果。Block NeRF展示了利用NeRF构建大城市规模模型的能力。对于大规模建模，需要大量的图像数据。从专门设计的数据采集车上采集图像无法支持大规模应用。如何获取大量高质量的数据仍然是一个悬而未决的问题。注意到汽车行业拥有大量的图像数据，众包是大规模数据收集的便捷方式。在本文中，我们提出了一个众包框架，该框架利用生产车辆捕获的大量数据来使用NeRF模型重建场景。这种方法解决了大规模重建的关键问题，即数据来自哪里以及如何使用它们。首先，对众包海量数据进行过滤，以消除冗余，并在时间和空间上保持平衡分布。然后执行来自运动模块的结构来细化相机姿态。最后，使用图像以及姿势来训练某个块中的NeRF模型。我们强调，我们提出了一个综合框架，集成了多个模块，包括数据选择、稀疏3D重建、序列外观嵌入、地表深度监测和遮挡完成。完整的系统能够从众包数据中有效地处理和重建高质量的3D场景。进行了大量的定量和定性实验来验证我们的系统的性能。此外，我们提出了一个名为“第一视角导航”的应用程序，该应用程序利用NeRF模型生成3D街景，并用合成视频引导驾驶员。 et.al.|[2406.16289](http://arxiv.org/abs/2406.16289)|null|
|**2024-06-23**|**LiveScene: Language Embedding Interactive Radiance Fields for Physical Scene Rendering and Control**|本文旨在通过将交互式对象重构从单一对象层次扩展到复杂场景层次，推动物理世界交互式场景重构的进展。为此，我们首先构建了一个模拟和一个真实场景级的物理交互数据集，该数据集包含28个场景，每个场景具有多个交互对象。此外，为了准确地建模复杂场景中多个对象的交互运动，我们提出了LiveScene，这是第一个场景级语言嵌入的交互式神经辐射场，可以有效地重建和控制复杂场景中的多个交互对象。LiveScene引入了一种高效的因子分解，将交互式场景分解为多个局部可变形场，以单独重构单个交互式对象，实现了对复杂场景中多个交互式对象的首次精确独立控制。此外，我们引入了一种感知交互的语言嵌入方法，该方法生成不同的语言嵌入，以在不同的交互状态下定位各个交互对象，从而能够使用自然语言任意控制交互对象。最后，我们在构建的数据集OminiSim和InterReal上评估LiveScene，这些数据集具有各种模拟和真实世界的复杂场景。大量的实验结果表明，该方法实现了SOTA新的视图合成和语言基础性能，在CoNeRF Synthetic、OminiSim#通道和InterReal#通道数据集上的PSNR分别超过现有方法+9.89、+1.30和+1.99，在OminiSim上的mIOU分别超过了现有方法+65.12。项目页面：\ href{https://livescenes.github.io}{https://livescenes.github.io}. et.al.|[2406.16038](http://arxiv.org/abs/2406.16038)|null|
|**2024-06-21**|**Taming 3DGS: High-Quality Radiance Fields with Limited Resources**|三维高斯散点（3DGS）以其快速、可解释和高保真的渲染方式改变了新的视图合成，但其资源需求限制了其可用性。特别是在受约束的设备上，由于模型的过度内存消耗，训练性能会迅速下降，而且往往无法完成。该方法与不确定数量的高斯收敛——其中许多是冗余的——这使得渲染变得不必要地慢，并阻止了它在期望固定大小输入的下游任务中的使用。为了解决这些问题，我们在预算内解决训练和渲染3DGS模型的挑战。我们使用了一种有指导的、纯粹建设性的致密化过程，将致密化引向高斯，从而提高重建质量。模型大小以可控的方式不断增加，以达到精确的预算，使用基于分数的高斯密度和测量其贡献的训练时间先验。我们进一步解决了训练速度障碍：在仔细分析3DGS的原始管道后，我们导出了用于梯度计算和属性更新的更快、数值等效的解决方案，包括用于高效反向传播的替代并行化。我们还提出了在适当的情况下保持质量的近似值，以进一步减少训练时间。总之，这些增强功能提供了一个强健、可扩展的解决方案，减少了训练时间，降低了计算和内存需求，并具有高质量。我们的评估表明，在预算设置中，我们使用3DGS获得了有竞争力的质量指标，同时实现了模型大小和训练时间的4-5倍减少。有了更慷慨的预算，我们的衡量质量超过了他们。这些进步为受限环境（例如移动设备）中的新型视图合成打开了大门。 et.al.|[2406.15643](http://arxiv.org/abs/2406.15643)|null|
|**2024-06-21**|**E2GS: Event Enhanced Gaussian Splatting**|事件摄像机以其高动态范围、无运动模糊和低能耗而闻名，由于这些特性，最近得到了广泛的应用。在过去的几年里，基于事件的三维重建领域取得了显著进展，基于神经辐射场（NeRF）的方法展示了真实感视图合成的结果。然而，NeRF的体绘制范式需要大量的训练和绘制时间。在本文中，我们介绍了事件增强高斯散射（E2GS），这是一种将事件数据合并到高斯散射中的新方法，最近在新视图合成领域取得了重大进展。我们的E2GS有效地利用了模糊图像和事件数据，显著改善了图像去模糊，并产生了高质量的新视图合成。我们在合成和真实世界数据集上的全面实验表明，我们的E2GS可以生成视觉上吸引人的渲染，同时提供更快的训练和渲染速度（140 FPS）。我们的代码可在https://github.com/deguchihiroyuki/E2GS. et.al.|[2406.14978](http://arxiv.org/abs/2406.14978)|**[link](https://github.com/deguchihiroyuki/e2gs)**|
|**2024-06-21**|**Relighting Scenes with Object Insertions in Neural Radiance Fields**|将对象插入场景和重新照明是增强现实（AR）中常用的应用。以前的方法侧重于使用CAD模型插入虚拟对象或从单视图图像中插入真实对象，导致AR应用场景非常有限。我们提出了一种新的基于NeRF的管道，用于将对象NeRF插入场景NeRF，实现新的视图合成和逼真的重新照明，支持物理交互，如从描绘对象和场景的两组图像中相互投射阴影。照明环境是球面谐波和球面高斯的混合表示，非常好地表示了高频和低频照明组件，并支持非朗伯曲面。具体而言，我们利用体积渲染的优势，通过比较相机视图和光源视图之间的深度图并生成生动的软阴影，引入了一种高效阴影渲染的创新方法。所提出的方法在广泛的实验评估中实现了现实的再照明效果。 et.al.|[2406.14806](http://arxiv.org/abs/2406.14806)|null|
|**2024-06-20**|**Deblurring Neural Radiance Fields with Event-driven Bundle Adjustment**|神经辐射场（NeRF）以高质量的多视图图像作为输入，实现了令人印象深刻的3D表示学习和新颖的视图合成结果。然而，图像中的运动模糊经常发生在低光照和高速运动场景中，这显著降低了NeRF的重建质量。以前的去模糊NeRF方法难以估计曝光时间内的信息，无法准确地对运动模糊进行建模。相比之下，以高时间分辨率测量强度变化的仿生事件相机弥补了这一信息不足。在本文中，我们提出了用于去模糊神经辐射场的事件驱动束调整（EBAD NeRF），以通过利用混合事件RGB数据来联合优化可学习姿态和NeRF参数。引入强度变化度量事件损失和照片度量模糊损失来加强相机运动模糊的显式建模。对合成数据和真实捕获数据的实验结果表明，与先前的工作相比，EBAD NeRF可以在曝光时间内获得准确的相机姿态，并学习更清晰的3D表示。 et.al.|[2406.14360](http://arxiv.org/abs/2406.14360)|null|
|**2024-06-19**|**Simultaneous Map and Object Reconstruction**|在本文中，我们提出了一种利用激光雷达对大规模城市场景进行动态表面重建的方法。基于深度的重建往往侧重于小规模对象或将移动对象视为异常值的大规模SLAM重建。我们采用整体视角，优化动态场景的组成模型，将世界分解为刚性移动的对象和背景。为了实现这一点，我们从最近的新颖视图合成方法中获得灵感，并将重建问题作为全局优化，最小化我们预测的表面和输入激光雷达扫描之间的距离。我们展示了如何将这种全局优化分解为配准和表面重建步骤，这些步骤可以通过现成的方法很好地处理，而无需任何重新训练。通过对连续时间运动进行仔细建模，我们的重建可以补偿旋转激光雷达传感器的滚动快门效应。这允许第一个系统（据我们所知）对刚性移动物体的激光雷达扫描进行适当的运动补偿，补充了广泛使用的静态场景运动补偿技术。除了将动态重建本身作为一个目标之外，我们还表明，这样的系统可以用于自动标记部分注释的序列，并为难以标记的问题（如深度完成和场景流）生成地面实况注释。 et.al.|[2406.13896](http://arxiv.org/abs/2406.13896)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-25**|**Unified Auto-Encoding with Masked Diffusion**|在成功的生成和自我监督表示学习模型的核心，都有一个包含某种形式的图像腐败的重建目标。扩散模型通过预定的高斯破坏过程来实现这种方法，而掩蔽的自动编码器模型则通过掩蔽图像的块来实现。尽管它们的方法不同，但它们方法的潜在相似性为能够同时执行去噪任务的自动编码器提供了一条很有前途的途径。我们提出了一个统一的自监督目标，称为统一掩蔽扩散（UMD），它将基于补丁和基于噪声的破坏技术结合在一个单独的自动编码框架内。具体而言，UMD通过在扩散噪声调度中引入额外的无噪声、高掩蔽表示步骤来修改扩散变换器（DiT）训练过程，并将掩蔽和噪声的混合图像用于后续的时间步长。通过集成对扩散建模和预测屏蔽补丁令牌有用的特征，UMD在下游生成和表示学习任务中实现了强大的性能，包括线性探测和类条件生成。这是在不需要大量数据扩充、多视图或额外编码器的情况下实现的。此外，UMD在总训练时间上提高了先前基于扩散的方法的计算效率。我们在发布代码https://github.com/philippe-eecs/small-vision. et.al.|[2406.17688](http://arxiv.org/abs/2406.17688)|null|
|**2024-06-25**|**Test-Time Generative Augmentation for Medical Image Segmentation**|在本文中，我们提出了一种在测试期间增强医学图像分割的新方法。我们主张使用高级域微调生成模型（GM），例如稳定扩散（SD）来增加测试时间，而不是在输入测试图像上使用手工制作的变换或函数来创建多个视图以增加测试时间。考虑到GM已经被训练来理解和封装全面的领域数据知识，它在表示数据特征和分布方面优于分割模型。因此，通过将GM集成到测试时间扩充中，我们可以有效地生成给定测试样本的多个视图，与样本的内容和外观特征以及相关的局部数据分布保持一致。与传统的手工转换相比，这种方法使增强过程更具适应性和弹性。在三个医学图像分割任务（九个数据集）上进行的综合实验证明了所提出的TTGA在增强分割结果方面的有效性和多功能性。此外，TTGA显著提高了像素误差估计，从而有助于部署更可靠的分割系统。代码将在以下位置发布：https://github.com/maxiao0234/TTGA. et.al.|[2406.17608](http://arxiv.org/abs/2406.17608)|**[link](https://github.com/maxiao0234/ttga)**|
|**2024-06-25**|**SyncNoise: Geometrically Consistent Noise Prediction for Text-based 3D Scene Editing**|基于文本的二维扩散模型在图像生成和编辑方面表现出了令人印象深刻的能力。同时，2D扩散模型也表现出用于3D编辑任务的巨大潜力。然而，如何在多个视点之间实现一致的编辑仍然是一个挑战。虽然迭代数据集更新方法能够实现全局一致性，但它存在收敛缓慢和纹理过度平滑的问题。我们提出了SyncNoise，这是一种新颖的几何引导的多视图一致性噪声编辑方法，用于高保真3D场景编辑。SyncNoise使用2D扩散模型同步编辑多个视图，同时强制多视图噪声预测保持几何一致，从而确保语义结构和低频外观的全局一致性。为了进一步增强高频细节的局部一致性，我们设置了一组锚视图，并通过跨视图重投影将它们传播到相邻的帧。为了提高多视图对应的可靠性，我们在训练过程中引入了深度监督，以增强精确几何形状的重建。我们的方法通过增强噪声和像素级别的几何一致性，在尊重文本指令的情况下，特别是在具有复杂纹理的场景中，实现了高质量的3D编辑结果。 et.al.|[2406.17396](http://arxiv.org/abs/2406.17396)|null|
|**2024-06-24**|**Crowd-Sourced NeRF: Collecting Data from Production Vehicles for 3D Street View Reconstruction**|最近，神经辐射场（NeRF）在新的视图合成中取得了令人印象深刻的结果。Block NeRF展示了利用NeRF构建大城市规模模型的能力。对于大规模建模，需要大量的图像数据。从专门设计的数据采集车上采集图像无法支持大规模应用。如何获取大量高质量的数据仍然是一个悬而未决的问题。注意到汽车行业拥有大量的图像数据，众包是大规模数据收集的便捷方式。在本文中，我们提出了一个众包框架，该框架利用生产车辆捕获的大量数据来使用NeRF模型重建场景。这种方法解决了大规模重建的关键问题，即数据来自哪里以及如何使用它们。首先，对众包海量数据进行过滤，以消除冗余，并在时间和空间上保持平衡分布。然后执行来自运动模块的结构来细化相机姿态。最后，使用图像以及姿势来训练某个块中的NeRF模型。我们强调，我们提出了一个综合框架，集成了多个模块，包括数据选择、稀疏3D重建、序列外观嵌入、地表深度监测和遮挡完成。完整的系统能够从众包数据中有效地处理和重建高质量的3D场景。进行了大量的定量和定性实验来验证我们的系统的性能。此外，我们提出了一个名为“第一视角导航”的应用程序，该应用程序利用NeRF模型生成3D街景，并用合成视频引导驾驶员。 et.al.|[2406.16289](http://arxiv.org/abs/2406.16289)|null|
|**2024-06-23**|**MLPHand: Real Time Multi-View 3D Hand Mesh Reconstruction via MLP Modeling**|多视图手部网格重建是虚拟现实和人机交互应用中的一项关键任务，但它仍然是一项艰巨的挑战。尽管现有的多视角手部重建方法实现了显著的准确性，但它们通常会带来巨大的计算负担，阻碍实时推理。为此，我们提出了MLPHand，这是一种用于实时多视图单手重建的新方法。MLP-Hand由两个主要模块组成：（1）一个基于MLP的轻量级Skeleton2Mesh模型，可有效地从手部骨骼中恢复手部网格；（2）一个多视图几何特征融合预测模块，可利用来自多个视图的详细几何信息增强Skeleton4Mesh模型。在三个广泛使用的数据集上的实验表明，MLPHand可以将计算复杂度降低90%，同时实现与现有最先进基线相当的重建精度。 et.al.|[2406.16137](http://arxiv.org/abs/2406.16137)|null|
|**2024-06-23**|**Learning with Noisy Ground Truth: From 2D Classification to 3D Reconstruction**|深度神经网络在数据密集型计算机视觉应用中取得了巨大成功，而这种成功在很大程度上依赖于大量干净的数据。在现实世界中，有时很难获得干净的数据。例如，在图像分类和分割任务中，数百万个样本的精确注释通常非常昂贵和耗时。在3D静态场景重建任务中，大多数与NeRF相关的方法都需要对静态场景进行基本假设（例如，一致的照明条件和持久的物体位置），这在现实世界的场景中经常被违反。为了解决这些问题，带噪声地面实况学习（LNGT）已成为一种有效的学习方法，并显示出巨大的潜力。在这项简短的调查中，我们提出了一个正式的定义，将LNGT-LNGT的分析统一到不同机器学习任务（分类和回归）的背景下。基于这一定义，我们提出了一种新的分类法，根据机器学习的基本定义，根据误差分解对现有工作进行分类。此外，我们对记忆效应进行了深入分析，并对未来从2D分类到3D重建的潜在研究机会进行了深入讨论，希望为后续研究提供指导。 et.al.|[2406.15982](http://arxiv.org/abs/2406.15982)|null|
|**2024-06-22**|**psPRF:Pansharpening Planar Neural Radiance Field for Generalized 3D Reconstruction Satellite Imagery**|目前大多数卫星NeRF变体都是针对一个特定场景设计的，无法推广到新的几何结构。此外，RGB图像需要平移锐化作为独立的预处理步骤。本文介绍了psPRF，这是一种平面神经辐射场，用于使用有理多项式相机（RPC）从卫星传感器获得的成对低分辨率RGB（LR-RGB）和高分辨率全色（HR-PAN）图像。为了从LR-RGB和HR-PAN图像中捕获跨模态先验，对于Unet形结构，我们将编码器与显式频谱到空间卷积（SSConv）相适应，以增强多模态表示能力。为了支持psRPF跨场景的泛化能力，我们采用了投影损失来确保强大的几何自监督。使用多场景WorldView-3 LR-RGB和HR-PAN对对所提出的方法进行了评估，并实现了最先进的性能。 et.al.|[2406.15707](http://arxiv.org/abs/2406.15707)|null|
|**2024-06-21**|**E2GS: Event Enhanced Gaussian Splatting**|事件摄像机以其高动态范围、无运动模糊和低能耗而闻名，由于这些特性，最近得到了广泛的应用。在过去的几年里，基于事件的三维重建领域取得了显著进展，基于神经辐射场（NeRF）的方法展示了真实感视图合成的结果。然而，NeRF的体绘制范式需要大量的训练和绘制时间。在本文中，我们介绍了事件增强高斯散射（E2GS），这是一种将事件数据合并到高斯散射中的新方法，最近在新视图合成领域取得了重大进展。我们的E2GS有效地利用了模糊图像和事件数据，显著改善了图像去模糊，并产生了高质量的新视图合成。我们在合成和真实世界数据集上的全面实验表明，我们的E2GS可以生成视觉上吸引人的渲染，同时提供更快的训练和渲染速度（140 FPS）。我们的代码可在https://github.com/deguchihiroyuki/E2GS. et.al.|[2406.14978](http://arxiv.org/abs/2406.14978)|**[link](https://github.com/deguchihiroyuki/e2gs)**|
|**2024-06-19**|**MVSBoost: An Efficient Point Cloud-based 3D Reconstruction**|高效准确的3D重建对于各种应用至关重要，包括增强现实和虚拟现实、医学成像和电影特效。虽然传统的多视图立体（MVS）系统在这些应用中是基础，但在隐式3D场景建模中使用神经隐式场为处理复杂拓扑和连续曲面带来了新的可能性。然而，神经隐式场往往存在计算效率低、过拟合和严重依赖数据质量的问题，限制了其实际应用。本文提出了一种增强的MVS框架，该框架通过运动结构（SfM）和用于点云致密化、网格重建和纹理化的高级图像处理，将多视图360度图像与稳健的相机姿态估计相结合。我们的方法显著改进了传统的MVS方法，在真实合成360数据集上使用切角距离度量进行验证，提供了卓越的准确性和精度。所开发的MVS技术增强了3D重建的细节和清晰度，并在复杂场景重建中展示了卓越的计算效率和稳健性，有效地处理了遮挡和不同的视点。这些改进表明，我们的MVS框架可以与当前最先进的神经隐场方法竞争，并有可能超越这些方法，尤其是在需要实时处理和可扩展性的场景中。 et.al.|[2406.13515](http://arxiv.org/abs/2406.13515)|null|
|**2024-06-19**|**Assessing the 3D resolution of refocused correlation plenoptic images using a general-purpose image quality estimator**|相关全光成像（CPI）是一种很有前途的光场成像（LFI）方法，这是一种能够同时测量场景中光强分布和传播方向的技术。LFI允许单次3D采样，为广泛的应用提供快速的3D重建。然而，LFI中通常用于获得3D信息的微透镜阵列限制了图像分辨率，图像分辨率随着体积重建能力的增强而迅速下降。CPI通过使用两个具有空间分辨率的光电探测器来解耦光场信息测量，从而消除了对微透镜的需求，从而解决了这一限制。3D信息被编码在四维相关函数中，该函数在后处理中被解码以重建图像，而没有传统LFI中看到的分辨率损失。本文评估了CPI的断层成像性能，证明了重新聚焦重建方法提供了与传统成像系统相当的轴向切片能力。提出了一种基于图像保真度的通用分析方法来定量研究轴向和横向分辨率。该分析充分表征了任何CPI架构的体积分辨率，提供了对其成像性能的全面评估。 et.al.|[2406.13501](http://arxiv.org/abs/2406.13501)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-25**|**DiffusionPDE: Generative PDE-Solving Under Partial Observation**|我们介绍了一个使用生成扩散模型求解偏微分方程的通用框架。特别是，我们关注的场景是，我们不具备应用经典解算器所需的全部场景知识。当对数据或基础系数的观测不完整时，大多数现有的正向或反向PDE方法表现不佳，这是真实世界测量的常见假设。在这项工作中，我们提出了DiffusionPDE，它可以同时填充缺失的信息，并通过对解和系数空间的联合分布进行建模来求解PDE。我们表明，学习的生成先验为在部分观测下准确求解广泛的偏微分方程提供了一个通用的框架，在正向和反向方向上都显著优于最先进的方法。 et.al.|[2406.17763](http://arxiv.org/abs/2406.17763)|null|
|**2024-06-25**|**Fairness in Social Influence Maximization via Optimal Transport**|我们研究了社会影响力最大化的公平性，即人们试图选择在整个网络中传播给定信息的种子，确保不同社区（如人口群体）之间的均衡外联。在文献中，公平性往往是根据个体社区内的预期外联来量化的。在本文中，我们证明了这种公平性度量可能具有误导性，因为它们忽略了信息扩散过程的随机性。当信息传播以概率的方式发生时，可能会出现多种外联场景。因此，诸如“在50%的情况下，第1组中没有人收到信息，第2组中的每个人都收到了信息，而在其他50%的情况中，情况正好相反”之类的结果，总是导致很大程度上不公平的结果，在文献中被各种公平性指标归类为公平。我们通过设计一种新的公平指标——相互公平来解决这个问题，该指标通过最优运输理论来捕捉外联活动的可变性。我们提出了一种新的种子选择算法，该算法优化了外联和相互公平，并在几个真实数据集上展示了其有效性。我们发现，我们的算法提高了公平性，但效率只略有下降（有时甚至有所提高）。 et.al.|[2406.17736](http://arxiv.org/abs/2406.17736)|null|
|**2024-06-25**|**Extreme Diffusion Measures Statistical Fluctuations of the Environment**|我们考虑一个空间维度上的多粒子扩散，建模为随机环境中的随机游动（RWRE）。共享的短程时空随机环境决定了驱动粒子运动的跳跃分布。我们确定了环境对极端首次通过时间和极端位置变化的贡献的普遍幂律。我们证明了前置因子依赖于单个极端扩散系数，该系数等于随机环境施加在粒子上的局部漂移的系综方差。该系数应与爱因斯坦扩散系数进行对比，爱因斯坦扩散系数决定了描述单个扩散粒子方差的幂律中的前置因子，并等于系综平均随机环境中的跳跃方差。因此，对许多粒子扩散中的极端行为的测量产生了在其他方面难以测量的扩散发生的通常隐藏的环境的波动的统计特性。我们在许多RWRE模型和系统尺寸上对我们的理论和普遍行为进行了数值验证。 et.al.|[2406.17733](http://arxiv.org/abs/2406.17733)|null|
|**2024-06-25**|**On Explicit Solutions for Coupled Reaction-Diffusion and Burgers-Type Equations with Variable Coefficients Through a Riccati System**|本文研究了广义耦合反应扩散和Burgers型变系数系统的显式解。包括变系数非线性模型，如扩散Lotka-Volterra模型、Gray-Scott模型、Burgers方程。方程的可积性（通过解的显式公式）是通过使用相似变换并要求系数满足Riccati系统来实现的。我们介绍了行波型解，以及具有更复杂动力学和相关特征（如弯曲）的解。已经准备了一个Mathematica文件作为补充材料，用于验证解决方案构建中使用的Riccati系统。 et.al.|[2406.17690](http://arxiv.org/abs/2406.17690)|null|
|**2024-06-25**|**Unified Auto-Encoding with Masked Diffusion**|在成功的生成和自我监督表示学习模型的核心，都有一个包含某种形式的图像腐败的重建目标。扩散模型通过预定的高斯破坏过程来实现这种方法，而掩蔽的自动编码器模型则通过掩蔽图像的块来实现。尽管它们的方法不同，但它们方法的潜在相似性为能够同时执行去噪任务的自动编码器提供了一条很有前途的途径。我们提出了一个统一的自监督目标，称为统一掩蔽扩散（UMD），它将基于补丁和基于噪声的破坏技术结合在一个单独的自动编码框架内。具体而言，UMD通过在扩散噪声调度中引入额外的无噪声、高掩蔽表示步骤来修改扩散变换器（DiT）训练过程，并将掩蔽和噪声的混合图像用于后续的时间步长。通过集成对扩散建模和预测屏蔽补丁令牌有用的特征，UMD在下游生成和表示学习任务中实现了强大的性能，包括线性探测和类条件生成。这是在不需要大量数据扩充、多视图或额外编码器的情况下实现的。此外，UMD在总训练时间上提高了先前基于扩散的方法的计算效率。我们在发布代码https://github.com/philippe-eecs/small-vision. et.al.|[2406.17688](http://arxiv.org/abs/2406.17688)|null|
|**2024-06-25**|**Asymptotic Properties of Random Homology Induced by Diffusion Processes**|我们研究了与紧黎曼流形上随机扩散过程实现相关的随机同调在长时间限制下的渐近行为。特别地，建立了一个刚度结果：如果速率是二次的，那么流形是平面环面上的局部平凡纤维束，其中纤维在加权意义上是最小的（也就是说，将流形视为度量测量空间，不变概率是权量测量）。令人惊讶的是，这意味着至少对于某些类别的流形，不可逆过程的同调松弛到平衡的速度比其可逆过程慢（与相应的经验测度相反，后者松弛得更快）。 et.al.|[2406.17683](http://arxiv.org/abs/2406.17683)|null|
|**2024-06-25**|**LaTable: Towards Large Tabular Models**|表格数据是最普遍的模式之一，但关于表格生成基础模型的文献远远落后于文本和视觉模型。创建这样的模型是困难的，因为不同的表格数据集、表格元数据（例如数据集描述和特征头）和缺乏先验知识的表（例如特征顺序）的特征空间是异构的。在这项工作中，我们提出了LaTable：一种新的表格扩散模型，可以解决这些挑战，并可以在不同的数据集上进行训练。通过广泛的实验，我们发现LaTable在分布内生成方面优于基线，并且微调LaTable可以用更少的样本更好地生成分布外数据集。另一方面，我们探讨了LaTable较差的零样本性能，以及它可能教会我们如何构建具有更好零速和少速生成能力的生成表格基础模型。 et.al.|[2406.17673](http://arxiv.org/abs/2406.17673)|null|
|**2024-06-26**|**SpecMaskGIT: Masked Generative Modeling of Audio Spectrograms for Efficient Audio Synthesis and Beyond**|迭代合成音频片段的生成模型的最新进展引发了文本到音频合成（TTA）的巨大成功，但其代价是合成速度慢和计算量大。尽管已经有人试图加速迭代过程，但由于推理阶段需要数百次迭代和大量的模型参数，高质量的TTA系统仍然效率低下。为了应对这些挑战，我们提出了SpecMaskGIT，这是一种基于声谱图的掩蔽生成建模的轻量级、高效但有效的TTA模型。首先，SpecMaskGIT通过不到16次迭代合成逼真的10s音频片段，比以前的迭代TTA方法低一个数量级。作为一个离散模型，SpecMaskGIT在TTA基准测试中优于更大的VQ Diffusion和自回归模型，同时仅使用4个CPU内核即可实现实时性，使用GPU甚至可以提高30倍。接下来，建立在Mel谱图的潜在空间上，SpecMaskGIT比建立在潜波域上的类似方法具有更广泛的应用范围（例如，零样本带宽扩展）。此外，我们将SpecMaskGIT解释为对先前的判别性音频掩蔽变换器的生成扩展，并揭示了其音频表示学习潜力。我们希望我们的工作能启发人们对蒙面音频建模的探索，以实现更多样化的场景。 et.al.|[2406.17672](http://arxiv.org/abs/2406.17672)|null|
|**2024-06-25**|**Aligning Diffusion Models with Noise-Conditioned Perception**|人类偏好优化的最新进展，最初是为语言模型（LM）开发的，已经显示出文本到图像扩散模型的前景，增强了即时对齐、视觉吸引力和用户偏好。与LMs不同，扩散模型通常在像素或VAE空间中进行优化，这与人类感知不太一致，导致在偏好对齐阶段的训练速度较慢且效率较低。我们建议在扩散模型的U-Net嵌入空间中使用感知目标来解决这些问题。我们的方法涉及在该嵌入空间内使用直接偏好优化（DPO）、对比偏好优化（CPO）和监督微调（SFT）来微调稳定扩散1.5和XL。该方法在包括质量和计算成本在内的各种指标上显著优于标准潜在空间实现。对于SDXL，与PartiPrompts数据集上的原始开源SDXL-DPO相比，我们的方法提供了60.8%的一般偏好、62.2%的视觉吸引力和52.1%的提示跟随，同时显著减少了计算量。我们的方法不仅提高了扩散模型的人类偏好比对的效率和质量，而且很容易与其他优化技术相集成。此处提供训练代码和LoRA重量：https://huggingface.co/alexgambashidze/SDXL\_NCP-DPO\_v0.1 et.al.|[2406.17636](http://arxiv.org/abs/2406.17636)|null|
|**2024-06-25**|**Test-Time Generative Augmentation for Medical Image Segmentation**|在本文中，我们提出了一种在测试期间增强医学图像分割的新方法。我们主张使用高级域微调生成模型（GM），例如稳定扩散（SD）来增加测试时间，而不是在输入测试图像上使用手工制作的变换或函数来创建多个视图以增加测试时间。考虑到GM已经被训练来理解和封装全面的领域数据知识，它在表示数据特征和分布方面优于分割模型。因此，通过将GM集成到测试时间扩充中，我们可以有效地生成给定测试样本的多个视图，与样本的内容和外观特征以及相关的局部数据分布保持一致。与传统的手工转换相比，这种方法使增强过程更具适应性和弹性。在三个医学图像分割任务（九个数据集）上进行的综合实验证明了所提出的TTGA在增强分割结果方面的有效性和多功能性。此外，TTGA显著提高了像素误差估计，从而有助于部署更可靠的分割系统。代码将在以下位置发布：https://github.com/maxiao0234/TTGA. et.al.|[2406.17608](http://arxiv.org/abs/2406.17608)|**[link](https://github.com/maxiao0234/ttga)**|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-25**|**Masked Generative Extractor for Synergistic Representation and 3D Generation of Point Clouds**|在2D图像生成建模和表示学习领域，掩模生成编码器（MAGE）已经证明了生成建模与表示学习之间的协同潜力。受此启发，我们提出了Point MAGE，将这一概念扩展到点云数据。具体而言，该框架首先利用矢量量化变分自动编码器（VQVAE）来重建3D形状的神经场表示，从而学习点块的离散语义特征。随后，通过将掩蔽模型与可变掩蔽比相结合，我们实现了生成和表示学习的同步训练。此外，我们的框架与现有的点云自监督学习（SSL）模型无缝集成，从而提高了它们的性能。我们广泛评估了Point MAGE的表示学习和生成能力。在形状分类任务中，Point MAGE在ModelNet40数据集上的准确率为94.2%，在ScanObjectNN数据集上达到92.9%（+1.3%）。此外，它在少量镜头学习和零件分割任务中实现了最先进的性能。实验结果还证实，点MAGE可以在无条件和有条件的设置中生成详细和高质量的3D形状。 et.al.|[2406.17342](http://arxiv.org/abs/2406.17342)|null|
|**2024-06-17**|**DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features**|我们提出了DistilleNeRF，这是一种自监督学习框架，解决了在自动驾驶中从有限的2D观测中理解3D环境的挑战。我们的方法是一个可推广的前馈模型，它从稀疏的单帧多视图相机输入中预测丰富的神经场景表示，并通过可微分渲染进行自监督训练，以重建RGB、深度或特征图像。我们的第一个见解是通过生成密集的深度和虚拟相机目标进行训练，利用每场景优化的神经辐射场（NeRF），从而帮助我们的模型从稀疏的非重叠图像输入中学习3D几何。其次，为了学习语义丰富的3D表示，我们建议从预先训练的2D基础模型（如CLIP或DINOv2）中提取特征，从而实现各种下游任务，而不需要昂贵的3D人工注释。为了利用这两个见解，我们引入了一种新的模型架构，该架构具有两级提升-飞溅-拍摄编码器和参数化稀疏分层体素表示。在NuScenes数据集上的实验结果表明，DistilleNeRF在场景重建、新视图合成和深度估计方面显著优于现有的可比自监督方法；并且它允许竞争性的零样本3D语义占用预测，以及通过提取的基础模型特征来理解开放世界场景。演示和代码将在https://distillnerf.github.io/. et.al.|[2406.12095](http://arxiv.org/abs/2406.12095)|null|
|**2024-06-18**|**Effective Rank Analysis and Regularization for Enhanced 3D Gaussian Splatting**|从多视图图像中进行三维重建是计算机视觉和图形学的基本挑战之一。近年来，三维高斯散射（3DGS）已经成为一种很有前途的技术，能够实时渲染和高质量的三维重建。该方法利用了三维高斯表示和基于瓦片的飞溅技术，绕过了昂贵的神经场查询。尽管3DGS具有潜力，但由于高斯收敛为具有一个主导方差的各向异性高斯，3DGS仍面临挑战，包括针状伪影、次优几何结构和不准确法线。我们建议使用有效秩分析来检查3D高斯基元的形状统计，并识别高斯确实收敛为有效秩为1的针状形状。为了解决这个问题，我们引入了有效秩作为正则化，它约束高斯的结构。我们的新正则化方法增强了法线和几何重建，同时减少了针状伪影。该方法可以作为附加模块集成到其他3DGS变体中，在不影响视觉逼真度的情况下提高其质量。 et.al.|[2406.11672](http://arxiv.org/abs/2406.11672)|null|
|**2024-06-13**|**Well-posedness and regularity of solutions to neural field problems with dendritic processing**|我们研究了最近提出的神经场模型的解决方案，在该模型中，树突被建模为源自体细胞层的垂直纤维的连续体。由于电压通过具有非局部源的电缆方程沿树枝状方向传播，因此该模型具有各向异性扩散算子以及突触耦合的积分项。因此，相应的柯西问题与经典的神经场方程明显不同。我们证明了问题的弱公式允许一个唯一的解，嵌入估计类似于非线性局部反应扩散方程的嵌入估计。我们的分析依赖于无扩散问题的扰动弱解，即标准神经场，迄今为止尚未对其弱问题进行研究。我们找到了有扩散和无扩散问题的严格渐近估计，并证明了这两个模型的解在有限时间间隔上在适当的范数下保持接近。我们提供了微扰结果的数值证据。 et.al.|[2406.09222](http://arxiv.org/abs/2406.09222)|null|
|**2024-06-13**|**Preserving Identity with Variational Score for General-purpose 3D Editing**|我们提出了Piva（用变分分数蒸馏保持同一性），这是一种新的基于优化的方法，用于编辑基于扩散模型的图像和3D模型。具体来说，我们的方法受到了最近提出的2D图像编辑方法——德尔塔去噪分数（DDS）的启发。我们指出了DDS在二维和三维编辑中的局限性，这会导致细节丢失和过饱和。为了解决这一问题，我们提出了一个额外的分数提取术语，以强制执行身份保护。这导致了更稳定的编辑过程，逐步优化NeRF模型以匹配目标提示，同时保留关键的输入特征。我们证明了我们的方法在零样本图像和神经场编辑中的有效性。我们的方法成功地改变了视觉属性，添加了微妙和实质性的结构元素，转换了形状，并在标准的2D和3D编辑基准上取得了有竞争力的结果。此外，我们的方法没有施加任何约束，如掩蔽或预训练，使其与广泛的预训练扩散模型兼容。这允许进行多功能编辑，而不需要神经场到网格的转换，提供更用户友好的体验。 et.al.|[2406.08953](http://arxiv.org/abs/2406.08953)|null|
|**2024-06-12**|**Category-level Neural Field for Reconstruction of Partially Observed Objects in Indoor Environment**|通过各种成功案例，神经隐式表示在三维重建中引起了人们的关注。对于进一步的应用，如场景理解或编辑，一些作品已经显示出在对象组成重建方面的进展。尽管它们在观测区域具有优越的性能，但在重建部分观测到的对象时，它们的性能仍然有限。为了更好地处理这个问题，我们引入了类别级神经场，该神经场在场景中属于同一类别的对象之间学习有意义的公共3D信息。我们的主要想法是根据观察到的形状对对象进行子分类，以便更好地训练类别级模型。然后，我们利用神经场，通过选择基于射线的不确定性选择的代表性对象并与之对齐，来执行配准部分观测对象的挑战性任务。在模拟和真实世界数据集上的实验表明，我们的方法改进了几个类别的未观察零件的重建。 et.al.|[2406.08176](http://arxiv.org/abs/2406.08176)|**[link](https://github.com/Taekbum/category-nerf-reconstruction-official)**|
|**2024-06-12**|**OpenObj: Open-Vocabulary Object-Level Neural Radiance Fields with Fine-Grained Understanding**|近年来，人们对由视觉语言模型（VLM）促进的开放词汇三维场景重建产生了浓厚的兴趣，VLM在开放集检索中展示了非凡的能力。然而，现有的方法面临一些局限性：它们要么专注于学习逐点特征，导致语义理解模糊，要么只处理对象级重建，从而忽略对象内部的复杂细节。为了应对这些挑战，我们引入了OpenObj，这是一种创新的方法，用于构建具有细粒度理解的开放词汇表对象级神经辐射场（NeRF）。从本质上讲，OpenObj建立了一个健壮的框架，用于在对象级别进行高效和严密的场景建模和理解。此外，我们将零件级特征融入神经领域，从而实现物体内部的细致入微的表示。这种方法捕获对象级实例，同时保持细粒度的理解。在多个数据集上的结果表明，OpenObj在零样本语义分割和检索任务中取得了优异的性能。此外，OpenObj支持多尺度的真实世界机器人任务，包括全局移动和局部操纵。 et.al.|[2406.08009](http://arxiv.org/abs/2406.08009)|**[link](https://github.com/BIT-DYN/OpenObj)**|
|**2024-06-11**|**Image Neural Field Diffusion Models**|扩散模型在对复杂数据分布建模方面表现出了令人印象深刻的能力，与GANs相比具有几个关键优势，例如稳定的训练、更好地覆盖训练分布的模式，以及在没有额外训练的情况下解决反问题的能力。然而，大多数扩散模型学习固定分辨率图像的分布。我们建议通过在图像神经场上训练扩散模型来学习连续图像的分布，该模型可以以任何分辨率渲染，并显示出其相对于固定分辨率模型的优势。为了实现这一点，一个关键的挑战是获得一个代表真实感图像神经场的潜在空间。受最近几项技术的启发，我们提出了一种简单有效的方法，但有一些关键的变化，使图像神经场具有真实感。我们的方法可以用于将现有的潜在扩散自动编码器转换为图像神经场自动编码器。我们证明，图像神经场扩散模型可以使用混合分辨率图像数据集进行训练，优于固定分辨率扩散模型和超分辨率模型，并且可以有效地解决不同尺度条件下的逆问题。 et.al.|[2406.07480](http://arxiv.org/abs/2406.07480)|null|
|**2024-06-10**|**Space-Time Continuous PDE Forecasting using Equivariant Neural Fields**|最近，条件神经场（NeF）通过将解学习为条件NeF的潜在空间中的流，已成为偏微分方程的强大建模范式。尽管受益于NeFs的有利特性，如网格不可知性和时空连续动力学建模，但这种方法限制了将PDE的已知约束强加给解决方案的能力，例如对称性或边界条件，有利于建模的灵活性。相反，我们提出了一种基于时空连续NeF的求解框架，该框架通过在潜在空间中保留几何信息，尊重PDE的已知对称性。我们表明，将解建模为感兴趣组 $G$ 上的点云流，可以提高泛化和数据效率。我们验证了我们的框架很容易推广到看不见的空间和时间位置，以及初始条件的几何变换——在其他基于NeF的PDE预测方法失败的地方——并在一些具有挑战性的几何结构中超过基线进行改进。 et.al.|[2406.06660](http://arxiv.org/abs/2406.06660)|null|
|**2024-06-11**|**LOP-Field: Brain-inspired Layout-Object-Position Fields for Robotic Scene Understanding**|空间认知使动物具有非常高效的导航能力，这在很大程度上取决于对空间环境的场景级理解。最近，人们发现，大鼠大脑嗅后皮层的神经群体比场景中的物体更能强烈地适应空间布局。受局部场景中空间布局表示的启发，我们提出了实现布局对象位置（LOP）关联的LOP域，以对机器人场景理解的层次表示进行建模。在基础模型和隐式场景表示的支持下，神经场被实现为机器人的场景存储器，存储具有位置、对象和布局信息的场景的可查询表示。为了验证所建立的LOP关联，对该模型进行了测试，以使用定量指标从3D位置推断区域信息，实现了超过88%的平均准确度。还表明，与最先进的定位方法相比，所提出的使用区域信息的方法可以在文本和RGB输入的情况下实现改进的对象和视图定位结果。 et.al.|[2406.05985](http://arxiv.org/abs/2406.05985)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

