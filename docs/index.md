---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.05.19
> Usage instructions: [here](./docs/README.md#usage)

## Video Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-16**|**QVGen: Pushing the Limit of Quantized Video Generative Models**|视频扩散模型（DM）实现了高质量的视频合成。然而，它们巨大的计算和内存需求对现实世界的部署构成了严重挑战，即使在高端GPU上也是如此。作为一种常用的解决方案，量化已被证明在降低图像DM的成本方面取得了显著成功，但将其直接应用于视频DM仍然无效。在本文中，我们提出了QVGen，这是一种新的量化感知训练（QAT）框架，专为极低比特量化（例如4比特或更低）下的高性能和推理高效视频DM而设计。我们从理论分析开始，证明降低梯度范数对于促进QAT的收敛至关重要。为此，我们引入了辅助模块（ $\Phi$）来减轻较大的量化误差，从而显著增强收敛性。为了消除$\Phi$的推理开销，我们提出了一种逐步消除$\Pi$的秩衰减策略。具体来说，我们反复使用奇异值分解（SVD）和提出的基于秩的正则化$\mathbf{\gamma}$来识别和衰减低贡献分量。此策略在保持性能的同时消除了推理开销。在4美元的最先进（SOTA）视频DM上进行的广泛实验表明，QVGen是第一个在4位设置下达到全精度可比质量的设备，参数大小从13美元到14美元不等。此外，它明显优于现有方法。例如，我们的3位CogVideoX-2B在VBench上的动态度和场景一致性分别提高了$25.28$和$+8.43$ 。 et.al.|[2505.11497](http://arxiv.org/abs/2505.11497)|null|
|**2025-05-16**|**Face Consistency Benchmark for GenAI Video**|由人工智能驱动的视频生成技术取得了显著进步，能够创建动态和逼真的内容。然而，保持视频序列中的字符一致性仍然是一个主要挑战，目前的模型难以确保外观和属性的一致性。本文介绍了人脸一致性基准（FCB），这是一个用于评估和比较人工智能生成视频中字符一致性的框架。通过提供标准化的指标，该基准突出了现有解决方案中的差距，并促进了更可靠方法的发展。这项工作是提高人工智能视频生成技术中字符一致性的关键一步。 et.al.|[2505.11425](http://arxiv.org/abs/2505.11425)|null|
|**2025-05-16**|**Diffusion-NPO: Negative Preference Optimization for Better Preference Aligned Generation of Diffusion Models**|扩散模型在图像生成方面取得了重大进展，但在大型、未经过滤的数据集上训练的模型往往会产生与人类偏好不符的输出。已经提出了许多方法来微调预训练的扩散模型，在将生成的输出与人类偏好对齐方面取得了显著的进步。然而，我们认为，现有的偏好对齐方法忽略了处理无条件/负条件输出的关键作用，导致避免产生不良结果的能力降低。这种疏忽限制了无分类器引导（CFG）的有效性，CFG依赖于条件生成和无条件/负条件生成之间的对比来优化输出质量。作为回应，我们提出了一种简单但通用的有效方法，该方法涉及训练一个专门适应负面偏好的模型。这种方法不需要新的训练策略或数据集，而是需要对现有技术进行小幅修改。我们的方法与SD1.5、SDXL、视频扩散模型和经过偏好优化的模型无缝集成，始终如一地增强了它们与人类偏好的一致性。 et.al.|[2505.11245](http://arxiv.org/abs/2505.11245)|null|
|**2025-05-14**|**Aquarius: A Family of Industry-Level Video Generation Models for Marketing Scenarios**|本报告介绍了Aquarius，这是一个用于营销场景的行业级视频生成模型系列，专为数千个xPU集群和具有数千亿参数的模型而设计。Aquarius利用高效的工程架构和算法创新，在高保真度、多宽高比和长时间视频合成方面表现出色。通过披露该框架的设计细节，我们的目标是揭开工业规模视频生成系统的神秘面纱，并促进生成视频社区的进步。Aquarius框架由五个组件组成：分布式图形和视频数据处理管道：通过自动任务分配管理数万个CPU和数千个xPU，实现高效的视频数据处理。此外，我们即将开源名为“Aquarius Datapipe”的整个数据处理框架。不同尺度的模型架构：包括2B模型的单DiT架构和13.4B模型的多模态DiT架构，支持多宽高比、多分辨率和多持续时间的视频生成。专为视频生成模型训练设计的高性能基础设施：该基础设施结合了混合并行和细粒度内存优化策略，大规模实现了36%的MFU。多xPU并行推理加速：利用扩散缓存和注意力优化实现2.35倍的推理加速。多种营销场景应用：包括图像到视频、文本到视频（化身）、视频修复和视频个性化等。在即将到来的版本更新中，将添加更多的下游应用程序和多维评估指标。 et.al.|[2505.10584](http://arxiv.org/abs/2505.10584)|null|
|**2025-05-16**|**MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation**|人体图像动画因其在数字人类中的广泛应用而受到越来越多的关注并迅速发展。然而，现有的方法在很大程度上依赖于2D渲染的姿态图像进行运动引导，这限制了泛化能力，并丢弃了开放世界动画的基本3D信息。为了解决这个问题，我们提出了MTVCrafter（运动标记化视频工匠），这是第一个直接为人类图像动画建模原始3D运动序列（即4D运动）的框架。具体来说，我们引入4DIoT（4D运动标记器）将3D运动序列量化为4D运动标记。与2D渲染的姿势图像相比，4D运动标记提供了更稳健的时空线索，避免了姿势图像和角色之间严格的像素级对齐，实现了更灵活、更清晰的控制。然后，我们介绍了MV DiT（运动感知视频DiT）。通过使用4D位置编码设计独特的运动注意力，MV DiT可以有效地利用运动标记作为复杂3D世界中人类图像动画的4D紧凑而富有表现力的上下文。因此，它标志着该领域向前迈出了重要一步，并为姿势引导的人体视频生成开辟了新的方向。实验表明，我们的MTVCrafter达到了最先进的结果，FID-VID为6.98，比第二好的高出65%。在强大的动作令牌的支持下，MTVCrafter还可以很好地推广到各种风格和场景中的各种开放世界角色（单体/多体、全身/半身）。我们的视频演示和代码已发布：https://github.com/DINGYANB/MTVCrafter. et.al.|[2505.10238](http://arxiv.org/abs/2505.10238)|**[link](https://github.com/dingyanb/mtvcrafter)**|
|**2025-05-15**|**ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars**|3D高斯混合形状的引入使得能够从单眼视频中实时重建可动画化的头部化身。Toonify是一个基于StyleGAN的框架，已被广泛用于面部图像风格化。为了扩展Toonify，使用高斯混合形状合成各种风格化的3D头部化身，我们提出了一种高效的两阶段框架ToonifyGB。在第一阶段（风格化视频生成），我们采用改进的StyleGAN从输入视频帧生成风格化视频，解决了以固定分辨率裁剪对齐人脸作为普通StyleGAN预处理的局限性。这个过程提供了一个更稳定的视频，这使得高斯混合形状能够更好地捕捉视频帧的高频细节，并在下一阶段有效地生成高质量的动画。在第二阶段（高斯混合形状合成），我们从生成的视频中学习一个程式化的中性头部模型和一组表情混合形状。通过将中性头部模型与表情混合形状相结合，ToonifyGB可以有效地渲染具有任意表情的程式化化身。我们使用Arcane和Pixar两种风格在基准数据集上验证了ToonifyGB的有效性。 et.al.|[2505.10072](http://arxiv.org/abs/2505.10072)|null|
|**2025-05-14**|**Mission Balance: Generating Under-represented Class Samples using Video Diffusion Models**|计算机辅助干预可以改善手术中的指导，特别是通过利用手术视频中的时空信息的深度学习方法。然而，手术视频数据集中经常出现的严重数据不平衡阻碍了高性能模型的开发。在这项工作中，我们的目标是通过合成手术视频来克服数据不平衡。我们提出了一种独特的两阶段、基于文本条件的扩散方法，为代表性不足的类别生成高保真手术视频。我们的方法根据文本提示来调节生成过程，并通过利用2D潜在扩散模型来捕获空间内容，然后整合时间注意力层以确保时间一致性，从而将空间和时间建模解耦。此外，我们引入了一种拒绝采样策略来选择最合适的合成样本，有效地增强了现有的数据集以解决类不平衡问题。我们在两个下游任务上评估了我们的方法——手术动作识别和手术中事件预测——表明，结合我们方法中的合成视频可以大大提高模型性能。我们将我们的实现开源于https://gitlab.com/nct_tso_public/surgvgen. et.al.|[2505.09858](http://arxiv.org/abs/2505.09858)|**[link](https://gitlab.com/nct_tso_public/surgvgen)**|
|**2025-05-14**|**EWMBench: Evaluating Scene, Motion, and Semantic Quality in Embodied World Models**|创造性人工智能的最新进展使基于语言指令的高保真图像和视频的合成成为可能。在这些发展的基础上，文本到视频的扩散模型已经演变为实体世界模型（EWM），能够从语言命令生成物理上合理的场景，有效地在实体AI应用程序中桥接视觉和动作。这项工作解决了评估超越一般感知指标的EWM的关键挑战，以确保产生物理基础和行动一致的行为。我们提出了嵌入式世界模型基准（EWMBench），这是一个专门的框架，旨在基于三个关键方面评估EWM：视觉场景一致性、运动正确性和语义对齐。我们的方法利用精心策划的数据集，包括各种场景和运动模式，以及全面的多维评估工具包，来评估和比较候选模型。拟议的基准不仅确定了现有视频生成模型在满足具体任务的独特要求方面的局限性，还为指导该领域的未来发展提供了宝贵的见解。数据集和评估工具可在以下网址公开获取https://github.com/AgibotTech/EWMBench. et.al.|[2505.09694](http://arxiv.org/abs/2505.09694)|**[link](https://github.com/agibottech/ewmbench)**|
|**2025-05-15**|**Generating time-consistent dynamics with discriminator-guided image diffusion models**|真实的时间动态对于许多视频生成、处理和建模应用至关重要，例如在计算流体动力学、天气预报或长期气候模拟中。视频扩散模型（VDM）是目前最先进的生成高度逼真动态的方法。然而，从头开始训练VDM可能具有挑战性，需要大量的计算资源，限制了它们的广泛应用。在这里，我们提出了一种时间一致性鉴别器，使预训练的图像扩散模型能够生成逼真的时空动态。鉴别器指导采样推理过程，不需要扩展或微调图像扩散模型。我们将我们的方法与在理想湍流模拟和现实世界全球降水数据集上从头开始训练的VDM进行了比较。我们的方法在时间一致性方面表现同样出色，与VDM相比，显示出改进的不确定性校准和更低的偏差，并在每日时间步长实现了稳定的百年尺度气候模拟。 et.al.|[2505.09089](http://arxiv.org/abs/2505.09089)|null|
|**2025-05-13**|**Generative AI for Autonomous Driving: Frontiers and Opportunities**|生成型人工智能（GenAI）构成了一股变革性的技术浪潮，通过其无与伦比的内容创建、推理、规划和多模式理解能力重新配置行业。这股革命性的力量为解决工程领域最大的挑战之一提供了迄今为止最有前景的道路：实现可靠的全自动驾驶，特别是追求5级自动驾驶。这项调查对GenAI在自动驾驶堆栈中的新兴作用进行了全面而关键的综合。我们首先提炼了现代生成建模的原则和权衡，包括VAE、GAN、扩散模型和大型语言模型（LLM）。然后，我们绘制了它们在图像、激光雷达、轨迹、占用、视频生成以及LLM引导推理和决策中的前沿应用。我们对实际应用进行分类，如合成数据工作流程、端到端驱动策略、高保真数字孪生系统、智能交通网络和跨域传输到嵌入式人工智能。我们确定了关键障碍和可能性，如罕见情况下的全面概化、评估和安全检查、预算有限的实施、监管合规性、伦理问题和环境影响，同时提出了跨理论保证、信任指标、交通整合和社会技术影响的研究计划。通过统一这些线索，该调查为研究人员、工程师和政策制定者提供了一个前瞻性的参考，以引导生成人工智能和高级自主移动的融合。一个积极维护的引用作品库可在https://github.com/taco-group/GenAI4AD. et.al.|[2505.08854](http://arxiv.org/abs/2505.08854)|**[link](https://github.com/taco-group/genai4ad)**|

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-16**|**Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views**|基于视觉的机器人操纵使用相机捕捉包含待操纵对象的场景的一个或多个图像。如果任何物体从一个视点被遮挡，但从另一个视点更可见，拍摄多张图像会有所帮助。然而，必须将相机移动到一系列合适的位置以捕获多个图像，这需要时间，并且由于可达性限制，可能并不总是可能的。因此，虽然由于可用的额外信息，额外的图像可以产生更准确的抓握姿势，但时间成本会随着采样的额外视图数量的增加而增加。高斯散点等场景表示能够从用户指定的新颖视点渲染出精确的逼真虚拟图像。在这项工作中，我们展示了初步结果，表明新颖的视图合成可以在生成抓握姿势时提供额外的背景。我们在Grassnet-1十亿数据集上的实验表明，除了从稀疏采样的真实视图中获得的力闭合抓取外，新视图还贡献了力闭合抓取，同时提高了抓取覆盖率。未来，我们希望这项工作可以扩展到使用例如扩散模型或可推广的辐射场来改进从由单个输入图像构建的辐射场中提取的抓取。 et.al.|[2505.11467](http://arxiv.org/abs/2505.11467)|null|
|**2025-05-16**|**MutualNeRF: Improve the Performance of NeRF under Limited Samples with Mutual Information Theory**|本文介绍了MutualNeRF，这是一种使用互信息理论在有限样本下增强神经辐射场（NeRF）性能的框架。虽然NeRF在3D场景合成方面表现出色，但数据有限，旨在引入先验知识的现有方法缺乏统一框架中的理论支持，这带来了挑战。我们引入了一个简单但理论上稳健的概念，互信息，作为统一衡量图像之间相关性的指标，同时考虑了宏观（语义）和微观（像素）层面。对于稀疏视图采样，我们通过最小化互信息来策略性地选择包含更多非重叠场景信息的额外视点，而无需事先知道地面真实图像。我们的框架采用贪婪算法，提供近乎最优的解决方案。对于少镜头视图合成，我们最大化推断图像和地面实况之间的互信息，期望推断图像从已知图像中获得更多相关信息。这是通过结合高效的即插即用正则化术语来实现的。在有限样本下的实验表明，在不同环境下，与最先进的基线相比，我们的框架的有效性得到了持续的改善。 et.al.|[2505.11386](http://arxiv.org/abs/2505.11386)|null|
|**2025-05-15**|**NVSPolicy: Adaptive Novel-View Synthesis for Generalizable Language-Conditioned Policy Learning**|深度生成模型的最新进展展示了前所未有的零样本泛化能力，为非结构化环境中的机器人操作提供了巨大的潜力。给定对场景的部分观察，深度生成模型可以生成看不见的区域，从而提供更多的上下文，这增强了机器人在看不见环境中进行泛化的能力。然而，由于生成图像中的视觉伪影和策略学习中多模态特征的低效集成，这一方向仍然是一个悬而未决的挑战。我们介绍了NVSPolicy，这是一种可推广的语言条件策略学习方法，它将自适应新视图合成模块与分层策略网络相结合。给定输入图像，NVSPolicy动态选择一个有信息的视点，并合成一个自适应新视图图像，以丰富视觉上下文。为了减轻合成图像不完美的影响，我们采用了一种循环一致的VAE机制，将视觉特征分解为语义特征和剩余特征。然后，这两个特征分别被馈送到分层策略网络中：语义特征通知高级元技能选择，其余特征指导低级动作估计。此外，我们提出了几种实用的机制来提高所提出方法的效率。CALVIN上的大量实验证明了我们方法的最先进性能。具体来说，它在所有任务中的平均成功率为90.4%，大大优于最近的方法。消融研究证实了我们自适应新视角合成范式的重要性。此外，我们在现实世界的机器人平台上评估了NVSPolicy，以证明其实际适用性。 et.al.|[2505.10359](http://arxiv.org/abs/2505.10359)|null|
|**2025-05-15**|**VRSplat: Fast and Robust Gaussian Splatting for Virtual Reality**|3D高斯散斑（3DGS）已迅速成为新型视图合成的领先技术，通过高效的基于软件的GPU光栅化提供卓越的性能。它的多功能性使实时应用成为可能，包括在移动设备和低功耗设备上。然而，3DGS在虚拟现实（VR）中面临着关键挑战：（1）时间伪影，如头部运动时爆裂；（2）基于投影的失真，导致令人不安和视图不一致的漂浮物；（3）渲染大量高斯分布时帧率降低，低于VR的临界阈值。与桌面环境相比，这些问题因大视场、持续的头部移动和头戴式显示器（HMD）的高分辨率而大大加剧。在这项工作中，我们介绍了VRSplat：我们结合并扩展了3DGS的几个最新进展，以全面应对VR的挑战。我们展示了如何通过修改单个技术和核心3DGS光栅化器，使Mini Splatting、StopThePop和Optimal Projection的想法相辅相成。此外，我们提出了一种高效的中心凹光栅化器，可以在单个GPU启动中处理焦点和外围区域，避免冗余计算并提高GPU利用率。我们的方法还包含了一个微调步骤，该步骤基于StopThePop深度评估和最优投影来优化高斯参数。我们通过一项有25名参与者参与的对照用户研究来验证我们的方法，结果显示VRSplat比其他配置的Mini Splatting更受欢迎。VRSplat是第一个经过系统评估的3DGS方法，能够支持现代VR应用程序，实现72+FPS，同时消除爆裂和立体声干扰浮动。 et.al.|[2505.10144](http://arxiv.org/abs/2505.10144)|**[link](https://github.com/cekavis/vrsplat)**|
|**2025-05-13**|**FOCI: Trajectory Optimization on Gaussian Splats**|3D高斯散斑（3DGS）最近作为3D重建和视图合成方法中神经辐射场（NeRF）的更快替代方案而受到欢迎。利用3DGS中编码的空间信息，这项工作提出了FOCI（场重叠碰撞积分），这是一种能够直接在高斯本身上优化轨迹的算法。FOCI利用高斯重叠积分的概念，为3DGS利用了一种新颖且可解释的碰撞公式。与其他方法相反，这些方法用保守的边界框表示机器人，低估了环境的可穿越性，我们建议将环境和机器人表示为高斯散点。这不仅具有理想的计算特性，而且允许进行方向感知规划，使机器人能够穿过非常狭窄的空间。我们在合成和真实高斯Splats中广泛测试了我们的算法，展示了ANYmal腿式机器人的无碰撞轨迹，即使有数十万高斯人组成环境，也可以在几秒钟内计算出来。项目页面和代码可在https://rffr.leggedrobotics.com/works/foci/ et.al.|[2505.08510](http://arxiv.org/abs/2505.08510)|null|
|**2025-05-13**|**ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image**|我们将自适应视图规划引入多视图合成，旨在提高单视图3D重建的遮挡显示和3D一致性。我们不是独立或同时生成一组无序的视图，而是生成一系列视图，利用时间一致性来增强3D一致性。最重要的是，我们的视图序列不是由预先确定的相机设置决定的。相反，我们计算自适应相机轨迹（ACT），具体来说，是相机视图的轨迹，它最大限度地提高了要重建的3D对象的遮挡区域的可见性。一旦找到最佳轨道，我们将其输入视频扩散模型，以生成轨道周围的新视图，然后将其传递给多视图3D重建模型，以获得最终重建。我们的多视图合成管道非常高效，因为它不涉及运行时训练/优化，只涉及通过应用预训练的模型进行遮挡分析和多视图合成的前向推理。我们的方法预测了相机轨迹，有效地揭示了遮挡并产生了一致的新视图，在看不见的GSO数据集上显著改善了SOTA的3D重建，无论是定量还是定性。 et.al.|[2505.08239](http://arxiv.org/abs/2505.08239)|null|
|**2025-05-13**|**TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin Benchmark Dataset**|城市数字双胞胎（UDTs）已成为管理城市和整合来自不同来源的复杂异构数据的关键。创建UDT涉及多个过程阶段的挑战，包括获取准确的3D源数据、重建高保真3D模型、维护模型的更新，以及确保与下游任务的无缝互操作性。当前的数据集通常仅限于处理链的一部分，阻碍了全面的UDT验证。为了应对这些挑战，我们推出了第一个全面的多模式城市数字孪生基准数据集：TUM2TWIN。该数据集包括地理参考、语义对齐的3D模型和网络，以及各种地面、移动、空中和卫星观测，拥有32个数据子集，数据量约为100000美元，目前为767 GB。通过确保地理参考的室内外采集、高精度和多模态数据集成，该基准支持传感器的稳健分析和先进重建方法的开发。此外，我们还探索了展示TUM2TWIN潜力的下游任务，包括NeRF和高斯散斑的新颖视图合成、太阳势分析、点云语义分割和LoD3建筑重建。我们相信，这一贡献为克服UDT创建中的当前局限性奠定了基础，为更智能、数据驱动的城市环境培养了新的研究方向和实用的解决方案。该项目可在以下网址获得：https://tum2t.win et.al.|[2505.07396](http://arxiv.org/abs/2505.07396)|null|
|**2025-05-12**|**Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild**|使用体绘制技术的神经隐式表面重建最近在从多个2D图像创建高保真表面方面取得了重大进展。然而，目前的方法主要针对具有一致照明的场景，并且难以在具有瞬态遮挡或不同外观的不受控制的环境中准确重建3D几何体。虽然一些基于神经辐射场（NeRF）的变体可以更好地管理复杂场景中的光度变化和瞬态对象，但由于有限的表面约束，它们被设计用于新颖的视图合成，而不是精确的表面重建。为了克服这一局限性，我们引入了一种新方法，该方法将多个几何约束应用于隐式曲面优化过程，从而能够从无约束图像集合中进行更精确的重建。首先，我们利用运动结构中的稀疏3D点（SfM）来细化重建表面的带符号距离函数估计，并通过位移补偿来适应稀疏点中的噪声。此外，我们采用从法线预测器导出的鲁棒法线先验，并通过边缘先验滤波和多视图一致性约束进行增强，以改善与实际表面几何形状的对齐。对Heritage Recon基准和其他数据集的广泛测试表明，所提出的方法可以从野外图像中准确重建表面，与现有技术相比，可以产生具有更高精度和粒度的几何形状。我们的方法能够对各种地标进行高质量的3D重建，使其适用于各种场景，如文化遗产的数字保护。 et.al.|[2505.07373](http://arxiv.org/abs/2505.07373)|null|
|**2025-05-11**|**NeuGen: Amplifying the 'Neural' in Neural Radiance Fields for Domain Generalization**|神经辐射场（NeRF）显著推进了新视图合成领域，但它们在不同场景和条件下的泛化仍然具有挑战性。为了解决这个问题，我们建议将一种新的大脑启发的归一化技术神经泛化（NeuGen）集成到领先的NeRF架构中，包括MVSNeRF和GeoNeRF。NeuGen提取域不变特征，从而增强模型的泛化能力。它可以无缝集成到NeRF架构中，并培养出一套全面的功能集，显著提高了图像渲染的准确性和鲁棒性。通过这种集成，NeuGen在最先进的NeRF架构的不同数据集上的基准测试中表现出了更高的性能，使其能够在不同的场景中更好地推广。我们的定量和定性综合评估证实，我们的方法不仅在泛化能力上超越了现有模型，而且显著提高了渲染质量。我们的工作展示了将神经科学原理与深度学习框架相结合的潜力，为提高新视图合成的泛化能力和效率树立了新的先例。我们的研究演示可在https://neugennerf.github.io. et.al.|[2505.06894](http://arxiv.org/abs/2505.06894)|null|
|**2025-05-10**|**Gaussian Wave Splatting for Computer-Generated Holography**|最先进的神经渲染方法从几张照片中优化高斯场景表示，以实现新颖的视图合成。基于这些表示，我们开发了一种高效的算法，称为高斯波散布，将这些高斯波转化为全息图。与现有的计算机生成全息术（CGH）算法不同，高斯波散布通过利用神经渲染的最新进展，为照片级真实感场景支持精确的遮挡和视图相关效果。具体来说，我们为支持遮挡和阿尔法混合的2D高斯到全息图变换推导了一个封闭形式的解决方案。受经典计算机图形学技术的启发，我们还推导出了傅里叶域中上述过程的有效近似值，该近似值易于并行化，并使用自定义CUDA内核实现。通过将新兴的神经渲染管道与全息显示技术相结合，我们基于高斯的CGH框架为下一代全息显示器铺平了道路。 et.al.|[2505.06582](http://arxiv.org/abs/2505.06582)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-16**|**Patient-Specific Dynamic Digital-Physical Twin for Coronary Intervention Training: An Integrated Mixed Reality Approach**|背景和目的：冠状动脉介入治疗的精确术前计划和有效的医生培训越来越重要。尽管医学成像技术取得了进步，但将静态或有限的动态成像数据转化为全面的动态心脏模型仍然具有挑战性。现有的训练系统缺乏对心脏生理动力学的精确模拟。本研究基于4D-CTA开发了一个全面的动态心脏模型研究框架，整合了数字孪生技术、计算机视觉和物理模型制造，为介入心脏病学提供了精确、个性化的工具。方法：利用一名60岁女性三支冠状动脉狭窄患者的4D-CTA数据，我们分割了心腔和冠状动脉，构建了动态模型，并实现了骨骼蒙皮重量计算，以模拟20个心脏阶段的血管变形。使用医用级硅胶制造透明血管物理模型。我们开发了心输出量分析和虚拟血管造影系统，使用双目立体视觉实现了导丝3D重建，并通过血管造影验证和冠状动脉旁路移植术训练应用程序对系统进行了评估。结果：虚拟和真实血管造影的形态学一致性达到80.9%。导丝运动的Dice相似系数范围为0.741-0.812，平均轨迹误差低于1.1 mm。透明模型在冠状动脉旁路移植术训练中具有优势，可以在模拟心脏跳动挑战的同时进行直接可视化。结论：我们的患者特异性数字物理双胞胎方法有效地再现了冠状动脉血管的解剖结构和动态特征，提供了一个具有视觉和触觉反馈的动态环境，对教育和临床规划具有重要价值。 et.al.|[2505.10902](http://arxiv.org/abs/2505.10902)|null|
|**2025-05-15**|**Mapping Semantic Segmentation to Point Clouds Using Structure from Motion for Forest Analysis**|尽管使用遥感技术监测森林环境越来越受到关注，但由于成本高、传感器要求高和采集时间密集，公开可用的点云数据集仍然稀缺。此外，据我们所知，没有通过应用于图像的运动结构（SfM）算法生成的公共注释数据集，这可能是由于缺乏能够将语义分割信息映射到准确点云中的SfM算法，特别是在森林等具有挑战性的环境中。在这项工作中，我们提出了一种新的管道，用于生成森林环境的语义分段点云。使用定制的森林模拟器，我们生成了各种森林场景的逼真RGB图像及其相应的语义分割蒙版。然后，使用修改后的开源SfM软件对这些标记图像进行处理，该软件能够在3D重建过程中保留语义信息。由此产生的点云提供了几何和语义细节，为训练和评估旨在分割通过SfM获得的真实森林点云的深度学习模型提供了宝贵的资源。 et.al.|[2505.10751](http://arxiv.org/abs/2505.10751)|null|
|**2025-05-14**|**Robust Photo-Realistic Hand Gesture Generation: from Single View to Multiple View**|高保真手势生成是以人为中心的生成任务中的一项重大挑战。现有方法通常在提高手势生成质量之前采用单视图3D MANO网格渲染图像。然而，手部动作的复杂性和单视图渲染的固有局限性使得捕捉完整的3D手部信息变得困难，特别是在手指被遮挡的情况下。基本矛盾在于通过2D投影失去了3D拓扑关系，以及单视图表示固有的不完整空间覆盖。与单视图先验方法不同，我们提出了一种多视图先验框架，称为基于多模态UNet的特征编码器（MUFEN），用于指导扩散模型学习全面的3D手部信息。具体来说，我们扩展了传统的前视图渲染，包括后、左、右、上和下视角，选择信息最丰富的视图组合作为训练先验，以解决遮挡完成问题。这种具有专用双流编码器的多视图先验显著提高了模型对完整手部特征的理解。此外，我们设计了一个边界框特征融合模块，该模块可以融合手势定位特征和手势多模态特征，以增强MUFEN特征对手势相关特征的位置感知。实验证明，我们的方法在定量指标和定性评估方面都达到了最先进的性能。 et.al.|[2505.10576](http://arxiv.org/abs/2505.10576)|null|
|**2025-05-15**|**VolE: A Point-cloud Framework for Food 3D Reconstruction and Volume Estimation**|准确的食物量估计对于医疗营养管理和健康监测应用至关重要，但目前的食物量估算方法往往受到单核数据的限制，利用3D扫描仪等单一用途硬件，收集深度信息等面向传感器的信息，或依赖于使用参考对象的相机校准。在这篇论文中，我们提出了VolE，这是一种利用移动设备驱动的3D重建来估计食物量的新框架。得益于支持AR的移动设备，VolE可以自由捕捉图像和相机位置，以生成精确的3D模型。为了实现真实世界的测量，VolE是一个无参考和深度的框架，它利用食物视频分割来生成食物口罩。我们还引入了一个新的食品数据集，涵盖了之前基准测试中没有的具有挑战性的场景。我们的实验表明，VolE在多个数据集上的表现优于现有的体积估计技术，实现了2.22%的MAPE，突显了其在食物体积估计方面的卓越性能。 et.al.|[2505.10205](http://arxiv.org/abs/2505.10205)|null|
|**2025-05-13**|**Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions**|高质量的肺节段三维重建在肺癌节段切除术和手术治疗计划中起着至关重要的作用。由于目标重建的分辨率要求，传统的基于深度学习的方法经常受到计算资源约束或粒度有限的影响。相反，隐式建模因其计算效率和在任何分辨率下的连续表示而受到青睐。我们提出了一种基于神经隐式函数的方法来学习3D表面，以实现解剖感知的精确肺段重建，通过变形可学习的模板将其表示为形状。此外，我们引入了两个临床相关的评估指标来全面评估重建。此外，由于缺乏公开可用的形状数据集来对重建算法进行基准测试，我们开发了一个名为Lung3D的形状数据集中，包括800个标记的肺段和相应的气道、动脉、静脉和段间静脉的3D模型。我们证明，所提出的方法优于现有的方法，为肺段重建提供了新的视角。代码和数据将在https://github.com/M3DV/ImPulSe. et.al.|[2505.08919](http://arxiv.org/abs/2505.08919)|**[link](https://github.com/m3dv/impulse)**|
|**2025-05-13**|**FOCI: Trajectory Optimization on Gaussian Splats**|3D高斯散斑（3DGS）最近作为3D重建和视图合成方法中神经辐射场（NeRF）的更快替代方案而受到欢迎。利用3DGS中编码的空间信息，这项工作提出了FOCI（场重叠碰撞积分），这是一种能够直接在高斯本身上优化轨迹的算法。FOCI利用高斯重叠积分的概念，为3DGS利用了一种新颖且可解释的碰撞公式。与其他方法相反，这些方法用保守的边界框表示机器人，低估了环境的可穿越性，我们建议将环境和机器人表示为高斯散点。这不仅具有理想的计算特性，而且允许进行方向感知规划，使机器人能够穿过非常狭窄的空间。我们在合成和真实高斯Splats中广泛测试了我们的算法，展示了ANYmal腿式机器人的无碰撞轨迹，即使有数十万高斯人组成环境，也可以在几秒钟内计算出来。项目页面和代码可在https://rffr.leggedrobotics.com/works/foci/ et.al.|[2505.08510](http://arxiv.org/abs/2505.08510)|null|
|**2025-05-13**|**A Survey of 3D Reconstruction with Event Cameras: From Event-based Geometry to Neural 3D Rendering**|事件相机已成为3D重建的有前景的传感器，因为它们能够异步捕获每像素的亮度变化。与传统的基于帧的相机不同，它们产生稀疏且时间丰富的数据流，这使得能够进行更精确的3D重建，并为在高速运动、低光照或高动态范围场景等极端环境中进行重建开辟了可能性。在这项调查中，我们提供了第一个专门针对使用事件相机进行3D重建的全面综述。该调查根据输入模态将现有作品分为三大类——立体、单眼和多模态系统，并通过重建方法进一步对其进行分类，包括基于几何、基于深度学习和最近的神经渲染技术，如神经辐射场和3D高斯散斑。具有相似研究重点的方法按时间顺序分为最细分的组。我们还总结了与基于事件的3D重建相关的公共数据集。最后，我们强调了当前在数据可用性、评估、表示和动态场景处理方面的研究局限性，并概述了未来有前景的研究方向。这项调查旨在为事件驱动的3D重建的未来发展提供全面的参考和路线图。 et.al.|[2505.08438](http://arxiv.org/abs/2505.08438)|null|
|**2025-05-13**|**ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image**|我们将自适应视图规划引入多视图合成，旨在提高单视图3D重建的遮挡显示和3D一致性。我们不是独立或同时生成一组无序的视图，而是生成一系列视图，利用时间一致性来增强3D一致性。最重要的是，我们的视图序列不是由预先确定的相机设置决定的。相反，我们计算自适应相机轨迹（ACT），具体来说，是相机视图的轨迹，它最大限度地提高了要重建的3D对象的遮挡区域的可见性。一旦找到最佳轨道，我们将其输入视频扩散模型，以生成轨道周围的新视图，然后将其传递给多视图3D重建模型，以获得最终重建。我们的多视图合成管道非常高效，因为它不涉及运行时训练/优化，只涉及通过应用预训练的模型进行遮挡分析和多视图合成的前向推理。我们的方法预测了相机轨迹，有效地揭示了遮挡并产生了一致的新视图，在看不见的GSO数据集上显著改善了SOTA的3D重建，无论是定量还是定性。 et.al.|[2505.08239](http://arxiv.org/abs/2505.08239)|null|
|**2025-05-12**|**RDD: Robust Feature Detector and Descriptor using Deformable Transformer**|作为从运动和SLAM构建结构的核心步骤，尽管存在普遍性，但在诸如显著视点变化等具有挑战性的场景下，鲁棒的特征检测和描述仍未得到解决。虽然最近的工作已经确定了局部特征在建模几何变换中的重要性，但这些方法未能学习到长距离关系中存在的视觉线索。我们提出了鲁棒可变形检测器（RDD），这是一种利用可变形变换器的新型鲁棒关键点检测器/描述符，它通过可变形的自关注机制捕获全局上下文和几何不变性。具体来说，我们观察到可变形注意力集中在关键位置，有效地降低了搜索空间的复杂性，并对几何不变性进行了建模。此外，除了标准的MegaDepth数据集外，我们还收集了一个空对地数据集进行训练。我们提出的方法在稀疏匹配任务中优于所有最先进的关键点检测/描述方法，并且还能够进行半密集匹配。为了确保全面评估，我们引入了两个具有挑战性的基准：一个强调大视角和尺度变化，另一个是空对地基准——这是一种最近在不同高度的3D重建中越来越受欢迎的评估设置。 et.al.|[2505.08013](http://arxiv.org/abs/2505.08013)|null|
|**2025-05-12**|**Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild**|使用体绘制技术的神经隐式表面重建最近在从多个2D图像创建高保真表面方面取得了重大进展。然而，目前的方法主要针对具有一致照明的场景，并且难以在具有瞬态遮挡或不同外观的不受控制的环境中准确重建3D几何体。虽然一些基于神经辐射场（NeRF）的变体可以更好地管理复杂场景中的光度变化和瞬态对象，但由于有限的表面约束，它们被设计用于新颖的视图合成，而不是精确的表面重建。为了克服这一局限性，我们引入了一种新方法，该方法将多个几何约束应用于隐式曲面优化过程，从而能够从无约束图像集合中进行更精确的重建。首先，我们利用运动结构中的稀疏3D点（SfM）来细化重建表面的带符号距离函数估计，并通过位移补偿来适应稀疏点中的噪声。此外，我们采用从法线预测器导出的鲁棒法线先验，并通过边缘先验滤波和多视图一致性约束进行增强，以改善与实际表面几何形状的对齐。对Heritage Recon基准和其他数据集的广泛测试表明，所提出的方法可以从野外图像中准确重建表面，与现有技术相比，可以产生具有更高精度和粒度的几何形状。我们的方法能够对各种地标进行高质量的3D重建，使其适用于各种场景，如文化遗产的数字保护。 et.al.|[2505.07373](http://arxiv.org/abs/2505.07373)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-16**|**QVGen: Pushing the Limit of Quantized Video Generative Models**|视频扩散模型（DM）实现了高质量的视频合成。然而，它们巨大的计算和内存需求对现实世界的部署构成了严重挑战，即使在高端GPU上也是如此。作为一种常用的解决方案，量化已被证明在降低图像DM的成本方面取得了显著成功，但将其直接应用于视频DM仍然无效。在本文中，我们提出了QVGen，这是一种新的量化感知训练（QAT）框架，专为极低比特量化（例如4比特或更低）下的高性能和推理高效视频DM而设计。我们从理论分析开始，证明降低梯度范数对于促进QAT的收敛至关重要。为此，我们引入了辅助模块（ $\Phi$）来减轻较大的量化误差，从而显著增强收敛性。为了消除$\Phi$的推理开销，我们提出了一种逐步消除$\Pi$的秩衰减策略。具体来说，我们反复使用奇异值分解（SVD）和提出的基于秩的正则化$\mathbf{\gamma}$来识别和衰减低贡献分量。此策略在保持性能的同时消除了推理开销。在4美元的最先进（SOTA）视频DM上进行的广泛实验表明，QVGen是第一个在4位设置下达到全精度可比质量的设备，参数大小从13美元到14美元不等。此外，它明显优于现有方法。例如，我们的3位CogVideoX-2B在VBench上的动态度和场景一致性分别提高了$25.28$和$+8.43$ 。 et.al.|[2505.11497](http://arxiv.org/abs/2505.11497)|null|
|**2025-05-16**|**Unsupervised Detection of Distribution Shift in Inverse Problems using Diffusion Models**|扩散模型在成像逆问题中被广泛用作先验。然而，在训练和测试时间图像之间的分布变化下，它们的性能往往会下降。用于识别和量化分布偏移的现有方法通常需要访问干净的测试图像，而在解决逆问题（在测试时）时，这些图像几乎永远不可用。我们提出了一种完全无监督的度量方法，仅使用间接（损坏）测量值和来自在不同数据集上训练的扩散模型的评分函数来估计分布变化。我们从理论上证明了该度量估计了训练和测试图像分布之间的KL散度。根据经验，我们表明，我们的基于分数的度量，仅使用损坏的测量值，非常接近从干净图像计算出的KL散度。受这一结果的启发，我们表明，将分布外得分与分布内得分对齐——仅使用损坏的测量值——可以减少KL散度，并提高多个逆问题的重建质量。 et.al.|[2505.11482](http://arxiv.org/abs/2505.11482)|null|
|**2025-05-16**|**PSDiffusion: Harmonized Multi-Layer Image Generation via Layout and Appearance Alignment**|扩散模型在从文本描述生成高质量图像方面取得了显著进展。LayerDiffuse等最新作品将之前的单层统一图像生成范式扩展到透明图像层生成。然而，现有的多层生成方法无法处理多层之间的交互，如合理的全局布局、物理上合理的接触以及阴影和反射等视觉效果，同时保持高阿尔法质量。为了解决这个问题，我们提出了PSDiffusion，这是一个用于同时生成多层文本到图像的统一扩散框架。我们的模型可以通过一个前馈过程自动生成具有一个RGB背景和多个RGBA前景的多层图像。与现有的组合多个工具进行后分解或顺序和单独生成层的方法不同，我们的方法引入了一种全局层交互机制，该机制并行协作地生成分层图像，不仅确保了每一层的高质量和完整性，还确保了层之间的空间和视觉交互以实现全局一致性。 et.al.|[2505.11468](http://arxiv.org/abs/2505.11468)|null|
|**2025-05-16**|**Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views**|基于视觉的机器人操纵使用相机捕捉包含待操纵对象的场景的一个或多个图像。如果任何物体从一个视点被遮挡，但从另一个视点更可见，拍摄多张图像会有所帮助。然而，必须将相机移动到一系列合适的位置以捕获多个图像，这需要时间，并且由于可达性限制，可能并不总是可能的。因此，虽然由于可用的额外信息，额外的图像可以产生更准确的抓握姿势，但时间成本会随着采样的额外视图数量的增加而增加。高斯散点等场景表示能够从用户指定的新颖视点渲染出精确的逼真虚拟图像。在这项工作中，我们展示了初步结果，表明新颖的视图合成可以在生成抓握姿势时提供额外的背景。我们在Grassnet-1十亿数据集上的实验表明，除了从稀疏采样的真实视图中获得的力闭合抓取外，新视图还贡献了力闭合抓取，同时提高了抓取覆盖率。未来，我们希望这项工作可以扩展到使用例如扩散模型或可推广的辐射场来改进从由单个输入图像构建的辐射场中提取的抓取。 et.al.|[2505.11467](http://arxiv.org/abs/2505.11467)|null|
|**2025-05-16**|**A Generative Framework for Causal Estimation via Importance-Weighted Diffusion Distillation**|从观察数据中估计个体化治疗效果是因果推断中的一个核心挑战，主要是由于协变量失衡和非随机治疗分配的混杂偏倚。虽然逆概率加权（IPW）是解决这个问题的一个行之有效的解决方案，但它与现代深度学习框架的集成仍然有限。在这项工作中，我们提出了重要性加权扩散蒸馏（IWDD），这是一种新的生成框架，将扩散模型的预训练与重要性加权分数蒸馏相结合，以实现准确快速的因果估计，包括潜在结果预测和治疗效果估计。我们演示了如何将IPW自然地纳入预训练扩散模型的蒸馏中，并进一步引入了基于随机化的调整，消除了显式计算IPW的需要，从而简化了计算，更重要的是，可证明地降低了梯度估计的方差。实证结果表明，IWDD实现了最先进的样本外预测性能，与其他基线相比，获胜率最高，显著改善了因果估计，并支持了个性化治疗策略的开发。我们将发布我们的PyTorch代码，用于可重复性和未来的研究。 et.al.|[2505.11444](http://arxiv.org/abs/2505.11444)|null|
|**2025-05-16**|**Combined Experimental and Computational Analysis of Lithium Diffusion in Isostructural Pair VNb9O25 and VTa9O25**|Wadsley-Roth晶体结构是一类有吸引力的电池材料，因为ReO3样块结构促进了锂的扩散，通过沿剪切面的边缘共享实现了电子传输。然而，清晰的结构-性能关系仍然有限，这使得开发改进的材料具有挑战性。这里报告了VTa9O25的首次锂化，从而能够与更为人所知的VNb9O25进行直接的同构比较。这些材料具有相似的晶胞体积和原子半径，但表现出不同的电压窗口、C速率相关容量和传输度量。时间依赖性过电位分析表明，在这两种情况下，离子扩散都是高速率性能的主要瓶颈，然而，VNb9O25的锂扩散率比VTa9O25快一个数量级。这些实验趋势与密度泛函理论计算和分子动力学相结合，表明VNb9O25中的扩散速度快了六倍。对可能跳跃路径的核弹性带计算表明，VNb9O25始终表现出较低的锂扩散活化势垒。Bader电荷分析揭示，由于Nb的电负性较高，VNb9O25中Li的净电荷较大，这稳定了过渡态并降低了势垒。这种稳定源于Li与其配位O环境之间更强的库仑相互作用。这些材料在锂化过程中表现相似，其中晶格矢量（对应于块体平面）增加，直到锂化约50%，然后减少。然而，电子结构不同，表明VNb9O25在较低的电荷状态下经历了绝缘体到金属的转变。总的来说，这项工作确定了阳离子（Nb或Ta）在锂化过程中对电子和输运性质的作用。 et.al.|[2505.11443](http://arxiv.org/abs/2505.11443)|null|
|**2025-05-16**|**Diff-Unfolding: A Model-Based Score Learning Framework for Inverse Problems**|扩散模型被广泛用于对逆问题的图像先验进行建模。我们引入\emph{Diff Unfolding}，这是一个通过将物理测量算子明确地结合到模块化网络架构中来学习\emph{条件扩散模型}的后验分数函数的原则框架。Diff Unfolding将后验分数学习表述为展开优化方案的训练，其中测量模型与先前学习的图像解耦。这种设计允许我们的方法在推理时通过简单地替换正向算子而无需重新训练来泛化逆问题。我们通过证明后验分数可以从基于复合模型的优化公式中得出，从理论上证明了我们的展开方法的合理性。对图像恢复和加速MRI的广泛实验表明，Diff Unfolding实现了最先进的性能，将PSNR提高了2 dB，将LPIPS降低了22.7美元，同时既紧凑（4700万个参数）又高效（每256美元乘以256美元的图像0.72秒）。优化的C++/LibTorch实现将推理时间进一步缩短到0.63秒，突显了我们方法的实用性。 et.al.|[2505.11393](http://arxiv.org/abs/2505.11393)|null|
|**2025-05-16**|**LipDiffuser: Lip-to-Speech Generation with Conditional Diffusion Models**|我们提出了LipDiffuser，这是一种用于唇语生成的条件扩散模型，可以直接从无声视频记录中合成自然和可理解的语音。我们的方法利用幅度保持烧蚀扩散模型（MP-ADM）架构作为降噪模型。为了有效地调节模型，我们使用幅度保持特征线性调制（MP-FiLM）和扬声器嵌入来结合视觉特征。然后，神经声码器根据生成的梅尔频谱图重建语音波形。对LRS3和TCD-TIMIT的评估表明，LipDiffuser在感知语音质量和说话者相似性方面优于现有的唇对语音基线，同时在下游自动语音识别（ASR）方面保持竞争力。这些发现也得到了正式听力实验的支持。广泛的消融研究和跨数据集评估证实了我们方法的有效性和泛化能力。 et.al.|[2505.11391](http://arxiv.org/abs/2505.11391)|null|
|**2025-05-16**|**Long-Term Average Impulse Control with Mean Field Interactions**|本文分析并给出了具有特定平均场相互作用的长期平均脉冲控制问题的显式解。其基本过程是具有适当边界行为的一般一维扩散。该模型的动力来自可再生自然资源的最佳长期管理和金融投资组合管理等应用。每个个体代理人都试图最大化长期平均回报，该回报由连续回报和离散冲动的收入组成，其中单位干预价格通过固定的供应率取决于市场。在竞争性市场环境中，我们在温和条件下，在一大类政策中建立均衡策略的存在性，并明确地描述其特征。此外，我们制定并解决了平均场控制问题，其中代理相互合作，旨在实现共同的最大长期平均利润。为了说明理论结果，我们研究了具有脉冲控制的随机环境中的随机逻辑斯谛增长模型和人口增长模型。 et.al.|[2505.11345](http://arxiv.org/abs/2505.11345)|null|
|**2025-05-16**|**MARRS: Masked Autoregressive Unit-based Reaction Synthesis**|这项工作旨在完成一项具有挑战性的任务：人类动作反应合成，即根据他人的动作序列作为条件产生人类反应。目前，自回归建模方法在运动生成任务中取得了显著的性能，例如文本到运动。然而，伴随自回归生成的矢量量化（VQ）具有固有的缺点，包括量化信息的丢失、码本利用率低等。此外，与仅关注身体关节运动的文本到运动不同，人体动作反应合成还包括精细的手部动作。在这项工作中，我们提出了MARRS，这是一种新的框架，旨在在连续表示中生成协调和精细的反应运动。最初，我们提出了单元区分的运动变分自动编码器（UD-VAE），它将整个身体分割成不同的身体和手单元，并独立编码。随后，我们提出了动作条件融合（ACF），它涉及随机屏蔽反应性令牌的子集，并从活动令牌中提取有关身体和手的特定信息。此外，我们引入了自适应单元调制（AUM），通过使用来自一个单元的信息来自适应地调制另一个单元，以促进身体和手单元之间的交互。最后，对于扩散模型，我们采用紧凑的MLP作为每个不同身体单元的噪声预测器，并结合扩散损失来模拟每个令牌的概率分布。定量和定性结果表明，我们的方法取得了优异的性能。代码将在验收后发布。 et.al.|[2505.11334](http://arxiv.org/abs/2505.11334)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-05-15**|**Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field**|近年来，在神经辐射场和3D高斯溅射技术的突破推动下，动态场景表示和重建取得了革命性的进展。虽然最初是为静态环境开发的，但这些方法已经通过广泛的研究迅速发展，以解决4D动态场景中固有的复杂性。结合可微分体绘制的创新，这些方法显著提高了运动表示和动态场景重建的质量，从而引起了计算机视觉和图形界的广泛关注。这项调查对200多篇论文进行了系统分析，这些论文侧重于使用辐射场进行动态场景表示，涵盖了从隐式神经表示到显式高斯基元的光谱。我们通过多个关键镜头对这些作品进行分类和评估：运动表示范式、不同场景动态的重建技术、辅助信息集成策略以及确保时间一致性和物理合理性的正则化方法。我们在统一的代表性框架下组织了不同的方法论方法，最后对持续存在的挑战和有前景的研究方向进行了批判性考察。通过提供这一全面的概述，我们的目标是为进入这一快速发展领域的研究人员建立一个明确的参考，同时为经验丰富的从业者提供对动态场景重建的概念原理和实践前沿的系统理解。 et.al.|[2505.10049](http://arxiv.org/abs/2505.10049)|**[link](https://github.com/moonflo/dynamic-radiation-field-paper-list)**|
|**2025-04-30**|**Neural Co-Optimization of Structural Topology, Manufacturable Layers, and Path Orientations for Fiber-Reinforced Composites**|我们提出了一种基于神经网络的计算框架，用于同时优化结构拓扑、弯曲层和路径方向，以在确保可制造性的同时实现纤维增强热塑性复合材料的强各向异性强度。我们的框架采用三个隐式神经场来表示几何形状、层序列和纤维取向。这使得设计和可制造性目标（如各向异性强度、结构体积、机器运动控制、层曲率和层厚度）能够直接公式化为一个集成和可微分的优化过程。通过将这些目标作为损失函数，该框架确保了所得复合材料具有优化的机械强度，同时保持了其在不同硬件平台上基于长丝的多轴3D打印的可制造性。物理实验表明，与具有顺序优化结构和制造顺序的复合材料相比，我们的协同优化方法产生的复合材料的破坏载荷可以提高33.1%。 et.al.|[2505.03779](http://arxiv.org/abs/2505.03779)|null|
|**2025-05-05**|**A New Perspective To Understanding Multi-resolution Hash Encoding For Neural Fields**|Instant NGP是近年来最先进的神经场架构。其令人难以置信的信号拟合能力通常归因于其多分辨率哈希网格结构，并在许多后续工作中得到了使用和改进。然而，目前尚不清楚这种哈希网格结构如何以及为什么能够如此大幅度地提高神经网络的能力。对哈希网格缺乏原则性的理解也意味着，伴随Instant NGP的大量超参数只能通过经验进行调整，而没有太多的启发式方法。为了直观地解释哈希网格的工作原理，我们提出了一种新的视角，即域操作。这一视角提供了一种全新的解释，即特征网格如何学习目标信号，并通过人工创建多个预先存在的线性段来提高神经场的表现力。我们对精心构建的一维信号进行了大量实验，以实证支持我们的主张，并辅助我们的说明。虽然我们的分析主要集中在一维信号上，但我们表明这个想法可以推广到更高的维度。 et.al.|[2505.03042](http://arxiv.org/abs/2505.03042)|**[link](https://github.com/stevolopolis/cp)**|
|**2025-04-27**|**HumMorph: Generalized Dynamic Human Neural Fields from Few Views**|我们介绍了HumMorph，这是一种新的广义方法，用于在显式姿态控制下对动态人体进行自由视点渲染。HumMorph以任意姿势渲染给定几个观察到的视图（从一个开始）的任何指定姿势的人类演员。我们的方法能够实现快速推理，因为它只依赖于通过模型的前馈传递。我们首先在规范T姿势中构建演员的粗略表示，该表示结合了来自个体部分观察的视觉特征，并使用学习到的先验知识填充缺失的信息。粗表示由直接从观察到的视图中提取的细粒度像素对齐特征补充，这些特征提供了高分辨率的外观信息。我们证明，当只有一个输入视图可用时，HumMorph与最先进的技术具有竞争力，但是，在仅进行2次单目观察的情况下，我们可以获得明显更好的视觉质量。此外，之前的广义方法假设可以使用同步的多相机设置获得精确的身体形状和姿势参数。相比之下，我们考虑了一种更实际的场景，其中这些身体参数直接从观察到的视图中进行噪声估计。我们的实验结果表明，我们的架构对噪声参数中的误差更具鲁棒性，在这种情况下明显优于最新技术。 et.al.|[2504.19390](http://arxiv.org/abs/2504.19390)|null|
|**2025-04-24**|**Geometry aware inference of steady state PDEs using Equivariant Neural Fields representations**|神经场的最新进展使学习神经算子的强大离散不变方法成为可能，这些算子在一般几何上近似偏微分方程（PDE）的解。基于这些发展，我们引入了enf2enf，这是一种基于最近提出的等变神经场架构的编码器-解码器方法，用于预测具有非参数化几何变异性的稳态偏微分方程。在enf2enf中，输入几何被编码为潜在的点云嵌入，这些嵌入固有地保留了几何基础并捕获了局部现象。然后将得到的表示与全局参数相结合，并直接解码为连续的输出场，从而有效地对几何和物理之间的耦合进行建模。通过利用局部性和平移不变性的归纳偏差，我们的方法能够捕捉精细尺度的物理特征以及复杂的形状变化，从而增强泛化能力和物理顺应性。对高保真空气动力学数据集、超弹性材料基准和多元素翼型几何形状的广泛实验表明，与最先进的基于图、操作员学习和神经场的方法相比，所提出的模型具有更优越或更具竞争力的性能。值得注意的是，我们的方法支持实时推理和零样本超分辨率，能够在低分辨率网格上进行高效训练，同时保持全尺寸离散化的高精度。 et.al.|[2504.18591](http://arxiv.org/abs/2504.18591)|**[link](https://github.com/giovannicatalani/enf2enf)**|
|**2025-04-28**|**Physics-Driven Neural Compensation For Electrical Impedance Tomography**|电阻抗断层成像（EIT）提供了一种非侵入性的便携式成像方式，在医疗和工业应用中具有巨大的潜力。尽管EIT具有优势，但它遇到了两个主要挑战：其逆问题的不适定性质和空间可变、位置相关的灵敏度分布。传统的基于模型的方法通过正则化来减轻病态性，但忽略了灵敏度的可变性，而监督深度学习方法需要大量的训练数据，缺乏泛化能力。神经领域的最新发展引入了用于图像重建的隐式正则化技术，但这些方法通常忽略了EIT背后的物理原理，从而限制了它们的有效性。在这项研究中，我们提出了PhyNC（物理驱动神经补偿），这是一个无监督的深度学习框架，结合了EIT的物理原理。PhyNC通过动态地将神经表征能力分配给灵敏度较低的区域，确保准确和平衡的电导率重建，解决了不适定逆问题和灵敏度分布问题。对模拟和实验数据的广泛评估表明，PhyNC在细节保存和抗伪影方面优于现有方法，特别是在低灵敏度区域。我们的方法增强了EIT重建的鲁棒性，并提供了一个灵活的框架，可以适应具有类似挑战的其他成像方式。 et.al.|[2504.18067](http://arxiv.org/abs/2504.18067)|null|
|**2025-04-23**|**Spot solutions to a neural field equation on oblate spheroids**|理解神经场中激发模式的动力学是神经科学的一个重要课题。神经场方程是描述相互作用神经元的激发动力学以进行理论分析的数学模型。尽管许多神经场方程的分析都集中在神经元相互作用对平面的影响上，但在对大脑等器官进行建模时，动力学的几何约束也是一个有吸引力的话题。本文报道了在球体作为模型曲面上定义的神经场方程中的模式动力学。我们将点解视为局部模式，并讨论曲面的几何特性如何改变它们的特性。为了分析具有小展平的球体上的斑点模式，我们首先在球面上构造精确的静止斑点解，并揭示它们的稳定性。然后，我们扩展了分析，以证明球状情况下驻点解的存在性和稳定性。我们的一个理论结果是推导了扁球体极点处定域的驻点解的稳定性判据。该标准决定了点解是保持在极点还是移动。最后，我们进行了数值模拟，根据我们的理论预测讨论了点解的动力学。我们的结果表明，点解的动力学取决于曲面和神经相互作用的协调。 et.al.|[2504.16342](http://arxiv.org/abs/2504.16342)|null|
|**2025-04-22**|**Low-Rank Adaptation of Neural Fields**|处理视觉数据通常涉及微小的调整或变化序列，例如图像滤波、表面平滑和视频存储。虽然现有的图形技术，如法线映射和视频压缩，利用冗余来有效地对这种小变化进行编码，但对神经场（NF）的小变化（视觉或物理功能的神经网络参数化）进行编码的问题却很少受到关注。我们提出了一种使用低秩自适应（LoRA）更新神经场的参数高效策略。LoRA是一种来自参数高效微调LLM社区的方法，它以最小的计算开销对预训练模型进行小更新编码。我们使LoRA适应特定于实例的神经场，避免了对大型预训练模型的需求，从而产生了适用于低计算硬件的流水线。我们通过图像滤波、视频压缩和几何编辑的实验验证了我们的方法，证明了它在表示神经场更新方面的有效性和通用性。 et.al.|[2504.15933](http://arxiv.org/abs/2504.15933)|null|
|**2025-04-21**|**Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields**|弱引力透镜是星系形状的轻微扭曲，主要是由宇宙中暗物质的引力效应引起的。在我们的工作中，我们试图从2D望远镜图像中反转弱透镜信号，以重建宇宙暗物质场的3D图。虽然反演通常会产生暗物质场的二维投影，但暗物质分布的精确三维图对于定位感兴趣的结构和测试我们宇宙的理论至关重要。然而，3D反演带来了重大挑战。首先，与依赖于多个视点的标准3D重建不同，在这种情况下，图像仅从单个视点观察。通过观察整个体积中的星系发射器是如何被透镜化的，可以部分解决这一挑战。然而，这导致了第二个挑战：无透镜星系的形状和确切位置是未知的，只能在非常大的不确定性下进行估计。这引入了大量的噪声，几乎完全淹没了透镜信号。以前的方法通过对卷中的结构施加强有力的假设来解决这个问题。相反，我们提出了一种使用引力约束神经场来灵活模拟连续物质分布的方法。我们采用综合分析方法，通过完全可微的物理正向模型优化神经网络的权重，以再现图像测量中存在的透镜信号。我们展示了我们的模拟方法，包括模拟即将到来的望远镜调查数据的暗物质分布的真实模拟测量。我们的结果表明，我们的方法不仅可以超越以前的方法，而且重要的是还能够恢复潜在的令人惊讶的暗物质结构。 et.al.|[2504.15262](http://arxiv.org/abs/2504.15262)|null|
|**2025-04-20**|**Efficient Implicit Neural Compression of Point Clouds via Learnable Activation in Latent Space**|隐式神经表示（INR），也称为神经场，已成为深度学习中的一种强大范式，使用基于坐标的神经网络对连续空间场进行参数化。在本文中，我们提出了\textbf{PICO}，这是一个基于INR的静态点云压缩框架。与主流的编码器-解码器范式不同，我们将点云压缩任务分解为两个单独的阶段：几何压缩和属性压缩，每个阶段都有不同的INR优化目标。受Kolmogorov-Arnold网络（KANs）的启发，我们引入了一种新的网络架构\textbf{LeAFNet}，它利用潜在空间中的可学习激活函数来更好地近似目标信号的隐函数。通过将点云压缩重新表述为神经参数压缩，我们通过量化和熵编码进一步提高了压缩效率。实验结果表明，\textbf{LeAFNet}在基于INR的点云压缩中优于传统的MLP。此外，与当前的MPEG点云压缩标准相比，\textbf{PICO}实现了卓越的几何压缩性能，D1 PSNR平均提高了4.92 $dB。在联合几何和属性压缩方面，我们的方法表现出了极具竞争力的结果，平均PCQM增益为2.7美元乘以10^{-3}$ 。 et.al.|[2504.14471](http://arxiv.org/abs/2504.14471)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

