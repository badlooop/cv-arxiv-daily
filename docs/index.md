---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.06.05
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-05-31**|**GS-Phong: Meta-Learned 3D Gaussians for Relightable Novel View Synthesis**|三维场景中的照明解耦对于新颖的视图合成和重新照明至关重要。在本文中，我们提出了一种新的方法，使用一组可重新照明的3D高斯点来表示点光源照明的场景。受Blinn Phong模型的启发，我们的方法将场景分解为环境光、漫反射和镜面反射组件，从而能够合成逼真的照明效果。为了便于独立于光照条件的几何信息的分解，我们引入了一种新的基于双层优化的元学习框架。其基本思想是将不同光照位置下的渲染任务视为一个多任务学习问题，我们的元学习方法不仅在不同的视点上，而且在不同的光照位置上推广所学习的高斯几何，从而有效地解决了这一问题。实验结果表明，与现有的自由视点重新照明方法相比，我们的方法在训练效率和渲染质量方面是有效的。 et.al.|[2405.20791](http://arxiv.org/abs/2405.20791)|null|
|**2024-05-31**|**ContextGS: Compact 3D Gaussian Splatting with Anchor Level Context Model**|近年来，三维高斯散射（3DGS）以其快速的渲染速度和高保真度，成为一种很有前途的新型视图合成框架。然而，大量的高斯及其相关属性需要有效的压缩技术。现有的方法主要单独和独立地压缩神经高斯，即同时对所有神经高斯进行编码，对它们的相互作用和空间依赖性几乎没有设计。受上下文模型在图像压缩中的有效性的启发，我们在这项工作中提出了第一个用于3DGS压缩的锚级别的自回归模型。我们将锚划分为不同的级别，并且可以在所有较粗级别中基于已经编码的锚来预测尚未编码的锚，从而实现更准确的建模和更高的编码效率。为了进一步提高熵编码的效率，例如，在没有已经编码的锚的情况下对最粗级别进行编码，我们建议引入低维量化特征作为每个锚的超优先级，该特征可以被有效压缩。我们的工作开创了3DGS表示的锚级别的上下文模型，与普通3DGS相比，尺寸缩小了100多倍，与最新的最先进的作品Scaffold GS相比，缩小了15倍，同时实现了相当甚至更高的渲染质量。 et.al.|[2405.20721](http://arxiv.org/abs/2405.20721)|**[link](https://github.com/wyf0912/contextgs)**|
|**2024-06-03**|**A Pixel Is Worth More Than One 3D Gaussians in Single-View 3D Reconstruction**|从单视图图像中学习3D场景表示是计算机视觉中一个长期存在的基本问题，在预测输入视图中看不到的内容时存在固有的模糊性。Splatter Image方法建立在最近提出的3D高斯Splatting（3DGS）的基础上，通过基于输入图像的U-Net特征图为每个像素学习单个3D高斯，在快速单图像新视图合成方面取得了有希望的进展。然而，表示在输入视图中无法观察到的遮挡组件的表达能力有限。为了解决这个问题，本文提出了一种分层飞溅图像方法，其中一个像素值超过一个三维高斯。具体地，每个像素由父3D高斯和少量子3D高斯表示。父3D高斯像在香草飞溅图像中一样学习。通过轻量级多层感知器（MLP）学习子3D高斯，MLP将父3D高斯的投影图像特征和目标相机视图的嵌入作为输入。父母和孩子的3D高斯都是以阶段性的方式端到端学习的。来自父母高斯人眼睛的输入图像特征和目标相机位置的联合条件有助于学习分配子高斯人“看不见的东西”，恢复父母高斯人经常错过的被遮挡的细节。在实验中，所提出的方法在ShapeNet SRN和CO3D数据集上进行了测试，获得了最先进的性能，特别是显示了在输入视图中重建被遮挡内容的良好能力。 et.al.|[2405.20310](http://arxiv.org/abs/2405.20310)|null|
|**2024-05-31**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|神经辐射场（NeRF）是一种开创性的计算机视觉技术，能够从多个视点生成高质量、身临其境的视觉内容。这种能力在虚拟/增强现实、3D建模以及电影和娱乐行业的内容创作等应用中具有显著优势。然而，NeRF方法的评估带来了一些挑战，包括缺乏全面的数据集、可靠的评估方法和客观的质量指标。本文通过进行严格的主观质量评估测试，全面解决了NeRF质量评估的问题，该测试考虑了几个场景类别和最近提出的NeRF视图合成方法。此外，根据主观研究的主观得分来评估各种最先进的传统和基于学习的全参考2D图像和视频质量评估指标的性能。对实验结果进行了深入分析，对不同类别的视觉场景中的几种NeRF方法和客观质量指标进行了比较评估，包括正面和360度相机轨迹的真实和合成内容。 et.al.|[2405.20078](http://arxiv.org/abs/2405.20078)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|NERF的进步已经允许3D场景重建和新颖的视图合成。然而，在保持照片真实性的同时有效地编辑这些表示是一个新出现的挑战。最近的方法面临三个主要限制：交互使用速度慢，对象边界缺乏精度，难以确保多视图的一致性。我们引入IReNe来解决这些限制，从而在NeRF中实现快速、接近实时的颜色编辑。利用预先训练的NeRF模型和带有用户应用的颜色编辑的单个训练图像，IReNe可以在几秒钟内快速调整网络参数。这种调整允许模型生成新的场景视图，准确地表示训练图像的颜色变化，同时控制对象边界和视图特定效果。通过将可训练分割模块集成到模型中来实现对象边界控制。该过程通过仅重新训练最后一个网络层的权重来提高效率。我们观察到，这一层的神经元可以分为负责视觉依赖性外观的神经元和有助于扩散外观的神经元。我们引入了一种自动分类方法来识别这些神经元类型，并专门微调扩散神经元的权重。这进一步加速了训练，并确保在不同视图中进行一致的颜色编辑。在经过编辑的对象颜色的新数据集上进行的彻底验证显示，与竞争对手相比，在数量和质量上都取得了显著进步，速度提高了5倍至500倍。 et.al.|[2405.19876](http://arxiv.org/abs/2405.19876)|null|
|**2024-05-30**|**GaussianPrediction: Dynamic 3D Gaussian Prediction for Motion Extrapolation and Free View Synthesis**|在动态环境中预测未来场景对于智能决策和导航至关重要，这是计算机视觉和机器人领域尚未完全实现的挑战。传统的方法，如视频预测和新颖的视图合成，要么缺乏从任意视点进行预测的能力，要么缺乏预测时间动态的能力。在本文中，我们介绍了GaussianPrediction，这是一种新的框架，它使3D高斯表示能够在动态环境中进行动态场景建模和未来场景合成。GaussianPrediction可以使用动态场景的视频观测，从任何角度预测未来的状态。为此，我们首先提出了一个具有变形建模的3D高斯正则空间，以捕捉动态场景的外观和几何结构，并将生命周期特性集成到高斯中以实现不可逆变形。为了使预测变得可行和高效，提出了一种通过提取关键点的场景运动来提取同心运动的方法。最后，使用图卷积网络来预测关键点的运动，从而能够绘制出未来场景的真实感图像。我们的框架在合成数据集和真实世界数据集上都表现出出色的性能，证明了它在预测和渲染未来环境方面的功效。 et.al.|[2405.19745](http://arxiv.org/abs/2405.19745)|null|
|**2024-05-30**|**GaussianRoom: Improving 3D Gaussian Splatting with SDF Guidance and Monocular Cues for Indoor Scene Reconstruction**|近年来，三维高斯散射（3DGS）以其高质量的渲染和实时速度彻底改变了神经渲染。然而，当涉及到具有大量无纹理区域的室内场景时，由于点云的初始化较差和优化受限，3DGS产生了不完整和有噪声的重建结果。受符号距离场（SDF）连续性的启发，我们提出了一个将神经SDF与3DGS相结合的统一优化框架，符号距离场在曲面建模中自然具有优势。该框架结合了一个可学习的神经SDF字段来指导高斯的加密和修剪，使高斯即使在初始化较差的点云情况下也能准确地对场景进行建模。同时，高斯表示的几何图形通过试点点采样提高了SDF场的效率。此外，我们使用法线和边缘先验对优化进行正则化，以消除无纹理区域中的几何模糊性并改进细节。在ScanNet和ScanNet++中进行的大量实验表明，我们的方法在表面重建和新视图合成方面都达到了最先进的性能。 et.al.|[2405.19671](http://arxiv.org/abs/2405.19671)|null|
|**2024-05-30**|**Uncertainty-guided Optimal Transport in Depth Supervised Sparse-View 3D Gaussian**|3D高斯飞溅在实时新颖视图合成中表现出了令人印象深刻的性能。然而，实现从RGB图像的成功重建通常需要在静态条件下捕获多个输入视图。为了解决稀疏输入视图的挑战，以前的方法已经将深度监督纳入3D高斯的训练中，以减轻过拟合，使用来自预训练的深度网络的密集预测作为伪地面实况。然而，单目深度估计模型的深度预测在特定区域固有地表现出显著的不确定性。仅仅依赖像素L2损失可能会无意中包含来自这些不确定区域的有害噪声。在这项工作中，我们介绍了一种新的方法来监督三维高斯的深度分布，利用深度先验和集成的不确定性估计。为了解决深度预测中的这些局部误差，我们集成了一种逐片优化传输策略，以补充深度监督中的传统L2损失。在LLFF、DTU和Blender数据集上进行的大量实验表明，我们的方法UGOT实现了卓越的新视图合成，并始终优于最先进的方法。 et.al.|[2405.19657](http://arxiv.org/abs/2405.19657)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|从预先捕获的单目胃镜图像中合成患者胃内任意新颖的视点图像是胃诊断中一个很有前途的课题。实现这一目标的典型方法集成了传统的三维重建技术，包括运动结构（SfM）和泊松曲面重建。这些方法产生显式的3D表示，例如点云和网格，从而能够从新的视点渲染图像。然而，胃内低纹理和非朗伯区域的存在往往会导致点云和网格重建的噪声和不完整，阻碍了高质量图像渲染的实现。本文将新兴的神经辐射场（NeRF）技术应用于单目胃镜数据，以合成新视点的照片逼真图像。为了解决单眼胃镜检查局部区域中由于视图稀疏而导致的性能下降问题，我们将来自预重建点云的几何先验纳入NeRF的训练中，这为预捕获的观察到的视图和生成的未观察到的图像引入了一种新的基于几何的损失。与最近的其他NeRF方法相比，我们的方法在定性和定量上都展示了从胃内新视角进行的高保真图像渲染。 et.al.|[2405.18863](http://arxiv.org/abs/2405.18863)|null|
|**2024-05-29**|**LP-3DGS: Learning to Prune 3D Gaussian Splatting**|近年来，三维高斯散射（3DGS）以其高质量和快速的渲染速度成为新视图合成（NVS）的主流方法之一。然而，作为一种基于点的场景表示，3DGS可能会生成大量高斯来适应场景，从而导致高内存使用率。已经提出的改进需要经验和预设的修剪比率或重要性得分阈值来修剪点云。这样的超参数需要多轮训练来优化和实现最大修剪率，同时保持每个场景的渲染质量。在这项工作中，我们提出了学习修剪3DGS（LP-3DGS），其中将可训练的二进制掩码应用于重要性得分，可以自动找到最佳修剪率。我们没有使用传统的直通估计器（STE）方法来近似二进制掩模梯度，而是重新设计了掩模函数，以利用Gumbel-Sigmoid方法，使其可微并与现有的3DGS训练过程兼容。大量实验表明，LP-3DGS始终能产生高效且高质量的良好平衡。 et.al.|[2405.18784](http://arxiv.org/abs/2405.18784)|**[link](https://github.com/dexgfsdfdsg/LP-3DGS)**|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-06-03**|**Physically Compatible 3D Object Modeling from a Single Image**|我们提出了一个计算框架，将单个图像转换为3D物理对象。图像中物理对象的视觉几何图形由三个正交属性决定：机械特性、外力和静止形状几何图形。现有的单视图3D重建方法往往忽略了这种潜在的组成，假定刚性或忽略外力。因此，重建的物体无法承受现实世界中的物理力，导致不稳定或不希望的变形——偏离了图像中所示的预期设计。我们的优化框架通过在重建过程中嵌入物理兼容性来解决这一问题。我们明确地分解了这三个物理属性，并通过静态平衡将它们联系起来，这是一个硬约束，确保优化的物理形状表现出所需的物理行为。对从Objaverse收集的数据集的评估表明，与现有方法相比，我们的框架始终增强了3D模型的物理真实性。我们的框架的实用性扩展到动态模拟和3D打印的实际应用，在这些应用中，遵守物理兼容性至关重要。 et.al.|[2405.20510](http://arxiv.org/abs/2405.20510)|null|
|**2024-05-30**|**Geometric Characterization of Rat Urinary Bladder Wall During Ex-Vivo Filling Using Micro-Computed Tomography (Micro-CT)**|本研究采用微型计算机断层扫描（micro-CT）来揭示大鼠膀胱壁在各种体外充盈状态下的几何复杂性，与通常理想化的均匀膀胱几何形状形成鲜明对比。通过分辨率在10-20微米之间的精确3D重建，这项研究仔细记录了膀胱在不同填充压力下的形态变化。这些发现说明了与均匀厚度的球形囊状物的理论模型的实质性偏差，特别是在从空隙状态到填充状态的过渡过程中，壁厚和囊状物体积的变化突出了这一点。这些结果对于完善膀胱功能的力学模型至关重要，传统上膀胱功能的机械模型过于简化了膀胱复杂的几何和生物力学行为。此外，这项研究强调了显微CT在深入了解膀胱力学方面的潜力，这对于推进膀胱出口梗阻（BOO）等疾病的治疗策略至关重要，从而增强手术和药物治疗模式。 et.al.|[2405.20454](http://arxiv.org/abs/2405.20454)|null|
|**2024-05-30**|**Learning 3D Robotics Perception using Inductive Priors**|深度学习的最新进展导致了以数据为中心的智能，即人工智能模型释放了吸收大量数据的潜力，并真正擅长执行数字任务，如文本到图像生成、机器-人类对话和图像识别。本文涵盖了利用结构化归纳偏见和先验知识进行学习的主题，以设计方法和算法来释放以原则为中心的智能的潜力。先验知识（简称先验）通常以过去的经验以及对世界如何运作的假设为依据，有助于自主主体更好地进行概括，并根据过去的经验调整其行为。在这篇论文中，我展示了先验知识在三个不同的机器人感知问题中的应用。1.以对象为中心的三维重建，2。决策的愿景和语言，以及3。3D场景理解。为了解决这些具有挑战性的问题，我提出了各种先验知识来源，包括1。来自合成数据的几何和外观先验，2。模块化和语义映射先验和3。语义、结构和上下文先验。我研究了解决机器人三维感知任务的这些先验，并提出了在深度学习模型中有效编码它们的方法。一些先验用于暖启动网络进行迁移学习，另一些则用作硬约束来限制机器人代理的动作空间。虽然经典技术很脆弱，无法推广到看不见的场景，并且以数据为中心的方法需要大量的标记数据，但本文旨在构建智能代理，这些智能代理需要很少的真实世界数据或仅从模拟中获取的数据，以推广到新模拟（即sim2sim）或真实世界看不见环境（即sim2real）中的高度动态和杂乱环境，从而对3D世界进行整体场景理解。 et.al.|[2405.20364](http://arxiv.org/abs/2405.20364)|null|
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|真实感街道场景的三维重建是开发自动驾驶真实世界模拟器的关键技术。尽管神经辐射场（NeRF）对驾驶场景很有效，但3D高斯散射（3DGS）由于其更快的速度和更明确的表示而成为一个有前途的方向。然而，大多数现有的街道3DGS方法需要跟踪的3D车辆边界框来分解静态和动态元素以进行有效的重建，这限制了它们在野外场景中的应用。为了在没有昂贵注释的情况下促进高效的3D场景重建，我们提出了一种自监督街道高斯（$\textit{S}^3$Gaussian）方法来从4D一致性分解动态和静态元素。我们用3D高斯表示每个场景，以保持其明确性，并进一步用时空场网络对其进行紧凑建模。我们在具有挑战性的Waymo Open数据集上进行了广泛的实验，以评估我们方法的有效性。我们的$\textit｛S｝^3$ Gaussian演示了分解静态和动态场景的能力，并在不使用3D注释的情况下实现了最佳性能。代码位于：https://github.com/nnanhuang/S3Gaussian/. et.al.|[2405.20323](http://arxiv.org/abs/2405.20323)|**[link](https://github.com/nnanhuang/s3gaussian)**|
|**2024-06-03**|**A Pixel Is Worth More Than One 3D Gaussians in Single-View 3D Reconstruction**|从单视图图像中学习3D场景表示是计算机视觉中一个长期存在的基本问题，在预测输入视图中看不到的内容时存在固有的模糊性。Splatter Image方法建立在最近提出的3D高斯Splatting（3DGS）的基础上，通过基于输入图像的U-Net特征图为每个像素学习单个3D高斯，在快速单图像新视图合成方面取得了有希望的进展。然而，表示在输入视图中无法观察到的遮挡组件的表达能力有限。为了解决这个问题，本文提出了一种分层飞溅图像方法，其中一个像素值超过一个三维高斯。具体地，每个像素由父3D高斯和少量子3D高斯表示。父3D高斯像在香草飞溅图像中一样学习。通过轻量级多层感知器（MLP）学习子3D高斯，MLP将父3D高斯的投影图像特征和目标相机视图的嵌入作为输入。父母和孩子的3D高斯都是以阶段性的方式端到端学习的。来自父母高斯人眼睛的输入图像特征和目标相机位置的联合条件有助于学习分配子高斯人“看不见的东西”，恢复父母高斯人经常错过的被遮挡的细节。在实验中，所提出的方法在ShapeNet SRN和CO3D数据集上进行了测试，获得了最先进的性能，特别是显示了在输入视图中重建被遮挡内容的良好能力。 et.al.|[2405.20310](http://arxiv.org/abs/2405.20310)|null|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|我们介绍了TetSphere splatting，这是一种显式的拉格朗日表示，用于重建具有高质量几何结构的3D形状。传统的对象重建方法主要使用欧拉表示，包括神经隐式（如NeRF、NeuS）和显式表示（如DMET），并且经常难以满足高计算要求和次优网格质量，与此相反，TetSphere splating使用了一种未充分使用但高效的几何基元——四面体网格。这种方法直接产生优越的网格质量，而不依赖于神经网络或后处理。它通过可微分渲染和几何能量优化的组合，使多个初始四面体球体变形，以准确重建3D形状，从而提高计算效率。作为一种强大而通用的几何表示，Tet Sphere splatting无缝集成到各种应用程序中，包括单视图3D重建、图像/文本到3D内容生成。实验结果表明，TetSphere飞溅优于现有的表示，提供了更快的优化速度、增强的网格质量和可靠的薄结构保存。 et.al.|[2405.20283](http://arxiv.org/abs/2405.20283)|null|
|**2024-05-30**|**Object-centric Reconstruction and Tracking of Dynamic Unknown Objects using 3D Gaussian Splatting**|可泛化感知是空间机器人高级自主的支柱之一。在动态环境中估计未知物体的结构和运动是这种自治系统的基础。传统上，解决方案依赖于目标对象的先验知识、多个不同的表示或不适合机器人操作的低保真度输出。这项工作提出了一种新的方法，使用统一的表示——一组描述其几何结构和外观的3D高斯斑点——来逐步重建和跟踪动态未知对象。可微分的三维高斯散射框架适用于动态的以对象为中心的设置。流水线的输入是一组连续的RGB-D图像。使用基于一阶梯度的优化来处理3D重建和6-DoF姿态跟踪任务。该公式简单，不需要预先训练，不假设物体或其运动的先验知识，适合在线应用。在10个不同几何形状和纹理的未知航天器在任意相对运动下的数据集上验证了所提出的方法。实验证明了在短到中等持续时间内，在邻近操作中成功地进行了目标物体的3D重建和精确的6-DoF跟踪。讨论了跟踪漂移的原因，并概述了可能的解决方案。 et.al.|[2405.20104](http://arxiv.org/abs/2405.20104)|null|
|**2024-05-29**|**Learning Mixture-of-Experts for General-Purpose Black-Box Discrete Optimization**|实际应用涉及各种离散优化问题。为这些问题中的每一个设计专门的优化器都是具有挑战性的，通常需要大量的领域知识和人力。因此，开发通用优化器作为解决一系列问题的现成工具一直是一个长期的研究目标。本文介绍了MEGO，这是一种通过完全数据驱动的学习优化（L2O）方法训练的新型通用神经优化器。MEGO由根据解决训练问题的经验训练的专家组成，可以被视为具有二元决策变量的优化问题的基础模型。当遇到需要解决的问题时，MEGO会主动选择相关的专家模型来生成高质量的解决方案。MEGO可以用作独立的高效样本优化器，也可以与现有的搜索方法一起用作初始解决方案生成器。在六个问题类中验证了MEGO的通用性，包括三个经典问题类和三个由编译器、网络分析和三维重建中的真实应用程序产生的问题类。仅在经典问题类上进行过培训，MEGO在所有六个问题类上都表现出色，在解决方案质量和效率方面显著超过了广泛使用的通用优化器。在某些情况下，MEGO甚至超越了最先进的专业优化器。此外，MEGO提供了问题之间的相似性度量，为问题分类提供了一个新的视角。在通过L2O追求通用优化器的过程中，MEGO代表了向前迈出的第一步，但意义重大。 et.al.|[2405.18884](http://arxiv.org/abs/2405.18884)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|从预先捕获的单目胃镜图像中合成患者胃内任意新颖的视点图像是胃诊断中一个很有前途的课题。实现这一目标的典型方法集成了传统的三维重建技术，包括运动结构（SfM）和泊松曲面重建。这些方法产生显式的3D表示，例如点云和网格，从而能够从新的视点渲染图像。然而，胃内低纹理和非朗伯区域的存在往往会导致点云和网格重建的噪声和不完整，阻碍了高质量图像渲染的实现。本文将新兴的神经辐射场（NeRF）技术应用于单目胃镜数据，以合成新视点的照片逼真图像。为了解决单眼胃镜检查局部区域中由于视图稀疏而导致的性能下降问题，我们将来自预重建点云的几何先验纳入NeRF的训练中，这为预捕获的观察到的视图和生成的未观察到的图像引入了一种新的基于几何的损失。与最近的其他NeRF方法相比，我们的方法在定性和定量上都展示了从胃内新视角进行的高保真图像渲染。 et.al.|[2405.18863](http://arxiv.org/abs/2405.18863)|null|
|**2024-05-28**|**FreeSplat: Generalizable 3D Gaussian Splatting Towards Free-View Synthesis of Indoor Scenes**|赋予3D高斯飞溅以泛化能力是很有吸引力的。然而，现有的可推广的3D高斯散点方法由于其主干较重，在很大程度上局限于立体图像之间的窄范围插值，因此缺乏准确定位3D高斯并支持宽视野范围内的自由视野合成的能力。在本文中，我们提出了一种新的框架FreeSplat，它能够从长序列输入到自由视图合成重建几何一致的3D场景。具体而言，我们首先介绍了低成本跨视图聚合，该聚合通过在附近视图之间构建自适应成本体积并使用多尺度结构聚合特征来实现。随后，我们提出了逐像素三元组融合，以消除重叠视图区域中3D高斯的冗余，并聚合在多个视图中观察到的特征。此外，我们提出了一种简单但有效的自由视图训练策略，无论视图的数量如何，都能确保在更广泛的视图范围内进行稳健的视图合成。我们的经验结果表明，在不同数量的输入视图中，新视图渲染的颜色图质量和深度图精度都具有最先进的新视图合成性能。我们还表明，FreeSplat可以更有效地执行推理，并可以有效地减少冗余高斯，为无深度先验的前馈大场景重建提供了可能性。 et.al.|[2405.17958](http://arxiv.org/abs/2405.17958)|**[link](https://github.com/wangys16/freesplat)**|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-05-31**|**Mixed Diffusion for 3D Indoor Scene Synthesis**|逼真的条件三维场景合成显著增强和加速了虚拟环境的创建，也可以为计算机视觉和机器人研究等应用提供广泛的训练数据。扩散模型在相关应用中表现出了良好的性能，例如，对无序集进行精确排列。然而，这些模型尚未在地板条件下的场景合成问题中得到充分的探索。我们介绍了MiDiffusion，这是一种新颖的混合离散连续扩散模型架构，旨在从给定的房间类型、平面图和潜在的预先存在的物体中合成合理的3D室内场景。我们通过二维平面图和一组对象来表示场景布局，每个对象都由其类别、位置、大小和方向定义。我们的方法在混合的离散语义和连续几何域上唯一地实现了结构化破坏，从而为反向去噪步骤带来了更好的条件问题。我们在3D-FRONT数据集上评估了我们的方法。我们的实验结果表明，MiDiffusion在地板条件的3D场景合成中显著优于最先进的自回归和扩散模型。此外，我们的模型可以通过破坏和掩蔽策略处理部分对象约束，而无需特定任务的训练。我们展示了MiDiffusion在场景完成和家具布置实验中比现有方法保持着明显的优势。 et.al.|[2405.21066](http://arxiv.org/abs/2405.21066)|null|
|**2024-05-31**|**Unified Directly Denoising for Both Variance Preserving and Variance Exploding Diffusion Models**|先前的工作已经证明，在方差保持（VP）场景中，新生的直接去噪扩散模型（DDDM）可以一步生成高质量的图像，同时在多步采样中实现更好的性能。然而，DDDM中使用的伪LPIPS损失导致了对评估中偏差的担忧。在这里，我们提出了一个统一的DDDM（uDDDM）框架，该框架在一步/多步中生成方差保持（VP）和方差分解（VE）情况下的图像。我们提供了模型解路径的存在性和唯一性的理论证明，以及采样路径的不相交性质。此外，我们还提出了一个自适应伪Huber损失函数，以平衡对真解的收敛性和收敛过程的稳定性。通过综合评估，我们证明uDDDM在VP和VE中实现的FID得分与CIFAR-10可用的最佳方法相当。具体而言，uDDDM实现了在CIFAR10上的一步生成，VE和VP的FID分别为2.63和2.53。通过将采样扩展到1000个步骤，我们进一步将VE和VP的FID得分分别降低到1.71和1.65，在这两种情况下都设置了最先进的性能。 et.al.|[2405.21059](http://arxiv.org/abs/2405.21059)|null|
|**2024-05-31**|**Spectrum-Aware Parameter Efficient Fine-Tuning for Diffusion Models**|以参数有效的方式适应大规模预先训练的生成模型越来越受欢迎。像低秩自适应这样的传统方法通过施加约束来实现参数效率，但对于需要高表示能力的任务来说可能不是最优的。我们为生成模型提出了一种新的频谱感知自适应框架。我们的方法调整预训练权重的奇异值及其基向量。使用Kronecker乘积和有效的Stiefel优化器，我们实现了正交矩阵的参数有效自适应。我们引入了谱正交分解自适应（SODA），它平衡了计算效率和表示能力。对文本到图像扩散模型的广泛评估证明了SODA的有效性，为现有的微调方法提供了一种频谱感知的替代方案。 et.al.|[2405.21050](http://arxiv.org/abs/2405.21050)|null|
|**2024-05-31**|**Kaleido Diffusion: Improving Conditional Diffusion Models with Autoregressive Latent Modeling**|扩散模型已经成为从文本描述生成高质量图像的强大工具。尽管这些模型取得了成功，但它们在采样图像中往往表现出有限的多样性，特别是当使用高的无分类器引导权重进行采样时。为了解决这个问题，我们提出了Kaleido，这是一种通过引入自回归潜在先验来增强样本多样性的新方法。Kaleido集成了一个自回归语言模型，该模型对原始字幕进行编码并生成潜在变量，作为指导和促进图像生成过程的抽象和中介表示。在本文中，我们探索了各种离散的潜在表示，包括文本描述、检测边界框、对象斑点和视觉标记。这些表示使扩散模型的输入条件多样化和丰富，从而实现更多样化的输出。我们的实验结果表明，Kaleido在保持高图像质量的同时，有效地拓宽了来自给定文本描述的生成图像样本的多样性。此外，我们还表明，Kaleido严格遵循生成的潜在变量提供的指导，证明了其有效控制和指导图像生成过程的能力。 et.al.|[2405.21048](http://arxiv.org/abs/2405.21048)|null|
|**2024-05-31**|**Beyond Conventional Parametric Modeling: Data-Driven Framework for Estimation and Prediction of Time Activity Curves in Dynamic PET Imaging**|动态正电子发射断层扫描（dPET）成像和时间-活性曲线（TAC）分析对于理解和量化放射性药物在时间和空间上的生物分布至关重要。传统的分区建模虽然是基础性的，但通常难以完全捕捉生物系统的复杂性，包括非线性动力学和可变性。这项研究引入了一种创新的数据驱动神经网络框架，其灵感来自反应扩散系统，旨在解决这些局限性。我们的方法自适应地拟合了来自dPET的TAC，能够直接校准观测数据中的扩散系数和反应项，与传统方法相比，在预测准确性和稳健性方面有了显著提高，尤其是在复杂的生物场景中。通过更准确地建模放射性药物的时空动力学，我们的方法推进了药代动力学和药效学过程的建模，为定量核医学提供了新的可能性。 et.al.|[2405.21021](http://arxiv.org/abs/2405.21021)|null|
|**2024-05-31**|**Amortizing intractable inference in diffusion models for vision, language, and control**|扩散模型已成为视觉、语言和强化学习中的有效分布估计器，但在下游任务中用作先验会带来棘手的后验推理问题。本文研究了由扩散生成模型先验 $p（\mathbf｛x｝）$和黑箱约束或似然函数$r（\mathbf｛x}）$组成的模型中后验数据$ \mathbf{x｝\sim p^｛\rm-post｝。我们陈述并证明了无数据学习目标相对轨迹平衡的渐近正确性，用于训练从该后验中采样的扩散模型，这是现有方法仅近似或在有限情况下解决的问题。相对轨迹平衡源于扩散模型的生成流网络视角，这允许使用深度强化学习技术来提高模式覆盖率。实验说明了在扩散先验下对任意后验进行无偏推理的广泛潜力：在视觉（分类器引导）、语言（在离散扩散LLM下填充）和多模式数据（文本到图像生成）中。除了生成建模之外，我们还将相对轨迹平衡应用于具有基于分数的行为先验的连续控制问题，在离线强化学习的基准上实现了最先进的结果。 et.al.|[2405.20971](http://arxiv.org/abs/2405.20971)|**[link](https://github.com/gfnorg/diffusion-finetuning)**|
|**2024-06-03**|**Large Language Models are Zero-Shot Next Location Predictors**|预测个人未来将访问的地点对于解决许多社会问题至关重要，如疾病传播和减少污染等。然而，设计用于处理下一个位置预测的模型需要大量的个人层面的信息才能有效地进行训练。在某些地理区域或特殊情况下（例如，推荐系统中的冷启动），此类数据可能稀缺，甚至不可用。此外，设计能够概括或在地理上转移知识的下一个位置预测器仍然是一个开放的研究挑战。自然语言处理的最新进展导致了大型语言模型（LLM）的快速传播，它们显示出良好的泛化和推理能力。这些见解，加上最近发现LLM具有丰富的地理知识，使我们相信这些模型可以作为零样本下一个位置的预测因子。本文评估了许多流行的LLM在这一角色中的能力，特别是Llama、GPT-3.5和Mistral 7B。在设计了适当的提示后，我们在三个真实世界的移动数据集上测试了模型。结果表明，LLM可以获得高达32.4%的精度，与专门为人类移动设计的复杂DL模型相比，这一精度显著提高了600%以上。此外，我们还表明其他LLM无法正确执行任务。为了防止出现有正偏差的结果，我们还提出了一个受其他研究启发的框架来测试数据污染。最后，我们探讨了使用LLM作为基于文本的解释器进行下一个位置预测的可能性，这表明LLM可以有效地为他们的决定提供解释。值得注意的是，与较大的模型相比，7B模型提供了更通用但仍然可靠的解释。代码：github.com/sai-trento/LLM-零-热NL et.al.|[2405.20962](http://arxiv.org/abs/2405.20962)|**[link](https://github.com/ssai-trento/llm-zero-shot-nl)**|
|**2024-05-31**|**Search of extended emission from HESS J1702-420 with eROSITA**|HESS J1702-420是一种特殊的TeV复合物，其形态从 $\lesssim 2$TeV的扩散（HESS J1701-420B源）转变为$\lessim 10$TeV能量的点状（HESS J1 702-420A）。HESS J1702-420的形态和光谱性质可以根据（扩散）强子或轻子模型来理解，在该模型中，观察到的TeV发射相应地产生于该区域中存在的相对论粒子的质子-质子或IC辐射。在这项工作中，我们对HESS J1702-420B源的X射线对应物进行了搜索，该源源于轻子或强子模型中产生的初级或次级相对论电子的同步辐射。这种发射可以在很大程度上超出像XMM-Newton这样的狭窄FoV仪器的探测能力。我们使用公开的前6个月eROSITA数据集（DR1），该数据集完全覆盖HESS J1702-420周围半径为$>5^\circ$-的分析区域。我们讨论了与该区域中可变等离子体温度/中性氢柱密度相关的偏差，并基于背景建模方法给出了结果。所进行的分析不允许我们检测到HESS J1702-420的扩展X射线对应物，其半径大小为0.07^\约-3^\约$-。导出的上限明显高于X射线对应物的预期强子模型通量。对于轻子模型，导出的极限表明区域$B\lesssim 2\mu$ G中的磁场。我们认为，扩散X射线对应物搜索的进一步进展可以通过下一代任务或使用当前运行的仪器进行Msec长期观测活动来实现。 et.al.|[2405.20927](http://arxiv.org/abs/2405.20927)|null|
|**2024-05-31**|**Flow matching achieves minimax optimal convergence**|流匹配作为一种无需仿真的生成模型，已经引起了人们的广泛关注。与基于随机微分方程的扩散模型不同，FM采用了一种更简单的方法，通过求解具有正态分布初始条件的常微分方程，从而简化了样本生成过程。本文用 $p$-Waserstein距离（一种分布差异的度量）讨论了FM的收敛性。我们建立了FM可以实现$1\leqp\leq2$ 的最小-最大最优收敛速度，这提供了第一个理论证据，证明FM可以达到与扩散模型相当的收敛速度。我们的分析通过检查向量场的一类更广泛的均值和方差函数来扩展现有框架，并确定了获得这些最优速率所需的特定条件。 et.al.|[2405.20879](http://arxiv.org/abs/2405.20879)|null|
|**2024-05-31**|**MegActor: Harness the Power of Raw Video for Vivid Portrait Animation**|尽管原始驾驶视频比肖像动画领域的地标等中间表示包含更丰富的面部表情信息，但它们很少成为研究的主题。这是由于原始视频驱动的人像动画固有的两个挑战：1）显著的身份泄露；2） 不相关的背景和面部细节（如皱纹）会降低性能。为了利用原始视频的力量制作生动的肖像动画，我们提出了一个名为MegActor的开创性条件扩散模型。首先，我们引入了一个合成数据生成框架，用于创建具有一致运动和表情但ID不一致的视频，以缓解ID泄漏的问题。其次，我们对参考图像的前景和背景进行分割，并使用CLIP对背景细节进行编码。然后通过文本嵌入模块将这些编码信息集成到网络中，从而确保背景的稳定性。最后，我们进一步将参考图像的外观风格转移到驾驶视频中，以消除驾驶视频中面部细节的影响。我们的最终模型仅在公共数据集上进行训练，取得了与商业模型相当的结果。我们希望这将有助于开源社区。代码位于https://github.com/megvii-research/MegFaceAnimate. et.al.|[2405.20851](http://arxiv.org/abs/2405.20851)|**[link](https://github.com/megvii-research/megfaceanimate)**|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-05-31**|**Neural Gaussian Scale-Space Fields**|高斯尺度空间是信号表示和处理的基石，在滤波、多尺度分析、抗混叠等方面都有应用。然而，获得这样的尺度空间是昂贵和繁琐的，特别是对于诸如神经场的连续表示。我们提出了一种有效且轻量级的方法来学习任意信号的全连续、各向异性高斯尺度空间。基于傅立叶特征调制和Lipschitz边界，我们的方法是自监督训练的，即训练不需要任何手动滤波。我们的神经高斯尺度空间场忠实地捕捉各种模态的多尺度表示，并支持多种应用。其中包括图像、几何、光台数据、纹理抗锯齿和多尺度优化。 et.al.|[2405.20980](http://arxiv.org/abs/2405.20980)|null|
|**2024-05-30**|**Gated Fields: Learning Scene Reconstruction from Gated Videos**|根据时间观测重建户外3D场景是一项挑战，最近在神经领域的工作为其提供了一条新的途径。然而，仅从RGB捕获恢复场景属性（如几何体、外观或辐射）的现有方法在处理光线不足或纹理不足的区域时往往会失败。同样，使用扫描激光雷达传感器恢复场景也很困难，因为它们的角采样率较低，这使得恢复广阔的真实世界场景变得困难。为了解决这些差距，我们介绍了门控场——一种利用主动门控视频序列的神经场景重建方法。为此，我们提出了一种无缝结合时间门控捕获和照明的神经渲染方法。我们的方法利用了门控视频中的内在深度线索，无论环境照明条件如何，都能实现精确而密集的几何重建。我们在昼夜场景中验证了该方法，并发现门控场与RGB和激光雷达重建方法相比是有利的。我们的代码和数据集可在https://light.princeton.edu/gatedfields/. et.al.|[2405.19819](http://arxiv.org/abs/2405.19819)|null|
|**2024-05-27**|**Extreme Compression of Adaptive Neural Images**|隐式神经表示（INRs）和神经场是一种新的信号表示范式，从图像和音频到3D场景和视频。其基本思想是将信号表示为连续且可微分的神经网络。这一思想提供了前所未有的优势，如连续分辨率和存储效率，从而实现了新的压缩技术。然而，将数据表示为神经网络带来了新的挑战。例如，给定一个2D图像作为神经网络，我们如何进一步压缩这样的神经图像？。在这项工作中，我们提出了一种新的压缩神经场的分析，重点是图像。我们还介绍了自适应神经图像（ANI），这是一种有效的神经表示，能够适应不同的推理或传输要求。我们提出的方法可以将神经图像的每像素比特数（bpp）减少4倍，而不会丢失敏感细节或损害保真度。我们之所以能做到这一点，是因为我们成功地实现了4位神经表示。我们的工作为开发压缩神经场提供了一个新的框架。 et.al.|[2405.16807](http://arxiv.org/abs/2405.16807)|null|
|**2024-05-24**|**Blaze3DM: Marry Triplane Representation with Diffusion for 3D Medical Inverse Problem Solving**|解决图像恢复和重建等三维医学逆问题在现代医学领域至关重要。然而，3D医疗数据中的维度诅咒导致主流的体积方法遭受高资源消耗，并挑战模型成功捕捉自然分布，导致不可避免的体积不一致和伪影。最近的一些工作试图简化潜在空间中的生成，但缺乏对复杂图像细节进行有效建模的能力。为了解决这些局限性，我们提出了Blaze3DM，这是一种新的方法，通过集成紧凑的三平面神经场和强大的扩散模型，实现了快速高保真的生成。在技术上，Blaze3DM首先同时优化数据相关的三平面嵌入和共享解码器，将每个三平面重建回相应的3D体积。为了进一步增强3D一致性，我们引入了一个轻量级的3D感知模块来对三个垂直平面的相关性进行建模。然后，在潜在的三平面嵌入上训练扩散模型，并实现无条件和有条件的三平面生成，最终解码为任意大小的体积。对零样本三维医学逆问题求解的大量实验，包括稀疏视图CT、有限角度CT、压缩传感MRI和MRI各向同性超分辨率，表明Blaze3DM不仅实现了最先进的性能，而且显著提高了现有方法的计算效率（比以前的工作快22~40倍）。 et.al.|[2405.15241](http://arxiv.org/abs/2405.15241)|null|
|**2024-05-17**|**SNF-ROM: Projection-based nonlinear reduced order modeling with smooth neural fields**|降阶建模通过从数据中学习低阶空间表示并使用控制方程的流形投影动态演化这些表示，降低了求解偏微分方程的计算成本。虽然通常使用线性子空间降阶模型（ROM），但对于Kolmogorov $n$ -宽度缓慢衰减的问题，例如高雷诺数下以平流为主的流体流动，通常是次优的。人们对非线性ROM越来越感兴趣，它使用最先进的表示学习技术以较少的自由度准确地捕捉这种现象。我们提出了光滑神经场ROM（SNF-ROM），这是一种将无网格简化表示与Galerkin投影相结合的非线性简化建模框架。SNF-ROM体系结构将学习到的ROM轨迹约束为平滑变化的路径，这在根据支配PDE遍历简化流形时的动力学评估中是有益的。此外，我们设计了鲁棒正则化方案，以确保学习的神经场是光滑和可微的。这使我们能够使用自动微分来非侵入地计算简化系统的基于物理的动力学，并使用经典时间积分器来演化简化系统。SNF-ROM可以实现快速的离线训练，并提高在线动力学评估的准确性和稳定性。我们证明了SNF-ROM在一系列平流主导的线性和非线性PDE问题上的有效性，在这些问题上，我们始终优于最先进的ROM。 et.al.|[2405.14890](http://arxiv.org/abs/2405.14890)|null|
|**2024-05-23**|**NeuroGauss4D-PCI: 4D Neural Fields and Gaussian Deformation Fields for Point Cloud Interpolation**|点云插值面临着点稀疏性、复杂的时空动力学以及从稀疏的时间信息中导出完整的三维点云的困难等挑战。本文介绍了NeuroGauss4D PCI，它擅长在各种动态场景中建模复杂的非刚性变形。该方法从迭代高斯云软聚类模块开始，提供结构化的时间点云表示。所提出的时间径向基函数高斯残差利用高斯参数随时间插值，实现平滑的参数转换并捕获高斯分布的时间残差。此外，4D高斯变形场跟踪这些参数的演变，创建连续的时空变形场。4D神经场将低维时空坐标（ $x，y，z，t$ ）转换为高维潜在空间。最后，我们自适应有效地融合了来自神经场的潜在特征和来自高斯变形场的几何特征。NeuroGauss4D PCI在点云帧插值方面优于现有方法，在对象级（DHB）和大规模自动驾驶数据集（NL Drive）上都提供了领先的性能，并可扩展到自动标记和点云加密任务。源代码发布于https://github.com/jiangchaokang/NeuroGauss4D-PCI. et.al.|[2405.14241](http://arxiv.org/abs/2405.14241)|**[link](https://github.com/jiangchaokang/neurogauss4d-pci)**|
|**2024-05-23**|**Multi-view Remote Sensing Image Segmentation With SAM priors**|遥感中的多视图分割（RS）寻求从场景内的不同视角对图像进行分割。最近的方法利用了从隐式神经场（INF）中提取的3D信息，增强了多个视图的结果一致性，同时使用有限的标签（甚至在3-5个标签内）来简化劳动力。尽管如此，由于不充分的全场景监督和INF中不充分的语义特征，在有限视图标签的约束下实现卓越性能仍然具有挑战性。我们建议将视觉基础模型Segment Anything（SAM）的先验注入INF，以在有限的训练数据下获得更好的结果。具体而言，我们对比测试视图和训练视图之间的SAM特征，以导出每个测试视图的伪标签，增强场景范围的标签信息。随后，我们通过转换器将SAM特征引入场景的INF中，补充语义信息。实验结果表明，我们的方法优于主流方法，证实了SAM作为INF的补充对该任务的有效性。 et.al.|[2405.14171](http://arxiv.org/abs/2405.14171)|null|
|**2024-05-22**|**Bridging Operator Learning and Conditioned Neural Fields: A Unifying Perspective**|算子学习是机器学习的一个新兴领域，旨在学习无穷维函数空间之间的映射。在这里，我们从计算机视觉中揭示了算子学习架构和条件神经场之间的联系，为研究流行的算子学习模型之间的差异提供了一个统一的视角。我们发现，许多常用的算子学习模型可以被视为神经场，其条件机制仅限于点和/或全局信息。受此启发，我们提出了连续视觉转换器（CViT），这是一种新的神经算子架构，它使用视觉转换器编码器，并使用交叉注意力来调制由可训练的基于网格的查询坐标位置编码构建的基场。尽管它很简单，但CViT在气候建模和流体动力学的挑战性基准中取得了最先进的结果。我们的贡献可以被视为在物理科学中适应先进的计算机视觉架构以构建更灵活、更准确的机器学习模型的第一步。 et.al.|[2405.13998](http://arxiv.org/abs/2405.13998)|**[link](https://github.com/predictiveintelligencelab/cvit)**|
|**2024-05-21**|**Unsupervised Searches for Cosmological Parity Violation: Improving Detection Power with the Neural Field Scattering Transform**|最近使用四点相关性的研究表明，星系分布中存在宇称破坏，尽管这些探测的重要性对用于模拟星系分布噪声特性的模拟的选择很敏感。在最近的一篇论文中，我们介绍了一种无监督学习方法，该方法提供了一种替代方法，通过直接从观测数据中学习奇偶性违反，避免了对模拟目录的依赖。然而，我们以前的无监督方法所使用的卷积神经网络（CNN）模型很难扩展到数据有限的更现实的场景。我们提出了一种新的方法，即神经场散射变换（NFST），它通过添加可训练滤波器来增强小波散射变换（WST）技术，该滤波器被参数化为神经场。我们首先调整NFST模型，以在简化的数据集中检测奇偶校验违规，然后在不同的训练集大小下，将其性能与WST和CNN基准进行比较。我们发现，NFST可以检测奇偶校验违规，数据比CNN少4倍，比WST少32倍。此外，在数据有限的情况下，NFST可以检测到高达 $6\sigma$ 置信度的奇偶校验违规，其中WST和CNN无法进行任何检测。我们发现，与基准模型相比，NFST增加的灵活性，特别是学习不对称滤波器的能力，以及NFST架构中内置的特定对称性，有助于提高其性能。我们进一步证明了NFST是易于解释的，这对于物理应用（如奇偶校验违反的检测）是有价值的。 et.al.|[2405.13083](http://arxiv.org/abs/2405.13083)|null|
|**2024-05-21**|**Implicit-ARAP: Efficient Handle-Guided Deformation of High-Resolution Meshes and Neural Fields via Local Patch Meshing**|在这项工作中，我们提出了神经符号距离场的局部补丁网格表示。该技术允许通过仅使用SDF信息及其梯度将平面面片网格投影和变形到标高集曲面上来离散输入SDF的标高集的局部区域。我们的分析表明，这种方法比标准的行进立方体算法更准确地逼近隐式曲面。然后，我们将这种表示应用于手柄引导变形的设置：我们引入了两个不同的管道，它们利用3D神经场来计算在给定约束集下高分辨率网格和神经场的“尽可能刚性”变形。我们对我们的方法和神经场和网格变形的各种基线进行了全面评估，结果表明，这两条管道在结果质量和稳健性方面都取得了令人印象深刻的效率和显著的改进。通过我们的新型流水线，我们引入了一种可扩展的方法来解决高分辨率网格上公认的几何处理问题，并为通过局部面片网格将其他几何任务扩展到隐式曲面领域铺平了道路。 et.al.|[2405.12895](http://arxiv.org/abs/2405.12895)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

