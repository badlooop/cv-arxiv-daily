---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.11.15
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-11-13**|**4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization**|动态场景的新颖视图合成在各种应用中变得越来越重要，包括增强现实和虚拟现实。我们提出了一种新的4D高斯散斑（4DGS）算法，用于随机记录的单眼视频中的动态场景。为了克服这些真实世界视频的现有工作的过拟合问题，我们引入了一种不确定性感知正则化，该正则化可以识别具有很少观测值的不确定区域，并基于扩散模型和深度平滑度在这些区域上选择性地施加额外的先验。该方法提高了新颖视图合成的性能和训练图像重建的质量。我们还发现了快速移动动态区域中4DGS的初始化问题，其中运动结构（SfM）算法无法提供可靠的3D地标。为了在这些区域中初始化高斯基元，我们提出了一种使用估计的深度图和场景流的动态区域致密化方法。我们的实验表明，所提出的方法提高了从手持单目相机捕获的视频中重建4DGS的性能，并且在少镜头静态场景重建中也显示出有前景的结果。 et.al.|[2411.08879](http://arxiv.org/abs/2411.08879)|null|
|**2024-11-13**|**BillBoard Splatting (BBSplat): Learnable Textured Primitives for Novel View Synthesis**|我们提出了一种基于纹理几何图元的3D场景表示新方法——广告牌飞溅（BBSplat）。BBSplat将场景表示为一组可优化的纹理平面图元，具有可学习的RGB纹理和阿尔法贴图来控制其形状。BBSplat基元可用于任何高斯Splatting管道中，作为高斯分布的插入式替换。当BBSplat达到1200 FPS以上时，当使用较少的基元时，我们的方法对3D和2D高斯的定性和定量改进最为明显。我们新颖的正则化项鼓励纹理具有更稀疏的结构，从而实现了高效的压缩，减少了模型的存储空间。我们的实验表明，BBSplat在真实室内和室外场景的标准数据集（如坦克和寺庙、DTU和Mip-NeRF-360）上的效率很高。与最新技术相比，我们展示了PSNR、SSIM和LPIPS指标的改进，特别是在使用较少基元的情况下，另一方面，在相同的渲染质量下，推理速度提高了2倍。 et.al.|[2411.08508](http://arxiv.org/abs/2411.08508)|null|
|**2024-11-13**|**DG-SLAM: Robust Dynamic Gaussian Splatting SLAM with Hybrid Pose Optimization**|在动态场景中实现鲁棒和精确的姿态估计是视觉同步定位和映射（SLAM）领域的一个重大研究挑战。最近将高斯散斑集成到SLAM系统中的进展已被证明在使用显式3D高斯模型创建高质量渲染方面是有效的，显著提高了环境重建的保真度。然而，这些方法依赖于静态环境假设，并且由于对几何和光度的不一致观测，在动态环境中面临挑战。为了解决这个问题，我们提出了DG-SLAM，这是第一个基于3D高斯的鲁棒动态视觉SLAM系统，它提供了精确的相机姿态估计和高保真重建。具体而言，我们提出了有效的策略，包括运动掩模生成、自适应高斯点管理和混合相机跟踪算法，以提高姿态估计的准确性和鲁棒性。大量实验表明，DG-SLAM在动态场景中的相机姿态估计、地图重建和新颖的视图合成方面具有最先进的性能，在保持实时渲染能力的同时优于现有方法。 et.al.|[2411.08373](http://arxiv.org/abs/2411.08373)|null|
|**2024-11-12**|**Novel View Synthesis with Pixel-Space Diffusion Models**|从单个输入图像合成新视图是一项具有挑战性的任务。传统上，这项任务是通过估计场景深度、扭曲和修复来完成的，机器学习模型支持部分管道。最近，生成模型越来越多地用于新颖视图合成（NVS），通常涵盖整个端到端系统。在这项工作中，我们采用了一种现代扩散模型架构，用于像素空间中的端到端NVS，其性能大大优于先前最先进的（SOTA）技术。我们探索了将几何信息编码到网络中的不同方法。我们的实验表明，虽然这些方法可以提高性能，但与使用改进的生成模型相比，它们的影响很小。此外，我们引入了一种新的NVS训练方案，该方案利用了单视图数据集，利用了它们与多视图数据集相比的相对丰富性。这提高了对具有域外内容的场景的泛化能力。 et.al.|[2411.07765](http://arxiv.org/abs/2411.07765)|null|
|**2024-11-14**|**Projecting Gaussian Ellipsoids While Avoiding Affine Projection Approximation**|最近，3D高斯散斑以其实时渲染速度和最先进的渲染质量主导了新颖的视图合成。然而，在渲染过程中，使用投影变换的仿射近似的雅可比矩阵会导致不可避免的误差，从而导致最终渲染图像中的模糊、伪影和缺乏场景一致性。为了解决这个问题，我们引入了一种基于椭球体的投影方法来计算高斯椭球体在图像平面上的投影，这是3D高斯散斑的基本方法。由于我们提出的基于椭球体的投影方法无法处理内部有相机原点或相机空间中位于 $z=0$ 平面以下的高斯椭球体，我们设计了一种预滤波策略。在多个广泛采用的基准数据集上的实验表明，我们的基于椭球体的投影方法可以提高3D高斯散斑及其扩展的渲染质量。 et.al.|[2411.07579](http://arxiv.org/abs/2411.07579)|null|
|**2024-11-11**|**A Hierarchical Compression Technique for 3D Gaussian Splatting Compression**|3D高斯散斑（GS）在新颖的视图合成中表现出优异的渲染质量和生成速度。然而，大量的数据量给存储和传输带来了挑战，使3D GS压缩成为一项必不可少的技术。当前的3D GS压缩研究主要集中在开发更紧凑的场景表示，例如将显式的3D GS数据转换为隐式形式。相比之下，GS数据本身的压缩几乎并没有得到探索。为了解决这一差距，我们提出了一种分层GS压缩（HGSC）技术。最初，我们根据从全局和局部重要性中得出的重要性得分来修剪不重要的高斯分布，有效地减少了冗余，同时保持了视觉质量。八叉树结构用于压缩3D位置。基于3D GS八叉树，我们采用KD树将3D GS划分为多个块，实现了一种分层属性压缩策略。我们应用最远点采样来选择每个块内的锚基元，并将其他锚基元作为具有不同细节级别（LoD）的非锚基元。锚基元用作跨不同LoD预测非锚基元的参考点，以减少空间冗余。对于锚基元，我们使用区域自适应分层变换来实现各种属性的近无损压缩。对于非锚基元，每个基元都是基于k个最近的锚基元进行预测的。为了进一步最小化预测误差，将重建的LoD和锚基元组合在一起，形成新的锚基元，以预测下一个LoD。与小型场景数据集上最先进的压缩方法相比，我们的方法显著实现了卓越的压缩质量，数据大小大幅减少了4.5倍以上。 et.al.|[2411.06976](http://arxiv.org/abs/2411.06976)|null|
|**2024-11-10**|**Adaptive and Temporally Consistent Gaussian Surfels for Multi-view Dynamic Reconstruction**|3D高斯散点最近在动态场景的新颖视图合成和静态场景的几何重建方面取得了显著成功。在这些进步的基础上，通过全局优化整个序列，开发了用于动态表面重建的早期方法。然而，重建具有显著拓扑变化、出现或消失的物体以及快速运动的动态场景仍然是一个巨大的挑战，特别是对于长序列。为了解决这些问题，我们提出了AT-GS，这是一种通过每帧增量优化从多视图视频中重建高质量动态曲面的新方法。为了避免跨帧的局部最小值，我们引入了一种统一的自适应梯度感知致密化策略，该策略整合了传统克隆和分裂技术的优势。此外，我们通过确保连续帧中曲率图的一致性来减少动态曲面中的时间抖动。我们的方法在动态表面重建中实现了卓越的精度和时间相干性，即使在复杂和具有挑战性的场景中也能提供高保真的时空新颖视图合成。对不同多视图视频数据集的广泛实验证明了我们的方法的有效性，显示出比基线方法明显的优势。项目页面：\url{https://fraunhoferhhi.github.io/AT-GS} et.al.|[2411.06602](http://arxiv.org/abs/2411.06602)|null|
|**2024-11-12**|**SplatFormer: Point Transformer for Robust 3D Gaussian Splatting**|3D高斯散斑（3DGS）最近改变了真实感重建，实现了高视觉保真度和实时性能。然而，当测试视图偏离训练期间使用的相机角度时，渲染质量会显著下降，这对沉浸式自由视点渲染和导航的应用程序构成了重大挑战。在这项工作中，我们对3DGS和相关的新型视图合成方法在非分布（OOD）测试相机场景下进行了全面评估。通过使用合成和真实世界的数据集创建不同的测试用例，我们证明了大多数现有的方法，包括那些结合了各种正则化技术和数据驱动先验的方法，都难以有效地推广到面向对象的视图。为了解决这一局限性，我们引入了SplatFormer，这是第一个专门设计用于操作高斯斑点的点变换器模型。SplatFormer将在有限训练视图下优化的初始3DGS集作为输入，并在一次前向传递中对其进行细化，有效地消除了OOD测试视图中的潜在伪影。据我们所知，这是点变换器直接在3DGS集上的首次成功应用，超越了以前多场景训练方法的局限性，这些方法在推理过程中只能处理有限数量的输入视图。我们的模型显著提高了极端新颖视图下的渲染质量，在这些具有挑战性的场景中实现了最先进的性能，并优于各种3DGS正则化技术、为稀疏视图合成量身定制的多场景模型和基于扩散的框架。 et.al.|[2411.06390](http://arxiv.org/abs/2411.06390)|**[link](https://github.com/ChenYutongTHU/SplatFormer)**|
|**2024-11-10**|**Through the Curved Cover: Synthesizing Cover Aberrated Scenes with Refractive Field**|最近的扩展现实耳机和现场机器人已经采用了覆盖物来保护前置摄像头免受环境危害和坠落。盖子上的表面不规则性会导致光学像差，如模糊和非参数失真。NeRF和3D高斯散斑等新型视图合成方法不适合从具有光学像差的序列进行合成。为了应对这一挑战，我们引入了SynthCover，通过保护罩为下游扩展现实应用实现新颖的视图合成。SynthCover采用折射场来估计覆盖物的几何形状，从而能够对折射光线进行精确的分析计算。在合成场景和真实场景上的实验表明，我们的方法能够准确地模拟通过保护罩看到的场景，与现有方法相比，渲染质量有了显著提高。我们还表明，该模型可以很好地适应各种覆盖几何形状，并使用不同表面曲率的覆盖物捕获合成序列。为了推动对这一问题的进一步研究，我们提供了包含用保护罩光学像差捕获的真实和合成可步行场景的基准数据集。 et.al.|[2411.06365](http://arxiv.org/abs/2411.06365)|null|
|**2024-11-09**|**GaussianSpa: An "Optimizing-Sparsifying" Simplification Framework for Compact and High-Quality 3D Gaussian Splatting**|3D高斯散斑（3DGS）已成为新型视图合成的主流，利用高斯函数的连续聚合来模拟场景几何。然而，3DGS需要大量的内存来存储大量的高斯人，这阻碍了它的实用性。为了应对这一挑战，我们引入了GaussiansSpa，这是一个基于优化的简化框架，用于紧凑和高质量的3DGS。具体来说，我们将简化问题表述为与3DGS训练相关的优化问题。相应地，我们提出了一种高效的“优化稀疏”解决方案，交替解决两个独立的子问题，在训练过程中逐渐将强稀疏性强加到高斯算子上。我们对各种数据集的综合评估表明，GaussianSpa优于现有的最先进方法。值得注意的是，GaussianSpa在真实世界的深度混合数据集上实现了0.9 dB的平均PSNR改善，与普通3DGS相比，Gaussian减少了10倍。我们的项目页面可在https://gaussianspa.github.io/. et.al.|[2411.06019](http://arxiv.org/abs/2411.06019)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-11-13**|**Biomass phenotyping of oilseed rape through UAV multi-view oblique imaging with 3DGS and SAM model**|油菜生物量估算对于优化作物生产力和育种策略至关重要。虽然基于无人机的成像具有先进的高通量表型，但目前的方法通常依赖于正射影像图像，在复杂的野外环境中，正射影像难以处理重叠的叶子和不完整的结构信息。本研究将3D高斯散点（3DGS）与分段任意模型（SAM）相结合，用于油菜的精确3D重建和生物量估算。使用来自36个角度的无人机多视角斜向图像进行3D重建，SAM模块增强了点云分割。然后将分割的点云转换为点云体积，使用线性回归将其与地面测量的生物量进行拟合。结果表明，3DGS（7k和30k迭代）提供了高精度，峰值信噪比（PSNR）分别为27.43和29.53，训练时间分别为7和49分钟。该性能超越了运动结构（SfM）和mipmap神经辐射场（Mip-NeRF），展现出卓越的效率。SAM模块实现了高分割精度，平均交集超过并集（mIoU）为0.961，F1得分为0.980。此外，对生物质提取模型的比较发现，点云体积模型是最准确的，其决定系数（R2）为0.976，均方根误差（RMSE）为2.92 g/株，平均绝对百分比误差（MAPE）为6.81%，优于地块作物体积和单个作物体积模型。这项研究强调了将3DGS与多视图无人机成像相结合以改善生物量表型的潜力。 et.al.|[2411.08453](http://arxiv.org/abs/2411.08453)|null|
|**2024-11-12**|**Constraints on local primordial non-Gaussianity with 3d Velocity Reconstruction from the Kinetic Sunyaev-Zeldovich Effect**|宇宙速度场是总物质分布的无偏探测器，但在中等和高红移下直接测量具有挑战性。大尺度速度场通过动力学Sunyaev-Zeldovich（kSZ）效应在宇宙微波背景（CMB）中留下信号。我们通过将二次估计器应用于CMB温度图和星系的三维位置，从kSZ效应对大尺度速度场进行了首次三维重建。我们通过结合阿塔卡马宇宙学望远镜（与普朗克望远镜结合）第五次数据发布的CMB数据和斯隆数字巡天的光谱星系样本来实现这一目标。然后，我们测量了星系速度交叉功率谱，并在信噪比为7.2 $\sigma$时检测到kSZ信号的存在。仅使用这个星系速度互相关，我们约束了局部原始非高斯性的振幅，发现$f_{\rm NL}=-90 ^{+210}_{-350}$。这一探路者测量为联合星系CMB-kSZ约束奠定了基础，通过样本方差抵消显著增强了从星系调查中获得的$f_{\rm NL}$ 信息。 et.al.|[2411.08240](http://arxiv.org/abs/2411.08240)|null|
|**2024-11-12**|**SP-VIO: Robust and Efficient Filter-Based Visual Inertial Odometry with State Transformation Model and Pose-Only Visual Description**|基于滤波器的视觉惯性里程计（VIO）具有计算效率高、内存需求小的优点，在小型化和有效载荷受限的嵌入式系统中具有良好的应用前景。然而，基于滤波器的方法存在精度不足的问题。为此，我们通过重建状态和测量模型，并考虑进一步的视觉剥夺条件，提出了状态转换和仅姿态VIO（SP-VIO）。详细地说，我们首先提出了一种基于双状态变换扩展卡尔曼滤波器（DST-EKF）的系统模型，该模型已被证明比基于扩展卡尔曼滤波器和状态变换扩展Kalman滤波器的模型具有更好的可观测性和一致性。其次，为了减少由不准确的3D重建引起的线性化误差的影响，我们采用仅位姿（PO）理论将测量模型与3D特征解耦。此外，为了应对视觉剥夺的情况，我们提出了一种双态变换Rauch Tung-Striebel（DST-RTS）回溯方法来优化视觉中断期间的运动轨迹。在公共（EuRoC、Tum VI、KITTI）和个人数据集上的实验表明，SP-VIO比最先进的（SOTA）VIO算法具有更好的准确性和效率，并且在视觉剥夺条件下具有更好的鲁棒性。 et.al.|[2411.07551](http://arxiv.org/abs/2411.07551)|null|
|**2024-11-12**|**Extreme Rotation Estimation in the Wild**|我们提出了一种技术和基准数据集，用于估计在极端环境中捕获的一对互联网图像之间的相对3D方向，其中图像具有有限或不重叠的视场。之前针对极端旋转估计的工作假设了受约束的3D环境，并通过从全景图中裁剪区域来模拟透视图像。然而，在野外拍摄的真实图像非常多样化，在外观和相机内部都表现出变化。在这项工作中，我们提出了一种基于Transformer的方法来估计极端现实环境中的相对旋转，并贡献了由场景级互联网照片集组装而成的ExtremeLandmarkPairs数据集。我们的评估表明，我们的方法成功地估计了各种极端视图互联网图像对中的相对旋转，优于各种基线，包括专用旋转估计技术和当代3D重建方法。 et.al.|[2411.07096](http://arxiv.org/abs/2411.07096)|null|
|**2024-11-11**|**AV-PedAware: Self-Supervised Audio-Visual Fusion for Dynamic Pedestrian Awareness**|在这项研究中，我们介绍了AV PedAware，这是一种自我监督的视听融合系统，旨在提高机器人应用中的动态行人感知能力。行人意识是许多机器人应用中的关键要求。然而，依赖相机和LIDAR覆盖多个视图的传统方法可能很昂贵，并且容易受到光照、遮挡和天气条件变化等问题的影响。我们提出的解决方案使用低成本的音频和视觉融合来复制人类对3D行人检测的感知。这项研究首次尝试利用视听融合来监测脚步声，以预测附近行人的运动。该系统通过基于激光雷达生成标签的自我监督学习进行训练，使其成为基于激光雷达的行人感知的经济高效的替代方案。AV PedAware以极低的成本实现了与基于激光雷达的系统相当的结果。通过利用注意力机制，它可以处理动态照明和遮挡，克服了传统激光雷达和基于相机的系统的局限性。为了评估我们的方法的有效性，我们收集了一个新的多模式行人检测数据集，并进行了实验，证明该系统即使在极端的视觉条件下，也能仅使用音频和视觉数据提供可靠的3D检测结果。我们将把收集到的数据集和源代码在线提供给社区，以鼓励机器人感知系统领域的进一步发展。 et.al.|[2411.06789](http://arxiv.org/abs/2411.06789)|null|
|**2024-11-10**|**Real-time Deformation-aware Control for Autonomous Robotic Subretinal Injection under iOCT Guidance**|机器人平台提供可重复和精确的工具定位，显著增强视网膜显微手术。这种系统与术中光学相干断层扫描（iOCT）的集成实现了图像引导的机器人干预，允许自主执行高级治疗可能性，例如将治疗剂注射到视网膜下腔。然而，在自主iOCT引导的机器人视网膜下注射中，由于工具-组织相互作用导致的组织变形是一个主要挑战，会影响正确的针头定位，从而影响手术的结果。本文提出了一种在iOCT引导下自主视网膜下注射的新方法，该方法考虑了插入过程中的组织变形。这是通过从密集采样的iOCT B扫描（我们称之为B5扫描）中实时分割和3D重建手术场景来实现的，以监测仪器相对于ILM和RPE之间相对位置处定义的虚拟目标层的定位。我们在离体猪眼睛上的实验表明，与之前的自主插入方法相比，插入深度的动态调整和针头定位的整体精度得到了提高。与之前方法生成视网膜下泡的成功率为35%相比，我们提出的方法在所有实验中都可靠、稳健地创建了视网膜下泡。 et.al.|[2411.06557](http://arxiv.org/abs/2411.06557)|null|
|**2024-11-10**|**A novel algorithm for optimizing bundle adjustment in image sequence alignment**|捆绑调整（BA）模型通常使用非线性最小二乘法进行优化，Levenberg-Marquardt（L-M）算法是典型的选择。然而，尽管L-M算法很有效，但当应用于条件较差的数据集时，它对初始条件的敏感性往往会导致收敛速度较慢，从而激发了对替代优化策略的探索。本文介绍了一种在低温电子断层成像图像序列比对背景下优化BA模型的新算法，该算法利用最优控制理论直接优化一般非线性函数。所提出的最优控制算法（OCA）表现出优异的收敛速度，并有效地缓解了L-M算法中经常观察到的振荡行为。对合成数据集和真实世界数据集进行了广泛的实验，以评估算法的性能。结果表明，与L-M算法相比，OCA实现了更快的收敛。此外，基于二分法的更新过程显著提高了OCA的性能，特别是在初始化不佳的数据集中。这些发现表明，OCA可以大大提高低温电子断层扫描中3D重建的效率。 et.al.|[2411.06343](http://arxiv.org/abs/2411.06343)|null|
|**2024-11-08**|**Benchmarking 3D multi-coil NC-PDNet MRI reconstruction**|深度学习在从欠采样数据中重建MRI方面显示出巨大的前景，但目前还缺乏对其在非笛卡尔欠采样的3D并行成像采集中的性能进行验证的研究。此外，伪影和由此产生的图像质量取决于欠采样模式。为了解决这一未知领域的问题，我们将非笛卡尔原始双网络（NC PDNet）扩展到3D多线圈设置，这是一种最先进的展开神经网络。我们评估了通道特定训练配置与通道无关训练配置的影响，并检查了线圈压缩的效果。最后，我们使用公开的卡尔加里坎皮纳斯数据集，对四种不同的非笛卡尔欠采样模式进行基准测试，加速因子为6。我们的结果表明，在具有不同输入通道数的压缩数据上训练的NC PDNet在1mm各向同性32通道全脑3D重建中实现了42.98 dB的平均PSNR。推理时间为4.95秒，GPU内存使用率为5.49 GB，我们的方法在临床研究应用中具有巨大的潜力。 et.al.|[2411.05883](http://arxiv.org/abs/2411.05883)|null|
|**2024-11-07**|**MVSplat360: Feed-Forward 360 Scene Synthesis from Sparse Views**|我们介绍MVSplat360，这是一种前馈方法，用于仅使用稀疏观测对不同现实世界场景进行360度新颖视图合成（NVS）。由于输入视图之间的最小重叠和提供的视觉信息不足，这种设置本身就不合适，这使得传统方法难以实现高质量的结果。我们的MVSplat360通过有效地将几何感知3D重建与时间一致的视频生成相结合来解决这个问题。具体来说，它重构了一个前馈的3D高斯散斑（3DGS）模型，将特征直接渲染到预训练的稳定视频扩散（SVD）模型的潜在空间中，然后这些特征作为姿态和视觉线索来指导去噪过程，并产生逼真的3D一致视图。我们的模型是端到端可训练的，支持用少至5个稀疏输入视图渲染任意视图。为了评估MVSplat360的性能，我们使用具有挑战性的DL3DV-10K数据集引入了一个新的基准，与最先进的方法相比，MVSplat36在宽扫甚至360度NVS任务中实现了卓越的视觉质量。在现有基准RealEstate10K上的实验也证实了我们模型的有效性。视频结果可在我们的项目页面上查看：https://donydchen.github.io/mvsplat360. et.al.|[2411.04924](http://arxiv.org/abs/2411.04924)|**[link](https://github.com/donydchen/mvsplat360)**|
|**2024-11-07**|**Differentiable Gaussian Representation for Incomplete CT Reconstruction**|不完全计算机断层扫描（CT）通过减少辐射暴露使患者受益。然而，由于问题的不适定性质，从有限的视图或角度重建高保真图像仍然具有挑战性。深度学习重建（DLR）方法在提高图像质量方面显示出了希望，但训练数据多样性和高泛化能力之间的悖论仍未得到解决。在这篇论文中，我们提出了一种新的不完全CT重建的高斯表示法（GRCT），无需使用任何神经网络或全剂量CT数据。具体来说，我们将3D体积建模为一组可学习的高斯分布，这些高斯分布直接从不完整的正弦图中优化。我们的方法可以应用于多个视图和角度，而无需改变架构。此外，我们提出了一种可区分的快速CT重建方法，以实现高效的临床应用。在多个数据集和设置上进行的广泛实验表明，重建质量指标和效率有了显著提高。我们计划以开源的形式发布我们的代码。 et.al.|[2411.04844](http://arxiv.org/abs/2411.04844)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-11-13**|**4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization**|动态场景的新颖视图合成在各种应用中变得越来越重要，包括增强现实和虚拟现实。我们提出了一种新的4D高斯散斑（4DGS）算法，用于随机记录的单眼视频中的动态场景。为了克服这些真实世界视频的现有工作的过拟合问题，我们引入了一种不确定性感知正则化，该正则化可以识别具有很少观测值的不确定区域，并基于扩散模型和深度平滑度在这些区域上选择性地施加额外的先验。该方法提高了新颖视图合成的性能和训练图像重建的质量。我们还发现了快速移动动态区域中4DGS的初始化问题，其中运动结构（SfM）算法无法提供可靠的3D地标。为了在这些区域中初始化高斯基元，我们提出了一种使用估计的深度图和场景流的动态区域致密化方法。我们的实验表明，所提出的方法提高了从手持单目相机捕获的视频中重建4DGS的性能，并且在少镜头静态场景重建中也显示出有前景的结果。 et.al.|[2411.08879](http://arxiv.org/abs/2411.08879)|null|
|**2024-11-13**|**On the number of crossings and bouncings of a diffusion at a sticky threshold**|我们区分了一维粘性扩散过程在粘性阈值下的三种交叉行为，并分析了在粘性布朗运动的情况下，三种相应交叉次数统计的渐近性质。每种类型的交叉对应一个不同的统计渐近状态。此外，我们认为三种弹跳行为是交叉行为的对称对应物。当过程是粘性布朗运动时，反弹的数量与其交叉的数量表现相似。由此，我们推断出粘性反射布朗运动的反弹次数的行为。交叉和反弹的结果扩展到粘性扩散。作为应用，我们提出了粘性扩散和粘性反射布朗运动粘性参数的一致估计。 et.al.|[2411.08846](http://arxiv.org/abs/2411.08846)|null|
|**2024-11-13**|**Offline Adaptation of Quadruped Locomotion using Diffusion Models**|我们提出了一种基于扩散的四足动物运动方法，该方法同时解决了学习和在多种技能之间插值的局限性，以及训练后离线适应新运动行为的局限性。这是第一个将无分类器引导扩散应用于四足动物运动的框架，并通过从最初未标记的数据集中提取目标条件行为来证明其有效性。我们表明，这些功能与多技能策略兼容，可以在几乎不需要修改和最小计算开销的情况下应用，即完全在机器人板载CPU上运行。我们在ANYmal四足平台上进行了硬件实验，验证了我们方法的有效性。 et.al.|[2411.08832](http://arxiv.org/abs/2411.08832)|null|
|**2024-11-13**|**Fluctuations of driven probes reveal nonequilibrium transitions in complex fluids**|受到局部微观能量输入的复杂流体表现出非平衡行为，但人们对此知之甚少。为了识别流体微观结构构象的变化，我们引入了一种通用方法，该方法基于以平均恒定速度拖动的激光捕获探针的均分定理的分解。具体来说，我们将通过聚合物流体的大规模布朗模拟获得的探针位置方差中的不同缩放制度与从扩散动力学到跳跃动力学的转变联系起来，在跳跃动力学中，流体间歇性地释放累积的应力。这表明，储存的弹性应力可能是最近测量的非线性摩擦曲线背后的物理机制。我们的方法克服了连续宏观描述的局限性，引入了一种经验方法来实验检测流体结构中的非平衡转变。 et.al.|[2411.08817](http://arxiv.org/abs/2411.08817)|null|
|**2024-11-13**|**A combined diffusion/rate equation model to describe charge generation in phase-separated donor-acceptor blends**|通过引入新型非富勒烯受体（NFAs），有机太阳能电池（OSC）的功率转换效率（PCE）得到了很大提高。PCE的进一步改进需要更全面地了解免费生成过程。最近，供体-受体共混物的小PCE与相关前沿轨道之间的低偏移被归因于低效的激子解离。然而，光电流损失的另一个来源是激子扩散和衰变之间的竞争，这与具有相分离形态的双层或体异质结共混物特别相关。在这里，我们提出了一个分析模型，该模型将激子扩散与基于马库斯电荷转移理论的一组速率方程相结合。从模型的稳态解中推导出电荷产生效率的表达式。因此，尽管激子解离的驱动力消失，但本征激子寿命被确定为促进有效电荷产生的关键参数。该模型的动态公式用于阐明电荷产生的特征时间尺度。研究发现，对于低偏移系统，纯扩散时间比与电荷产生相关的扩散时间要短得多。因此，可以得出结论，当通过激子扩散测量来估计畴尺寸时，激子在供体-受体界面瞬间淬灭的假设只有在存在激子解离的高驱动力时才有效。该模型被应用于PM6:Y6混合物的瞬态吸收动力学。结果表明，电荷产生动力学由激子扩散和空穴转移动力学之间的相互作用决定，估计Y6畴尺寸为25nm，而界面电荷转移（CT）态迅速分离为自由电荷。 et.al.|[2411.08812](http://arxiv.org/abs/2411.08812)|null|
|**2024-11-13**|**A novel imaging setup for hybrid radiotherapy tailored PET/MR in patients with head and neck cancer**|目的：放射治疗通常依赖于CT，但人们对使用混合PET/MR的兴趣越来越大。因此，已经为PET/MR系统提出了专用的硬件设置，使其能够在放射治疗位置进行成像。这些放射治疗装置通常包括一个平板、定位工具和专门为设备量身定制的线圈架。然而，有报道称MR图像质量降低。特别是在颈部和上胸部，传统的放射治疗设置不是最佳的，因为它们只包括头部线圈配置。目的是开发一种新型的PET/MR放射治疗装置，以提高头部、颈部和胸部的MR图像质量，并在多中心环境中测试依从性。方法：在三个不同中心的3T PET/MR系统上设计、原型制作和测试了一种新型放射治疗装置。成像实验在人体模型和健康志愿者中进行，与标准放射治疗设置进行比较。成像方案包括T1、T2和弥散加权MR（DWI）。最后，评估了对美国放射学会（ACR）和定量成像生物标志物联盟（QIBA）验收标准的遵守情况。结果：在体模（p=0.031）和志愿者图像中，颈部/胸部的信噪比增加了1.6倍。新设置通过了ACR可检测性和QIBA信噪比测试，但标准设置失败了。新装置通过了三个中心除两个ACR测试标准外的所有标准，重复性和再现性变化分别为4.9%和7.8%，符合DWI的所有QIBA标准，但ADC精度除外。结论：所提出的装置产生了更高的信噪比、更好的可检测性，并且几乎符合所有ACR和QIBA图像质量标准。因此，它可能会促进PET/MR在放射治疗中的应用。 et.al.|[2411.08783](http://arxiv.org/abs/2411.08783)|null|
|**2024-11-13**|**Particle acceleration and multi-messenger radiation from Ultra-Luminous X-ray Sources -- A new class of Galactic PeVatrons**|恒星质量致密物体上的超级爱丁顿吸积为超发光X射线源（ULX）的快速外流提供了动力。这种外流可以达到温和的相对论速度，经常被观察到形成气泡结构。预计气泡会产生强烈的风终止冲击，这是扩散冲击加速的重要场所。我们开发了一个由ULX驱动的气泡中扩散冲击加速度的模型。我们发现，这些物体的最大能量很容易达到PeV范围，促进ULX风成为一类新的PeVatrons。我们在银河系源SS 433的背景下专门研究了我们的模型，并表明气泡中的高能质子可能解释了LHAASO最近观测到的最高能量光子（>100 TeV）及其形态。我们讨论了中微子中这种源的可检测性，并分析了ULX的可能无线电对应物，重点关注SS 433周围的星云W50的情况。最后，我们讨论了银河系超新星对膝盖处宇宙射线通量的可能贡献，得出的结论是，它们的作用可能是巨大的。 et.al.|[2411.08762](http://arxiv.org/abs/2411.08762)|null|
|**2024-11-13**|**Berry-Esseen bounds for large-time asymptotics of one-dimensional diffusion processes via Malliavin-Stein method**|我们考虑随机微分方程的解，当时间参数趋于无穷大时，这些解会发散到无穷大。如果系数随着空间变量趋于无穷大而收敛，那么随着时间参数趋于无穷大，解将接近一些具有正漂移的高斯过程。本文证明了在这种情况下解的Berry-Esseen型界。特别地，我们得到了随机微分方程中心解和标度解定律与标准正态分布之间的总变差距离的界限，该界限在时间参数中具有最佳收敛速度。在证明中，我们应用Malliavin-Stein方法来估计总变化距离。 et.al.|[2411.08725](http://arxiv.org/abs/2411.08725)|null|
|**2024-11-13**|**Starburst heating and synthetic ion column densities in multiphase galactic outflows**|恒星驱动的星系风是能量和物质的多相外流，将星际和环星系介质（CGM）与星系间介质连接起来。银河风包含一个在X射线中检测到的热和扩散相，以及一个通过外流离子的发射和吸收线检测到的冷和稠密相。星系风中的离子产生在很大程度上取决于恒星形成产生的背景紫外辐射场，而这反过来又取决于星爆的年龄、气体金属丰度、流出气体与中心恒星形成区的接近程度。我们的研究通过分析合成柱密度和谱线，探讨了风云系统与紫外背景源的接近程度的影响，以及磁场对N V离子产生的影响。我们利用磁流体动力学模拟来研究弱磁化的风云系统，并使用Trident和yt提取合成谱线。我们的模拟表明，横向于风的磁场对稠密气体具有屏蔽作用，产生更宽的N V吸收线。此外，弱（远）紫外线背景仅在没有光谱特征的外层云层中产生N V，而强（近）紫外线背景在光谱线较窄的云核中产生N V。总体而言，横向磁场和50kpc的紫外线辐射会产生更强的N V谱线。 et.al.|[2411.08704](http://arxiv.org/abs/2411.08704)|null|
|**2024-11-14**|**MikuDance: Animating Character Art with Mixed Motion Dynamics**|我们提出了MikuDance，这是一种基于扩散的管道，结合了混合运动动力学来为程式化的角色艺术制作动画。MikuDances由两项关键技术组成：混合运动建模和混合控制扩散，以解决角色艺术动画中高动态运动和参考引导错位的挑战。具体而言，提出了一种场景运动跟踪策略，在像素空间中显式地对动态相机进行建模，从而实现了统一的角色场景运动建模。在此基础上，混合控制扩散隐式地将不同角色的比例和身体形状与运动引导对齐，从而允许对局部角色运动进行灵活控制。随后，引入了运动自适应归一化模块，有效地注入全局场景运动，为全面的角色艺术动画铺平了道路。通过广泛的实验，我们证明了MikuDance在各种角色艺术和动作指导中的有效性和通用性，始终如一地制作出具有卓越动作动态的高质量动画。 et.al.|[2411.08656](http://arxiv.org/abs/2411.08656)|null|

## NeRF

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2024-11-09**|**Epi-NAF: Enhancing Neural Attenuation Fields for Limited-Angle CT with Epipolar Consistency Conditions**|神经场方法最初在逆渲染领域取得了成功，最近已扩展到CT重建，标志着传统技术的范式转变。虽然这些方法在稀疏视图CT重建中提供了最先进的结果，但它们在有限的角度设置中很难实现，在有限的视角范围内捕获输入投影。我们提出了一种基于X射线投影图像中相应极线之间一致性条件的新损失项，旨在规范神经衰减场优化。通过强制执行这些一致性条件，我们的方法Epi NAF将监督从有限角度范围内的输入视图传播到整个锥束CT范围内的预测投影。与基线方法相比，这种损失导致重建的定性和定量改进。 et.al.|[2411.06181](http://arxiv.org/abs/2411.06181)|null|
|**2024-11-07**|**LoFi: Scalable Local Image Reconstruction with Implicit Neural Representation**|神经场或隐式神经表示（INR）因其对图像和3D体积的有效连续表示而在机器学习和信号处理中引起了广泛关注。在这项工作中，我们以INR为基础，引入了一种基于坐标的局部处理框架来解决成像逆问题，称为LoFi（局部场）。与传统的图像重建方法不同，LoFi通过多层感知器（MLP）分别处理每个坐标处的局部信息，在该特定坐标处恢复对象。与INR类似，LoFi可以在任何连续坐标下恢复图像，从而实现多分辨率的图像重建。LoFi在图像重建方面的性能与标准CNN相当或更好，几乎与图像分辨率无关，对分布外数据和内存使用具有出色的泛化能力。值得注意的是，对1024美元×1024美元的图像进行训练只需要3GB的内存，比标准CNN通常需要的内存少20多倍。此外，LoFi的局部设计使其能够在小于10个样本的极小数据集上进行训练，而不会过拟合或需要正则化或提前停止。最后，我们使用LoFi作为即插即用框架中的去噪先验，用于解决一般的逆问题，以受益于其连续的图像表示和强大的泛化能力。尽管在低分辨率图像上进行了训练，但LoFi可以用作低维先验，以解决任何分辨率的逆问题。我们通过各种成像方式验证了我们的框架，从低剂量计算机断层扫描到无线电干涉成像。 et.al.|[2411.04995](http://arxiv.org/abs/2411.04995)|null|
|**2024-11-04**|**Physically Based Neural Bidirectional Reflectance Distribution Function**|我们介绍了基于物理的神经双向反射分布函数（PBNBRDF），这是一种基于神经场的材料外观的新颖连续表示。我们的模型准确地重建了真实世界的材料，同时独特地增强了现实BRDF的物理特性，特别是通过重新参数化的亥姆霍兹互易性和通过高效分析积分的能量无源性。我们进行了系统分析，证明了遵守这些物理定律对重建材料的视觉质量的好处。此外，我们通过引入色度强制监督RGB通道的规范来提高神经BRDF的颜色精度。通过在多个测量的真实BRDF数据库上进行定性和定量实验，我们表明，遵守这些物理约束可以使神经场更忠实、更稳定地表示原始数据，并实现更高的渲染质量。 et.al.|[2411.02347](http://arxiv.org/abs/2411.02347)|null|
|**2024-11-01**|**Intensity Field Decomposition for Tissue-Guided Neural Tomography**|锥束计算机断层扫描（CBCT）通常需要数百次X射线投影，这引起了人们对辐射暴露的担忧。虽然稀疏视图重建通过使用更少的投影来减少曝光，但它很难达到令人满意的图像质量。为了应对这一挑战，本文介绍了一种新的稀疏视图CBCT重建方法，该方法为神经场赋予了人体组织正则化的能力。我们的方法被称为组织引导神经断层扫描（TNT），其动机是CBCT中骨骼和软组织之间明显的强度差异。直观地说，分离这些成分可能有助于神经场的学习过程。更确切地说，TNT包括一个异构的四重网络和相应的训练策略。该网络将强度场表示为软组织和硬组织成分及其各自纹理的组合。我们在估计的组织投影的指导下训练网络，从而能够有效地学习网络头所需的模式。大量实验表明，所提出的方法显著改善了稀疏视图CBCT重建，投影数量从10到60不等。与最先进的基于神经渲染的方法相比，我们的方法以更少的投影和更快的收敛实现了相当的重建质量。 et.al.|[2411.00900](http://arxiv.org/abs/2411.00900)|null|
|**2024-10-26**|**Neural Fields in Robotics: A Survey**|神经场已经成为计算机视觉和机器人技术中3D场景表示的一种变革性方法，能够从姿势的2D数据中准确推断几何、3D语义和动力学。利用可微分渲染，神经场包括连续隐式和显式神经表示，实现了高保真3D重建、多模态传感器数据的集成和新视点的生成。这项调查探讨了它们在机器人技术中的应用，强调了它们在增强感知、规划和控制方面的潜力。它们的紧凑性、内存效率和可微性，以及与基础模型和生成模型的无缝集成，使其成为实时应用的理想选择，提高了机器人的适应性和决策能力。本文基于200多篇论文，对机器人中的神经场进行了全面的回顾，对各个领域的应用进行了分类，并评估了它们的优势和局限性。首先，我们介绍了四个关键的神经场框架：占用网络、有符号距离场、神经辐射场和高斯散斑。其次，我们详细介绍了神经场在五个主要机器人领域的应用：姿态估计、操纵、导航、物理和自动驾驶，重点介绍了关键工作，并讨论了要点和公开挑战。最后，我们概述了神经场在机器人技术中的局限性，并为未来的研究提出了有前景的方向。项目页面：https://robonerf.github.io et.al.|[2410.20220](http://arxiv.org/abs/2410.20220)|**[link](https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics)**|
|**2024-10-24**|**3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation**|多视图图像扩散模型显著推进了开放域3D对象生成。然而，大多数现有模型依赖于缺乏固有3D偏差的2D网络架构，导致几何一致性受损。为了应对这一挑战，我们引入了3D Adapter，这是一个插件模块，旨在将3D几何感知注入预训练的图像扩散模型中。我们方法的核心是3D反馈增强的思想：对于采样循环中的每个去噪步骤，3D Adapter将中间的多视图特征解码为连贯的3D表示，然后对渲染的RGBD视图进行重新编码，通过特征添加来增强预训练的基础模型。我们研究了3D Adapter的两种变体：一种是基于高斯飞溅的快速前馈版本，另一种是利用神经场和网格的通用无训练版本。我们广泛的实验表明，3D Adapter不仅大大提高了文本到多视图模型（如Instant3D和Zero123++）的几何质量，而且还使用纯文本到图像的稳定扩散实现了高质量的3D生成。此外，我们通过在文本到3D、图像到3D、文本到纹理和文本到化身任务中呈现高质量的结果，展示了3D适配器的广泛应用潜力。 et.al.|[2410.18974](http://arxiv.org/abs/2410.18974)|**[link](https://github.com/Lakonik/MVEdit)**|
|**2024-10-22**|**Cortical Dynamics of Neural-Connectivity Fields**|皮质组织的宏观研究揭示了振荡活动的普遍性，这反映了神经相互作用的微调。本研究通过将广义振荡动力学纳入先前关于保守或半保守神经场动力学的工作中，扩展了神经场理论。先前的研究在很大程度上假设了神经单元之间的各向同性连接；然而，这项研究表明，广泛的各向异性和波动连接仍然可以维持振荡。使用拉格朗日场方法，我们研究了不同类型的连接、它们的动力学以及与神经场的潜在相互作用。基于这一理论基础，我们推导出了一个框架，该框架通过连接场的概念将Hebbian和非Hebbian学习（即可塑性）纳入神经场的研究中。 et.al.|[2410.16852](http://arxiv.org/abs/2410.16852)|null|
|**2024-10-15**|**Deep vectorised operators for pulsatile hemodynamics estimation in coronary arteries from a steady-state prior**|心血管血流动力学场为冠状动脉疾病提供了有价值的医学决策标志。计算流体动力学（CFD）是体内准确、无创评估这些量的金标准。在这项工作中，我们提出了一种基于机器学习的时间高效替代模型，用于基于稳态先验估计脉动血流动力学。我们引入了深度矢量化算子，这是一种用于在无限维函数空间上进行离散化独立学习的建模框架。基础神经结构是一个以血流动力学边界条件为条件的神经场。重要的是，我们展示了如何将逐点动作的要求放宽到置换等变，从而产生一系列可以通过消息传递和自我关注层进行参数化的模型。我们在从冠状动脉计算机断层扫描血管造影（CCTA）中提取的74条狭窄冠状动脉的数据集上评估了我们的方法，并将患者特异性脉动CFD模拟作为基本事实。我们证明，我们的模型能够准确估计脉动速度和压力，同时不受源域重新采样的影响（离散化独立性）。这表明，深度矢量化算子是冠状动脉及其他动脉心血管血流动力学估计的强大建模工具。 et.al.|[2410.11920](http://arxiv.org/abs/2410.11920)|null|
|**2024-10-07**|**Fast Training of Sinusoidal Neural Fields via Scaling Initialization**|神经场是一种新兴的范式，它将数据表示为由神经网络参数化的连续函数。尽管有许多优点，但神经场通常具有较高的训练成本，这阻碍了更广泛的采用。在本文中，我们关注一个流行的神经场家族，称为正弦神经场（SNF），并研究如何初始化它以最大限度地提高训练速度。我们发现，基于信号传播原理设计的SNF标准初始化方案是次优的。特别是，我们证明，通过简单地将每个权重（最后一层除外）乘以一个常数，我们可以将SNF训练加速10 $\times$。这种方法被称为$\textit{weight scaling}$ ，在各种数据域上持续提供显著的加速，使SNF的训练速度比最近提出的架构更快。为了理解为什么权重缩放效果良好，我们进行了广泛的理论和实证分析，结果表明，权重缩放不仅有效地解决了频谱偏差，而且具有良好的优化轨迹。 et.al.|[2410.04779](http://arxiv.org/abs/2410.04779)|null|
|**2024-10-04**|**End-to-End Reaction Field Energy Modeling via Deep Learning based Voxel-to-voxel Transform**|在计算生物化学和生物物理学中，理解静电相互作用的作用对于阐明生物分子的结构、动力学和功能至关重要。泊松-玻尔兹曼（PB）方程是通过描述带电分子内部和周围的静电势来模拟这些相互作用的基础工具。然而，由于生物分子表面的复杂性和需要考虑可移动离子，求解PB方程带来了重大的计算挑战。虽然求解PB方程的传统数值方法是准确的，但它们的计算成本很高，并且随着系统规模的增加而扩展性较差。为了应对这些挑战，我们引入了PBNeF，这是一种新的机器学习方法，灵感来自基于神经网络的偏微分方程求解器的最新进展。我们的方法将PB方程的输入和边界静电条件转化为可学习的体素表示，使神经场变换器能够预测PB解，进而预测反应场势能。大量实验表明，与传统的PB求解器相比，PBNeF的速度提高了100倍以上，同时保持了与广义玻恩（GB）模型相当的精度。 et.al.|[2410.03927](http://arxiv.org/abs/2410.03927)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

