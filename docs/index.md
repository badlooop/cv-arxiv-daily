---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2023.12.30
> Usage instructions: [here](./docs/README.md#usage)

## 3D

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-12-28**|**iFusion: Inverting Diffusion for Pose-Free Reconstruction from Sparse Views**|我们提出了iFusion，这是一种新颖的3D对象重建框架，只需要两个具有未知相机姿态的视图。虽然单视图重建会产生视觉上吸引人的结果，但它可能会与实际对象有很大的偏差，尤其是在看不见的一侧。附加视图提高了重建保真度，但需要已知的摄影机姿势。然而，假设姿态的可用性可能是不现实的，并且现有的姿态估计器在稀疏视图场景中失败。为了解决这一问题，我们利用了一个预先训练的新颖视图合成扩散模型，该模型嵌入了关于不同对象的几何形状和外观的隐含知识。我们的策略分为三个步骤：（1）我们反转用于相机姿态估计的扩散模型，而不是合成新的视图。（2） 使用提供的视图和估计的姿态对扩散模型进行微调，使其成为为目标对象量身定制的新型视图合成器。（3） 利用配准的视图和微调的扩散模型，我们重建了3D对象。实验表明，在姿态估计和新视图合成方面都有很强的性能。此外，iFusion与各种重建方法无缝集成，并对其进行了增强。 et.al.|[2312.17250](http://arxiv.org/abs/2312.17250)|**[link](https://github.com/chinhsuanwu/ifusion)**|
|**2023-12-28**|**Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis**|动态场景的新颖视图合成一直是一个有趣但具有挑战性的问题。尽管取得了最新进展，但同时实现高分辨率的真实照片效果、实时渲染和紧凑的存储仍然是一项艰巨的任务。为了应对这些挑战，我们提出了时空高斯特征飞溅作为一种新的动态场景表示，由三个关键组件组成。首先，我们通过增强具有时间不透明度和参数运动/旋转的3D高斯，来形成富有表现力的时空高斯。这使得时空高斯能够捕捉场景中的静态、动态以及瞬态内容。其次，我们介绍了飞溅特征渲染，它用神经特征代替了球面谐波。这些功能有助于在保持小尺寸的同时对视图和与时间相关的外观进行建模。第三，我们利用训练误差和粗略深度的指导，在难以与现有管道融合的区域对新的高斯采样。在几个已建立的真实世界数据集上的实验表明，我们的方法在保持紧凑存储的同时，实现了最先进的渲染质量和速度。在8K分辨率下，我们的lite版本模型可以在Nvidia RTX 4090 GPU上以60 FPS的速度渲染。 et.al.|[2312.16812](http://arxiv.org/abs/2312.16812)|null|
|**2023-12-26**|**DL3DV-10K: A Large-Scale Scene Dataset for Deep Learning-based 3D Vision**|我们见证了基于深度学习的3D视觉的重大进展，从基于神经辐射场（NeRF）的3D表示学习到在新视图合成（NVS）中的应用。然而，用于基于深度学习的3D视觉的现有场景级数据集，仅限于合成环境或现实世界场景的狭窄选择，是非常不足的。这种不足不仅阻碍了现有方法的全面基准，而且限制了在基于深度学习的3D分析中可以探索的内容。为了解决这一关键差距，我们展示了DL3DV-10K，这是一个大型场景数据集，其特征是从65种类型的兴趣点（POI）位置捕获的10510个视频中的5120万帧，涵盖了有界和无界场景，具有不同的反射、透明度和光照水平。我们在DL3DV-10K上对最近的NVS方法进行了全面的基准测试，为未来的NVS研究提供了宝贵的见解。此外，我们在一项从DL3DV-10K学习可推广NeRF的试点研究中获得了令人鼓舞的结果，这表明了大规模场景级数据集的必要性，以打造学习3D表示的基础模型。我们的DL3DV-10K数据集、基准测试结果和模型将在https://dl3dv-10k.github.io/DL3DV-10K/. et.al.|[2312.16256](http://arxiv.org/abs/2312.16256)|null|
|**2023-12-26**|**fMPI: Fast Novel View Synthesis in the Wild with Layered Scene Representations**|在这项研究中，我们为基于分层场景表示的新视图合成（NVS）方法提出了两种新的输入处理范式，这两种方法在不影响质量的情况下显著提高了它们的运行时间。我们的方法识别并减轻了传统管道最耗时的两个方面：构建和处理所谓的平面扫描体积（PSV），这是输入相机视图的平面重新投影的高维张量。特别是，我们建议在并行组中处理该张量，以提高计算效率，并对相邻输入平面进行超采样，从而生成更密集、更准确的场景表示。所提出的增强提供了显著的灵活性，允许在性能和速度之间取得平衡，从而朝着实时应用迈出了实质性的步伐。此外，它们非常通用，因为任何基于PSV的方法都可以使用它们，包括使用多平面图像、多球体图像和分层深度图像的方法。在一组全面的实验中，我们证明了我们提出的范式能够设计出一种NVS方法，该方法在公共基准上达到最先进的水平，同时比现有的最先进的方法快50倍。它在速度方面也比目前的前辈高出3倍多，同时实现了明显更好的渲染质量。 et.al.|[2312.16109](http://arxiv.org/abs/2312.16109)|null|
|**2023-12-25**|**Sparse-view CT Reconstruction with 3D Gaussian Volumetric Representation**|稀疏视图CT是减少传统CT扫描辐射剂量的一种很有前途的策略，但从不完整和有噪声的数据中重建高质量图像是一项挑战。最近，3D高斯已被应用于复杂自然场景的建模，与隐式神经表示（INRs）相比，它表现出快速收敛和更好的新颖视图渲染。我们从3D高斯在自然场景建模和新视图合成中的成功应用中获得灵感，研究了它们在稀疏视图CT重建中的潜力。我们利用来自滤波后的反投影重建图像的先验信息来初始化高斯；并且通过比较投影空间中的差异来更新它们的参数。自适应密度控制进一步提高了性能。与INRs相比，3D高斯从先验信息中受益更多，可以明确绕过空白空间中的学习，并有效地分配容量，加速收敛。3D高斯还可以有效地学习高频细节。3D高斯以自我监督的方式进行训练，避免了对大规模配对数据的需要。我们在AAPM-Mayo数据集上的实验表明，与基于INR的方法相比，3D高斯可以提供优越的性能。这项工作正在进行中，代码将公开。 et.al.|[2312.15676](http://arxiv.org/abs/2312.15676)|null|
|**2023-12-22**|**Deformable 3D Gaussian Splatting for Animatable Human Avatars**|神经辐射场的最新进展使得能够在动态设置中对照片真实感图像进行新颖的视图合成，这可以应用于具有人类动画的场景。然而，通常使用的隐式主干来建立准确的模型，需要许多输入视图和额外的注释，如人体遮罩、UV贴图和深度贴图。在这项工作中，我们提出了ParDy Human（参数化动态人类化身），这是一种完全明确的方法，可以从一个单一的单目序列中构建数字化身。ParDy Human在3D高斯飞溅中引入了参数驱动的动力学，其中通过人体姿势模型使3D高斯变形以使化身动画化。我们的方法由两个部分组成：第一个模块根据SMPL顶点使标准3D高斯变形，第二个模块进一步采用其设计的联合编码并预测每高斯变形，以处理SMPL顶点变形之外的动力学。然后通过光栅化器合成图像。ParDy Human构成了逼真动态人类化身的显式模型，其需要显著更少的训练视图和图像。我们的化身学习不需要额外的注释，如掩码，并且可以在可变背景下进行训练，同时即使在消费硬件上也能高效地推断出全分辨率图像。我们提供的实验证据表明，在ZJU MoCap和THUman4.0数据集上，ParDy-Human在数量和视觉上都优于最先进的方法。 et.al.|[2312.15059](http://arxiv.org/abs/2312.15059)|null|
|**2023-12-21**|**PlatoNeRF: 3D Reconstruction in Plato's Cave via Single-View Two-Bounce Lidar**|由于单目线索的模糊性和缺乏关于遮挡区域的信息，从单个视图进行3D重建是具有挑战性的。神经辐射场（NeRF）虽然在视图合成和3D重建中很受欢迎，但通常依赖于多视图图像。现有的使用NeRF进行单视图3D重建的方法要么依赖于数据先验来幻觉被遮挡区域的视图，这在物理上可能不准确，要么依赖于RGB相机观察到的阴影，这在环境光和低反照率背景中很难检测到。我们建议使用单光子雪崩二极管捕获的飞行时间数据来克服这些限制。我们的方法使用NeRF对两个反弹光路进行建模，使用激光雷达瞬态数据进行监督。通过利用激光雷达测量的NeRF和双反射光的优势，我们证明了我们可以在没有数据先验或依赖受控环境照明或场景反照率的情况下重建可见和遮挡的几何结构。此外，我们还展示了在传感器空间和时间分辨率的实际约束下改进的泛化能力。我们相信，随着单光子激光雷达在手机、平板电脑和耳机等消费设备上无处不在，我们的方法是一个很有前途的方向。 et.al.|[2312.14239](http://arxiv.org/abs/2312.14239)|null|
|**2023-12-21**|**SyncDreamer for 3D Reconstruction of Endangered Animal Species with NeRF and NeuS**|本研究的主要目的是演示如何使用创新的视图合成和3D重建技术，使用单目RGB图像创建濒危物种的模型。为了实现这一点，我们使用SyncDreamer来产生独特的视角，并使用NeuS和NeRF来重建3D表示。我们选择了四种不同的动物，包括东方鹳、青蛙、蜻蜓和老虎，作为我们的研究对象。我们的研究结果表明，SyncDreamer、NeRF和NeuS技术的结合可以成功创建濒危动物的3D模型。然而，我们也观察到NeuS产生了模糊的图像，而NeRF产生了更清晰但更嘈杂的图像。这项研究突出了模拟濒危动物的潜力，并为该领域的未来研究提供了新的方向。通过展示这些先进技术的有效性，我们希望鼓励进一步探索和发展保护和研究濒危物种的技术。 et.al.|[2312.13832](http://arxiv.org/abs/2312.13832)|null|
|**2023-12-21**|**DyBluRF: Dynamic Deblurring Neural Radiance Fields for Blurry Monocular Video**|视频视图合成允许从任意视点和时间创建具有视觉吸引力的帧，提供身临其境的观看体验。神经辐射场，特别是最初为静态场景开发的NeRF，刺激了视频视图合成的各种方法的产生。然而，视频视图合成的挑战来自运动模糊，这是物体或相机在曝光过程中移动的结果，阻碍了清晰的时空视图的精确合成。作为回应，我们提出了一种用于模糊单目视频的新的动态去模糊NeRF框架，称为DyBluRF，由Interleave Ray Refinement（IRR）阶段和基于运动分解的去模糊（MDD）阶段组成。我们的DyBluRF是第一个解决和处理模糊单目视频的新型视图合成的公司。IRR阶段联合重建动态3D场景，并细化不准确的相机姿态信息，以对抗从给定模糊帧中提取的不准确姿态信息。MDD阶段是一种新的增量潜在锐射线预测（ILSP）方法，用于模糊单目视频帧，将潜在锐射线分解为全局相机运动和局部对象运动分量。大量的实验结果表明，我们的DyBluRF在质量和数量上都优于最新的最先进的方法。我们的项目页面包括源代码和预训练模型，可在https://kaist-viclab.github.io/dyblurf-site/. et.al.|[2312.13528](http://arxiv.org/abs/2312.13528)|null|
|**2023-12-20**|**NeRF-VO: Real-Time Sparse Visual Odometry with Neural Radiance Fields**|我们介绍了一种新的单目视觉里程计（VO）系统NeRF VO，该系统集成了用于低延迟相机跟踪的基于学习的稀疏视觉里程计和用于复杂密集重建和新颖视图合成的神经辐射场景表示。我们的系统使用稀疏视觉里程计初始化相机姿态，并从单目深度预测网络中获得与视图相关的密集几何先验。我们协调姿势的尺度和密集的几何体，将它们视为训练神经隐式场景表示的监督线索。NeRF VO通过联合优化关键帧姿势的滑动窗口和底层密集几何体，在场景表示的光度和几何保真度方面表现出非凡的性能，这是通过使用体渲染训练辐射场来实现的。我们在各种合成和真实世界数据集的姿态估计精度、新颖的视图合成保真度和密集的重建质量方面超过了最先进的方法，同时实现了更高的相机跟踪频率和更少的GPU内存消耗。 et.al.|[2312.13471](http://arxiv.org/abs/2312.13471)|null|

## 3D Reconstruction

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-12-28**|**Toward Semantic Scene Understanding for Fine-Grained 3D Modeling of Plants**|由于全球人口增长以及对粮食和劳动力短缺的预期，农业机器人是一个活跃的研究领域。机器人可能有助于完成修剪、收割、表型分析和植物建模等任务。然而，农业自动化受到阻碍，因为难以在该领域创建高分辨率3D语义地图，从而实现安全操作和导航。在本文中，我们致力于解决这一问题，并展示了语义和环境先验的使用如何帮助为高粱的目标应用构建准确的3D地图。具体而言，我们1）使用高粱种子作为语义地标来构建视觉同步定位和映射（SLAM）系统，该系统使我们能够平均映射78%的高粱范围，而ORB-SLAM2的映射率为38%；和2）使用种子作为语义特征来改进由机器人手持相机拍摄的图像对完整高粱穗的3D重建。 et.al.|[2312.17110](http://arxiv.org/abs/2312.17110)|null|
|**2023-12-28**|**Geometry-Biased Transformer for Robust Multi-View 3D Human Pose Reconstruction**|我们解决了在遮挡和有限重叠视图下从多个视图估计3D人体姿态的挑战。我们将多视图、单人三维人体姿态重建作为一个回归问题，并提出了一种新的编码器-解码器-转换器架构，用于从多视图二维姿态序列中估计三维姿态。编码器对在不同视图和时间检测到的2D骨骼关节进行细化，通过全局自关注融合多视图和时间信息。我们通过结合有几何偏见的注意力机制来增强编码器，有效地利用视图之间的几何关系。此外，我们使用2D姿势检测器提供的检测分数来基于2D检测的可靠性进一步引导编码器的注意力。解码器随后使用针对每个关节的预定义查询，从这些细化的标记回归3D姿势序列。为了增强我们的方法对看不见的场景的泛化能力，并提高对缺失关节的恢复能力，我们实施了包括场景居中、合成视图和标记丢弃在内的策略。我们在三个基准公共数据集Human3.6M、CMU Panoptic和Occlusion Persons上进行了广泛的实验。我们的结果证明了我们的方法的有效性，特别是在遮挡场景和视图很少的情况下，这对于基于三角测量的方法来说是传统上具有挑战性的场景。 et.al.|[2312.17106](http://arxiv.org/abs/2312.17106)|null|
|**2023-12-28**|**Learning Spatially Collaged Fourier Bases for Implicit Neural Representation**|现有的隐式神经表示（INR）方法可以通过不同频率的傅立叶基的线性组合解释为全局场景表示。然而，这种通用基函数可能会限制不需要特定组件的局部区域的表示能力，从而导致令人不快的伪影。为此，我们引入了一种可学习的空间掩模，它可以有效地将不同的傅立叶基分派到各个区域中。这转化为拼贴傅立叶补丁，从而实现复杂信号的精确表示。综合实验证明，在各种INR任务中，包括图像拟合、视频表示和3D形状表示，所提出的方法的重建质量优于现有基线。我们的方法优于所有其他基线，将图像拟合PSNR提高了3dB以上，并将3D重建提高到98.81 IoU和0.0011倒角距离。 et.al.|[2312.17018](http://arxiv.org/abs/2312.17018)|null|
|**2023-12-27**|**In-Hand 3D Object Reconstruction from a Monocular RGB Video**|我们的工作旨在重建一只手在静态RGB相机前握住并旋转的3D物体。以前的方法使用隐式神经表示从多视图图像中恢复通用手持物体的几何结构，在物体的可见部分取得了令人信服的结果。然而，由于遮挡，这些方法在准确捕捉手-物体接触区域内的形状方面有困难。在本文中，我们提出了一种新的方法，通过结合二维遮挡说明的先验和物理接触约束来处理遮挡下的表面重建。对于前者，我们引入了一个对象阿莫尔完成网络来推断遮挡下对象的二维完全掩模。为了确保预测的2D变形掩模的准确性和视图一致性，我们设计了一种用于变形掩模细化和3D重建的联合优化方法。对于后者，我们对接触区域中的局部几何体施加穿透和吸引约束。我们在HO3D和HOD数据集上评估了我们的方法，并证明它在重建表面质量方面优于最先进的方法，在HO3D上提高了52美元，在HOD上提高了20美元。项目网页：https://east-j.github.io/ihor. et.al.|[2312.16425](http://arxiv.org/abs/2312.16425)|null|
|**2023-12-24**|**SUNDIAL: 3D Satellite Understanding through Direct, Ambient, and Complex Lighting Decomposition**|卫星图像的三维建模在环境科学、城市规划、农业和灾害应对领域至关重要。然而，传统的3D建模技术在遥感环境中面临着独特的挑战，包括大范围区域上有限的多视图基线，不同的直接、环境和复杂照明条件，以及不同捕获之间的时变场景变化。在这项工作中，我们介绍了SUNDIAL，这是一种使用神经辐射场进行卫星图像三维重建的综合方法。在这种单一模型方法中，我们共同学习了卫星场景几何结构、照明组件和太阳方向，并提出了一种二次阴影光线投射技术，以1）使用倾斜的太阳角来渲染阴影，改善场景几何结构，2）实现场景反照率和照明的物理解纠缠，以及3）确定来自直接环境（天空）的照明组件，以及复杂的来源。为了实现这一点，我们将遥感文献中的照明线索和几何先验纳入神经渲染方法，对卫星场景的物理特性进行建模，如阴影、散射天空照明以及植被和水的复杂照明和阴影。我们评估了SUNDIAL相对于现有基于NeRF的卫星场景建模技术的性能，并在具有小基线、稀疏输入和可变照明的具有挑战性的场景中展示了改进的场景和照明解纠缠、新颖的视图和照明渲染以及几何体和太阳方向估计。 et.al.|[2312.16215](http://arxiv.org/abs/2312.16215)|null|
|**2023-12-24**|**A theory of volumetric representations for opaque solids**|我们开发了一种将不透明固体表示为体积模型的理论。从不透明固体作为随机指示函数的随机表示开始，我们证明了可以使用指数体积输运对这种固体进行建模的条件。我们还导出了体积衰减系数的表达式，作为基本指标函数的概率分布的函数。我们将我们的理论推广到考虑固体不同部分的各向同性和各向异性散射，以及将不透明固体表示为隐式表面。我们从第一性原理推导出体积表示，这确保了它满足物理约束，如互易性和可逆性。我们使用我们的理论来解释、比较和纠正以前的体积表示，并提出有意义的扩展，从而提高3D重建任务的性能。 et.al.|[2312.15406](http://arxiv.org/abs/2312.15406)|null|
|**2023-12-23**|**WildScenes: A Benchmark for 2D and 3D Semantic Segmentation in Large-scale Natural Environments**|语义场景理解的最新进展主要得益于城市环境中语义注释的双模（相机和激光雷达）数据集的可用性。然而，自然、非结构化环境也需要这样的注释数据集，以实现应用程序的语义感知，包括保护、搜救、环境监测和农业自动化。因此，我们介绍了WildScenes，这是一个双模态基准数据集，由自然环境中的多个大规模遍历组成，包括高分辨率2D图像和密集3D激光雷达点云中的语义注释，以及精确的6-DoF姿态信息。数据（1）以轨迹为中心，具有精确的定位和全局对齐的点云，（2）校准和同步以支持双模态推理，以及（3）在6个月内包含不同的自然环境，以支持领域适应研究。我们的3D语义标签是通过一个高效的自动化过程获得的，该过程将人工注释的2D标签从多个视图转移到3D点云中，从而避免了在3D中进行昂贵且耗时的人工注释的需要。我们介绍了2D和3D语义分割的基准，并评估了最近的各种深度学习技术，以展示自然环境中语义分割的挑战。我们建议为标准基准和领域自适应基准训练val测试分割，并利用自动分割生成技术来确保类标签分布的平衡。数据、评估脚本和预训练模型将在https://csiro-robotics.github.io/WildScenes. et.al.|[2312.15364](http://arxiv.org/abs/2312.15364)|null|
|**2023-12-22**|**Enhanced Latent Multi-view Subspace Clustering**|潜在多视图子空间聚类已被证明具有理想的聚类性能。然而，原始的潜在表示方法沿着维度方向将来自多个视图的数据矩阵垂直连接到单个矩阵中，以恢复潜在表示矩阵，这可能导致不完整的信息恢复。为了完全恢复潜在空间表示，我们在本文中提出了一种增强的潜在多视图子空间聚类（ELMSC）方法。ELMSC方法包括构建增强数据矩阵，该矩阵增强多视图数据的表示。具体来说，我们将来自不同视图的数据矩阵堆叠到增广矩阵的块对角位置，以利用互补信息。同时，基于不同视图之间的相似性来组合非块对角条目，以获取一致的信息。此外，我们对增广自表示矩阵的非对角块强制执行稀疏正则化，以避免一致性信息的冗余计算。最后，基于交替方向乘法器（ADMM）的框架，提出了一种新的迭代算法来解决ELMSC的优化问题。在真实世界数据集上的大量实验表明，我们提出的ELMSC能够实现比一些现有技术的多视图聚类方法更高的聚类性能。 et.al.|[2312.14763](http://arxiv.org/abs/2312.14763)|**[link](https://github.com/caolei2000/elmsc-code)**|
|**2023-12-22**|**BonnBeetClouds3D: A Dataset Towards Point Cloud-based Organ-level Phenotyping of Sugar Beet Plants under Field Conditions**|未来几十年，农业生产面临着气候变化和可持续性需求带来的严峻挑战，从而减少其对环境的影响。通过机器人的非化学除草，结合自动无人机对作物的监测，以及培育新的、更具弹性的作物品种，在田间管理方面取得了进展，这有助于应对这些挑战。植物性状的分析，即表型分析，是植物育种中的一项重要活动，但它需要大量的体力劳动。通过这篇论文，我们解决了精确表型所需的自动细粒度器官级几何分析的问题。由于该领域的真实世界数据相对较少，我们提出了一个新的数据集，该数据集是使用无人机获取的，该无人机捕捉了包含48个植物品种的真实育种试验的高分辨率图像，因此涵盖了巨大的形态和外观多样性。这使得自主表型的方法能够很好地推广到不同的品种。基于多个视角的重叠高分辨率图像，我们计算了摄影测量密集点云，并为植物、叶子和作为尖端和底部的突出点提供了详细准确的逐点标签。此外，我们还包括德国联邦植物品种办公室的专家对真实植物进行的表型性状测量，从而不仅可以评估分割和关键点检测方面的新方法，还可以直接评估下游任务。所提供的标记点云能够进行细粒度的植物分析，并支持自动表型方法开发的进一步进展，但也能够在表面重建、点云完成和点云的语义解释方面进行进一步研究。 et.al.|[2312.14706](http://arxiv.org/abs/2312.14706)|null|
|**2023-12-22**|**Pola4All: survey of polarimetric applications and an open-source toolkit to analyze polarization**|光的偏振信息可以为计算机视觉和场景理解任务提供丰富的线索，例如物体的材料类型、姿势和形状。随着新的廉价偏振传感器的出现，这种成像方式越来越容易被更广泛的公众所使用，以解决诸如姿态估计、3D重建、水下导航和深度估计等问题。然而，我们观察到这种感觉模态的使用存在一些局限性，并且缺乏分析偏振图像的标准和公开可用的工具。此外，尽管偏振相机制造商通常提供采集工具来与他们的相机接口，但他们很少包括利用偏振信息的处理算法。在这篇论文中，我们回顾了偏振成像应用的最新进展，包括对视觉和机器人感知任务的偏振最新进展的全面调查。我们还介绍了一个完整的软件工具包，该工具包提供了与市场上大多数现有微栅格偏振相机通信和处理信息的通用标准。该工具包还为这种模式实现了几种图像处理算法，并在GitHub上公开提供：https://github.com/vibot-lab/Pola4all_JEI_2023. et.al.|[2312.14697](http://arxiv.org/abs/2312.14697)|null|

## Diffusion

| Publish Date | Title | Abstract | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2023-12-28**|**iFusion: Inverting Diffusion for Pose-Free Reconstruction from Sparse Views**|我们提出了iFusion，这是一种新颖的3D对象重建框架，只需要两个具有未知相机姿态的视图。虽然单视图重建会产生视觉上吸引人的结果，但它可能会与实际对象有很大的偏差，尤其是在看不见的一侧。附加视图提高了重建保真度，但需要已知的摄影机姿势。然而，假设姿态的可用性可能是不现实的，并且现有的姿态估计器在稀疏视图场景中失败。为了解决这一问题，我们利用了一个预先训练的新颖视图合成扩散模型，该模型嵌入了关于不同对象的几何形状和外观的隐含知识。我们的策略分为三个步骤：（1）我们反转用于相机姿态估计的扩散模型，而不是合成新的视图。（2） 使用提供的视图和估计的姿态对扩散模型进行微调，使其成为为目标对象量身定制的新型视图合成器。（3） 利用配准的视图和微调的扩散模型，我们重建了3D对象。实验表明，在姿态估计和新视图合成方面都有很强的性能。此外，iFusion与各种重建方法无缝集成，并对其进行了增强。 et.al.|[2312.17250](http://arxiv.org/abs/2312.17250)|**[link](https://github.com/chinhsuanwu/ifusion)**|
|**2023-12-28**|**Amodal Ground Truth and Completion in the Wild**|我们在本文中研究的问题是amodal图像分割：预测包括可见和不可见（遮挡）部分的整个对象分割掩码。在以往的工作中，真实图像上的阿莫尔分割地面实况通常是通过手动注释来预测的，因此是主观的。相反，我们使用3D数据来建立一个自动管道，以确定真实图像中部分遮挡对象的真实地面实况阿莫尔掩模。该管道用于构建阿莫达尔完工评估基准MP3D阿莫达尔，该基准由各种对象类别和标签组成。为了更好地处理野外的amodal完成任务，我们探索了两种架构变体：一个两阶段模型，首先推断封堵器，然后完成amodal掩模；以及一个单阶段模型，该模型利用Stable Diffusion的表示能力进行跨多个类别的畸形分割。我们的方法在覆盖各种对象的Amodal分割数据集上实现了最先进的性能，包括COCOA和我们新的MP3D Amodal数据集。数据集、模型和代码可在https://www.robots.ox.ac.uk/~vgg/研究/阿莫达尔/。 et.al.|[2312.17247](http://arxiv.org/abs/2312.17247)|**[link](https://github.com/Championchess/Amodal-Completion-in-the-Wild)**|
|**2023-12-28**|**Personalized Restoration via Dual-Pivot Tuning**|生成扩散模型可以作为先验，确保图像恢复系统的解决方案符合自然图像的多样性。然而，为了恢复面部图像，需要个性化的先验来准确地表示和重建给定个体的独特面部特征。在本文中，我们提出了一种简单而有效的个性化恢复方法，称为双轴调整，这是一种两阶段的方法，可以个性化盲恢复系统，同时保持一般先验的完整性和每个组件的不同作用。我们的主要观察结果是，为了实现最佳个性化，生成模型应围绕固定的文本轴心进行调整，而引导网络应以通用（非个性化）方式进行调整，将个性化生成模型用作固定的“轴心”。这种方法确保了个性化不会干扰恢复过程，从而产生对个人身份和退化图像属性具有高保真度的自然外观。我们通过对广泛识别的个人图像进行广泛实验，并将其与相关基线进行比较，对我们的方法进行了定性和定量评估。令人惊讶的是，我们发现，我们的个性化先验不仅在个人身份方面实现了更高的身份保真度，而且在总体图像质量方面优于最先进的通用先验。项目网页：https://personalized-restoration.github.io et.al.|[2312.17234](http://arxiv.org/abs/2312.17234)|null|
|**2023-12-28**|**4DGen: Grounded 4D Content Generation with Spatial-temporal Consistency**|在文本到图像和文本到视频扩散模型的帮助下，现有的4D内容创建管道利用分数蒸馏采样来优化整个动态3D场景。然而，由于这些管道从文本或图像输入中生成4D内容，因此在通过试错进行快速工程方面需要花费大量时间和精力。这项工作介绍了4DGen，这是一个新颖的、整体的4D内容创建框架，将4D生成任务分解为多个阶段。我们将静态3D资产和单眼视频序列确定为构建4D内容的关键组件。我们的管道有助于有条件的4D生成，使用户能够指定几何形状（3D资产）和运动（单眼视频），从而提供对内容创建的卓越控制。此外，我们使用动态3D高斯构建我们的4D表示，这允许在训练期间通过渲染进行高效、高分辨率的监督，从而促进高质量的4D生成。此外，我们在锚帧上使用时空伪标签，以及通过3D感知分数提取采样和平滑度正则化实现的无缝一致性先验。与现有的基线相比，我们的方法在忠实地重建输入信号和从新的视角和时间步长真实地推断渲染方面产生了有竞争力的结果。最重要的是，我们的方法支持基础生成，为用户提供增强的控制，这是以前方法难以实现的功能。项目页面：https://vita-group.github.io/4DGen/ et.al.|[2312.17225](http://arxiv.org/abs/2312.17225)|null|
|**2023-12-28**|**EFHQ: Multi-purpose ExtremePose-Face-HQ dataset**|现有的面部数据集虽然在近正面视图中有大量图像，但缺乏具有极端头部姿势的图像，导致深度学习模型在处理侧面或倾斜人脸时性能下降。这项工作旨在通过引入一个名为“极限姿势人脸高质量数据集”（EFHQ）的新数据集来解决这一差距，该数据集最多包括450k张极限姿势人脸的高质量图像。为了生成如此庞大的数据集，我们利用一个新颖而细致的数据集处理管道来策划两个公开可用的数据集VFHQ和CelebV HQ，其中包含许多在各种环境中捕获的高分辨率人脸视频。我们的数据集可以补充各种面部相关任务的现有数据集，例如具有2D/3D感知GAN的面部合成、基于扩散的文本到图像人脸生成和人脸再现。具体来说，使用EFHQ进行训练有助于模型在不同姿势下很好地概括，显著提高了在涉及极端视角的场景中的性能，这一点得到了广泛实验的证实。此外，我们利用EFHQ来定义一个具有挑战性的跨视图人脸验证基准，其中SOTA人脸识别模型的性能与正面到正面的场景相比下降了5-37%，旨在刺激野外恶劣姿态条件下的人脸识别研究。 et.al.|[2312.17205](http://arxiv.org/abs/2312.17205)|null|
|**2023-12-28**|**Single particle algorithms to reveal cellular nanodomain organization**|首次在电子显微镜图像中观察到的高密度富含蛋白质的有组织纳米结构域的形成、维持和生理学，由于其体积小，仍具有研究的挑战性。然而，这些区域调节更高细胞功能所需的分子运输、组装和分选，如通讯或可塑性变化。在过去的十年里，超分辨率单粒子轨迹（SPT）已被用于以纳米分辨率对膜蛋白和可溶性蛋白的这些亚细胞环境进行采样。我们在这里介绍了将高通量分子轨迹转换为分子密度、扩散和局部漂移组织图的数据分析发展和算法。这些方法将固有的轨迹特性转换为底层细胞组织的统计信息。大量高密度区域的自动识别允许量化它们的边界位置和组织、它们随时间的稳定性以及它们瞬时保留分子的能力。总之，最近的自动化算法现在可以用于提取大量轨迹上的亚细胞纳米结构域的生物物理参数。 et.al.|[2312.17191](http://arxiv.org/abs/2312.17191)|null|
|**2023-12-28**|**Restoration by Generation with Constrained Priors**|去噪扩散模型的固有生成能力使其非常适合图像恢复任务，其中目标是在生成空间内找到与输入图像非常相似的最佳高质量图像。我们提出了一种方法，通过简单地向要恢复的输入图像添加噪声，然后去噪，将预训练的扩散模型用于图像恢复。我们的方法是基于对生成模型的空间需要约束的观察。我们通过用一组捕获输入图像特征的锚图像来微调生成模型来施加这种约束。在受限空间的情况下，我们可以利用用于生成的采样策略来进行图像恢复。我们与以前的方法进行了比较，并在多个真实世界的恢复数据集上显示出在保持身份和图像质量方面的卓越性能。我们还展示了个性化修复的一个重要而实用的应用，即我们使用个人相册作为锚图像来约束生成空间。这种方法使我们能够产生准确保留高频细节的结果，而以前的工作无法做到这一点。项目网页：https://gen2res.github.io. et.al.|[2312.17161](http://arxiv.org/abs/2312.17161)|null|
|**2023-12-28**|**Branching Brownian motion with generation-dependent diffusivity and nonlocal partial differential equations**|我们研究了 $\mathbb｛R｝$上分支布朗运动过程的投票模型，其中每个子粒子的扩散率比父粒子的扩散系数增加了$\gamma>1$。整体投票的概率分布是根据非局部非线性PDE的解给出的。我们展示了非线性的条件，使得分布的长期行为在$\gamma$中经历相变。如果$\gamma$足够大，则长时间分布收敛为均匀分布。如果$\gamma$足够接近$1$ ，那么长时间分布在很大程度上取决于初始粒子的位置。通过非局部偏微分方程的稳态解给出了极限依赖性。我们的研究给出了一类双线性非局部偏变方程的概率解释。有趣的是，虽然PDE是非局部的，但底层的随机过程不需要任何非局部的相互作用。 et.al.|[2312.17139](http://arxiv.org/abs/2312.17139)|null|
|**2023-12-28**|**InsActor: Instruction-driven Physics-based Characters**|长期以来，通过直观控制生成基于物理的角色动画一直是一项具有众多应用的理想任务。然而，由于物理环境的复杂性和人类语言的丰富性，生成反映高级人类指令的物理模拟动画仍然是一个难题。在本文中，我们介绍了InsActor，这是一个原则性的生成框架，它利用基于扩散的人类运动模型的最新进展来生成基于物理的角色的指令驱动动画。我们的框架使InsActor能够通过采用扩散策略进行灵活的动作规划，来捕捉高级人类指令和角色动作之间的复杂关系。为了克服计划运动中的无效状态和不可行状态转换，InsActor发现低级技能，并将计划映射到紧凑的潜在空间中的潜在技能序列。大量实验表明，InsActor在各种任务上都取得了最先进的结果，包括指令驱动的运动生成和指令驱动的航路点航向。值得注意的是，InsActor使用高级人工指令生成物理模拟动画的能力使其成为一种有价值的工具，尤其是在使用丰富的指令集执行长期任务时。 et.al.|[2312.17135](http://arxiv.org/abs/2312.17135)|null|
|**2023-12-28**|**100-fold improvement in relaxed eddy accumulation flux estimates through error diffusion**|大气表面交换的测量在很大程度上受到快速响应气体分析仪可用性的限制；这种局限性阻碍了我们对陆地生态系统在大气化学和全球变化中的作用的理解。目前的微气象方法与慢响应气体分析仪兼容，很难实施或依赖于引入大的系统误差的经验参数。在这里，我们开发了一种新的微气象方法，该方法针对慢响应气体分析仪进行了优化，可以以最低要求直接测量不同大气成分的交换率。新方法只需要以恒定的速率对空气进行采样，并根据垂直风速的方向将其引导到两个水库中的一个。该技术的一个组成部分是误差扩散算法，该算法最大限度地减少测量通量中的偏差，并实现直接通量估计。我们证明了新方法的精度在最先进的涡流协方差测量的0.1%以内，并证明了它在最大化测量标量的信噪比方面的实用性。我们的新方法为解决复杂的环境问题提供了一种简单可靠的方法，并为推进我们对生态系统和大气化学的理解提供了一条有希望的途径。 et.al.|[2312.17027](http://arxiv.org/abs/2312.17027)|null|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

